{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrieval Dataset Analysis Report\n\n",
    "## 1. Methodology\n",
    "Analysis of empirical relevance using Monte Carlo Causal Inference.\n\n",
    "### Algorithm\n",
    "1. Randomized Trials (N=40)\n",
    "2. Blind Solving\n",
    "3. Impact Scoring (Delta P)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "import json\n",
    "from pathlib import Path\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "from tools.retrieval_dataset_generation.lib import RetrievalDataset, RetrievalCase\n",
    "\n",
    "print(f\"Current Working Directory: {os.getcwd()}\")\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = (10, 6)\n",
    "pd.set_option('display.max_colwidth', 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Logs\n",
    "trial_events = []\n",
    "convergence_events = []\n",
    "trials_df = pd.DataFrame()\n",
    "log_files = glob.glob(\"../logs/*.yaml\")\n",
    "if not log_files: log_files = glob.glob(\"logs/*.yaml\")\n",
    "\n",
    "if log_files:\n",
    "    latest_log = max(log_files, key=os.path.getctime)\n",
    "    print(f\"Loading logs from: {latest_log}\")\n",
    "    with open(latest_log, 'r') as f:\n",
    "        events = list(yaml.safe_load_all(f))\n",
    "    trial_events = [e for e in events if e and e.get('event') == 'trial_complete']\n",
    "    trials_df = pd.DataFrame(trial_events)\n",
    "    convergence_events = [e for e in events if e and e.get('event') == 'convergence_check']\n",
    "    print(f\"Loaded {len(trials_df)} trials.\")\n",
    "else:\n",
    "    print(\"No logs found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = Path(\"../retrieval_dataset_verified.yaml\")\n",
    "if not dataset_path.exists(): dataset_path = Path(\"retrieval_dataset_verified.yaml\")\n",
    "\n",
    "if dataset_path.exists():\n",
    "    print(f\"Loading metadata from: {dataset_path}\")\n",
    "    with open(dataset_path, 'r') as f:\n",
    "        dataset = RetrievalDataset.model_validate(yaml.safe_load(f))\n",
    "    print(f\"Loaded {len(dataset.cases)} cases.\")\n",
    "    \n",
    "    cases = dataset.cases\n",
    "    records = []\n",
    "    convergence_traces = []\n",
    "    for case in cases:\n",
    "        if 'convergence_trace' in case.metadata:\n",
    "            convergence_traces.append({'case_id': case.id, 'trace': case.metadata['convergence_trace']})\n",
    "        for ctx in case.candidates:\n",
    "            meta = ctx.metadata\n",
    "            records.append({\n",
    "                'case_id': case.id,\n",
    "                'fqn': ctx.fqn,\n",
    "                'source_type': ctx.context_type,\n",
    "                'delta_p': meta.delta_p,\n",
    "                'n_in': meta.n_in\n",
    "            })\n",
    "    stats_df = pd.DataFrame(records)\n",
    "else:\n",
    "    print(\"No dataset found.\")\n",
    "    stats_df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', None)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "\n",
    "if not stats_df.empty:\n",
    "    cases_groups = stats_df.groupby('case_id')\n",
    "    for case_id, group in cases_groups:\n",
    "        print()\n",
    "        print(f\"# Case: {case_id}\")\n",
    "        case_obj = next((c for c in dataset.cases if c.id == case_id), None)\n",
    "        if case_obj:\n",
    "             print(f\"**Query:** {case_obj.query}\")\n",
    "             print(f\"**Zero-Context Success:** {case_obj.metadata.get('zero_context_success_rate', 'N/A')}\")\n",
    "\n",
    "        sorted_group = group.sort_values('delta_p', ascending=False)\n",
    "        relevant = sorted_group[sorted_group['delta_p'] > 0.1]\n",
    "        toxic = sorted_group[sorted_group['delta_p'] < -0.1]\n",
    "        display_cols = ['fqn', 'delta_p', 'source_type', 'n_in']\n",
    "\n",
    "        if not relevant.empty:\n",
    "            print()\n",
    "            print(\"### \u2705 Relevant Documents (Delta P > 0.1)\")\n",
    "            print(relevant[display_cols].to_markdown(index=False))\n",
    "        else:\n",
    "            print()\n",
    "            print(\"*No highly relevant documents found.*\")\n",
    "\n",
    "        if not toxic.empty:\n",
    "             print()\n",
    "             print(\"### \u274c Toxic Documents (Delta P < -0.1)\")\n",
    "             print(toxic[display_cols].to_markdown(index=False))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}