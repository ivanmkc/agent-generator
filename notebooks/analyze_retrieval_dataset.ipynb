{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrieval Dataset Analysis\n",
    "\n",
    "This notebook analyzes the `retrieval_dataset_verified.yaml` generated by the validation pipeline. It visualizes the empirical impact of contexts mined from benchmarks vs. vector search.\n",
    "\n",
    "## Methodology: Monte Carlo Relevance Verification\n",
    "\n",
    "The dataset was generated using a rigorous statistical approach (Causal Inference) to determine which documentation actually improves an agent's performance.\n",
    "\n",
    "1.  **Candidate Pooling:** For each benchmark query, we gathered candidates from Gold Mining (ground truth), Vector Search, and Random Noise.\n",
    "2.  **Monte Carlo Trials:** We ran randomized Bernoulli trials ($p=0.5$). In each trial, a subset of candidates was injected into the prompt of a `gemini-2.5-flash` solver.\n",
    "3.  **Causal Impact Scoring (Delta P):** We measured the **Lift** in success probability:\n",
    "    $$\\Delta P = P(\\text{Success} | \\text{Context Present}) - P(\\text{Success} | \\text{Context Absent})$$"",
    "\n",
    "This provide a scalar measure of relevance that avoids arbitrary binary thresholding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "\n",
    "# Configure plotting\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = (10, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Data\n",
    "dataset_path = Path(\"../retrieval_dataset_verified.yaml\")\n",
    "if not dataset_path.exists():\n",
    "    print(f\"File not found: {dataset_path}\")\n",
    "else:\n",
    "    with open(dataset_path, 'r') as f:\n",
    "        data = yaml.safe_load(f)\n",
    "    \n",
    "    cases = data.get('cases', [])\n",
    "    print(f\"Loaded {len(cases)} cases.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten Candidates into a DataFrame\n",
    "records = []\n",
    "for case in cases:\n",
    "    candidates = case.get('candidates', [])\n",
    "    for ctx in candidates:\n",
    "        meta = ctx.get('metadata', {})
",
    "        records.append({\n",
    "            'case_id': case['id'],\n",
    "            'query': case['query'],\n",
    "            'fqn': ctx['fqn'],\n",
    "            'source_type': ctx['type'],\n",
    "            'delta_p': meta.get('delta_p', 0.0),\n",
    "            'p_in': meta.get('p_in', 0.0),\n",
    "            'p_out': meta.get('p_out', 0.0),\n",
    "            'n_in': meta.get('n_in', 0),\n",
    "            'se_in': meta.get('se_in', 0.0)\n",
    "        })\n",
    "\n",
    "df = pd.DataFrame(records)\n",
    "print(f\"Total Candidates Analyzed: {len(df)}\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Impact Score (Delta P) Distribution\n",
    "\n",
    "Distribution of causal impact scores across different source types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "sns.kdeplot(data=df, x='delta_p', hue='source_type', fill=True, common_norm=False)\n",
    "plt.title('Impact Score Density by Candidate Source')\n",
    "plt.xlabel('Delta P (Impact Score)')\n",
    "plt.axvline(0, color='red', linestyle='--')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Source Efficiency Analysis\n",
    "Average impact of candidates from each source."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_stats = df.groupby('source_type')['delta_p'].agg(['mean', 'std', 'count'])\n",
    "print(source_stats)\n",
    "\n",
    "sns.boxplot(data=df, x='source_type', y='delta_p', palette='Set2')\n",
    "plt.title('Impact Score Variance by Source')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. High Impact Contexts (The Signal)\n",
    "Top documents that provide the most utility for solving tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_impact = df.sort_values('delta_p', ascending=False).head(20)\n",
    "top_impact[['fqn', 'delta_p', 'se_in', 'source_type', 'case_id']]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}