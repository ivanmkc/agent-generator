- rank: 1
  id: google.adk.runners.InMemoryRunner
  name: InMemoryRunner
  file_path: google/adk/runners.py
  type: CLASS
  group: Seed
  usage_score: 40
  docstring: "An in-memory Runner for testing and development.\n\nThis runner uses in-memory implementations for artifact, session, and memory\nservices, providing a lightweight and self-contained environment for agent\nexecution.\n\nAttributes:\n    agent: The root agent to run.\n    app_name: The application name of the runner. Defaults to\n      'InMemoryRunner'."
  constructor_signature: 'def __init__(self, agent: typing.Optional[google.adk.agents.base_agent.BaseAgent], *, app_name: typing.Optional[str]=None, plugins: typing.Optional[list[google.adk.plugins.base_plugin.BasePlugin]]=None, app: typing.Optional[google.adk.apps.app.App]=None, plugin_close_timeout: float=5.0):'
  inherited_methods:
    Runner:
    - signature: 'def run(self, *, user_id: str, session_id: str, new_message: google.genai.types.Content, run_config: typing.Optional[google.adk.agents.run_config.RunConfig]=None) -> typing.Generator[google.adk.events.event.Event, None, None]:'
      docstring: "Runs the agent.\n\nNOTE:\n  This sync interface is only for local testing and convenience purpose.\n  Consider using `run_async` for production usage.\n\nIf event compaction is enabled in the App configuration, it will be\nperformed after all agent events for the current invocation have been\nyielded. The generator will only finish iterating after event\ncompaction is complete.\n\nArgs:\n  user_id: The user ID of the session.\n  session_id: The session ID of the session.\n  new_message: A new message to append to the session.\n  run_config: The run config for the agent.\n\nYields:\n  The events generated by the agent."
    - signature: 'def run_async(self, *, user_id: str, session_id: str, invocation_id: typing.Optional[str]=None, new_message: typing.Optional[google.genai.types.Content]=None, state_delta: typing.Optional[dict[str, typing.Any]]=None, run_config: typing.Optional[google.adk.agents.run_config.RunConfig]=None) -> typing.AsyncGenerator[google.adk.events.event.Event, None]:'
      docstring: "Main entry method to run the agent in this runner.\n\nIf event compaction is enabled in the App configuration, it will be\nperformed after all agent events for the current invocation have been\nyielded. The async generator will only finish iterating after event\ncompaction is complete. However, this does not block new `run_async`\ncalls for subsequent user queries, which can be started concurrently.\n\nArgs:\n  user_id: The user ID of the session.\n  session_id: The session ID of the session.\n  invocation_id: The invocation ID of the session, set this to resume an\n    interrupted invocation.\n  new_message: A new message to append to the session.\n  state_delta: Optional state changes to apply to the session.\n  run_config: The run config for the agent.\n\nYields:\n  The events generated by the agent.\n\nRaises:\n  ValueError: If the session is not found; If both invocation_id and\n    new_message are None."
    - signature: 'def execute(ctx: google.adk.agents.invocation_context.InvocationContext) -> typing.AsyncGenerator[google.adk.events.event.Event]:'
    - signature: 'def rewind_async(self, *, user_id: str, session_id: str, rewind_before_invocation_id: str) -> None:'
      docstring: Rewinds the session to before the specified invocation.
    - signature: 'def run_live(self, *, user_id: typing.Optional[str]=None, session_id: typing.Optional[str]=None, live_request_queue: google.adk.agents.live_request_queue.LiveRequestQueue, run_config: typing.Optional[google.adk.agents.run_config.RunConfig]=None, session: typing.Optional[google.adk.sessions.session.Session]=None) -> typing.AsyncGenerator[google.adk.events.event.Event, None]:'
      docstring: "Runs the agent in live mode (experimental feature).\n\nThe `run_live` method yields a stream of `Event` objects, but not all\nyielded events are saved to the session. Here's a breakdown:\n\n**Events Yielded to Callers:**\n*   **Live Model Audio Events with Inline Data:** Events containing raw\n    audio `Blob` data(`inline_data`).\n*   **Live Model Audio Events with File Data:** Both input and ouput audio\n    data are aggregated into a audio file saved into artifacts. The\n    reference to the file is saved in the event as `file_data`.\n*   **Usage Metadata:** Events containing token usage.\n*   **Transcription Events:** Both partial and non-partial transcription\n    events are yielded.\n*   **Function Call and Response Events:** Always saved.\n*   **Other Control Events:** Most control events are saved.\n\n**Events Saved to the Session:**\n*   **Live Model Audio Events with File Data:** Both input and ouput audio\n    data are aggregated into a audio file saved into\
        \ artifacts. The\n    reference to the file is saved as event in the `file_data` to session\n    if RunConfig.save_live_model_audio_to_session is True.\n*   **Usage Metadata Events:** Saved to the session.\n*   **Non-Partial Transcription Events:** Non-partial transcription events\n    are saved.\n*   **Function Call and Response Events:** Always saved.\n*   **Other Control Events:** Most control events are saved.\n\n**Events Not Saved to the Session:**\n*   **Live Model Audio Events with Inline Data:** Events containing raw\n    audio `Blob` data are **not** saved to the session.\n\nArgs:\n    user_id: The user ID for the session. Required if `session` is None.\n    session_id: The session ID for the session. Required if `session` is\n      None.\n    live_request_queue: The queue for live requests.\n    run_config: The run config for the agent.\n    session: The session to use. This parameter is deprecated, please use\n      `user_id` and `session_id` instead.\n\nYields:\n    AsyncGenerator[Event,\
        \ None]: An asynchronous generator that yields\n    `Event`\n    objects as they are produced by the agent during its live execution.\n\n.. warning::\n    This feature is **experimental** and its API or behavior may change\n    in future releases.\n\n.. NOTE::\n    Either `session` or both `user_id` and `session_id` must be provided."
    - signature: 'def execute(ctx: google.adk.agents.invocation_context.InvocationContext) -> typing.AsyncGenerator[google.adk.events.event.Event]:'
    - signature: 'def run_debug(self, user_messages: str | list[str], *, user_id: str=''debug_user_id'', session_id: str=''debug_session_id'', run_config: RunConfig | None=None, quiet: bool=False, verbose: bool=False) -> list[google.adk.events.event.Event]:'
      docstring: "Debug helper for quick agent experimentation and testing.\n\nThis convenience method is designed for developers getting started with ADK\nwho want to quickly test agents without dealing with session management,\ncontent formatting, or event streaming. It automatically handles common\nboilerplate while hiding complexity.\n\nIMPORTANT: This is for debugging and experimentation only. For production\nuse, please use the standard run_async() method which provides full control\nover session management, event streaming, and error handling.\n\nArgs:\n    user_messages: Message(s) to send to the agent. Can be: - Single string:\n      \"What is 2+2?\" - List of strings: [\"Hello!\", \"What's my name?\"]\n    user_id: User identifier. Defaults to \"debug_user_id\".\n    session_id: Session identifier for conversation persistence. Defaults to\n      \"debug_session_id\". Reuse the same ID to continue a conversation.\n    run_config: Optional configuration for the agent execution.\n\
        \    quiet: If True, suppresses console output. Defaults to False (output\n      shown).\n    verbose: If True, shows detailed tool calls and responses. Defaults to\n      False for cleaner output showing only final agent responses.\n\nReturns:\n    list[Event]: All events from all messages.\n\nRaises:\n    ValueError: If session creation/retrieval fails.\n\nExamples:\n    Quick debugging:\n    >>> runner = InMemoryRunner(agent=my_agent)\n    >>> await runner.run_debug(\"What is 2+2?\")\n\n    Multiple queries in conversation:\n    >>> await runner.run_debug([\"Hello!\", \"What's my name?\"])\n\n    Continue a debug session:\n    >>> await runner.run_debug(\"What did we discuss?\")  # Continues default\n    session\n\n    Separate debug sessions:\n    >>> await runner.run_debug(\"Hi\", user_id=\"alice\", session_id=\"debug1\")\n    >>> await runner.run_debug(\"Hi\", user_id=\"bob\", session_id=\"debug2\")\n\n    Capture events for inspection:\n    >>> events = await runner.run_debug(\"\
        Analyze this\")\n    >>> for event in events:\n    ...     inspect_event(event)\n\nNote:\n    For production applications requiring:\n    - Custom session/memory services (Spanner, Cloud SQL, etc.)\n    - Fine-grained event processing and streaming\n    - Error recovery and resumability\n    - Performance optimization\n    Please use run_async() with proper configuration."
    - signature: 'def close(self):'
      docstring: Closes the runner.
  inherited_properties:
    Runner:
    - signature: 'app_name: str'
      docstring: The app name of the runner.
    - signature: 'agent: google.adk.agents.base_agent.BaseAgent'
      docstring: The root agent to run.
    - signature: 'artifact_service: typing.Optional[google.adk.artifacts.base_artifact_service.BaseArtifactService]'
      docstring: The artifact service for the runner.
    - signature: 'plugin_manager: google.adk.plugins.plugin_manager.PluginManager'
      docstring: The plugin manager for the runner.
    - signature: 'session_service: google.adk.sessions.base_session_service.BaseSessionService'
      docstring: The session service for the runner.
    - signature: 'memory_service: typing.Optional[google.adk.memory.base_memory_service.BaseMemoryService]'
      docstring: The memory service for the runner.
    - signature: 'credential_service: typing.Optional[google.adk.auth.credential_service.base_credential_service.BaseCredentialService]'
      docstring: The credential service for the runner.
    - signature: 'context_cache_config: typing.Optional[google.adk.agents.context_cache_config.ContextCacheConfig]'
      docstring: The context cache config for the runner.
    - signature: 'resumability_config: typing.Optional[google.adk.apps.app.ResumabilityConfig]'
      docstring: The resumability config for the application.
    - signature: 'Self: str'
- rank: 2
  id: google.adk.tools.agent_tool.AgentTool
  name: AgentTool
  file_path: google/adk/tools/agent_tool.py
  type: CLASS
  group: Seed
  usage_score: 30
  docstring: "A tool that wraps an agent.\n\nThis tool allows an agent to be called as a tool within a larger application.\nThe agent's input schema is used to define the tool's input parameters, and\nthe agent's output is returned as the tool's result.\n\nAttributes:\n  agent: The agent to wrap.\n  skip_summarization: Whether to skip summarization of the agent output.\n  include_plugins: Whether to propagate plugins from the parent runner context\n    to the agent's runner. When True (default), the agent will inherit all\n    plugins from its parent. Set to False to run the agent with an isolated\n    plugin environment.\n\n[Note: Inherited members from ABC are omitted.]"
  constructor_signature: 'def __init__(self, agent: google.adk.agents.base_agent.BaseAgent, skip_summarization: bool, *, include_plugins: bool=True):'
  aliases:
  - google.adk.tools.AgentTool
  methods:
  - signature: 'def populate_name(cls, data: typing.Any) -> typing.Any:'
  - signature: 'def run_async(self, *, args: dict[str, typing.Any], tool_context: google.adk.tools.tool_context.ToolContext) -> typing.Any:'
  - signature: 'def from_config(cls, config: google.adk.tools.tool_configs.ToolArgsConfig, config_abs_path: str) -> google.adk.tools.agent_tool.AgentTool:'
  inherited_methods:
    BaseTool:
    - signature: 'def run_async(self, *, args: dict[str, typing.Any], tool_context: google.adk.tools.tool_context.ToolContext) -> typing.Any:'
      docstring: "Runs the tool with the given arguments and context.\n\nNOTE:\n  - Required if this tool needs to run at the client side.\n  - Otherwise, can be skipped, e.g. for a built-in GoogleSearch tool for\n    Gemini.\n\nArgs:\n  args: The LLM-filled arguments.\n  tool_context: The context of the tool.\n\nReturns:\n  The result of running the tool."
    - signature: 'def process_llm_request(self, *, tool_context: google.adk.tools.tool_context.ToolContext, llm_request: google.adk.models.llm_request.LlmRequest) -> None:'
      docstring: "Processes the outgoing LLM request for this tool.\n\nUse cases:\n- Most common use case is adding this tool to the LLM request.\n- Some tools may just preprocess the LLM request before it's sent out.\n\nArgs:\n  tool_context: The context of the tool.\n  llm_request: The outgoing LLM request, mutable this method."
    - signature: 'def from_config(cls: typing.Type[google.adk.tools.base_tool.SelfTool], config: google.adk.tools.tool_configs.ToolArgsConfig, config_abs_path: str) -> google.adk.tools.base_tool.SelfTool:'
      docstring: "Creates a tool instance from a config.\n\nThis default implementation uses inspect to automatically map config values\nto constructor arguments based on their type hints. Subclasses should\noverride this method for custom initialization logic.\n\nArgs:\n  config: The config for the tool.\n  config_abs_path: The absolute path to the config file that contains the\n    tool config.\n\nReturns:\n  The tool instance."
  inherited_properties:
    BaseTool:
    - signature: 'name: str'
      docstring: The name of the tool.
    - signature: 'description: str'
      docstring: The description of the tool.
    - signature: 'is_long_running: bool'
      docstring: 'Whether the tool is a long running operation, which typically returns a

        resource id first and finishes the operation later.'
    - signature: 'custom_metadata: typing.Optional[dict[str, typing.Any]]'
      docstring: 'The custom metadata of the BaseTool.


        An optional key-value pair for storing and retrieving tool-specific metadata,

        such as tool manifests, etc.


        NOTE: the entire dict must be JSON serializable.'
  omitted_inherited_members_from:
  - ABC
- rank: 3
  id: google.adk.agents.llm_agent.LlmAgent
  name: LlmAgent
  file_path: google/adk/agents/llm_agent.py
  type: CLASS
  group: Seed
  usage_score: 27
  docstring: 'LLM-based Agent.


    [Note: Inherited members from pydantic.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, name: str, description: str = '''', sub_agents: list[google.adk.agents.base_agent.BaseAgent] = list(), before_agent_callback: typing.Optional[google.adk.agents.base_agent.BeforeAgentCallback] = None, after_agent_callback: typing.Optional[google.adk.agents.base_agent.AfterAgentCallback] = None, model: typing.Union[str, google.adk.models.base_llm.BaseLlm] = '''', instruction: typing.Union[str, google.adk.agents.llm_agent.InstructionProvider] = '''', global_instruction: typing.Union[str, google.adk.agents.llm_agent.InstructionProvider] = '''', static_instruction: typing.Optional[google.genai.types.ContentUnion] = None, tools: list[google.adk.agents.llm_agent.ToolUnion] = list(), generate_content_config: typing.Optional[google.genai.types.GenerateContentConfig] = None, disallow_transfer_to_parent: bool = False, disallow_transfer_to_peers: bool = False, include_contents: typing.Literal[default, none] = ''default'', input_schema: typing.Optional[type[pydantic.BaseModel]]
    = None, output_schema: typing.Optional[type[pydantic.BaseModel]] = None, output_key: typing.Optional[str] = None, planner: typing.Optional[google.adk.planners.base_planner.BasePlanner] = None, code_executor: typing.Optional[google.adk.code_executors.base_code_executor.BaseCodeExecutor] = None, before_model_callback: typing.Optional[google.adk.agents.llm_agent.BeforeModelCallback] = None, after_model_callback: typing.Optional[google.adk.agents.llm_agent.AfterModelCallback] = None, on_model_error_callback: typing.Optional[google.adk.agents.llm_agent.OnModelErrorCallback] = None, before_tool_callback: typing.Optional[google.adk.agents.llm_agent.BeforeToolCallback] = None, after_tool_callback: typing.Optional[google.adk.agents.llm_agent.AfterToolCallback] = None, on_tool_error_callback: typing.Optional[google.adk.agents.llm_agent.OnToolErrorCallback] = None):'
  methods:
  - signature: 'def _run_async_impl(self, ctx: google.adk.agents.invocation_context.InvocationContext) -> typing.AsyncGenerator[google.adk.events.event.Event, None]:'
  - signature: 'def collect_agents(agent):'
  - signature: 'def validate_generate_content_config(cls, generate_content_config: typing.Optional[google.genai.types.GenerateContentConfig]) -> google.genai.types.GenerateContentConfig:'
  properties:
  - signature: 'model: typing.Union[str, google.adk.models.base_llm.BaseLlm]'
    docstring: 'The model to use for the agent.


      When not set, the agent will inherit the model from its ancestor.'
  - signature: 'config_type: typing.ClassVar[typing.Type[google.adk.agents.base_agent_config.BaseAgentConfig]]'
    docstring: The config type for this agent.
  - signature: 'instruction: typing.Union[str, google.adk.agents.llm_agent.InstructionProvider]'
    docstring: 'Dynamic instructions for the LLM model, guiding the agent''s behavior.


      These instructions can contain placeholders like {variable_name} that will be

      resolved at runtime using session state and context.


      **Behavior depends on static_instruction:**

      - If static_instruction is None: instruction goes to system_instruction

      - If static_instruction is set: instruction goes to user content in the request


      This allows for context caching optimization where static content (static_instruction)

      comes first in the prompt, followed by dynamic content (instruction).'
  - signature: 'global_instruction: typing.Union[str, google.adk.agents.llm_agent.InstructionProvider]'
    docstring: 'Instructions for all the agents in the entire agent tree.


      DEPRECATED: This field is deprecated and will be removed in a future version.

      Use GlobalInstructionPlugin instead, which provides the same functionality

      at the App level. See migration guide for details.


      ONLY the global_instruction in root agent will take effect.


      For example: use global_instruction to make all agents have a stable identity

      or personality.'
  - signature: 'static_instruction: typing.Optional[google.genai.types.ContentUnion]'
    docstring: "Static instruction content sent literally as system instruction at the beginning.\n\nThis field is for content that never changes and doesn't contain placeholders.\nIt's sent directly to the model without any processing or variable substitution.\n\nThis field is primarily for context caching optimization. Static instructions\nare sent as system instruction at the beginning of the request, allowing\nfor improved performance when the static portion remains unchanged. Live API\nhas its own cache mechanism, thus this field doesn't work with Live API.\n\n**Impact on instruction field:**\n- When static_instruction is None: instruction \u2192 system_instruction\n- When static_instruction is set: instruction \u2192 user content (after static content)\n\n**Context Caching:**\n- **Implicit Cache**: Automatic caching by model providers (no config needed)\n- **Explicit Cache**: Cache explicitly created by user for instructions, tools and contents\n\nSee below for more information of\
      \ Implicit Cache and Explicit Cache\nGemini API: https://ai.google.dev/gemini-api/docs/caching?lang=python\nVertex API: https://cloud.google.com/vertex-ai/generative-ai/docs/context-cache/context-cache-overview\n\nSetting static_instruction alone does NOT enable caching automatically.\nFor explicit caching control, configure context_cache_config at App level.\n\n**Content Support:**\nAccepts types.ContentUnion which includes:\n- str: Simple text instruction\n- types.Content: Rich content object\n- types.Part: Single part (text, inline_data, file_data, etc.)\n- PIL.Image.Image: Image object\n- types.File: File reference\n- list[PartUnion]: List of parts\n\n**Examples:**\n```python\n# Simple string instruction\nstatic_instruction = \"You are a helpful assistant.\"\n\n# Rich content with files\nstatic_instruction = types.Content(\n    role='user',\n    parts=[\n        types.Part(text='You are a helpful assistant.'),\n        types.Part(file_data=types.FileData(...))\n    ]\n)\n```"
  - signature: 'tools: list[google.adk.agents.llm_agent.ToolUnion]'
    docstring: Tools available to this agent.
  - signature: 'generate_content_config: typing.Optional[google.genai.types.GenerateContentConfig]'
    docstring: 'The additional content generation configurations.


      NOTE: not all fields are usable, e.g. tools must be configured via `tools`,

      thinking_config must be configured via `planner` in LlmAgent.


      For example: use this config to adjust model temperature, configure safety

      settings, etc.'
  - signature: 'disallow_transfer_to_parent: bool'
    docstring: 'Disallows LLM-controlled transferring to the parent agent.


      NOTE: Setting this as True also prevents this agent from continuing to reply

      to the end-user, and will transfer control back to the parent agent in the

      next turn. This behavior prevents one-way transfer, in which end-user may be

      stuck with one agent that cannot transfer to other agents in the agent tree.'
  - signature: 'disallow_transfer_to_peers: bool'
    docstring: Disallows LLM-controlled transferring to the peer agents.
  - signature: 'include_contents: typing.Literal[default, none]'
    docstring: "Controls content inclusion in model requests.\n\nOptions:\n  default: Model receives relevant conversation history\n  none: Model receives no prior history, operates solely on current\n  instruction and input"
  - signature: 'input_schema: typing.Optional[type[pydantic.BaseModel]]'
    docstring: The input schema when agent is used as a tool.
  - signature: 'output_schema: typing.Optional[type[pydantic.BaseModel]]'
    docstring: "The output schema when agent replies.\n\nNOTE:\n  When this is set, agent can ONLY reply and CANNOT use any tools, such as\n  function tools, RAGs, agent transfer, etc."
  - signature: 'output_key: typing.Optional[str]'
    docstring: 'The key in session state to store the output of the agent.


      Typically use cases:

      - Extracts agent reply for later use, such as in tools, callbacks, etc.

      - Connects agents to coordinate with each other.'
  - signature: 'planner: typing.Optional[google.adk.planners.base_planner.BasePlanner]'
    docstring: "Instructs the agent to make a plan and execute it step by step.\n\nNOTE:\n  To use model's built-in thinking features, set the `thinking_config`\n  field in `google.adk.planners.built_in_planner`."
  - signature: 'code_executor: typing.Optional[google.adk.code_executors.base_code_executor.BaseCodeExecutor]'
    docstring: "Allow agent to execute code blocks from model responses using the provided\nCodeExecutor.\n\nCheck out available code executions in `google.adk.code_executor` package.\n\nNOTE:\n  To use model's built-in code executor, use the `BuiltInCodeExecutor`."
  - signature: 'before_model_callback: typing.Optional[google.adk.agents.llm_agent.BeforeModelCallback]'
    docstring: "Callback or list of callbacks to be called before calling the LLM.\n\nWhen a list of callbacks is provided, the callbacks will be called in the\norder they are listed until a callback does not return None.\n\nArgs:\n  callback_context: CallbackContext,\n  llm_request: LlmRequest, The raw model request. Callback can mutate the\n  request.\n\nReturns:\n  The content to return to the user. When present, the model call will be\n  skipped and the provided content will be returned to user."
  - signature: 'after_model_callback: typing.Optional[google.adk.agents.llm_agent.AfterModelCallback]'
    docstring: "Callback or list of callbacks to be called after calling the LLM.\n\nWhen a list of callbacks is provided, the callbacks will be called in the\norder they are listed until a callback does not return None.\n\nArgs:\n  callback_context: CallbackContext,\n  llm_response: LlmResponse, the actual model response.\n\nReturns:\n  The content to return to the user. When present, the actual model response\n  will be ignored and the provided content will be returned to user."
  - signature: 'on_model_error_callback: typing.Optional[google.adk.agents.llm_agent.OnModelErrorCallback]'
    docstring: "Callback or list of callbacks to be called when a model call encounters an error.\n\nWhen a list of callbacks is provided, the callbacks will be called in the\norder they are listed until a callback does not return None.\n\nArgs:\n  callback_context: CallbackContext,\n  llm_request: LlmRequest, The raw model request.\n  error: The error from the model call.\n\nReturns:\n  The content to return to the user. When present, the error will be\n  ignored and the provided content will be returned to user."
  - signature: 'before_tool_callback: typing.Optional[google.adk.agents.llm_agent.BeforeToolCallback]'
    docstring: "Callback or list of callbacks to be called before calling the tool.\n\nWhen a list of callbacks is provided, the callbacks will be called in the\norder they are listed until a callback does not return None.\n\nArgs:\n  tool: The tool to be called.\n  args: The arguments to the tool.\n  tool_context: ToolContext,\n\nReturns:\n  The tool response. When present, the returned tool response will be used and\n  the framework will skip calling the actual tool."
  - signature: 'after_tool_callback: typing.Optional[google.adk.agents.llm_agent.AfterToolCallback]'
    docstring: "Callback or list of callbacks to be called after calling the tool.\n\nWhen a list of callbacks is provided, the callbacks will be called in the\norder they are listed until a callback does not return None.\n\nArgs:\n  tool: The tool to be called.\n  args: The arguments to the tool.\n  tool_context: ToolContext,\n  tool_response: The response from the tool.\n\nReturns:\n  When present, the returned dict will be used as tool result."
  - signature: 'on_tool_error_callback: typing.Optional[google.adk.agents.llm_agent.OnToolErrorCallback]'
    docstring: "Callback or list of callbacks to be called when a tool call encounters an error.\n\nWhen a list of callbacks is provided, the callbacks will be called in the\norder they are listed until a callback does not return None.\n\nArgs:\n  tool: The tool to be called.\n  args: The arguments to the tool.\n  tool_context: ToolContext,\n  error: The error from the tool call.\n\nReturns:\n  When present, the returned dict will be used as tool result."
  inherited_methods:
    BaseAgent:
    - signature: 'def clone(self: google.adk.agents.base_agent.SelfAgent, update: Mapping[str, Any] | None) -> google.adk.agents.base_agent.SelfAgent:'
      docstring: "Creates a copy of this agent instance.\n\nArgs:\n  update: Optional mapping of new values for the fields of the cloned agent.\n    The keys of the mapping are the names of the fields to be updated, and\n    the values are the new values for those fields.\n    For example: {\"name\": \"cloned_agent\"}\n\nReturns:\n  A new agent instance with identical configuration as the original\n  agent except for the fields specified in the update."
    - signature: 'def run_async(self, parent_context: google.adk.agents.invocation_context.InvocationContext) -> typing.AsyncGenerator[google.adk.events.event.Event, None]:'
      docstring: "Entry method to run an agent via text-based conversation.\n\nArgs:\n  parent_context: InvocationContext, the invocation context of the parent\n    agent.\n\nYields:\n  Event: the events generated by the agent."
    - signature: 'def run_live(self, parent_context: google.adk.agents.invocation_context.InvocationContext) -> typing.AsyncGenerator[google.adk.events.event.Event, None]:'
      docstring: "Entry method to run an agent via video/audio-based conversation.\n\nArgs:\n  parent_context: InvocationContext, the invocation context of the parent\n    agent.\n\nYields:\n  Event: the events generated by the agent."
    - signature: 'def _run_async_impl(self, ctx: google.adk.agents.invocation_context.InvocationContext) -> typing.AsyncGenerator[google.adk.events.event.Event, None]:'
      docstring: "Core logic to run this agent via text-based conversation.\n\nArgs:\n  ctx: InvocationContext, the invocation context for this agent.\n\nYields:\n  Event: the events generated by the agent."
    - signature: 'def root_agent(self) -> google.adk.agents.base_agent.BaseAgent:'
      docstring: Gets the root agent of this agent.
    - signature: 'def find_agent(self, name: str) -> typing.Optional[google.adk.agents.base_agent.BaseAgent]:'
      docstring: "Finds the agent with the given name in this agent and its descendants.\n\nArgs:\n  name: The name of the agent to find.\n\nReturns:\n  The agent with the matching name, or None if no such agent is found."
    - signature: 'def find_sub_agent(self, name: str) -> typing.Optional[google.adk.agents.base_agent.BaseAgent]:'
      docstring: "Finds the agent with the given name in this agent's descendants.\n\nArgs:\n  name: The name of the agent to find.\n\nReturns:\n  The agent with the matching name, or None if no such agent is found."
    - signature: 'def model_post_init(self, __context: typing.Any) -> None:'
    - signature: 'def validate_name(cls, value: str):'
    - signature: 'def validate_sub_agents_unique_names(cls, value: list[google.adk.agents.base_agent.BaseAgent]) -> list[google.adk.agents.base_agent.BaseAgent]:'
      docstring: "Validates that all sub-agents have unique names.\n\nArgs:\n  value: The list of sub-agents to validate.\n\nReturns:\n  The validated list of sub-agents."
    - signature: 'def from_config(cls: typing.Type[google.adk.agents.base_agent.SelfAgent], config: google.adk.agents.base_agent_config.BaseAgentConfig, config_abs_path: str) -> google.adk.agents.base_agent.SelfAgent:'
      docstring: "Creates an agent from a config.\n\nIf sub-classes uses a custom agent config, override `_from_config_kwargs`\nmethod to return an updated kwargs for agent constructor.\n\nArgs:\n  config: The config to create the agent from.\n  config_abs_path: The absolute path to the config file that contains the\n    agent config.\n\nReturns:\n  The created agent."
  inherited_properties:
    BaseAgent:
    - signature: 'model_config: pydantic.ConfigDict'
      docstring: The pydantic model config.
    - signature: 'config_type: typing.ClassVar[type[google.adk.agents.base_agent_config.BaseAgentConfig]]'
      docstring: "The config type for this agent.\n\nSub-classes should override this to specify their own config type.\n\nExample:\n\n```\nclass MyAgentConfig(BaseAgentConfig):\n  my_field: str = ''\n\nclass MyAgent(BaseAgent):\n  config_type: ClassVar[type[BaseAgentConfig]] = MyAgentConfig\n```"
    - signature: 'name: str'
      docstring: 'The agent''s name.


        Agent name must be a Python identifier and unique within the agent tree.

        Agent name cannot be "user", since it''s reserved for end-user''s input.'
    - signature: 'description: str'
      docstring: 'Description about the agent''s capability.


        The model uses this to determine whether to delegate control to the agent.

        One-line description is enough and preferred.'
    - signature: 'parent_agent: typing.Optional[google.adk.agents.base_agent.BaseAgent]'
      docstring: 'The parent agent of this agent.


        Note that an agent can ONLY be added as sub-agent once.


        If you want to add one agent twice as sub-agent, consider to create two agent

        instances with identical config, but with different name and add them to the

        agent tree.'
    - signature: 'sub_agents: list[google.adk.agents.base_agent.BaseAgent]'
      docstring: The sub-agents of this agent.
    - signature: 'before_agent_callback: typing.Optional[google.adk.agents.base_agent.BeforeAgentCallback]'
      docstring: "Callback or list of callbacks to be invoked before the agent run.\n\nWhen a list of callbacks is provided, the callbacks will be called in the\norder they are listed until a callback does not return None.\n\nArgs:\n  callback_context: MUST be named 'callback_context' (enforced).\n\nReturns:\n  Optional[types.Content]: The content to return to the user.\n    When the content is present, the agent run will be skipped and the\n    provided content will be returned to user."
    - signature: 'after_agent_callback: typing.Optional[google.adk.agents.base_agent.AfterAgentCallback]'
      docstring: "Callback or list of callbacks to be invoked after the agent run.\n\nWhen a list of callbacks is provided, the callbacks will be called in the\norder they are listed until a callback does not return None.\n\nArgs:\n  callback_context: MUST be named 'callback_context' (enforced).\n\nReturns:\n  Optional[types.Content]: The content to return to the user.\n    When the content is present, an additional event with the provided content\n    will be appended to event history as an additional agent response."
    BaseModel:
    - signature: 'model_config: pydantic.ConfigDict'
  omitted_inherited_members_from:
  - pydantic.BaseModel
- rank: 4
  id: google.adk.cli.utils.logs.log_to_tmp_folder
  name: log_to_tmp_folder
  file_path: google/adk/cli/utils/logs.py
  type: METHOD
  group: Seed
  usage_score: 18
  docstring: "Logs to system temp folder, instead of logging to stderr.\n\nArgs\n  sub_folder: str = 'agents_log',\n  log_file_prefix: str = 'agent',\n  log_file_timestamp: str = time.strftime('%Y%m%d_%H%M%S'),\n\nReturns\n  the log file path."
  signature: 'def log_to_tmp_folder(level, *, sub_folder: str=''agents_log'', log_file_prefix: str=''agent'', log_file_timestamp: str=time.strftime(''%Y%m%d_%H%M%S'')):'
- rank: 5
  id: google.adk.agents.run_config.RunConfig
  name: RunConfig
  file_path: google/adk/agents/run_config.py
  type: CLASS
  group: Seed
  usage_score: 16
  docstring: 'Configs for runtime behavior of agents.


    The configs here will be overridden by agent-specific configurations.


    [Note: Inherited members from pydantic.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, speech_config: typing.Optional[google.genai.types.SpeechConfig] = None, response_modalities: typing.Optional[list[str]] = None, save_input_blobs_as_artifacts: bool = False, support_cfc: bool = False, streaming_mode: google.adk.agents.run_config.StreamingMode = StreamingMode.NONE, output_audio_transcription: typing.Optional[google.genai.types.AudioTranscriptionConfig] = Factory(types.AudioTranscriptionConfig), input_audio_transcription: typing.Optional[google.genai.types.AudioTranscriptionConfig] = Factory(types.AudioTranscriptionConfig), realtime_input_config: typing.Optional[google.genai.types.RealtimeInputConfig] = None, enable_affective_dialog: typing.Optional[bool] = None, proactivity: typing.Optional[google.genai.types.ProactivityConfig] = None, session_resumption: typing.Optional[google.genai.types.SessionResumptionConfig] = None, context_window_compression: typing.Optional[google.genai.types.ContextWindowCompressionConfig] = None, save_live_blob:
    bool = False, save_live_audio: bool = False, max_llm_calls: int = 500, custom_metadata: typing.Optional[dict[str, typing.Any]] = None):'
  methods:
  - signature: 'def check_for_deprecated_save_live_audio(cls, data: typing.Any) -> typing.Any:'
    docstring: If save_live_audio is passed, use it to set save_live_blob.
  - signature: 'def validate_max_llm_calls(cls, value: int) -> int:'
  properties:
  - signature: 'model_config: pydantic.ConfigDict'
    docstring: The pydantic model config.
  - signature: 'speech_config: typing.Optional[google.genai.types.SpeechConfig]'
    docstring: Speech configuration for the live agent.
  - signature: 'response_modalities: typing.Optional[list[str]]'
    docstring: The output modalities. If not set, it's default to AUDIO.
  - signature: 'save_input_blobs_as_artifacts: bool'
  - signature: 'support_cfc: bool'
    docstring: "Whether to support CFC (Compositional Function Calling). Only applicable for\nStreamingMode.SSE. If it's true. the LIVE API will be invoked. Since only LIVE\nAPI supports CFC\n\n.. warning::\n    This feature is **experimental** and its API or behavior may change\n    in future releases."
  - signature: 'streaming_mode: google.adk.agents.run_config.StreamingMode'
    docstring: Streaming mode, None or StreamingMode.SSE or StreamingMode.BIDI.
  - signature: 'output_audio_transcription: typing.Optional[google.genai.types.AudioTranscriptionConfig]'
    docstring: Output transcription for live agents with audio response.
  - signature: 'input_audio_transcription: typing.Optional[google.genai.types.AudioTranscriptionConfig]'
    docstring: Input transcription for live agents with audio input from user.
  - signature: 'realtime_input_config: typing.Optional[google.genai.types.RealtimeInputConfig]'
    docstring: Realtime input config for live agents with audio input from user.
  - signature: 'enable_affective_dialog: typing.Optional[bool]'
    docstring: If enabled, the model will detect emotions and adapt its responses accordingly.
  - signature: 'proactivity: typing.Optional[google.genai.types.ProactivityConfig]'
    docstring: Configures the proactivity of the model. This allows the model to respond proactively to the input and to ignore irrelevant input.
  - signature: 'session_resumption: typing.Optional[google.genai.types.SessionResumptionConfig]'
    docstring: Configures session resumption mechanism. Only support transparent session resumption mode now.
  - signature: 'context_window_compression: typing.Optional[google.genai.types.ContextWindowCompressionConfig]'
    docstring: Configuration for context window compression. If set, this will enable context window compression for LLM input.
  - signature: 'save_live_blob: bool'
    docstring: Saves live video and audio data to session and artifact service.
  - signature: 'save_live_audio: bool'
  - signature: 'max_llm_calls: int'
    docstring: "A limit on the total number of llm calls for a given run.\n\nValid Values:\n  - More than 0 and less than sys.maxsize: The bound on the number of llm\n    calls is enforced, if the value is set in this range.\n  - Less than or equal to 0: This allows for unbounded number of llm calls."
  - signature: 'custom_metadata: typing.Optional[dict[str, typing.Any]]'
    docstring: Custom metadata for the current invocation.
  inherited_properties:
    BaseModel:
    - signature: 'model_config: pydantic.ConfigDict'
  omitted_inherited_members_from:
  - pydantic.BaseModel
- rank: 6
  id: google.adk.agents.loop_agent.LoopAgent
  name: LoopAgent
  file_path: google/adk/agents/loop_agent.py
  type: CLASS
  group: Seed
  usage_score: 16
  docstring: 'A shell agent that run its sub-agents in a loop.


    When sub-agent generates an event with escalate or max_iterations are

    reached, the loop agent will stop.


    [Note: Inherited members from pydantic.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, name: str, description: str = '''', sub_agents: list[google.adk.agents.base_agent.BaseAgent] = list(), before_agent_callback: typing.Optional[google.adk.agents.base_agent.BeforeAgentCallback] = None, after_agent_callback: typing.Optional[google.adk.agents.base_agent.AfterAgentCallback] = None, max_iterations: typing.Optional[int] = None):'
  methods:
  - signature: 'def _run_async_impl(self, ctx: google.adk.agents.invocation_context.InvocationContext) -> typing.AsyncGenerator[google.adk.events.event.Event, None]:'
  properties:
  - signature: 'config_type: typing.ClassVar[type[google.adk.agents.base_agent_config.BaseAgentConfig]]'
    docstring: The config type for this agent.
  - signature: 'max_iterations: typing.Optional[int]'
    docstring: 'The maximum number of iterations to run the loop agent.


      If not set, the loop agent will run indefinitely until a sub-agent

      escalates.'
  inherited_methods:
    BaseAgent:
    - signature: 'def clone(self: google.adk.agents.base_agent.SelfAgent, update: Mapping[str, Any] | None) -> google.adk.agents.base_agent.SelfAgent:'
      docstring: "Creates a copy of this agent instance.\n\nArgs:\n  update: Optional mapping of new values for the fields of the cloned agent.\n    The keys of the mapping are the names of the fields to be updated, and\n    the values are the new values for those fields.\n    For example: {\"name\": \"cloned_agent\"}\n\nReturns:\n  A new agent instance with identical configuration as the original\n  agent except for the fields specified in the update."
    - signature: 'def run_async(self, parent_context: google.adk.agents.invocation_context.InvocationContext) -> typing.AsyncGenerator[google.adk.events.event.Event, None]:'
      docstring: "Entry method to run an agent via text-based conversation.\n\nArgs:\n  parent_context: InvocationContext, the invocation context of the parent\n    agent.\n\nYields:\n  Event: the events generated by the agent."
    - signature: 'def run_live(self, parent_context: google.adk.agents.invocation_context.InvocationContext) -> typing.AsyncGenerator[google.adk.events.event.Event, None]:'
      docstring: "Entry method to run an agent via video/audio-based conversation.\n\nArgs:\n  parent_context: InvocationContext, the invocation context of the parent\n    agent.\n\nYields:\n  Event: the events generated by the agent."
    - signature: 'def _run_async_impl(self, ctx: google.adk.agents.invocation_context.InvocationContext) -> typing.AsyncGenerator[google.adk.events.event.Event, None]:'
      docstring: "Core logic to run this agent via text-based conversation.\n\nArgs:\n  ctx: InvocationContext, the invocation context for this agent.\n\nYields:\n  Event: the events generated by the agent."
    - signature: 'def root_agent(self) -> google.adk.agents.base_agent.BaseAgent:'
      docstring: Gets the root agent of this agent.
    - signature: 'def find_agent(self, name: str) -> typing.Optional[google.adk.agents.base_agent.BaseAgent]:'
      docstring: "Finds the agent with the given name in this agent and its descendants.\n\nArgs:\n  name: The name of the agent to find.\n\nReturns:\n  The agent with the matching name, or None if no such agent is found."
    - signature: 'def find_sub_agent(self, name: str) -> typing.Optional[google.adk.agents.base_agent.BaseAgent]:'
      docstring: "Finds the agent with the given name in this agent's descendants.\n\nArgs:\n  name: The name of the agent to find.\n\nReturns:\n  The agent with the matching name, or None if no such agent is found."
    - signature: 'def model_post_init(self, __context: typing.Any) -> None:'
    - signature: 'def validate_name(cls, value: str):'
    - signature: 'def validate_sub_agents_unique_names(cls, value: list[google.adk.agents.base_agent.BaseAgent]) -> list[google.adk.agents.base_agent.BaseAgent]:'
      docstring: "Validates that all sub-agents have unique names.\n\nArgs:\n  value: The list of sub-agents to validate.\n\nReturns:\n  The validated list of sub-agents."
    - signature: 'def from_config(cls: typing.Type[google.adk.agents.base_agent.SelfAgent], config: google.adk.agents.base_agent_config.BaseAgentConfig, config_abs_path: str) -> google.adk.agents.base_agent.SelfAgent:'
      docstring: "Creates an agent from a config.\n\nIf sub-classes uses a custom agent config, override `_from_config_kwargs`\nmethod to return an updated kwargs for agent constructor.\n\nArgs:\n  config: The config to create the agent from.\n  config_abs_path: The absolute path to the config file that contains the\n    agent config.\n\nReturns:\n  The created agent."
  inherited_properties:
    BaseAgent:
    - signature: 'model_config: pydantic.ConfigDict'
      docstring: The pydantic model config.
    - signature: 'config_type: typing.ClassVar[type[google.adk.agents.base_agent_config.BaseAgentConfig]]'
      docstring: "The config type for this agent.\n\nSub-classes should override this to specify their own config type.\n\nExample:\n\n```\nclass MyAgentConfig(BaseAgentConfig):\n  my_field: str = ''\n\nclass MyAgent(BaseAgent):\n  config_type: ClassVar[type[BaseAgentConfig]] = MyAgentConfig\n```"
    - signature: 'name: str'
      docstring: 'The agent''s name.


        Agent name must be a Python identifier and unique within the agent tree.

        Agent name cannot be "user", since it''s reserved for end-user''s input.'
    - signature: 'description: str'
      docstring: 'Description about the agent''s capability.


        The model uses this to determine whether to delegate control to the agent.

        One-line description is enough and preferred.'
    - signature: 'parent_agent: typing.Optional[google.adk.agents.base_agent.BaseAgent]'
      docstring: 'The parent agent of this agent.


        Note that an agent can ONLY be added as sub-agent once.


        If you want to add one agent twice as sub-agent, consider to create two agent

        instances with identical config, but with different name and add them to the

        agent tree.'
    - signature: 'sub_agents: list[google.adk.agents.base_agent.BaseAgent]'
      docstring: The sub-agents of this agent.
    - signature: 'before_agent_callback: typing.Optional[google.adk.agents.base_agent.BeforeAgentCallback]'
      docstring: "Callback or list of callbacks to be invoked before the agent run.\n\nWhen a list of callbacks is provided, the callbacks will be called in the\norder they are listed until a callback does not return None.\n\nArgs:\n  callback_context: MUST be named 'callback_context' (enforced).\n\nReturns:\n  Optional[types.Content]: The content to return to the user.\n    When the content is present, the agent run will be skipped and the\n    provided content will be returned to user."
    - signature: 'after_agent_callback: typing.Optional[google.adk.agents.base_agent.AfterAgentCallback]'
      docstring: "Callback or list of callbacks to be invoked after the agent run.\n\nWhen a list of callbacks is provided, the callbacks will be called in the\norder they are listed until a callback does not return None.\n\nArgs:\n  callback_context: MUST be named 'callback_context' (enforced).\n\nReturns:\n  Optional[types.Content]: The content to return to the user.\n    When the content is present, an additional event with the provided content\n    will be appended to event history as an additional agent response."
    BaseModel:
    - signature: 'model_config: pydantic.ConfigDict'
  omitted_inherited_members_from:
  - pydantic.BaseModel
- rank: 7
  id: google.adk.models.llm_response.LlmResponse
  name: LlmResponse
  file_path: google/adk/models/llm_response.py
  type: CLASS
  group: Seed
  usage_score: 16
  docstring: "LLM response class that provides the first candidate response from the\n\nmodel if available. Otherwise, returns error code and message.\n\nAttributes:\n  content: The content of the response.\n  grounding_metadata: The grounding metadata of the response.\n  partial: Indicates whether the text content is part of an unfinished text\n    stream. Only used for streaming mode and when the content is plain text.\n  turn_complete: Indicates whether the response from the model is complete.\n    Only used for streaming mode.\n  error_code: Error code if the response is an error. Code varies by model.\n  error_message: Error message if the response is an error.\n  interrupted: Flag indicating that LLM was interrupted when generating the\n    content. Usually it's due to user interruption during a bidi streaming.\n  custom_metadata: The custom metadata of the LlmResponse.\n  input_transcription: Audio transcription of user input.\n  output_transcription: Audio transcription of model\
    \ output.\n  avg_logprobs: Average log probability of the generated tokens.\n  logprobs_result: Detailed log probabilities for chosen and top candidate tokens.\n\n[Note: Inherited members from pydantic.BaseModel are omitted.]"
  constructor_signature: 'def __init__(self, *, model_version: typing.Optional[str] = None, content: typing.Optional[google.genai.types.Content] = None, grounding_metadata: typing.Optional[google.genai.types.GroundingMetadata] = None, partial: typing.Optional[bool] = None, turn_complete: typing.Optional[bool] = None, finish_reason: typing.Optional[google.genai.types.FinishReason] = None, error_code: typing.Optional[str] = None, error_message: typing.Optional[str] = None, interrupted: typing.Optional[bool] = None, custom_metadata: typing.Optional[dict[str, typing.Any]] = None, usage_metadata: typing.Optional[google.genai.types.GenerateContentResponseUsageMetadata] = None, live_session_resumption_update: typing.Optional[google.genai.types.LiveServerSessionResumptionUpdate] = None, input_transcription: typing.Optional[google.genai.types.Transcription] = None, output_transcription: typing.Optional[google.genai.types.Transcription] = None, avg_logprobs: typing.Optional[float] = None, logprobs_result:
    typing.Optional[google.genai.types.LogprobsResult] = None, cache_metadata: typing.Optional[google.adk.models.cache_metadata.CacheMetadata] = None, citation_metadata: typing.Optional[google.genai.types.CitationMetadata] = None):'
  methods:
  - signature: 'def create(generate_content_response: google.genai.types.GenerateContentResponse) -> google.adk.models.llm_response.LlmResponse:'
    docstring: "Creates an LlmResponse from a GenerateContentResponse.\n\nArgs:\n  generate_content_response: The GenerateContentResponse to create the\n    LlmResponse from.\n\nReturns:\n  The LlmResponse."
  properties:
  - signature: 'model_config: pydantic.ConfigDict'
    docstring: The pydantic model config.
  - signature: 'model_version: typing.Optional[str]'
    docstring: Output only. The model version used to generate the response.
  - signature: 'content: typing.Optional[google.genai.types.Content]'
    docstring: 'The generative content of the response.


      This should only contain content from the user or the model, and not any

      framework or system-generated data.'
  - signature: 'grounding_metadata: typing.Optional[google.genai.types.GroundingMetadata]'
    docstring: The grounding metadata of the response.
  - signature: 'partial: typing.Optional[bool]'
    docstring: 'Indicates whether the text content is part of an unfinished text stream.


      Only used for streaming mode and when the content is plain text.'
  - signature: 'turn_complete: typing.Optional[bool]'
    docstring: 'Indicates whether the response from the model is complete.


      Only used for streaming mode.'
  - signature: 'finish_reason: typing.Optional[google.genai.types.FinishReason]'
    docstring: The finish reason of the response.
  - signature: 'error_code: typing.Optional[str]'
    docstring: Error code if the response is an error. Code varies by model.
  - signature: 'error_message: typing.Optional[str]'
    docstring: Error message if the response is an error.
  - signature: 'interrupted: typing.Optional[bool]'
    docstring: 'Flag indicating that LLM was interrupted when generating the content.

      Usually it''s due to user interruption during a bidi streaming.'
  - signature: 'custom_metadata: typing.Optional[dict[str, typing.Any]]'
    docstring: 'The custom metadata of the LlmResponse.


      An optional key-value pair to label an LlmResponse.


      NOTE: the entire dict must be JSON serializable.'
  - signature: 'usage_metadata: typing.Optional[google.genai.types.GenerateContentResponseUsageMetadata]'
    docstring: The usage metadata of the LlmResponse
  - signature: 'live_session_resumption_update: typing.Optional[google.genai.types.LiveServerSessionResumptionUpdate]'
    docstring: The session resumption update of the LlmResponse
  - signature: 'input_transcription: typing.Optional[google.genai.types.Transcription]'
    docstring: Audio transcription of user input.
  - signature: 'output_transcription: typing.Optional[google.genai.types.Transcription]'
    docstring: Audio transcription of model output.
  - signature: 'avg_logprobs: typing.Optional[float]'
    docstring: Average log probability of the generated tokens.
  - signature: 'logprobs_result: typing.Optional[google.genai.types.LogprobsResult]'
    docstring: Detailed log probabilities for chosen and top candidate tokens.
  - signature: 'cache_metadata: typing.Optional[google.adk.models.cache_metadata.CacheMetadata]'
    docstring: 'Context cache metadata if caching was used for this response.


      Contains cache identification, usage tracking, and lifecycle information.

      This field is automatically populated when context caching is enabled.'
  - signature: 'citation_metadata: typing.Optional[google.genai.types.CitationMetadata]'
    docstring: 'Citation metadata for the response.


      This field is automatically populated when citation is enabled.'
  inherited_properties:
    BaseModel:
    - signature: 'model_config: pydantic.ConfigDict'
  omitted_inherited_members_from:
  - pydantic.BaseModel
- rank: 8
  id: google.adk.cli.utils.logs.setup_adk_logger
  name: setup_adk_logger
  file_path: google/adk/cli/utils/logs.py
  type: METHOD
  group: Seed
  usage_score: 14
  signature: 'def setup_adk_logger(level):'
- rank: 9
  id: google.adk.evaluation.agent_evaluator.AgentEvaluator.evaluate
  name: evaluate
  file_path: google/adk/evaluation/agent_evaluator.py
  type: METHOD
  group: Seed
  usage_score: 14
  docstring: "Evaluates an Agent given eval data.\n\nArgs:\n  agent_module: The path to python module that contains the definition of\n    the agent. There is convention in place here, where the code is going to\n    look for 'root_agent' or 'get_agent_async' in the loaded module.\n  eval_dataset_file_path_or_dir: The eval data set. This can be either a\n    string representing full path to the file containing eval dataset, or a\n    directory that is recursively explored for all files that have a\n    `.test.json` suffix.\n  num_runs: Number of times all entries in the eval dataset should be\n    assessed.\n  agent_name: The name of the agent.\n  initial_session_file: File that contains initial session state that is\n    needed by all the evals in the eval dataset.\n  print_detailed_results: Whether to print detailed results for each metric\n    evaluation."
  signature: 'def evaluate(agent_module: str, eval_dataset_file_path_or_dir: str, num_runs: int, agent_name: typing.Optional[str], initial_session_file: typing.Optional[str], print_detailed_results: bool):'
- rank: 10
  id: google.adk.events.event.Event
  name: Event
  file_path: google/adk/events/event.py
  type: CLASS
  group: Seed
  usage_score: 14
  docstring: 'Represents an event in a conversation between agents and users.


    It is used to store the content of the conversation, as well as the actions

    taken by the agents like function calls, etc.


    [Note: Inherited members from pydantic.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, model_version: typing.Optional[str] = None, content: typing.Optional[google.genai.types.Content] = None, grounding_metadata: typing.Optional[google.genai.types.GroundingMetadata] = None, partial: typing.Optional[bool] = None, turn_complete: typing.Optional[bool] = None, finish_reason: typing.Optional[google.genai.types.FinishReason] = None, error_code: typing.Optional[str] = None, error_message: typing.Optional[str] = None, interrupted: typing.Optional[bool] = None, custom_metadata: typing.Optional[dict[str, typing.Any]] = None, usage_metadata: typing.Optional[google.genai.types.GenerateContentResponseUsageMetadata] = None, live_session_resumption_update: typing.Optional[google.genai.types.LiveServerSessionResumptionUpdate] = None, input_transcription: typing.Optional[google.genai.types.Transcription] = None, output_transcription: typing.Optional[google.genai.types.Transcription] = None, avg_logprobs: typing.Optional[float] = None, logprobs_result:
    typing.Optional[google.genai.types.LogprobsResult] = None, cache_metadata: typing.Optional[google.adk.models.cache_metadata.CacheMetadata] = None, citation_metadata: typing.Optional[google.genai.types.CitationMetadata] = None, author: str, actions: google.adk.events.event_actions.EventActions = Factory(EventActions), long_running_tool_ids: typing.Optional[set[str]] = None, branch: typing.Optional[str] = None, id: str = '''', timestamp: float = Factory(lambda: datetime.now().timestamp())):'
  aliases:
  - google.adk.events.Event
  methods:
  - signature: 'def model_post_init(self, __context):'
    docstring: Post initialization logic for the event.
  - signature: 'def is_final_response(self) -> bool:'
    docstring: 'Returns whether the event is the final response of an agent.


      NOTE: This method is ONLY for use by Agent Development Kit.


      Note that when multiple agents participate in one invocation, there could be

      one event has `is_final_response()` as True for each participating agent.'
  - signature: 'def get_function_calls(self) -> list[google.genai.types.FunctionCall]:'
    docstring: Returns the function calls in the event.
  - signature: 'def get_function_responses(self) -> list[google.genai.types.FunctionResponse]:'
    docstring: Returns the function responses in the event.
  - signature: 'def has_trailing_code_execution_result(self) -> bool:'
    docstring: Returns whether the event has a trailing code execution result.
  - signature: 'def new_id():'
  properties:
  - signature: 'model_config: pydantic.ConfigDict'
    docstring: The pydantic model config.
  - signature: 'invocation_id: str'
    docstring: The invocation ID of the event. Should be non-empty before appending to a session.
  - signature: 'author: str'
    docstring: '''user'' or the name of the agent, indicating who appended the event to the

      session.'
  - signature: 'actions: google.adk.events.event_actions.EventActions'
    docstring: The actions taken by the agent.
  - signature: 'long_running_tool_ids: typing.Optional[set[str]]'
    docstring: 'Set of ids of the long running function calls.

      Agent client will know from this field about which function call is long running.

      only valid for function call event'
  - signature: 'branch: typing.Optional[str]'
    docstring: 'The branch of the event.


      The format is like agent_1.agent_2.agent_3, where agent_1 is the parent of

      agent_2, and agent_2 is the parent of agent_3.


      Branch is used when multiple sub-agent shouldn''t see their peer agents''

      conversation history.'
  - signature: 'id: str'
    docstring: The unique identifier of the event.
  - signature: 'timestamp: float'
    docstring: The timestamp of the event.
  inherited_methods:
    LlmResponse:
    - signature: 'def create(generate_content_response: google.genai.types.GenerateContentResponse) -> google.adk.models.llm_response.LlmResponse:'
      docstring: "Creates an LlmResponse from a GenerateContentResponse.\n\nArgs:\n  generate_content_response: The GenerateContentResponse to create the\n    LlmResponse from.\n\nReturns:\n  The LlmResponse."
  inherited_properties:
    LlmResponse:
    - signature: 'model_config: pydantic.ConfigDict'
      docstring: The pydantic model config.
    - signature: 'model_version: typing.Optional[str]'
      docstring: Output only. The model version used to generate the response.
    - signature: 'content: typing.Optional[google.genai.types.Content]'
      docstring: 'The generative content of the response.


        This should only contain content from the user or the model, and not any

        framework or system-generated data.'
    - signature: 'grounding_metadata: typing.Optional[google.genai.types.GroundingMetadata]'
      docstring: The grounding metadata of the response.
    - signature: 'partial: typing.Optional[bool]'
      docstring: 'Indicates whether the text content is part of an unfinished text stream.


        Only used for streaming mode and when the content is plain text.'
    - signature: 'turn_complete: typing.Optional[bool]'
      docstring: 'Indicates whether the response from the model is complete.


        Only used for streaming mode.'
    - signature: 'finish_reason: typing.Optional[google.genai.types.FinishReason]'
      docstring: The finish reason of the response.
    - signature: 'error_code: typing.Optional[str]'
      docstring: Error code if the response is an error. Code varies by model.
    - signature: 'error_message: typing.Optional[str]'
      docstring: Error message if the response is an error.
    - signature: 'interrupted: typing.Optional[bool]'
      docstring: 'Flag indicating that LLM was interrupted when generating the content.

        Usually it''s due to user interruption during a bidi streaming.'
    - signature: 'custom_metadata: typing.Optional[dict[str, typing.Any]]'
      docstring: 'The custom metadata of the LlmResponse.


        An optional key-value pair to label an LlmResponse.


        NOTE: the entire dict must be JSON serializable.'
    - signature: 'usage_metadata: typing.Optional[google.genai.types.GenerateContentResponseUsageMetadata]'
      docstring: The usage metadata of the LlmResponse
    - signature: 'live_session_resumption_update: typing.Optional[google.genai.types.LiveServerSessionResumptionUpdate]'
      docstring: The session resumption update of the LlmResponse
    - signature: 'input_transcription: typing.Optional[google.genai.types.Transcription]'
      docstring: Audio transcription of user input.
    - signature: 'output_transcription: typing.Optional[google.genai.types.Transcription]'
      docstring: Audio transcription of model output.
    - signature: 'avg_logprobs: typing.Optional[float]'
      docstring: Average log probability of the generated tokens.
    - signature: 'logprobs_result: typing.Optional[google.genai.types.LogprobsResult]'
      docstring: Detailed log probabilities for chosen and top candidate tokens.
    - signature: 'cache_metadata: typing.Optional[google.adk.models.cache_metadata.CacheMetadata]'
      docstring: 'Context cache metadata if caching was used for this response.


        Contains cache identification, usage tracking, and lifecycle information.

        This field is automatically populated when context caching is enabled.'
    - signature: 'citation_metadata: typing.Optional[google.genai.types.CitationMetadata]'
      docstring: 'Citation metadata for the response.


        This field is automatically populated when citation is enabled.'
    BaseModel:
    - signature: 'model_config: pydantic.ConfigDict'
  omitted_inherited_members_from:
  - pydantic.BaseModel
- rank: 11
  id: google.adk.artifacts.in_memory_artifact_service.InMemoryArtifactService
  name: InMemoryArtifactService
  file_path: google/adk/artifacts/in_memory_artifact_service.py
  type: CLASS
  group: Seed
  usage_score: 12
  docstring: 'An in-memory implementation of the artifact service.


    It is not suitable for multi-threaded production environments. Use it for

    testing and development only.


    [Note: Inherited members from ABC, pydantic.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, artifacts: dict[str, list[google.adk.artifacts.in_memory_artifact_service._ArtifactEntry]] = dict()):'
  methods:
  - signature: 'def save_artifact(self, *, app_name: str, user_id: str, filename: str, artifact: google.genai.types.Part, session_id: typing.Optional[str]=None, custom_metadata: typing.Optional[dict[str, typing.Any]]=None) -> int:'
  - signature: 'def load_artifact(self, *, app_name: str, user_id: str, filename: str, session_id: typing.Optional[str]=None, version: typing.Optional[int]=None) -> typing.Optional[google.genai.types.Part]:'
  - signature: 'def list_artifact_keys(self, *, app_name: str, user_id: str, session_id: typing.Optional[str]=None) -> list[str]:'
  - signature: 'def delete_artifact(self, *, app_name: str, user_id: str, filename: str, session_id: typing.Optional[str]=None) -> None:'
  - signature: 'def list_versions(self, *, app_name: str, user_id: str, filename: str, session_id: typing.Optional[str]=None) -> list[int]:'
  - signature: 'def list_artifact_versions(self, *, app_name: str, user_id: str, filename: str, session_id: typing.Optional[str]=None) -> list[google.adk.artifacts.base_artifact_service.ArtifactVersion]:'
  - signature: 'def get_artifact_version(self, *, app_name: str, user_id: str, filename: str, session_id: typing.Optional[str]=None, version: typing.Optional[int]=None) -> typing.Optional[google.adk.artifacts.base_artifact_service.ArtifactVersion]:'
  properties:
  - signature: 'artifacts: dict[str, list[google.adk.artifacts.in_memory_artifact_service._ArtifactEntry]]'
  inherited_methods:
    BaseArtifactService:
    - signature: 'def save_artifact(self, *, app_name: str, user_id: str, filename: str, artifact: google.genai.types.Part, session_id: typing.Optional[str]=None, custom_metadata: typing.Optional[dict[str, typing.Any]]=None) -> int:'
      docstring: "Saves an artifact to the artifact service storage.\n\nThe artifact is a file identified by the app name, user ID, session ID, and\nfilename. After saving the artifact, a revision ID is returned to identify\nthe artifact version.\n\nArgs:\n  app_name: The app name.\n  user_id: The user ID.\n  filename: The filename of the artifact.\n  artifact: The artifact to save. If the artifact consists of `file_data`,\n    the artifact service assumes its content has been uploaded separately,\n    and this method will associate the `file_data` with the artifact if\n    necessary.\n  session_id: The session ID. If `None`, the artifact is user-scoped.\n  custom_metadata: custom metadata to associate with the artifact.\n\nReturns:\n  The revision ID. The first version of the artifact has a revision ID of 0.\n  This is incremented by 1 after each successful save."
    - signature: 'def load_artifact(self, *, app_name: str, user_id: str, filename: str, session_id: typing.Optional[str]=None, version: typing.Optional[int]=None) -> typing.Optional[google.genai.types.Part]:'
      docstring: "Gets an artifact from the artifact service storage.\n\nThe artifact is a file identified by the app name, user ID, session ID, and\nfilename.\n\nArgs:\n  app_name: The app name.\n  user_id: The user ID.\n  filename: The filename of the artifact.\n  session_id: The session ID. If `None`, load the user-scoped artifact.\n  version: The version of the artifact. If None, the latest version will be\n    returned.\n\nReturns:\n  The artifact or None if not found."
    - signature: 'def list_artifact_keys(self, *, app_name: str, user_id: str, session_id: typing.Optional[str]=None) -> list[str]:'
      docstring: "Lists all the artifact filenames within a session.\n\nArgs:\n    app_name: The name of the application.\n    user_id: The ID of the user.\n    session_id: The ID of the session.\n\nReturns:\n    A list of artifact filenames. If `session_id` is provided, returns\n    both session-scoped and user-scoped artifact filenames. If `session_id`\n    is `None`, returns\n    user-scoped artifact filenames."
    - signature: 'def delete_artifact(self, *, app_name: str, user_id: str, filename: str, session_id: typing.Optional[str]=None) -> None:'
      docstring: "Deletes an artifact.\n\nArgs:\n    app_name: The name of the application.\n    user_id: The ID of the user.\n    filename: The name of the artifact file.\n    session_id: The ID of the session. If `None`, delete the user-scoped\n      artifact."
    - signature: 'def list_versions(self, *, app_name: str, user_id: str, filename: str, session_id: typing.Optional[str]=None) -> list[int]:'
      docstring: "Lists all versions of an artifact.\n\nArgs:\n    app_name: The name of the application.\n    user_id: The ID of the user.\n    filename: The name of the artifact file.\n    session_id: The ID of the session. If `None`, only list the user-scoped\n      artifacts versions.\n\nReturns:\n    A list of all available versions of the artifact."
    - signature: 'def list_artifact_versions(self, *, app_name: str, user_id: str, filename: str, session_id: typing.Optional[str]=None) -> list[google.adk.artifacts.base_artifact_service.ArtifactVersion]:'
      docstring: "Lists all versions and their metadata for a specific artifact.\n\nArgs:\n  app_name: The name of the application.\n  user_id: The ID of the user.\n  filename: The name of the artifact file.\n  session_id: The ID of the session. If `None`, lists versions of the\n    user-scoped artifact. Otherwise, lists versions of the artifact within\n    the specified session.\n\nReturns:\n  A list of ArtifactVersion objects, each representing a version of the\n  artifact and its associated metadata."
    - signature: 'def get_artifact_version(self, *, app_name: str, user_id: str, filename: str, session_id: typing.Optional[str]=None, version: typing.Optional[int]=None) -> typing.Optional[google.adk.artifacts.base_artifact_service.ArtifactVersion]:'
      docstring: "Gets the metadata for a specific version of an artifact.\n\nArgs:\n  app_name: The name of the application.\n  user_id: The ID of the user.\n  filename: The name of the artifact file.\n  session_id: The ID of the session. If `None`, the artifact will be fetched\n    from the user-scoped artifacts. Otherwise, it will be fetched from the\n    specified session.\n  version: The version number of the artifact to retrieve. If `None`, the\n    latest version will be returned.\n\nReturns:\n  An ArtifactVersion object containing the metadata of the specified\n  artifact version, or `None` if the artifact version is not found."
  inherited_properties:
    BaseModel:
    - signature: 'model_config: pydantic.ConfigDict'
  omitted_inherited_members_from:
  - ABC
  - pydantic.BaseModel
- rank: 12
  id: google.adk.sessions.in_memory_session_service.InMemorySessionService
  name: InMemorySessionService
  file_path: google/adk/sessions/in_memory_session_service.py
  type: CLASS
  group: Seed
  usage_score: 11
  docstring: 'An in-memory implementation of the session service.


    It is not suitable for multi-threaded production environments. Use it for

    testing and development only.


    [Note: Inherited members from abc.ABC are omitted.]'
  constructor_signature: 'def __init__(self):'
  methods:
  - signature: 'def create_session(self, *, app_name: str, user_id: str, state: typing.Optional[dict[str, typing.Any]]=None, session_id: typing.Optional[str]=None) -> google.adk.sessions.session.Session:'
  - signature: 'def create_session_sync(self, *, app_name: str, user_id: str, state: typing.Optional[dict[str, typing.Any]]=None, session_id: typing.Optional[str]=None) -> google.adk.sessions.session.Session:'
  - signature: 'def get_session(self, *, app_name: str, user_id: str, session_id: str, config: typing.Optional[google.adk.sessions.base_session_service.GetSessionConfig]=None) -> typing.Optional[google.adk.sessions.session.Session]:'
  - signature: 'def get_session_sync(self, *, app_name: str, user_id: str, session_id: str, config: typing.Optional[google.adk.sessions.base_session_service.GetSessionConfig]=None) -> typing.Optional[google.adk.sessions.session.Session]:'
  - signature: 'def list_sessions(self, *, app_name: str, user_id: typing.Optional[str]=None) -> google.adk.sessions.base_session_service.ListSessionsResponse:'
  - signature: 'def list_sessions_sync(self, *, app_name: str, user_id: typing.Optional[str]=None) -> google.adk.sessions.base_session_service.ListSessionsResponse:'
  - signature: 'def delete_session(self, *, app_name: str, user_id: str, session_id: str) -> None:'
  - signature: 'def delete_session_sync(self, *, app_name: str, user_id: str, session_id: str) -> None:'
  - signature: 'def append_event(self, session: google.adk.sessions.session.Session, event: google.adk.events.event.Event) -> google.adk.events.event.Event:'
  inherited_methods:
    BaseSessionService:
    - signature: 'def create_session(self, *, app_name: str, user_id: str, state: typing.Optional[dict[str, typing.Any]]=None, session_id: typing.Optional[str]=None) -> google.adk.sessions.session.Session:'
      docstring: "Creates a new session.\n\nArgs:\n  app_name: the name of the app.\n  user_id: the id of the user.\n  state: the initial state of the session.\n  session_id: the client-provided id of the session. If not provided, a\n    generated ID will be used.\n\nReturns:\n  session: The newly created session instance."
    - signature: 'def get_session(self, *, app_name: str, user_id: str, session_id: str, config: typing.Optional[google.adk.sessions.base_session_service.GetSessionConfig]=None) -> typing.Optional[google.adk.sessions.session.Session]:'
      docstring: Gets a session.
    - signature: 'def list_sessions(self, *, app_name: str, user_id: typing.Optional[str]=None) -> google.adk.sessions.base_session_service.ListSessionsResponse:'
      docstring: "Lists all the sessions for a user.\n\nArgs:\n  app_name: The name of the app.\n  user_id: The ID of the user. If not provided, lists all sessions for all\n    users.\n\nReturns:\n  A ListSessionsResponse containing the sessions."
    - signature: 'def delete_session(self, *, app_name: str, user_id: str, session_id: str) -> None:'
      docstring: Deletes a session.
    - signature: 'def append_event(self, session: google.adk.sessions.session.Session, event: google.adk.events.event.Event) -> google.adk.events.event.Event:'
      docstring: Appends an event to a session object.
  omitted_inherited_members_from:
  - abc.ABC
- rank: 13
  id: google.adk.models.lite_llm.LiteLlm
  name: LiteLlm
  file_path: google/adk/models/lite_llm.py
  type: CLASS
  group: Seed
  usage_score: 10
  docstring: "Wrapper around litellm.\n\nThis wrapper can be used with any of the models supported by litellm. The\nenvironment variable(s) needed for authenticating with the model endpoint must\nbe set prior to instantiating this class.\n\nExample usage:\n```\nos.environ[\"VERTEXAI_PROJECT\"] = \"your-gcp-project-id\"\nos.environ[\"VERTEXAI_LOCATION\"] = \"your-gcp-location\"\n\nagent = Agent(\n    model=LiteLlm(model=\"vertex_ai/claude-3-7-sonnet@20250219\"),\n    ...\n)\n```\n\nAttributes:\n  model: The name of the LiteLlm model.\n  llm_client: The LLM client to use for the model.\n\n[Note: Inherited members from pydantic.BaseModel are omitted.]"
  constructor_signature: 'def __init__(self, model: str):'
  methods:
  - signature: 'def generate_content_async(self, llm_request: google.adk.models.llm_request.LlmRequest, stream: bool) -> typing.AsyncGenerator[google.adk.models.llm_response.LlmResponse, None]:'
    docstring: "Generates content asynchronously.\n\nArgs:\n  llm_request: LlmRequest, the request to send to the LiteLlm model.\n  stream: bool = False, whether to do streaming call.\n\nYields:\n  LlmResponse: The model response."
  - signature: 'def supported_models(cls) -> list[str]:'
    docstring: "Provides the list of supported models.\n\nThis registers common provider prefixes. LiteLlm can handle many more,\nbut these patterns activate the integration for the most common use cases.\nSee https://docs.litellm.ai/docs/providers for a full list.\n\nReturns:\n  A list of supported models."
  properties:
  - signature: 'llm_client: google.adk.models.lite_llm.LiteLLMClient'
    docstring: The LLM client to use for the model.
  inherited_methods:
    BaseLlm:
    - signature: 'def supported_models(cls) -> list[str]:'
      docstring: Returns a list of supported models in regex for LlmRegistry.
    - signature: 'def generate_content_async(self, llm_request: google.adk.models.llm_request.LlmRequest, stream: bool) -> typing.AsyncGenerator[google.adk.models.llm_response.LlmResponse, None]:'
      docstring: "Generates content for a single model turn.\n\n    This method handles Server-Sent Events (SSE) streaming for unidirectional\n    content generation. For bidirectional streaming (e.g., Gemini Live API),\n    use the `connect()` method instead.\n\n    Args:\n      llm_request: LlmRequest, the request to send to the LLM.\n      stream: bool = False, whether to enable SSE streaming mode.\n\n    Yields:\n      LlmResponse objects representing the model's response for one turn.\n\n      **Non-streaming mode (stream=False):**\n\n        Yields exactly one LlmResponse containing the complete model output\n        (text, function calls, bytes, etc.). This response has `partial=False`.\n\n      **Streaming mode (stream=True):**\n\n        Yields multiple LlmResponse objects as chunks arrive:\n\n        - Intermediate chunks: `partial=True` (progressive updates)\n        - Final chunk: `partial=False` (aggregated content from entire turn,\n          identical to stream=False output)\n\
        \        - Text consolidation: Consecutive text parts of the same type\n          (thought/non-thought) SHOULD merge without separator, but client\n          code must not rely on this - unconsolidated parts are unusual but also\n          valid\n\n      **Common content in partial chunks:**\n\n        All intermediate chunks have `partial=True` regardless of content type.\n        Common examples include:\n\n        - Text: Streams incrementally as tokens arrive\n        - Function calls: May arrive in separate chunks\n        - Bytes (e.g., images): Typically arrive as single chunk, interleaved\n          with text\n        - Thoughts: Stream incrementally when thinking_config is enabled\n\n      **Examples:**\n\n      1. Simple text streaming::\n\n           LlmResponse(partial=True,  parts=[\"The weather\"])\n           LlmResponse(partial=True,  parts=[\" in Tokyo is\"])\n           LlmResponse(partial=True,  parts=[\" sunny.\"])\n           LlmResponse(partial=False, parts=[\"\
        The weather in Tokyo is sunny.\"])\n\n      2. Text + function call::\n\n           LlmResponse(partial=True,  parts=[Text(\"Let me check...\")])\n           LlmResponse(partial=True,  parts=[FunctionCall(\"get_weather\", ...)])\n           LlmResponse(partial=False, parts=[Text(\"Let me check...\"),\n                                             FunctionCall(\"get_weather\", ...)])\n\n      3. Parallel function calls across chunks::\n\n           LlmResponse(partial=True,  parts=[Text(\"Checking both cities...\")])\n           LlmResponse(partial=True,  parts=[FunctionCall(\"get_weather\", Tokyo)])\n           LlmResponse(partial=True,  parts=[FunctionCall(\"get_weather\", NYC)])\n           LlmResponse(partial=False, parts=[Text(\"Checking both cities...\"),\n                                             FunctionCall(\"get_weather\", Tokyo),\n                                             FunctionCall(\"get_weather\", NYC)])\n\n      4. Text + bytes (image generation with gemini-2.5-flash-image)::\n\
        \n           LlmResponse(partial=True,  parts=[Text(\"Here's an image of a dog.\")])\n           LlmResponse(partial=True,  parts=[Text(\"\n\")])\n           LlmResponse(partial=True,  parts=[Blob(image/png, 1.6MB)])\n           LlmResponse(partial=True,  parts=[Text(\"It carries a bone\")])\n           LlmResponse(partial=True,  parts=[Text(\" and running around.\")])\n           LlmResponse(partial=False, parts=[Text(\"Here's an image of a dog.\n\"),\n                                             Blob(image/png, 1.6MB),\n                                             Text(\"It carries a bone and running around.\")])\n\n         Note: Consecutive text parts before and after blob merge separately.\n\n      5. Text with thinking (gemini-2.5-flash with thinking_config)::\n\n           LlmResponse(partial=True,  parts=[Thought(\"Let me analyze...\")])\n           LlmResponse(partial=True,  parts=[Thought(\"The user wants...\")])\n           LlmResponse(partial=True,  parts=[Text(\"Based\
        \ on my analysis,\")])\n           LlmResponse(partial=True,  parts=[Text(\" the answer is 42.\")])\n           LlmResponse(partial=False, parts=[Thought(\"Let me analyze...The user wants...\"),\n                                             Text(\"Based on my analysis, the answer is 42.\")])\n\n         Note: Consecutive parts of same type merge (thoughts\u2192thought, text\u2192text).\n\n      **Important:** All yielded responses represent one logical model turn.\n      The final response with `partial=False` should be identical to the\n      response that would be received with `stream=False`.\n    "
    - signature: 'def connect(self, llm_request: google.adk.models.llm_request.LlmRequest) -> google.adk.models.base_llm_connection.BaseLlmConnection:'
      docstring: "Creates a live connection to the LLM.\n\nArgs:\n  llm_request: LlmRequest, the request to send to the LLM.\n\nReturns:\n  BaseLlmConnection, the connection to the LLM."
  inherited_properties:
    BaseLlm:
    - signature: 'model_config: pydantic.ConfigDict'
      docstring: The pydantic model config.
    - signature: 'model: str'
      docstring: The name of the LLM, e.g. gemini-2.5-flash or gemini-2.5-pro.
    BaseModel:
    - signature: 'model_config: pydantic.ConfigDict'
  omitted_inherited_members_from:
  - pydantic.BaseModel
- rank: 14
  id: google.adk.runners.Runner
  name: Runner
  file_path: google/adk/runners.py
  type: CLASS
  group: Seed
  usage_score: 8
  docstring: "The Runner class is used to run agents.\n\nIt manages the execution of an agent within a session, handling message\nprocessing, event generation, and interaction with various services like\nartifact storage, session management, and memory.\n\nAttributes:\n    app_name: The application name of the runner.\n    agent: The root agent to run.\n    artifact_service: The artifact service for the runner.\n    plugin_manager: The plugin manager for the runner.\n    session_service: The session service for the runner.\n    memory_service: The memory service for the runner.\n    credential_service: The credential service for the runner.\n    context_cache_config: The context cache config for the runner.\n    resumability_config: The resumability config for the application."
  constructor_signature: 'def __init__(self, *, app: typing.Optional[google.adk.apps.app.App]=None, app_name: typing.Optional[str]=None, agent: typing.Optional[google.adk.agents.base_agent.BaseAgent]=None, plugins: typing.Optional[typing.List[google.adk.plugins.base_plugin.BasePlugin]]=None, artifact_service: typing.Optional[google.adk.artifacts.base_artifact_service.BaseArtifactService]=None, session_service: google.adk.sessions.base_session_service.BaseSessionService, memory_service: typing.Optional[google.adk.memory.base_memory_service.BaseMemoryService]=None, credential_service: typing.Optional[google.adk.auth.credential_service.base_credential_service.BaseCredentialService]=None, plugin_close_timeout: float=5.0):'
  methods:
  - signature: 'def run(self, *, user_id: str, session_id: str, new_message: google.genai.types.Content, run_config: typing.Optional[google.adk.agents.run_config.RunConfig]=None) -> typing.Generator[google.adk.events.event.Event, None, None]:'
    docstring: "Runs the agent.\n\nNOTE:\n  This sync interface is only for local testing and convenience purpose.\n  Consider using `run_async` for production usage.\n\nIf event compaction is enabled in the App configuration, it will be\nperformed after all agent events for the current invocation have been\nyielded. The generator will only finish iterating after event\ncompaction is complete.\n\nArgs:\n  user_id: The user ID of the session.\n  session_id: The session ID of the session.\n  new_message: A new message to append to the session.\n  run_config: The run config for the agent.\n\nYields:\n  The events generated by the agent."
  - signature: 'def run_async(self, *, user_id: str, session_id: str, invocation_id: typing.Optional[str]=None, new_message: typing.Optional[google.genai.types.Content]=None, state_delta: typing.Optional[dict[str, typing.Any]]=None, run_config: typing.Optional[google.adk.agents.run_config.RunConfig]=None) -> typing.AsyncGenerator[google.adk.events.event.Event, None]:'
    docstring: "Main entry method to run the agent in this runner.\n\nIf event compaction is enabled in the App configuration, it will be\nperformed after all agent events for the current invocation have been\nyielded. The async generator will only finish iterating after event\ncompaction is complete. However, this does not block new `run_async`\ncalls for subsequent user queries, which can be started concurrently.\n\nArgs:\n  user_id: The user ID of the session.\n  session_id: The session ID of the session.\n  invocation_id: The invocation ID of the session, set this to resume an\n    interrupted invocation.\n  new_message: A new message to append to the session.\n  state_delta: Optional state changes to apply to the session.\n  run_config: The run config for the agent.\n\nYields:\n  The events generated by the agent.\n\nRaises:\n  ValueError: If the session is not found; If both invocation_id and\n    new_message are None."
  - signature: 'def execute(ctx: google.adk.agents.invocation_context.InvocationContext) -> typing.AsyncGenerator[google.adk.events.event.Event]:'
  - signature: 'def rewind_async(self, *, user_id: str, session_id: str, rewind_before_invocation_id: str) -> None:'
    docstring: Rewinds the session to before the specified invocation.
  - signature: 'def run_live(self, *, user_id: typing.Optional[str]=None, session_id: typing.Optional[str]=None, live_request_queue: google.adk.agents.live_request_queue.LiveRequestQueue, run_config: typing.Optional[google.adk.agents.run_config.RunConfig]=None, session: typing.Optional[google.adk.sessions.session.Session]=None) -> typing.AsyncGenerator[google.adk.events.event.Event, None]:'
    docstring: "Runs the agent in live mode (experimental feature).\n\nThe `run_live` method yields a stream of `Event` objects, but not all\nyielded events are saved to the session. Here's a breakdown:\n\n**Events Yielded to Callers:**\n*   **Live Model Audio Events with Inline Data:** Events containing raw\n    audio `Blob` data(`inline_data`).\n*   **Live Model Audio Events with File Data:** Both input and ouput audio\n    data are aggregated into a audio file saved into artifacts. The\n    reference to the file is saved in the event as `file_data`.\n*   **Usage Metadata:** Events containing token usage.\n*   **Transcription Events:** Both partial and non-partial transcription\n    events are yielded.\n*   **Function Call and Response Events:** Always saved.\n*   **Other Control Events:** Most control events are saved.\n\n**Events Saved to the Session:**\n*   **Live Model Audio Events with File Data:** Both input and ouput audio\n    data are aggregated into a audio file saved into artifacts.\
      \ The\n    reference to the file is saved as event in the `file_data` to session\n    if RunConfig.save_live_model_audio_to_session is True.\n*   **Usage Metadata Events:** Saved to the session.\n*   **Non-Partial Transcription Events:** Non-partial transcription events\n    are saved.\n*   **Function Call and Response Events:** Always saved.\n*   **Other Control Events:** Most control events are saved.\n\n**Events Not Saved to the Session:**\n*   **Live Model Audio Events with Inline Data:** Events containing raw\n    audio `Blob` data are **not** saved to the session.\n\nArgs:\n    user_id: The user ID for the session. Required if `session` is None.\n    session_id: The session ID for the session. Required if `session` is\n      None.\n    live_request_queue: The queue for live requests.\n    run_config: The run config for the agent.\n    session: The session to use. This parameter is deprecated, please use\n      `user_id` and `session_id` instead.\n\nYields:\n    AsyncGenerator[Event,\
      \ None]: An asynchronous generator that yields\n    `Event`\n    objects as they are produced by the agent during its live execution.\n\n.. warning::\n    This feature is **experimental** and its API or behavior may change\n    in future releases.\n\n.. NOTE::\n    Either `session` or both `user_id` and `session_id` must be provided."
  - signature: 'def execute(ctx: google.adk.agents.invocation_context.InvocationContext) -> typing.AsyncGenerator[google.adk.events.event.Event]:'
  - signature: 'def run_debug(self, user_messages: str | list[str], *, user_id: str=''debug_user_id'', session_id: str=''debug_session_id'', run_config: RunConfig | None=None, quiet: bool=False, verbose: bool=False) -> list[google.adk.events.event.Event]:'
    docstring: "Debug helper for quick agent experimentation and testing.\n\nThis convenience method is designed for developers getting started with ADK\nwho want to quickly test agents without dealing with session management,\ncontent formatting, or event streaming. It automatically handles common\nboilerplate while hiding complexity.\n\nIMPORTANT: This is for debugging and experimentation only. For production\nuse, please use the standard run_async() method which provides full control\nover session management, event streaming, and error handling.\n\nArgs:\n    user_messages: Message(s) to send to the agent. Can be: - Single string:\n      \"What is 2+2?\" - List of strings: [\"Hello!\", \"What's my name?\"]\n    user_id: User identifier. Defaults to \"debug_user_id\".\n    session_id: Session identifier for conversation persistence. Defaults to\n      \"debug_session_id\". Reuse the same ID to continue a conversation.\n    run_config: Optional configuration for the agent execution.\n \
      \   quiet: If True, suppresses console output. Defaults to False (output\n      shown).\n    verbose: If True, shows detailed tool calls and responses. Defaults to\n      False for cleaner output showing only final agent responses.\n\nReturns:\n    list[Event]: All events from all messages.\n\nRaises:\n    ValueError: If session creation/retrieval fails.\n\nExamples:\n    Quick debugging:\n    >>> runner = InMemoryRunner(agent=my_agent)\n    >>> await runner.run_debug(\"What is 2+2?\")\n\n    Multiple queries in conversation:\n    >>> await runner.run_debug([\"Hello!\", \"What's my name?\"])\n\n    Continue a debug session:\n    >>> await runner.run_debug(\"What did we discuss?\")  # Continues default\n    session\n\n    Separate debug sessions:\n    >>> await runner.run_debug(\"Hi\", user_id=\"alice\", session_id=\"debug1\")\n    >>> await runner.run_debug(\"Hi\", user_id=\"bob\", session_id=\"debug2\")\n\n    Capture events for inspection:\n    >>> events = await runner.run_debug(\"\
      Analyze this\")\n    >>> for event in events:\n    ...     inspect_event(event)\n\nNote:\n    For production applications requiring:\n    - Custom session/memory services (Spanner, Cloud SQL, etc.)\n    - Fine-grained event processing and streaming\n    - Error recovery and resumability\n    - Performance optimization\n    Please use run_async() with proper configuration."
  - signature: 'def close(self):'
    docstring: Closes the runner.
  properties:
  - signature: 'app_name: str'
    docstring: The app name of the runner.
  - signature: 'agent: google.adk.agents.base_agent.BaseAgent'
    docstring: The root agent to run.
  - signature: 'artifact_service: typing.Optional[google.adk.artifacts.base_artifact_service.BaseArtifactService]'
    docstring: The artifact service for the runner.
  - signature: 'plugin_manager: google.adk.plugins.plugin_manager.PluginManager'
    docstring: The plugin manager for the runner.
  - signature: 'session_service: google.adk.sessions.base_session_service.BaseSessionService'
    docstring: The session service for the runner.
  - signature: 'memory_service: typing.Optional[google.adk.memory.base_memory_service.BaseMemoryService]'
    docstring: The memory service for the runner.
  - signature: 'credential_service: typing.Optional[google.adk.auth.credential_service.base_credential_service.BaseCredentialService]'
    docstring: The credential service for the runner.
  - signature: 'context_cache_config: typing.Optional[google.adk.agents.context_cache_config.ContextCacheConfig]'
    docstring: The context cache config for the runner.
  - signature: 'resumability_config: typing.Optional[google.adk.apps.app.ResumabilityConfig]'
    docstring: The resumability config for the application.
  - signature: 'Self: str'
- rank: 15
  id: google.adk.agents.sequential_agent.SequentialAgent
  name: SequentialAgent
  file_path: google/adk/agents/sequential_agent.py
  type: CLASS
  group: Seed
  usage_score: 7
  docstring: 'A shell agent that runs its sub-agents in sequence.


    [Note: Inherited members from pydantic.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, name: str, description: str = '''', sub_agents: list[google.adk.agents.base_agent.BaseAgent] = list(), before_agent_callback: typing.Optional[google.adk.agents.base_agent.BeforeAgentCallback] = None, after_agent_callback: typing.Optional[google.adk.agents.base_agent.AfterAgentCallback] = None):'
  aliases:
  - google.adk.agents.SequentialAgent
  methods:
  - signature: 'def _run_async_impl(self, ctx: google.adk.agents.invocation_context.InvocationContext) -> typing.AsyncGenerator[google.adk.events.event.Event, None]:'
  - signature: 'def task_completed():'
    docstring: 'Signals that the agent has successfully completed the user''s question

      or task.'
  properties:
  - signature: 'config_type: typing.ClassVar[typing.Type[google.adk.agents.base_agent_config.BaseAgentConfig]]'
    docstring: The config type for this agent.
  inherited_methods:
    BaseAgent:
    - signature: 'def clone(self: google.adk.agents.base_agent.SelfAgent, update: Mapping[str, Any] | None) -> google.adk.agents.base_agent.SelfAgent:'
      docstring: "Creates a copy of this agent instance.\n\nArgs:\n  update: Optional mapping of new values for the fields of the cloned agent.\n    The keys of the mapping are the names of the fields to be updated, and\n    the values are the new values for those fields.\n    For example: {\"name\": \"cloned_agent\"}\n\nReturns:\n  A new agent instance with identical configuration as the original\n  agent except for the fields specified in the update."
    - signature: 'def run_async(self, parent_context: google.adk.agents.invocation_context.InvocationContext) -> typing.AsyncGenerator[google.adk.events.event.Event, None]:'
      docstring: "Entry method to run an agent via text-based conversation.\n\nArgs:\n  parent_context: InvocationContext, the invocation context of the parent\n    agent.\n\nYields:\n  Event: the events generated by the agent."
    - signature: 'def run_live(self, parent_context: google.adk.agents.invocation_context.InvocationContext) -> typing.AsyncGenerator[google.adk.events.event.Event, None]:'
      docstring: "Entry method to run an agent via video/audio-based conversation.\n\nArgs:\n  parent_context: InvocationContext, the invocation context of the parent\n    agent.\n\nYields:\n  Event: the events generated by the agent."
    - signature: 'def _run_async_impl(self, ctx: google.adk.agents.invocation_context.InvocationContext) -> typing.AsyncGenerator[google.adk.events.event.Event, None]:'
      docstring: "Core logic to run this agent via text-based conversation.\n\nArgs:\n  ctx: InvocationContext, the invocation context for this agent.\n\nYields:\n  Event: the events generated by the agent."
    - signature: 'def root_agent(self) -> google.adk.agents.base_agent.BaseAgent:'
      docstring: Gets the root agent of this agent.
    - signature: 'def find_agent(self, name: str) -> typing.Optional[google.adk.agents.base_agent.BaseAgent]:'
      docstring: "Finds the agent with the given name in this agent and its descendants.\n\nArgs:\n  name: The name of the agent to find.\n\nReturns:\n  The agent with the matching name, or None if no such agent is found."
    - signature: 'def find_sub_agent(self, name: str) -> typing.Optional[google.adk.agents.base_agent.BaseAgent]:'
      docstring: "Finds the agent with the given name in this agent's descendants.\n\nArgs:\n  name: The name of the agent to find.\n\nReturns:\n  The agent with the matching name, or None if no such agent is found."
    - signature: 'def model_post_init(self, __context: typing.Any) -> None:'
    - signature: 'def validate_name(cls, value: str):'
    - signature: 'def validate_sub_agents_unique_names(cls, value: list[google.adk.agents.base_agent.BaseAgent]) -> list[google.adk.agents.base_agent.BaseAgent]:'
      docstring: "Validates that all sub-agents have unique names.\n\nArgs:\n  value: The list of sub-agents to validate.\n\nReturns:\n  The validated list of sub-agents."
    - signature: 'def from_config(cls: typing.Type[google.adk.agents.base_agent.SelfAgent], config: google.adk.agents.base_agent_config.BaseAgentConfig, config_abs_path: str) -> google.adk.agents.base_agent.SelfAgent:'
      docstring: "Creates an agent from a config.\n\nIf sub-classes uses a custom agent config, override `_from_config_kwargs`\nmethod to return an updated kwargs for agent constructor.\n\nArgs:\n  config: The config to create the agent from.\n  config_abs_path: The absolute path to the config file that contains the\n    agent config.\n\nReturns:\n  The created agent."
  inherited_properties:
    BaseAgent:
    - signature: 'model_config: pydantic.ConfigDict'
      docstring: The pydantic model config.
    - signature: 'config_type: typing.ClassVar[type[google.adk.agents.base_agent_config.BaseAgentConfig]]'
      docstring: "The config type for this agent.\n\nSub-classes should override this to specify their own config type.\n\nExample:\n\n```\nclass MyAgentConfig(BaseAgentConfig):\n  my_field: str = ''\n\nclass MyAgent(BaseAgent):\n  config_type: ClassVar[type[BaseAgentConfig]] = MyAgentConfig\n```"
    - signature: 'name: str'
      docstring: 'The agent''s name.


        Agent name must be a Python identifier and unique within the agent tree.

        Agent name cannot be "user", since it''s reserved for end-user''s input.'
    - signature: 'description: str'
      docstring: 'Description about the agent''s capability.


        The model uses this to determine whether to delegate control to the agent.

        One-line description is enough and preferred.'
    - signature: 'parent_agent: typing.Optional[google.adk.agents.base_agent.BaseAgent]'
      docstring: 'The parent agent of this agent.


        Note that an agent can ONLY be added as sub-agent once.


        If you want to add one agent twice as sub-agent, consider to create two agent

        instances with identical config, but with different name and add them to the

        agent tree.'
    - signature: 'sub_agents: list[google.adk.agents.base_agent.BaseAgent]'
      docstring: The sub-agents of this agent.
    - signature: 'before_agent_callback: typing.Optional[google.adk.agents.base_agent.BeforeAgentCallback]'
      docstring: "Callback or list of callbacks to be invoked before the agent run.\n\nWhen a list of callbacks is provided, the callbacks will be called in the\norder they are listed until a callback does not return None.\n\nArgs:\n  callback_context: MUST be named 'callback_context' (enforced).\n\nReturns:\n  Optional[types.Content]: The content to return to the user.\n    When the content is present, the agent run will be skipped and the\n    provided content will be returned to user."
    - signature: 'after_agent_callback: typing.Optional[google.adk.agents.base_agent.AfterAgentCallback]'
      docstring: "Callback or list of callbacks to be invoked after the agent run.\n\nWhen a list of callbacks is provided, the callbacks will be called in the\norder they are listed until a callback does not return None.\n\nArgs:\n  callback_context: MUST be named 'callback_context' (enforced).\n\nReturns:\n  Optional[types.Content]: The content to return to the user.\n    When the content is present, an additional event with the provided content\n    will be appended to event history as an additional agent response."
    BaseModel:
    - signature: 'model_config: pydantic.ConfigDict'
  omitted_inherited_members_from:
  - pydantic.BaseModel
- rank: 16
  id: google.adk.tools.mcp_tool.mcp_toolset.MCPToolset
  name: MCPToolset
  file_path: google/adk/tools/mcp_tool/mcp_toolset.py
  type: CLASS
  group: Seed
  usage_score: 6
  docstring: 'Deprecated name, use `McpToolset` instead.


    [Note: Inherited members from ABC are omitted.]'
  constructor_signature: 'def __init__(self):'
  inherited_methods:
    McpToolset:
    - signature: 'def get_tools(self, readonly_context: typing.Optional[google.adk.agents.readonly_context.ReadonlyContext]) -> typing.List[google.adk.tools.base_tool.BaseTool]:'
      docstring: "Return all tools in the toolset based on the provided context.\n\nArgs:\n    readonly_context: Context used to filter tools available to the agent.\n        If None, all tools in the toolset are returned.\n\nReturns:\n    List[BaseTool]: A list of tools available under the specified context."
    - signature: 'def close(self) -> None:'
      docstring: 'Performs cleanup and releases resources held by the toolset.


        This method closes the MCP session and cleans up all associated resources.

        It''s designed to be safe to call multiple times and handles cleanup errors

        gracefully to avoid blocking application shutdown.'
    - signature: 'def from_config(cls: type[google.adk.tools.mcp_tool.mcp_toolset.McpToolset], config: google.adk.tools.tool_configs.ToolArgsConfig, config_abs_path: str) -> google.adk.tools.mcp_tool.mcp_toolset.McpToolset:'
      docstring: Creates an McpToolset from a configuration object.
    BaseToolset:
    - signature: 'def get_tools(self, readonly_context: typing.Optional[google.adk.agents.readonly_context.ReadonlyContext]) -> list[google.adk.tools.base_tool.BaseTool]:'
      docstring: "Return all tools in the toolset based on the provided context.\n\nArgs:\n  readonly_context (ReadonlyContext, optional): Context used to filter tools\n    available to the agent. If None, all tools in the toolset are returned.\n\nReturns:\n  list[BaseTool]: A list of tools available under the specified context."
    - signature: 'def get_tools_with_prefix(self, readonly_context: typing.Optional[google.adk.agents.readonly_context.ReadonlyContext]) -> list[google.adk.tools.base_tool.BaseTool]:'
      docstring: "Return all tools with optional prefix applied to tool names.\n\nThis method calls get_tools() and applies prefixing if tool_name_prefix is provided.\n\nArgs:\n  readonly_context (ReadonlyContext, optional): Context used to filter tools\n    available to the agent. If None, all tools in the toolset are returned.\n\nReturns:\n  list[BaseTool]: A list of tools with prefixed names if tool_name_prefix is provided."
    - signature: 'def close(self) -> None:'
      docstring: "Performs cleanup and releases resources held by the toolset.\n\nNOTE:\n  This method is invoked, for example, at the end of an agent server's\n  lifecycle or when the toolset is no longer needed. Implementations\n  should ensure that any open connections, files, or other managed\n  resources are properly released to prevent leaks."
    - signature: 'def from_config(cls: typing.Type[google.adk.tools.base_toolset.SelfToolset], config: google.adk.tools.tool_configs.ToolArgsConfig, config_abs_path: str) -> google.adk.tools.base_toolset.SelfToolset:'
      docstring: "Creates a toolset instance from a config.\n\nArgs:\n  config: The config for the tool.\n  config_abs_path: The absolute path to the config file that contains the\n    tool config.\n\nReturns:\n  The toolset instance."
    - signature: 'def process_llm_request(self, *, tool_context: google.adk.tools.tool_context.ToolContext, llm_request: google.adk.models.llm_request.LlmRequest) -> None:'
      docstring: "Processes the outgoing LLM request for this toolset. This method will be\ncalled before each tool processes the llm request.\n\nUse cases:\n- Instead of let each tool process the llm request, we can let the toolset\n  process the llm request. e.g. ComputerUseToolset can add computer use\n  tool to the llm request.\n\nArgs:\n  tool_context: The context of the tool.\n  llm_request: The outgoing LLM request, mutable this method."
  omitted_inherited_members_from:
  - ABC
- rank: 17
  id: google.adk.sessions.vertex_ai_session_service.VertexAiSessionService
  name: VertexAiSessionService
  file_path: google/adk/sessions/vertex_ai_session_service.py
  type: CLASS
  group: Seed
  usage_score: 6
  docstring: 'Connects to the Vertex AI Agent Engine Session Service using Agent Engine SDK.


    https://cloud.google.com/vertex-ai/generative-ai/docs/agent-engine/sessions/overview


    [Note: Inherited members from abc.ABC are omitted.]'
  constructor_signature: 'def __init__(self, project: typing.Optional[str], location: typing.Optional[str], agent_engine_id: typing.Optional[str], *, express_mode_api_key: typing.Optional[str]=None):'
  methods:
  - signature: 'def create_session(self, *, app_name: str, user_id: str, state: typing.Optional[dict[str, typing.Any]]=None, session_id: typing.Optional[str]=None) -> google.adk.sessions.session.Session:'
    docstring: "Creates a new session.\n\nArgs:\n  app_name: The name of the application.\n  user_id: The ID of the user.\n  state: The initial state of the session.\n  session_id: The ID of the session.\n  **kwargs: Additional arguments to pass to the session creation. E.g. set\n    expire_time='2025-10-01T00:00:00Z' to set the session expiration time.\n    See https://cloud.google.com/vertex-ai/generative-ai/docs/reference/rest/v1beta1/projects.locations.reasoningEngines.sessions\n    for more details.\nReturns:\n  The created session."
  - signature: 'def get_session(self, *, app_name: str, user_id: str, session_id: str, config: typing.Optional[google.adk.sessions.base_session_service.GetSessionConfig]=None) -> typing.Optional[google.adk.sessions.session.Session]:'
  - signature: 'def list_sessions(self, *, app_name: str, user_id: typing.Optional[str]=None) -> google.adk.sessions.base_session_service.ListSessionsResponse:'
  - signature: 'def delete_session(self, *, app_name: str, user_id: str, session_id: str) -> None:'
  - signature: 'def append_event(self, session: google.adk.sessions.session.Session, event: google.adk.events.event.Event) -> google.adk.events.event.Event:'
  inherited_methods:
    BaseSessionService:
    - signature: 'def create_session(self, *, app_name: str, user_id: str, state: typing.Optional[dict[str, typing.Any]]=None, session_id: typing.Optional[str]=None) -> google.adk.sessions.session.Session:'
      docstring: "Creates a new session.\n\nArgs:\n  app_name: the name of the app.\n  user_id: the id of the user.\n  state: the initial state of the session.\n  session_id: the client-provided id of the session. If not provided, a\n    generated ID will be used.\n\nReturns:\n  session: The newly created session instance."
    - signature: 'def get_session(self, *, app_name: str, user_id: str, session_id: str, config: typing.Optional[google.adk.sessions.base_session_service.GetSessionConfig]=None) -> typing.Optional[google.adk.sessions.session.Session]:'
      docstring: Gets a session.
    - signature: 'def list_sessions(self, *, app_name: str, user_id: typing.Optional[str]=None) -> google.adk.sessions.base_session_service.ListSessionsResponse:'
      docstring: "Lists all the sessions for a user.\n\nArgs:\n  app_name: The name of the app.\n  user_id: The ID of the user. If not provided, lists all sessions for all\n    users.\n\nReturns:\n  A ListSessionsResponse containing the sessions."
    - signature: 'def delete_session(self, *, app_name: str, user_id: str, session_id: str) -> None:'
      docstring: Deletes a session.
    - signature: 'def append_event(self, session: google.adk.sessions.session.Session, event: google.adk.events.event.Event) -> google.adk.events.event.Event:'
      docstring: Appends an event to a session object.
  omitted_inherited_members_from:
  - abc.ABC
- rank: 18
  id: google.adk.examples.example.Example
  name: Example
  file_path: google/adk/examples/example.py
  type: CLASS
  group: Seed
  usage_score: 6
  docstring: "A few-shot example.\n\nAttributes:\n  input: The input content for the example.\n  output: The expected output content for the example.\n\n[Note: Inherited members from pydantic.BaseModel are omitted.]"
  constructor_signature: 'def __init__(self, *, input: google.genai.types.Content, output: list[google.genai.types.Content]):'
  properties:
  - signature: 'input: google.genai.types.Content'
  - signature: 'output: list[google.genai.types.Content]'
  inherited_properties:
    BaseModel:
    - signature: 'model_config: pydantic.ConfigDict'
  omitted_inherited_members_from:
  - pydantic.BaseModel
- rank: 19
  id: google.adk.tools.langchain_tool.LangchainTool
  name: LangchainTool
  file_path: google/adk/tools/langchain_tool.py
  type: CLASS
  group: Seed
  usage_score: 5
  docstring: "Adapter class that wraps a Langchain tool for use with ADK.\n\nThis adapter converts Langchain tools into a format compatible with Google's\ngenerative AI function calling interface. It preserves the tool's name,\ndescription, and functionality while adapting its schema.\n\nThe original tool's name and description can be overridden if needed.\n\nArgs:\n    tool: A Langchain tool to wrap (BaseTool or a tool with a .run method)\n    name: Optional override for the tool's name\n    description: Optional override for the tool's description\n\nExamples::\n\n    from langchain.tools import DuckDuckGoSearchTool\n    from google.genai.tools import LangchainTool\n\n    search_tool = DuckDuckGoSearchTool()\n    wrapped_tool = LangchainTool(search_tool)\n\n[Note: Inherited members from ABC are omitted.]"
  constructor_signature: 'def __init__(self, tool: typing.Union[langchain_core.tools.BaseTool, object], name: typing.Optional[str], description: typing.Optional[str]):'
  methods:
  - signature: 'def from_config(cls: type[google.adk.tools.langchain_tool.LangchainTool], config: google.adk.tools.tool_configs.ToolArgsConfig, config_abs_path: str) -> google.adk.tools.langchain_tool.LangchainTool:'
  inherited_methods:
    FunctionTool:
    - signature: 'def run_async(self, *, args: dict[str, typing.Any], tool_context: google.adk.tools.tool_context.ToolContext) -> typing.Any:'
    BaseTool:
    - signature: 'def run_async(self, *, args: dict[str, typing.Any], tool_context: google.adk.tools.tool_context.ToolContext) -> typing.Any:'
      docstring: "Runs the tool with the given arguments and context.\n\nNOTE:\n  - Required if this tool needs to run at the client side.\n  - Otherwise, can be skipped, e.g. for a built-in GoogleSearch tool for\n    Gemini.\n\nArgs:\n  args: The LLM-filled arguments.\n  tool_context: The context of the tool.\n\nReturns:\n  The result of running the tool."
    - signature: 'def process_llm_request(self, *, tool_context: google.adk.tools.tool_context.ToolContext, llm_request: google.adk.models.llm_request.LlmRequest) -> None:'
      docstring: "Processes the outgoing LLM request for this tool.\n\nUse cases:\n- Most common use case is adding this tool to the LLM request.\n- Some tools may just preprocess the LLM request before it's sent out.\n\nArgs:\n  tool_context: The context of the tool.\n  llm_request: The outgoing LLM request, mutable this method."
    - signature: 'def from_config(cls: typing.Type[google.adk.tools.base_tool.SelfTool], config: google.adk.tools.tool_configs.ToolArgsConfig, config_abs_path: str) -> google.adk.tools.base_tool.SelfTool:'
      docstring: "Creates a tool instance from a config.\n\nThis default implementation uses inspect to automatically map config values\nto constructor arguments based on their type hints. Subclasses should\noverride this method for custom initialization logic.\n\nArgs:\n  config: The config for the tool.\n  config_abs_path: The absolute path to the config file that contains the\n    tool config.\n\nReturns:\n  The tool instance."
  inherited_properties:
    BaseTool:
    - signature: 'name: str'
      docstring: The name of the tool.
    - signature: 'description: str'
      docstring: The description of the tool.
    - signature: 'is_long_running: bool'
      docstring: 'Whether the tool is a long running operation, which typically returns a

        resource id first and finishes the operation later.'
    - signature: 'custom_metadata: typing.Optional[dict[str, typing.Any]]'
      docstring: 'The custom metadata of the BaseTool.


        An optional key-value pair for storing and retrieving tool-specific metadata,

        such as tool manifests, etc.


        NOTE: the entire dict must be JSON serializable.'
  omitted_inherited_members_from:
  - ABC
- rank: 20
  id: google.adk.tools.bigquery.client.get_bigquery_client
  name: get_bigquery_client
  file_path: google/adk/tools/bigquery/client.py
  type: METHOD
  group: Seed
  usage_score: 5
  docstring: "Get a BigQuery client.\n\nArgs:\n  project: The GCP project ID.\n  credentials: The credentials to use for the request.\n  location: The location of the BigQuery client.\n  user_agent: The user agent to use for the request.\n\nReturns:\n  A BigQuery client."
  signature: 'def get_bigquery_client(*, project: typing.Optional[str], credentials: google.auth.credentials.Credentials, location: typing.Optional[str]=None, user_agent: typing.Optional[typing.Union[str, typing.List[str]]]=None) -> google.cloud.bigquery.Client:'
- rank: 21
  id: google.adk.models.google_llm.Gemini
  name: Gemini
  file_path: google/adk/models/google_llm.py
  type: CLASS
  group: Seed
  usage_score: 5
  docstring: "Integration for Gemini models.\n\nAttributes:\n  model: The name of the Gemini model.\n\n[Note: Inherited members from pydantic.BaseModel are omitted.]"
  constructor_signature: 'def __init__(self, *, model: str, speech_config: typing.Optional[google.genai.types.SpeechConfig] = None, retry_options: typing.Optional[google.genai.types.HttpRetryOptions] = None):'
  methods:
  - signature: 'def supported_models(cls) -> list[str]:'
    docstring: "Provides the list of supported models.\n\nReturns:\n  A list of supported models."
  - signature: 'def generate_content_async(self, llm_request: google.adk.models.llm_request.LlmRequest, stream: bool) -> typing.AsyncGenerator[google.adk.models.llm_response.LlmResponse, None]:'
    docstring: "Sends a request to the Gemini model.\n\nArgs:\n  llm_request: LlmRequest, the request to send to the Gemini model.\n  stream: bool = False, whether to do streaming call.\n\nYields:\n  LlmResponse: The model response."
  - signature: 'def api_client(self) -> google.genai.Client:'
    docstring: "Provides the api client.\n\nReturns:\n  The api client."
  - signature: 'def connect(self, llm_request: google.adk.models.llm_request.LlmRequest) -> google.adk.models.base_llm_connection.BaseLlmConnection:'
    docstring: "Connects to the Gemini model and returns an llm connection.\n\nArgs:\n  llm_request: LlmRequest, the request to send to the Gemini model.\n\nYields:\n  BaseLlmConnection, the connection to the Gemini model."
  - signature: 'def convert_wait_to_wait_5_seconds(wait_func):'
  - signature: 'def wait_5_seconds():'
  properties:
  - signature: 'model: str'
  - signature: 'speech_config: typing.Optional[google.genai.types.SpeechConfig]'
  - signature: 'retry_options: typing.Optional[google.genai.types.HttpRetryOptions]'
    docstring: "Allow Gemini to retry failed responses.\n\nSample:\n```python\nfrom google.genai import types\n\n# ...\n\nagent = Agent(\n  model=Gemini(\n    retry_options=types.HttpRetryOptions(initial_delay=1, attempts=2),\n  )\n)\n```"
  inherited_methods:
    BaseLlm:
    - signature: 'def supported_models(cls) -> list[str]:'
      docstring: Returns a list of supported models in regex for LlmRegistry.
    - signature: 'def generate_content_async(self, llm_request: google.adk.models.llm_request.LlmRequest, stream: bool) -> typing.AsyncGenerator[google.adk.models.llm_response.LlmResponse, None]:'
      docstring: "Generates content for a single model turn.\n\n    This method handles Server-Sent Events (SSE) streaming for unidirectional\n    content generation. For bidirectional streaming (e.g., Gemini Live API),\n    use the `connect()` method instead.\n\n    Args:\n      llm_request: LlmRequest, the request to send to the LLM.\n      stream: bool = False, whether to enable SSE streaming mode.\n\n    Yields:\n      LlmResponse objects representing the model's response for one turn.\n\n      **Non-streaming mode (stream=False):**\n\n        Yields exactly one LlmResponse containing the complete model output\n        (text, function calls, bytes, etc.). This response has `partial=False`.\n\n      **Streaming mode (stream=True):**\n\n        Yields multiple LlmResponse objects as chunks arrive:\n\n        - Intermediate chunks: `partial=True` (progressive updates)\n        - Final chunk: `partial=False` (aggregated content from entire turn,\n          identical to stream=False output)\n\
        \        - Text consolidation: Consecutive text parts of the same type\n          (thought/non-thought) SHOULD merge without separator, but client\n          code must not rely on this - unconsolidated parts are unusual but also\n          valid\n\n      **Common content in partial chunks:**\n\n        All intermediate chunks have `partial=True` regardless of content type.\n        Common examples include:\n\n        - Text: Streams incrementally as tokens arrive\n        - Function calls: May arrive in separate chunks\n        - Bytes (e.g., images): Typically arrive as single chunk, interleaved\n          with text\n        - Thoughts: Stream incrementally when thinking_config is enabled\n\n      **Examples:**\n\n      1. Simple text streaming::\n\n           LlmResponse(partial=True,  parts=[\"The weather\"])\n           LlmResponse(partial=True,  parts=[\" in Tokyo is\"])\n           LlmResponse(partial=True,  parts=[\" sunny.\"])\n           LlmResponse(partial=False, parts=[\"\
        The weather in Tokyo is sunny.\"])\n\n      2. Text + function call::\n\n           LlmResponse(partial=True,  parts=[Text(\"Let me check...\")])\n           LlmResponse(partial=True,  parts=[FunctionCall(\"get_weather\", ...)])\n           LlmResponse(partial=False, parts=[Text(\"Let me check...\"),\n                                             FunctionCall(\"get_weather\", ...)])\n\n      3. Parallel function calls across chunks::\n\n           LlmResponse(partial=True,  parts=[Text(\"Checking both cities...\")])\n           LlmResponse(partial=True,  parts=[FunctionCall(\"get_weather\", Tokyo)])\n           LlmResponse(partial=True,  parts=[FunctionCall(\"get_weather\", NYC)])\n           LlmResponse(partial=False, parts=[Text(\"Checking both cities...\"),\n                                             FunctionCall(\"get_weather\", Tokyo),\n                                             FunctionCall(\"get_weather\", NYC)])\n\n      4. Text + bytes (image generation with gemini-2.5-flash-image)::\n\
        \n           LlmResponse(partial=True,  parts=[Text(\"Here's an image of a dog.\")])\n           LlmResponse(partial=True,  parts=[Text(\"\n\")])\n           LlmResponse(partial=True,  parts=[Blob(image/png, 1.6MB)])\n           LlmResponse(partial=True,  parts=[Text(\"It carries a bone\")])\n           LlmResponse(partial=True,  parts=[Text(\" and running around.\")])\n           LlmResponse(partial=False, parts=[Text(\"Here's an image of a dog.\n\"),\n                                             Blob(image/png, 1.6MB),\n                                             Text(\"It carries a bone and running around.\")])\n\n         Note: Consecutive text parts before and after blob merge separately.\n\n      5. Text with thinking (gemini-2.5-flash with thinking_config)::\n\n           LlmResponse(partial=True,  parts=[Thought(\"Let me analyze...\")])\n           LlmResponse(partial=True,  parts=[Thought(\"The user wants...\")])\n           LlmResponse(partial=True,  parts=[Text(\"Based\
        \ on my analysis,\")])\n           LlmResponse(partial=True,  parts=[Text(\" the answer is 42.\")])\n           LlmResponse(partial=False, parts=[Thought(\"Let me analyze...The user wants...\"),\n                                             Text(\"Based on my analysis, the answer is 42.\")])\n\n         Note: Consecutive parts of same type merge (thoughts\u2192thought, text\u2192text).\n\n      **Important:** All yielded responses represent one logical model turn.\n      The final response with `partial=False` should be identical to the\n      response that would be received with `stream=False`.\n    "
    - signature: 'def connect(self, llm_request: google.adk.models.llm_request.LlmRequest) -> google.adk.models.base_llm_connection.BaseLlmConnection:'
      docstring: "Creates a live connection to the LLM.\n\nArgs:\n  llm_request: LlmRequest, the request to send to the LLM.\n\nReturns:\n  BaseLlmConnection, the connection to the LLM."
  inherited_properties:
    BaseLlm:
    - signature: 'model_config: pydantic.ConfigDict'
      docstring: The pydantic model config.
    - signature: 'model: str'
      docstring: The name of the LLM, e.g. gemini-2.5-flash or gemini-2.5-pro.
    BaseModel:
    - signature: 'model_config: pydantic.ConfigDict'
  omitted_inherited_members_from:
  - pydantic.BaseModel
- rank: 22
  id: google.adk.apps.app.App
  name: App
  file_path: google/adk/apps/app.py
  type: CLASS
  group: Seed
  usage_score: 5
  docstring: 'Represents an LLM-backed agentic application.


    An `App` is the top-level container for an agentic system powered by LLMs.

    It manages a root agent (`root_agent`), which serves as the root of an agent

    tree, enabling coordination and communication across all agents in the

    hierarchy.

    The `plugins` are application-wide components that provide shared capabilities

    and services to the entire system.


    [Note: Inherited members from pydantic.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, name: str, root_agent: google.adk.agents.base_agent.BaseAgent, plugins: list[google.adk.plugins.base_plugin.BasePlugin] = list(), events_compaction_config: typing.Optional[google.adk.apps.app.EventsCompactionConfig] = None, context_cache_config: typing.Optional[google.adk.agents.context_cache_config.ContextCacheConfig] = None, resumability_config: typing.Optional[google.adk.apps.app.ResumabilityConfig] = None):'
  properties:
  - signature: 'model_config: pydantic.ConfigDict'
  - signature: 'name: str'
    docstring: The name of the application.
  - signature: 'root_agent: google.adk.agents.base_agent.BaseAgent'
    docstring: The root agent in the application. One app can only have one root agent.
  - signature: 'plugins: list[google.adk.plugins.base_plugin.BasePlugin]'
    docstring: The plugins in the application.
  - signature: 'events_compaction_config: typing.Optional[google.adk.apps.app.EventsCompactionConfig]'
    docstring: The config of event compaction for the application.
  - signature: 'context_cache_config: typing.Optional[google.adk.agents.context_cache_config.ContextCacheConfig]'
    docstring: Context cache configuration that applies to all LLM agents in the app.
  - signature: 'resumability_config: typing.Optional[google.adk.apps.app.ResumabilityConfig]'
    docstring: 'The config of the resumability for the application.

      If configured, will be applied to all agents in the app.'
  inherited_properties:
    BaseModel:
    - signature: 'model_config: pydantic.ConfigDict'
  omitted_inherited_members_from:
  - pydantic.BaseModel
- rank: 23
  id: google.adk.tools.function_tool.FunctionTool
  name: FunctionTool
  file_path: google/adk/tools/function_tool.py
  type: CLASS
  group: Seed
  usage_score: 4
  docstring: "A tool that wraps a user-defined Python function.\n\nAttributes:\n  func: The function to wrap.\n\n[Note: Inherited members from ABC are omitted.]"
  constructor_signature: 'def __init__(self, func: typing.Callable[Ellipsis, typing.Any], *, require_confirmation: typing.Union[bool, typing.Callable[Ellipsis, bool]]=False):'
  methods:
  - signature: 'def run_async(self, *, args: dict[str, typing.Any], tool_context: google.adk.tools.tool_context.ToolContext) -> typing.Any:'
  inherited_methods:
    BaseTool:
    - signature: 'def run_async(self, *, args: dict[str, typing.Any], tool_context: google.adk.tools.tool_context.ToolContext) -> typing.Any:'
      docstring: "Runs the tool with the given arguments and context.\n\nNOTE:\n  - Required if this tool needs to run at the client side.\n  - Otherwise, can be skipped, e.g. for a built-in GoogleSearch tool for\n    Gemini.\n\nArgs:\n  args: The LLM-filled arguments.\n  tool_context: The context of the tool.\n\nReturns:\n  The result of running the tool."
    - signature: 'def process_llm_request(self, *, tool_context: google.adk.tools.tool_context.ToolContext, llm_request: google.adk.models.llm_request.LlmRequest) -> None:'
      docstring: "Processes the outgoing LLM request for this tool.\n\nUse cases:\n- Most common use case is adding this tool to the LLM request.\n- Some tools may just preprocess the LLM request before it's sent out.\n\nArgs:\n  tool_context: The context of the tool.\n  llm_request: The outgoing LLM request, mutable this method."
    - signature: 'def from_config(cls: typing.Type[google.adk.tools.base_tool.SelfTool], config: google.adk.tools.tool_configs.ToolArgsConfig, config_abs_path: str) -> google.adk.tools.base_tool.SelfTool:'
      docstring: "Creates a tool instance from a config.\n\nThis default implementation uses inspect to automatically map config values\nto constructor arguments based on their type hints. Subclasses should\noverride this method for custom initialization logic.\n\nArgs:\n  config: The config for the tool.\n  config_abs_path: The absolute path to the config file that contains the\n    tool config.\n\nReturns:\n  The tool instance."
  inherited_properties:
    BaseTool:
    - signature: 'name: str'
      docstring: The name of the tool.
    - signature: 'description: str'
      docstring: The description of the tool.
    - signature: 'is_long_running: bool'
      docstring: 'Whether the tool is a long running operation, which typically returns a

        resource id first and finishes the operation later.'
    - signature: 'custom_metadata: typing.Optional[dict[str, typing.Any]]'
      docstring: 'The custom metadata of the BaseTool.


        An optional key-value pair for storing and retrieving tool-specific metadata,

        such as tool manifests, etc.


        NOTE: the entire dict must be JSON serializable.'
  omitted_inherited_members_from:
  - ABC
- rank: 24
  id: google.adk.tools.bigquery.config.BigQueryToolConfig
  name: BigQueryToolConfig
  file_path: google/adk/tools/bigquery/config.py
  type: CLASS
  group: Seed
  usage_score: 4
  docstring: 'Configuration for BigQuery tools.


    [Note: Inherited members from pydantic.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, write_mode: google.adk.tools.bigquery.config.WriteMode = WriteMode.BLOCKED, maximum_bytes_billed: typing.Optional[int] = None, max_query_result_rows: int = 50, application_name: typing.Optional[str] = None, compute_project_id: typing.Optional[str] = None, location: typing.Optional[str] = None):'
  methods:
  - signature: 'def validate_maximum_bytes_billed(cls, v):'
    docstring: Validate the maximum bytes billed.
  - signature: 'def validate_application_name(cls, v):'
    docstring: Validate the application name.
  properties:
  - signature: 'model_config: pydantic.ConfigDict'
  - signature: 'write_mode: google.adk.tools.bigquery.config.WriteMode'
    docstring: 'Write mode for BigQuery tools.


      By default, the tool will allow only read operations. This behaviour may

      change in future versions.'
  - signature: 'maximum_bytes_billed: typing.Optional[int]'
    docstring: 'Maximum number of bytes to bill for a query.


      In BigQuery on-demand pricing, charges are rounded up to the nearest MB, with

      a minimum 10 MB data processed per table referenced by the query, and with a

      minimum 10 MB data processed per query. So this value must be set >=10485760.'
  - signature: 'max_query_result_rows: int'
    docstring: 'Maximum number of rows to return from a query.


      By default, the query result will be limited to 50 rows.'
  - signature: 'application_name: typing.Optional[str]'
    docstring: 'Name of the application using the BigQuery tools.


      By default, no particular application name will be set in the BigQuery

      interaction. But if the tool user (agent builder) wants to differentiate

      their application/agent for tracking or support purpose, they can set this

      field. If set, this value will be added to the user_agent in BigQuery API calls, and also to the BigQuery job labels with the key

      "adk-bigquery-application-name".'
  - signature: 'compute_project_id: typing.Optional[str]'
    docstring: 'GCP project ID to use for the BigQuery compute operations.


      This can be set as a guardrail to ensure that the tools perform the compute

      operations (such as query execution) in a specific project.'
  - signature: 'location: typing.Optional[str]'
    docstring: 'BigQuery location to use for the data and compute.


      This can be set if the BigQuery tools are expected to process data in a

      particular BigQuery location. If not set, then location would be automatically

      determined based on the data location in the query. For all supported

      locations, see https://cloud.google.com/bigquery/docs/locations.'
  inherited_properties:
    BaseModel:
    - signature: 'model_config: pydantic.ConfigDict'
  omitted_inherited_members_from:
  - pydantic.BaseModel
- rank: 25
  id: google.adk.tools.apihub_tool.apihub_toolset.APIHubToolset
  name: APIHubToolset
  file_path: google/adk/tools/apihub_tool/apihub_toolset.py
  type: CLASS
  group: Seed
  usage_score: 4
  docstring: "APIHubTool generates tools from a given API Hub resource.\n\nExamples::\n\n  apihub_toolset = APIHubToolset(\n      apihub_resource_name=\"projects/test-project/locations/us-central1/apis/test-api\",\n      service_account_json=\"...\",\n      tool_filter=lambda tool, ctx=None: tool.name in ('my_tool',\n      'my_other_tool')\n  )\n\n  # Get all available tools\n  agent = LlmAgent(tools=apihub_toolset)\n\n**apihub_resource_name** is the resource name from API Hub. It must include\nAPI name, and can optionally include API version and spec name.\n\n- If apihub_resource_name includes a spec resource name, the content of that\n  spec will be used for generating the tools.\n- If apihub_resource_name includes only an api or a version name, the\n  first spec of the first version of that API will be used.\n\n[Note: Inherited members from ABC are omitted.]"
  constructor_signature: 'def __init__(self, *, apihub_resource_name: str, access_token: typing.Optional[str]=None, service_account_json: typing.Optional[str]=None, name: str='''', description: str='''', lazy_load_spec=False, auth_scheme: typing.Optional[google.adk.auth.auth_schemes.AuthScheme]=None, auth_credential: typing.Optional[google.adk.auth.auth_credential.AuthCredential]=None, apihub_client: typing.Optional[google.adk.tools.apihub_tool.clients.apihub_client.APIHubClient]=None, tool_filter: typing.Optional[typing.Union[google.adk.tools.base_toolset.ToolPredicate, typing.List[str]]]=None):'
  methods:
  - signature: 'def get_tools(self, readonly_context: typing.Optional[google.adk.agents.readonly_context.ReadonlyContext]) -> typing.List[google.adk.tools.openapi_tool.openapi_spec_parser.rest_api_tool.RestApiTool]:'
    docstring: "Retrieves all available tools.\n\nReturns:\n    A list of all available RestApiTool objects."
  - signature: 'def close(self):'
  inherited_methods:
    BaseToolset:
    - signature: 'def get_tools(self, readonly_context: typing.Optional[google.adk.agents.readonly_context.ReadonlyContext]) -> list[google.adk.tools.base_tool.BaseTool]:'
      docstring: "Return all tools in the toolset based on the provided context.\n\nArgs:\n  readonly_context (ReadonlyContext, optional): Context used to filter tools\n    available to the agent. If None, all tools in the toolset are returned.\n\nReturns:\n  list[BaseTool]: A list of tools available under the specified context."
    - signature: 'def get_tools_with_prefix(self, readonly_context: typing.Optional[google.adk.agents.readonly_context.ReadonlyContext]) -> list[google.adk.tools.base_tool.BaseTool]:'
      docstring: "Return all tools with optional prefix applied to tool names.\n\nThis method calls get_tools() and applies prefixing if tool_name_prefix is provided.\n\nArgs:\n  readonly_context (ReadonlyContext, optional): Context used to filter tools\n    available to the agent. If None, all tools in the toolset are returned.\n\nReturns:\n  list[BaseTool]: A list of tools with prefixed names if tool_name_prefix is provided."
    - signature: 'def close(self) -> None:'
      docstring: "Performs cleanup and releases resources held by the toolset.\n\nNOTE:\n  This method is invoked, for example, at the end of an agent server's\n  lifecycle or when the toolset is no longer needed. Implementations\n  should ensure that any open connections, files, or other managed\n  resources are properly released to prevent leaks."
    - signature: 'def from_config(cls: typing.Type[google.adk.tools.base_toolset.SelfToolset], config: google.adk.tools.tool_configs.ToolArgsConfig, config_abs_path: str) -> google.adk.tools.base_toolset.SelfToolset:'
      docstring: "Creates a toolset instance from a config.\n\nArgs:\n  config: The config for the tool.\n  config_abs_path: The absolute path to the config file that contains the\n    tool config.\n\nReturns:\n  The toolset instance."
    - signature: 'def process_llm_request(self, *, tool_context: google.adk.tools.tool_context.ToolContext, llm_request: google.adk.models.llm_request.LlmRequest) -> None:'
      docstring: "Processes the outgoing LLM request for this toolset. This method will be\ncalled before each tool processes the llm request.\n\nUse cases:\n- Instead of let each tool process the llm request, we can let the toolset\n  process the llm request. e.g. ComputerUseToolset can add computer use\n  tool to the llm request.\n\nArgs:\n  tool_context: The context of the tool.\n  llm_request: The outgoing LLM request, mutable this method."
  omitted_inherited_members_from:
  - ABC
- rank: 26
  id: google.adk.auth.auth_credential.AuthCredential
  name: AuthCredential
  file_path: google/adk/auth/auth_credential.py
  type: CLASS
  group: Seed
  usage_score: 4
  docstring: "Data class representing an authentication credential.\n\nTo exchange for the actual credential, please use\nCredentialExchanger.exchange_credential().\n\nExamples: API Key Auth\nAuthCredential(\n    auth_type=AuthCredentialTypes.API_KEY,\n    api_key=\"1234\",\n)\n\nExample: HTTP Auth\nAuthCredential(\n    auth_type=AuthCredentialTypes.HTTP,\n    http=HttpAuth(\n        scheme=\"basic\",\n        credentials=HttpCredentials(username=\"user\", password=\"password\"),\n    ),\n)\n\nExample: OAuth2 Bearer Token in HTTP Header\nAuthCredential(\n    auth_type=AuthCredentialTypes.HTTP,\n    http=HttpAuth(\n        scheme=\"bearer\",\n        credentials=HttpCredentials(token=\"eyAkaknabna....\"),\n    ),\n)\n\nExample: OAuth2 Auth with Authorization Code Flow\nAuthCredential(\n    auth_type=AuthCredentialTypes.OAUTH2,\n    oauth2=OAuth2Auth(\n        client_id=\"1234\",\n        client_secret=\"secret\",\n    ),\n)\n\nExample: OpenID Connect Auth\nAuthCredential(\n    auth_type=AuthCredentialTypes.OPEN_ID_CONNECT,\n\
    \    oauth2=OAuth2Auth(\n        client_id=\"1234\",\n        client_secret=\"secret\",\n        redirect_uri=\"https://example.com\",\n        scopes=[\"scope1\", \"scope2\"],\n    ),\n)\n\nExample: Auth with resource reference\nAuthCredential(\n    auth_type=AuthCredentialTypes.API_KEY,\n    resource_ref=\"projects/1234/locations/us-central1/resources/resource1\",\n)\n\n[Note: Inherited members from pydantic.BaseModel are omitted.]"
  constructor_signature: 'def __init__(self, *, auth_type: google.adk.auth.auth_credential.AuthCredentialTypes, resource_ref: typing.Optional[str] = None, api_key: typing.Optional[str] = None, http: typing.Optional[google.adk.auth.auth_credential.HttpAuth] = None, service_account: typing.Optional[google.adk.auth.auth_credential.ServiceAccount] = None, oauth2: typing.Optional[google.adk.auth.auth_credential.OAuth2Auth] = None):'
  properties:
  - signature: 'auth_type: google.adk.auth.auth_credential.AuthCredentialTypes'
  - signature: 'resource_ref: typing.Optional[str]'
  - signature: 'api_key: typing.Optional[str]'
  - signature: 'http: typing.Optional[google.adk.auth.auth_credential.HttpAuth]'
  - signature: 'service_account: typing.Optional[google.adk.auth.auth_credential.ServiceAccount]'
  - signature: 'oauth2: typing.Optional[google.adk.auth.auth_credential.OAuth2Auth]'
  inherited_properties:
    BaseModelWithConfig:
    - signature: 'model_config: pydantic.ConfigDict'
      docstring: The pydantic model config.
    BaseModel:
    - signature: 'model_config: pydantic.ConfigDict'
  omitted_inherited_members_from:
  - pydantic.BaseModel
- rank: 27
  id: google.adk.agents.remote_a2a_agent.RemoteA2aAgent
  name: RemoteA2aAgent
  file_path: google/adk/agents/remote_a2a_agent.py
  type: CLASS
  group: Seed
  usage_score: 4
  docstring: 'Agent that communicates with a remote A2A agent via A2A client.


    This agent supports multiple ways to specify the remote agent:

    1. Direct AgentCard object

    2. URL to agent card JSON

    3. File path to agent card JSON


    The agent handles:

    - Agent card resolution and validation

    - HTTP client management with proper resource cleanup

    - A2A message conversion and error handling

    - Session state management across requests


    [Note: Inherited members from pydantic.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, name: str, agent_card: typing.Union[a2a.types.AgentCard, str], *, description: str='''', httpx_client: typing.Optional[httpx.AsyncClient]=None, timeout: float=DEFAULT_TIMEOUT, genai_part_converter: google.adk.a2a.converters.part_converter.GenAIPartToA2APartConverter=convert_genai_part_to_a2a_part, a2a_part_converter: google.adk.a2a.converters.part_converter.A2APartToGenAIPartConverter=convert_a2a_part_to_genai_part, a2a_client_factory: typing.Optional[a2a.client.client_factory.ClientFactory]=None, a2a_request_meta_provider: typing.Optional[typing.Callable[[InvocationContext, A2AMessage], dict[str, typing.Any]]]=None) -> None:'
  methods:
  - signature: 'def _run_async_impl(self, ctx: google.adk.agents.invocation_context.InvocationContext) -> typing.AsyncGenerator[google.adk.events.event.Event, None]:'
    docstring: Core implementation for async agent execution.
  - signature: 'def cleanup(self) -> None:'
    docstring: Clean up resources, especially the HTTP client if owned by this agent.
  inherited_methods:
    BaseAgent:
    - signature: 'def clone(self: google.adk.agents.base_agent.SelfAgent, update: Mapping[str, Any] | None) -> google.adk.agents.base_agent.SelfAgent:'
      docstring: "Creates a copy of this agent instance.\n\nArgs:\n  update: Optional mapping of new values for the fields of the cloned agent.\n    The keys of the mapping are the names of the fields to be updated, and\n    the values are the new values for those fields.\n    For example: {\"name\": \"cloned_agent\"}\n\nReturns:\n  A new agent instance with identical configuration as the original\n  agent except for the fields specified in the update."
    - signature: 'def run_async(self, parent_context: google.adk.agents.invocation_context.InvocationContext) -> typing.AsyncGenerator[google.adk.events.event.Event, None]:'
      docstring: "Entry method to run an agent via text-based conversation.\n\nArgs:\n  parent_context: InvocationContext, the invocation context of the parent\n    agent.\n\nYields:\n  Event: the events generated by the agent."
    - signature: 'def run_live(self, parent_context: google.adk.agents.invocation_context.InvocationContext) -> typing.AsyncGenerator[google.adk.events.event.Event, None]:'
      docstring: "Entry method to run an agent via video/audio-based conversation.\n\nArgs:\n  parent_context: InvocationContext, the invocation context of the parent\n    agent.\n\nYields:\n  Event: the events generated by the agent."
    - signature: 'def _run_async_impl(self, ctx: google.adk.agents.invocation_context.InvocationContext) -> typing.AsyncGenerator[google.adk.events.event.Event, None]:'
      docstring: "Core logic to run this agent via text-based conversation.\n\nArgs:\n  ctx: InvocationContext, the invocation context for this agent.\n\nYields:\n  Event: the events generated by the agent."
    - signature: 'def root_agent(self) -> google.adk.agents.base_agent.BaseAgent:'
      docstring: Gets the root agent of this agent.
    - signature: 'def find_agent(self, name: str) -> typing.Optional[google.adk.agents.base_agent.BaseAgent]:'
      docstring: "Finds the agent with the given name in this agent and its descendants.\n\nArgs:\n  name: The name of the agent to find.\n\nReturns:\n  The agent with the matching name, or None if no such agent is found."
    - signature: 'def find_sub_agent(self, name: str) -> typing.Optional[google.adk.agents.base_agent.BaseAgent]:'
      docstring: "Finds the agent with the given name in this agent's descendants.\n\nArgs:\n  name: The name of the agent to find.\n\nReturns:\n  The agent with the matching name, or None if no such agent is found."
    - signature: 'def model_post_init(self, __context: typing.Any) -> None:'
    - signature: 'def validate_name(cls, value: str):'
    - signature: 'def validate_sub_agents_unique_names(cls, value: list[google.adk.agents.base_agent.BaseAgent]) -> list[google.adk.agents.base_agent.BaseAgent]:'
      docstring: "Validates that all sub-agents have unique names.\n\nArgs:\n  value: The list of sub-agents to validate.\n\nReturns:\n  The validated list of sub-agents."
    - signature: 'def from_config(cls: typing.Type[google.adk.agents.base_agent.SelfAgent], config: google.adk.agents.base_agent_config.BaseAgentConfig, config_abs_path: str) -> google.adk.agents.base_agent.SelfAgent:'
      docstring: "Creates an agent from a config.\n\nIf sub-classes uses a custom agent config, override `_from_config_kwargs`\nmethod to return an updated kwargs for agent constructor.\n\nArgs:\n  config: The config to create the agent from.\n  config_abs_path: The absolute path to the config file that contains the\n    agent config.\n\nReturns:\n  The created agent."
  inherited_properties:
    BaseAgent:
    - signature: 'model_config: pydantic.ConfigDict'
      docstring: The pydantic model config.
    - signature: 'config_type: typing.ClassVar[type[google.adk.agents.base_agent_config.BaseAgentConfig]]'
      docstring: "The config type for this agent.\n\nSub-classes should override this to specify their own config type.\n\nExample:\n\n```\nclass MyAgentConfig(BaseAgentConfig):\n  my_field: str = ''\n\nclass MyAgent(BaseAgent):\n  config_type: ClassVar[type[BaseAgentConfig]] = MyAgentConfig\n```"
    - signature: 'name: str'
      docstring: 'The agent''s name.


        Agent name must be a Python identifier and unique within the agent tree.

        Agent name cannot be "user", since it''s reserved for end-user''s input.'
    - signature: 'description: str'
      docstring: 'Description about the agent''s capability.


        The model uses this to determine whether to delegate control to the agent.

        One-line description is enough and preferred.'
    - signature: 'parent_agent: typing.Optional[google.adk.agents.base_agent.BaseAgent]'
      docstring: 'The parent agent of this agent.


        Note that an agent can ONLY be added as sub-agent once.


        If you want to add one agent twice as sub-agent, consider to create two agent

        instances with identical config, but with different name and add them to the

        agent tree.'
    - signature: 'sub_agents: list[google.adk.agents.base_agent.BaseAgent]'
      docstring: The sub-agents of this agent.
    - signature: 'before_agent_callback: typing.Optional[google.adk.agents.base_agent.BeforeAgentCallback]'
      docstring: "Callback or list of callbacks to be invoked before the agent run.\n\nWhen a list of callbacks is provided, the callbacks will be called in the\norder they are listed until a callback does not return None.\n\nArgs:\n  callback_context: MUST be named 'callback_context' (enforced).\n\nReturns:\n  Optional[types.Content]: The content to return to the user.\n    When the content is present, the agent run will be skipped and the\n    provided content will be returned to user."
    - signature: 'after_agent_callback: typing.Optional[google.adk.agents.base_agent.AfterAgentCallback]'
      docstring: "Callback or list of callbacks to be invoked after the agent run.\n\nWhen a list of callbacks is provided, the callbacks will be called in the\norder they are listed until a callback does not return None.\n\nArgs:\n  callback_context: MUST be named 'callback_context' (enforced).\n\nReturns:\n  Optional[types.Content]: The content to return to the user.\n    When the content is present, an additional event with the provided content\n    will be appended to event history as an additional agent response."
    BaseModel:
    - signature: 'model_config: pydantic.ConfigDict'
  omitted_inherited_members_from:
  - pydantic.BaseModel
- rank: 28
  id: google.adk.events.event_actions.EventActions
  name: EventActions
  file_path: google/adk/events/event_actions.py
  type: CLASS
  group: Seed
  usage_score: 4
  docstring: 'Represents the actions attached to an event.


    [Note: Inherited members from pydantic.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, skip_summarization: typing.Optional[bool] = None, state_delta: dict[str, object] = dict(), artifact_delta: dict[str, int] = dict(), transfer_to_agent: typing.Optional[str] = None, escalate: typing.Optional[bool] = None, requested_auth_configs: dict[str, google.adk.auth.auth_tool.AuthConfig] = dict(), requested_tool_confirmations: dict[str, google.adk.tools.tool_confirmation.ToolConfirmation] = dict(), compaction: typing.Optional[google.adk.events.event_actions.EventCompaction] = None, end_of_agent: typing.Optional[bool] = None, agent_state: typing.Optional[dict[str, typing.Any]] = None, rewind_before_invocation_id: typing.Optional[str] = None):'
  properties:
  - signature: 'model_config: pydantic.ConfigDict'
    docstring: The pydantic model config.
  - signature: 'skip_summarization: typing.Optional[bool]'
    docstring: 'If true, it won''t call model to summarize function response.


      Only used for function_response event.'
  - signature: 'state_delta: dict[str, object]'
    docstring: Indicates that the event is updating the state with the given delta.
  - signature: 'artifact_delta: dict[str, int]'
    docstring: 'Indicates that the event is updating an artifact. key is the filename,

      value is the version.'
  - signature: 'transfer_to_agent: typing.Optional[str]'
    docstring: If set, the event transfers to the specified agent.
  - signature: 'escalate: typing.Optional[bool]'
    docstring: The agent is escalating to a higher level agent.
  - signature: 'requested_auth_configs: dict[str, google.adk.auth.auth_tool.AuthConfig]'
    docstring: 'Authentication configurations requested by tool responses.


      This field will only be set by a tool response event indicating tool request

      auth credential.

      - Keys: The function call id. Since one function response event could contain

      multiple function responses that correspond to multiple function calls. Each

      function call could request different auth configs. This id is used to

      identify the function call.

      - Values: The requested auth config.'
  - signature: 'requested_tool_confirmations: dict[str, google.adk.tools.tool_confirmation.ToolConfirmation]'
    docstring: 'A dict of tool confirmation requested by this event, keyed by

      function call id.'
  - signature: 'compaction: typing.Optional[google.adk.events.event_actions.EventCompaction]'
    docstring: The compaction of the events.
  - signature: 'end_of_agent: typing.Optional[bool]'
    docstring: 'If true, the current agent has finished its current run. Note that there

      can be multiple events with end_of_agent=True for the same agent within one

      invocation when there is a loop. This should only be set by ADK workflow.'
  - signature: 'agent_state: typing.Optional[dict[str, typing.Any]]'
    docstring: 'The agent state at the current event, used for checkpoint and resume. This

      should only be set by ADK workflow.'
  - signature: 'rewind_before_invocation_id: typing.Optional[str]'
    docstring: The invocation id to rewind to. This is only set for rewind event.
  inherited_properties:
    BaseModel:
    - signature: 'model_config: pydantic.ConfigDict'
  omitted_inherited_members_from:
  - pydantic.BaseModel
- rank: 29
  id: google.adk.tools.vertex_ai_search_tool.VertexAiSearchTool
  name: VertexAiSearchTool
  file_path: google/adk/tools/vertex_ai_search_tool.py
  type: CLASS
  group: Seed
  usage_score: 3
  docstring: "A built-in tool using Vertex AI Search.\n\nAttributes:\n  data_store_id: The Vertex AI search data store resource ID.\n  search_engine_id: The Vertex AI search engine resource ID.\n\n[Note: Inherited members from ABC are omitted.]"
  constructor_signature: 'def __init__(self, *, data_store_id: typing.Optional[str]=None, data_store_specs: typing.Optional[list[google.genai.types.VertexAISearchDataStoreSpec]]=None, search_engine_id: typing.Optional[str]=None, filter: typing.Optional[str]=None, max_results: typing.Optional[int]=None, bypass_multi_tools_limit: bool=False):'
  methods:
  - signature: 'def process_llm_request(self, *, tool_context: google.adk.tools.tool_context.ToolContext, llm_request: google.adk.models.LlmRequest) -> None:'
  inherited_methods:
    BaseTool:
    - signature: 'def run_async(self, *, args: dict[str, typing.Any], tool_context: google.adk.tools.tool_context.ToolContext) -> typing.Any:'
      docstring: "Runs the tool with the given arguments and context.\n\nNOTE:\n  - Required if this tool needs to run at the client side.\n  - Otherwise, can be skipped, e.g. for a built-in GoogleSearch tool for\n    Gemini.\n\nArgs:\n  args: The LLM-filled arguments.\n  tool_context: The context of the tool.\n\nReturns:\n  The result of running the tool."
    - signature: 'def process_llm_request(self, *, tool_context: google.adk.tools.tool_context.ToolContext, llm_request: google.adk.models.llm_request.LlmRequest) -> None:'
      docstring: "Processes the outgoing LLM request for this tool.\n\nUse cases:\n- Most common use case is adding this tool to the LLM request.\n- Some tools may just preprocess the LLM request before it's sent out.\n\nArgs:\n  tool_context: The context of the tool.\n  llm_request: The outgoing LLM request, mutable this method."
    - signature: 'def from_config(cls: typing.Type[google.adk.tools.base_tool.SelfTool], config: google.adk.tools.tool_configs.ToolArgsConfig, config_abs_path: str) -> google.adk.tools.base_tool.SelfTool:'
      docstring: "Creates a tool instance from a config.\n\nThis default implementation uses inspect to automatically map config values\nto constructor arguments based on their type hints. Subclasses should\noverride this method for custom initialization logic.\n\nArgs:\n  config: The config for the tool.\n  config_abs_path: The absolute path to the config file that contains the\n    tool config.\n\nReturns:\n  The tool instance."
  inherited_properties:
    BaseTool:
    - signature: 'name: str'
      docstring: The name of the tool.
    - signature: 'description: str'
      docstring: The description of the tool.
    - signature: 'is_long_running: bool'
      docstring: 'Whether the tool is a long running operation, which typically returns a

        resource id first and finishes the operation later.'
    - signature: 'custom_metadata: typing.Optional[dict[str, typing.Any]]'
      docstring: 'The custom metadata of the BaseTool.


        An optional key-value pair for storing and retrieving tool-specific metadata,

        such as tool manifests, etc.


        NOTE: the entire dict must be JSON serializable.'
  omitted_inherited_members_from:
  - ABC
- rank: 30
  id: google.adk.tools.example_tool.ExampleTool
  name: ExampleTool
  file_path: google/adk/tools/example_tool.py
  type: CLASS
  group: Seed
  usage_score: 3
  docstring: "A tool that adds (few-shot) examples to the LLM request.\n\nAttributes:\n  examples: The examples to add to the LLM request.\n\n[Note: Inherited members from ABC are omitted.]"
  constructor_signature: 'def __init__(self, examples: typing.Union[list[google.adk.examples.example.Example], google.adk.examples.base_example_provider.BaseExampleProvider]):'
  methods:
  - signature: 'def process_llm_request(self, *, tool_context: google.adk.tools.tool_context.ToolContext, llm_request: google.adk.models.llm_request.LlmRequest) -> None:'
  - signature: 'def from_config(cls: type[google.adk.tools.example_tool.ExampleTool], config: google.adk.tools.tool_configs.ToolArgsConfig, config_abs_path: str) -> google.adk.tools.example_tool.ExampleTool:'
  inherited_methods:
    BaseTool:
    - signature: 'def run_async(self, *, args: dict[str, typing.Any], tool_context: google.adk.tools.tool_context.ToolContext) -> typing.Any:'
      docstring: "Runs the tool with the given arguments and context.\n\nNOTE:\n  - Required if this tool needs to run at the client side.\n  - Otherwise, can be skipped, e.g. for a built-in GoogleSearch tool for\n    Gemini.\n\nArgs:\n  args: The LLM-filled arguments.\n  tool_context: The context of the tool.\n\nReturns:\n  The result of running the tool."
    - signature: 'def process_llm_request(self, *, tool_context: google.adk.tools.tool_context.ToolContext, llm_request: google.adk.models.llm_request.LlmRequest) -> None:'
      docstring: "Processes the outgoing LLM request for this tool.\n\nUse cases:\n- Most common use case is adding this tool to the LLM request.\n- Some tools may just preprocess the LLM request before it's sent out.\n\nArgs:\n  tool_context: The context of the tool.\n  llm_request: The outgoing LLM request, mutable this method."
    - signature: 'def from_config(cls: typing.Type[google.adk.tools.base_tool.SelfTool], config: google.adk.tools.tool_configs.ToolArgsConfig, config_abs_path: str) -> google.adk.tools.base_tool.SelfTool:'
      docstring: "Creates a tool instance from a config.\n\nThis default implementation uses inspect to automatically map config values\nto constructor arguments based on their type hints. Subclasses should\noverride this method for custom initialization logic.\n\nArgs:\n  config: The config for the tool.\n  config_abs_path: The absolute path to the config file that contains the\n    tool config.\n\nReturns:\n  The tool instance."
  inherited_properties:
    BaseTool:
    - signature: 'name: str'
      docstring: The name of the tool.
    - signature: 'description: str'
      docstring: The description of the tool.
    - signature: 'is_long_running: bool'
      docstring: 'Whether the tool is a long running operation, which typically returns a

        resource id first and finishes the operation later.'
    - signature: 'custom_metadata: typing.Optional[dict[str, typing.Any]]'
      docstring: 'The custom metadata of the BaseTool.


        An optional key-value pair for storing and retrieving tool-specific metadata,

        such as tool manifests, etc.


        NOTE: the entire dict must be JSON serializable.'
  omitted_inherited_members_from:
  - ABC
- rank: 31
  id: google.adk.tools.bigtable.bigtable_credentials.BigtableCredentialsConfig
  name: BigtableCredentialsConfig
  file_path: google/adk/tools/bigtable/bigtable_credentials.py
  type: CLASS
  group: Seed
  usage_score: 3
  docstring: 'Bigtable Credentials Configuration for Google API tools (Experimental).


    Please do not use this in production, as it may be deprecated later.


    [Note: Inherited members from BaseGoogleCredentialsConfig are omitted.]'
  omitted_inherited_members_from:
  - BaseGoogleCredentialsConfig
- rank: 32
  id: google.adk.tools.bigquery.bigquery_credentials.BigQueryCredentialsConfig
  name: BigQueryCredentialsConfig
  file_path: google/adk/tools/bigquery/bigquery_credentials.py
  type: CLASS
  group: Seed
  usage_score: 3
  docstring: 'BigQuery Credentials Configuration for Google API tools (Experimental).


    Please do not use this in production, as it may be deprecated later.


    [Note: Inherited members from BaseGoogleCredentialsConfig are omitted.]'
  omitted_inherited_members_from:
  - BaseGoogleCredentialsConfig
- rank: 33
  id: google.adk.tools.bigquery.bigquery_toolset.BigQueryToolset
  name: BigQueryToolset
  file_path: google/adk/tools/bigquery/bigquery_toolset.py
  type: CLASS
  group: Seed
  usage_score: 3
  docstring: 'BigQuery Toolset contains tools for interacting with BigQuery data and metadata.


    [Note: Inherited members from ABC are omitted.]'
  constructor_signature: 'def __init__(self, *, tool_filter: typing.Optional[typing.Union[google.adk.tools.base_toolset.ToolPredicate, typing.List[str]]]=None, credentials_config: typing.Optional[google.adk.tools.bigquery.bigquery_credentials.BigQueryCredentialsConfig]=None, bigquery_tool_config: typing.Optional[google.adk.tools.bigquery.config.BigQueryToolConfig]=None):'
  methods:
  - signature: 'def get_tools(self, readonly_context: typing.Optional[google.adk.agents.readonly_context.ReadonlyContext]) -> typing.List[google.adk.tools.base_tool.BaseTool]:'
    docstring: Get tools from the toolset.
  - signature: 'def close(self):'
  inherited_methods:
    BaseToolset:
    - signature: 'def get_tools(self, readonly_context: typing.Optional[google.adk.agents.readonly_context.ReadonlyContext]) -> list[google.adk.tools.base_tool.BaseTool]:'
      docstring: "Return all tools in the toolset based on the provided context.\n\nArgs:\n  readonly_context (ReadonlyContext, optional): Context used to filter tools\n    available to the agent. If None, all tools in the toolset are returned.\n\nReturns:\n  list[BaseTool]: A list of tools available under the specified context."
    - signature: 'def get_tools_with_prefix(self, readonly_context: typing.Optional[google.adk.agents.readonly_context.ReadonlyContext]) -> list[google.adk.tools.base_tool.BaseTool]:'
      docstring: "Return all tools with optional prefix applied to tool names.\n\nThis method calls get_tools() and applies prefixing if tool_name_prefix is provided.\n\nArgs:\n  readonly_context (ReadonlyContext, optional): Context used to filter tools\n    available to the agent. If None, all tools in the toolset are returned.\n\nReturns:\n  list[BaseTool]: A list of tools with prefixed names if tool_name_prefix is provided."
    - signature: 'def close(self) -> None:'
      docstring: "Performs cleanup and releases resources held by the toolset.\n\nNOTE:\n  This method is invoked, for example, at the end of an agent server's\n  lifecycle or when the toolset is no longer needed. Implementations\n  should ensure that any open connections, files, or other managed\n  resources are properly released to prevent leaks."
    - signature: 'def from_config(cls: typing.Type[google.adk.tools.base_toolset.SelfToolset], config: google.adk.tools.tool_configs.ToolArgsConfig, config_abs_path: str) -> google.adk.tools.base_toolset.SelfToolset:'
      docstring: "Creates a toolset instance from a config.\n\nArgs:\n  config: The config for the tool.\n  config_abs_path: The absolute path to the config file that contains the\n    tool config.\n\nReturns:\n  The toolset instance."
    - signature: 'def process_llm_request(self, *, tool_context: google.adk.tools.tool_context.ToolContext, llm_request: google.adk.models.llm_request.LlmRequest) -> None:'
      docstring: "Processes the outgoing LLM request for this toolset. This method will be\ncalled before each tool processes the llm request.\n\nUse cases:\n- Instead of let each tool process the llm request, we can let the toolset\n  process the llm request. e.g. ComputerUseToolset can add computer use\n  tool to the llm request.\n\nArgs:\n  tool_context: The context of the tool.\n  llm_request: The outgoing LLM request, mutable this method."
  omitted_inherited_members_from:
  - ABC
- rank: 34
  id: google.adk.auth.auth_credential.OAuth2Auth
  name: OAuth2Auth
  file_path: google/adk/auth/auth_credential.py
  type: CLASS
  group: Seed
  usage_score: 3
  docstring: 'Represents credential value and its metadata for a OAuth2 credential.


    [Note: Inherited members from pydantic.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, client_id: typing.Optional[str] = None, client_secret: typing.Optional[str] = None, auth_uri: typing.Optional[str] = None, state: typing.Optional[str] = None, redirect_uri: typing.Optional[str] = None, auth_response_uri: typing.Optional[str] = None, auth_code: typing.Optional[str] = None, access_token: typing.Optional[str] = None, refresh_token: typing.Optional[str] = None, expires_at: typing.Optional[int] = None, expires_in: typing.Optional[int] = None, audience: typing.Optional[str] = None):'
  properties:
  - signature: 'client_id: typing.Optional[str]'
  - signature: 'client_secret: typing.Optional[str]'
  - signature: 'auth_uri: typing.Optional[str]'
  - signature: 'state: typing.Optional[str]'
  - signature: 'redirect_uri: typing.Optional[str]'
  - signature: 'auth_response_uri: typing.Optional[str]'
  - signature: 'auth_code: typing.Optional[str]'
  - signature: 'access_token: typing.Optional[str]'
  - signature: 'refresh_token: typing.Optional[str]'
  - signature: 'expires_at: typing.Optional[int]'
  - signature: 'expires_in: typing.Optional[int]'
  - signature: 'audience: typing.Optional[str]'
  inherited_properties:
    BaseModelWithConfig:
    - signature: 'model_config: pydantic.ConfigDict'
      docstring: The pydantic model config.
    BaseModel:
    - signature: 'model_config: pydantic.ConfigDict'
  omitted_inherited_members_from:
  - pydantic.BaseModel
- rank: 35
  id: google.adk.agents.parallel_agent.ParallelAgent
  name: ParallelAgent
  file_path: google/adk/agents/parallel_agent.py
  type: CLASS
  group: Seed
  usage_score: 3
  docstring: 'A shell agent that runs its sub-agents in parallel in an isolated manner.


    This approach is beneficial for scenarios requiring multiple perspectives or

    attempts on a single task, such as:


    - Running different algorithms simultaneously.

    - Generating multiple responses for review by a subsequent evaluation agent.


    [Note: Inherited members from pydantic.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, name: str, description: str = '''', sub_agents: list[google.adk.agents.base_agent.BaseAgent] = list(), before_agent_callback: typing.Optional[google.adk.agents.base_agent.BeforeAgentCallback] = None, after_agent_callback: typing.Optional[google.adk.agents.base_agent.AfterAgentCallback] = None):'
  methods:
  - signature: 'def _run_async_impl(self, ctx: google.adk.agents.invocation_context.InvocationContext) -> typing.AsyncGenerator[google.adk.events.event.Event, None]:'
  properties:
  - signature: 'config_type: typing.ClassVar[type[google.adk.agents.base_agent_config.BaseAgentConfig]]'
    docstring: The config type for this agent.
  inherited_methods:
    BaseAgent:
    - signature: 'def clone(self: google.adk.agents.base_agent.SelfAgent, update: Mapping[str, Any] | None) -> google.adk.agents.base_agent.SelfAgent:'
      docstring: "Creates a copy of this agent instance.\n\nArgs:\n  update: Optional mapping of new values for the fields of the cloned agent.\n    The keys of the mapping are the names of the fields to be updated, and\n    the values are the new values for those fields.\n    For example: {\"name\": \"cloned_agent\"}\n\nReturns:\n  A new agent instance with identical configuration as the original\n  agent except for the fields specified in the update."
    - signature: 'def run_async(self, parent_context: google.adk.agents.invocation_context.InvocationContext) -> typing.AsyncGenerator[google.adk.events.event.Event, None]:'
      docstring: "Entry method to run an agent via text-based conversation.\n\nArgs:\n  parent_context: InvocationContext, the invocation context of the parent\n    agent.\n\nYields:\n  Event: the events generated by the agent."
    - signature: 'def run_live(self, parent_context: google.adk.agents.invocation_context.InvocationContext) -> typing.AsyncGenerator[google.adk.events.event.Event, None]:'
      docstring: "Entry method to run an agent via video/audio-based conversation.\n\nArgs:\n  parent_context: InvocationContext, the invocation context of the parent\n    agent.\n\nYields:\n  Event: the events generated by the agent."
    - signature: 'def _run_async_impl(self, ctx: google.adk.agents.invocation_context.InvocationContext) -> typing.AsyncGenerator[google.adk.events.event.Event, None]:'
      docstring: "Core logic to run this agent via text-based conversation.\n\nArgs:\n  ctx: InvocationContext, the invocation context for this agent.\n\nYields:\n  Event: the events generated by the agent."
    - signature: 'def root_agent(self) -> google.adk.agents.base_agent.BaseAgent:'
      docstring: Gets the root agent of this agent.
    - signature: 'def find_agent(self, name: str) -> typing.Optional[google.adk.agents.base_agent.BaseAgent]:'
      docstring: "Finds the agent with the given name in this agent and its descendants.\n\nArgs:\n  name: The name of the agent to find.\n\nReturns:\n  The agent with the matching name, or None if no such agent is found."
    - signature: 'def find_sub_agent(self, name: str) -> typing.Optional[google.adk.agents.base_agent.BaseAgent]:'
      docstring: "Finds the agent with the given name in this agent's descendants.\n\nArgs:\n  name: The name of the agent to find.\n\nReturns:\n  The agent with the matching name, or None if no such agent is found."
    - signature: 'def model_post_init(self, __context: typing.Any) -> None:'
    - signature: 'def validate_name(cls, value: str):'
    - signature: 'def validate_sub_agents_unique_names(cls, value: list[google.adk.agents.base_agent.BaseAgent]) -> list[google.adk.agents.base_agent.BaseAgent]:'
      docstring: "Validates that all sub-agents have unique names.\n\nArgs:\n  value: The list of sub-agents to validate.\n\nReturns:\n  The validated list of sub-agents."
    - signature: 'def from_config(cls: typing.Type[google.adk.agents.base_agent.SelfAgent], config: google.adk.agents.base_agent_config.BaseAgentConfig, config_abs_path: str) -> google.adk.agents.base_agent.SelfAgent:'
      docstring: "Creates an agent from a config.\n\nIf sub-classes uses a custom agent config, override `_from_config_kwargs`\nmethod to return an updated kwargs for agent constructor.\n\nArgs:\n  config: The config to create the agent from.\n  config_abs_path: The absolute path to the config file that contains the\n    agent config.\n\nReturns:\n  The created agent."
  inherited_properties:
    BaseAgent:
    - signature: 'model_config: pydantic.ConfigDict'
      docstring: The pydantic model config.
    - signature: 'config_type: typing.ClassVar[type[google.adk.agents.base_agent_config.BaseAgentConfig]]'
      docstring: "The config type for this agent.\n\nSub-classes should override this to specify their own config type.\n\nExample:\n\n```\nclass MyAgentConfig(BaseAgentConfig):\n  my_field: str = ''\n\nclass MyAgent(BaseAgent):\n  config_type: ClassVar[type[BaseAgentConfig]] = MyAgentConfig\n```"
    - signature: 'name: str'
      docstring: 'The agent''s name.


        Agent name must be a Python identifier and unique within the agent tree.

        Agent name cannot be "user", since it''s reserved for end-user''s input.'
    - signature: 'description: str'
      docstring: 'Description about the agent''s capability.


        The model uses this to determine whether to delegate control to the agent.

        One-line description is enough and preferred.'
    - signature: 'parent_agent: typing.Optional[google.adk.agents.base_agent.BaseAgent]'
      docstring: 'The parent agent of this agent.


        Note that an agent can ONLY be added as sub-agent once.


        If you want to add one agent twice as sub-agent, consider to create two agent

        instances with identical config, but with different name and add them to the

        agent tree.'
    - signature: 'sub_agents: list[google.adk.agents.base_agent.BaseAgent]'
      docstring: The sub-agents of this agent.
    - signature: 'before_agent_callback: typing.Optional[google.adk.agents.base_agent.BeforeAgentCallback]'
      docstring: "Callback or list of callbacks to be invoked before the agent run.\n\nWhen a list of callbacks is provided, the callbacks will be called in the\norder they are listed until a callback does not return None.\n\nArgs:\n  callback_context: MUST be named 'callback_context' (enforced).\n\nReturns:\n  Optional[types.Content]: The content to return to the user.\n    When the content is present, the agent run will be skipped and the\n    provided content will be returned to user."
    - signature: 'after_agent_callback: typing.Optional[google.adk.agents.base_agent.AfterAgentCallback]'
      docstring: "Callback or list of callbacks to be invoked after the agent run.\n\nWhen a list of callbacks is provided, the callbacks will be called in the\norder they are listed until a callback does not return None.\n\nArgs:\n  callback_context: MUST be named 'callback_context' (enforced).\n\nReturns:\n  Optional[types.Content]: The content to return to the user.\n    When the content is present, an additional event with the provided content\n    will be appended to event history as an additional agent response."
    BaseModel:
    - signature: 'model_config: pydantic.ConfigDict'
  omitted_inherited_members_from:
  - pydantic.BaseModel
- rank: 36
  id: google.adk.tools.google_search_tool.GoogleSearchTool
  name: GoogleSearchTool
  file_path: google/adk/tools/google_search_tool.py
  type: CLASS
  group: Seed
  usage_score: 2
  docstring: 'A built-in tool that is automatically invoked by Gemini 2 models to retrieve search results from Google Search.


    This tool operates internally within the model and does not require or perform

    local code execution.


    [Note: Inherited members from ABC are omitted.]'
  constructor_signature: 'def __init__(self, *, bypass_multi_tools_limit: bool=False):'
  methods:
  - signature: 'def process_llm_request(self, *, tool_context: google.adk.tools.tool_context.ToolContext, llm_request: google.adk.models.LlmRequest) -> None:'
  inherited_methods:
    BaseTool:
    - signature: 'def run_async(self, *, args: dict[str, typing.Any], tool_context: google.adk.tools.tool_context.ToolContext) -> typing.Any:'
      docstring: "Runs the tool with the given arguments and context.\n\nNOTE:\n  - Required if this tool needs to run at the client side.\n  - Otherwise, can be skipped, e.g. for a built-in GoogleSearch tool for\n    Gemini.\n\nArgs:\n  args: The LLM-filled arguments.\n  tool_context: The context of the tool.\n\nReturns:\n  The result of running the tool."
    - signature: 'def process_llm_request(self, *, tool_context: google.adk.tools.tool_context.ToolContext, llm_request: google.adk.models.llm_request.LlmRequest) -> None:'
      docstring: "Processes the outgoing LLM request for this tool.\n\nUse cases:\n- Most common use case is adding this tool to the LLM request.\n- Some tools may just preprocess the LLM request before it's sent out.\n\nArgs:\n  tool_context: The context of the tool.\n  llm_request: The outgoing LLM request, mutable this method."
    - signature: 'def from_config(cls: typing.Type[google.adk.tools.base_tool.SelfTool], config: google.adk.tools.tool_configs.ToolArgsConfig, config_abs_path: str) -> google.adk.tools.base_tool.SelfTool:'
      docstring: "Creates a tool instance from a config.\n\nThis default implementation uses inspect to automatically map config values\nto constructor arguments based on their type hints. Subclasses should\noverride this method for custom initialization logic.\n\nArgs:\n  config: The config for the tool.\n  config_abs_path: The absolute path to the config file that contains the\n    tool config.\n\nReturns:\n  The tool instance."
  inherited_properties:
    BaseTool:
    - signature: 'name: str'
      docstring: The name of the tool.
    - signature: 'description: str'
      docstring: The description of the tool.
    - signature: 'is_long_running: bool'
      docstring: 'Whether the tool is a long running operation, which typically returns a

        resource id first and finishes the operation later.'
    - signature: 'custom_metadata: typing.Optional[dict[str, typing.Any]]'
      docstring: 'The custom metadata of the BaseTool.


        An optional key-value pair for storing and retrieving tool-specific metadata,

        such as tool manifests, etc.


        NOTE: the entire dict must be JSON serializable.'
  omitted_inherited_members_from:
  - ABC
- rank: 37
  id: google.adk.tools.authenticated_function_tool.AuthenticatedFunctionTool
  name: AuthenticatedFunctionTool
  file_path: google/adk/tools/authenticated_function_tool.py
  type: CLASS
  group: Seed
  usage_score: 2
  docstring: 'A FunctionTool that handles authentication before the actual tool logic

    gets called. Functions can accept a special `credential` argument which is the

    credential ready for use.(Experimental)


    [Note: Inherited members from ABC are omitted.]'
  constructor_signature: 'def __init__(self, *, func: typing.Callable[Ellipsis, typing.Any], auth_config: google.adk.auth.auth_tool.AuthConfig=None, response_for_auth_required: typing.Optional[typing.Union[dict[str, typing.Any], str]]=None):'
  methods:
  - signature: 'def run_async(self, *, args: dict[str, typing.Any], tool_context: google.adk.tools.tool_context.ToolContext) -> typing.Any:'
  - signature: 'def _run_async_impl(self, *, args: dict[str, typing.Any], tool_context: google.adk.tools.tool_context.ToolContext, credential: google.adk.auth.auth_credential.AuthCredential) -> typing.Any:'
  inherited_methods:
    FunctionTool:
    - signature: 'def run_async(self, *, args: dict[str, typing.Any], tool_context: google.adk.tools.tool_context.ToolContext) -> typing.Any:'
    BaseTool:
    - signature: 'def run_async(self, *, args: dict[str, typing.Any], tool_context: google.adk.tools.tool_context.ToolContext) -> typing.Any:'
      docstring: "Runs the tool with the given arguments and context.\n\nNOTE:\n  - Required if this tool needs to run at the client side.\n  - Otherwise, can be skipped, e.g. for a built-in GoogleSearch tool for\n    Gemini.\n\nArgs:\n  args: The LLM-filled arguments.\n  tool_context: The context of the tool.\n\nReturns:\n  The result of running the tool."
    - signature: 'def process_llm_request(self, *, tool_context: google.adk.tools.tool_context.ToolContext, llm_request: google.adk.models.llm_request.LlmRequest) -> None:'
      docstring: "Processes the outgoing LLM request for this tool.\n\nUse cases:\n- Most common use case is adding this tool to the LLM request.\n- Some tools may just preprocess the LLM request before it's sent out.\n\nArgs:\n  tool_context: The context of the tool.\n  llm_request: The outgoing LLM request, mutable this method."
    - signature: 'def from_config(cls: typing.Type[google.adk.tools.base_tool.SelfTool], config: google.adk.tools.tool_configs.ToolArgsConfig, config_abs_path: str) -> google.adk.tools.base_tool.SelfTool:'
      docstring: "Creates a tool instance from a config.\n\nThis default implementation uses inspect to automatically map config values\nto constructor arguments based on their type hints. Subclasses should\noverride this method for custom initialization logic.\n\nArgs:\n  config: The config for the tool.\n  config_abs_path: The absolute path to the config file that contains the\n    tool config.\n\nReturns:\n  The tool instance."
  inherited_properties:
    BaseTool:
    - signature: 'name: str'
      docstring: The name of the tool.
    - signature: 'description: str'
      docstring: The description of the tool.
    - signature: 'is_long_running: bool'
      docstring: 'Whether the tool is a long running operation, which typically returns a

        resource id first and finishes the operation later.'
    - signature: 'custom_metadata: typing.Optional[dict[str, typing.Any]]'
      docstring: 'The custom metadata of the BaseTool.


        An optional key-value pair for storing and retrieving tool-specific metadata,

        such as tool manifests, etc.


        NOTE: the entire dict must be JSON serializable.'
  omitted_inherited_members_from:
  - ABC
- rank: 38
  id: google.adk.tools.long_running_tool.LongRunningFunctionTool
  name: LongRunningFunctionTool
  file_path: google/adk/tools/long_running_tool.py
  type: CLASS
  group: Seed
  usage_score: 2
  docstring: "A function tool that returns the result asynchronously.\n\nThis tool is used for long-running operations that may take a significant\namount of time to complete. The framework will call the function. Once the\nfunction returns, the response will be returned asynchronously to the\nframework which is identified by the function_call_id.\n\nExample:\n```python\ntool = LongRunningFunctionTool(a_long_running_function)\n```\n\nAttributes:\n  is_long_running: Whether the tool is a long running operation.\n\n[Note: Inherited members from ABC are omitted.]"
  constructor_signature: 'def __init__(self, func: typing.Callable):'
  inherited_methods:
    FunctionTool:
    - signature: 'def run_async(self, *, args: dict[str, typing.Any], tool_context: google.adk.tools.tool_context.ToolContext) -> typing.Any:'
    BaseTool:
    - signature: 'def run_async(self, *, args: dict[str, typing.Any], tool_context: google.adk.tools.tool_context.ToolContext) -> typing.Any:'
      docstring: "Runs the tool with the given arguments and context.\n\nNOTE:\n  - Required if this tool needs to run at the client side.\n  - Otherwise, can be skipped, e.g. for a built-in GoogleSearch tool for\n    Gemini.\n\nArgs:\n  args: The LLM-filled arguments.\n  tool_context: The context of the tool.\n\nReturns:\n  The result of running the tool."
    - signature: 'def process_llm_request(self, *, tool_context: google.adk.tools.tool_context.ToolContext, llm_request: google.adk.models.llm_request.LlmRequest) -> None:'
      docstring: "Processes the outgoing LLM request for this tool.\n\nUse cases:\n- Most common use case is adding this tool to the LLM request.\n- Some tools may just preprocess the LLM request before it's sent out.\n\nArgs:\n  tool_context: The context of the tool.\n  llm_request: The outgoing LLM request, mutable this method."
    - signature: 'def from_config(cls: typing.Type[google.adk.tools.base_tool.SelfTool], config: google.adk.tools.tool_configs.ToolArgsConfig, config_abs_path: str) -> google.adk.tools.base_tool.SelfTool:'
      docstring: "Creates a tool instance from a config.\n\nThis default implementation uses inspect to automatically map config values\nto constructor arguments based on their type hints. Subclasses should\noverride this method for custom initialization logic.\n\nArgs:\n  config: The config for the tool.\n  config_abs_path: The absolute path to the config file that contains the\n    tool config.\n\nReturns:\n  The tool instance."
  inherited_properties:
    BaseTool:
    - signature: 'name: str'
      docstring: The name of the tool.
    - signature: 'description: str'
      docstring: The description of the tool.
    - signature: 'is_long_running: bool'
      docstring: 'Whether the tool is a long running operation, which typically returns a

        resource id first and finishes the operation later.'
    - signature: 'custom_metadata: typing.Optional[dict[str, typing.Any]]'
      docstring: 'The custom metadata of the BaseTool.


        An optional key-value pair for storing and retrieving tool-specific metadata,

        such as tool manifests, etc.


        NOTE: the entire dict must be JSON serializable.'
  omitted_inherited_members_from:
  - ABC
- rank: 39
  id: google.adk.tools.retrieval.vertex_ai_rag_retrieval.VertexAiRagRetrieval
  name: VertexAiRagRetrieval
  file_path: google/adk/tools/retrieval/vertex_ai_rag_retrieval.py
  type: CLASS
  group: Seed
  usage_score: 2
  docstring: 'A retrieval tool that uses Vertex AI RAG (Retrieval-Augmented Generation) to retrieve data.


    [Note: Inherited members from ABC are omitted.]'
  constructor_signature: 'def __init__(self, *, name: str, description: str, rag_corpora: list[str]=None, rag_resources: list[google.adk.dependencies.vertexai.rag.RagResource]=None, similarity_top_k: int=None, vector_distance_threshold: float=None):'
  methods:
  - signature: 'def process_llm_request(self, *, tool_context: google.adk.tools.tool_context.ToolContext, llm_request: google.adk.models.LlmRequest) -> None:'
  - signature: 'def run_async(self, *, args: dict[str, typing.Any], tool_context: google.adk.tools.tool_context.ToolContext) -> typing.Any:'
  inherited_methods:
    BaseTool:
    - signature: 'def run_async(self, *, args: dict[str, typing.Any], tool_context: google.adk.tools.tool_context.ToolContext) -> typing.Any:'
      docstring: "Runs the tool with the given arguments and context.\n\nNOTE:\n  - Required if this tool needs to run at the client side.\n  - Otherwise, can be skipped, e.g. for a built-in GoogleSearch tool for\n    Gemini.\n\nArgs:\n  args: The LLM-filled arguments.\n  tool_context: The context of the tool.\n\nReturns:\n  The result of running the tool."
    - signature: 'def process_llm_request(self, *, tool_context: google.adk.tools.tool_context.ToolContext, llm_request: google.adk.models.llm_request.LlmRequest) -> None:'
      docstring: "Processes the outgoing LLM request for this tool.\n\nUse cases:\n- Most common use case is adding this tool to the LLM request.\n- Some tools may just preprocess the LLM request before it's sent out.\n\nArgs:\n  tool_context: The context of the tool.\n  llm_request: The outgoing LLM request, mutable this method."
    - signature: 'def from_config(cls: typing.Type[google.adk.tools.base_tool.SelfTool], config: google.adk.tools.tool_configs.ToolArgsConfig, config_abs_path: str) -> google.adk.tools.base_tool.SelfTool:'
      docstring: "Creates a tool instance from a config.\n\nThis default implementation uses inspect to automatically map config values\nto constructor arguments based on their type hints. Subclasses should\noverride this method for custom initialization logic.\n\nArgs:\n  config: The config for the tool.\n  config_abs_path: The absolute path to the config file that contains the\n    tool config.\n\nReturns:\n  The tool instance."
  inherited_properties:
    BaseTool:
    - signature: 'name: str'
      docstring: The name of the tool.
    - signature: 'description: str'
      docstring: The description of the tool.
    - signature: 'is_long_running: bool'
      docstring: 'Whether the tool is a long running operation, which typically returns a

        resource id first and finishes the operation later.'
    - signature: 'custom_metadata: typing.Optional[dict[str, typing.Any]]'
      docstring: 'The custom metadata of the BaseTool.


        An optional key-value pair for storing and retrieving tool-specific metadata,

        such as tool manifests, etc.


        NOTE: the entire dict must be JSON serializable.'
  omitted_inherited_members_from:
  - ABC
- rank: 40
  id: google.adk.tools.application_integration_tool.application_integration_toolset.ApplicationIntegrationToolset
  name: ApplicationIntegrationToolset
  file_path: google/adk/tools/application_integration_tool/application_integration_toolset.py
  type: CLASS
  group: Seed
  usage_score: 2
  docstring: "ApplicationIntegrationToolset generates tools from a given Application\nIntegration or Integration Connector resource.\n\nExample Usage::\n\n  # Get all available tools for an integration with api trigger\n  application_integration_toolset = ApplicationIntegrationToolset(\n      project=\"test-project\",\n      location=\"us-central1\"\n      integration=\"test-integration\",\n      triggers=[\"api_trigger/test_trigger\"],\n      service_account_credentials={...},\n  )\n\n  # Get all available tools for a connection using entity operations and\n  # actions\n  # Note: Find the list of supported entity operations and actions for a\n  # connection using integration connector apis:\n  # https://cloud.google.com/integration-connectors/docs/reference/rest/v1/projects.locations.connections.connectionSchemaMetadata\n  application_integration_toolset = ApplicationIntegrationToolset(\n      project=\"test-project\",\n      location=\"us-central1\"\n      connection=\"test-connection\"\
    ,\n      entity_operations=[\"EntityId1\": [\"LIST\",\"CREATE\"], \"EntityId2\": []],\n      #empty list for actions means all operations on the entity are supported\n      actions=[\"action1\"],\n      service_account_credentials={...},\n  )\n\n  # Feed the toolset to agent\n  agent = LlmAgent(tools=[\n      ...,\n      application_integration_toolset,\n  ])\n\n[Note: Inherited members from ABC are omitted.]"
  constructor_signature: 'def __init__(self, project: str, location: str, integration: typing.Optional[str], triggers: typing.Optional[typing.List[str]], connection: typing.Optional[str], entity_operations: typing.Optional[str], actions: typing.Optional[list[str]], tool_name_prefix: typing.Optional[str], tool_instructions: typing.Optional[str], service_account_json: typing.Optional[str], auth_scheme: typing.Optional[google.adk.auth.auth_schemes.AuthScheme], auth_credential: typing.Optional[google.adk.auth.auth_credential.AuthCredential], tool_filter: typing.Optional[typing.Union[google.adk.tools.base_toolset.ToolPredicate, typing.List[str]]]):'
  aliases:
  - google.adk.tools.application_integration_tool.ApplicationIntegrationToolset
  methods:
  - signature: 'def get_tools(self, readonly_context: typing.Optional[google.adk.agents.readonly_context.ReadonlyContext]) -> typing.List[google.adk.tools.openapi_tool.openapi_spec_parser.rest_api_tool.RestApiTool]:'
  - signature: 'def close(self) -> None:'
  inherited_methods:
    BaseToolset:
    - signature: 'def get_tools(self, readonly_context: typing.Optional[google.adk.agents.readonly_context.ReadonlyContext]) -> list[google.adk.tools.base_tool.BaseTool]:'
      docstring: "Return all tools in the toolset based on the provided context.\n\nArgs:\n  readonly_context (ReadonlyContext, optional): Context used to filter tools\n    available to the agent. If None, all tools in the toolset are returned.\n\nReturns:\n  list[BaseTool]: A list of tools available under the specified context."
    - signature: 'def get_tools_with_prefix(self, readonly_context: typing.Optional[google.adk.agents.readonly_context.ReadonlyContext]) -> list[google.adk.tools.base_tool.BaseTool]:'
      docstring: "Return all tools with optional prefix applied to tool names.\n\nThis method calls get_tools() and applies prefixing if tool_name_prefix is provided.\n\nArgs:\n  readonly_context (ReadonlyContext, optional): Context used to filter tools\n    available to the agent. If None, all tools in the toolset are returned.\n\nReturns:\n  list[BaseTool]: A list of tools with prefixed names if tool_name_prefix is provided."
    - signature: 'def close(self) -> None:'
      docstring: "Performs cleanup and releases resources held by the toolset.\n\nNOTE:\n  This method is invoked, for example, at the end of an agent server's\n  lifecycle or when the toolset is no longer needed. Implementations\n  should ensure that any open connections, files, or other managed\n  resources are properly released to prevent leaks."
    - signature: 'def from_config(cls: typing.Type[google.adk.tools.base_toolset.SelfToolset], config: google.adk.tools.tool_configs.ToolArgsConfig, config_abs_path: str) -> google.adk.tools.base_toolset.SelfToolset:'
      docstring: "Creates a toolset instance from a config.\n\nArgs:\n  config: The config for the tool.\n  config_abs_path: The absolute path to the config file that contains the\n    tool config.\n\nReturns:\n  The toolset instance."
    - signature: 'def process_llm_request(self, *, tool_context: google.adk.tools.tool_context.ToolContext, llm_request: google.adk.models.llm_request.LlmRequest) -> None:'
      docstring: "Processes the outgoing LLM request for this toolset. This method will be\ncalled before each tool processes the llm request.\n\nUse cases:\n- Instead of let each tool process the llm request, we can let the toolset\n  process the llm request. e.g. ComputerUseToolset can add computer use\n  tool to the llm request.\n\nArgs:\n  tool_context: The context of the tool.\n  llm_request: The outgoing LLM request, mutable this method."
  omitted_inherited_members_from:
  - ABC
- rank: 41
  id: google.adk.tools.mcp_tool.mcp_session_manager.StdioConnectionParams
  name: StdioConnectionParams
  file_path: google/adk/tools/mcp_tool/mcp_session_manager.py
  type: CLASS
  group: Seed
  usage_score: 2
  docstring: "Parameters for the MCP Stdio connection.\n\nAttributes:\n    server_params: Parameters for the MCP Stdio server.\n    timeout: Timeout in seconds for establishing the connection to the MCP\n      stdio server.\n\n[Note: Inherited members from pydantic.BaseModel are omitted.]"
  constructor_signature: 'def __init__(self, *, server_params: mcp.StdioServerParameters, timeout: float = 5.0):'
  properties:
  - signature: 'server_params: mcp.StdioServerParameters'
  - signature: 'timeout: float'
  inherited_properties:
    BaseModel:
    - signature: 'model_config: pydantic.ConfigDict'
  omitted_inherited_members_from:
  - pydantic.BaseModel
- rank: 42
  id: google.adk.tools.mcp_tool.mcp_session_manager.SseConnectionParams
  name: SseConnectionParams
  file_path: google/adk/tools/mcp_tool/mcp_session_manager.py
  type: CLASS
  group: Seed
  usage_score: 2
  docstring: "Parameters for the MCP SSE connection.\n\nSee MCP SSE Client documentation for more details.\nhttps://github.com/modelcontextprotocol/python-sdk/blob/main/src/mcp/client/sse.py\n\nAttributes:\n    url: URL for the MCP SSE server.\n    headers: Headers for the MCP SSE connection.\n    timeout: Timeout in seconds for establishing the connection to the MCP SSE\n      server.\n    sse_read_timeout: Timeout in seconds for reading data from the MCP SSE\n      server.\n\n[Note: Inherited members from pydantic.BaseModel are omitted.]"
  constructor_signature: 'def __init__(self, *, url: str, headers: dict[str, Any] | None = None, timeout: float = 5.0, sse_read_timeout: float = 60 * 5.0):'
  properties:
  - signature: 'url: str'
  - signature: 'headers: dict[str, Any] | None'
  - signature: 'timeout: float'
  - signature: 'sse_read_timeout: float'
  inherited_properties:
    BaseModel:
    - signature: 'model_config: pydantic.ConfigDict'
  omitted_inherited_members_from:
  - pydantic.BaseModel
- rank: 43
  id: google.adk.tools.mcp_tool.mcp_session_manager.StreamableHTTPConnectionParams
  name: StreamableHTTPConnectionParams
  file_path: google/adk/tools/mcp_tool/mcp_session_manager.py
  type: CLASS
  group: Seed
  usage_score: 2
  docstring: "Parameters for the MCP Streamable HTTP connection.\n\nSee MCP Streamable HTTP Client documentation for more details.\nhttps://github.com/modelcontextprotocol/python-sdk/blob/main/src/mcp/client/streamable_http.py\n\nAttributes:\n    url: URL for the MCP Streamable HTTP server.\n    headers: Headers for the MCP Streamable HTTP connection.\n    timeout: Timeout in seconds for establishing the connection to the MCP\n      Streamable HTTP server.\n    sse_read_timeout: Timeout in seconds for reading data from the MCP\n      Streamable HTTP server.\n    terminate_on_close: Whether to terminate the MCP Streamable HTTP server\n      when the connection is closed.\n\n[Note: Inherited members from pydantic.BaseModel are omitted.]"
  constructor_signature: 'def __init__(self, *, url: str, headers: dict[str, Any] | None = None, timeout: float = 5.0, sse_read_timeout: float = 60 * 5.0, terminate_on_close: bool = True):'
  properties:
  - signature: 'url: str'
  - signature: 'headers: dict[str, Any] | None'
  - signature: 'timeout: float'
  - signature: 'sse_read_timeout: float'
  - signature: 'terminate_on_close: bool'
  inherited_properties:
    BaseModel:
    - signature: 'model_config: pydantic.ConfigDict'
  omitted_inherited_members_from:
  - pydantic.BaseModel
- rank: 44
  id: google.adk.tools.mcp_tool.mcp_toolset.McpToolset
  name: McpToolset
  file_path: google/adk/tools/mcp_tool/mcp_toolset.py
  type: CLASS
  group: Seed
  usage_score: 2
  docstring: "Connects to a MCP Server, and retrieves MCP Tools into ADK Tools.\n\nThis toolset manages the connection to an MCP server and provides tools\nthat can be used by an agent. It properly implements the BaseToolset\ninterface for easy integration with the agent framework.\n\nUsage::\n\n  toolset = McpToolset(\n      connection_params=StdioServerParameters(\n          command='npx',\n          args=[\"-y\", \"@modelcontextprotocol/server-filesystem\"],\n      ),\n      tool_filter=['read_file', 'list_directory']  # Optional: filter specific tools\n  )\n\n  # Use in an agent\n  agent = LlmAgent(\n      model='gemini-2.0-flash',\n      name='enterprise_assistant',\n      instruction='Help user accessing their file systems',\n      tools=[toolset],\n  )\n\n  # Cleanup is handled automatically by the agent framework\n  # But you can also manually close if needed:\n  # await toolset.close()\n\n[Note: Inherited members from ABC are omitted.]"
  constructor_signature: 'def __init__(self, *, connection_params: typing.Union[mcp.StdioServerParameters, google.adk.tools.mcp_tool.mcp_session_manager.StdioConnectionParams, google.adk.tools.mcp_tool.mcp_session_manager.SseConnectionParams, google.adk.tools.mcp_tool.mcp_session_manager.StreamableHTTPConnectionParams], tool_filter: typing.Optional[typing.Union[google.adk.tools.base_toolset.ToolPredicate, typing.List[str]]]=None, tool_name_prefix: typing.Optional[str]=None, errlog: typing.TextIO=sys.stderr, auth_scheme: typing.Optional[google.adk.auth.auth_schemes.AuthScheme]=None, auth_credential: typing.Optional[google.adk.auth.auth_credential.AuthCredential]=None, require_confirmation: typing.Union[bool, typing.Callable[Ellipsis, bool]]=False, header_provider: typing.Optional[typing.Callable[[ReadonlyContext], typing.Dict[str, str]]]=None):'
  methods:
  - signature: 'def get_tools(self, readonly_context: typing.Optional[google.adk.agents.readonly_context.ReadonlyContext]) -> typing.List[google.adk.tools.base_tool.BaseTool]:'
    docstring: "Return all tools in the toolset based on the provided context.\n\nArgs:\n    readonly_context: Context used to filter tools available to the agent.\n        If None, all tools in the toolset are returned.\n\nReturns:\n    List[BaseTool]: A list of tools available under the specified context."
  - signature: 'def close(self) -> None:'
    docstring: 'Performs cleanup and releases resources held by the toolset.


      This method closes the MCP session and cleans up all associated resources.

      It''s designed to be safe to call multiple times and handles cleanup errors

      gracefully to avoid blocking application shutdown.'
  - signature: 'def from_config(cls: type[google.adk.tools.mcp_tool.mcp_toolset.McpToolset], config: google.adk.tools.tool_configs.ToolArgsConfig, config_abs_path: str) -> google.adk.tools.mcp_tool.mcp_toolset.McpToolset:'
    docstring: Creates an McpToolset from a configuration object.
  inherited_methods:
    BaseToolset:
    - signature: 'def get_tools(self, readonly_context: typing.Optional[google.adk.agents.readonly_context.ReadonlyContext]) -> list[google.adk.tools.base_tool.BaseTool]:'
      docstring: "Return all tools in the toolset based on the provided context.\n\nArgs:\n  readonly_context (ReadonlyContext, optional): Context used to filter tools\n    available to the agent. If None, all tools in the toolset are returned.\n\nReturns:\n  list[BaseTool]: A list of tools available under the specified context."
    - signature: 'def get_tools_with_prefix(self, readonly_context: typing.Optional[google.adk.agents.readonly_context.ReadonlyContext]) -> list[google.adk.tools.base_tool.BaseTool]:'
      docstring: "Return all tools with optional prefix applied to tool names.\n\nThis method calls get_tools() and applies prefixing if tool_name_prefix is provided.\n\nArgs:\n  readonly_context (ReadonlyContext, optional): Context used to filter tools\n    available to the agent. If None, all tools in the toolset are returned.\n\nReturns:\n  list[BaseTool]: A list of tools with prefixed names if tool_name_prefix is provided."
    - signature: 'def close(self) -> None:'
      docstring: "Performs cleanup and releases resources held by the toolset.\n\nNOTE:\n  This method is invoked, for example, at the end of an agent server's\n  lifecycle or when the toolset is no longer needed. Implementations\n  should ensure that any open connections, files, or other managed\n  resources are properly released to prevent leaks."
    - signature: 'def from_config(cls: typing.Type[google.adk.tools.base_toolset.SelfToolset], config: google.adk.tools.tool_configs.ToolArgsConfig, config_abs_path: str) -> google.adk.tools.base_toolset.SelfToolset:'
      docstring: "Creates a toolset instance from a config.\n\nArgs:\n  config: The config for the tool.\n  config_abs_path: The absolute path to the config file that contains the\n    tool config.\n\nReturns:\n  The toolset instance."
    - signature: 'def process_llm_request(self, *, tool_context: google.adk.tools.tool_context.ToolContext, llm_request: google.adk.models.llm_request.LlmRequest) -> None:'
      docstring: "Processes the outgoing LLM request for this toolset. This method will be\ncalled before each tool processes the llm request.\n\nUse cases:\n- Instead of let each tool process the llm request, we can let the toolset\n  process the llm request. e.g. ComputerUseToolset can add computer use\n  tool to the llm request.\n\nArgs:\n  tool_context: The context of the tool.\n  llm_request: The outgoing LLM request, mutable this method."
  omitted_inherited_members_from:
  - ABC
- rank: 45
  id: google.adk.memory.base_memory_service.SearchMemoryResponse
  name: SearchMemoryResponse
  file_path: google/adk/memory/base_memory_service.py
  type: CLASS
  group: Seed
  usage_score: 2
  docstring: "Represents the response from a memory search.\n\nAttributes:\n    memories: A list of memory entries that relate to the search query.\n\n[Note: Inherited members from pydantic.BaseModel are omitted.]"
  constructor_signature: 'def __init__(self, *, memories: list[google.adk.memory.memory_entry.MemoryEntry] = list()):'
  properties:
  - signature: 'memories: list[google.adk.memory.memory_entry.MemoryEntry]'
  inherited_properties:
    BaseModel:
    - signature: 'model_config: pydantic.ConfigDict'
  omitted_inherited_members_from:
  - pydantic.BaseModel
- rank: 46
  id: google.adk.memory.memory_entry.MemoryEntry
  name: MemoryEntry
  file_path: google/adk/memory/memory_entry.py
  type: CLASS
  group: Seed
  usage_score: 2
  docstring: 'Represent one memory entry.


    [Note: Inherited members from pydantic.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, content: google.genai.types.Content, custom_metadata: dict[str, typing.Any] = dict(), id: typing.Optional[str] = None, author: typing.Optional[str] = None, timestamp: typing.Optional[str] = None):'
  properties:
  - signature: 'content: google.genai.types.Content'
    docstring: The main content of the memory.
  - signature: 'custom_metadata: dict[str, typing.Any]'
    docstring: Optional custom metadata associated with the memory.
  - signature: 'id: typing.Optional[str]'
    docstring: The unique identifier of the memory.
  - signature: 'author: typing.Optional[str]'
    docstring: The author of the memory.
  - signature: 'timestamp: typing.Optional[str]'
    docstring: 'The timestamp when the original content of this memory happened.


      This string will be forwarded to LLM. Preferred format is ISO 8601 format.'
  inherited_properties:
    BaseModel:
    - signature: 'model_config: pydantic.ConfigDict'
  omitted_inherited_members_from:
  - pydantic.BaseModel
- rank: 47
  id: google.adk.auth.auth_tool.AuthConfig
  name: AuthConfig
  file_path: google/adk/auth/auth_tool.py
  type: CLASS
  group: Seed
  usage_score: 2
  docstring: 'The auth config sent by tool asking client to collect auth credentials and


    adk and client will help to fill in the response


    [Note: Inherited members from pydantic.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self):'
  methods:
  - signature: 'def get_credential_key(self):'
    docstring: 'Builds a hash key based on auth_scheme and raw_auth_credential used to

      save / load this credential to / from a credentials service.'
  properties:
  - signature: 'auth_scheme: google.adk.auth.auth_schemes.AuthScheme'
    docstring: The auth scheme used to collect credentials
  - signature: 'raw_auth_credential: typing.Optional[google.adk.auth.auth_credential.AuthCredential]'
    docstring: 'The raw auth credential used to collect credentials. The raw auth

      credentials are used in some auth scheme that needs to exchange auth

      credentials. e.g. OAuth2 and OIDC. For other auth scheme, it could be None.'
  - signature: 'exchanged_auth_credential: typing.Optional[google.adk.auth.auth_credential.AuthCredential]'
    docstring: 'The exchanged auth credential used to collect credentials. adk and client

      will work together to fill it. For those auth scheme that doesn''t need to

      exchange auth credentials, e.g. API key, service account etc. It''s filled by

      client directly. For those auth scheme that need to exchange auth credentials,

      e.g. OAuth2 and OIDC, it''s first filled by adk. If the raw credentials

      passed by tool only has client id and client credential, adk will help to

      generate the corresponding authorization uri and state and store the processed

      credential in this field. If the raw credentials passed by tool already has

      authorization uri, state, etc. then it''s copied to this field. Client will use

      this field to guide the user through the OAuth2 flow and fill auth response in

      this field'
  - signature: 'credential_key: typing.Optional[str]'
    docstring: 'A user specified key used to load and save this credential in a credential

      service.'
  inherited_properties:
    BaseModelWithConfig:
    - signature: 'model_config: pydantic.ConfigDict'
      docstring: The pydantic model config.
    BaseModel:
    - signature: 'model_config: pydantic.ConfigDict'
  omitted_inherited_members_from:
  - pydantic.BaseModel
- rank: 48
  id: google.adk.agents.context_cache_config.ContextCacheConfig
  name: ContextCacheConfig
  file_path: google/adk/agents/context_cache_config.py
  type: CLASS
  group: Seed
  usage_score: 2
  docstring: "Configuration for context caching across all agents in an app.\n\nThis configuration enables and controls context caching behavior for\nall LLM agents in an app. When this config is present on an app, context\ncaching is enabled for all agents. When absent (None), context caching\nis disabled.\n\nContext caching can significantly reduce costs and improve response times\nby reusing previously processed context across multiple requests.\n\nAttributes:\n    cache_intervals: Maximum number of invocations to reuse the same cache before refreshing it\n    ttl_seconds: Time-to-live for cache in seconds\n    min_tokens: Minimum tokens required to enable caching\n\n[Note: Inherited members from pydantic.BaseModel are omitted.]"
  constructor_signature: 'def __init__(self, *, cache_intervals: int = 10, ttl_seconds: int = 1800, min_tokens: int = 0):'
  methods:
  - signature: 'def ttl_string(self) -> str:'
    docstring: Get TTL as string format for cache creation.
  properties:
  - signature: 'model_config: pydantic.ConfigDict'
  - signature: 'cache_intervals: int'
  - signature: 'ttl_seconds: int'
  - signature: 'min_tokens: int'
  inherited_properties:
    BaseModel:
    - signature: 'model_config: pydantic.ConfigDict'
  omitted_inherited_members_from:
  - pydantic.BaseModel
- rank: 49
  id: google.adk.utils.cache_performance_analyzer.CachePerformanceAnalyzer
  name: CachePerformanceAnalyzer
  file_path: google/adk/utils/cache_performance_analyzer.py
  type: CLASS
  group: Seed
  usage_score: 2
  docstring: Analyzes cache performance through event history.
  constructor_signature: 'def __init__(self, session_service: google.adk.sessions.base_session_service.BaseSessionService):'
  methods:
  - signature: 'def analyze_agent_cache_performance(self, session_id: str, user_id: str, app_name: str, agent_name: str) -> typing.Dict[str, typing.Any]:'
    docstring: "Analyze cache performance for agent.\n\nArgs:\n    session_id: Session to analyze\n    user_id: User ID for session lookup\n    app_name: App name for session lookup\n    agent_name: Agent to analyze\n\nReturns:\n    Performance analysis dictionary containing:\n    - status: \"active\" if cache data found, \"no_cache_data\" if none\n    - requests_with_cache: Number of requests that used caching\n    - avg_invocations_used: Average number of invocations each cache was used\n    - latest_cache: Resource name of most recent cache used\n    - cache_refreshes: Number of unique cache instances created\n    - total_invocations: Total number of invocations across all caches\n    - total_prompt_tokens: Total prompt tokens across all requests\n    - total_cached_tokens: Total cached content tokens across all requests\n    - cache_hit_ratio_percent: Percentage of tokens served from cache\n    - cache_utilization_ratio_percent: Percentage of requests with cache hits\n    - avg_cached_tokens_per_request:\
      \ Average cached tokens per request\n    - total_requests: Total number of requests processed\n    - requests_with_cache_hits: Number of requests that had cache hits"
- rank: 50
  id: google.adk.utils.variant_utils.get_google_llm_variant
  name: get_google_llm_variant
  file_path: google/adk/utils/variant_utils.py
  type: METHOD
  group: Seed
  usage_score: 2
  signature: 'def get_google_llm_variant() -> google.adk.utils.variant_utils.GoogleLLMVariant:'
- rank: 51
  id: google.adk.models.anthropic_llm.Claude
  name: Claude
  file_path: google/adk/models/anthropic_llm.py
  type: CLASS
  group: Seed
  usage_score: 2
  docstring: "Integration with Claude models served from Vertex AI.\n\nAttributes:\n  model: The name of the Claude model.\n  max_tokens: The maximum number of tokens to generate.\n\n[Note: Inherited members from pydantic.BaseModel are omitted.]"
  constructor_signature: 'def __init__(self, *, model: str, max_tokens: int = 8192):'
  properties:
  - signature: 'model: str'
  inherited_methods:
    AnthropicLlm:
    - signature: 'def supported_models(cls) -> list[str]:'
    - signature: 'def generate_content_async(self, llm_request: google.adk.models.llm_request.LlmRequest, stream: bool) -> typing.AsyncGenerator[google.adk.models.llm_response.LlmResponse, None]:'
    BaseLlm:
    - signature: 'def supported_models(cls) -> list[str]:'
      docstring: Returns a list of supported models in regex for LlmRegistry.
    - signature: 'def generate_content_async(self, llm_request: google.adk.models.llm_request.LlmRequest, stream: bool) -> typing.AsyncGenerator[google.adk.models.llm_response.LlmResponse, None]:'
      docstring: "Generates content for a single model turn.\n\n    This method handles Server-Sent Events (SSE) streaming for unidirectional\n    content generation. For bidirectional streaming (e.g., Gemini Live API),\n    use the `connect()` method instead.\n\n    Args:\n      llm_request: LlmRequest, the request to send to the LLM.\n      stream: bool = False, whether to enable SSE streaming mode.\n\n    Yields:\n      LlmResponse objects representing the model's response for one turn.\n\n      **Non-streaming mode (stream=False):**\n\n        Yields exactly one LlmResponse containing the complete model output\n        (text, function calls, bytes, etc.). This response has `partial=False`.\n\n      **Streaming mode (stream=True):**\n\n        Yields multiple LlmResponse objects as chunks arrive:\n\n        - Intermediate chunks: `partial=True` (progressive updates)\n        - Final chunk: `partial=False` (aggregated content from entire turn,\n          identical to stream=False output)\n\
        \        - Text consolidation: Consecutive text parts of the same type\n          (thought/non-thought) SHOULD merge without separator, but client\n          code must not rely on this - unconsolidated parts are unusual but also\n          valid\n\n      **Common content in partial chunks:**\n\n        All intermediate chunks have `partial=True` regardless of content type.\n        Common examples include:\n\n        - Text: Streams incrementally as tokens arrive\n        - Function calls: May arrive in separate chunks\n        - Bytes (e.g., images): Typically arrive as single chunk, interleaved\n          with text\n        - Thoughts: Stream incrementally when thinking_config is enabled\n\n      **Examples:**\n\n      1. Simple text streaming::\n\n           LlmResponse(partial=True,  parts=[\"The weather\"])\n           LlmResponse(partial=True,  parts=[\" in Tokyo is\"])\n           LlmResponse(partial=True,  parts=[\" sunny.\"])\n           LlmResponse(partial=False, parts=[\"\
        The weather in Tokyo is sunny.\"])\n\n      2. Text + function call::\n\n           LlmResponse(partial=True,  parts=[Text(\"Let me check...\")])\n           LlmResponse(partial=True,  parts=[FunctionCall(\"get_weather\", ...)])\n           LlmResponse(partial=False, parts=[Text(\"Let me check...\"),\n                                             FunctionCall(\"get_weather\", ...)])\n\n      3. Parallel function calls across chunks::\n\n           LlmResponse(partial=True,  parts=[Text(\"Checking both cities...\")])\n           LlmResponse(partial=True,  parts=[FunctionCall(\"get_weather\", Tokyo)])\n           LlmResponse(partial=True,  parts=[FunctionCall(\"get_weather\", NYC)])\n           LlmResponse(partial=False, parts=[Text(\"Checking both cities...\"),\n                                             FunctionCall(\"get_weather\", Tokyo),\n                                             FunctionCall(\"get_weather\", NYC)])\n\n      4. Text + bytes (image generation with gemini-2.5-flash-image)::\n\
        \n           LlmResponse(partial=True,  parts=[Text(\"Here's an image of a dog.\")])\n           LlmResponse(partial=True,  parts=[Text(\"\n\")])\n           LlmResponse(partial=True,  parts=[Blob(image/png, 1.6MB)])\n           LlmResponse(partial=True,  parts=[Text(\"It carries a bone\")])\n           LlmResponse(partial=True,  parts=[Text(\" and running around.\")])\n           LlmResponse(partial=False, parts=[Text(\"Here's an image of a dog.\n\"),\n                                             Blob(image/png, 1.6MB),\n                                             Text(\"It carries a bone and running around.\")])\n\n         Note: Consecutive text parts before and after blob merge separately.\n\n      5. Text with thinking (gemini-2.5-flash with thinking_config)::\n\n           LlmResponse(partial=True,  parts=[Thought(\"Let me analyze...\")])\n           LlmResponse(partial=True,  parts=[Thought(\"The user wants...\")])\n           LlmResponse(partial=True,  parts=[Text(\"Based\
        \ on my analysis,\")])\n           LlmResponse(partial=True,  parts=[Text(\" the answer is 42.\")])\n           LlmResponse(partial=False, parts=[Thought(\"Let me analyze...The user wants...\"),\n                                             Text(\"Based on my analysis, the answer is 42.\")])\n\n         Note: Consecutive parts of same type merge (thoughts\u2192thought, text\u2192text).\n\n      **Important:** All yielded responses represent one logical model turn.\n      The final response with `partial=False` should be identical to the\n      response that would be received with `stream=False`.\n    "
    - signature: 'def connect(self, llm_request: google.adk.models.llm_request.LlmRequest) -> google.adk.models.base_llm_connection.BaseLlmConnection:'
      docstring: "Creates a live connection to the LLM.\n\nArgs:\n  llm_request: LlmRequest, the request to send to the LLM.\n\nReturns:\n  BaseLlmConnection, the connection to the LLM."
  inherited_properties:
    AnthropicLlm:
    - signature: 'model: str'
    - signature: 'max_tokens: int'
    BaseLlm:
    - signature: 'model_config: pydantic.ConfigDict'
      docstring: The pydantic model config.
    - signature: 'model: str'
      docstring: The name of the LLM, e.g. gemini-2.5-flash or gemini-2.5-pro.
    BaseModel:
    - signature: 'model_config: pydantic.ConfigDict'
  omitted_inherited_members_from:
  - pydantic.BaseModel
- rank: 52
  id: google.adk.planners.built_in_planner.BuiltInPlanner
  name: BuiltInPlanner
  file_path: google/adk/planners/built_in_planner.py
  type: CLASS
  group: Seed
  usage_score: 2
  docstring: "The built-in planner that uses model's built-in thinking features.\n\nAttributes:\n    thinking_config: Config for model built-in thinking features. An error\n      will be returned if this field is set for models that don't support\n      thinking.\n\n[Note: Inherited members from ABC are omitted.]"
  constructor_signature: 'def __init__(self, *, thinking_config: google.genai.types.ThinkingConfig):'
  methods:
  - signature: 'def apply_thinking_config(self, llm_request: google.adk.models.llm_request.LlmRequest) -> None:'
    docstring: "Applies the thinking config to the LLM request.\n\nArgs:\n  llm_request: The LLM request to apply the thinking config to."
  - signature: 'def build_planning_instruction(self, readonly_context: google.adk.agents.readonly_context.ReadonlyContext, llm_request: google.adk.models.llm_request.LlmRequest) -> typing.Optional[str]:'
  - signature: 'def process_planning_response(self, callback_context: google.adk.agents.callback_context.CallbackContext, response_parts: typing.List[google.genai.types.Part]) -> typing.Optional[typing.List[google.genai.types.Part]]:'
  properties:
  - signature: 'thinking_config: google.genai.types.ThinkingConfig'
    docstring: 'Config for model built-in thinking features. An error will be returned if this

      field is set for models that don''t support thinking.'
  inherited_methods:
    BasePlanner:
    - signature: 'def build_planning_instruction(self, readonly_context: google.adk.agents.readonly_context.ReadonlyContext, llm_request: google.adk.models.llm_request.LlmRequest) -> typing.Optional[str]:'
      docstring: "Builds the system instruction to be appended to the LLM request for planning.\n\nArgs:\n    readonly_context: The readonly context of the invocation.\n    llm_request: The LLM request. Readonly.\n\nReturns:\n    The planning system instruction, or None if no instruction is needed."
    - signature: 'def process_planning_response(self, callback_context: google.adk.agents.callback_context.CallbackContext, response_parts: typing.List[google.genai.types.Part]) -> typing.Optional[typing.List[google.genai.types.Part]]:'
      docstring: "Processes the LLM response for planning.\n\nArgs:\n    callback_context: The callback context of the invocation.\n    response_parts: The LLM response parts. Readonly.\n\nReturns:\n    The processed response parts, or None if no processing is needed."
  omitted_inherited_members_from:
  - ABC
- rank: 53
  id: google.adk
  name: adk
  file_path: google/adk/__init__.py
  type: MODULE
  group: Orphan
  usage_score: 0
- rank: 54
  id: google.adk.a2a
  name: a2a
  file_path: google/adk/a2a/__init__.py
  type: MODULE
  group: Orphan
  usage_score: 0
- rank: 55
  id: google.adk.a2a.converters
  name: converters
  file_path: google/adk/a2a/converters/__init__.py
  type: MODULE
  group: Orphan
  usage_score: 0
- rank: 56
  id: google.adk.a2a.converters.event_converter
  name: event_converter
  file_path: google/adk/a2a/converters/event_converter.py
  type: MODULE
  group: Orphan
  usage_score: 0
  methods:
  - signature: 'def convert_a2a_task_to_event(a2a_task: a2a.types.Task, author: typing.Optional[str], invocation_context: typing.Optional[google.adk.agents.invocation_context.InvocationContext], part_converter: google.adk.a2a.converters.part_converter.A2APartToGenAIPartConverter) -> google.adk.events.event.Event:'
    docstring: "Converts an A2A task to an ADK event.\n\nArgs:\n  a2a_task: The A2A task to convert. Must not be None.\n  author: The author of the event. Defaults to \"a2a agent\" if not provided.\n  invocation_context: The invocation context containing session information.\n    If provided, the branch will be set from the context.\n  part_converter: The function to convert A2A part to GenAI part.\n\nReturns:\n  An ADK Event object representing the converted task.\n\nRaises:\n  ValueError: If a2a_task is None.\n  RuntimeError: If conversion of the underlying message fails."
  - signature: 'def convert_a2a_message_to_event(a2a_message: a2a.types.Message, author: typing.Optional[str], invocation_context: typing.Optional[google.adk.agents.invocation_context.InvocationContext], part_converter: google.adk.a2a.converters.part_converter.A2APartToGenAIPartConverter) -> google.adk.events.event.Event:'
    docstring: "Converts an A2A message to an ADK event.\n\nArgs:\n  a2a_message: The A2A message to convert. Must not be None.\n  author: The author of the event. Defaults to \"a2a agent\" if not provided.\n  invocation_context: The invocation context containing session information.\n    If provided, the branch will be set from the context.\n  part_converter: The function to convert A2A part to GenAI part.\n\nReturns:\n  An ADK Event object with converted content and long-running tool metadata.\n\nRaises:\n  ValueError: If a2a_message is None.\n  RuntimeError: If conversion of message parts fails."
  - signature: 'def convert_event_to_a2a_message(event: google.adk.events.event.Event, invocation_context: google.adk.agents.invocation_context.InvocationContext, role: a2a.types.Role, part_converter: google.adk.a2a.converters.part_converter.GenAIPartToA2APartConverter) -> typing.Optional[a2a.types.Message]:'
    docstring: "Converts an ADK event to an A2A message.\n\nArgs:\n  event: The ADK event to convert.\n  invocation_context: The invocation context.\n  role: The role of the message.\n  part_converter: The function to convert GenAI part to A2A part.\n\nReturns:\n  An A2A Message if the event has content, None otherwise.\n\nRaises:\n  ValueError: If required parameters are invalid."
  - signature: 'def convert_event_to_a2a_events(event: google.adk.events.event.Event, invocation_context: google.adk.agents.invocation_context.InvocationContext, task_id: typing.Optional[str], context_id: typing.Optional[str], part_converter: google.adk.a2a.converters.part_converter.GenAIPartToA2APartConverter) -> typing.List[a2a.server.events.Event]:'
    docstring: "Converts a GenAI event to a list of A2A events.\n\nArgs:\n  event: The ADK event to convert.\n  invocation_context: The invocation context.\n  task_id: Optional task ID to use for generated events.\n  context_id: Optional Context ID to use for generated events.\n  part_converter: The function to convert GenAI part to A2A part.\n\nReturns:\n  A list of A2A events representing the converted ADK event.\n\nRaises:\n  ValueError: If required parameters are invalid."
- rank: 57
  id: google.adk.a2a.converters.event_converter.convert_a2a_message_to_event
  name: convert_a2a_message_to_event
  file_path: google/adk/a2a/converters/event_converter.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Converts an A2A message to an ADK event.\n\nArgs:\n  a2a_message: The A2A message to convert. Must not be None.\n  author: The author of the event. Defaults to \"a2a agent\" if not provided.\n  invocation_context: The invocation context containing session information.\n    If provided, the branch will be set from the context.\n  part_converter: The function to convert A2A part to GenAI part.\n\nReturns:\n  An ADK Event object with converted content and long-running tool metadata.\n\nRaises:\n  ValueError: If a2a_message is None.\n  RuntimeError: If conversion of message parts fails."
  signature: 'def convert_a2a_message_to_event(a2a_message: a2a.types.Message, author: typing.Optional[str], invocation_context: typing.Optional[google.adk.agents.invocation_context.InvocationContext], part_converter: google.adk.a2a.converters.part_converter.A2APartToGenAIPartConverter) -> google.adk.events.event.Event:'
- rank: 58
  id: google.adk.a2a.converters.event_converter.convert_a2a_task_to_event
  name: convert_a2a_task_to_event
  file_path: google/adk/a2a/converters/event_converter.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Converts an A2A task to an ADK event.\n\nArgs:\n  a2a_task: The A2A task to convert. Must not be None.\n  author: The author of the event. Defaults to \"a2a agent\" if not provided.\n  invocation_context: The invocation context containing session information.\n    If provided, the branch will be set from the context.\n  part_converter: The function to convert A2A part to GenAI part.\n\nReturns:\n  An ADK Event object representing the converted task.\n\nRaises:\n  ValueError: If a2a_task is None.\n  RuntimeError: If conversion of the underlying message fails."
  signature: 'def convert_a2a_task_to_event(a2a_task: a2a.types.Task, author: typing.Optional[str], invocation_context: typing.Optional[google.adk.agents.invocation_context.InvocationContext], part_converter: google.adk.a2a.converters.part_converter.A2APartToGenAIPartConverter) -> google.adk.events.event.Event:'
- rank: 59
  id: google.adk.a2a.converters.event_converter.convert_event_to_a2a_events
  name: convert_event_to_a2a_events
  file_path: google/adk/a2a/converters/event_converter.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Converts a GenAI event to a list of A2A events.\n\nArgs:\n  event: The ADK event to convert.\n  invocation_context: The invocation context.\n  task_id: Optional task ID to use for generated events.\n  context_id: Optional Context ID to use for generated events.\n  part_converter: The function to convert GenAI part to A2A part.\n\nReturns:\n  A list of A2A events representing the converted ADK event.\n\nRaises:\n  ValueError: If required parameters are invalid."
  signature: 'def convert_event_to_a2a_events(event: google.adk.events.event.Event, invocation_context: google.adk.agents.invocation_context.InvocationContext, task_id: typing.Optional[str], context_id: typing.Optional[str], part_converter: google.adk.a2a.converters.part_converter.GenAIPartToA2APartConverter) -> typing.List[a2a.server.events.Event]:'
- rank: 60
  id: google.adk.a2a.converters.event_converter.convert_event_to_a2a_message
  name: convert_event_to_a2a_message
  file_path: google/adk/a2a/converters/event_converter.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Converts an ADK event to an A2A message.\n\nArgs:\n  event: The ADK event to convert.\n  invocation_context: The invocation context.\n  role: The role of the message.\n  part_converter: The function to convert GenAI part to A2A part.\n\nReturns:\n  An A2A Message if the event has content, None otherwise.\n\nRaises:\n  ValueError: If required parameters are invalid."
  signature: 'def convert_event_to_a2a_message(event: google.adk.events.event.Event, invocation_context: google.adk.agents.invocation_context.InvocationContext, role: a2a.types.Role, part_converter: google.adk.a2a.converters.part_converter.GenAIPartToA2APartConverter) -> typing.Optional[a2a.types.Message]:'
- rank: 61
  id: google.adk.a2a.converters.part_converter
  name: part_converter
  file_path: google/adk/a2a/converters/part_converter.py
  type: MODULE
  group: Orphan
  usage_score: 0
  docstring: module containing utilities for conversion between A2A Part and Google GenAI Part
  methods:
  - signature: 'def convert_a2a_part_to_genai_part(a2a_part: a2a.types.Part) -> typing.Optional[google.genai.types.Part]:'
    docstring: Convert an A2A Part to a Google GenAI Part.
  - signature: 'def convert_genai_part_to_a2a_part(part: google.genai.types.Part) -> typing.Optional[a2a.types.Part]:'
    docstring: Convert a Google GenAI Part to an A2A Part.
- rank: 62
  id: google.adk.a2a.converters.part_converter.convert_a2a_part_to_genai_part
  name: convert_a2a_part_to_genai_part
  file_path: google/adk/a2a/converters/part_converter.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: Convert an A2A Part to a Google GenAI Part.
  signature: 'def convert_a2a_part_to_genai_part(a2a_part: a2a.types.Part) -> typing.Optional[google.genai.types.Part]:'
- rank: 63
  id: google.adk.a2a.converters.part_converter.convert_genai_part_to_a2a_part
  name: convert_genai_part_to_a2a_part
  file_path: google/adk/a2a/converters/part_converter.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: Convert a Google GenAI Part to an A2A Part.
  signature: 'def convert_genai_part_to_a2a_part(part: google.genai.types.Part) -> typing.Optional[a2a.types.Part]:'
- rank: 64
  id: google.adk.a2a.converters.request_converter
  name: request_converter
  file_path: google/adk/a2a/converters/request_converter.py
  type: MODULE
  group: Orphan
  usage_score: 0
  methods:
  - signature: 'def convert_a2a_request_to_agent_run_request(request: a2a.server.agent_execution.RequestContext, part_converter: google.adk.a2a.converters.part_converter.A2APartToGenAIPartConverter) -> google.adk.a2a.converters.request_converter.AgentRunRequest:'
    docstring: "Converts an A2A RequestContext to an AgentRunRequest model.\n\nArgs:\n  request: The incoming request context from the A2A server.\n  part_converter: A function to convert A2A content parts to GenAI parts.\n\nReturns:\n  A AgentRunRequest object ready to be used as arguments for the ADK runner.\n\nRaises:\n  ValueError: If the request message is None."
- rank: 65
  id: google.adk.a2a.converters.request_converter.AgentRunRequest
  name: AgentRunRequest
  file_path: google/adk/a2a/converters/request_converter.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Data model for arguments passed to the ADK runner.


    [Note: Inherited members from pydantic.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, user_id: typing.Optional[str] = None, session_id: typing.Optional[str] = None, new_message: typing.Optional[google.genai.types.Content] = None, state_delta: typing.Optional[dict[str, typing.Any]] = None, run_config: typing.Optional[google.adk.runners.RunConfig] = None):'
  properties:
  - signature: 'user_id: typing.Optional[str]'
  - signature: 'session_id: typing.Optional[str]'
  - signature: 'invocation_id: typing.Optional[str]'
  - signature: 'new_message: typing.Optional[google.genai.types.Content]'
  - signature: 'state_delta: typing.Optional[dict[str, typing.Any]]'
  - signature: 'run_config: typing.Optional[google.adk.runners.RunConfig]'
  inherited_properties:
    BaseModel:
    - signature: 'model_config: pydantic.ConfigDict'
  omitted_inherited_members_from:
  - pydantic.BaseModel
- rank: 66
  id: google.adk.a2a.converters.request_converter.convert_a2a_request_to_agent_run_request
  name: convert_a2a_request_to_agent_run_request
  file_path: google/adk/a2a/converters/request_converter.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Converts an A2A RequestContext to an AgentRunRequest model.\n\nArgs:\n  request: The incoming request context from the A2A server.\n  part_converter: A function to convert A2A content parts to GenAI parts.\n\nReturns:\n  A AgentRunRequest object ready to be used as arguments for the ADK runner.\n\nRaises:\n  ValueError: If the request message is None."
  signature: 'def convert_a2a_request_to_agent_run_request(request: a2a.server.agent_execution.RequestContext, part_converter: google.adk.a2a.converters.part_converter.A2APartToGenAIPartConverter) -> google.adk.a2a.converters.request_converter.AgentRunRequest:'
- rank: 67
  id: google.adk.a2a.converters.utils
  name: utils
  file_path: google/adk/a2a/converters/utils.py
  type: MODULE
  group: Orphan
  usage_score: 0
- rank: 68
  id: google.adk.a2a.executor
  name: executor
  file_path: google/adk/a2a/executor/__init__.py
  type: MODULE
  group: Orphan
  usage_score: 0
- rank: 69
  id: google.adk.a2a.executor.a2a_agent_executor
  name: a2a_agent_executor
  file_path: google/adk/a2a/executor/a2a_agent_executor.py
  type: MODULE
  group: Orphan
  usage_score: 0
- rank: 70
  id: google.adk.a2a.executor.a2a_agent_executor.A2aAgentExecutor
  name: A2aAgentExecutor
  file_path: google/adk/a2a/executor/a2a_agent_executor.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'An AgentExecutor that runs an ADK Agent against an A2A request and


    publishes updates to an event queue.


    [Note: Inherited members from AgentExecutor are omitted.]'
  constructor_signature: 'def __init__(self, *, runner: Runner | Callable[..., Runner | Awaitable[Runner]], config: typing.Optional[google.adk.a2a.executor.a2a_agent_executor.A2aAgentExecutorConfig]=None):'
  methods:
  - signature: 'def cancel(self, context: a2a.server.agent_execution.context.RequestContext, event_queue: a2a.server.events.event_queue.EventQueue):'
    docstring: Cancel the execution.
  - signature: 'def execute(self, context: a2a.server.agent_execution.context.RequestContext, event_queue: a2a.server.events.event_queue.EventQueue):'
    docstring: 'Executes an A2A request and publishes updates to the event queue

      specified. It runs as following:

      * Takes the input from the A2A request

      * Convert the input to ADK input content, and runs the ADK agent

      * Collects output events of the underlying ADK Agent

      * Converts the ADK output events into A2A task updates

      * Publishes the updates back to A2A server via event queue'
  omitted_inherited_members_from:
  - AgentExecutor
- rank: 71
  id: google.adk.a2a.executor.a2a_agent_executor.A2aAgentExecutor.__init__
  name: __init__
  file_path: google/adk/a2a/executor/a2a_agent_executor.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def __init__(self, *, runner: Runner | Callable[..., Runner | Awaitable[Runner]], config: typing.Optional[google.adk.a2a.executor.a2a_agent_executor.A2aAgentExecutorConfig]=None):'
- rank: 72
  id: google.adk.a2a.executor.a2a_agent_executor.A2aAgentExecutor.cancel
  name: cancel
  file_path: google/adk/a2a/executor/a2a_agent_executor.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: Cancel the execution.
  signature: 'def cancel(self, context: a2a.server.agent_execution.context.RequestContext, event_queue: a2a.server.events.event_queue.EventQueue):'
- rank: 73
  id: google.adk.a2a.executor.a2a_agent_executor.A2aAgentExecutor.execute
  name: execute
  file_path: google/adk/a2a/executor/a2a_agent_executor.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: 'Executes an A2A request and publishes updates to the event queue

    specified. It runs as following:

    * Takes the input from the A2A request

    * Convert the input to ADK input content, and runs the ADK agent

    * Collects output events of the underlying ADK Agent

    * Converts the ADK output events into A2A task updates

    * Publishes the updates back to A2A server via event queue'
  signature: 'def execute(self, context: a2a.server.agent_execution.context.RequestContext, event_queue: a2a.server.events.event_queue.EventQueue):'
- rank: 74
  id: google.adk.a2a.executor.a2a_agent_executor.A2aAgentExecutorConfig
  name: A2aAgentExecutorConfig
  file_path: google/adk/a2a/executor/a2a_agent_executor.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Configuration for the A2aAgentExecutor.


    [Note: Inherited members from pydantic.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, a2a_part_converter: google.adk.a2a.converters.part_converter.A2APartToGenAIPartConverter = convert_a2a_part_to_genai_part, gen_ai_part_converter: google.adk.a2a.converters.part_converter.GenAIPartToA2APartConverter = convert_genai_part_to_a2a_part, request_converter: google.adk.a2a.converters.request_converter.A2ARequestToAgentRunRequestConverter = convert_a2a_request_to_agent_run_request, event_converter: google.adk.a2a.converters.event_converter.AdkEventToA2AEventsConverter = convert_event_to_a2a_events):'
  properties:
  - signature: 'a2a_part_converter: google.adk.a2a.converters.part_converter.A2APartToGenAIPartConverter'
  - signature: 'gen_ai_part_converter: google.adk.a2a.converters.part_converter.GenAIPartToA2APartConverter'
  - signature: 'request_converter: google.adk.a2a.converters.request_converter.A2ARequestToAgentRunRequestConverter'
  - signature: 'event_converter: google.adk.a2a.converters.event_converter.AdkEventToA2AEventsConverter'
  inherited_properties:
    BaseModel:
    - signature: 'model_config: pydantic.ConfigDict'
  omitted_inherited_members_from:
  - pydantic.BaseModel
- rank: 75
  id: google.adk.a2a.executor.task_result_aggregator
  name: task_result_aggregator
  file_path: google/adk/a2a/executor/task_result_aggregator.py
  type: MODULE
  group: Orphan
  usage_score: 0
- rank: 76
  id: google.adk.a2a.executor.task_result_aggregator.TaskResultAggregator
  name: TaskResultAggregator
  file_path: google/adk/a2a/executor/task_result_aggregator.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: Aggregates the task status updates and provides the final task state.
  constructor_signature: 'def __init__(self):'
  methods:
  - signature: 'def process_event(self, event: a2a.server.events.Event):'
    docstring: 'Process an event from the agent run and detect signals about the task status.

      Priority of task state:

      - failed

      - auth_required

      - input_required

      - working'
  - signature: 'def task_state(self) -> a2a.types.TaskState:'
  - signature: 'def task_status_message(self) -> Message | None:'
- rank: 77
  id: google.adk.a2a.executor.task_result_aggregator.TaskResultAggregator.process_event
  name: process_event
  file_path: google/adk/a2a/executor/task_result_aggregator.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: 'Process an event from the agent run and detect signals about the task status.

    Priority of task state:

    - failed

    - auth_required

    - input_required

    - working'
  signature: 'def process_event(self, event: a2a.server.events.Event):'
- rank: 78
  id: google.adk.a2a.experimental
  name: experimental
  file_path: google/adk/a2a/experimental.py
  type: MODULE
  group: Orphan
  usage_score: 0
  docstring: A2A specific experimental decorator with custom warning message.
- rank: 79
  id: google.adk.a2a.logs
  name: logs
  file_path: google/adk/a2a/logs/__init__.py
  type: MODULE
  group: Orphan
  usage_score: 0
- rank: 80
  id: google.adk.a2a.logs.log_utils
  name: log_utils
  file_path: google/adk/a2a/logs/log_utils.py
  type: MODULE
  group: Orphan
  usage_score: 0
  docstring: Utility functions for structured A2A request and response logging.
  methods:
  - signature: 'def build_message_part_log(part: a2a.types.Part) -> str:'
    docstring: "Builds a log representation of an A2A message part.\n\nArgs:\n  part: The A2A message part to log.\n\nReturns:\n  A string representation of the part."
  - signature: 'def build_a2a_request_log(req: a2a.types.Message) -> str:'
    docstring: "Builds a structured log representation of an A2A request.\n\nArgs:\n  req: The A2A SendMessageRequest to log.\n\nReturns:\n  A formatted string representation of the request."
  - signature: 'def build_a2a_response_log(resp: A2AClientEvent | A2AMessage) -> str:'
    docstring: "Builds a structured log representation of an A2A response.\n\nArgs:\n  resp: The A2A SendMessage Response to log.\n\nReturns:\n  A formatted string representation of the response."
- rank: 81
  id: google.adk.a2a.logs.log_utils.build_a2a_request_log
  name: build_a2a_request_log
  file_path: google/adk/a2a/logs/log_utils.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Builds a structured log representation of an A2A request.\n\nArgs:\n  req: The A2A SendMessageRequest to log.\n\nReturns:\n  A formatted string representation of the request."
  signature: 'def build_a2a_request_log(req: a2a.types.Message) -> str:'
- rank: 82
  id: google.adk.a2a.logs.log_utils.build_a2a_response_log
  name: build_a2a_response_log
  file_path: google/adk/a2a/logs/log_utils.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Builds a structured log representation of an A2A response.\n\nArgs:\n  resp: The A2A SendMessage Response to log.\n\nReturns:\n  A formatted string representation of the response."
  signature: 'def build_a2a_response_log(resp: A2AClientEvent | A2AMessage) -> str:'
- rank: 83
  id: google.adk.a2a.logs.log_utils.build_message_part_log
  name: build_message_part_log
  file_path: google/adk/a2a/logs/log_utils.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Builds a log representation of an A2A message part.\n\nArgs:\n  part: The A2A message part to log.\n\nReturns:\n  A string representation of the part."
  signature: 'def build_message_part_log(part: a2a.types.Part) -> str:'
- rank: 84
  id: google.adk.a2a.utils
  name: utils
  file_path: google/adk/a2a/utils/__init__.py
  type: MODULE
  group: Orphan
  usage_score: 0
- rank: 85
  id: google.adk.a2a.utils.agent_card_builder
  name: agent_card_builder
  file_path: google/adk/a2a/utils/agent_card_builder.py
  type: MODULE
  group: Orphan
  usage_score: 0
- rank: 86
  id: google.adk.a2a.utils.agent_card_builder.AgentCardBuilder
  name: AgentCardBuilder
  file_path: google/adk/a2a/utils/agent_card_builder.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Builder class for creating agent cards from ADK agents.


    This class provides functionality to convert ADK agents into A2A agent cards,

    including extracting skills, capabilities, and metadata from various agent

    types.'
  constructor_signature: 'def __init__(self, *, agent: google.adk.agents.base_agent.BaseAgent, rpc_url: typing.Optional[str]=None, capabilities: typing.Optional[a2a.types.AgentCapabilities]=None, doc_url: typing.Optional[str]=None, provider: typing.Optional[a2a.types.AgentProvider]=None, agent_version: typing.Optional[str]=None, security_schemes: typing.Optional[typing.Dict[str, a2a.types.SecurityScheme]]=None):'
  methods:
  - signature: 'def build(self) -> a2a.types.AgentCard:'
    docstring: Build and return the complete agent card.
- rank: 87
  id: google.adk.a2a.utils.agent_card_builder.AgentCardBuilder.__init__
  name: __init__
  file_path: google/adk/a2a/utils/agent_card_builder.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def __init__(self, *, agent: google.adk.agents.base_agent.BaseAgent, rpc_url: typing.Optional[str]=None, capabilities: typing.Optional[a2a.types.AgentCapabilities]=None, doc_url: typing.Optional[str]=None, provider: typing.Optional[a2a.types.AgentProvider]=None, agent_version: typing.Optional[str]=None, security_schemes: typing.Optional[typing.Dict[str, a2a.types.SecurityScheme]]=None):'
- rank: 88
  id: google.adk.a2a.utils.agent_card_builder.AgentCardBuilder.build
  name: build
  file_path: google/adk/a2a/utils/agent_card_builder.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: Build and return the complete agent card.
  signature: 'def build(self) -> a2a.types.AgentCard:'
- rank: 89
  id: google.adk.a2a.utils.agent_to_a2a
  name: agent_to_a2a
  file_path: google/adk/a2a/utils/agent_to_a2a.py
  type: MODULE
  group: Orphan
  usage_score: 0
  methods:
  - signature: 'def to_a2a(agent: google.adk.agents.base_agent.BaseAgent, *, host: str=''localhost'', port: int=8000, protocol: str=''http'', agent_card: typing.Optional[typing.Union[a2a.types.AgentCard, str]]=None, runner: typing.Optional[google.adk.runners.Runner]=None) -> starlette.applications.Starlette:'
    docstring: "Convert an ADK agent to a A2A Starlette application.\n\nArgs:\n    agent: The ADK agent to convert\n    host: The host for the A2A RPC URL (default: \"localhost\")\n    port: The port for the A2A RPC URL (default: 8000)\n    protocol: The protocol for the A2A RPC URL (default: \"http\")\n    agent_card: Optional pre-built AgentCard object or path to agent card\n                JSON. If not provided, will be built automatically from the\n                agent.\n    runner: Optional pre-built Runner object. If not provided, a default\n            runner will be created using in-memory services.\n\nReturns:\n    A Starlette application that can be run with uvicorn\n\nExample:\n    agent = MyAgent()\n    app = to_a2a(agent, host=\"localhost\", port=8000, protocol=\"http\")\n    # Then run with: uvicorn module:app --host localhost --port 8000\n\n    # Or with custom agent card:\n    app = to_a2a(agent, agent_card=my_custom_agent_card)"
  - signature: 'def create_runner() -> google.adk.runners.Runner:'
    docstring: Create a runner for the agent.
  - signature: 'def setup_a2a():'
- rank: 90
  id: google.adk.a2a.utils.agent_to_a2a.create_runner
  name: create_runner
  file_path: google/adk/a2a/utils/agent_to_a2a.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: Create a runner for the agent.
  signature: 'def create_runner() -> google.adk.runners.Runner:'
- rank: 91
  id: google.adk.a2a.utils.agent_to_a2a.setup_a2a
  name: setup_a2a
  file_path: google/adk/a2a/utils/agent_to_a2a.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def setup_a2a():'
- rank: 92
  id: google.adk.a2a.utils.agent_to_a2a.to_a2a
  name: to_a2a
  file_path: google/adk/a2a/utils/agent_to_a2a.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Convert an ADK agent to a A2A Starlette application.\n\nArgs:\n    agent: The ADK agent to convert\n    host: The host for the A2A RPC URL (default: \"localhost\")\n    port: The port for the A2A RPC URL (default: 8000)\n    protocol: The protocol for the A2A RPC URL (default: \"http\")\n    agent_card: Optional pre-built AgentCard object or path to agent card\n                JSON. If not provided, will be built automatically from the\n                agent.\n    runner: Optional pre-built Runner object. If not provided, a default\n            runner will be created using in-memory services.\n\nReturns:\n    A Starlette application that can be run with uvicorn\n\nExample:\n    agent = MyAgent()\n    app = to_a2a(agent, host=\"localhost\", port=8000, protocol=\"http\")\n    # Then run with: uvicorn module:app --host localhost --port 8000\n\n    # Or with custom agent card:\n    app = to_a2a(agent, agent_card=my_custom_agent_card)"
  signature: 'def to_a2a(agent: google.adk.agents.base_agent.BaseAgent, *, host: str=''localhost'', port: int=8000, protocol: str=''http'', agent_card: typing.Optional[typing.Union[a2a.types.AgentCard, str]]=None, runner: typing.Optional[google.adk.runners.Runner]=None) -> starlette.applications.Starlette:'
- rank: 93
  id: google.adk.agents
  name: agents
  file_path: google/adk/agents/__init__.py
  type: MODULE
  group: Orphan
  usage_score: 0
- rank: 94
  id: google.adk.agents.active_streaming_tool
  name: active_streaming_tool
  file_path: google/adk/agents/active_streaming_tool.py
  type: MODULE
  group: Orphan
  usage_score: 0
- rank: 95
  id: google.adk.agents.active_streaming_tool.ActiveStreamingTool
  name: ActiveStreamingTool
  file_path: google/adk/agents/active_streaming_tool.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Manages streaming tool related resources during invocation.


    [Note: Inherited members from pydantic.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, task: typing.Optional[asyncio.Task] = None, stream: typing.Optional[google.adk.agents.live_request_queue.LiveRequestQueue] = None):'
  properties:
  - signature: 'model_config: pydantic.ConfigDict'
    docstring: The pydantic model config.
  - signature: 'task: typing.Optional[asyncio.Task]'
    docstring: The active task of this streaming tool.
  - signature: 'stream: typing.Optional[google.adk.agents.live_request_queue.LiveRequestQueue]'
    docstring: The active (input) streams of this streaming tool.
  inherited_properties:
    BaseModel:
    - signature: 'model_config: pydantic.ConfigDict'
  omitted_inherited_members_from:
  - pydantic.BaseModel
- rank: 96
  id: google.adk.agents.agent_config
  name: agent_config
  file_path: google/adk/agents/agent_config.py
  type: MODULE
  group: Orphan
  usage_score: 0
  methods:
  - signature: 'def agent_config_discriminator(v: typing.Any) -> str:'
    docstring: Discriminator function that returns the tag name for Pydantic.
- rank: 97
  id: google.adk.agents.agent_config.AgentConfig
  name: AgentConfig
  file_path: google/adk/agents/agent_config.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: The config for the YAML schema to create an agent.
- rank: 98
  id: google.adk.agents.agent_config.agent_config_discriminator
  name: agent_config_discriminator
  file_path: google/adk/agents/agent_config.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: Discriminator function that returns the tag name for Pydantic.
  signature: 'def agent_config_discriminator(v: typing.Any) -> str:'
- rank: 99
  id: google.adk.agents.base_agent
  name: base_agent
  file_path: google/adk/agents/base_agent.py
  type: MODULE
  group: Orphan
  usage_score: 0
- rank: 100
  id: google.adk.agents.base_agent.BaseAgent
  name: BaseAgent
  file_path: google/adk/agents/base_agent.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Base class for all agents in Agent Development Kit.


    [Note: Inherited members from pydantic.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, name: str, description: str = '''', sub_agents: list[google.adk.agents.base_agent.BaseAgent] = list(), before_agent_callback: typing.Optional[google.adk.agents.base_agent.BeforeAgentCallback] = None, after_agent_callback: typing.Optional[google.adk.agents.base_agent.AfterAgentCallback] = None):'
  aliases:
  - google.adk.agents.BaseAgent
  methods:
  - signature: 'def clone(self: google.adk.agents.base_agent.SelfAgent, update: Mapping[str, Any] | None) -> google.adk.agents.base_agent.SelfAgent:'
    docstring: "Creates a copy of this agent instance.\n\nArgs:\n  update: Optional mapping of new values for the fields of the cloned agent.\n    The keys of the mapping are the names of the fields to be updated, and\n    the values are the new values for those fields.\n    For example: {\"name\": \"cloned_agent\"}\n\nReturns:\n  A new agent instance with identical configuration as the original\n  agent except for the fields specified in the update."
  - signature: 'def run_async(self, parent_context: google.adk.agents.invocation_context.InvocationContext) -> typing.AsyncGenerator[google.adk.events.event.Event, None]:'
    docstring: "Entry method to run an agent via text-based conversation.\n\nArgs:\n  parent_context: InvocationContext, the invocation context of the parent\n    agent.\n\nYields:\n  Event: the events generated by the agent."
  - signature: 'def run_live(self, parent_context: google.adk.agents.invocation_context.InvocationContext) -> typing.AsyncGenerator[google.adk.events.event.Event, None]:'
    docstring: "Entry method to run an agent via video/audio-based conversation.\n\nArgs:\n  parent_context: InvocationContext, the invocation context of the parent\n    agent.\n\nYields:\n  Event: the events generated by the agent."
  - signature: 'def _run_async_impl(self, ctx: google.adk.agents.invocation_context.InvocationContext) -> typing.AsyncGenerator[google.adk.events.event.Event, None]:'
    docstring: "Core logic to run this agent via text-based conversation.\n\nArgs:\n  ctx: InvocationContext, the invocation context for this agent.\n\nYields:\n  Event: the events generated by the agent."
  - signature: 'def root_agent(self) -> google.adk.agents.base_agent.BaseAgent:'
    docstring: Gets the root agent of this agent.
  - signature: 'def find_agent(self, name: str) -> typing.Optional[google.adk.agents.base_agent.BaseAgent]:'
    docstring: "Finds the agent with the given name in this agent and its descendants.\n\nArgs:\n  name: The name of the agent to find.\n\nReturns:\n  The agent with the matching name, or None if no such agent is found."
  - signature: 'def find_sub_agent(self, name: str) -> typing.Optional[google.adk.agents.base_agent.BaseAgent]:'
    docstring: "Finds the agent with the given name in this agent's descendants.\n\nArgs:\n  name: The name of the agent to find.\n\nReturns:\n  The agent with the matching name, or None if no such agent is found."
  - signature: 'def model_post_init(self, __context: typing.Any) -> None:'
  - signature: 'def validate_name(cls, value: str):'
  - signature: 'def validate_sub_agents_unique_names(cls, value: list[google.adk.agents.base_agent.BaseAgent]) -> list[google.adk.agents.base_agent.BaseAgent]:'
    docstring: "Validates that all sub-agents have unique names.\n\nArgs:\n  value: The list of sub-agents to validate.\n\nReturns:\n  The validated list of sub-agents."
  - signature: 'def from_config(cls: typing.Type[google.adk.agents.base_agent.SelfAgent], config: google.adk.agents.base_agent_config.BaseAgentConfig, config_abs_path: str) -> google.adk.agents.base_agent.SelfAgent:'
    docstring: "Creates an agent from a config.\n\nIf sub-classes uses a custom agent config, override `_from_config_kwargs`\nmethod to return an updated kwargs for agent constructor.\n\nArgs:\n  config: The config to create the agent from.\n  config_abs_path: The absolute path to the config file that contains the\n    agent config.\n\nReturns:\n  The created agent."
  properties:
  - signature: 'model_config: pydantic.ConfigDict'
    docstring: The pydantic model config.
  - signature: 'config_type: typing.ClassVar[type[google.adk.agents.base_agent_config.BaseAgentConfig]]'
    docstring: "The config type for this agent.\n\nSub-classes should override this to specify their own config type.\n\nExample:\n\n```\nclass MyAgentConfig(BaseAgentConfig):\n  my_field: str = ''\n\nclass MyAgent(BaseAgent):\n  config_type: ClassVar[type[BaseAgentConfig]] = MyAgentConfig\n```"
  - signature: 'name: str'
    docstring: 'The agent''s name.


      Agent name must be a Python identifier and unique within the agent tree.

      Agent name cannot be "user", since it''s reserved for end-user''s input.'
  - signature: 'description: str'
    docstring: 'Description about the agent''s capability.


      The model uses this to determine whether to delegate control to the agent.

      One-line description is enough and preferred.'
  - signature: 'parent_agent: typing.Optional[google.adk.agents.base_agent.BaseAgent]'
    docstring: 'The parent agent of this agent.


      Note that an agent can ONLY be added as sub-agent once.


      If you want to add one agent twice as sub-agent, consider to create two agent

      instances with identical config, but with different name and add them to the

      agent tree.'
  - signature: 'sub_agents: list[google.adk.agents.base_agent.BaseAgent]'
    docstring: The sub-agents of this agent.
  - signature: 'before_agent_callback: typing.Optional[google.adk.agents.base_agent.BeforeAgentCallback]'
    docstring: "Callback or list of callbacks to be invoked before the agent run.\n\nWhen a list of callbacks is provided, the callbacks will be called in the\norder they are listed until a callback does not return None.\n\nArgs:\n  callback_context: MUST be named 'callback_context' (enforced).\n\nReturns:\n  Optional[types.Content]: The content to return to the user.\n    When the content is present, the agent run will be skipped and the\n    provided content will be returned to user."
  - signature: 'after_agent_callback: typing.Optional[google.adk.agents.base_agent.AfterAgentCallback]'
    docstring: "Callback or list of callbacks to be invoked after the agent run.\n\nWhen a list of callbacks is provided, the callbacks will be called in the\norder they are listed until a callback does not return None.\n\nArgs:\n  callback_context: MUST be named 'callback_context' (enforced).\n\nReturns:\n  Optional[types.Content]: The content to return to the user.\n    When the content is present, an additional event with the provided content\n    will be appended to event history as an additional agent response."
  inherited_properties:
    BaseModel:
    - signature: 'model_config: pydantic.ConfigDict'
  omitted_inherited_members_from:
  - pydantic.BaseModel
- rank: 101
  id: google.adk.agents.base_agent.BaseAgent._run_async_impl
  name: _run_async_impl
  file_path: google/adk/agents/base_agent.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Core logic to run this agent via text-based conversation.\n\nArgs:\n  ctx: InvocationContext, the invocation context for this agent.\n\nYields:\n  Event: the events generated by the agent."
  signature: 'def _run_async_impl(self, ctx: google.adk.agents.invocation_context.InvocationContext) -> typing.AsyncGenerator[google.adk.events.event.Event, None]:'
- rank: 102
  id: google.adk.agents.base_agent.BaseAgent.canonical_after_agent_callbacks
  name: canonical_after_agent_callbacks
  file_path: google/adk/agents/base_agent.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: 'The resolved self.after_agent_callback field as a list of _SingleAgentCallback.


    This method is only for use by Agent Development Kit.'
  signature: 'def canonical_after_agent_callbacks(self) -> list[google.adk.agents.base_agent._SingleAgentCallback]:'
- rank: 103
  id: google.adk.agents.base_agent.BaseAgent.canonical_before_agent_callbacks
  name: canonical_before_agent_callbacks
  file_path: google/adk/agents/base_agent.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: 'The resolved self.before_agent_callback field as a list of _SingleAgentCallback.


    This method is only for use by Agent Development Kit.'
  signature: 'def canonical_before_agent_callbacks(self) -> list[google.adk.agents.base_agent._SingleAgentCallback]:'
- rank: 104
  id: google.adk.agents.base_agent.BaseAgent.clone
  name: clone
  file_path: google/adk/agents/base_agent.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Creates a copy of this agent instance.\n\nArgs:\n  update: Optional mapping of new values for the fields of the cloned agent.\n    The keys of the mapping are the names of the fields to be updated, and\n    the values are the new values for those fields.\n    For example: {\"name\": \"cloned_agent\"}\n\nReturns:\n  A new agent instance with identical configuration as the original\n  agent except for the fields specified in the update."
  signature: 'def clone(self: google.adk.agents.base_agent.SelfAgent, update: Mapping[str, Any] | None) -> google.adk.agents.base_agent.SelfAgent:'
- rank: 105
  id: google.adk.agents.base_agent.BaseAgent.find_agent
  name: find_agent
  file_path: google/adk/agents/base_agent.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Finds the agent with the given name in this agent and its descendants.\n\nArgs:\n  name: The name of the agent to find.\n\nReturns:\n  The agent with the matching name, or None if no such agent is found."
  signature: 'def find_agent(self, name: str) -> typing.Optional[google.adk.agents.base_agent.BaseAgent]:'
- rank: 106
  id: google.adk.agents.base_agent.BaseAgent.find_sub_agent
  name: find_sub_agent
  file_path: google/adk/agents/base_agent.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Finds the agent with the given name in this agent's descendants.\n\nArgs:\n  name: The name of the agent to find.\n\nReturns:\n  The agent with the matching name, or None if no such agent is found."
  signature: 'def find_sub_agent(self, name: str) -> typing.Optional[google.adk.agents.base_agent.BaseAgent]:'
- rank: 107
  id: google.adk.agents.base_agent.BaseAgent.from_config
  name: from_config
  file_path: google/adk/agents/base_agent.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Creates an agent from a config.\n\nIf sub-classes uses a custom agent config, override `_from_config_kwargs`\nmethod to return an updated kwargs for agent constructor.\n\nArgs:\n  config: The config to create the agent from.\n  config_abs_path: The absolute path to the config file that contains the\n    agent config.\n\nReturns:\n  The created agent."
  signature: 'def from_config(cls: typing.Type[google.adk.agents.base_agent.SelfAgent], config: google.adk.agents.base_agent_config.BaseAgentConfig, config_abs_path: str) -> google.adk.agents.base_agent.SelfAgent:'
- rank: 108
  id: google.adk.agents.base_agent.BaseAgent.root_agent
  name: root_agent
  file_path: google/adk/agents/base_agent.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: Gets the root agent of this agent.
  signature: 'def root_agent(self) -> google.adk.agents.base_agent.BaseAgent:'
- rank: 109
  id: google.adk.agents.base_agent.BaseAgent.run_async
  name: run_async
  file_path: google/adk/agents/base_agent.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Entry method to run an agent via text-based conversation.\n\nArgs:\n  parent_context: InvocationContext, the invocation context of the parent\n    agent.\n\nYields:\n  Event: the events generated by the agent."
  signature: 'def run_async(self, parent_context: google.adk.agents.invocation_context.InvocationContext) -> typing.AsyncGenerator[google.adk.events.event.Event, None]:'
- rank: 110
  id: google.adk.agents.base_agent.BaseAgent.run_live
  name: run_live
  file_path: google/adk/agents/base_agent.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Entry method to run an agent via video/audio-based conversation.\n\nArgs:\n  parent_context: InvocationContext, the invocation context of the parent\n    agent.\n\nYields:\n  Event: the events generated by the agent."
  signature: 'def run_live(self, parent_context: google.adk.agents.invocation_context.InvocationContext) -> typing.AsyncGenerator[google.adk.events.event.Event, None]:'
- rank: 111
  id: google.adk.agents.base_agent.BaseAgent.validate_name
  name: validate_name
  file_path: google/adk/agents/base_agent.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def validate_name(cls, value: str):'
- rank: 112
  id: google.adk.agents.base_agent.BaseAgent.validate_sub_agents_unique_names
  name: validate_sub_agents_unique_names
  file_path: google/adk/agents/base_agent.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Validates that all sub-agents have unique names.\n\nArgs:\n  value: The list of sub-agents to validate.\n\nReturns:\n  The validated list of sub-agents."
  signature: 'def validate_sub_agents_unique_names(cls, value: list[google.adk.agents.base_agent.BaseAgent]) -> list[google.adk.agents.base_agent.BaseAgent]:'
- rank: 113
  id: google.adk.agents.base_agent.BaseAgentState
  name: BaseAgentState
  file_path: google/adk/agents/base_agent.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Base class for all agent states.


    [Note: Inherited members from pydantic.BaseModel are omitted.]'
  properties:
  - signature: 'model_config: pydantic.ConfigDict'
  inherited_properties:
    BaseModel:
    - signature: 'model_config: pydantic.ConfigDict'
  omitted_inherited_members_from:
  - pydantic.BaseModel
- rank: 114
  id: google.adk.agents.base_agent_config
  name: base_agent_config
  file_path: google/adk/agents/base_agent_config.py
  type: MODULE
  group: Orphan
  usage_score: 0
- rank: 115
  id: google.adk.agents.base_agent_config.BaseAgentConfig
  name: BaseAgentConfig
  file_path: google/adk/agents/base_agent_config.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'The config for the YAML schema of a BaseAgent.


    Do not use this class directly. It''s the base class for all agent configs.


    [Note: Inherited members from pydantic.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, agent_class: typing.Union[typing.Literal[BaseAgent], str] = ''BaseAgent'', name: str, description: str = '''', sub_agents: typing.Optional[typing.List[google.adk.agents.common_configs.AgentRefConfig]] = None, before_agent_callbacks: typing.Optional[typing.List[google.adk.agents.common_configs.CodeConfig]] = None, after_agent_callbacks: typing.Optional[typing.List[google.adk.agents.common_configs.CodeConfig]] = None):'
  properties:
  - signature: 'model_config: pydantic.ConfigDict'
  - signature: 'agent_class: typing.Union[typing.Literal[BaseAgent], str]'
  - signature: 'name: str'
  - signature: 'description: str'
  - signature: 'sub_agents: typing.Optional[typing.List[google.adk.agents.common_configs.AgentRefConfig]]'
  - signature: 'before_agent_callbacks: typing.Optional[typing.List[google.adk.agents.common_configs.CodeConfig]]'
  - signature: 'after_agent_callbacks: typing.Optional[typing.List[google.adk.agents.common_configs.CodeConfig]]'
  inherited_properties:
    BaseModel:
    - signature: 'model_config: pydantic.ConfigDict'
  omitted_inherited_members_from:
  - pydantic.BaseModel
- rank: 116
  id: google.adk.agents.callback_context
  name: callback_context
  file_path: google/adk/agents/callback_context.py
  type: MODULE
  group: Orphan
  usage_score: 0
- rank: 117
  id: google.adk.agents.callback_context.CallbackContext
  name: CallbackContext
  file_path: google/adk/agents/callback_context.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: The context of various callbacks within an agent run.
  constructor_signature: 'def __init__(self, invocation_context: google.adk.agents.invocation_context.InvocationContext, *, event_actions: typing.Optional[google.adk.events.event_actions.EventActions]=None) -> None:'
  methods:
  - signature: 'def state(self) -> google.adk.sessions.state.State:'
    docstring: 'The delta-aware state of the current session.


      For any state change, you can mutate this object directly,

      e.g. `ctx.state[''foo''] = ''bar''`'
  - signature: 'def load_artifact(self, filename: str, version: typing.Optional[int]) -> typing.Optional[google.genai.types.Part]:'
    docstring: "Loads an artifact attached to the current session.\n\nArgs:\n  filename: The filename of the artifact.\n  version: The version of the artifact. If None, the latest version will be\n    returned.\n\nReturns:\n  The artifact."
  - signature: 'def save_artifact(self, filename: str, artifact: google.genai.types.Part, custom_metadata: typing.Optional[dict[str, typing.Any]]) -> int:'
    docstring: "Saves an artifact and records it as delta for the current session.\n\nArgs:\n  filename: The filename of the artifact.\n  artifact: The artifact to save.\n  custom_metadata: Custom metadata to associate with the artifact.\n\nReturns:\n The version of the artifact."
  - signature: 'def get_artifact_version(self, filename: str, version: typing.Optional[int]) -> typing.Optional[google.adk.artifacts.base_artifact_service.ArtifactVersion]:'
    docstring: "Gets artifact version info.\n\nArgs:\n  filename: The filename of the artifact.\n  version: The version of the artifact. If None, the latest version will be\n    returned.\n\nReturns:\n  The artifact version info."
  - signature: 'def list_artifacts(self) -> list[str]:'
    docstring: Lists the filenames of the artifacts attached to the current session.
  - signature: 'def save_credential(self, auth_config: google.adk.auth.auth_tool.AuthConfig) -> None:'
    docstring: "Saves a credential to the credential service.\n\nArgs:\n  auth_config: The authentication configuration containing the credential."
  - signature: 'def load_credential(self, auth_config: google.adk.auth.auth_tool.AuthConfig) -> typing.Optional[google.adk.auth.auth_credential.AuthCredential]:'
    docstring: "Loads a credential from the credential service.\n\nArgs:\n  auth_config: The authentication configuration for the credential.\n\nReturns:\n  The loaded credential, or None if not found."
  inherited_methods:
    ReadonlyContext:
    - signature: 'def user_content(self) -> typing.Optional[google.genai.types.Content]:'
      docstring: The user content that started this invocation. READONLY field.
    - signature: 'def invocation_id(self) -> str:'
      docstring: The current invocation id.
    - signature: 'def agent_name(self) -> str:'
      docstring: The name of the agent that is currently running.
    - signature: 'def state(self) -> types.MappingProxyType[str, typing.Any]:'
      docstring: The state of the current session. READONLY field.
    - signature: 'def session(self) -> google.adk.sessions.session.Session:'
      docstring: The current session for this invocation.
    - signature: 'def user_id(self) -> str:'
      docstring: The id of the user. READONLY field.
    - signature: 'def run_config(self) -> typing.Optional[google.adk.agents.run_config.RunConfig]:'
      docstring: The run config of the current invocation. READONLY field.
- rank: 118
  id: google.adk.agents.callback_context.CallbackContext.__init__
  name: __init__
  file_path: google/adk/agents/callback_context.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def __init__(self, invocation_context: google.adk.agents.invocation_context.InvocationContext, *, event_actions: typing.Optional[google.adk.events.event_actions.EventActions]=None) -> None:'
- rank: 119
  id: google.adk.agents.callback_context.CallbackContext.get_artifact_version
  name: get_artifact_version
  file_path: google/adk/agents/callback_context.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Gets artifact version info.\n\nArgs:\n  filename: The filename of the artifact.\n  version: The version of the artifact. If None, the latest version will be\n    returned.\n\nReturns:\n  The artifact version info."
  signature: 'def get_artifact_version(self, filename: str, version: typing.Optional[int]) -> typing.Optional[google.adk.artifacts.base_artifact_service.ArtifactVersion]:'
- rank: 120
  id: google.adk.agents.callback_context.CallbackContext.list_artifacts
  name: list_artifacts
  file_path: google/adk/agents/callback_context.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: Lists the filenames of the artifacts attached to the current session.
  signature: 'def list_artifacts(self) -> list[str]:'
- rank: 121
  id: google.adk.agents.callback_context.CallbackContext.load_artifact
  name: load_artifact
  file_path: google/adk/agents/callback_context.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Loads an artifact attached to the current session.\n\nArgs:\n  filename: The filename of the artifact.\n  version: The version of the artifact. If None, the latest version will be\n    returned.\n\nReturns:\n  The artifact."
  signature: 'def load_artifact(self, filename: str, version: typing.Optional[int]) -> typing.Optional[google.genai.types.Part]:'
- rank: 122
  id: google.adk.agents.callback_context.CallbackContext.load_credential
  name: load_credential
  file_path: google/adk/agents/callback_context.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Loads a credential from the credential service.\n\nArgs:\n  auth_config: The authentication configuration for the credential.\n\nReturns:\n  The loaded credential, or None if not found."
  signature: 'def load_credential(self, auth_config: google.adk.auth.auth_tool.AuthConfig) -> typing.Optional[google.adk.auth.auth_credential.AuthCredential]:'
- rank: 123
  id: google.adk.agents.callback_context.CallbackContext.save_artifact
  name: save_artifact
  file_path: google/adk/agents/callback_context.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Saves an artifact and records it as delta for the current session.\n\nArgs:\n  filename: The filename of the artifact.\n  artifact: The artifact to save.\n  custom_metadata: Custom metadata to associate with the artifact.\n\nReturns:\n The version of the artifact."
  signature: 'def save_artifact(self, filename: str, artifact: google.genai.types.Part, custom_metadata: typing.Optional[dict[str, typing.Any]]) -> int:'
- rank: 124
  id: google.adk.agents.callback_context.CallbackContext.save_credential
  name: save_credential
  file_path: google/adk/agents/callback_context.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Saves a credential to the credential service.\n\nArgs:\n  auth_config: The authentication configuration containing the credential."
  signature: 'def save_credential(self, auth_config: google.adk.auth.auth_tool.AuthConfig) -> None:'
- rank: 125
  id: google.adk.agents.callback_context.CallbackContext.state
  name: state
  file_path: google/adk/agents/callback_context.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: 'The delta-aware state of the current session.


    For any state change, you can mutate this object directly,

    e.g. `ctx.state[''foo''] = ''bar''`'
  signature: 'def state(self) -> google.adk.sessions.state.State:'
- rank: 126
  id: google.adk.agents.common_configs
  name: common_configs
  file_path: google/adk/agents/common_configs.py
  type: MODULE
  group: Orphan
  usage_score: 0
  docstring: Common configuration classes for agent YAML configs.
- rank: 127
  id: google.adk.agents.common_configs.AgentRefConfig
  name: AgentRefConfig
  file_path: google/adk/agents/common_configs.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'The config for the reference to another agent.


    [Note: Inherited members from pydantic.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, config_path: typing.Optional[str] = None, code: typing.Optional[str] = None):'
  methods:
  - signature: 'def validate_exactly_one_field(self) -> google.adk.agents.common_configs.AgentRefConfig:'
  properties:
  - signature: 'model_config: pydantic.ConfigDict'
  - signature: 'config_path: typing.Optional[str]'
    docstring: "The YAML config file path of the sub-agent.\n\nOnly one of `config_path` or `code` can be set.\n\nExample:\n\n  ```\n  sub_agents:\n    - config_path: search_agent.yaml\n    - config_path: my_library/my_custom_agent.yaml\n  ```"
  - signature: 'code: typing.Optional[str]'
    docstring: "The agent instance defined in the code.\n\nOnly one of `config` or `code` can be set.\n\nExample:\n\n  For the following agent defined in Python code:\n\n  ```\n  # my_library/custom_agents.py\n  from google.adk.agents.llm_agent import LlmAgent\n\n  my_custom_agent = LlmAgent(\n      name=\"my_custom_agent\",\n      instruction=\"You are a helpful custom agent.\",\n      model=\"gemini-2.0-flash\",\n  )\n  ```\n\n  The yaml config should be:\n\n  ```\n  sub_agents:\n    - code: my_library.custom_agents.my_custom_agent\n  ```\n  "
  inherited_properties:
    BaseModel:
    - signature: 'model_config: pydantic.ConfigDict'
  omitted_inherited_members_from:
  - pydantic.BaseModel
- rank: 128
  id: google.adk.agents.common_configs.AgentRefConfig.validate_exactly_one_field
  name: validate_exactly_one_field
  file_path: google/adk/agents/common_configs.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def validate_exactly_one_field(self) -> google.adk.agents.common_configs.AgentRefConfig:'
- rank: 129
  id: google.adk.agents.common_configs.ArgumentConfig
  name: ArgumentConfig
  file_path: google/adk/agents/common_configs.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'An argument passed to a function or a class''s constructor.


    [Note: Inherited members from pydantic.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, name: typing.Optional[str] = None, value: typing.Any):'
  properties:
  - signature: 'model_config: pydantic.ConfigDict'
  - signature: 'name: typing.Optional[str]'
    docstring: 'Optional. The argument name.


      When the argument is for a positional argument, this can be omitted.'
  - signature: 'value: typing.Any'
    docstring: The argument value.
  inherited_properties:
    BaseModel:
    - signature: 'model_config: pydantic.ConfigDict'
  omitted_inherited_members_from:
  - pydantic.BaseModel
- rank: 130
  id: google.adk.agents.common_configs.CodeConfig
  name: CodeConfig
  file_path: google/adk/agents/common_configs.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Code reference config for a variable, a function, or a class.


    This config is used for configuring callbacks and tools.


    [Note: Inherited members from pydantic.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, name: str, args: typing.Optional[typing.List[google.adk.agents.common_configs.ArgumentConfig]] = None):'
  properties:
  - signature: 'model_config: pydantic.ConfigDict'
  - signature: 'name: str'
    docstring: "Required. The name of the variable, function, class, etc. in code.\n\nExamples:\n\n  When used for tools,\n    - It can be ADK built-in tools, such as `google_search` and `AgentTool`.\n    - It can also be users' custom tools, e.g. my_library.my_tools.my_tool.\n\n  When used for callbacks, it refers to a function, e.g. `my_library.my_callbacks.my_callback`"
  - signature: 'args: typing.Optional[typing.List[google.adk.agents.common_configs.ArgumentConfig]]'
    docstring: "Optional. The arguments for the code when `name` refers to a function or a\nclass's constructor.\n\nExamples:\n  ```\n  tools\n    - name: AgentTool\n      args:\n        - name: agent\n          value: search_agent.yaml\n        - name: skip_summarization\n          value: True\n  ```"
  inherited_properties:
    BaseModel:
    - signature: 'model_config: pydantic.ConfigDict'
  omitted_inherited_members_from:
  - pydantic.BaseModel
- rank: 131
  id: google.adk.agents.config_agent_utils
  name: config_agent_utils
  file_path: google/adk/agents/config_agent_utils.py
  type: MODULE
  group: Orphan
  usage_score: 0
  methods:
  - signature: 'def from_config(config_path: str) -> google.adk.agents.base_agent.BaseAgent:'
    docstring: "Build agent from a configfile path.\n\nArgs:\n  config: the path to a YAML config file.\n\nReturns:\n  The created agent instance.\n\nRaises:\n  FileNotFoundError: If config file doesn't exist.\n  ValidationError: If config file's content is invalid YAML.\n  ValueError: If agent type is unsupported."
  - signature: 'def resolve_fully_qualified_name(name: str) -> typing.Any:'
  - signature: 'def resolve_agent_reference(ref_config: google.adk.agents.common_configs.AgentRefConfig, referencing_agent_config_abs_path: str) -> google.adk.agents.base_agent.BaseAgent:'
    docstring: "Build an agent from a reference.\n\nArgs:\n  ref_config: The agent reference configuration (AgentRefConfig).\n  referencing_agent_config_abs_path: The absolute path to the agent config\n  that contains the reference.\n\nReturns:\n  The created agent instance."
  - signature: 'def resolve_code_reference(code_config: google.adk.agents.common_configs.CodeConfig) -> typing.Any:'
    docstring: "Resolve a code reference to actual Python object.\n\nArgs:\n  code_config: The code configuration (CodeConfig).\n\nReturns:\n  The resolved Python object.\n\nRaises:\n  ValueError: If the code reference cannot be resolved."
  - signature: 'def resolve_callbacks(callbacks_config: typing.List[google.adk.agents.common_configs.CodeConfig]) -> typing.Any:'
    docstring: "Resolve callbacks from configuration.\n\nArgs:\n  callbacks_config: List of callback configurations (CodeConfig objects).\n\nReturns:\n  List of resolved callback objects."
- rank: 132
  id: google.adk.agents.config_agent_utils.from_config
  name: from_config
  file_path: google/adk/agents/config_agent_utils.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Build agent from a configfile path.\n\nArgs:\n  config: the path to a YAML config file.\n\nReturns:\n  The created agent instance.\n\nRaises:\n  FileNotFoundError: If config file doesn't exist.\n  ValidationError: If config file's content is invalid YAML.\n  ValueError: If agent type is unsupported."
  signature: 'def from_config(config_path: str) -> google.adk.agents.base_agent.BaseAgent:'
- rank: 133
  id: google.adk.agents.config_agent_utils.resolve_agent_reference
  name: resolve_agent_reference
  file_path: google/adk/agents/config_agent_utils.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Build an agent from a reference.\n\nArgs:\n  ref_config: The agent reference configuration (AgentRefConfig).\n  referencing_agent_config_abs_path: The absolute path to the agent config\n  that contains the reference.\n\nReturns:\n  The created agent instance."
  signature: 'def resolve_agent_reference(ref_config: google.adk.agents.common_configs.AgentRefConfig, referencing_agent_config_abs_path: str) -> google.adk.agents.base_agent.BaseAgent:'
- rank: 134
  id: google.adk.agents.config_agent_utils.resolve_callbacks
  name: resolve_callbacks
  file_path: google/adk/agents/config_agent_utils.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Resolve callbacks from configuration.\n\nArgs:\n  callbacks_config: List of callback configurations (CodeConfig objects).\n\nReturns:\n  List of resolved callback objects."
  signature: 'def resolve_callbacks(callbacks_config: typing.List[google.adk.agents.common_configs.CodeConfig]) -> typing.Any:'
- rank: 135
  id: google.adk.agents.config_agent_utils.resolve_code_reference
  name: resolve_code_reference
  file_path: google/adk/agents/config_agent_utils.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Resolve a code reference to actual Python object.\n\nArgs:\n  code_config: The code configuration (CodeConfig).\n\nReturns:\n  The resolved Python object.\n\nRaises:\n  ValueError: If the code reference cannot be resolved."
  signature: 'def resolve_code_reference(code_config: google.adk.agents.common_configs.CodeConfig) -> typing.Any:'
- rank: 136
  id: google.adk.agents.config_agent_utils.resolve_fully_qualified_name
  name: resolve_fully_qualified_name
  file_path: google/adk/agents/config_agent_utils.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def resolve_fully_qualified_name(name: str) -> typing.Any:'
- rank: 137
  id: google.adk.agents.context_cache_config
  name: context_cache_config
  file_path: google/adk/agents/context_cache_config.py
  type: MODULE
  group: Orphan
  usage_score: 0
- rank: 138
  id: google.adk.agents.invocation_context
  name: invocation_context
  file_path: google/adk/agents/invocation_context.py
  type: MODULE
  group: Orphan
  usage_score: 0
  methods:
  - signature: 'def new_invocation_context_id() -> str:'
- rank: 139
  id: google.adk.agents.invocation_context.InvocationContext
  name: InvocationContext
  file_path: google/adk/agents/invocation_context.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: "An invocation context represents the data of a single invocation of an agent.\n\nAn invocation:\n  1. Starts with a user message and ends with a final response.\n  2. Can contain one or multiple agent calls.\n  3. Is handled by runner.run_async().\n\nAn invocation runs an agent until it does not request to transfer to another\nagent.\n\nAn agent call:\n  1. Is handled by agent.run().\n  2. Ends when agent.run() ends.\n\nAn LLM agent call is an agent with a BaseLLMFlow.\nAn LLM agent call can contain one or multiple steps.\n\nAn LLM agent runs steps in a loop until:\n  1. A final response is generated.\n  2. The agent transfers to another agent.\n  3. The end_invocation is set to true by any callbacks or tools.\n\nA step:\n  1. Calls the LLM only once and yields its response.\n  2. Calls the tools and yields their responses if requested.\n\nThe summarization of the function response is considered another step, since\nit is another llm call.\nA step ends when it's done calling\
    \ llm and tools, or if the end_invocation\nis set to true at any time.\n\n```\n   \u250C\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 invocation \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n   \u250C\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 llm_agent_call_1 \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u250C\u2500 agent_call_2 \u2500\u2510\n   \u250C\u2500\u2500\u2500\u2500 step_1 \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u250C\u2500\u2500\u2500\u2500\u2500 step_2 \u2500\u2500\u2500\u2500\u2500\u2500\u2510\n   [call_llm] [call_tool] [call_llm] [transfer]\n```\n\n[Note: Inherited members from pydantic.BaseModel are omitted.]"
  constructor_signature: 'def __init__(self, *, artifact_service: typing.Optional[google.adk.artifacts.base_artifact_service.BaseArtifactService] = None, session_service: google.adk.sessions.base_session_service.BaseSessionService, memory_service: typing.Optional[google.adk.memory.base_memory_service.BaseMemoryService] = None, credential_service: typing.Optional[google.adk.auth.credential_service.base_credential_service.BaseCredentialService] = None, context_cache_config: typing.Optional[google.adk.agents.context_cache_config.ContextCacheConfig] = None, branch: typing.Optional[str] = None, agent: google.adk.agents.base_agent.BaseAgent, user_content: typing.Optional[google.genai.types.Content] = None, session: google.adk.sessions.session.Session, agent_states: dict[str, dict[str, typing.Any]] = dict(), end_of_agents: dict[str, bool] = dict(), end_invocation: bool = False, live_request_queue: typing.Optional[google.adk.agents.live_request_queue.LiveRequestQueue] = None, active_streaming_tools:
    typing.Optional[dict[str, google.adk.agents.active_streaming_tool.ActiveStreamingTool]] = None, transcription_cache: typing.Optional[list[google.adk.agents.transcription_entry.TranscriptionEntry]] = None, live_session_resumption_handle: typing.Optional[str] = None, input_realtime_cache: typing.Optional[list[google.adk.agents.invocation_context.RealtimeCacheEntry]] = None, output_realtime_cache: typing.Optional[list[google.adk.agents.invocation_context.RealtimeCacheEntry]] = None, run_config: typing.Optional[google.adk.agents.run_config.RunConfig] = None, resumability_config: typing.Optional[google.adk.apps.app.ResumabilityConfig] = None, plugin_manager: google.adk.plugins.plugin_manager.PluginManager = Factory(PluginManager), canonical_tools_cache: typing.Optional[list[google.adk.tools.base_tool.BaseTool]] = None):'
  methods:
  - signature: 'def is_resumable(self) -> bool:'
    docstring: Returns whether the current invocation is resumable.
  - signature: 'def set_agent_state(self, agent_name: str, *, agent_state: typing.Optional[google.adk.agents.base_agent.BaseAgentState]=None, end_of_agent: bool=False) -> None:'
    docstring: "Sets the state of an agent in this invocation.\n\n* If end_of_agent is True, will set the end_of_agent flag to True and\n  clear the agent_state.\n* Otherwise, if agent_state is not None, will set the agent_state and\n  reset the end_of_agent flag to False.\n* Otherwise, will clear the agent_state and end_of_agent flag, to allow the\n  agent to re-run.\n\nArgs:\n  agent_name: The name of the agent.\n  agent_state: The state of the agent. Will be ignored if end_of_agent is\n    True.\n  end_of_agent: Whether the agent has finished running."
  - signature: 'def reset_sub_agent_states(self, agent_name: str) -> None:'
    docstring: "Resets the state of all sub-agents of the given agent in this invocation.\n\nArgs:\n  agent_name: The name of the agent whose sub-agent states need to be reset."
  - signature: 'def populate_invocation_agent_states(self) -> None:'
    docstring: 'Populates agent states for the current invocation if it is resumable.


      For history events that contain agent state information, set the

      agent_state and end_of_agent of the agent that generated the event.


      For non-workflow agents, also set an initial agent_state if it has

      already generated some contents.'
  - signature: 'def increment_llm_call_count(self):'
    docstring: "Tracks number of llm calls made.\n\nRaises:\n  LlmCallsLimitExceededError: If number of llm calls made exceed the set\n    threshold."
  - signature: 'def app_name(self) -> str:'
  - signature: 'def user_id(self) -> str:'
  - signature: 'def should_pause_invocation(self, event: google.adk.events.event.Event) -> bool:'
    docstring: "Returns whether to pause the invocation right after this event.\n\n\"Pausing\" an invocation is different from \"ending\" an invocation. A paused\ninvocation can be resumed later, while an ended invocation cannot.\n\nPausing the current agent's run will also pause all the agents that\ndepend on its execution, i.e. the subsequent agents in a workflow, and the\ncurrent agent's ancestors, etc.\n\nNote that parallel sibling agents won't be affected, but their common\nancestors will be paused after all the non-blocking sub-agents finished\nrunning.\n\nShould meet all following conditions to pause an invocation:\n  1. The app is resumable.\n  2. The current event has a long running function call.\n\nArgs:\n  event: The current event.\n\nReturns:\n  Whether to pause the invocation right after this event."
  properties:
  - signature: 'model_config: pydantic.ConfigDict'
    docstring: The pydantic model config.
  - signature: 'artifact_service: typing.Optional[google.adk.artifacts.base_artifact_service.BaseArtifactService]'
  - signature: 'session_service: google.adk.sessions.base_session_service.BaseSessionService'
  - signature: 'memory_service: typing.Optional[google.adk.memory.base_memory_service.BaseMemoryService]'
  - signature: 'credential_service: typing.Optional[google.adk.auth.credential_service.base_credential_service.BaseCredentialService]'
  - signature: 'context_cache_config: typing.Optional[google.adk.agents.context_cache_config.ContextCacheConfig]'
  - signature: 'invocation_id: str'
    docstring: The id of this invocation context. Readonly.
  - signature: 'branch: typing.Optional[str]'
    docstring: 'The branch of the invocation context.


      The format is like agent_1.agent_2.agent_3, where agent_1 is the parent of

      agent_2, and agent_2 is the parent of agent_3.


      Branch is used when multiple sub-agents shouldn''t see their peer agents''

      conversation history.'
  - signature: 'agent: google.adk.agents.base_agent.BaseAgent'
    docstring: The current agent of this invocation context. Readonly.
  - signature: 'user_content: typing.Optional[google.genai.types.Content]'
    docstring: The user content that started this invocation. Readonly.
  - signature: 'session: google.adk.sessions.session.Session'
    docstring: The current session of this invocation context. Readonly.
  - signature: 'agent_states: dict[str, dict[str, typing.Any]]'
    docstring: The state of the agent for this invocation.
  - signature: 'end_of_agents: dict[str, bool]'
    docstring: The end of agent status for each agent in this invocation.
  - signature: 'end_invocation: bool'
    docstring: 'Whether to end this invocation.


      Set to True in callbacks or tools to terminate this invocation.'
  - signature: 'live_request_queue: typing.Optional[google.adk.agents.live_request_queue.LiveRequestQueue]'
    docstring: The queue to receive live requests.
  - signature: 'active_streaming_tools: typing.Optional[dict[str, google.adk.agents.active_streaming_tool.ActiveStreamingTool]]'
    docstring: The running streaming tools of this invocation.
  - signature: 'transcription_cache: typing.Optional[list[google.adk.agents.transcription_entry.TranscriptionEntry]]'
    docstring: Caches necessary data, audio or contents, that are needed by transcription.
  - signature: 'live_session_resumption_handle: typing.Optional[str]'
    docstring: The handle for live session resumption.
  - signature: 'input_realtime_cache: typing.Optional[list[google.adk.agents.invocation_context.RealtimeCacheEntry]]'
    docstring: Caches input audio chunks before flushing to session and artifact services.
  - signature: 'output_realtime_cache: typing.Optional[list[google.adk.agents.invocation_context.RealtimeCacheEntry]]'
    docstring: Caches output audio chunks before flushing to session and artifact services.
  - signature: 'run_config: typing.Optional[google.adk.agents.run_config.RunConfig]'
    docstring: Configurations for live agents under this invocation.
  - signature: 'resumability_config: typing.Optional[google.adk.apps.app.ResumabilityConfig]'
    docstring: The resumability config that applies to all agents under this invocation.
  - signature: 'plugin_manager: google.adk.plugins.plugin_manager.PluginManager'
    docstring: The manager for keeping track of plugins in this invocation.
  - signature: 'canonical_tools_cache: typing.Optional[list[google.adk.tools.base_tool.BaseTool]]'
    docstring: The cache of canonical tools for this invocation.
  inherited_properties:
    BaseModel:
    - signature: 'model_config: pydantic.ConfigDict'
  omitted_inherited_members_from:
  - pydantic.BaseModel
- rank: 140
  id: google.adk.agents.invocation_context.InvocationContext.increment_llm_call_count
  name: increment_llm_call_count
  file_path: google/adk/agents/invocation_context.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Tracks number of llm calls made.\n\nRaises:\n  LlmCallsLimitExceededError: If number of llm calls made exceed the set\n    threshold."
  signature: 'def increment_llm_call_count(self):'
- rank: 141
  id: google.adk.agents.invocation_context.InvocationContext.is_resumable
  name: is_resumable
  file_path: google/adk/agents/invocation_context.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: Returns whether the current invocation is resumable.
  signature: 'def is_resumable(self) -> bool:'
- rank: 142
  id: google.adk.agents.invocation_context.InvocationContext.populate_invocation_agent_states
  name: populate_invocation_agent_states
  file_path: google/adk/agents/invocation_context.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: 'Populates agent states for the current invocation if it is resumable.


    For history events that contain agent state information, set the

    agent_state and end_of_agent of the agent that generated the event.


    For non-workflow agents, also set an initial agent_state if it has

    already generated some contents.'
  signature: 'def populate_invocation_agent_states(self) -> None:'
- rank: 143
  id: google.adk.agents.invocation_context.InvocationContext.reset_sub_agent_states
  name: reset_sub_agent_states
  file_path: google/adk/agents/invocation_context.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Resets the state of all sub-agents of the given agent in this invocation.\n\nArgs:\n  agent_name: The name of the agent whose sub-agent states need to be reset."
  signature: 'def reset_sub_agent_states(self, agent_name: str) -> None:'
- rank: 144
  id: google.adk.agents.invocation_context.InvocationContext.set_agent_state
  name: set_agent_state
  file_path: google/adk/agents/invocation_context.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Sets the state of an agent in this invocation.\n\n* If end_of_agent is True, will set the end_of_agent flag to True and\n  clear the agent_state.\n* Otherwise, if agent_state is not None, will set the agent_state and\n  reset the end_of_agent flag to False.\n* Otherwise, will clear the agent_state and end_of_agent flag, to allow the\n  agent to re-run.\n\nArgs:\n  agent_name: The name of the agent.\n  agent_state: The state of the agent. Will be ignored if end_of_agent is\n    True.\n  end_of_agent: Whether the agent has finished running."
  signature: 'def set_agent_state(self, agent_name: str, *, agent_state: typing.Optional[google.adk.agents.base_agent.BaseAgentState]=None, end_of_agent: bool=False) -> None:'
- rank: 145
  id: google.adk.agents.invocation_context.InvocationContext.should_pause_invocation
  name: should_pause_invocation
  file_path: google/adk/agents/invocation_context.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Returns whether to pause the invocation right after this event.\n\n\"Pausing\" an invocation is different from \"ending\" an invocation. A paused\ninvocation can be resumed later, while an ended invocation cannot.\n\nPausing the current agent's run will also pause all the agents that\ndepend on its execution, i.e. the subsequent agents in a workflow, and the\ncurrent agent's ancestors, etc.\n\nNote that parallel sibling agents won't be affected, but their common\nancestors will be paused after all the non-blocking sub-agents finished\nrunning.\n\nShould meet all following conditions to pause an invocation:\n  1. The app is resumable.\n  2. The current event has a long running function call.\n\nArgs:\n  event: The current event.\n\nReturns:\n  Whether to pause the invocation right after this event."
  signature: 'def should_pause_invocation(self, event: google.adk.events.event.Event) -> bool:'
- rank: 146
  id: google.adk.agents.invocation_context.LlmCallsLimitExceededError
  name: LlmCallsLimitExceededError
  file_path: google/adk/agents/invocation_context.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Error thrown when the number of LLM calls exceed the limit.


    [Note: Inherited members from Exception are omitted.]'
  omitted_inherited_members_from:
  - Exception
- rank: 147
  id: google.adk.agents.invocation_context.RealtimeCacheEntry
  name: RealtimeCacheEntry
  file_path: google/adk/agents/invocation_context.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Store audio data chunks for caching before flushing.


    [Note: Inherited members from pydantic.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, role: str, data: google.genai.types.Blob, timestamp: float):'
  properties:
  - signature: 'model_config: pydantic.ConfigDict'
    docstring: The pydantic model config.
  - signature: 'role: str'
    docstring: The role that created this audio data, typically "user" or "model".
  - signature: 'data: google.genai.types.Blob'
    docstring: The audio data chunk.
  - signature: 'timestamp: float'
    docstring: Timestamp when the audio chunk was received.
  inherited_properties:
    BaseModel:
    - signature: 'model_config: pydantic.ConfigDict'
  omitted_inherited_members_from:
  - pydantic.BaseModel
- rank: 148
  id: google.adk.agents.langgraph_agent
  name: langgraph_agent
  file_path: google/adk/agents/langgraph_agent.py
  type: MODULE
  group: Orphan
  usage_score: 0
- rank: 149
  id: google.adk.agents.langgraph_agent.LangGraphAgent
  name: LangGraphAgent
  file_path: google/adk/agents/langgraph_agent.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Currently a concept implementation, supports single and multi-turn.


    [Note: Inherited members from pydantic.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, name: str, description: str = '''', sub_agents: list[google.adk.agents.base_agent.BaseAgent] = list(), before_agent_callback: typing.Optional[google.adk.agents.base_agent.BeforeAgentCallback] = None, after_agent_callback: typing.Optional[google.adk.agents.base_agent.AfterAgentCallback] = None, graph: langgraph.graph.graph.CompiledGraph, instruction: str = ''''):'
  methods:
  - signature: 'def _run_async_impl(self, ctx: google.adk.agents.invocation_context.InvocationContext) -> typing.AsyncGenerator[google.adk.events.event.Event, None]:'
  properties:
  - signature: 'model_config: pydantic.ConfigDict'
    docstring: The pydantic model config.
  - signature: 'graph: langgraph.graph.graph.CompiledGraph'
  - signature: 'instruction: str'
  inherited_methods:
    BaseAgent:
    - signature: 'def clone(self: google.adk.agents.base_agent.SelfAgent, update: Mapping[str, Any] | None) -> google.adk.agents.base_agent.SelfAgent:'
      docstring: "Creates a copy of this agent instance.\n\nArgs:\n  update: Optional mapping of new values for the fields of the cloned agent.\n    The keys of the mapping are the names of the fields to be updated, and\n    the values are the new values for those fields.\n    For example: {\"name\": \"cloned_agent\"}\n\nReturns:\n  A new agent instance with identical configuration as the original\n  agent except for the fields specified in the update."
    - signature: 'def run_async(self, parent_context: google.adk.agents.invocation_context.InvocationContext) -> typing.AsyncGenerator[google.adk.events.event.Event, None]:'
      docstring: "Entry method to run an agent via text-based conversation.\n\nArgs:\n  parent_context: InvocationContext, the invocation context of the parent\n    agent.\n\nYields:\n  Event: the events generated by the agent."
    - signature: 'def run_live(self, parent_context: google.adk.agents.invocation_context.InvocationContext) -> typing.AsyncGenerator[google.adk.events.event.Event, None]:'
      docstring: "Entry method to run an agent via video/audio-based conversation.\n\nArgs:\n  parent_context: InvocationContext, the invocation context of the parent\n    agent.\n\nYields:\n  Event: the events generated by the agent."
    - signature: 'def _run_async_impl(self, ctx: google.adk.agents.invocation_context.InvocationContext) -> typing.AsyncGenerator[google.adk.events.event.Event, None]:'
      docstring: "Core logic to run this agent via text-based conversation.\n\nArgs:\n  ctx: InvocationContext, the invocation context for this agent.\n\nYields:\n  Event: the events generated by the agent."
    - signature: 'def root_agent(self) -> google.adk.agents.base_agent.BaseAgent:'
      docstring: Gets the root agent of this agent.
    - signature: 'def find_agent(self, name: str) -> typing.Optional[google.adk.agents.base_agent.BaseAgent]:'
      docstring: "Finds the agent with the given name in this agent and its descendants.\n\nArgs:\n  name: The name of the agent to find.\n\nReturns:\n  The agent with the matching name, or None if no such agent is found."
    - signature: 'def find_sub_agent(self, name: str) -> typing.Optional[google.adk.agents.base_agent.BaseAgent]:'
      docstring: "Finds the agent with the given name in this agent's descendants.\n\nArgs:\n  name: The name of the agent to find.\n\nReturns:\n  The agent with the matching name, or None if no such agent is found."
    - signature: 'def model_post_init(self, __context: typing.Any) -> None:'
    - signature: 'def validate_name(cls, value: str):'
    - signature: 'def validate_sub_agents_unique_names(cls, value: list[google.adk.agents.base_agent.BaseAgent]) -> list[google.adk.agents.base_agent.BaseAgent]:'
      docstring: "Validates that all sub-agents have unique names.\n\nArgs:\n  value: The list of sub-agents to validate.\n\nReturns:\n  The validated list of sub-agents."
    - signature: 'def from_config(cls: typing.Type[google.adk.agents.base_agent.SelfAgent], config: google.adk.agents.base_agent_config.BaseAgentConfig, config_abs_path: str) -> google.adk.agents.base_agent.SelfAgent:'
      docstring: "Creates an agent from a config.\n\nIf sub-classes uses a custom agent config, override `_from_config_kwargs`\nmethod to return an updated kwargs for agent constructor.\n\nArgs:\n  config: The config to create the agent from.\n  config_abs_path: The absolute path to the config file that contains the\n    agent config.\n\nReturns:\n  The created agent."
  inherited_properties:
    BaseAgent:
    - signature: 'model_config: pydantic.ConfigDict'
      docstring: The pydantic model config.
    - signature: 'config_type: typing.ClassVar[type[google.adk.agents.base_agent_config.BaseAgentConfig]]'
      docstring: "The config type for this agent.\n\nSub-classes should override this to specify their own config type.\n\nExample:\n\n```\nclass MyAgentConfig(BaseAgentConfig):\n  my_field: str = ''\n\nclass MyAgent(BaseAgent):\n  config_type: ClassVar[type[BaseAgentConfig]] = MyAgentConfig\n```"
    - signature: 'name: str'
      docstring: 'The agent''s name.


        Agent name must be a Python identifier and unique within the agent tree.

        Agent name cannot be "user", since it''s reserved for end-user''s input.'
    - signature: 'description: str'
      docstring: 'Description about the agent''s capability.


        The model uses this to determine whether to delegate control to the agent.

        One-line description is enough and preferred.'
    - signature: 'parent_agent: typing.Optional[google.adk.agents.base_agent.BaseAgent]'
      docstring: 'The parent agent of this agent.


        Note that an agent can ONLY be added as sub-agent once.


        If you want to add one agent twice as sub-agent, consider to create two agent

        instances with identical config, but with different name and add them to the

        agent tree.'
    - signature: 'sub_agents: list[google.adk.agents.base_agent.BaseAgent]'
      docstring: The sub-agents of this agent.
    - signature: 'before_agent_callback: typing.Optional[google.adk.agents.base_agent.BeforeAgentCallback]'
      docstring: "Callback or list of callbacks to be invoked before the agent run.\n\nWhen a list of callbacks is provided, the callbacks will be called in the\norder they are listed until a callback does not return None.\n\nArgs:\n  callback_context: MUST be named 'callback_context' (enforced).\n\nReturns:\n  Optional[types.Content]: The content to return to the user.\n    When the content is present, the agent run will be skipped and the\n    provided content will be returned to user."
    - signature: 'after_agent_callback: typing.Optional[google.adk.agents.base_agent.AfterAgentCallback]'
      docstring: "Callback or list of callbacks to be invoked after the agent run.\n\nWhen a list of callbacks is provided, the callbacks will be called in the\norder they are listed until a callback does not return None.\n\nArgs:\n  callback_context: MUST be named 'callback_context' (enforced).\n\nReturns:\n  Optional[types.Content]: The content to return to the user.\n    When the content is present, an additional event with the provided content\n    will be appended to event history as an additional agent response."
    BaseModel:
    - signature: 'model_config: pydantic.ConfigDict'
  omitted_inherited_members_from:
  - pydantic.BaseModel
- rank: 150
  id: google.adk.agents.langgraph_agent.LangGraphAgent._run_async_impl
  name: _run_async_impl
  file_path: google/adk/agents/langgraph_agent.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def _run_async_impl(self, ctx: google.adk.agents.invocation_context.InvocationContext) -> typing.AsyncGenerator[google.adk.events.event.Event, None]:'
- rank: 151
  id: google.adk.agents.live_request_queue
  name: live_request_queue
  file_path: google/adk/agents/live_request_queue.py
  type: MODULE
  group: Orphan
  usage_score: 0
- rank: 152
  id: google.adk.agents.live_request_queue.LiveRequest
  name: LiveRequest
  file_path: google/adk/agents/live_request_queue.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Request send to live agents.


    [Note: Inherited members from pydantic.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, content: typing.Optional[google.genai.types.Content] = None, blob: typing.Optional[google.genai.types.Blob] = None, activity_start: typing.Optional[google.genai.types.ActivityStart] = None, activity_end: typing.Optional[google.genai.types.ActivityEnd] = None, close: bool = False):'
  aliases:
  - google.adk.agents.LiveRequest
  properties:
  - signature: 'model_config: pydantic.ConfigDict'
    docstring: The pydantic model config.
  - signature: 'content: typing.Optional[google.genai.types.Content]'
    docstring: If set, send the content to the model in turn-by-turn mode.
  - signature: 'blob: typing.Optional[google.genai.types.Blob]'
    docstring: If set, send the blob to the model in realtime mode.
  - signature: 'activity_start: typing.Optional[google.genai.types.ActivityStart]'
    docstring: If set, signal the start of user activity to the model.
  - signature: 'activity_end: typing.Optional[google.genai.types.ActivityEnd]'
    docstring: If set, signal the end of user activity to the model.
  - signature: 'close: bool'
    docstring: If set, close the queue. queue.shutdown() is only supported in Python 3.13+.
  inherited_properties:
    BaseModel:
    - signature: 'model_config: pydantic.ConfigDict'
  omitted_inherited_members_from:
  - pydantic.BaseModel
- rank: 153
  id: google.adk.agents.live_request_queue.LiveRequestQueue
  name: LiveRequestQueue
  file_path: google/adk/agents/live_request_queue.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: Queue used to send LiveRequest in a live(bidirectional streaming) way.
  constructor_signature: 'def __init__(self):'
  aliases:
  - google.adk.agents.LiveRequestQueue
  methods:
  - signature: 'def close(self):'
  - signature: 'def send_content(self, content: google.genai.types.Content):'
  - signature: 'def send_realtime(self, blob: google.genai.types.Blob):'
  - signature: 'def send_activity_start(self):'
    docstring: Sends an activity start signal to mark the beginning of user input.
  - signature: 'def send_activity_end(self):'
    docstring: Sends an activity end signal to mark the end of user input.
  - signature: 'def send(self, req: google.adk.agents.live_request_queue.LiveRequest):'
  - signature: 'def get(self) -> google.adk.agents.live_request_queue.LiveRequest:'
- rank: 154
  id: google.adk.agents.live_request_queue.LiveRequestQueue.__init__
  name: __init__
  file_path: google/adk/agents/live_request_queue.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def __init__(self):'
- rank: 155
  id: google.adk.agents.llm_agent
  name: llm_agent
  file_path: google/adk/agents/llm_agent.py
  type: MODULE
  group: Orphan
  usage_score: 0
- rank: 156
  id: google.adk.agents.llm_agent.LlmAgent._run_async_impl
  name: _run_async_impl
  file_path: google/adk/agents/llm_agent.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def _run_async_impl(self, ctx: google.adk.agents.invocation_context.InvocationContext) -> typing.AsyncGenerator[google.adk.events.event.Event, None]:'
- rank: 157
  id: google.adk.agents.llm_agent.LlmAgent.canonical_after_model_callbacks
  name: canonical_after_model_callbacks
  file_path: google/adk/agents/llm_agent.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: 'The resolved self.after_model_callback field as a list of _SingleAfterModelCallback.


    This method is only for use by Agent Development Kit.'
  signature: 'def canonical_after_model_callbacks(self) -> list[google.adk.agents.llm_agent._SingleAfterModelCallback]:'
- rank: 158
  id: google.adk.agents.llm_agent.LlmAgent.canonical_after_tool_callbacks
  name: canonical_after_tool_callbacks
  file_path: google/adk/agents/llm_agent.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: 'The resolved self.after_tool_callback field as a list of AfterToolCallback.


    This method is only for use by Agent Development Kit.'
  signature: 'def canonical_after_tool_callbacks(self) -> list[google.adk.agents.llm_agent.AfterToolCallback]:'
- rank: 159
  id: google.adk.agents.llm_agent.LlmAgent.canonical_before_model_callbacks
  name: canonical_before_model_callbacks
  file_path: google/adk/agents/llm_agent.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: 'The resolved self.before_model_callback field as a list of _SingleBeforeModelCallback.


    This method is only for use by Agent Development Kit.'
  signature: 'def canonical_before_model_callbacks(self) -> list[google.adk.agents.llm_agent._SingleBeforeModelCallback]:'
- rank: 160
  id: google.adk.agents.llm_agent.LlmAgent.canonical_before_tool_callbacks
  name: canonical_before_tool_callbacks
  file_path: google/adk/agents/llm_agent.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: 'The resolved self.before_tool_callback field as a list of BeforeToolCallback.


    This method is only for use by Agent Development Kit.'
  signature: 'def canonical_before_tool_callbacks(self) -> list[google.adk.agents.llm_agent.BeforeToolCallback]:'
- rank: 161
  id: google.adk.agents.llm_agent.LlmAgent.canonical_global_instruction
  name: canonical_global_instruction
  file_path: google/adk/agents/llm_agent.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "The resolved self.instruction field to construct global instruction.\n\nThis method is only for use by Agent Development Kit.\n\nArgs:\n  ctx: The context to retrieve the session state.\n\nReturns:\n  A tuple of (instruction, bypass_state_injection).\n  instruction: The resolved self.global_instruction field.\n  bypass_state_injection: Whether the instruction is based on\n  InstructionProvider."
  signature: 'def canonical_global_instruction(self, ctx: google.adk.agents.readonly_context.ReadonlyContext) -> tuple[str, bool]:'
- rank: 162
  id: google.adk.agents.llm_agent.LlmAgent.canonical_instruction
  name: canonical_instruction
  file_path: google/adk/agents/llm_agent.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "The resolved self.instruction field to construct instruction for this agent.\n\nThis method is only for use by Agent Development Kit.\n\nArgs:\n  ctx: The context to retrieve the session state.\n\nReturns:\n  A tuple of (instruction, bypass_state_injection).\n  instruction: The resolved self.instruction field.\n  bypass_state_injection: Whether the instruction is based on\n  InstructionProvider."
  signature: 'def canonical_instruction(self, ctx: google.adk.agents.readonly_context.ReadonlyContext) -> tuple[str, bool]:'
- rank: 163
  id: google.adk.agents.llm_agent.LlmAgent.canonical_model
  name: canonical_model
  file_path: google/adk/agents/llm_agent.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: 'The resolved self.model field as BaseLlm.


    This method is only for use by Agent Development Kit.'
  signature: 'def canonical_model(self) -> google.adk.models.base_llm.BaseLlm:'
- rank: 164
  id: google.adk.agents.llm_agent.LlmAgent.canonical_on_model_error_callbacks
  name: canonical_on_model_error_callbacks
  file_path: google/adk/agents/llm_agent.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: 'The resolved self.on_model_error_callback field as a list of _SingleOnModelErrorCallback.


    This method is only for use by Agent Development Kit.'
  signature: 'def canonical_on_model_error_callbacks(self) -> list[google.adk.agents.llm_agent._SingleOnModelErrorCallback]:'
- rank: 165
  id: google.adk.agents.llm_agent.LlmAgent.canonical_on_tool_error_callbacks
  name: canonical_on_tool_error_callbacks
  file_path: google/adk/agents/llm_agent.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: 'The resolved self.on_tool_error_callback field as a list of OnToolErrorCallback.


    This method is only for use by Agent Development Kit.'
  signature: 'def canonical_on_tool_error_callbacks(self) -> list[google.adk.agents.llm_agent.OnToolErrorCallback]:'
- rank: 166
  id: google.adk.agents.llm_agent.LlmAgent.canonical_tools
  name: canonical_tools
  file_path: google/adk/agents/llm_agent.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: 'The resolved self.tools field as a list of BaseTool based on the context.


    This method is only for use by Agent Development Kit.'
  signature: 'def canonical_tools(self, ctx: google.adk.agents.readonly_context.ReadonlyContext) -> list[google.adk.tools.base_tool.BaseTool]:'
- rank: 167
  id: google.adk.agents.llm_agent.LlmAgent.collect_agents
  name: collect_agents
  file_path: google/adk/agents/llm_agent.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def collect_agents(agent):'
- rank: 168
  id: google.adk.agents.llm_agent.LlmAgent.validate_generate_content_config
  name: validate_generate_content_config
  file_path: google/adk/agents/llm_agent.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def validate_generate_content_config(cls, generate_content_config: typing.Optional[google.genai.types.GenerateContentConfig]) -> google.genai.types.GenerateContentConfig:'
- rank: 169
  id: google.adk.agents.llm_agent_config
  name: llm_agent_config
  file_path: google/adk/agents/llm_agent_config.py
  type: MODULE
  group: Orphan
  usage_score: 0
- rank: 170
  id: google.adk.agents.llm_agent_config.LlmAgentConfig
  name: LlmAgentConfig
  file_path: google/adk/agents/llm_agent_config.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'The config for the YAML schema of a LlmAgent.


    [Note: Inherited members from pydantic.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, agent_class: typing.Union[typing.Literal[BaseAgent], str] = ''BaseAgent'', name: str, description: str = '''', sub_agents: typing.Optional[typing.List[google.adk.agents.common_configs.AgentRefConfig]] = None, before_agent_callbacks: typing.Optional[typing.List[google.adk.agents.common_configs.CodeConfig]] = None, after_agent_callbacks: typing.Optional[typing.List[google.adk.agents.common_configs.CodeConfig]] = None, model: typing.Optional[str] = None, model_code: typing.Optional[google.adk.agents.common_configs.CodeConfig] = None, instruction: str, static_instruction: typing.Optional[google.genai.types.ContentUnion] = None, disallow_transfer_to_parent: typing.Optional[bool] = None, disallow_transfer_to_peers: typing.Optional[bool] = None, input_schema: typing.Optional[google.adk.agents.common_configs.CodeConfig] = None, output_schema: typing.Optional[google.adk.agents.common_configs.CodeConfig] = None, output_key: typing.Optional[str] = None,
    include_contents: typing.Literal[default, none] = ''default'', tools: typing.Optional[list[google.adk.tools.tool_configs.ToolConfig]] = None, before_model_callbacks: typing.Optional[typing.List[google.adk.agents.common_configs.CodeConfig]] = None, after_model_callbacks: typing.Optional[typing.List[google.adk.agents.common_configs.CodeConfig]] = None, before_tool_callbacks: typing.Optional[typing.List[google.adk.agents.common_configs.CodeConfig]] = None, after_tool_callbacks: typing.Optional[typing.List[google.adk.agents.common_configs.CodeConfig]] = None, generate_content_config: typing.Optional[google.genai.types.GenerateContentConfig] = None):'
  properties:
  - signature: 'model_config: pydantic.ConfigDict'
  - signature: 'agent_class: str'
  - signature: 'model: typing.Optional[str]'
  - signature: 'model_code: typing.Optional[google.adk.agents.common_configs.CodeConfig]'
  - signature: 'instruction: str'
  - signature: 'static_instruction: typing.Optional[google.genai.types.ContentUnion]'
  - signature: 'disallow_transfer_to_parent: typing.Optional[bool]'
  - signature: 'disallow_transfer_to_peers: typing.Optional[bool]'
  - signature: 'input_schema: typing.Optional[google.adk.agents.common_configs.CodeConfig]'
  - signature: 'output_schema: typing.Optional[google.adk.agents.common_configs.CodeConfig]'
  - signature: 'output_key: typing.Optional[str]'
  - signature: 'include_contents: typing.Literal[default, none]'
  - signature: 'tools: typing.Optional[list[google.adk.tools.tool_configs.ToolConfig]]'
  - signature: 'before_model_callbacks: typing.Optional[typing.List[google.adk.agents.common_configs.CodeConfig]]'
  - signature: 'after_model_callbacks: typing.Optional[typing.List[google.adk.agents.common_configs.CodeConfig]]'
  - signature: 'before_tool_callbacks: typing.Optional[typing.List[google.adk.agents.common_configs.CodeConfig]]'
  - signature: 'after_tool_callbacks: typing.Optional[typing.List[google.adk.agents.common_configs.CodeConfig]]'
  - signature: 'generate_content_config: typing.Optional[google.genai.types.GenerateContentConfig]'
  inherited_properties:
    BaseAgentConfig:
    - signature: 'model_config: pydantic.ConfigDict'
    - signature: 'agent_class: typing.Union[typing.Literal[BaseAgent], str]'
    - signature: 'name: str'
    - signature: 'description: str'
    - signature: 'sub_agents: typing.Optional[typing.List[google.adk.agents.common_configs.AgentRefConfig]]'
    - signature: 'before_agent_callbacks: typing.Optional[typing.List[google.adk.agents.common_configs.CodeConfig]]'
    - signature: 'after_agent_callbacks: typing.Optional[typing.List[google.adk.agents.common_configs.CodeConfig]]'
    BaseModel:
    - signature: 'model_config: pydantic.ConfigDict'
  omitted_inherited_members_from:
  - pydantic.BaseModel
- rank: 171
  id: google.adk.agents.loop_agent
  name: loop_agent
  file_path: google/adk/agents/loop_agent.py
  type: MODULE
  group: Orphan
  usage_score: 0
  docstring: Loop agent implementation.
- rank: 172
  id: google.adk.agents.loop_agent.LoopAgent._run_async_impl
  name: _run_async_impl
  file_path: google/adk/agents/loop_agent.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def _run_async_impl(self, ctx: google.adk.agents.invocation_context.InvocationContext) -> typing.AsyncGenerator[google.adk.events.event.Event, None]:'
- rank: 173
  id: google.adk.agents.loop_agent.LoopAgentState
  name: LoopAgentState
  file_path: google/adk/agents/loop_agent.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'State for LoopAgent.


    [Note: Inherited members from pydantic.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, current_sub_agent: str = '''', times_looped: int = 0):'
  properties:
  - signature: 'current_sub_agent: str'
    docstring: The name of the current sub-agent to run in the loop.
  - signature: 'times_looped: int'
    docstring: The number of times the loop agent has looped.
  inherited_properties:
    BaseAgentState:
    - signature: 'model_config: pydantic.ConfigDict'
    BaseModel:
    - signature: 'model_config: pydantic.ConfigDict'
  omitted_inherited_members_from:
  - pydantic.BaseModel
- rank: 174
  id: google.adk.agents.loop_agent_config
  name: loop_agent_config
  file_path: google/adk/agents/loop_agent_config.py
  type: MODULE
  group: Orphan
  usage_score: 0
  docstring: Loop agent implementation.
- rank: 175
  id: google.adk.agents.loop_agent_config.LoopAgentConfig
  name: LoopAgentConfig
  file_path: google/adk/agents/loop_agent_config.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'The config for the YAML schema of a LoopAgent.


    [Note: Inherited members from pydantic.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, agent_class: typing.Union[typing.Literal[BaseAgent], str] = ''BaseAgent'', name: str, description: str = '''', sub_agents: typing.Optional[typing.List[google.adk.agents.common_configs.AgentRefConfig]] = None, before_agent_callbacks: typing.Optional[typing.List[google.adk.agents.common_configs.CodeConfig]] = None, after_agent_callbacks: typing.Optional[typing.List[google.adk.agents.common_configs.CodeConfig]] = None, max_iterations: typing.Optional[int] = None):'
  properties:
  - signature: 'model_config: pydantic.ConfigDict'
  - signature: 'agent_class: str'
  - signature: 'max_iterations: typing.Optional[int]'
  inherited_properties:
    BaseAgentConfig:
    - signature: 'model_config: pydantic.ConfigDict'
    - signature: 'agent_class: typing.Union[typing.Literal[BaseAgent], str]'
    - signature: 'name: str'
    - signature: 'description: str'
    - signature: 'sub_agents: typing.Optional[typing.List[google.adk.agents.common_configs.AgentRefConfig]]'
    - signature: 'before_agent_callbacks: typing.Optional[typing.List[google.adk.agents.common_configs.CodeConfig]]'
    - signature: 'after_agent_callbacks: typing.Optional[typing.List[google.adk.agents.common_configs.CodeConfig]]'
    BaseModel:
    - signature: 'model_config: pydantic.ConfigDict'
  omitted_inherited_members_from:
  - pydantic.BaseModel
- rank: 176
  id: google.adk.agents.mcp_instruction_provider
  name: mcp_instruction_provider
  file_path: google/adk/agents/mcp_instruction_provider.py
  type: MODULE
  group: Orphan
  usage_score: 0
  docstring: Provides instructions to an agent by fetching prompts from an MCP server.
- rank: 177
  id: google.adk.agents.mcp_instruction_provider.McpInstructionProvider
  name: McpInstructionProvider
  file_path: google/adk/agents/mcp_instruction_provider.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Fetches agent instructions from an MCP server.


    [Note: Inherited members from InstructionProvider are omitted.]'
  constructor_signature: 'def __init__(self, connection_params: typing.Any, prompt_name: str, errlog: typing.TextIO):'
  omitted_inherited_members_from:
  - InstructionProvider
- rank: 178
  id: google.adk.agents.mcp_instruction_provider.McpInstructionProvider.__init__
  name: __init__
  file_path: google/adk/agents/mcp_instruction_provider.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Initializes the McpInstructionProvider.\n\nArgs:\n    connection_params: Parameters for connecting to the MCP server.\n    prompt_name: The name of the MCP Prompt to fetch.\n    errlog: TextIO stream for error logging."
  signature: 'def __init__(self, connection_params: typing.Any, prompt_name: str, errlog: typing.TextIO):'
- rank: 179
  id: google.adk.agents.parallel_agent
  name: parallel_agent
  file_path: google/adk/agents/parallel_agent.py
  type: MODULE
  group: Orphan
  usage_score: 0
  docstring: Parallel agent implementation.
  methods:
  - signature: 'def propagate_exceptions(tasks):'
  - signature: 'def process_an_agent(events_for_one_agent):'
  - signature: 'def process_an_agent(events_for_one_agent):'
- rank: 180
  id: google.adk.agents.parallel_agent.ParallelAgent._run_async_impl
  name: _run_async_impl
  file_path: google/adk/agents/parallel_agent.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def _run_async_impl(self, ctx: google.adk.agents.invocation_context.InvocationContext) -> typing.AsyncGenerator[google.adk.events.event.Event, None]:'
- rank: 181
  id: google.adk.agents.parallel_agent.process_an_agent
  name: process_an_agent
  file_path: google/adk/agents/parallel_agent.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def process_an_agent(events_for_one_agent):'
- rank: 182
  id: google.adk.agents.parallel_agent.process_an_agent
  name: process_an_agent
  file_path: google/adk/agents/parallel_agent.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def process_an_agent(events_for_one_agent):'
- rank: 183
  id: google.adk.agents.parallel_agent.propagate_exceptions
  name: propagate_exceptions
  file_path: google/adk/agents/parallel_agent.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def propagate_exceptions(tasks):'
- rank: 184
  id: google.adk.agents.parallel_agent_config
  name: parallel_agent_config
  file_path: google/adk/agents/parallel_agent_config.py
  type: MODULE
  group: Orphan
  usage_score: 0
  docstring: Parallel agent implementation.
- rank: 185
  id: google.adk.agents.parallel_agent_config.ParallelAgentConfig
  name: ParallelAgentConfig
  file_path: google/adk/agents/parallel_agent_config.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'The config for the YAML schema of a ParallelAgent.


    [Note: Inherited members from pydantic.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, agent_class: typing.Union[typing.Literal[BaseAgent], str] = ''BaseAgent'', name: str, description: str = '''', sub_agents: typing.Optional[typing.List[google.adk.agents.common_configs.AgentRefConfig]] = None, before_agent_callbacks: typing.Optional[typing.List[google.adk.agents.common_configs.CodeConfig]] = None, after_agent_callbacks: typing.Optional[typing.List[google.adk.agents.common_configs.CodeConfig]] = None):'
  properties:
  - signature: 'model_config: pydantic.ConfigDict'
  - signature: 'agent_class: str'
  inherited_properties:
    BaseAgentConfig:
    - signature: 'model_config: pydantic.ConfigDict'
    - signature: 'agent_class: typing.Union[typing.Literal[BaseAgent], str]'
    - signature: 'name: str'
    - signature: 'description: str'
    - signature: 'sub_agents: typing.Optional[typing.List[google.adk.agents.common_configs.AgentRefConfig]]'
    - signature: 'before_agent_callbacks: typing.Optional[typing.List[google.adk.agents.common_configs.CodeConfig]]'
    - signature: 'after_agent_callbacks: typing.Optional[typing.List[google.adk.agents.common_configs.CodeConfig]]'
    BaseModel:
    - signature: 'model_config: pydantic.ConfigDict'
  omitted_inherited_members_from:
  - pydantic.BaseModel
- rank: 186
  id: google.adk.agents.readonly_context
  name: readonly_context
  file_path: google/adk/agents/readonly_context.py
  type: MODULE
  group: Orphan
  usage_score: 0
- rank: 187
  id: google.adk.agents.readonly_context.ReadonlyContext
  name: ReadonlyContext
  file_path: google/adk/agents/readonly_context.py
  type: CLASS
  group: Orphan
  usage_score: 0
  constructor_signature: 'def __init__(self, invocation_context: google.adk.agents.invocation_context.InvocationContext) -> None:'
  methods:
  - signature: 'def user_content(self) -> typing.Optional[google.genai.types.Content]:'
    docstring: The user content that started this invocation. READONLY field.
  - signature: 'def invocation_id(self) -> str:'
    docstring: The current invocation id.
  - signature: 'def agent_name(self) -> str:'
    docstring: The name of the agent that is currently running.
  - signature: 'def state(self) -> types.MappingProxyType[str, typing.Any]:'
    docstring: The state of the current session. READONLY field.
  - signature: 'def session(self) -> google.adk.sessions.session.Session:'
    docstring: The current session for this invocation.
  - signature: 'def user_id(self) -> str:'
    docstring: The id of the user. READONLY field.
  - signature: 'def run_config(self) -> typing.Optional[google.adk.agents.run_config.RunConfig]:'
    docstring: The run config of the current invocation. READONLY field.
- rank: 188
  id: google.adk.agents.readonly_context.ReadonlyContext.__init__
  name: __init__
  file_path: google/adk/agents/readonly_context.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def __init__(self, invocation_context: google.adk.agents.invocation_context.InvocationContext) -> None:'
- rank: 189
  id: google.adk.agents.remote_a2a_agent
  name: remote_a2a_agent
  file_path: google/adk/agents/remote_a2a_agent.py
  type: MODULE
  group: Orphan
  usage_score: 0
- rank: 190
  id: google.adk.agents.remote_a2a_agent.A2AClientError
  name: A2AClientError
  file_path: google/adk/agents/remote_a2a_agent.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Raised when A2A client operations fail.


    [Note: Inherited members from Exception are omitted.]'
  omitted_inherited_members_from:
  - Exception
- rank: 191
  id: google.adk.agents.remote_a2a_agent.AgentCardResolutionError
  name: AgentCardResolutionError
  file_path: google/adk/agents/remote_a2a_agent.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Raised when agent card resolution fails.


    [Note: Inherited members from Exception are omitted.]'
  omitted_inherited_members_from:
  - Exception
- rank: 192
  id: google.adk.agents.remote_a2a_agent.RemoteA2aAgent.__init__
  name: __init__
  file_path: google/adk/agents/remote_a2a_agent.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Initialize RemoteA2aAgent.\n\nArgs:\n  name: Agent name (must be unique identifier)\n  agent_card: AgentCard object, URL string, or file path string\n  description: Agent description (auto-populated from card if empty)\n  httpx_client: Optional shared HTTP client (will create own if not\n    provided) [deprecated] Use a2a_client_factory instead.\n  timeout: HTTP timeout in seconds\n  a2a_client_factory: Optional A2AClientFactory object (will create own if\n    not provided)\n  a2a_request_meta_provider: Optional callable that takes InvocationContext\n    and A2AMessage and returns a metadata object to attach to the A2A\n    request.\n  **kwargs: Additional arguments passed to BaseAgent\n\nRaises:\n  ValueError: If name is invalid or agent_card is None\n  TypeError: If agent_card is not a supported type"
  signature: 'def __init__(self, name: str, agent_card: typing.Union[a2a.types.AgentCard, str], *, description: str='''', httpx_client: typing.Optional[httpx.AsyncClient]=None, timeout: float=DEFAULT_TIMEOUT, genai_part_converter: google.adk.a2a.converters.part_converter.GenAIPartToA2APartConverter=convert_genai_part_to_a2a_part, a2a_part_converter: google.adk.a2a.converters.part_converter.A2APartToGenAIPartConverter=convert_a2a_part_to_genai_part, a2a_client_factory: typing.Optional[a2a.client.client_factory.ClientFactory]=None, a2a_request_meta_provider: typing.Optional[typing.Callable[[InvocationContext, A2AMessage], dict[str, typing.Any]]]=None) -> None:'
- rank: 193
  id: google.adk.agents.remote_a2a_agent.RemoteA2aAgent._run_async_impl
  name: _run_async_impl
  file_path: google/adk/agents/remote_a2a_agent.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: Core implementation for async agent execution.
  signature: 'def _run_async_impl(self, ctx: google.adk.agents.invocation_context.InvocationContext) -> typing.AsyncGenerator[google.adk.events.event.Event, None]:'
- rank: 194
  id: google.adk.agents.remote_a2a_agent.RemoteA2aAgent.cleanup
  name: cleanup
  file_path: google/adk/agents/remote_a2a_agent.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: Clean up resources, especially the HTTP client if owned by this agent.
  signature: 'def cleanup(self) -> None:'
- rank: 195
  id: google.adk.agents.run_config
  name: run_config
  file_path: google/adk/agents/run_config.py
  type: MODULE
  group: Orphan
  usage_score: 0
- rank: 196
  id: google.adk.agents.run_config.RunConfig.check_for_deprecated_save_live_audio
  name: check_for_deprecated_save_live_audio
  file_path: google/adk/agents/run_config.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: If save_live_audio is passed, use it to set save_live_blob.
  signature: 'def check_for_deprecated_save_live_audio(cls, data: typing.Any) -> typing.Any:'
- rank: 197
  id: google.adk.agents.run_config.RunConfig.validate_max_llm_calls
  name: validate_max_llm_calls
  file_path: google/adk/agents/run_config.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def validate_max_llm_calls(cls, value: int) -> int:'
- rank: 198
  id: google.adk.agents.run_config.StreamingMode
  name: StreamingMode
  file_path: google/adk/agents/run_config.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: '[Note: Inherited members from Enum are omitted.]'
  properties:
  - signature: 'NONE: NoneType'
  - signature: 'SSE: str'
  - signature: 'BIDI: str'
  omitted_inherited_members_from:
  - Enum
- rank: 199
  id: google.adk.agents.sequential_agent
  name: sequential_agent
  file_path: google/adk/agents/sequential_agent.py
  type: MODULE
  group: Orphan
  usage_score: 0
  docstring: Sequential agent implementation.
- rank: 200
  id: google.adk.agents.sequential_agent.SequentialAgent._run_async_impl
  name: _run_async_impl
  file_path: google/adk/agents/sequential_agent.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def _run_async_impl(self, ctx: google.adk.agents.invocation_context.InvocationContext) -> typing.AsyncGenerator[google.adk.events.event.Event, None]:'
- rank: 201
  id: google.adk.agents.sequential_agent.SequentialAgent.task_completed
  name: task_completed
  file_path: google/adk/agents/sequential_agent.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: 'Signals that the agent has successfully completed the user''s question

    or task.'
  signature: 'def task_completed():'
- rank: 202
  id: google.adk.agents.sequential_agent.SequentialAgentState
  name: SequentialAgentState
  file_path: google/adk/agents/sequential_agent.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'State for SequentialAgent.


    [Note: Inherited members from pydantic.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, current_sub_agent: str = ''''):'
  properties:
  - signature: 'current_sub_agent: str'
    docstring: The name of the current sub-agent to run.
  inherited_properties:
    BaseAgentState:
    - signature: 'model_config: pydantic.ConfigDict'
    BaseModel:
    - signature: 'model_config: pydantic.ConfigDict'
  omitted_inherited_members_from:
  - pydantic.BaseModel
- rank: 203
  id: google.adk.agents.sequential_agent_config
  name: sequential_agent_config
  file_path: google/adk/agents/sequential_agent_config.py
  type: MODULE
  group: Orphan
  usage_score: 0
  docstring: Config definition for SequentialAgent.
- rank: 204
  id: google.adk.agents.sequential_agent_config.SequentialAgentConfig
  name: SequentialAgentConfig
  file_path: google/adk/agents/sequential_agent_config.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'The config for the YAML schema of a SequentialAgent.


    [Note: Inherited members from pydantic.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, agent_class: typing.Union[typing.Literal[BaseAgent], str] = ''BaseAgent'', name: str, description: str = '''', sub_agents: typing.Optional[typing.List[google.adk.agents.common_configs.AgentRefConfig]] = None, before_agent_callbacks: typing.Optional[typing.List[google.adk.agents.common_configs.CodeConfig]] = None, after_agent_callbacks: typing.Optional[typing.List[google.adk.agents.common_configs.CodeConfig]] = None):'
  properties:
  - signature: 'model_config: pydantic.ConfigDict'
  - signature: 'agent_class: str'
  inherited_properties:
    BaseAgentConfig:
    - signature: 'model_config: pydantic.ConfigDict'
    - signature: 'agent_class: typing.Union[typing.Literal[BaseAgent], str]'
    - signature: 'name: str'
    - signature: 'description: str'
    - signature: 'sub_agents: typing.Optional[typing.List[google.adk.agents.common_configs.AgentRefConfig]]'
    - signature: 'before_agent_callbacks: typing.Optional[typing.List[google.adk.agents.common_configs.CodeConfig]]'
    - signature: 'after_agent_callbacks: typing.Optional[typing.List[google.adk.agents.common_configs.CodeConfig]]'
    BaseModel:
    - signature: 'model_config: pydantic.ConfigDict'
  omitted_inherited_members_from:
  - pydantic.BaseModel
- rank: 205
  id: google.adk.agents.transcription_entry
  name: transcription_entry
  file_path: google/adk/agents/transcription_entry.py
  type: MODULE
  group: Orphan
  usage_score: 0
- rank: 206
  id: google.adk.agents.transcription_entry.TranscriptionEntry
  name: TranscriptionEntry
  file_path: google/adk/agents/transcription_entry.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Store the data that can be used for transcription.


    [Note: Inherited members from pydantic.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, role: typing.Optional[str] = None, data: typing.Union[google.genai.types.Blob, google.genai.types.Content]):'
  properties:
  - signature: 'model_config: pydantic.ConfigDict'
    docstring: The pydantic model config.
  - signature: 'role: typing.Optional[str]'
    docstring: "The role that created this data, typically \"user\" or \"model\". For function \ncall, this is None."
  - signature: 'data: typing.Union[google.genai.types.Blob, google.genai.types.Content]'
    docstring: The data that can be used for transcription
  inherited_properties:
    BaseModel:
    - signature: 'model_config: pydantic.ConfigDict'
  omitted_inherited_members_from:
  - pydantic.BaseModel
- rank: 207
  id: google.adk.apps
  name: apps
  file_path: google/adk/apps/__init__.py
  type: MODULE
  group: Orphan
  usage_score: 0
- rank: 208
  id: google.adk.apps.app
  name: app
  file_path: google/adk/apps/app.py
  type: MODULE
  group: Orphan
  usage_score: 0
  methods:
  - signature: 'def validate_app_name(name: str) -> None:'
    docstring: Ensures the provided application name is safe and intuitive.
- rank: 209
  id: google.adk.apps.app.EventsCompactionConfig
  name: EventsCompactionConfig
  file_path: google/adk/apps/app.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'The config of event compaction for an application.


    [Note: Inherited members from pydantic.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, summarizer: typing.Optional[google.adk.apps.base_events_summarizer.BaseEventsSummarizer] = None, compaction_interval: int, overlap_size: int):'
  properties:
  - signature: 'model_config: pydantic.ConfigDict'
  - signature: 'summarizer: typing.Optional[google.adk.apps.base_events_summarizer.BaseEventsSummarizer]'
    docstring: The event summarizer to use for compaction.
  - signature: 'compaction_interval: int'
    docstring: 'The number of *new* user-initiated invocations that, once

      fully represented in the session''s events, will trigger a compaction.'
  - signature: 'overlap_size: int'
    docstring: 'The number of preceding invocations to include from the

      end of the last compacted range. This creates an overlap between consecutive

      compacted summaries, maintaining context.'
  inherited_properties:
    BaseModel:
    - signature: 'model_config: pydantic.ConfigDict'
  omitted_inherited_members_from:
  - pydantic.BaseModel
- rank: 210
  id: google.adk.apps.app.ResumabilityConfig
  name: ResumabilityConfig
  file_path: google/adk/apps/app.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'The config of the resumability for an application.


    The "resumability" in ADK refers to the ability to:

    1. pause an invocation upon a long running function call.

    2. resume an invocation from the last event, if it''s paused or failed midway

    through.


    Note: ADK resumes the invocation in a best-effort manner:

    1. Tool call to resume needs to be idempotent because we only guarantee

    an at-least-once behavior once resumed.

    2. Any temporary / in-memory state will be lost upon resumption.


    [Note: Inherited members from pydantic.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, is_resumable: bool = False):'
  properties:
  - signature: 'is_resumable: bool'
    docstring: 'Whether the app supports agent resumption.

      If enabled, the feature will be enabled for all agents in the app.'
  inherited_properties:
    BaseModel:
    - signature: 'model_config: pydantic.ConfigDict'
  omitted_inherited_members_from:
  - pydantic.BaseModel
- rank: 211
  id: google.adk.apps.app.validate_app_name
  name: validate_app_name
  file_path: google/adk/apps/app.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: Ensures the provided application name is safe and intuitive.
  signature: 'def validate_app_name(name: str) -> None:'
- rank: 212
  id: google.adk.apps.base_events_summarizer
  name: base_events_summarizer
  file_path: google/adk/apps/base_events_summarizer.py
  type: MODULE
  group: Orphan
  usage_score: 0
- rank: 213
  id: google.adk.apps.base_events_summarizer.BaseEventsSummarizer
  name: BaseEventsSummarizer
  file_path: google/adk/apps/base_events_summarizer.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Base interface for compacting events.


    [Note: Inherited members from abc.ABC are omitted.]'
  methods:
  - signature: 'def maybe_summarize_events(self, *, events: list[google.adk.events.event.Event]) -> typing.Optional[google.adk.events.event.Event]:'
    docstring: "Compact a list of events into a single event.\n\nIf compaction failed, return None. Otherwise, compact into a content and\nreturn it.\n\nThis method will summarize the events and return a new summary event\nindicating the range of events it summarized.\n\nArgs:\n  events: Events to compact.\n\nReturns:\n  The new compacted event, or None if no compaction happened."
  omitted_inherited_members_from:
  - abc.ABC
- rank: 214
  id: google.adk.apps.base_events_summarizer.BaseEventsSummarizer.maybe_summarize_events
  name: maybe_summarize_events
  file_path: google/adk/apps/base_events_summarizer.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Compact a list of events into a single event.\n\nIf compaction failed, return None. Otherwise, compact into a content and\nreturn it.\n\nThis method will summarize the events and return a new summary event\nindicating the range of events it summarized.\n\nArgs:\n  events: Events to compact.\n\nReturns:\n  The new compacted event, or None if no compaction happened."
  signature: 'def maybe_summarize_events(self, *, events: list[google.adk.events.event.Event]) -> typing.Optional[google.adk.events.event.Event]:'
- rank: 215
  id: google.adk.apps.compaction
  name: compaction
  file_path: google/adk/apps/compaction.py
  type: MODULE
  group: Orphan
  usage_score: 0
- rank: 216
  id: google.adk.apps.llm_event_summarizer
  name: llm_event_summarizer
  file_path: google/adk/apps/llm_event_summarizer.py
  type: MODULE
  group: Orphan
  usage_score: 0
- rank: 217
  id: google.adk.apps.llm_event_summarizer.LlmEventSummarizer
  name: LlmEventSummarizer
  file_path: google/adk/apps/llm_event_summarizer.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'An LLM-based event summarizer for sliding window compaction.


    This class is responsible for summarizing a provided list of events into a

    single compacted event. It is designed to be used as part of a sliding window

    compaction process.


    The actual logic for determining *when* to trigger compaction and *which*

    events form the sliding window (based on parameters like

    `compaction_invocation_threshold` and `overlap_size` from

    `EventsCompactionConfig`) is handled by an external component, such as an ADK

    "Runner". This compactor focuses solely on generating a summary of the events

    it receives.


    When `maybe_compact_events` is called with a list of events, this class

    formats the events, generates a summary using an LLM, and returns a new

    `Event` containing the summary within an `EventCompaction`.


    [Note: Inherited members from abc.ABC are omitted.]'
  constructor_signature: 'def __init__(self, llm: google.adk.models.base_llm.BaseLlm, prompt_template: typing.Optional[str]):'
  methods:
  - signature: 'def maybe_summarize_events(self, *, events: list[google.adk.events.event.Event]) -> typing.Optional[google.adk.events.event.Event]:'
    docstring: "Compacts given events and returns the compacted content.\n\nArgs:\n  events: A list of events to compact.\n\nReturns:\n  The new compacted event, or None if no compaction is needed."
  inherited_methods:
    BaseEventsSummarizer:
    - signature: 'def maybe_summarize_events(self, *, events: list[google.adk.events.event.Event]) -> typing.Optional[google.adk.events.event.Event]:'
      docstring: "Compact a list of events into a single event.\n\nIf compaction failed, return None. Otherwise, compact into a content and\nreturn it.\n\nThis method will summarize the events and return a new summary event\nindicating the range of events it summarized.\n\nArgs:\n  events: Events to compact.\n\nReturns:\n  The new compacted event, or None if no compaction happened."
  omitted_inherited_members_from:
  - abc.ABC
- rank: 218
  id: google.adk.apps.llm_event_summarizer.LlmEventSummarizer.__init__
  name: __init__
  file_path: google/adk/apps/llm_event_summarizer.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Initializes the LlmEventSummarizer.\n\nArgs:\n    llm: The LLM used for summarization.\n    prompt_template: An optional template string for the summarization\n      prompt. If not provided, a default template will be used. The template\n      should contain a '{conversation_history}' placeholder."
  signature: 'def __init__(self, llm: google.adk.models.base_llm.BaseLlm, prompt_template: typing.Optional[str]):'
- rank: 219
  id: google.adk.apps.llm_event_summarizer.LlmEventSummarizer.maybe_summarize_events
  name: maybe_summarize_events
  file_path: google/adk/apps/llm_event_summarizer.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Compacts given events and returns the compacted content.\n\nArgs:\n  events: A list of events to compact.\n\nReturns:\n  The new compacted event, or None if no compaction is needed."
  signature: 'def maybe_summarize_events(self, *, events: list[google.adk.events.event.Event]) -> typing.Optional[google.adk.events.event.Event]:'
- rank: 220
  id: google.adk.artifacts
  name: artifacts
  file_path: google/adk/artifacts/__init__.py
  type: MODULE
  group: Orphan
  usage_score: 0
- rank: 221
  id: google.adk.artifacts.artifact_util
  name: artifact_util
  file_path: google/adk/artifacts/artifact_util.py
  type: MODULE
  group: Orphan
  usage_score: 0
  docstring: Utility functions for handling artifact URIs.
  methods:
  - signature: 'def parse_artifact_uri(uri: str) -> typing.Optional[google.adk.artifacts.artifact_util.ParsedArtifactUri]:'
    docstring: "Parses an artifact URI.\n\nArgs:\n    uri: The artifact URI to parse.\n\nReturns:\n    A ParsedArtifactUri if parsing is successful, None otherwise."
  - signature: 'def get_artifact_uri(app_name: str, user_id: str, filename: str, version: int, session_id: typing.Optional[str]) -> str:'
    docstring: "Constructs an artifact URI.\n\nArgs:\n    app_name: The name of the application.\n    user_id: The ID of the user.\n    filename: The name of the artifact file.\n    version: The version of the artifact.\n    session_id: The ID of the session.\n\nReturns:\n    The constructed artifact URI."
  - signature: 'def is_artifact_ref(artifact: google.genai.types.Part) -> bool:'
    docstring: "Checks if an artifact part is an artifact reference.\n\nArgs:\n    artifact: The artifact part to check.\n\nReturns:\n    True if the artifact part is an artifact reference, False otherwise."
- rank: 222
  id: google.adk.artifacts.artifact_util.ParsedArtifactUri
  name: ParsedArtifactUri
  file_path: google/adk/artifacts/artifact_util.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'The result of parsing an artifact URI.


    [Note: Inherited members from NamedTuple are omitted.]'
  properties:
  - signature: 'app_name: str'
  - signature: 'user_id: str'
  - signature: 'session_id: typing.Optional[str]'
  - signature: 'filename: str'
  - signature: 'version: int'
  omitted_inherited_members_from:
  - NamedTuple
- rank: 223
  id: google.adk.artifacts.artifact_util.get_artifact_uri
  name: get_artifact_uri
  file_path: google/adk/artifacts/artifact_util.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Constructs an artifact URI.\n\nArgs:\n    app_name: The name of the application.\n    user_id: The ID of the user.\n    filename: The name of the artifact file.\n    version: The version of the artifact.\n    session_id: The ID of the session.\n\nReturns:\n    The constructed artifact URI."
  signature: 'def get_artifact_uri(app_name: str, user_id: str, filename: str, version: int, session_id: typing.Optional[str]) -> str:'
- rank: 224
  id: google.adk.artifacts.artifact_util.is_artifact_ref
  name: is_artifact_ref
  file_path: google/adk/artifacts/artifact_util.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Checks if an artifact part is an artifact reference.\n\nArgs:\n    artifact: The artifact part to check.\n\nReturns:\n    True if the artifact part is an artifact reference, False otherwise."
  signature: 'def is_artifact_ref(artifact: google.genai.types.Part) -> bool:'
- rank: 225
  id: google.adk.artifacts.artifact_util.parse_artifact_uri
  name: parse_artifact_uri
  file_path: google/adk/artifacts/artifact_util.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Parses an artifact URI.\n\nArgs:\n    uri: The artifact URI to parse.\n\nReturns:\n    A ParsedArtifactUri if parsing is successful, None otherwise."
  signature: 'def parse_artifact_uri(uri: str) -> typing.Optional[google.adk.artifacts.artifact_util.ParsedArtifactUri]:'
- rank: 226
  id: google.adk.artifacts.base_artifact_service
  name: base_artifact_service
  file_path: google/adk/artifacts/base_artifact_service.py
  type: MODULE
  group: Orphan
  usage_score: 0
- rank: 227
  id: google.adk.artifacts.base_artifact_service.ArtifactVersion
  name: ArtifactVersion
  file_path: google/adk/artifacts/base_artifact_service.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Metadata describing a specific version of an artifact.


    [Note: Inherited members from pydantic.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, version: int, canonical_uri: str, custom_metadata: dict[str, typing.Any] = dict(), create_time: float = Factory(lambda: datetime.now().timestamp()), mime_type: typing.Optional[str] = None):'
  properties:
  - signature: 'model_config: pydantic.ConfigDict'
  - signature: 'version: int'
  - signature: 'canonical_uri: str'
  - signature: 'custom_metadata: dict[str, typing.Any]'
  - signature: 'create_time: float'
  - signature: 'mime_type: typing.Optional[str]'
  inherited_properties:
    BaseModel:
    - signature: 'model_config: pydantic.ConfigDict'
  omitted_inherited_members_from:
  - pydantic.BaseModel
- rank: 228
  id: google.adk.artifacts.base_artifact_service.BaseArtifactService
  name: BaseArtifactService
  file_path: google/adk/artifacts/base_artifact_service.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Abstract base class for artifact services.


    [Note: Inherited members from ABC are omitted.]'
  aliases:
  - google.adk.artifacts.BaseArtifactService
  methods:
  - signature: 'def save_artifact(self, *, app_name: str, user_id: str, filename: str, artifact: google.genai.types.Part, session_id: typing.Optional[str]=None, custom_metadata: typing.Optional[dict[str, typing.Any]]=None) -> int:'
    docstring: "Saves an artifact to the artifact service storage.\n\nThe artifact is a file identified by the app name, user ID, session ID, and\nfilename. After saving the artifact, a revision ID is returned to identify\nthe artifact version.\n\nArgs:\n  app_name: The app name.\n  user_id: The user ID.\n  filename: The filename of the artifact.\n  artifact: The artifact to save. If the artifact consists of `file_data`,\n    the artifact service assumes its content has been uploaded separately,\n    and this method will associate the `file_data` with the artifact if\n    necessary.\n  session_id: The session ID. If `None`, the artifact is user-scoped.\n  custom_metadata: custom metadata to associate with the artifact.\n\nReturns:\n  The revision ID. The first version of the artifact has a revision ID of 0.\n  This is incremented by 1 after each successful save."
  - signature: 'def load_artifact(self, *, app_name: str, user_id: str, filename: str, session_id: typing.Optional[str]=None, version: typing.Optional[int]=None) -> typing.Optional[google.genai.types.Part]:'
    docstring: "Gets an artifact from the artifact service storage.\n\nThe artifact is a file identified by the app name, user ID, session ID, and\nfilename.\n\nArgs:\n  app_name: The app name.\n  user_id: The user ID.\n  filename: The filename of the artifact.\n  session_id: The session ID. If `None`, load the user-scoped artifact.\n  version: The version of the artifact. If None, the latest version will be\n    returned.\n\nReturns:\n  The artifact or None if not found."
  - signature: 'def list_artifact_keys(self, *, app_name: str, user_id: str, session_id: typing.Optional[str]=None) -> list[str]:'
    docstring: "Lists all the artifact filenames within a session.\n\nArgs:\n    app_name: The name of the application.\n    user_id: The ID of the user.\n    session_id: The ID of the session.\n\nReturns:\n    A list of artifact filenames. If `session_id` is provided, returns\n    both session-scoped and user-scoped artifact filenames. If `session_id`\n    is `None`, returns\n    user-scoped artifact filenames."
  - signature: 'def delete_artifact(self, *, app_name: str, user_id: str, filename: str, session_id: typing.Optional[str]=None) -> None:'
    docstring: "Deletes an artifact.\n\nArgs:\n    app_name: The name of the application.\n    user_id: The ID of the user.\n    filename: The name of the artifact file.\n    session_id: The ID of the session. If `None`, delete the user-scoped\n      artifact."
  - signature: 'def list_versions(self, *, app_name: str, user_id: str, filename: str, session_id: typing.Optional[str]=None) -> list[int]:'
    docstring: "Lists all versions of an artifact.\n\nArgs:\n    app_name: The name of the application.\n    user_id: The ID of the user.\n    filename: The name of the artifact file.\n    session_id: The ID of the session. If `None`, only list the user-scoped\n      artifacts versions.\n\nReturns:\n    A list of all available versions of the artifact."
  - signature: 'def list_artifact_versions(self, *, app_name: str, user_id: str, filename: str, session_id: typing.Optional[str]=None) -> list[google.adk.artifacts.base_artifact_service.ArtifactVersion]:'
    docstring: "Lists all versions and their metadata for a specific artifact.\n\nArgs:\n  app_name: The name of the application.\n  user_id: The ID of the user.\n  filename: The name of the artifact file.\n  session_id: The ID of the session. If `None`, lists versions of the\n    user-scoped artifact. Otherwise, lists versions of the artifact within\n    the specified session.\n\nReturns:\n  A list of ArtifactVersion objects, each representing a version of the\n  artifact and its associated metadata."
  - signature: 'def get_artifact_version(self, *, app_name: str, user_id: str, filename: str, session_id: typing.Optional[str]=None, version: typing.Optional[int]=None) -> typing.Optional[google.adk.artifacts.base_artifact_service.ArtifactVersion]:'
    docstring: "Gets the metadata for a specific version of an artifact.\n\nArgs:\n  app_name: The name of the application.\n  user_id: The ID of the user.\n  filename: The name of the artifact file.\n  session_id: The ID of the session. If `None`, the artifact will be fetched\n    from the user-scoped artifacts. Otherwise, it will be fetched from the\n    specified session.\n  version: The version number of the artifact to retrieve. If `None`, the\n    latest version will be returned.\n\nReturns:\n  An ArtifactVersion object containing the metadata of the specified\n  artifact version, or `None` if the artifact version is not found."
  omitted_inherited_members_from:
  - ABC
- rank: 229
  id: google.adk.artifacts.base_artifact_service.BaseArtifactService.delete_artifact
  name: delete_artifact
  file_path: google/adk/artifacts/base_artifact_service.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Deletes an artifact.\n\nArgs:\n    app_name: The name of the application.\n    user_id: The ID of the user.\n    filename: The name of the artifact file.\n    session_id: The ID of the session. If `None`, delete the user-scoped\n      artifact."
  signature: 'def delete_artifact(self, *, app_name: str, user_id: str, filename: str, session_id: typing.Optional[str]=None) -> None:'
- rank: 230
  id: google.adk.artifacts.base_artifact_service.BaseArtifactService.get_artifact_version
  name: get_artifact_version
  file_path: google/adk/artifacts/base_artifact_service.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Gets the metadata for a specific version of an artifact.\n\nArgs:\n  app_name: The name of the application.\n  user_id: The ID of the user.\n  filename: The name of the artifact file.\n  session_id: The ID of the session. If `None`, the artifact will be fetched\n    from the user-scoped artifacts. Otherwise, it will be fetched from the\n    specified session.\n  version: The version number of the artifact to retrieve. If `None`, the\n    latest version will be returned.\n\nReturns:\n  An ArtifactVersion object containing the metadata of the specified\n  artifact version, or `None` if the artifact version is not found."
  signature: 'def get_artifact_version(self, *, app_name: str, user_id: str, filename: str, session_id: typing.Optional[str]=None, version: typing.Optional[int]=None) -> typing.Optional[google.adk.artifacts.base_artifact_service.ArtifactVersion]:'
- rank: 231
  id: google.adk.artifacts.base_artifact_service.BaseArtifactService.list_artifact_keys
  name: list_artifact_keys
  file_path: google/adk/artifacts/base_artifact_service.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Lists all the artifact filenames within a session.\n\nArgs:\n    app_name: The name of the application.\n    user_id: The ID of the user.\n    session_id: The ID of the session.\n\nReturns:\n    A list of artifact filenames. If `session_id` is provided, returns\n    both session-scoped and user-scoped artifact filenames. If `session_id`\n    is `None`, returns\n    user-scoped artifact filenames."
  signature: 'def list_artifact_keys(self, *, app_name: str, user_id: str, session_id: typing.Optional[str]=None) -> list[str]:'
- rank: 232
  id: google.adk.artifacts.base_artifact_service.BaseArtifactService.list_artifact_versions
  name: list_artifact_versions
  file_path: google/adk/artifacts/base_artifact_service.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Lists all versions and their metadata for a specific artifact.\n\nArgs:\n  app_name: The name of the application.\n  user_id: The ID of the user.\n  filename: The name of the artifact file.\n  session_id: The ID of the session. If `None`, lists versions of the\n    user-scoped artifact. Otherwise, lists versions of the artifact within\n    the specified session.\n\nReturns:\n  A list of ArtifactVersion objects, each representing a version of the\n  artifact and its associated metadata."
  signature: 'def list_artifact_versions(self, *, app_name: str, user_id: str, filename: str, session_id: typing.Optional[str]=None) -> list[google.adk.artifacts.base_artifact_service.ArtifactVersion]:'
- rank: 233
  id: google.adk.artifacts.base_artifact_service.BaseArtifactService.list_versions
  name: list_versions
  file_path: google/adk/artifacts/base_artifact_service.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Lists all versions of an artifact.\n\nArgs:\n    app_name: The name of the application.\n    user_id: The ID of the user.\n    filename: The name of the artifact file.\n    session_id: The ID of the session. If `None`, only list the user-scoped\n      artifacts versions.\n\nReturns:\n    A list of all available versions of the artifact."
  signature: 'def list_versions(self, *, app_name: str, user_id: str, filename: str, session_id: typing.Optional[str]=None) -> list[int]:'
- rank: 234
  id: google.adk.artifacts.base_artifact_service.BaseArtifactService.load_artifact
  name: load_artifact
  file_path: google/adk/artifacts/base_artifact_service.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Gets an artifact from the artifact service storage.\n\nThe artifact is a file identified by the app name, user ID, session ID, and\nfilename.\n\nArgs:\n  app_name: The app name.\n  user_id: The user ID.\n  filename: The filename of the artifact.\n  session_id: The session ID. If `None`, load the user-scoped artifact.\n  version: The version of the artifact. If None, the latest version will be\n    returned.\n\nReturns:\n  The artifact or None if not found."
  signature: 'def load_artifact(self, *, app_name: str, user_id: str, filename: str, session_id: typing.Optional[str]=None, version: typing.Optional[int]=None) -> typing.Optional[google.genai.types.Part]:'
- rank: 235
  id: google.adk.artifacts.base_artifact_service.BaseArtifactService.save_artifact
  name: save_artifact
  file_path: google/adk/artifacts/base_artifact_service.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Saves an artifact to the artifact service storage.\n\nThe artifact is a file identified by the app name, user ID, session ID, and\nfilename. After saving the artifact, a revision ID is returned to identify\nthe artifact version.\n\nArgs:\n  app_name: The app name.\n  user_id: The user ID.\n  filename: The filename of the artifact.\n  artifact: The artifact to save. If the artifact consists of `file_data`,\n    the artifact service assumes its content has been uploaded separately,\n    and this method will associate the `file_data` with the artifact if\n    necessary.\n  session_id: The session ID. If `None`, the artifact is user-scoped.\n  custom_metadata: custom metadata to associate with the artifact.\n\nReturns:\n  The revision ID. The first version of the artifact has a revision ID of 0.\n  This is incremented by 1 after each successful save."
  signature: 'def save_artifact(self, *, app_name: str, user_id: str, filename: str, artifact: google.genai.types.Part, session_id: typing.Optional[str]=None, custom_metadata: typing.Optional[dict[str, typing.Any]]=None) -> int:'
- rank: 236
  id: google.adk.artifacts.file_artifact_service
  name: file_artifact_service
  file_path: google/adk/artifacts/file_artifact_service.py
  type: MODULE
  group: Orphan
  usage_score: 0
- rank: 237
  id: google.adk.artifacts.file_artifact_service.FileArtifactService
  name: FileArtifactService
  file_path: google/adk/artifacts/file_artifact_service.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Stores filesystem-backed artifacts beneath a configurable root directory.


    [Note: Inherited members from ABC are omitted.]'
  constructor_signature: 'def __init__(self, root_dir: Path | str):'
  methods:
  - signature: 'def save_artifact(self, *, app_name: str, user_id: str, filename: str, artifact: google.genai.types.Part, session_id: typing.Optional[str]=None, custom_metadata: typing.Optional[dict[str, typing.Any]]=None) -> int:'
    docstring: 'Persists an artifact to disk.


      Filenames may be simple (``"report.txt"``), nested

      (``"images/photo.png"``), or explicitly user-scoped

      (``"user:shared/diagram.png"``). All values are interpreted relative to the

      computed scope root; absolute paths or inputs that traverse outside that

      root (for example ``"../../secret.txt"``) raise ``ValueError``.'
  - signature: 'def load_artifact(self, *, app_name: str, user_id: str, filename: str, session_id: typing.Optional[str]=None, version: typing.Optional[int]=None) -> typing.Optional[google.genai.types.Part]:'
  - signature: 'def list_artifact_keys(self, *, app_name: str, user_id: str, session_id: typing.Optional[str]=None) -> list[str]:'
  - signature: 'def delete_artifact(self, *, app_name: str, user_id: str, filename: str, session_id: typing.Optional[str]=None) -> None:'
    docstring: "Deletes an artifact.\n\nArgs:\n    app_name: The name of the application.\n    user_id: The ID of the user.\n    filename: The name of the artifact file.\n    session_id: The ID of the session. Leave unset for user-scoped\n      artifacts."
  - signature: 'def list_versions(self, *, app_name: str, user_id: str, filename: str, session_id: typing.Optional[str]=None) -> list[int]:'
    docstring: Lists all versions stored for an artifact.
  - signature: 'def list_artifact_versions(self, *, app_name: str, user_id: str, filename: str, session_id: typing.Optional[str]=None) -> list[google.adk.artifacts.base_artifact_service.ArtifactVersion]:'
    docstring: Lists metadata for each artifact version on disk.
  - signature: 'def get_artifact_version(self, *, app_name: str, user_id: str, filename: str, session_id: typing.Optional[str]=None, version: typing.Optional[int]=None) -> typing.Optional[google.adk.artifacts.base_artifact_service.ArtifactVersion]:'
    docstring: Gets metadata for a specific artifact version.
  inherited_methods:
    BaseArtifactService:
    - signature: 'def save_artifact(self, *, app_name: str, user_id: str, filename: str, artifact: google.genai.types.Part, session_id: typing.Optional[str]=None, custom_metadata: typing.Optional[dict[str, typing.Any]]=None) -> int:'
      docstring: "Saves an artifact to the artifact service storage.\n\nThe artifact is a file identified by the app name, user ID, session ID, and\nfilename. After saving the artifact, a revision ID is returned to identify\nthe artifact version.\n\nArgs:\n  app_name: The app name.\n  user_id: The user ID.\n  filename: The filename of the artifact.\n  artifact: The artifact to save. If the artifact consists of `file_data`,\n    the artifact service assumes its content has been uploaded separately,\n    and this method will associate the `file_data` with the artifact if\n    necessary.\n  session_id: The session ID. If `None`, the artifact is user-scoped.\n  custom_metadata: custom metadata to associate with the artifact.\n\nReturns:\n  The revision ID. The first version of the artifact has a revision ID of 0.\n  This is incremented by 1 after each successful save."
    - signature: 'def load_artifact(self, *, app_name: str, user_id: str, filename: str, session_id: typing.Optional[str]=None, version: typing.Optional[int]=None) -> typing.Optional[google.genai.types.Part]:'
      docstring: "Gets an artifact from the artifact service storage.\n\nThe artifact is a file identified by the app name, user ID, session ID, and\nfilename.\n\nArgs:\n  app_name: The app name.\n  user_id: The user ID.\n  filename: The filename of the artifact.\n  session_id: The session ID. If `None`, load the user-scoped artifact.\n  version: The version of the artifact. If None, the latest version will be\n    returned.\n\nReturns:\n  The artifact or None if not found."
    - signature: 'def list_artifact_keys(self, *, app_name: str, user_id: str, session_id: typing.Optional[str]=None) -> list[str]:'
      docstring: "Lists all the artifact filenames within a session.\n\nArgs:\n    app_name: The name of the application.\n    user_id: The ID of the user.\n    session_id: The ID of the session.\n\nReturns:\n    A list of artifact filenames. If `session_id` is provided, returns\n    both session-scoped and user-scoped artifact filenames. If `session_id`\n    is `None`, returns\n    user-scoped artifact filenames."
    - signature: 'def delete_artifact(self, *, app_name: str, user_id: str, filename: str, session_id: typing.Optional[str]=None) -> None:'
      docstring: "Deletes an artifact.\n\nArgs:\n    app_name: The name of the application.\n    user_id: The ID of the user.\n    filename: The name of the artifact file.\n    session_id: The ID of the session. If `None`, delete the user-scoped\n      artifact."
    - signature: 'def list_versions(self, *, app_name: str, user_id: str, filename: str, session_id: typing.Optional[str]=None) -> list[int]:'
      docstring: "Lists all versions of an artifact.\n\nArgs:\n    app_name: The name of the application.\n    user_id: The ID of the user.\n    filename: The name of the artifact file.\n    session_id: The ID of the session. If `None`, only list the user-scoped\n      artifacts versions.\n\nReturns:\n    A list of all available versions of the artifact."
    - signature: 'def list_artifact_versions(self, *, app_name: str, user_id: str, filename: str, session_id: typing.Optional[str]=None) -> list[google.adk.artifacts.base_artifact_service.ArtifactVersion]:'
      docstring: "Lists all versions and their metadata for a specific artifact.\n\nArgs:\n  app_name: The name of the application.\n  user_id: The ID of the user.\n  filename: The name of the artifact file.\n  session_id: The ID of the session. If `None`, lists versions of the\n    user-scoped artifact. Otherwise, lists versions of the artifact within\n    the specified session.\n\nReturns:\n  A list of ArtifactVersion objects, each representing a version of the\n  artifact and its associated metadata."
    - signature: 'def get_artifact_version(self, *, app_name: str, user_id: str, filename: str, session_id: typing.Optional[str]=None, version: typing.Optional[int]=None) -> typing.Optional[google.adk.artifacts.base_artifact_service.ArtifactVersion]:'
      docstring: "Gets the metadata for a specific version of an artifact.\n\nArgs:\n  app_name: The name of the application.\n  user_id: The ID of the user.\n  filename: The name of the artifact file.\n  session_id: The ID of the session. If `None`, the artifact will be fetched\n    from the user-scoped artifacts. Otherwise, it will be fetched from the\n    specified session.\n  version: The version number of the artifact to retrieve. If `None`, the\n    latest version will be returned.\n\nReturns:\n  An ArtifactVersion object containing the metadata of the specified\n  artifact version, or `None` if the artifact version is not found."
  omitted_inherited_members_from:
  - ABC
- rank: 238
  id: google.adk.artifacts.file_artifact_service.FileArtifactService.__init__
  name: __init__
  file_path: google/adk/artifacts/file_artifact_service.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Initializes the file-based artifact service.\n\nArgs:\n  root_dir: The directory that will contain artifact data."
  signature: 'def __init__(self, root_dir: Path | str):'
- rank: 239
  id: google.adk.artifacts.file_artifact_service.FileArtifactService.delete_artifact
  name: delete_artifact
  file_path: google/adk/artifacts/file_artifact_service.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Deletes an artifact.\n\nArgs:\n    app_name: The name of the application.\n    user_id: The ID of the user.\n    filename: The name of the artifact file.\n    session_id: The ID of the session. Leave unset for user-scoped\n      artifacts."
  signature: 'def delete_artifact(self, *, app_name: str, user_id: str, filename: str, session_id: typing.Optional[str]=None) -> None:'
- rank: 240
  id: google.adk.artifacts.file_artifact_service.FileArtifactService.get_artifact_version
  name: get_artifact_version
  file_path: google/adk/artifacts/file_artifact_service.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: Gets metadata for a specific artifact version.
  signature: 'def get_artifact_version(self, *, app_name: str, user_id: str, filename: str, session_id: typing.Optional[str]=None, version: typing.Optional[int]=None) -> typing.Optional[google.adk.artifacts.base_artifact_service.ArtifactVersion]:'
- rank: 241
  id: google.adk.artifacts.file_artifact_service.FileArtifactService.list_artifact_keys
  name: list_artifact_keys
  file_path: google/adk/artifacts/file_artifact_service.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def list_artifact_keys(self, *, app_name: str, user_id: str, session_id: typing.Optional[str]=None) -> list[str]:'
- rank: 242
  id: google.adk.artifacts.file_artifact_service.FileArtifactService.list_artifact_versions
  name: list_artifact_versions
  file_path: google/adk/artifacts/file_artifact_service.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: Lists metadata for each artifact version on disk.
  signature: 'def list_artifact_versions(self, *, app_name: str, user_id: str, filename: str, session_id: typing.Optional[str]=None) -> list[google.adk.artifacts.base_artifact_service.ArtifactVersion]:'
- rank: 243
  id: google.adk.artifacts.file_artifact_service.FileArtifactService.list_versions
  name: list_versions
  file_path: google/adk/artifacts/file_artifact_service.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: Lists all versions stored for an artifact.
  signature: 'def list_versions(self, *, app_name: str, user_id: str, filename: str, session_id: typing.Optional[str]=None) -> list[int]:'
- rank: 244
  id: google.adk.artifacts.file_artifact_service.FileArtifactService.load_artifact
  name: load_artifact
  file_path: google/adk/artifacts/file_artifact_service.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def load_artifact(self, *, app_name: str, user_id: str, filename: str, session_id: typing.Optional[str]=None, version: typing.Optional[int]=None) -> typing.Optional[google.genai.types.Part]:'
- rank: 245
  id: google.adk.artifacts.file_artifact_service.FileArtifactService.save_artifact
  name: save_artifact
  file_path: google/adk/artifacts/file_artifact_service.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: 'Persists an artifact to disk.


    Filenames may be simple (``"report.txt"``), nested

    (``"images/photo.png"``), or explicitly user-scoped

    (``"user:shared/diagram.png"``). All values are interpreted relative to the

    computed scope root; absolute paths or inputs that traverse outside that

    root (for example ``"../../secret.txt"``) raise ``ValueError``.'
  signature: 'def save_artifact(self, *, app_name: str, user_id: str, filename: str, artifact: google.genai.types.Part, session_id: typing.Optional[str]=None, custom_metadata: typing.Optional[dict[str, typing.Any]]=None) -> int:'
- rank: 246
  id: google.adk.artifacts.file_artifact_service.FileArtifactVersion
  name: FileArtifactVersion
  file_path: google/adk/artifacts/file_artifact_service.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Represents persisted metadata for a file-backed artifact.


    [Note: Inherited members from pydantic.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, version: int, canonical_uri: str, custom_metadata: dict[str, typing.Any] = dict(), create_time: float = Factory(lambda: datetime.now().timestamp()), mime_type: typing.Optional[str] = None, file_name: str):'
  properties:
  - signature: 'model_config: pydantic.ConfigDict'
  - signature: 'file_name: str'
  inherited_properties:
    ArtifactVersion:
    - signature: 'model_config: pydantic.ConfigDict'
    - signature: 'version: int'
    - signature: 'canonical_uri: str'
    - signature: 'custom_metadata: dict[str, typing.Any]'
    - signature: 'create_time: float'
    - signature: 'mime_type: typing.Optional[str]'
    BaseModel:
    - signature: 'model_config: pydantic.ConfigDict'
  omitted_inherited_members_from:
  - pydantic.BaseModel
- rank: 247
  id: google.adk.artifacts.gcs_artifact_service
  name: gcs_artifact_service
  file_path: google/adk/artifacts/gcs_artifact_service.py
  type: MODULE
  group: Orphan
  usage_score: 0
  docstring: "An artifact service implementation using Google Cloud Storage (GCS).\n\nThe blob name format used depends on whether the filename has a user namespace:\n  - For files with user namespace (starting with \"user:\"):\n    {app_name}/{user_id}/user/{filename}/{version}\n  - For regular session-scoped files:\n    {app_name}/{user_id}/{session_id}/{filename}/{version}"
- rank: 248
  id: google.adk.artifacts.gcs_artifact_service.GcsArtifactService
  name: GcsArtifactService
  file_path: google/adk/artifacts/gcs_artifact_service.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'An artifact service implementation using Google Cloud Storage (GCS).


    [Note: Inherited members from ABC are omitted.]'
  constructor_signature: 'def __init__(self, bucket_name: str):'
  methods:
  - signature: 'def save_artifact(self, *, app_name: str, user_id: str, filename: str, artifact: google.genai.types.Part, session_id: typing.Optional[str]=None, custom_metadata: typing.Optional[dict[str, typing.Any]]=None) -> int:'
  - signature: 'def load_artifact(self, *, app_name: str, user_id: str, filename: str, session_id: typing.Optional[str]=None, version: typing.Optional[int]=None) -> typing.Optional[google.genai.types.Part]:'
  - signature: 'def list_artifact_keys(self, *, app_name: str, user_id: str, session_id: typing.Optional[str]=None) -> list[str]:'
  - signature: 'def delete_artifact(self, *, app_name: str, user_id: str, filename: str, session_id: typing.Optional[str]=None) -> None:'
  - signature: 'def list_versions(self, *, app_name: str, user_id: str, filename: str, session_id: typing.Optional[str]=None) -> list[int]:'
  - signature: 'def list_artifact_versions(self, *, app_name: str, user_id: str, filename: str, session_id: typing.Optional[str]=None) -> list[google.adk.artifacts.base_artifact_service.ArtifactVersion]:'
  - signature: 'def get_artifact_version(self, *, app_name: str, user_id: str, filename: str, session_id: typing.Optional[str]=None, version: typing.Optional[int]=None) -> typing.Optional[google.adk.artifacts.base_artifact_service.ArtifactVersion]:'
  inherited_methods:
    BaseArtifactService:
    - signature: 'def save_artifact(self, *, app_name: str, user_id: str, filename: str, artifact: google.genai.types.Part, session_id: typing.Optional[str]=None, custom_metadata: typing.Optional[dict[str, typing.Any]]=None) -> int:'
      docstring: "Saves an artifact to the artifact service storage.\n\nThe artifact is a file identified by the app name, user ID, session ID, and\nfilename. After saving the artifact, a revision ID is returned to identify\nthe artifact version.\n\nArgs:\n  app_name: The app name.\n  user_id: The user ID.\n  filename: The filename of the artifact.\n  artifact: The artifact to save. If the artifact consists of `file_data`,\n    the artifact service assumes its content has been uploaded separately,\n    and this method will associate the `file_data` with the artifact if\n    necessary.\n  session_id: The session ID. If `None`, the artifact is user-scoped.\n  custom_metadata: custom metadata to associate with the artifact.\n\nReturns:\n  The revision ID. The first version of the artifact has a revision ID of 0.\n  This is incremented by 1 after each successful save."
    - signature: 'def load_artifact(self, *, app_name: str, user_id: str, filename: str, session_id: typing.Optional[str]=None, version: typing.Optional[int]=None) -> typing.Optional[google.genai.types.Part]:'
      docstring: "Gets an artifact from the artifact service storage.\n\nThe artifact is a file identified by the app name, user ID, session ID, and\nfilename.\n\nArgs:\n  app_name: The app name.\n  user_id: The user ID.\n  filename: The filename of the artifact.\n  session_id: The session ID. If `None`, load the user-scoped artifact.\n  version: The version of the artifact. If None, the latest version will be\n    returned.\n\nReturns:\n  The artifact or None if not found."
    - signature: 'def list_artifact_keys(self, *, app_name: str, user_id: str, session_id: typing.Optional[str]=None) -> list[str]:'
      docstring: "Lists all the artifact filenames within a session.\n\nArgs:\n    app_name: The name of the application.\n    user_id: The ID of the user.\n    session_id: The ID of the session.\n\nReturns:\n    A list of artifact filenames. If `session_id` is provided, returns\n    both session-scoped and user-scoped artifact filenames. If `session_id`\n    is `None`, returns\n    user-scoped artifact filenames."
    - signature: 'def delete_artifact(self, *, app_name: str, user_id: str, filename: str, session_id: typing.Optional[str]=None) -> None:'
      docstring: "Deletes an artifact.\n\nArgs:\n    app_name: The name of the application.\n    user_id: The ID of the user.\n    filename: The name of the artifact file.\n    session_id: The ID of the session. If `None`, delete the user-scoped\n      artifact."
    - signature: 'def list_versions(self, *, app_name: str, user_id: str, filename: str, session_id: typing.Optional[str]=None) -> list[int]:'
      docstring: "Lists all versions of an artifact.\n\nArgs:\n    app_name: The name of the application.\n    user_id: The ID of the user.\n    filename: The name of the artifact file.\n    session_id: The ID of the session. If `None`, only list the user-scoped\n      artifacts versions.\n\nReturns:\n    A list of all available versions of the artifact."
    - signature: 'def list_artifact_versions(self, *, app_name: str, user_id: str, filename: str, session_id: typing.Optional[str]=None) -> list[google.adk.artifacts.base_artifact_service.ArtifactVersion]:'
      docstring: "Lists all versions and their metadata for a specific artifact.\n\nArgs:\n  app_name: The name of the application.\n  user_id: The ID of the user.\n  filename: The name of the artifact file.\n  session_id: The ID of the session. If `None`, lists versions of the\n    user-scoped artifact. Otherwise, lists versions of the artifact within\n    the specified session.\n\nReturns:\n  A list of ArtifactVersion objects, each representing a version of the\n  artifact and its associated metadata."
    - signature: 'def get_artifact_version(self, *, app_name: str, user_id: str, filename: str, session_id: typing.Optional[str]=None, version: typing.Optional[int]=None) -> typing.Optional[google.adk.artifacts.base_artifact_service.ArtifactVersion]:'
      docstring: "Gets the metadata for a specific version of an artifact.\n\nArgs:\n  app_name: The name of the application.\n  user_id: The ID of the user.\n  filename: The name of the artifact file.\n  session_id: The ID of the session. If `None`, the artifact will be fetched\n    from the user-scoped artifacts. Otherwise, it will be fetched from the\n    specified session.\n  version: The version number of the artifact to retrieve. If `None`, the\n    latest version will be returned.\n\nReturns:\n  An ArtifactVersion object containing the metadata of the specified\n  artifact version, or `None` if the artifact version is not found."
  omitted_inherited_members_from:
  - ABC
- rank: 249
  id: google.adk.artifacts.gcs_artifact_service.GcsArtifactService.__init__
  name: __init__
  file_path: google/adk/artifacts/gcs_artifact_service.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Initializes the GcsArtifactService.\n\nArgs:\n    bucket_name: The name of the bucket to use.\n    **kwargs: Keyword arguments to pass to the Google Cloud Storage client."
  signature: 'def __init__(self, bucket_name: str):'
- rank: 250
  id: google.adk.artifacts.gcs_artifact_service.GcsArtifactService.delete_artifact
  name: delete_artifact
  file_path: google/adk/artifacts/gcs_artifact_service.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def delete_artifact(self, *, app_name: str, user_id: str, filename: str, session_id: typing.Optional[str]=None) -> None:'
- rank: 251
  id: google.adk.artifacts.gcs_artifact_service.GcsArtifactService.get_artifact_version
  name: get_artifact_version
  file_path: google/adk/artifacts/gcs_artifact_service.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def get_artifact_version(self, *, app_name: str, user_id: str, filename: str, session_id: typing.Optional[str]=None, version: typing.Optional[int]=None) -> typing.Optional[google.adk.artifacts.base_artifact_service.ArtifactVersion]:'
- rank: 252
  id: google.adk.artifacts.gcs_artifact_service.GcsArtifactService.list_artifact_keys
  name: list_artifact_keys
  file_path: google/adk/artifacts/gcs_artifact_service.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def list_artifact_keys(self, *, app_name: str, user_id: str, session_id: typing.Optional[str]=None) -> list[str]:'
- rank: 253
  id: google.adk.artifacts.gcs_artifact_service.GcsArtifactService.list_artifact_versions
  name: list_artifact_versions
  file_path: google/adk/artifacts/gcs_artifact_service.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def list_artifact_versions(self, *, app_name: str, user_id: str, filename: str, session_id: typing.Optional[str]=None) -> list[google.adk.artifacts.base_artifact_service.ArtifactVersion]:'
- rank: 254
  id: google.adk.artifacts.gcs_artifact_service.GcsArtifactService.list_versions
  name: list_versions
  file_path: google/adk/artifacts/gcs_artifact_service.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def list_versions(self, *, app_name: str, user_id: str, filename: str, session_id: typing.Optional[str]=None) -> list[int]:'
- rank: 255
  id: google.adk.artifacts.gcs_artifact_service.GcsArtifactService.load_artifact
  name: load_artifact
  file_path: google/adk/artifacts/gcs_artifact_service.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def load_artifact(self, *, app_name: str, user_id: str, filename: str, session_id: typing.Optional[str]=None, version: typing.Optional[int]=None) -> typing.Optional[google.genai.types.Part]:'
- rank: 256
  id: google.adk.artifacts.gcs_artifact_service.GcsArtifactService.save_artifact
  name: save_artifact
  file_path: google/adk/artifacts/gcs_artifact_service.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def save_artifact(self, *, app_name: str, user_id: str, filename: str, artifact: google.genai.types.Part, session_id: typing.Optional[str]=None, custom_metadata: typing.Optional[dict[str, typing.Any]]=None) -> int:'
- rank: 257
  id: google.adk.artifacts.in_memory_artifact_service
  name: in_memory_artifact_service
  file_path: google/adk/artifacts/in_memory_artifact_service.py
  type: MODULE
  group: Orphan
  usage_score: 0
- rank: 258
  id: google.adk.artifacts.in_memory_artifact_service.InMemoryArtifactService.delete_artifact
  name: delete_artifact
  file_path: google/adk/artifacts/in_memory_artifact_service.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def delete_artifact(self, *, app_name: str, user_id: str, filename: str, session_id: typing.Optional[str]=None) -> None:'
- rank: 259
  id: google.adk.artifacts.in_memory_artifact_service.InMemoryArtifactService.get_artifact_version
  name: get_artifact_version
  file_path: google/adk/artifacts/in_memory_artifact_service.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def get_artifact_version(self, *, app_name: str, user_id: str, filename: str, session_id: typing.Optional[str]=None, version: typing.Optional[int]=None) -> typing.Optional[google.adk.artifacts.base_artifact_service.ArtifactVersion]:'
- rank: 260
  id: google.adk.artifacts.in_memory_artifact_service.InMemoryArtifactService.list_artifact_keys
  name: list_artifact_keys
  file_path: google/adk/artifacts/in_memory_artifact_service.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def list_artifact_keys(self, *, app_name: str, user_id: str, session_id: typing.Optional[str]=None) -> list[str]:'
- rank: 261
  id: google.adk.artifacts.in_memory_artifact_service.InMemoryArtifactService.list_artifact_versions
  name: list_artifact_versions
  file_path: google/adk/artifacts/in_memory_artifact_service.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def list_artifact_versions(self, *, app_name: str, user_id: str, filename: str, session_id: typing.Optional[str]=None) -> list[google.adk.artifacts.base_artifact_service.ArtifactVersion]:'
- rank: 262
  id: google.adk.artifacts.in_memory_artifact_service.InMemoryArtifactService.list_versions
  name: list_versions
  file_path: google/adk/artifacts/in_memory_artifact_service.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def list_versions(self, *, app_name: str, user_id: str, filename: str, session_id: typing.Optional[str]=None) -> list[int]:'
- rank: 263
  id: google.adk.artifacts.in_memory_artifact_service.InMemoryArtifactService.load_artifact
  name: load_artifact
  file_path: google/adk/artifacts/in_memory_artifact_service.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def load_artifact(self, *, app_name: str, user_id: str, filename: str, session_id: typing.Optional[str]=None, version: typing.Optional[int]=None) -> typing.Optional[google.genai.types.Part]:'
- rank: 264
  id: google.adk.artifacts.in_memory_artifact_service.InMemoryArtifactService.save_artifact
  name: save_artifact
  file_path: google/adk/artifacts/in_memory_artifact_service.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def save_artifact(self, *, app_name: str, user_id: str, filename: str, artifact: google.genai.types.Part, session_id: typing.Optional[str]=None, custom_metadata: typing.Optional[dict[str, typing.Any]]=None) -> int:'
- rank: 265
  id: google.adk.auth
  name: auth
  file_path: google/adk/auth/__init__.py
  type: MODULE
  group: Orphan
  usage_score: 0
- rank: 266
  id: google.adk.auth.auth_credential
  name: auth_credential
  file_path: google/adk/auth/auth_credential.py
  type: MODULE
  group: Orphan
  usage_score: 0
- rank: 267
  id: google.adk.auth.auth_credential.AuthCredentialTypes
  name: AuthCredentialTypes
  file_path: google/adk/auth/auth_credential.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Represents the type of authentication credential.


    [Note: Inherited members from Enum, str are omitted.]'
  properties:
  - signature: 'API_KEY: str'
  - signature: 'HTTP: str'
  - signature: 'OAUTH2: str'
  - signature: 'OPEN_ID_CONNECT: str'
  - signature: 'SERVICE_ACCOUNT: str'
  omitted_inherited_members_from:
  - str
  - Enum
- rank: 268
  id: google.adk.auth.auth_credential.BaseModelWithConfig
  name: BaseModelWithConfig
  file_path: google/adk/auth/auth_credential.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: '[Note: Inherited members from pydantic.BaseModel are omitted.]'
  properties:
  - signature: 'model_config: pydantic.ConfigDict'
    docstring: The pydantic model config.
  inherited_properties:
    BaseModel:
    - signature: 'model_config: pydantic.ConfigDict'
  omitted_inherited_members_from:
  - pydantic.BaseModel
- rank: 269
  id: google.adk.auth.auth_credential.HttpAuth
  name: HttpAuth
  file_path: google/adk/auth/auth_credential.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'The credentials and metadata for HTTP authentication.


    [Note: Inherited members from pydantic.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, scheme: str, credentials: google.adk.auth.auth_credential.HttpCredentials):'
  properties:
  - signature: 'scheme: str'
  - signature: 'credentials: google.adk.auth.auth_credential.HttpCredentials'
  inherited_properties:
    BaseModelWithConfig:
    - signature: 'model_config: pydantic.ConfigDict'
      docstring: The pydantic model config.
    BaseModel:
    - signature: 'model_config: pydantic.ConfigDict'
  omitted_inherited_members_from:
  - pydantic.BaseModel
- rank: 270
  id: google.adk.auth.auth_credential.HttpCredentials
  name: HttpCredentials
  file_path: google/adk/auth/auth_credential.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Represents the secret token value for HTTP authentication, like user name, password, oauth token, etc.


    [Note: Inherited members from pydantic.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, username: typing.Optional[str] = None, password: typing.Optional[str] = None, token: typing.Optional[str] = None):'
  methods:
  - signature: 'def model_validate(cls, data: typing.Dict[str, typing.Any]) -> google.adk.auth.auth_credential.HttpCredentials:'
  properties:
  - signature: 'username: typing.Optional[str]'
  - signature: 'password: typing.Optional[str]'
  - signature: 'token: typing.Optional[str]'
  inherited_properties:
    BaseModelWithConfig:
    - signature: 'model_config: pydantic.ConfigDict'
      docstring: The pydantic model config.
    BaseModel:
    - signature: 'model_config: pydantic.ConfigDict'
  omitted_inherited_members_from:
  - pydantic.BaseModel
- rank: 271
  id: google.adk.auth.auth_credential.HttpCredentials.model_validate
  name: model_validate
  file_path: google/adk/auth/auth_credential.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def model_validate(cls, data: typing.Dict[str, typing.Any]) -> google.adk.auth.auth_credential.HttpCredentials:'
- rank: 272
  id: google.adk.auth.auth_credential.ServiceAccount
  name: ServiceAccount
  file_path: google/adk/auth/auth_credential.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Represents Google Service Account configuration.


    [Note: Inherited members from pydantic.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, service_account_credential: typing.Optional[google.adk.auth.auth_credential.ServiceAccountCredential] = None, scopes: typing.List[str], use_default_credential: typing.Optional[bool] = False):'
  properties:
  - signature: 'service_account_credential: typing.Optional[google.adk.auth.auth_credential.ServiceAccountCredential]'
  - signature: 'scopes: typing.List[str]'
  - signature: 'use_default_credential: typing.Optional[bool]'
  inherited_properties:
    BaseModelWithConfig:
    - signature: 'model_config: pydantic.ConfigDict'
      docstring: The pydantic model config.
    BaseModel:
    - signature: 'model_config: pydantic.ConfigDict'
  omitted_inherited_members_from:
  - pydantic.BaseModel
- rank: 273
  id: google.adk.auth.auth_credential.ServiceAccountCredential
  name: ServiceAccountCredential
  file_path: google/adk/auth/auth_credential.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: "Represents Google Service Account configuration.\n\nAttributes:\n  type: The type should be \"service_account\".\n  project_id: The project ID.\n  private_key_id: The ID of the private key.\n  private_key: The private key.\n  client_email: The client email.\n  client_id: The client ID.\n  auth_uri: The authorization URI.\n  token_uri: The token URI.\n  auth_provider_x509_cert_url: URL for auth provider's X.509 cert.\n  client_x509_cert_url: URL for the client's X.509 cert.\n  universe_domain: The universe domain.\n\nExample:\n\n    config = ServiceAccountCredential(\n        type_=\"service_account\",\n        project_id=\"your_project_id\",\n        private_key_id=\"your_private_key_id\",\n        private_key=\"-----BEGIN PRIVATE KEY-----...\",\n        client_email=\"...@....iam.gserviceaccount.com\",\n        client_id=\"your_client_id\",\n        auth_uri=\"https://accounts.google.com/o/oauth2/auth\",\n        token_uri=\"https://oauth2.googleapis.com/token\",\n       \
    \ auth_provider_x509_cert_url=\"https://www.googleapis.com/oauth2/v1/certs\",\n        client_x509_cert_url=\"https://www.googleapis.com/robot/v1/metadata/x509/...\",\n        universe_domain=\"googleapis.com\"\n    )\n\n    config = ServiceAccountConfig.model_construct(**{\n        ...service account config dict\n    })\n\n[Note: Inherited members from pydantic.BaseModel are omitted.]"
  constructor_signature: 'def __init__(self, *, type_: str, project_id: str, private_key_id: str, private_key: str, client_email: str, client_id: str, auth_uri: str, token_uri: str, auth_provider_x509_cert_url: str, client_x509_cert_url: str, universe_domain: str):'
  properties:
  - signature: 'type_: str'
  - signature: 'project_id: str'
  - signature: 'private_key_id: str'
  - signature: 'private_key: str'
  - signature: 'client_email: str'
  - signature: 'client_id: str'
  - signature: 'auth_uri: str'
  - signature: 'token_uri: str'
  - signature: 'auth_provider_x509_cert_url: str'
  - signature: 'client_x509_cert_url: str'
  - signature: 'universe_domain: str'
  inherited_properties:
    BaseModelWithConfig:
    - signature: 'model_config: pydantic.ConfigDict'
      docstring: The pydantic model config.
    BaseModel:
    - signature: 'model_config: pydantic.ConfigDict'
  omitted_inherited_members_from:
  - pydantic.BaseModel
- rank: 274
  id: google.adk.auth.auth_handler
  name: auth_handler
  file_path: google/adk/auth/auth_handler.py
  type: MODULE
  group: Orphan
  usage_score: 0
- rank: 275
  id: google.adk.auth.auth_handler.AuthHandler
  name: AuthHandler
  file_path: google/adk/auth/auth_handler.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'A handler that handles the auth flow in Agent Development Kit to help

    orchestrate the credential request and response flow (e.g. OAuth flow)

    This class should only be used by Agent Development Kit.'
  constructor_signature: 'def __init__(self, auth_config: google.adk.auth.auth_tool.AuthConfig):'
  aliases:
  - google.adk.auth.AuthHandler
  methods:
  - signature: 'def exchange_auth_token(self) -> google.adk.auth.auth_credential.AuthCredential:'
  - signature: 'def parse_and_store_auth_response(self, state: google.adk.sessions.state.State) -> None:'
  - signature: 'def get_auth_response(self, state: google.adk.sessions.state.State) -> google.adk.auth.auth_credential.AuthCredential:'
  - signature: 'def generate_auth_request(self) -> google.adk.auth.auth_tool.AuthConfig:'
  - signature: 'def generate_auth_uri(self) -> google.adk.auth.auth_credential.AuthCredential:'
    docstring: "Generates a response containing the auth uri for user to sign in.\n\nReturns:\n    An AuthCredential object containing the auth URI and state.\n\nRaises:\n    ValueError: If the authorization endpoint is not configured in the auth\n        scheme."
- rank: 276
  id: google.adk.auth.auth_handler.AuthHandler.exchange_auth_token
  name: exchange_auth_token
  file_path: google/adk/auth/auth_handler.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def exchange_auth_token(self) -> google.adk.auth.auth_credential.AuthCredential:'
- rank: 277
  id: google.adk.auth.auth_handler.AuthHandler.generate_auth_request
  name: generate_auth_request
  file_path: google/adk/auth/auth_handler.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def generate_auth_request(self) -> google.adk.auth.auth_tool.AuthConfig:'
- rank: 278
  id: google.adk.auth.auth_handler.AuthHandler.generate_auth_uri
  name: generate_auth_uri
  file_path: google/adk/auth/auth_handler.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Generates a response containing the auth uri for user to sign in.\n\nReturns:\n    An AuthCredential object containing the auth URI and state.\n\nRaises:\n    ValueError: If the authorization endpoint is not configured in the auth\n        scheme."
  signature: 'def generate_auth_uri(self) -> google.adk.auth.auth_credential.AuthCredential:'
- rank: 279
  id: google.adk.auth.auth_handler.AuthHandler.parse_and_store_auth_response
  name: parse_and_store_auth_response
  file_path: google/adk/auth/auth_handler.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def parse_and_store_auth_response(self, state: google.adk.sessions.state.State) -> None:'
- rank: 280
  id: google.adk.auth.auth_preprocessor
  name: auth_preprocessor
  file_path: google/adk/auth/auth_preprocessor.py
  type: MODULE
  group: Orphan
  usage_score: 0
- rank: 281
  id: google.adk.auth.auth_schemes
  name: auth_schemes
  file_path: google/adk/auth/auth_schemes.py
  type: MODULE
  group: Orphan
  usage_score: 0
- rank: 282
  id: google.adk.auth.auth_schemes.ExtendedOAuth2
  name: ExtendedOAuth2
  file_path: google/adk/auth/auth_schemes.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'OAuth2 scheme that incorporates auto-discovery for endpoints.


    [Note: Inherited members from OAuth2 are omitted.]'
  properties:
  - signature: 'issuer_url: typing.Optional[str]'
  omitted_inherited_members_from:
  - OAuth2
- rank: 283
  id: google.adk.auth.auth_schemes.OAuthGrantType
  name: OAuthGrantType
  file_path: google/adk/auth/auth_schemes.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Represents the OAuth2 flow (or grant type).


    [Note: Inherited members from Enum, str are omitted.]'
  methods:
  - signature: 'def from_flow(flow: fastapi.openapi.models.OAuthFlows) -> google.adk.auth.auth_schemes.OAuthGrantType:'
    docstring: Converts an OAuthFlows object to a OAuthGrantType.
  properties:
  - signature: 'CLIENT_CREDENTIALS: str'
  - signature: 'AUTHORIZATION_CODE: str'
  - signature: 'IMPLICIT: str'
  - signature: 'PASSWORD: str'
  omitted_inherited_members_from:
  - str
  - Enum
- rank: 284
  id: google.adk.auth.auth_schemes.OAuthGrantType.from_flow
  name: from_flow
  file_path: google/adk/auth/auth_schemes.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: Converts an OAuthFlows object to a OAuthGrantType.
  signature: 'def from_flow(flow: fastapi.openapi.models.OAuthFlows) -> google.adk.auth.auth_schemes.OAuthGrantType:'
- rank: 285
  id: google.adk.auth.auth_schemes.OpenIdConnectWithConfig
  name: OpenIdConnectWithConfig
  file_path: google/adk/auth/auth_schemes.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: '[Note: Inherited members from SecurityBase are omitted.]'
  properties:
  - signature: 'type_: fastapi.openapi.models.SecuritySchemeType'
  - signature: 'authorization_endpoint: str'
  - signature: 'token_endpoint: str'
  - signature: 'userinfo_endpoint: typing.Optional[str]'
  - signature: 'revocation_endpoint: typing.Optional[str]'
  - signature: 'token_endpoint_auth_methods_supported: typing.Optional[typing.List[str]]'
  - signature: 'grant_types_supported: typing.Optional[typing.List[str]]'
  - signature: 'scopes: typing.Optional[typing.List[str]]'
  omitted_inherited_members_from:
  - SecurityBase
- rank: 286
  id: google.adk.auth.auth_tool
  name: auth_tool
  file_path: google/adk/auth/auth_tool.py
  type: MODULE
  group: Orphan
  usage_score: 0
- rank: 287
  id: google.adk.auth.auth_tool.AuthConfig.__init__
  name: __init__
  file_path: google/adk/auth/auth_tool.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def __init__(self):'
- rank: 288
  id: google.adk.auth.auth_tool.AuthConfig.get_credential_key
  name: get_credential_key
  file_path: google/adk/auth/auth_tool.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: 'Builds a hash key based on auth_scheme and raw_auth_credential used to

    save / load this credential to / from a credentials service.'
  signature: 'def get_credential_key(self):'
- rank: 289
  id: google.adk.auth.auth_tool.AuthToolArguments
  name: AuthToolArguments
  file_path: google/adk/auth/auth_tool.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'the arguments for the special long running function tool that is used to


    request end user credentials.


    [Note: Inherited members from pydantic.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, function_call_id: str, auth_config: google.adk.auth.auth_tool.AuthConfig):'
  properties:
  - signature: 'function_call_id: str'
  - signature: 'auth_config: google.adk.auth.auth_tool.AuthConfig'
  inherited_properties:
    BaseModelWithConfig:
    - signature: 'model_config: pydantic.ConfigDict'
      docstring: The pydantic model config.
    BaseModel:
    - signature: 'model_config: pydantic.ConfigDict'
  omitted_inherited_members_from:
  - pydantic.BaseModel
- rank: 290
  id: google.adk.auth.credential_manager
  name: credential_manager
  file_path: google/adk/auth/credential_manager.py
  type: MODULE
  group: Orphan
  usage_score: 0
- rank: 291
  id: google.adk.auth.credential_manager.CredentialManager
  name: CredentialManager
  file_path: google/adk/auth/credential_manager.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: "Manages authentication credentials through a structured workflow.\n\nThe CredentialManager orchestrates the complete lifecycle of authentication\ncredentials, from initial loading to final preparation for use. It provides\na centralized interface for handling various credential types and authentication\nschemes while maintaining proper credential hygiene (refresh, exchange, caching).\n\nThis class is only for use by Agent Development Kit.\n\nArgs:\n    auth_config: Configuration containing authentication scheme and credentials\n\nExample:\n    ```python\n    auth_config = AuthConfig(\n        auth_scheme=oauth2_scheme,\n        raw_auth_credential=service_account_credential\n    )\n    manager = CredentialManager(auth_config)\n\n    # Register custom exchanger if needed\n    manager.register_credential_exchanger(\n        AuthCredentialTypes.CUSTOM_TYPE,\n        CustomCredentialExchanger()\n    )\n\n    # Register custom refresher if needed\n    manager.register_credential_refresher(\n\
    \        AuthCredentialTypes.CUSTOM_TYPE,\n        CustomCredentialRefresher()\n    )\n\n    # Load and prepare credential\n    credential = await manager.load_auth_credential(callback_context)\n    ```"
  constructor_signature: 'def __init__(self, auth_config: google.adk.auth.auth_tool.AuthConfig):'
  methods:
  - signature: 'def register_credential_exchanger(self, credential_type: google.adk.auth.auth_credential.AuthCredentialTypes, exchanger_instance: google.adk.auth.exchanger.base_credential_exchanger.BaseCredentialExchanger) -> None:'
    docstring: "Register a credential exchanger for a credential type.\n\nArgs:\n    credential_type: The credential type to register for.\n    exchanger_instance: The exchanger instance to register."
  - signature: 'def request_credential(self, callback_context: google.adk.agents.callback_context.CallbackContext) -> None:'
  - signature: 'def get_auth_credential(self, callback_context: google.adk.agents.callback_context.CallbackContext) -> typing.Optional[google.adk.auth.auth_credential.AuthCredential]:'
    docstring: Load and prepare authentication credential through a structured workflow.
- rank: 292
  id: google.adk.auth.credential_manager.CredentialManager.__init__
  name: __init__
  file_path: google/adk/auth/credential_manager.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def __init__(self, auth_config: google.adk.auth.auth_tool.AuthConfig):'
- rank: 293
  id: google.adk.auth.credential_manager.CredentialManager.get_auth_credential
  name: get_auth_credential
  file_path: google/adk/auth/credential_manager.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: Load and prepare authentication credential through a structured workflow.
  signature: 'def get_auth_credential(self, callback_context: google.adk.agents.callback_context.CallbackContext) -> typing.Optional[google.adk.auth.auth_credential.AuthCredential]:'
- rank: 294
  id: google.adk.auth.credential_manager.CredentialManager.register_credential_exchanger
  name: register_credential_exchanger
  file_path: google/adk/auth/credential_manager.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Register a credential exchanger for a credential type.\n\nArgs:\n    credential_type: The credential type to register for.\n    exchanger_instance: The exchanger instance to register."
  signature: 'def register_credential_exchanger(self, credential_type: google.adk.auth.auth_credential.AuthCredentialTypes, exchanger_instance: google.adk.auth.exchanger.base_credential_exchanger.BaseCredentialExchanger) -> None:'
- rank: 295
  id: google.adk.auth.credential_service
  name: credential_service
  file_path: google/adk/auth/credential_service/__init__.py
  type: MODULE
  group: Orphan
  usage_score: 0
- rank: 296
  id: google.adk.auth.credential_service.base_credential_service
  name: base_credential_service
  file_path: google/adk/auth/credential_service/base_credential_service.py
  type: MODULE
  group: Orphan
  usage_score: 0
- rank: 297
  id: google.adk.auth.credential_service.base_credential_service.BaseCredentialService
  name: BaseCredentialService
  file_path: google/adk/auth/credential_service/base_credential_service.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Abstract class for Service that loads / saves tool credentials from / to

    the backend credential store.


    [Note: Inherited members from ABC are omitted.]'
  methods:
  - signature: 'def load_credential(self, auth_config: google.adk.auth.auth_tool.AuthConfig, callback_context: google.adk.agents.callback_context.CallbackContext) -> typing.Optional[google.adk.auth.auth_credential.AuthCredential]:'
    docstring: "Loads the credential by auth config and current callback context from the\nbackend credential store.\n\nArgs:\n    auth_config: The auth config which contains the auth scheme and auth\n    credential information. auth_config.get_credential_key will be used to\n    build the key to load the credential.\n\n    callback_context: The context of the current invocation when the tool is\n    trying to load the credential.\n\nReturns:\n    Optional[AuthCredential]: the credential saved in the store."
  - signature: 'def save_credential(self, auth_config: google.adk.auth.auth_tool.AuthConfig, callback_context: google.adk.agents.callback_context.CallbackContext) -> None:'
    docstring: "Saves the exchanged_auth_credential in auth config to the backend credential\nstore.\n\nArgs:\n    auth_config: The auth config which contains the auth scheme and auth\n    credential information. auth_config.get_credential_key will be used to\n    build the key to save the credential.\n\n    callback_context: The context of the current invocation when the tool is\n    trying to save the credential.\n\nReturns:\n    None"
  omitted_inherited_members_from:
  - ABC
- rank: 298
  id: google.adk.auth.credential_service.base_credential_service.BaseCredentialService.load_credential
  name: load_credential
  file_path: google/adk/auth/credential_service/base_credential_service.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Loads the credential by auth config and current callback context from the\nbackend credential store.\n\nArgs:\n    auth_config: The auth config which contains the auth scheme and auth\n    credential information. auth_config.get_credential_key will be used to\n    build the key to load the credential.\n\n    callback_context: The context of the current invocation when the tool is\n    trying to load the credential.\n\nReturns:\n    Optional[AuthCredential]: the credential saved in the store."
  signature: 'def load_credential(self, auth_config: google.adk.auth.auth_tool.AuthConfig, callback_context: google.adk.agents.callback_context.CallbackContext) -> typing.Optional[google.adk.auth.auth_credential.AuthCredential]:'
- rank: 299
  id: google.adk.auth.credential_service.base_credential_service.BaseCredentialService.save_credential
  name: save_credential
  file_path: google/adk/auth/credential_service/base_credential_service.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Saves the exchanged_auth_credential in auth config to the backend credential\nstore.\n\nArgs:\n    auth_config: The auth config which contains the auth scheme and auth\n    credential information. auth_config.get_credential_key will be used to\n    build the key to save the credential.\n\n    callback_context: The context of the current invocation when the tool is\n    trying to save the credential.\n\nReturns:\n    None"
  signature: 'def save_credential(self, auth_config: google.adk.auth.auth_tool.AuthConfig, callback_context: google.adk.agents.callback_context.CallbackContext) -> None:'
- rank: 300
  id: google.adk.auth.credential_service.in_memory_credential_service
  name: in_memory_credential_service
  file_path: google/adk/auth/credential_service/in_memory_credential_service.py
  type: MODULE
  group: Orphan
  usage_score: 0
- rank: 301
  id: google.adk.auth.credential_service.in_memory_credential_service.InMemoryCredentialService
  name: InMemoryCredentialService
  file_path: google/adk/auth/credential_service/in_memory_credential_service.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Class for in memory implementation of credential service(Experimental)


    [Note: Inherited members from ABC are omitted.]'
  constructor_signature: 'def __init__(self):'
  methods:
  - signature: 'def load_credential(self, auth_config: google.adk.auth.auth_tool.AuthConfig, callback_context: google.adk.agents.callback_context.CallbackContext) -> typing.Optional[google.adk.auth.auth_credential.AuthCredential]:'
  - signature: 'def save_credential(self, auth_config: google.adk.auth.auth_tool.AuthConfig, callback_context: google.adk.agents.callback_context.CallbackContext) -> None:'
  inherited_methods:
    BaseCredentialService:
    - signature: 'def load_credential(self, auth_config: google.adk.auth.auth_tool.AuthConfig, callback_context: google.adk.agents.callback_context.CallbackContext) -> typing.Optional[google.adk.auth.auth_credential.AuthCredential]:'
      docstring: "Loads the credential by auth config and current callback context from the\nbackend credential store.\n\nArgs:\n    auth_config: The auth config which contains the auth scheme and auth\n    credential information. auth_config.get_credential_key will be used to\n    build the key to load the credential.\n\n    callback_context: The context of the current invocation when the tool is\n    trying to load the credential.\n\nReturns:\n    Optional[AuthCredential]: the credential saved in the store."
    - signature: 'def save_credential(self, auth_config: google.adk.auth.auth_tool.AuthConfig, callback_context: google.adk.agents.callback_context.CallbackContext) -> None:'
      docstring: "Saves the exchanged_auth_credential in auth config to the backend credential\nstore.\n\nArgs:\n    auth_config: The auth config which contains the auth scheme and auth\n    credential information. auth_config.get_credential_key will be used to\n    build the key to save the credential.\n\n    callback_context: The context of the current invocation when the tool is\n    trying to save the credential.\n\nReturns:\n    None"
  omitted_inherited_members_from:
  - ABC
- rank: 302
  id: google.adk.auth.credential_service.in_memory_credential_service.InMemoryCredentialService.load_credential
  name: load_credential
  file_path: google/adk/auth/credential_service/in_memory_credential_service.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def load_credential(self, auth_config: google.adk.auth.auth_tool.AuthConfig, callback_context: google.adk.agents.callback_context.CallbackContext) -> typing.Optional[google.adk.auth.auth_credential.AuthCredential]:'
- rank: 303
  id: google.adk.auth.credential_service.in_memory_credential_service.InMemoryCredentialService.save_credential
  name: save_credential
  file_path: google/adk/auth/credential_service/in_memory_credential_service.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def save_credential(self, auth_config: google.adk.auth.auth_tool.AuthConfig, callback_context: google.adk.agents.callback_context.CallbackContext) -> None:'
- rank: 304
  id: google.adk.auth.credential_service.session_state_credential_service
  name: session_state_credential_service
  file_path: google/adk/auth/credential_service/session_state_credential_service.py
  type: MODULE
  group: Orphan
  usage_score: 0
- rank: 305
  id: google.adk.auth.credential_service.session_state_credential_service.SessionStateCredentialService
  name: SessionStateCredentialService
  file_path: google/adk/auth/credential_service/session_state_credential_service.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Class for implementation of credential service using session state as the

    store.

    Note: store credential in session may not be secure, use at your own risk.


    [Note: Inherited members from ABC are omitted.]'
  methods:
  - signature: 'def load_credential(self, auth_config: google.adk.auth.auth_tool.AuthConfig, callback_context: google.adk.agents.callback_context.CallbackContext) -> typing.Optional[google.adk.auth.auth_credential.AuthCredential]:'
    docstring: "Loads the credential by auth config and current callback context from the\nbackend credential store.\n\nArgs:\n    auth_config: The auth config which contains the auth scheme and auth\n    credential information. auth_config.get_credential_key will be used to\n    build the key to load the credential.\n\n    callback_context: The context of the current invocation when the tool is\n    trying to load the credential.\n\nReturns:\n    Optional[AuthCredential]: the credential saved in the store."
  - signature: 'def save_credential(self, auth_config: google.adk.auth.auth_tool.AuthConfig, callback_context: google.adk.agents.callback_context.CallbackContext) -> None:'
    docstring: "Saves the exchanged_auth_credential in auth config to the backend credential\nstore.\n\nArgs:\n    auth_config: The auth config which contains the auth scheme and auth\n    credential information. auth_config.get_credential_key will be used to\n    build the key to save the credential.\n\n    callback_context: The context of the current invocation when the tool is\n    trying to save the credential.\n\nReturns:\n    None"
  inherited_methods:
    BaseCredentialService:
    - signature: 'def load_credential(self, auth_config: google.adk.auth.auth_tool.AuthConfig, callback_context: google.adk.agents.callback_context.CallbackContext) -> typing.Optional[google.adk.auth.auth_credential.AuthCredential]:'
      docstring: "Loads the credential by auth config and current callback context from the\nbackend credential store.\n\nArgs:\n    auth_config: The auth config which contains the auth scheme and auth\n    credential information. auth_config.get_credential_key will be used to\n    build the key to load the credential.\n\n    callback_context: The context of the current invocation when the tool is\n    trying to load the credential.\n\nReturns:\n    Optional[AuthCredential]: the credential saved in the store."
    - signature: 'def save_credential(self, auth_config: google.adk.auth.auth_tool.AuthConfig, callback_context: google.adk.agents.callback_context.CallbackContext) -> None:'
      docstring: "Saves the exchanged_auth_credential in auth config to the backend credential\nstore.\n\nArgs:\n    auth_config: The auth config which contains the auth scheme and auth\n    credential information. auth_config.get_credential_key will be used to\n    build the key to save the credential.\n\n    callback_context: The context of the current invocation when the tool is\n    trying to save the credential.\n\nReturns:\n    None"
  omitted_inherited_members_from:
  - ABC
- rank: 306
  id: google.adk.auth.credential_service.session_state_credential_service.SessionStateCredentialService.load_credential
  name: load_credential
  file_path: google/adk/auth/credential_service/session_state_credential_service.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Loads the credential by auth config and current callback context from the\nbackend credential store.\n\nArgs:\n    auth_config: The auth config which contains the auth scheme and auth\n    credential information. auth_config.get_credential_key will be used to\n    build the key to load the credential.\n\n    callback_context: The context of the current invocation when the tool is\n    trying to load the credential.\n\nReturns:\n    Optional[AuthCredential]: the credential saved in the store."
  signature: 'def load_credential(self, auth_config: google.adk.auth.auth_tool.AuthConfig, callback_context: google.adk.agents.callback_context.CallbackContext) -> typing.Optional[google.adk.auth.auth_credential.AuthCredential]:'
- rank: 307
  id: google.adk.auth.credential_service.session_state_credential_service.SessionStateCredentialService.save_credential
  name: save_credential
  file_path: google/adk/auth/credential_service/session_state_credential_service.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Saves the exchanged_auth_credential in auth config to the backend credential\nstore.\n\nArgs:\n    auth_config: The auth config which contains the auth scheme and auth\n    credential information. auth_config.get_credential_key will be used to\n    build the key to save the credential.\n\n    callback_context: The context of the current invocation when the tool is\n    trying to save the credential.\n\nReturns:\n    None"
  signature: 'def save_credential(self, auth_config: google.adk.auth.auth_tool.AuthConfig, callback_context: google.adk.agents.callback_context.CallbackContext) -> None:'
- rank: 308
  id: google.adk.auth.exchanger
  name: exchanger
  file_path: google/adk/auth/exchanger/__init__.py
  type: MODULE
  group: Orphan
  usage_score: 0
  docstring: Credential exchanger module.
- rank: 309
  id: google.adk.auth.exchanger.base_credential_exchanger
  name: base_credential_exchanger
  file_path: google/adk/auth/exchanger/base_credential_exchanger.py
  type: MODULE
  group: Orphan
  usage_score: 0
  docstring: Base credential exchanger interface.
- rank: 310
  id: google.adk.auth.exchanger.base_credential_exchanger.BaseCredentialExchanger
  name: BaseCredentialExchanger
  file_path: google/adk/auth/exchanger/base_credential_exchanger.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Base interface for credential exchangers.


    Credential exchangers are responsible for exchanging credentials from

    one format or scheme to another.


    [Note: Inherited members from abc.ABC are omitted.]'
  aliases:
  - google.adk.auth.exchanger.BaseCredentialExchanger
  methods:
  - signature: 'def exchange(self, auth_credential: google.adk.auth.auth_credential.AuthCredential, auth_scheme: typing.Optional[google.adk.auth.auth_schemes.AuthScheme]) -> google.adk.auth.auth_credential.AuthCredential:'
    docstring: "Exchange credential if needed.\n\nArgs:\n    auth_credential: The credential to exchange.\n    auth_scheme: The authentication scheme (optional, some exchangers don't need it).\n\nReturns:\n    The exchanged credential.\n\nRaises:\n    CredentialExchangeError: If credential exchange fails."
  omitted_inherited_members_from:
  - abc.ABC
- rank: 311
  id: google.adk.auth.exchanger.base_credential_exchanger.BaseCredentialExchanger.exchange
  name: exchange
  file_path: google/adk/auth/exchanger/base_credential_exchanger.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Exchange credential if needed.\n\nArgs:\n    auth_credential: The credential to exchange.\n    auth_scheme: The authentication scheme (optional, some exchangers don't need it).\n\nReturns:\n    The exchanged credential.\n\nRaises:\n    CredentialExchangeError: If credential exchange fails."
  signature: 'def exchange(self, auth_credential: google.adk.auth.auth_credential.AuthCredential, auth_scheme: typing.Optional[google.adk.auth.auth_schemes.AuthScheme]) -> google.adk.auth.auth_credential.AuthCredential:'
- rank: 312
  id: google.adk.auth.exchanger.base_credential_exchanger.CredentialExchangeError
  name: CredentialExchangeError
  file_path: google/adk/auth/exchanger/base_credential_exchanger.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Base exception for credential exchange errors.


    [Note: Inherited members from Exception are omitted.]'
  omitted_inherited_members_from:
  - Exception
- rank: 313
  id: google.adk.auth.exchanger.credential_exchanger_registry
  name: credential_exchanger_registry
  file_path: google/adk/auth/exchanger/credential_exchanger_registry.py
  type: MODULE
  group: Orphan
  usage_score: 0
  docstring: Credential exchanger registry.
- rank: 314
  id: google.adk.auth.exchanger.credential_exchanger_registry.CredentialExchangerRegistry
  name: CredentialExchangerRegistry
  file_path: google/adk/auth/exchanger/credential_exchanger_registry.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: Registry for credential exchanger instances.
  constructor_signature: 'def __init__(self):'
  methods:
  - signature: 'def register(self, credential_type: google.adk.auth.auth_credential.AuthCredentialTypes, exchanger_instance: google.adk.auth.exchanger.base_credential_exchanger.BaseCredentialExchanger) -> None:'
    docstring: "Register an exchanger instance for a credential type.\n\nArgs:\n    credential_type: The credential type to register for.\n    exchanger_instance: The exchanger instance to register."
  - signature: 'def get_exchanger(self, credential_type: google.adk.auth.auth_credential.AuthCredentialTypes) -> typing.Optional[google.adk.auth.exchanger.base_credential_exchanger.BaseCredentialExchanger]:'
    docstring: "Get the exchanger instance for a credential type.\n\nArgs:\n    credential_type: The credential type to get exchanger for.\n\nReturns:\n    The exchanger instance if registered, None otherwise."
- rank: 315
  id: google.adk.auth.exchanger.credential_exchanger_registry.CredentialExchangerRegistry.get_exchanger
  name: get_exchanger
  file_path: google/adk/auth/exchanger/credential_exchanger_registry.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Get the exchanger instance for a credential type.\n\nArgs:\n    credential_type: The credential type to get exchanger for.\n\nReturns:\n    The exchanger instance if registered, None otherwise."
  signature: 'def get_exchanger(self, credential_type: google.adk.auth.auth_credential.AuthCredentialTypes) -> typing.Optional[google.adk.auth.exchanger.base_credential_exchanger.BaseCredentialExchanger]:'
- rank: 316
  id: google.adk.auth.exchanger.credential_exchanger_registry.CredentialExchangerRegistry.register
  name: register
  file_path: google/adk/auth/exchanger/credential_exchanger_registry.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Register an exchanger instance for a credential type.\n\nArgs:\n    credential_type: The credential type to register for.\n    exchanger_instance: The exchanger instance to register."
  signature: 'def register(self, credential_type: google.adk.auth.auth_credential.AuthCredentialTypes, exchanger_instance: google.adk.auth.exchanger.base_credential_exchanger.BaseCredentialExchanger) -> None:'
- rank: 317
  id: google.adk.auth.exchanger.oauth2_credential_exchanger
  name: oauth2_credential_exchanger
  file_path: google/adk/auth/exchanger/oauth2_credential_exchanger.py
  type: MODULE
  group: Orphan
  usage_score: 0
  docstring: OAuth2 credential exchanger implementation.
- rank: 318
  id: google.adk.auth.exchanger.oauth2_credential_exchanger.OAuth2CredentialExchanger
  name: OAuth2CredentialExchanger
  file_path: google/adk/auth/exchanger/oauth2_credential_exchanger.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Exchanges OAuth2 credentials from authorization responses.


    [Note: Inherited members from abc.ABC are omitted.]'
  methods:
  - signature: 'def exchange(self, auth_credential: google.adk.auth.auth_credential.AuthCredential, auth_scheme: typing.Optional[google.adk.auth.auth_schemes.AuthScheme]) -> google.adk.auth.auth_credential.AuthCredential:'
    docstring: "Exchange OAuth2 credential from authorization response.\n\nif credential exchange failed, the original credential will be returned.\n\nArgs:\n    auth_credential: The OAuth2 credential to exchange.\n    auth_scheme: The OAuth2 authentication scheme.\n\nReturns:\n    The exchanged credential with access token.\n\nRaises:\n    CredentialExchangeError: If auth_scheme is missing."
  inherited_methods:
    BaseCredentialExchanger:
    - signature: 'def exchange(self, auth_credential: google.adk.auth.auth_credential.AuthCredential, auth_scheme: typing.Optional[google.adk.auth.auth_schemes.AuthScheme]) -> google.adk.auth.auth_credential.AuthCredential:'
      docstring: "Exchange credential if needed.\n\nArgs:\n    auth_credential: The credential to exchange.\n    auth_scheme: The authentication scheme (optional, some exchangers don't need it).\n\nReturns:\n    The exchanged credential.\n\nRaises:\n    CredentialExchangeError: If credential exchange fails."
  omitted_inherited_members_from:
  - abc.ABC
- rank: 319
  id: google.adk.auth.exchanger.oauth2_credential_exchanger.OAuth2CredentialExchanger.exchange
  name: exchange
  file_path: google/adk/auth/exchanger/oauth2_credential_exchanger.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Exchange OAuth2 credential from authorization response.\n\nif credential exchange failed, the original credential will be returned.\n\nArgs:\n    auth_credential: The OAuth2 credential to exchange.\n    auth_scheme: The OAuth2 authentication scheme.\n\nReturns:\n    The exchanged credential with access token.\n\nRaises:\n    CredentialExchangeError: If auth_scheme is missing."
  signature: 'def exchange(self, auth_credential: google.adk.auth.auth_credential.AuthCredential, auth_scheme: typing.Optional[google.adk.auth.auth_schemes.AuthScheme]) -> google.adk.auth.auth_credential.AuthCredential:'
- rank: 320
  id: google.adk.auth.oauth2_credential_util
  name: oauth2_credential_util
  file_path: google/adk/auth/oauth2_credential_util.py
  type: MODULE
  group: Orphan
  usage_score: 0
  methods:
  - signature: 'def create_oauth2_session(auth_scheme: google.adk.auth.auth_schemes.AuthScheme, auth_credential: google.adk.auth.auth_credential.AuthCredential) -> typing.Tuple[typing.Optional[authlib.integrations.requests_client.OAuth2Session], typing.Optional[str]]:'
    docstring: "Create an OAuth2 session for token operations.\n\nArgs:\n    auth_scheme: The authentication scheme configuration.\n    auth_credential: The authentication credential.\n\nReturns:\n    Tuple of (OAuth2Session, token_endpoint) or (None, None) if cannot create session."
  - signature: 'def update_credential_with_tokens(auth_credential: google.adk.auth.auth_credential.AuthCredential, tokens: authlib.oauth2.rfc6749.OAuth2Token) -> None:'
    docstring: "Update the credential with new tokens.\n\nArgs:\n    auth_credential: The authentication credential to update.\n    tokens: The OAuth2Token object containing new token information."
- rank: 321
  id: google.adk.auth.oauth2_credential_util.create_oauth2_session
  name: create_oauth2_session
  file_path: google/adk/auth/oauth2_credential_util.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Create an OAuth2 session for token operations.\n\nArgs:\n    auth_scheme: The authentication scheme configuration.\n    auth_credential: The authentication credential.\n\nReturns:\n    Tuple of (OAuth2Session, token_endpoint) or (None, None) if cannot create session."
  signature: 'def create_oauth2_session(auth_scheme: google.adk.auth.auth_schemes.AuthScheme, auth_credential: google.adk.auth.auth_credential.AuthCredential) -> typing.Tuple[typing.Optional[authlib.integrations.requests_client.OAuth2Session], typing.Optional[str]]:'
- rank: 322
  id: google.adk.auth.oauth2_credential_util.update_credential_with_tokens
  name: update_credential_with_tokens
  file_path: google/adk/auth/oauth2_credential_util.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Update the credential with new tokens.\n\nArgs:\n    auth_credential: The authentication credential to update.\n    tokens: The OAuth2Token object containing new token information."
  signature: 'def update_credential_with_tokens(auth_credential: google.adk.auth.auth_credential.AuthCredential, tokens: authlib.oauth2.rfc6749.OAuth2Token) -> None:'
- rank: 323
  id: google.adk.auth.oauth2_discovery
  name: oauth2_discovery
  file_path: google/adk/auth/oauth2_discovery.py
  type: MODULE
  group: Orphan
  usage_score: 0
- rank: 324
  id: google.adk.auth.oauth2_discovery.AuthorizationServerMetadata
  name: AuthorizationServerMetadata
  file_path: google/adk/auth/oauth2_discovery.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Represents the OAuth2 authorization server metadata per RFC8414.


    [Note: Inherited members from pydantic.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, issuer: str, authorization_endpoint: str, token_endpoint: str, scopes_supported: typing.Optional[typing.List[str]] = None, registration_endpoint: typing.Optional[str] = None):'
  properties:
  - signature: 'issuer: str'
  - signature: 'authorization_endpoint: str'
  - signature: 'token_endpoint: str'
  - signature: 'scopes_supported: typing.Optional[typing.List[str]]'
  - signature: 'registration_endpoint: typing.Optional[str]'
  inherited_properties:
    BaseModel:
    - signature: 'model_config: pydantic.ConfigDict'
  omitted_inherited_members_from:
  - pydantic.BaseModel
- rank: 325
  id: google.adk.auth.oauth2_discovery.OAuth2DiscoveryManager
  name: OAuth2DiscoveryManager
  file_path: google/adk/auth/oauth2_discovery.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: Implements Metadata discovery for OAuth2 following RFC8414 and RFC9728.
  methods:
  - signature: 'def discover_auth_server_metadata(self, issuer_url: str) -> typing.Optional[google.adk.auth.oauth2_discovery.AuthorizationServerMetadata]:'
    docstring: Discovers the OAuth2 authorization server metadata.
  - signature: 'def discover_resource_metadata(self, resource_url: str) -> typing.Optional[google.adk.auth.oauth2_discovery.ProtectedResourceMetadata]:'
    docstring: Discovers the OAuth2 protected resource metadata.
- rank: 326
  id: google.adk.auth.oauth2_discovery.OAuth2DiscoveryManager.discover_auth_server_metadata
  name: discover_auth_server_metadata
  file_path: google/adk/auth/oauth2_discovery.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: Discovers the OAuth2 authorization server metadata.
  signature: 'def discover_auth_server_metadata(self, issuer_url: str) -> typing.Optional[google.adk.auth.oauth2_discovery.AuthorizationServerMetadata]:'
- rank: 327
  id: google.adk.auth.oauth2_discovery.OAuth2DiscoveryManager.discover_resource_metadata
  name: discover_resource_metadata
  file_path: google/adk/auth/oauth2_discovery.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: Discovers the OAuth2 protected resource metadata.
  signature: 'def discover_resource_metadata(self, resource_url: str) -> typing.Optional[google.adk.auth.oauth2_discovery.ProtectedResourceMetadata]:'
- rank: 328
  id: google.adk.auth.oauth2_discovery.ProtectedResourceMetadata
  name: ProtectedResourceMetadata
  file_path: google/adk/auth/oauth2_discovery.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Represents the OAuth2 protected resource metadata per RFC9728.


    [Note: Inherited members from pydantic.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, resource: str, authorization_servers: typing.List[str] = []):'
  properties:
  - signature: 'resource: str'
  - signature: 'authorization_servers: typing.List[str]'
  inherited_properties:
    BaseModel:
    - signature: 'model_config: pydantic.ConfigDict'
  omitted_inherited_members_from:
  - pydantic.BaseModel
- rank: 329
  id: google.adk.auth.refresher
  name: refresher
  file_path: google/adk/auth/refresher/__init__.py
  type: MODULE
  group: Orphan
  usage_score: 0
  docstring: Credential refresher module.
- rank: 330
  id: google.adk.auth.refresher.base_credential_refresher
  name: base_credential_refresher
  file_path: google/adk/auth/refresher/base_credential_refresher.py
  type: MODULE
  group: Orphan
  usage_score: 0
  docstring: Base credential refresher interface.
- rank: 331
  id: google.adk.auth.refresher.base_credential_refresher.BaseCredentialRefresher
  name: BaseCredentialRefresher
  file_path: google/adk/auth/refresher/base_credential_refresher.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Base interface for credential refreshers.


    Credential refreshers are responsible for checking if a credential is expired

    or needs to be refreshed, and for refreshing it if necessary.


    [Note: Inherited members from abc.ABC are omitted.]'
  methods:
  - signature: 'def is_refresh_needed(self, auth_credential: google.adk.auth.auth_credential.AuthCredential, auth_scheme: typing.Optional[google.adk.auth.auth_schemes.AuthScheme]) -> bool:'
    docstring: "Checks if a credential needs to be refreshed.\n\nArgs:\n    auth_credential: The credential to check.\n    auth_scheme: The authentication scheme (optional, some refreshers don't need it).\n\nReturns:\n    True if the credential needs to be refreshed, False otherwise."
  - signature: 'def refresh(self, auth_credential: google.adk.auth.auth_credential.AuthCredential, auth_scheme: typing.Optional[google.adk.auth.auth_schemes.AuthScheme]) -> google.adk.auth.auth_credential.AuthCredential:'
    docstring: "Refreshes a credential if needed.\n\nArgs:\n    auth_credential: The credential to refresh.\n    auth_scheme: The authentication scheme (optional, some refreshers don't need it).\n\nReturns:\n    The refreshed credential.\n\nRaises:\n    CredentialRefresherError: If credential refresh fails."
  omitted_inherited_members_from:
  - abc.ABC
- rank: 332
  id: google.adk.auth.refresher.base_credential_refresher.BaseCredentialRefresher.is_refresh_needed
  name: is_refresh_needed
  file_path: google/adk/auth/refresher/base_credential_refresher.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Checks if a credential needs to be refreshed.\n\nArgs:\n    auth_credential: The credential to check.\n    auth_scheme: The authentication scheme (optional, some refreshers don't need it).\n\nReturns:\n    True if the credential needs to be refreshed, False otherwise."
  signature: 'def is_refresh_needed(self, auth_credential: google.adk.auth.auth_credential.AuthCredential, auth_scheme: typing.Optional[google.adk.auth.auth_schemes.AuthScheme]) -> bool:'
- rank: 333
  id: google.adk.auth.refresher.base_credential_refresher.BaseCredentialRefresher.refresh
  name: refresh
  file_path: google/adk/auth/refresher/base_credential_refresher.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Refreshes a credential if needed.\n\nArgs:\n    auth_credential: The credential to refresh.\n    auth_scheme: The authentication scheme (optional, some refreshers don't need it).\n\nReturns:\n    The refreshed credential.\n\nRaises:\n    CredentialRefresherError: If credential refresh fails."
  signature: 'def refresh(self, auth_credential: google.adk.auth.auth_credential.AuthCredential, auth_scheme: typing.Optional[google.adk.auth.auth_schemes.AuthScheme]) -> google.adk.auth.auth_credential.AuthCredential:'
- rank: 334
  id: google.adk.auth.refresher.base_credential_refresher.CredentialRefresherError
  name: CredentialRefresherError
  file_path: google/adk/auth/refresher/base_credential_refresher.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Base exception for credential refresh errors.


    [Note: Inherited members from Exception are omitted.]'
  omitted_inherited_members_from:
  - Exception
- rank: 335
  id: google.adk.auth.refresher.credential_refresher_registry
  name: credential_refresher_registry
  file_path: google/adk/auth/refresher/credential_refresher_registry.py
  type: MODULE
  group: Orphan
  usage_score: 0
  docstring: Credential refresher registry.
- rank: 336
  id: google.adk.auth.refresher.credential_refresher_registry.CredentialRefresherRegistry
  name: CredentialRefresherRegistry
  file_path: google/adk/auth/refresher/credential_refresher_registry.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: Registry for credential refresher instances.
  constructor_signature: 'def __init__(self):'
  methods:
  - signature: 'def register(self, credential_type: google.adk.auth.auth_credential.AuthCredentialTypes, refresher_instance: google.adk.auth.refresher.base_credential_refresher.BaseCredentialRefresher) -> None:'
    docstring: "Register a refresher instance for a credential type.\n\nArgs:\n    credential_type: The credential type to register for.\n    refresher_instance: The refresher instance to register."
  - signature: 'def get_refresher(self, credential_type: google.adk.auth.auth_credential.AuthCredentialTypes) -> typing.Optional[google.adk.auth.refresher.base_credential_refresher.BaseCredentialRefresher]:'
    docstring: "Get the refresher instance for a credential type.\n\nArgs:\n    credential_type: The credential type to get refresher for.\n\nReturns:\n    The refresher instance if registered, None otherwise."
- rank: 337
  id: google.adk.auth.refresher.credential_refresher_registry.CredentialRefresherRegistry.get_refresher
  name: get_refresher
  file_path: google/adk/auth/refresher/credential_refresher_registry.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Get the refresher instance for a credential type.\n\nArgs:\n    credential_type: The credential type to get refresher for.\n\nReturns:\n    The refresher instance if registered, None otherwise."
  signature: 'def get_refresher(self, credential_type: google.adk.auth.auth_credential.AuthCredentialTypes) -> typing.Optional[google.adk.auth.refresher.base_credential_refresher.BaseCredentialRefresher]:'
- rank: 338
  id: google.adk.auth.refresher.credential_refresher_registry.CredentialRefresherRegistry.register
  name: register
  file_path: google/adk/auth/refresher/credential_refresher_registry.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Register a refresher instance for a credential type.\n\nArgs:\n    credential_type: The credential type to register for.\n    refresher_instance: The refresher instance to register."
  signature: 'def register(self, credential_type: google.adk.auth.auth_credential.AuthCredentialTypes, refresher_instance: google.adk.auth.refresher.base_credential_refresher.BaseCredentialRefresher) -> None:'
- rank: 339
  id: google.adk.auth.refresher.oauth2_credential_refresher
  name: oauth2_credential_refresher
  file_path: google/adk/auth/refresher/oauth2_credential_refresher.py
  type: MODULE
  group: Orphan
  usage_score: 0
  docstring: OAuth2 credential refresher implementation.
- rank: 340
  id: google.adk.auth.refresher.oauth2_credential_refresher.OAuth2CredentialRefresher
  name: OAuth2CredentialRefresher
  file_path: google/adk/auth/refresher/oauth2_credential_refresher.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Refreshes OAuth2 credentials including Google OAuth2 JSON credentials.


    [Note: Inherited members from abc.ABC are omitted.]'
  methods:
  - signature: 'def is_refresh_needed(self, auth_credential: google.adk.auth.auth_credential.AuthCredential, auth_scheme: typing.Optional[google.adk.auth.auth_schemes.AuthScheme]) -> bool:'
    docstring: "Check if the OAuth2 credential needs to be refreshed.\n\nArgs:\n    auth_credential: The OAuth2 credential to check.\n    auth_scheme: The OAuth2 authentication scheme (optional for Google OAuth2 JSON).\n\nReturns:\n    True if the credential needs to be refreshed, False otherwise."
  - signature: 'def refresh(self, auth_credential: google.adk.auth.auth_credential.AuthCredential, auth_scheme: typing.Optional[google.adk.auth.auth_schemes.AuthScheme]) -> google.adk.auth.auth_credential.AuthCredential:'
    docstring: "Refresh the OAuth2 credential.\nIf refresh failed, return the original credential.\n\nArgs:\n    auth_credential: The OAuth2 credential to refresh.\n    auth_scheme: The OAuth2 authentication scheme (optional for Google OAuth2 JSON).\n\nReturns:\n    The refreshed credential."
  inherited_methods:
    BaseCredentialRefresher:
    - signature: 'def is_refresh_needed(self, auth_credential: google.adk.auth.auth_credential.AuthCredential, auth_scheme: typing.Optional[google.adk.auth.auth_schemes.AuthScheme]) -> bool:'
      docstring: "Checks if a credential needs to be refreshed.\n\nArgs:\n    auth_credential: The credential to check.\n    auth_scheme: The authentication scheme (optional, some refreshers don't need it).\n\nReturns:\n    True if the credential needs to be refreshed, False otherwise."
    - signature: 'def refresh(self, auth_credential: google.adk.auth.auth_credential.AuthCredential, auth_scheme: typing.Optional[google.adk.auth.auth_schemes.AuthScheme]) -> google.adk.auth.auth_credential.AuthCredential:'
      docstring: "Refreshes a credential if needed.\n\nArgs:\n    auth_credential: The credential to refresh.\n    auth_scheme: The authentication scheme (optional, some refreshers don't need it).\n\nReturns:\n    The refreshed credential.\n\nRaises:\n    CredentialRefresherError: If credential refresh fails."
  omitted_inherited_members_from:
  - abc.ABC
- rank: 341
  id: google.adk.auth.refresher.oauth2_credential_refresher.OAuth2CredentialRefresher.is_refresh_needed
  name: is_refresh_needed
  file_path: google/adk/auth/refresher/oauth2_credential_refresher.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Check if the OAuth2 credential needs to be refreshed.\n\nArgs:\n    auth_credential: The OAuth2 credential to check.\n    auth_scheme: The OAuth2 authentication scheme (optional for Google OAuth2 JSON).\n\nReturns:\n    True if the credential needs to be refreshed, False otherwise."
  signature: 'def is_refresh_needed(self, auth_credential: google.adk.auth.auth_credential.AuthCredential, auth_scheme: typing.Optional[google.adk.auth.auth_schemes.AuthScheme]) -> bool:'
- rank: 342
  id: google.adk.auth.refresher.oauth2_credential_refresher.OAuth2CredentialRefresher.refresh
  name: refresh
  file_path: google/adk/auth/refresher/oauth2_credential_refresher.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Refresh the OAuth2 credential.\nIf refresh failed, return the original credential.\n\nArgs:\n    auth_credential: The OAuth2 credential to refresh.\n    auth_scheme: The OAuth2 authentication scheme (optional for Google OAuth2 JSON).\n\nReturns:\n    The refreshed credential."
  signature: 'def refresh(self, auth_credential: google.adk.auth.auth_credential.AuthCredential, auth_scheme: typing.Optional[google.adk.auth.auth_schemes.AuthScheme]) -> google.adk.auth.auth_credential.AuthCredential:'
- rank: 343
  id: google.adk.cli
  name: cli
  file_path: google/adk/cli/__init__.py
  type: MODULE
  group: Orphan
  usage_score: 0
- rank: 344
  id: google.adk.cli.adk_web_server
  name: adk_web_server
  file_path: google/adk/cli/adk_web_server.py
  type: MODULE
  group: Orphan
  usage_score: 0
- rank: 345
  id: google.adk.cli.adk_web_server.AddSessionToEvalSetRequest
  name: AddSessionToEvalSetRequest
  file_path: google/adk/cli/adk_web_server.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: '[Note: Inherited members from pydantic.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, eval_id: str, session_id: str, user_id: str):'
  properties:
  - signature: 'eval_id: str'
  - signature: 'session_id: str'
  - signature: 'user_id: str'
  inherited_properties:
    BaseModel:
    - signature: 'model_config: pydantic.ConfigDict'
  omitted_inherited_members_from:
  - pydantic.BaseModel
- rank: 346
  id: google.adk.cli.adk_web_server.AdkWebServer
  name: AdkWebServer
  file_path: google/adk/cli/adk_web_server.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: "Helper class for setting up and running the ADK web server on FastAPI.\n\nYou construct this class with all the Services required to run ADK agents and\ncan then call the get_fast_api_app method to get a FastAPI app instance that\ncan will use your provided service instances, static assets, and agent loader.\nIf you pass in a web_assets_dir, the static assets will be served under\n/dev-ui in addition to the API endpoints created by default.\n\nYou can add additional API endpoints by modifying the FastAPI app\ninstance returned by get_fast_api_app as this class exposes the agent runners\nand most other bits of state retained during the lifetime of the server.\n\nAttributes:\n    agent_loader: An instance of BaseAgentLoader for loading agents.\n    session_service: An instance of BaseSessionService for managing sessions.\n    memory_service: An instance of BaseMemoryService for managing memory.\n    artifact_service: An instance of BaseArtifactService for managing\n      artifacts.\n\
    \    credential_service: An instance of BaseCredentialService for managing\n      credentials.\n    eval_sets_manager: An instance of EvalSetsManager for managing evaluation\n      sets.\n    eval_set_results_manager: An instance of EvalSetResultsManager for\n      managing evaluation set results.\n    agents_dir: Root directory containing subdirs for agents with those\n      containing resources (e.g. .env files, eval sets, etc.) for the agents.\n    extra_plugins: A list of fully qualified names of extra plugins to load.\n    logo_text: Text to display in the logo of the UI.\n    logo_image_url: URL of an image to display as logo of the UI.\n    runners_to_clean: Set of runner names marked for cleanup.\n    current_app_name_ref: A shared reference to the latest ran app name.\n    runner_dict: A dict of instantiated runners for each app."
  constructor_signature: 'def __init__(self, *, agent_loader: google.adk.cli.utils.base_agent_loader.BaseAgentLoader, session_service: google.adk.sessions.base_session_service.BaseSessionService, memory_service: google.adk.memory.base_memory_service.BaseMemoryService, artifact_service: google.adk.artifacts.base_artifact_service.BaseArtifactService, credential_service: google.adk.auth.credential_service.base_credential_service.BaseCredentialService, eval_sets_manager: google.adk.evaluation.eval_sets_manager.EvalSetsManager, eval_set_results_manager: google.adk.evaluation.eval_set_results_manager.EvalSetResultsManager, agents_dir: str, extra_plugins: typing.Optional[list[str]]=None, logo_text: typing.Optional[str]=None, logo_image_url: typing.Optional[str]=None, url_prefix: typing.Optional[str]=None):'
  methods:
  - signature: 'def get_runner_async(self, app_name: str) -> google.adk.runners.Runner:'
    docstring: Returns the cached runner for the given app.
  - signature: 'def get_fast_api_app(self, lifespan: typing.Optional[starlette.types.Lifespan[fastapi.FastAPI]], allow_origins: typing.Optional[list[str]], web_assets_dir: typing.Optional[str], setup_observer: typing.Callable[[Observer, ''AdkWebServer''], None], tear_down_observer: typing.Callable[[Observer, ''AdkWebServer''], None], register_processors: typing.Callable[[TracerProvider], None], otel_to_cloud: bool):'
    docstring: "Creates a FastAPI app for the ADK web server.\n\nBy default it'll just return a FastAPI instance with the API server\nendpoints,\nbut if you specify a web_assets_dir, it'll also serve the static web assets\nfrom that directory.\n\nArgs:\n  lifespan: The lifespan of the FastAPI app.\n  allow_origins: The origins that are allowed to make cross-origin requests.\n  web_assets_dir: The directory containing the web assets to serve.\n  setup_observer: Callback for setting up the file system observer.\n  tear_down_observer: Callback for cleaning up the file system observer.\n  register_processors: Callback for additional Span processors to be added\n    to the TracerProvider.\n  otel_to_cloud: EXPERIMENTAL. Whether to enable Cloud Trace\n  and Cloud Logging integrations.\n\nReturns:\n  A FastAPI app instance."
  - signature: 'def internal_lifespan(app: fastapi.FastAPI):'
  - signature: 'def list_apps(detailed: bool) -> list[str] | ListAppsResponse:'
  - signature: 'def get_trace_dict(event_id: str) -> typing.Any:'
  - signature: 'def get_session_trace(session_id: str) -> typing.Any:'
  - signature: 'def get_session(app_name: str, user_id: str, session_id: str) -> google.adk.sessions.session.Session:'
  - signature: 'def list_sessions(app_name: str, user_id: str) -> list[google.adk.sessions.session.Session]:'
  - signature: 'def create_session_with_id(app_name: str, user_id: str, session_id: str, state: typing.Optional[dict[str, typing.Any]]) -> google.adk.sessions.session.Session:'
  - signature: 'def create_session(app_name: str, user_id: str, req: typing.Optional[google.adk.cli.adk_web_server.CreateSessionRequest]) -> google.adk.sessions.session.Session:'
  - signature: 'def delete_session(app_name: str, user_id: str, session_id: str) -> None:'
  - signature: 'def update_session(app_name: str, user_id: str, session_id: str, req: google.adk.cli.adk_web_server.UpdateSessionRequest) -> google.adk.sessions.session.Session:'
    docstring: "Updates session state without running the agent.\n\nArgs:\n    app_name: The name of the application.\n    user_id: The ID of the user.\n    session_id: The ID of the session to update.\n    req: The patch request containing state changes.\n\nReturns:\n    The updated session.\n\nRaises:\n    HTTPException: If the session is not found."
  - signature: 'def create_eval_set(app_name: str, create_eval_set_request: google.adk.cli.adk_web_server.CreateEvalSetRequest) -> google.adk.evaluation.eval_set.EvalSet:'
  - signature: 'def create_eval_set_legacy(app_name: str, eval_set_id: str):'
    docstring: Creates an eval set, given the id.
  - signature: 'def list_eval_sets(app_name: str) -> google.adk.cli.adk_web_server.ListEvalSetsResponse:'
    docstring: Lists all eval sets for the given app.
  - signature: 'def list_eval_sets_legacy(app_name: str) -> list[str]:'
  - signature: 'def add_session_to_eval_set(app_name: str, eval_set_id: str, req: google.adk.cli.adk_web_server.AddSessionToEvalSetRequest):'
  - signature: 'def list_evals_in_eval_set(app_name: str, eval_set_id: str) -> list[str]:'
    docstring: Lists all evals in an eval set.
  - signature: 'def get_eval(app_name: str, eval_set_id: str, eval_case_id: str) -> google.adk.evaluation.eval_case.EvalCase:'
    docstring: Gets an eval case in an eval set.
  - signature: 'def update_eval(app_name: str, eval_set_id: str, eval_case_id: str, updated_eval_case: google.adk.evaluation.eval_case.EvalCase):'
  - signature: 'def delete_eval(app_name: str, eval_set_id: str, eval_case_id: str) -> None:'
  - signature: 'def run_eval_legacy(app_name: str, eval_set_id: str, req: google.adk.cli.adk_web_server.RunEvalRequest) -> list[google.adk.cli.adk_web_server.RunEvalResult]:'
  - signature: 'def run_eval(app_name: str, eval_set_id: str, req: google.adk.cli.adk_web_server.RunEvalRequest) -> google.adk.cli.adk_web_server.RunEvalResponse:'
    docstring: Runs an eval given the details in the eval request.
  - signature: 'def get_eval_result(app_name: str, eval_result_id: str) -> google.adk.cli.adk_web_server.EvalResult:'
    docstring: Gets the eval result for the given eval id.
  - signature: 'def get_eval_result_legacy(app_name: str, eval_result_id: str) -> google.adk.evaluation.eval_result.EvalSetResult:'
  - signature: 'def list_eval_results(app_name: str) -> google.adk.cli.adk_web_server.ListEvalResultsResponse:'
    docstring: Lists all eval results for the given app.
  - signature: 'def list_eval_results_legacy(app_name: str) -> list[str]:'
  - signature: 'def list_metrics_info(app_name: str) -> google.adk.cli.adk_web_server.ListMetricsInfoResponse:'
    docstring: Lists all eval metrics for the given app.
  - signature: 'def load_artifact(app_name: str, user_id: str, session_id: str, artifact_name: str, version: typing.Optional[int]) -> typing.Optional[google.genai.types.Part]:'
  - signature: 'def load_artifact_version(app_name: str, user_id: str, session_id: str, artifact_name: str, version_id: int) -> typing.Optional[google.genai.types.Part]:'
  - signature: 'def save_artifact(app_name: str, user_id: str, session_id: str, req: google.adk.cli.adk_web_server.SaveArtifactRequest) -> google.adk.artifacts.base_artifact_service.ArtifactVersion:'
  - signature: 'def list_artifact_names(app_name: str, user_id: str, session_id: str) -> list[str]:'
  - signature: 'def list_artifact_versions(app_name: str, user_id: str, session_id: str, artifact_name: str) -> list[int]:'
  - signature: 'def delete_artifact(app_name: str, user_id: str, session_id: str, artifact_name: str) -> None:'
  - signature: 'def patch_memory(app_name: str, user_id: str, update_memory_request: google.adk.cli.adk_web_server.UpdateMemoryRequest) -> None:'
    docstring: "Adds all events from a given session to the memory service.\n\nArgs:\n    app_name: The name of the application.\n    user_id: The ID of the user.\n    update_memory_request: The memory request for the update\n\nRaises:\n    HTTPException: If the memory service is not configured or the request is invalid."
  - signature: 'def run_agent(req: google.adk.cli.adk_web_server.RunAgentRequest) -> list[google.adk.events.event.Event]:'
  - signature: 'def run_agent_sse(req: google.adk.cli.adk_web_server.RunAgentRequest) -> fastapi.responses.StreamingResponse:'
  - signature: 'def event_generator():'
  - signature: 'def get_event_graph(app_name: str, user_id: str, session_id: str, event_id: str):'
  - signature: 'def run_agent_live(websocket: fastapi.websockets.WebSocket, app_name: str, user_id: str, session_id: str, modalities: typing.List[typing.Literal[TEXT, AUDIO]]) -> None:'
  - signature: 'def forward_events():'
  - signature: 'def process_messages():'
  - signature: 'def get_ui_config():'
  - signature: 'def redirect_root_to_dev_ui():'
  - signature: 'def redirect_dev_ui_add_slash():'
- rank: 347
  id: google.adk.cli.adk_web_server.AdkWebServer.__init__
  name: __init__
  file_path: google/adk/cli/adk_web_server.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def __init__(self, *, agent_loader: google.adk.cli.utils.base_agent_loader.BaseAgentLoader, session_service: google.adk.sessions.base_session_service.BaseSessionService, memory_service: google.adk.memory.base_memory_service.BaseMemoryService, artifact_service: google.adk.artifacts.base_artifact_service.BaseArtifactService, credential_service: google.adk.auth.credential_service.base_credential_service.BaseCredentialService, eval_sets_manager: google.adk.evaluation.eval_sets_manager.EvalSetsManager, eval_set_results_manager: google.adk.evaluation.eval_set_results_manager.EvalSetResultsManager, agents_dir: str, extra_plugins: typing.Optional[list[str]]=None, logo_text: typing.Optional[str]=None, logo_image_url: typing.Optional[str]=None, url_prefix: typing.Optional[str]=None):'
- rank: 348
  id: google.adk.cli.adk_web_server.AdkWebServer.add_session_to_eval_set
  name: add_session_to_eval_set
  file_path: google/adk/cli/adk_web_server.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def add_session_to_eval_set(app_name: str, eval_set_id: str, req: google.adk.cli.adk_web_server.AddSessionToEvalSetRequest):'
- rank: 349
  id: google.adk.cli.adk_web_server.AdkWebServer.create_eval_set
  name: create_eval_set
  file_path: google/adk/cli/adk_web_server.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def create_eval_set(app_name: str, create_eval_set_request: google.adk.cli.adk_web_server.CreateEvalSetRequest) -> google.adk.evaluation.eval_set.EvalSet:'
- rank: 350
  id: google.adk.cli.adk_web_server.AdkWebServer.create_eval_set_legacy
  name: create_eval_set_legacy
  file_path: google/adk/cli/adk_web_server.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: Creates an eval set, given the id.
  signature: 'def create_eval_set_legacy(app_name: str, eval_set_id: str):'
- rank: 351
  id: google.adk.cli.adk_web_server.AdkWebServer.create_session
  name: create_session
  file_path: google/adk/cli/adk_web_server.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def create_session(app_name: str, user_id: str, req: typing.Optional[google.adk.cli.adk_web_server.CreateSessionRequest]) -> google.adk.sessions.session.Session:'
- rank: 352
  id: google.adk.cli.adk_web_server.AdkWebServer.create_session_with_id
  name: create_session_with_id
  file_path: google/adk/cli/adk_web_server.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def create_session_with_id(app_name: str, user_id: str, session_id: str, state: typing.Optional[dict[str, typing.Any]]) -> google.adk.sessions.session.Session:'
- rank: 353
  id: google.adk.cli.adk_web_server.AdkWebServer.delete_artifact
  name: delete_artifact
  file_path: google/adk/cli/adk_web_server.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def delete_artifact(app_name: str, user_id: str, session_id: str, artifact_name: str) -> None:'
- rank: 354
  id: google.adk.cli.adk_web_server.AdkWebServer.delete_eval
  name: delete_eval
  file_path: google/adk/cli/adk_web_server.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def delete_eval(app_name: str, eval_set_id: str, eval_case_id: str) -> None:'
- rank: 355
  id: google.adk.cli.adk_web_server.AdkWebServer.delete_session
  name: delete_session
  file_path: google/adk/cli/adk_web_server.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def delete_session(app_name: str, user_id: str, session_id: str) -> None:'
- rank: 356
  id: google.adk.cli.adk_web_server.AdkWebServer.event_generator
  name: event_generator
  file_path: google/adk/cli/adk_web_server.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def event_generator():'
- rank: 357
  id: google.adk.cli.adk_web_server.AdkWebServer.forward_events
  name: forward_events
  file_path: google/adk/cli/adk_web_server.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def forward_events():'
- rank: 358
  id: google.adk.cli.adk_web_server.AdkWebServer.get_eval
  name: get_eval
  file_path: google/adk/cli/adk_web_server.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: Gets an eval case in an eval set.
  signature: 'def get_eval(app_name: str, eval_set_id: str, eval_case_id: str) -> google.adk.evaluation.eval_case.EvalCase:'
- rank: 359
  id: google.adk.cli.adk_web_server.AdkWebServer.get_eval_result
  name: get_eval_result
  file_path: google/adk/cli/adk_web_server.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: Gets the eval result for the given eval id.
  signature: 'def get_eval_result(app_name: str, eval_result_id: str) -> google.adk.cli.adk_web_server.EvalResult:'
- rank: 360
  id: google.adk.cli.adk_web_server.AdkWebServer.get_eval_result_legacy
  name: get_eval_result_legacy
  file_path: google/adk/cli/adk_web_server.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def get_eval_result_legacy(app_name: str, eval_result_id: str) -> google.adk.evaluation.eval_result.EvalSetResult:'
- rank: 361
  id: google.adk.cli.adk_web_server.AdkWebServer.get_event_graph
  name: get_event_graph
  file_path: google/adk/cli/adk_web_server.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def get_event_graph(app_name: str, user_id: str, session_id: str, event_id: str):'
- rank: 362
  id: google.adk.cli.adk_web_server.AdkWebServer.get_fast_api_app
  name: get_fast_api_app
  file_path: google/adk/cli/adk_web_server.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Creates a FastAPI app for the ADK web server.\n\nBy default it'll just return a FastAPI instance with the API server\nendpoints,\nbut if you specify a web_assets_dir, it'll also serve the static web assets\nfrom that directory.\n\nArgs:\n  lifespan: The lifespan of the FastAPI app.\n  allow_origins: The origins that are allowed to make cross-origin requests.\n  web_assets_dir: The directory containing the web assets to serve.\n  setup_observer: Callback for setting up the file system observer.\n  tear_down_observer: Callback for cleaning up the file system observer.\n  register_processors: Callback for additional Span processors to be added\n    to the TracerProvider.\n  otel_to_cloud: EXPERIMENTAL. Whether to enable Cloud Trace\n  and Cloud Logging integrations.\n\nReturns:\n  A FastAPI app instance."
  signature: 'def get_fast_api_app(self, lifespan: typing.Optional[starlette.types.Lifespan[fastapi.FastAPI]], allow_origins: typing.Optional[list[str]], web_assets_dir: typing.Optional[str], setup_observer: typing.Callable[[Observer, ''AdkWebServer''], None], tear_down_observer: typing.Callable[[Observer, ''AdkWebServer''], None], register_processors: typing.Callable[[TracerProvider], None], otel_to_cloud: bool):'
- rank: 363
  id: google.adk.cli.adk_web_server.AdkWebServer.get_runner_async
  name: get_runner_async
  file_path: google/adk/cli/adk_web_server.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: Returns the cached runner for the given app.
  signature: 'def get_runner_async(self, app_name: str) -> google.adk.runners.Runner:'
- rank: 364
  id: google.adk.cli.adk_web_server.AdkWebServer.get_session
  name: get_session
  file_path: google/adk/cli/adk_web_server.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def get_session(app_name: str, user_id: str, session_id: str) -> google.adk.sessions.session.Session:'
- rank: 365
  id: google.adk.cli.adk_web_server.AdkWebServer.get_session_trace
  name: get_session_trace
  file_path: google/adk/cli/adk_web_server.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def get_session_trace(session_id: str) -> typing.Any:'
- rank: 366
  id: google.adk.cli.adk_web_server.AdkWebServer.get_trace_dict
  name: get_trace_dict
  file_path: google/adk/cli/adk_web_server.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def get_trace_dict(event_id: str) -> typing.Any:'
- rank: 367
  id: google.adk.cli.adk_web_server.AdkWebServer.get_ui_config
  name: get_ui_config
  file_path: google/adk/cli/adk_web_server.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def get_ui_config():'
- rank: 368
  id: google.adk.cli.adk_web_server.AdkWebServer.internal_lifespan
  name: internal_lifespan
  file_path: google/adk/cli/adk_web_server.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def internal_lifespan(app: fastapi.FastAPI):'
- rank: 369
  id: google.adk.cli.adk_web_server.AdkWebServer.list_apps
  name: list_apps
  file_path: google/adk/cli/adk_web_server.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def list_apps(detailed: bool) -> list[str] | ListAppsResponse:'
- rank: 370
  id: google.adk.cli.adk_web_server.AdkWebServer.list_artifact_names
  name: list_artifact_names
  file_path: google/adk/cli/adk_web_server.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def list_artifact_names(app_name: str, user_id: str, session_id: str) -> list[str]:'
- rank: 371
  id: google.adk.cli.adk_web_server.AdkWebServer.list_artifact_versions
  name: list_artifact_versions
  file_path: google/adk/cli/adk_web_server.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def list_artifact_versions(app_name: str, user_id: str, session_id: str, artifact_name: str) -> list[int]:'
- rank: 372
  id: google.adk.cli.adk_web_server.AdkWebServer.list_eval_results
  name: list_eval_results
  file_path: google/adk/cli/adk_web_server.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: Lists all eval results for the given app.
  signature: 'def list_eval_results(app_name: str) -> google.adk.cli.adk_web_server.ListEvalResultsResponse:'
- rank: 373
  id: google.adk.cli.adk_web_server.AdkWebServer.list_eval_sets
  name: list_eval_sets
  file_path: google/adk/cli/adk_web_server.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: Lists all eval sets for the given app.
  signature: 'def list_eval_sets(app_name: str) -> google.adk.cli.adk_web_server.ListEvalSetsResponse:'
- rank: 374
  id: google.adk.cli.adk_web_server.AdkWebServer.list_evals_in_eval_set
  name: list_evals_in_eval_set
  file_path: google/adk/cli/adk_web_server.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: Lists all evals in an eval set.
  signature: 'def list_evals_in_eval_set(app_name: str, eval_set_id: str) -> list[str]:'
- rank: 375
  id: google.adk.cli.adk_web_server.AdkWebServer.list_metrics_info
  name: list_metrics_info
  file_path: google/adk/cli/adk_web_server.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: Lists all eval metrics for the given app.
  signature: 'def list_metrics_info(app_name: str) -> google.adk.cli.adk_web_server.ListMetricsInfoResponse:'
- rank: 376
  id: google.adk.cli.adk_web_server.AdkWebServer.list_sessions
  name: list_sessions
  file_path: google/adk/cli/adk_web_server.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def list_sessions(app_name: str, user_id: str) -> list[google.adk.sessions.session.Session]:'
- rank: 377
  id: google.adk.cli.adk_web_server.AdkWebServer.load_artifact
  name: load_artifact
  file_path: google/adk/cli/adk_web_server.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def load_artifact(app_name: str, user_id: str, session_id: str, artifact_name: str, version: typing.Optional[int]) -> typing.Optional[google.genai.types.Part]:'
- rank: 378
  id: google.adk.cli.adk_web_server.AdkWebServer.load_artifact_version
  name: load_artifact_version
  file_path: google/adk/cli/adk_web_server.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def load_artifact_version(app_name: str, user_id: str, session_id: str, artifact_name: str, version_id: int) -> typing.Optional[google.genai.types.Part]:'
- rank: 379
  id: google.adk.cli.adk_web_server.AdkWebServer.patch_memory
  name: patch_memory
  file_path: google/adk/cli/adk_web_server.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Adds all events from a given session to the memory service.\n\nArgs:\n    app_name: The name of the application.\n    user_id: The ID of the user.\n    update_memory_request: The memory request for the update\n\nRaises:\n    HTTPException: If the memory service is not configured or the request is invalid."
  signature: 'def patch_memory(app_name: str, user_id: str, update_memory_request: google.adk.cli.adk_web_server.UpdateMemoryRequest) -> None:'
- rank: 380
  id: google.adk.cli.adk_web_server.AdkWebServer.process_messages
  name: process_messages
  file_path: google/adk/cli/adk_web_server.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def process_messages():'
- rank: 381
  id: google.adk.cli.adk_web_server.AdkWebServer.run_agent
  name: run_agent
  file_path: google/adk/cli/adk_web_server.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def run_agent(req: google.adk.cli.adk_web_server.RunAgentRequest) -> list[google.adk.events.event.Event]:'
- rank: 382
  id: google.adk.cli.adk_web_server.AdkWebServer.run_agent_live
  name: run_agent_live
  file_path: google/adk/cli/adk_web_server.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def run_agent_live(websocket: fastapi.websockets.WebSocket, app_name: str, user_id: str, session_id: str, modalities: typing.List[typing.Literal[TEXT, AUDIO]]) -> None:'
- rank: 383
  id: google.adk.cli.adk_web_server.AdkWebServer.run_agent_sse
  name: run_agent_sse
  file_path: google/adk/cli/adk_web_server.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def run_agent_sse(req: google.adk.cli.adk_web_server.RunAgentRequest) -> fastapi.responses.StreamingResponse:'
- rank: 384
  id: google.adk.cli.adk_web_server.AdkWebServer.run_eval
  name: run_eval
  file_path: google/adk/cli/adk_web_server.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: Runs an eval given the details in the eval request.
  signature: 'def run_eval(app_name: str, eval_set_id: str, req: google.adk.cli.adk_web_server.RunEvalRequest) -> google.adk.cli.adk_web_server.RunEvalResponse:'
- rank: 385
  id: google.adk.cli.adk_web_server.AdkWebServer.run_eval_legacy
  name: run_eval_legacy
  file_path: google/adk/cli/adk_web_server.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def run_eval_legacy(app_name: str, eval_set_id: str, req: google.adk.cli.adk_web_server.RunEvalRequest) -> list[google.adk.cli.adk_web_server.RunEvalResult]:'
- rank: 386
  id: google.adk.cli.adk_web_server.AdkWebServer.save_artifact
  name: save_artifact
  file_path: google/adk/cli/adk_web_server.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def save_artifact(app_name: str, user_id: str, session_id: str, req: google.adk.cli.adk_web_server.SaveArtifactRequest) -> google.adk.artifacts.base_artifact_service.ArtifactVersion:'
- rank: 387
  id: google.adk.cli.adk_web_server.AdkWebServer.update_eval
  name: update_eval
  file_path: google/adk/cli/adk_web_server.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def update_eval(app_name: str, eval_set_id: str, eval_case_id: str, updated_eval_case: google.adk.evaluation.eval_case.EvalCase):'
- rank: 388
  id: google.adk.cli.adk_web_server.AdkWebServer.update_session
  name: update_session
  file_path: google/adk/cli/adk_web_server.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Updates session state without running the agent.\n\nArgs:\n    app_name: The name of the application.\n    user_id: The ID of the user.\n    session_id: The ID of the session to update.\n    req: The patch request containing state changes.\n\nReturns:\n    The updated session.\n\nRaises:\n    HTTPException: If the session is not found."
  signature: 'def update_session(app_name: str, user_id: str, session_id: str, req: google.adk.cli.adk_web_server.UpdateSessionRequest) -> google.adk.sessions.session.Session:'
- rank: 389
  id: google.adk.cli.adk_web_server.ApiServerSpanExporter
  name: ApiServerSpanExporter
  file_path: google/adk/cli/adk_web_server.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: '[Note: Inherited members from export_lib.SpanExporter are omitted.]'
  constructor_signature: 'def __init__(self, trace_dict):'
  methods:
  - signature: 'def export(self, spans: typing.Sequence[opentelemetry.sdk.trace.ReadableSpan]) -> opentelemetry.sdk.trace.export.SpanExportResult:'
  - signature: 'def force_flush(self, timeout_millis: int) -> bool:'
  omitted_inherited_members_from:
  - export_lib.SpanExporter
- rank: 390
  id: google.adk.cli.adk_web_server.ApiServerSpanExporter.export
  name: export
  file_path: google/adk/cli/adk_web_server.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def export(self, spans: typing.Sequence[opentelemetry.sdk.trace.ReadableSpan]) -> opentelemetry.sdk.trace.export.SpanExportResult:'
- rank: 391
  id: google.adk.cli.adk_web_server.AppInfo
  name: AppInfo
  file_path: google/adk/cli/adk_web_server.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: '[Note: Inherited members from pydantic.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, name: str, root_agent_name: str, description: str, language: typing.Literal[yaml, python]):'
  properties:
  - signature: 'name: str'
  - signature: 'root_agent_name: str'
  - signature: 'description: str'
  - signature: 'language: typing.Literal[yaml, python]'
  inherited_properties:
    BaseModel:
    - signature: 'model_config: pydantic.ConfigDict'
  omitted_inherited_members_from:
  - pydantic.BaseModel
- rank: 392
  id: google.adk.cli.adk_web_server.CreateEvalSetRequest
  name: CreateEvalSetRequest
  file_path: google/adk/cli/adk_web_server.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: '[Note: Inherited members from pydantic.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, eval_set: google.adk.evaluation.eval_set.EvalSet):'
  properties:
  - signature: 'eval_set: google.adk.evaluation.eval_set.EvalSet'
  inherited_properties:
    BaseModel:
    - signature: 'model_config: pydantic.ConfigDict'
  omitted_inherited_members_from:
  - pydantic.BaseModel
- rank: 393
  id: google.adk.cli.adk_web_server.CreateSessionRequest
  name: CreateSessionRequest
  file_path: google/adk/cli/adk_web_server.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: '[Note: Inherited members from pydantic.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, session_id: typing.Optional[str] = None, state: typing.Optional[dict[str, typing.Any]] = None, events: typing.Optional[list[google.adk.events.event.Event]] = None):'
  properties:
  - signature: 'session_id: typing.Optional[str]'
  - signature: 'state: typing.Optional[dict[str, typing.Any]]'
  - signature: 'events: typing.Optional[list[google.adk.events.event.Event]]'
  inherited_properties:
    BaseModel:
    - signature: 'model_config: pydantic.ConfigDict'
  omitted_inherited_members_from:
  - pydantic.BaseModel
- rank: 394
  id: google.adk.cli.adk_web_server.EvalResult
  name: EvalResult
  file_path: google/adk/cli/adk_web_server.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'This class has no field intentionally.


    The goal here is to just give a new name to the class to align with the API

    endpoint.


    [Note: Inherited members from pydantic.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, eval_set_result_id: str, eval_set_result_name: typing.Optional[str] = None, eval_set_id: str, eval_case_results: list[google.adk.evaluation.eval_result.EvalCaseResult] = list(), creation_timestamp: float = 0.0):'
  inherited_properties:
    EvalSetResult:
    - signature: 'model_config: pydantic.ConfigDict'
    - signature: 'eval_set_result_id: str'
    - signature: 'eval_set_result_name: typing.Optional[str]'
    - signature: 'eval_set_id: str'
    - signature: 'eval_case_results: list[google.adk.evaluation.eval_result.EvalCaseResult]'
    - signature: 'creation_timestamp: float'
    BaseModel:
    - signature: 'model_config: pydantic.ConfigDict'
  omitted_inherited_members_from:
  - pydantic.BaseModel
- rank: 395
  id: google.adk.cli.adk_web_server.GetEventGraphResult
  name: GetEventGraphResult
  file_path: google/adk/cli/adk_web_server.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: '[Note: Inherited members from pydantic.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, dot_src: str):'
  properties:
  - signature: 'dot_src: str'
  inherited_properties:
    BaseModel:
    - signature: 'model_config: pydantic.ConfigDict'
  omitted_inherited_members_from:
  - pydantic.BaseModel
- rank: 396
  id: google.adk.cli.adk_web_server.InMemoryExporter
  name: InMemoryExporter
  file_path: google/adk/cli/adk_web_server.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: '[Note: Inherited members from export_lib.SpanExporter are omitted.]'
  constructor_signature: 'def __init__(self, trace_dict):'
  methods:
  - signature: 'def export(self, spans: typing.Sequence[opentelemetry.sdk.trace.ReadableSpan]) -> opentelemetry.sdk.trace.export.SpanExportResult:'
  - signature: 'def force_flush(self, timeout_millis: int) -> bool:'
  - signature: 'def get_finished_spans(self, session_id: str):'
  - signature: 'def clear(self):'
  omitted_inherited_members_from:
  - export_lib.SpanExporter
- rank: 397
  id: google.adk.cli.adk_web_server.InMemoryExporter.__init__
  name: __init__
  file_path: google/adk/cli/adk_web_server.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def __init__(self, trace_dict):'
- rank: 398
  id: google.adk.cli.adk_web_server.InMemoryExporter.export
  name: export
  file_path: google/adk/cli/adk_web_server.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def export(self, spans: typing.Sequence[opentelemetry.sdk.trace.ReadableSpan]) -> opentelemetry.sdk.trace.export.SpanExportResult:'
- rank: 399
  id: google.adk.cli.adk_web_server.InMemoryExporter.get_finished_spans
  name: get_finished_spans
  file_path: google/adk/cli/adk_web_server.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def get_finished_spans(self, session_id: str):'
- rank: 400
  id: google.adk.cli.adk_web_server.ListAppsResponse
  name: ListAppsResponse
  file_path: google/adk/cli/adk_web_server.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: '[Note: Inherited members from pydantic.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, apps: list[google.adk.cli.adk_web_server.AppInfo]):'
  properties:
  - signature: 'apps: list[google.adk.cli.adk_web_server.AppInfo]'
  inherited_properties:
    BaseModel:
    - signature: 'model_config: pydantic.ConfigDict'
  omitted_inherited_members_from:
  - pydantic.BaseModel
- rank: 401
  id: google.adk.cli.adk_web_server.ListEvalResultsResponse
  name: ListEvalResultsResponse
  file_path: google/adk/cli/adk_web_server.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: '[Note: Inherited members from pydantic.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, eval_result_ids: list[str]):'
  properties:
  - signature: 'eval_result_ids: list[str]'
  inherited_properties:
    BaseModel:
    - signature: 'model_config: pydantic.ConfigDict'
  omitted_inherited_members_from:
  - pydantic.BaseModel
- rank: 402
  id: google.adk.cli.adk_web_server.ListEvalSetsResponse
  name: ListEvalSetsResponse
  file_path: google/adk/cli/adk_web_server.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: '[Note: Inherited members from pydantic.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, eval_set_ids: list[str]):'
  properties:
  - signature: 'eval_set_ids: list[str]'
  inherited_properties:
    BaseModel:
    - signature: 'model_config: pydantic.ConfigDict'
  omitted_inherited_members_from:
  - pydantic.BaseModel
- rank: 403
  id: google.adk.cli.adk_web_server.ListMetricsInfoResponse
  name: ListMetricsInfoResponse
  file_path: google/adk/cli/adk_web_server.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: '[Note: Inherited members from pydantic.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, metrics_info: list[google.adk.evaluation.eval_metrics.MetricInfo]):'
  properties:
  - signature: 'metrics_info: list[google.adk.evaluation.eval_metrics.MetricInfo]'
  inherited_properties:
    BaseModel:
    - signature: 'model_config: pydantic.ConfigDict'
  omitted_inherited_members_from:
  - pydantic.BaseModel
- rank: 404
  id: google.adk.cli.adk_web_server.RunAgentRequest
  name: RunAgentRequest
  file_path: google/adk/cli/adk_web_server.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: '[Note: Inherited members from pydantic.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, app_name: str, user_id: str, session_id: str, new_message: google.genai.types.Content, streaming: bool = False, state_delta: typing.Optional[dict[str, typing.Any]] = None):'
  properties:
  - signature: 'app_name: str'
  - signature: 'user_id: str'
  - signature: 'session_id: str'
  - signature: 'new_message: google.genai.types.Content'
  - signature: 'streaming: bool'
  - signature: 'state_delta: typing.Optional[dict[str, typing.Any]]'
  - signature: 'invocation_id: typing.Optional[str]'
  inherited_properties:
    BaseModel:
    - signature: 'model_config: pydantic.ConfigDict'
  omitted_inherited_members_from:
  - pydantic.BaseModel
- rank: 405
  id: google.adk.cli.adk_web_server.RunEvalRequest
  name: RunEvalRequest
  file_path: google/adk/cli/adk_web_server.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: '[Note: Inherited members from pydantic.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, eval_ids: list[str] = list(), eval_case_ids: list[str] = list(), eval_metrics: list[google.adk.evaluation.eval_metrics.EvalMetric]):'
  properties:
  - signature: 'eval_ids: list[str]'
  - signature: 'eval_case_ids: list[str]'
  - signature: 'eval_metrics: list[google.adk.evaluation.eval_metrics.EvalMetric]'
  inherited_properties:
    BaseModel:
    - signature: 'model_config: pydantic.ConfigDict'
  omitted_inherited_members_from:
  - pydantic.BaseModel
- rank: 406
  id: google.adk.cli.adk_web_server.RunEvalResponse
  name: RunEvalResponse
  file_path: google/adk/cli/adk_web_server.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: '[Note: Inherited members from pydantic.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, run_eval_results: list[google.adk.cli.adk_web_server.RunEvalResult]):'
  properties:
  - signature: 'run_eval_results: list[google.adk.cli.adk_web_server.RunEvalResult]'
  inherited_properties:
    BaseModel:
    - signature: 'model_config: pydantic.ConfigDict'
  omitted_inherited_members_from:
  - pydantic.BaseModel
- rank: 407
  id: google.adk.cli.adk_web_server.RunEvalResult
  name: RunEvalResult
  file_path: google/adk/cli/adk_web_server.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: '[Note: Inherited members from pydantic.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, eval_set_file: str, eval_set_id: str, eval_id: str, final_eval_status: google.adk.evaluation.eval_metrics.EvalStatus, eval_metric_results: list[tuple[google.adk.evaluation.eval_metrics.EvalMetric, google.adk.evaluation.eval_metrics.EvalMetricResult]] = [], overall_eval_metric_results: list[google.adk.evaluation.eval_metrics.EvalMetricResult], eval_metric_result_per_invocation: list[google.adk.evaluation.eval_metrics.EvalMetricResultPerInvocation], user_id: str, session_id: str):'
  properties:
  - signature: 'eval_set_file: str'
  - signature: 'eval_set_id: str'
  - signature: 'eval_id: str'
  - signature: 'final_eval_status: google.adk.evaluation.eval_metrics.EvalStatus'
  - signature: 'eval_metric_results: list[tuple[google.adk.evaluation.eval_metrics.EvalMetric, google.adk.evaluation.eval_metrics.EvalMetricResult]]'
  - signature: 'overall_eval_metric_results: list[google.adk.evaluation.eval_metrics.EvalMetricResult]'
  - signature: 'eval_metric_result_per_invocation: list[google.adk.evaluation.eval_metrics.EvalMetricResultPerInvocation]'
  - signature: 'user_id: str'
  - signature: 'session_id: str'
  inherited_properties:
    BaseModel:
    - signature: 'model_config: pydantic.ConfigDict'
  omitted_inherited_members_from:
  - pydantic.BaseModel
- rank: 408
  id: google.adk.cli.adk_web_server.SaveArtifactRequest
  name: SaveArtifactRequest
  file_path: google/adk/cli/adk_web_server.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Request payload for saving a new artifact.


    [Note: Inherited members from pydantic.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, filename: str, artifact: google.genai.types.Part, custom_metadata: typing.Optional[dict[str, typing.Any]] = None):'
  properties:
  - signature: 'filename: str'
  - signature: 'artifact: google.genai.types.Part'
  - signature: 'custom_metadata: typing.Optional[dict[str, typing.Any]]'
  inherited_properties:
    BaseModel:
    - signature: 'model_config: pydantic.ConfigDict'
  omitted_inherited_members_from:
  - pydantic.BaseModel
- rank: 409
  id: google.adk.cli.adk_web_server.UpdateMemoryRequest
  name: UpdateMemoryRequest
  file_path: google/adk/cli/adk_web_server.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Request to add a session to the memory service.


    [Note: Inherited members from pydantic.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, session_id: str):'
  properties:
  - signature: 'session_id: str'
    docstring: The ID of the session to add to memory.
  inherited_properties:
    BaseModel:
    - signature: 'model_config: pydantic.ConfigDict'
  omitted_inherited_members_from:
  - pydantic.BaseModel
- rank: 410
  id: google.adk.cli.adk_web_server.UpdateSessionRequest
  name: UpdateSessionRequest
  file_path: google/adk/cli/adk_web_server.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Request to update session state without running the agent.


    [Note: Inherited members from pydantic.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, state_delta: dict[str, typing.Any]):'
  properties:
  - signature: 'state_delta: dict[str, typing.Any]'
    docstring: The state changes to apply to the session.
  inherited_properties:
    BaseModel:
    - signature: 'model_config: pydantic.ConfigDict'
  omitted_inherited_members_from:
  - pydantic.BaseModel
- rank: 411
  id: google.adk.cli.agent_graph
  name: agent_graph
  file_path: google/adk/cli/agent_graph.py
  type: MODULE
  group: Orphan
  usage_score: 0
  methods:
  - signature: 'def build_graph(graph: graphviz.Digraph, agent: google.adk.agents.base_agent.BaseAgent, highlight_pairs, parent_agent):'
    docstring: "Build a graph of the agent and its sub-agents.\nArgs:\n  graph: The graph to build on.\n  agent: The agent to build the graph for.\n  highlight_pairs: A list of pairs of nodes to highlight.\n  parent_agent: The parent agent of the current agent. This is specifically used when building Workflow Agents to directly connect a node to nodes inside a Workflow Agent.\n\nReturns:\n  None"
  - signature: 'def get_node_name(tool_or_agent: typing.Union[google.adk.agents.base_agent.BaseAgent, google.adk.tools.base_tool.BaseTool]):'
  - signature: 'def get_node_caption(tool_or_agent: typing.Union[google.adk.agents.base_agent.BaseAgent, google.adk.tools.base_tool.BaseTool]):'
  - signature: 'def get_node_shape(tool_or_agent: typing.Union[google.adk.agents.base_agent.BaseAgent, google.adk.tools.base_tool.BaseTool]):'
  - signature: 'def should_build_agent_cluster(tool_or_agent: typing.Union[google.adk.agents.base_agent.BaseAgent, google.adk.tools.base_tool.BaseTool]):'
  - signature: 'def build_cluster(child: graphviz.Digraph, agent: google.adk.agents.base_agent.BaseAgent, name: str):'
  - signature: 'def draw_node(tool_or_agent: typing.Union[google.adk.agents.base_agent.BaseAgent, google.adk.tools.base_tool.BaseTool]):'
  - signature: 'def draw_edge(from_name, to_name):'
  - signature: 'def get_agent_graph(root_agent, highlights_pairs, image):'
- rank: 412
  id: google.adk.cli.agent_graph.build_cluster
  name: build_cluster
  file_path: google/adk/cli/agent_graph.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def build_cluster(child: graphviz.Digraph, agent: google.adk.agents.base_agent.BaseAgent, name: str):'
- rank: 413
  id: google.adk.cli.agent_graph.build_graph
  name: build_graph
  file_path: google/adk/cli/agent_graph.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Build a graph of the agent and its sub-agents.\nArgs:\n  graph: The graph to build on.\n  agent: The agent to build the graph for.\n  highlight_pairs: A list of pairs of nodes to highlight.\n  parent_agent: The parent agent of the current agent. This is specifically used when building Workflow Agents to directly connect a node to nodes inside a Workflow Agent.\n\nReturns:\n  None"
  signature: 'def build_graph(graph: graphviz.Digraph, agent: google.adk.agents.base_agent.BaseAgent, highlight_pairs, parent_agent):'
- rank: 414
  id: google.adk.cli.agent_graph.draw_edge
  name: draw_edge
  file_path: google/adk/cli/agent_graph.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def draw_edge(from_name, to_name):'
- rank: 415
  id: google.adk.cli.agent_graph.draw_node
  name: draw_node
  file_path: google/adk/cli/agent_graph.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def draw_node(tool_or_agent: typing.Union[google.adk.agents.base_agent.BaseAgent, google.adk.tools.base_tool.BaseTool]):'
- rank: 416
  id: google.adk.cli.agent_graph.get_agent_graph
  name: get_agent_graph
  file_path: google/adk/cli/agent_graph.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def get_agent_graph(root_agent, highlights_pairs, image):'
- rank: 417
  id: google.adk.cli.agent_graph.get_node_caption
  name: get_node_caption
  file_path: google/adk/cli/agent_graph.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def get_node_caption(tool_or_agent: typing.Union[google.adk.agents.base_agent.BaseAgent, google.adk.tools.base_tool.BaseTool]):'
- rank: 418
  id: google.adk.cli.agent_graph.get_node_name
  name: get_node_name
  file_path: google/adk/cli/agent_graph.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def get_node_name(tool_or_agent: typing.Union[google.adk.agents.base_agent.BaseAgent, google.adk.tools.base_tool.BaseTool]):'
- rank: 419
  id: google.adk.cli.agent_graph.get_node_shape
  name: get_node_shape
  file_path: google/adk/cli/agent_graph.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def get_node_shape(tool_or_agent: typing.Union[google.adk.agents.base_agent.BaseAgent, google.adk.tools.base_tool.BaseTool]):'
- rank: 420
  id: google.adk.cli.agent_graph.should_build_agent_cluster
  name: should_build_agent_cluster
  file_path: google/adk/cli/agent_graph.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def should_build_agent_cluster(tool_or_agent: typing.Union[google.adk.agents.base_agent.BaseAgent, google.adk.tools.base_tool.BaseTool]):'
- rank: 421
  id: google.adk.cli.built_in_agents
  name: built_in_agents
  file_path: google/adk/cli/built_in_agents/__init__.py
  type: MODULE
  group: Orphan
  usage_score: 0
  docstring: 'Agent Builder Assistant for ADK.


    This package provides an intelligent assistant for building multi-agent systems

    using YAML configurations. It can be used directly as an agent or integrated

    with ADK tools and web interfaces.'
- rank: 422
  id: google.adk.cli.built_in_agents.adk_agent_builder_assistant
  name: adk_agent_builder_assistant
  file_path: google/adk/cli/built_in_agents/adk_agent_builder_assistant.py
  type: MODULE
  group: Orphan
  usage_score: 0
  docstring: Agent factory for creating Agent Builder Assistant with embedded schema.
- rank: 423
  id: google.adk.cli.built_in_agents.adk_agent_builder_assistant.AgentBuilderAssistant
  name: AgentBuilderAssistant
  file_path: google/adk/cli/built_in_agents/adk_agent_builder_assistant.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: Agent Builder Assistant factory for creating configured instances.
  methods:
  - signature: 'def create_agent(model: typing.Union[str, google.adk.models.BaseLlm], working_directory: typing.Optional[str]) -> google.adk.agents.LlmAgent:'
    docstring: "Create Agent Builder Assistant with embedded ADK AgentConfig schema.\n\nArgs:\n  model: Model to use for the assistant (default: gemini-2.5-flash)\n  working_directory: Working directory for path resolution (default: current\n    working directory)\n\nReturns:\n  Configured LlmAgent with embedded ADK AgentConfig schema"
  - signature: 'def add(text: str, indent: int) -> None:'
    docstring: Append wrapped text with indentation.
  - signature: 'def instruction_provider(context: google.adk.agents.readonly_context.ReadonlyContext) -> str:'
- rank: 424
  id: google.adk.cli.built_in_agents.adk_agent_builder_assistant.AgentBuilderAssistant.add
  name: add
  file_path: google/adk/cli/built_in_agents/adk_agent_builder_assistant.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: Append wrapped text with indentation.
  signature: 'def add(text: str, indent: int) -> None:'
- rank: 425
  id: google.adk.cli.built_in_agents.adk_agent_builder_assistant.AgentBuilderAssistant.create_agent
  name: create_agent
  file_path: google/adk/cli/built_in_agents/adk_agent_builder_assistant.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Create Agent Builder Assistant with embedded ADK AgentConfig schema.\n\nArgs:\n  model: Model to use for the assistant (default: gemini-2.5-flash)\n  working_directory: Working directory for path resolution (default: current\n    working directory)\n\nReturns:\n  Configured LlmAgent with embedded ADK AgentConfig schema"
  signature: 'def create_agent(model: typing.Union[str, google.adk.models.BaseLlm], working_directory: typing.Optional[str]) -> google.adk.agents.LlmAgent:'
- rank: 426
  id: google.adk.cli.built_in_agents.adk_agent_builder_assistant.AgentBuilderAssistant.instruction_provider
  name: instruction_provider
  file_path: google/adk/cli/built_in_agents/adk_agent_builder_assistant.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def instruction_provider(context: google.adk.agents.readonly_context.ReadonlyContext) -> str:'
- rank: 427
  id: google.adk.cli.built_in_agents.agent
  name: agent
  file_path: google/adk/cli/built_in_agents/agent.py
  type: MODULE
  group: Orphan
  usage_score: 0
  docstring: Agent Builder Assistant instance for ADK web testing.
- rank: 428
  id: google.adk.cli.built_in_agents.sub_agents
  name: sub_agents
  file_path: google/adk/cli/built_in_agents/sub_agents/__init__.py
  type: MODULE
  group: Orphan
  usage_score: 0
  docstring: Sub-agents for Agent Builder Assistant.
- rank: 429
  id: google.adk.cli.built_in_agents.sub_agents.google_search_agent
  name: google_search_agent
  file_path: google/adk/cli/built_in_agents/sub_agents/google_search_agent.py
  type: MODULE
  group: Orphan
  usage_score: 0
  docstring: Sub-agent for Google Search functionality.
  methods:
  - signature: 'def create_google_search_agent() -> google.adk.agents.LlmAgent:'
    docstring: Create a sub-agent that only uses google_search tool.
- rank: 430
  id: google.adk.cli.built_in_agents.sub_agents.google_search_agent.create_google_search_agent
  name: create_google_search_agent
  file_path: google/adk/cli/built_in_agents/sub_agents/google_search_agent.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: Create a sub-agent that only uses google_search tool.
  signature: 'def create_google_search_agent() -> google.adk.agents.LlmAgent:'
- rank: 431
  id: google.adk.cli.built_in_agents.sub_agents.url_context_agent
  name: url_context_agent
  file_path: google/adk/cli/built_in_agents/sub_agents/url_context_agent.py
  type: MODULE
  group: Orphan
  usage_score: 0
  docstring: Sub-agent for URL context fetching functionality.
  methods:
  - signature: 'def create_url_context_agent() -> google.adk.agents.LlmAgent:'
    docstring: Create a sub-agent that only uses url_context tool.
- rank: 432
  id: google.adk.cli.built_in_agents.sub_agents.url_context_agent.create_url_context_agent
  name: create_url_context_agent
  file_path: google/adk/cli/built_in_agents/sub_agents/url_context_agent.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: Create a sub-agent that only uses url_context tool.
  signature: 'def create_url_context_agent() -> google.adk.agents.LlmAgent:'
- rank: 433
  id: google.adk.cli.built_in_agents.tools
  name: tools
  file_path: google/adk/cli/built_in_agents/tools/__init__.py
  type: MODULE
  group: Orphan
  usage_score: 0
  docstring: Tools for Agent Builder Assistant.
- rank: 434
  id: google.adk.cli.built_in_agents.tools.cleanup_unused_files
  name: cleanup_unused_files
  file_path: google/adk/cli/built_in_agents/tools/cleanup_unused_files.py
  type: MODULE
  group: Orphan
  usage_score: 0
  docstring: Cleanup unused files tool for Agent Builder Assistant.
  methods:
  - signature: 'def cleanup_unused_files(used_files: list[str], tool_context: google.adk.tools.tool_context.ToolContext, file_patterns: list[str] | None, exclude_patterns: list[str] | None) -> dict[str, typing.Any]:'
    docstring: "Identify and optionally delete unused files in project directories.\n\nThis tool helps clean up unused tool files when agent configurations change.\nIt identifies files that match patterns but aren't referenced in used_files\nlist. Paths are resolved automatically using the tool context.\n\nArgs:\n  used_files: List of file paths currently in use (should not be deleted)\n  tool_context: Tool execution context (provides session state)\n  file_patterns: List of glob patterns to match files (default: [\"*.py\"])\n  exclude_patterns: List of patterns to exclude (default: [\"__init__.py\"])\n\nReturns:\n  Dict containing cleanup results:\n    - success: bool indicating if scan succeeded\n    - unused_files: list of unused files found\n    - deleted_files: list of files actually deleted\n    - backup_files: list of backup files created\n    - errors: list of error messages\n    - total_freed_space: total bytes freed by deletions"
- rank: 435
  id: google.adk.cli.built_in_agents.tools.cleanup_unused_files.cleanup_unused_files
  name: cleanup_unused_files
  file_path: google/adk/cli/built_in_agents/tools/cleanup_unused_files.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Identify and optionally delete unused files in project directories.\n\nThis tool helps clean up unused tool files when agent configurations change.\nIt identifies files that match patterns but aren't referenced in used_files\nlist. Paths are resolved automatically using the tool context.\n\nArgs:\n  used_files: List of file paths currently in use (should not be deleted)\n  tool_context: Tool execution context (provides session state)\n  file_patterns: List of glob patterns to match files (default: [\"*.py\"])\n  exclude_patterns: List of patterns to exclude (default: [\"__init__.py\"])\n\nReturns:\n  Dict containing cleanup results:\n    - success: bool indicating if scan succeeded\n    - unused_files: list of unused files found\n    - deleted_files: list of files actually deleted\n    - backup_files: list of backup files created\n    - errors: list of error messages\n    - total_freed_space: total bytes freed by deletions"
  signature: 'def cleanup_unused_files(used_files: list[str], tool_context: google.adk.tools.tool_context.ToolContext, file_patterns: list[str] | None, exclude_patterns: list[str] | None) -> dict[str, typing.Any]:'
- rank: 436
  id: google.adk.cli.built_in_agents.tools.delete_files
  name: delete_files
  file_path: google/adk/cli/built_in_agents/tools/delete_files.py
  type: MODULE
  group: Orphan
  usage_score: 0
  docstring: File deletion tool for Agent Builder Assistant.
  methods:
  - signature: 'def delete_files(file_paths: typing.List[str], tool_context: google.adk.tools.tool_context.ToolContext, create_backup: bool, confirm_deletion: bool) -> typing.Dict[str, typing.Any]:'
    docstring: "Delete multiple files with optional backup creation.\n\nThis tool safely deletes multiple files with validation and optional backup\ncreation.\nIt's designed for cleaning up unused tool files when agent configurations\nchange.\n\nArgs:\n  file_paths: List of absolute or relative paths to files to delete\n  create_backup: Whether to create a backup before deletion (default: False)\n  confirm_deletion: Whether deletion was confirmed by user (default: True for\n    safety)\n\nReturns:\n  Dict containing deletion operation results:\n    - success: bool indicating if all deletions succeeded\n    - files: dict mapping file_path to file deletion info:\n      - existed: bool indicating if file existed before deletion\n      - backup_created: bool indicating if backup was created\n      - backup_path: path to backup file if created\n      - error: error message if deletion failed for this file\n      - file_size: size of deleted file in bytes (if existed)\n    - successful_deletions:\
      \ number of files deleted successfully\n    - total_files: total number of files requested\n    - errors: list of general error messages"
- rank: 437
  id: google.adk.cli.built_in_agents.tools.delete_files.delete_files
  name: delete_files
  file_path: google/adk/cli/built_in_agents/tools/delete_files.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Delete multiple files with optional backup creation.\n\nThis tool safely deletes multiple files with validation and optional backup\ncreation.\nIt's designed for cleaning up unused tool files when agent configurations\nchange.\n\nArgs:\n  file_paths: List of absolute or relative paths to files to delete\n  create_backup: Whether to create a backup before deletion (default: False)\n  confirm_deletion: Whether deletion was confirmed by user (default: True for\n    safety)\n\nReturns:\n  Dict containing deletion operation results:\n    - success: bool indicating if all deletions succeeded\n    - files: dict mapping file_path to file deletion info:\n      - existed: bool indicating if file existed before deletion\n      - backup_created: bool indicating if backup was created\n      - backup_path: path to backup file if created\n      - error: error message if deletion failed for this file\n      - file_size: size of deleted file in bytes (if existed)\n    - successful_deletions:\
    \ number of files deleted successfully\n    - total_files: total number of files requested\n    - errors: list of general error messages"
  signature: 'def delete_files(file_paths: typing.List[str], tool_context: google.adk.tools.tool_context.ToolContext, create_backup: bool, confirm_deletion: bool) -> typing.Dict[str, typing.Any]:'
- rank: 438
  id: google.adk.cli.built_in_agents.tools.explore_project
  name: explore_project
  file_path: google/adk/cli/built_in_agents/tools/explore_project.py
  type: MODULE
  group: Orphan
  usage_score: 0
  docstring: Project explorer tool for analyzing structure and suggesting file paths.
  methods:
  - signature: 'def explore_project(tool_context: google.adk.tools.tool_context.ToolContext) -> typing.Dict[str, typing.Any]:'
    docstring: "Analyze project structure and suggest optimal file paths for ADK agents.\n\nThis tool performs comprehensive project analysis to understand the existing\nstructure and recommend appropriate locations for new agent configurations,\ntools, and related files following ADK best practices.\n\nThe tool automatically determines the project directory from session state.\n\nReturns:\n  Dict containing analysis results with ALL PATHS RELATIVE TO PROJECT FOLDER:\n    Always included:\n      - success: bool indicating if exploration succeeded\n\n    Success cases only (success=True):\n      - project_info: dict with basic project metadata. Contains:\n                     \u2022 \"name\": project directory name\n                     \u2022 \"absolute_path\": full path to project root\n                     \u2022 \"is_empty\": bool indicating if directory is empty\n                     \u2022 \"total_files\": count of all files in project\n                     \u2022 \"total_directories\"\
      : count of all subdirectories\n                     \u2022 \"has_python_files\": bool indicating presence of .py\n                     files\n                     \u2022 \"has_yaml_files\": bool indicating presence of\n                     .yaml/.yml files\n                     \u2022 \"has_tools_directory\": bool indicating if tools/ exists\n                     \u2022 \"has_callbacks_directory\": bool indicating if\n                     callbacks/ exists\n      - existing_configs: list of dicts for found YAML configuration files.\n                         Each dict contains:\n                         \u2022 \"filename\": name of the config file\n                         \u2022 \"relative_path\": path relative to project folder\n                         \u2022 \"size\": file size in bytes\n                         \u2022 \"is_valid_yaml\": bool indicating if YAML parses\n                         correctly\n                         \u2022 \"agent_name\": extracted agent name (or None)\n\
      \                         \u2022 \"agent_class\": agent class type (default:\n                         \"LlmAgent\")\n                         \u2022 \"has_sub_agents\": bool indicating if config has\n                         sub_agents\n                         \u2022 \"has_tools\": bool indicating if config has tools\n      - directory_structure: dict with hierarchical project tree view\n      - suggestions: dict with recommended paths for new components. Contains:\n                    \u2022 \"root_agent_configs\": list of suggested main agent\n                    filenames\n                    \u2022 \"sub_agent_patterns\": list of naming pattern templates\n                    \u2022 \"directories\": dict with tool/callback directory info\n                    \u2022 \"naming_examples\": dict with example agent sets by\n                    domain\n      - conventions: dict with ADK naming and organization best practices\n\n    Error cases only (success=False):\n      - error: descriptive\
      \ error message explaining the failure\n\nExamples:\n  Basic project exploration:\n    result = await explore_project(tool_context)\n\n  Check project structure:\n    if result[\"project_info\"][\"has_tools_directory\"]:\n        print(\"Tools directory already exists\")\n\n  Analyze existing configs:\n    for config in result[\"existing_configs\"]:\n        if config[\"is_valid_yaml\"]:\n            print(f\"Found agent: {config['agent_name']}\")\n\n  Get path suggestions:\n    suggestions = result[\"suggestions\"][\"root_agent_configs\"]\n    directories = result[\"suggestions\"][\"directories\"][\"tools\"]"
  - signature: 'def build_tree_recursive(path: pathlib.Path, current_depth: int) -> typing.Dict[str, typing.Any]:'
- rank: 439
  id: google.adk.cli.built_in_agents.tools.explore_project.build_tree_recursive
  name: build_tree_recursive
  file_path: google/adk/cli/built_in_agents/tools/explore_project.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def build_tree_recursive(path: pathlib.Path, current_depth: int) -> typing.Dict[str, typing.Any]:'
- rank: 440
  id: google.adk.cli.built_in_agents.tools.explore_project.explore_project
  name: explore_project
  file_path: google/adk/cli/built_in_agents/tools/explore_project.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Analyze project structure and suggest optimal file paths for ADK agents.\n\nThis tool performs comprehensive project analysis to understand the existing\nstructure and recommend appropriate locations for new agent configurations,\ntools, and related files following ADK best practices.\n\nThe tool automatically determines the project directory from session state.\n\nReturns:\n  Dict containing analysis results with ALL PATHS RELATIVE TO PROJECT FOLDER:\n    Always included:\n      - success: bool indicating if exploration succeeded\n\n    Success cases only (success=True):\n      - project_info: dict with basic project metadata. Contains:\n                     \u2022 \"name\": project directory name\n                     \u2022 \"absolute_path\": full path to project root\n                     \u2022 \"is_empty\": bool indicating if directory is empty\n                     \u2022 \"total_files\": count of all files in project\n                     \u2022 \"total_directories\"\
    : count of all subdirectories\n                     \u2022 \"has_python_files\": bool indicating presence of .py\n                     files\n                     \u2022 \"has_yaml_files\": bool indicating presence of\n                     .yaml/.yml files\n                     \u2022 \"has_tools_directory\": bool indicating if tools/ exists\n                     \u2022 \"has_callbacks_directory\": bool indicating if\n                     callbacks/ exists\n      - existing_configs: list of dicts for found YAML configuration files.\n                         Each dict contains:\n                         \u2022 \"filename\": name of the config file\n                         \u2022 \"relative_path\": path relative to project folder\n                         \u2022 \"size\": file size in bytes\n                         \u2022 \"is_valid_yaml\": bool indicating if YAML parses\n                         correctly\n                         \u2022 \"agent_name\": extracted agent name (or None)\n\
    \                         \u2022 \"agent_class\": agent class type (default:\n                         \"LlmAgent\")\n                         \u2022 \"has_sub_agents\": bool indicating if config has\n                         sub_agents\n                         \u2022 \"has_tools\": bool indicating if config has tools\n      - directory_structure: dict with hierarchical project tree view\n      - suggestions: dict with recommended paths for new components. Contains:\n                    \u2022 \"root_agent_configs\": list of suggested main agent\n                    filenames\n                    \u2022 \"sub_agent_patterns\": list of naming pattern templates\n                    \u2022 \"directories\": dict with tool/callback directory info\n                    \u2022 \"naming_examples\": dict with example agent sets by\n                    domain\n      - conventions: dict with ADK naming and organization best practices\n\n    Error cases only (success=False):\n      - error: descriptive\
    \ error message explaining the failure\n\nExamples:\n  Basic project exploration:\n    result = await explore_project(tool_context)\n\n  Check project structure:\n    if result[\"project_info\"][\"has_tools_directory\"]:\n        print(\"Tools directory already exists\")\n\n  Analyze existing configs:\n    for config in result[\"existing_configs\"]:\n        if config[\"is_valid_yaml\"]:\n            print(f\"Found agent: {config['agent_name']}\")\n\n  Get path suggestions:\n    suggestions = result[\"suggestions\"][\"root_agent_configs\"]\n    directories = result[\"suggestions\"][\"directories\"][\"tools\"]"
  signature: 'def explore_project(tool_context: google.adk.tools.tool_context.ToolContext) -> typing.Dict[str, typing.Any]:'
- rank: 441
  id: google.adk.cli.built_in_agents.tools.query_schema
  name: query_schema
  file_path: google/adk/cli/built_in_agents/tools/query_schema.py
  type: MODULE
  group: Orphan
  usage_score: 0
  docstring: ADK AgentConfig schema query tool for dynamic schema information access.
  methods:
  - signature: 'def query_schema(query_type: str, component: typing.Optional[str], field_path: typing.Optional[str]) -> typing.Dict[str, typing.Any]:'
    docstring: "Dynamically query ADK AgentConfig schema for specific information.\n\nThis tool provides on-demand access to ADK AgentConfig schema details without\nembedding\nthe full schema in context. It's designed for \"query\" mode where\nagents need specific schema information without the memory overhead\nof the complete schema.\n\nArgs:\n  query_type: Type of schema query to perform. Supported values: - \"overview\":\n    Get high-level schema structure and main properties - \"component\": Get\n    detailed info about a specific top-level component - \"field\": Get details\n    about a specific field using dot notation - \"properties\": Get flat list of\n    all available properties\n  component: Component name to explore (required for \"component\" query_type).\n            Examples: \"name\", \"instruction\", \"tools\", \"model\", \"memory\"\n  field_path: Dot-separated path to specific field (required for \"field\"\n    query_type).\n             Examples: \"tools.function_tool.function_path\"\
      , \"model.name\"\n\nReturns:\n  Dict containing schema exploration results:\n    Always included:\n      - query_type: type of query performed\n      - success: bool indicating if exploration succeeded\n\n    Success cases vary by query_type:\n      overview: schema title, description, main properties list\n      component: component details, nested properties, type info\n      field: field traversal path, type, description, constraints\n      properties: complete flat property list with types\n\n    Error cases only (success=False):\n      - error: descriptive error message\n      - supported_queries: list of valid query types and usage\n\nExamples:\n  Get schema overview:\n    result = await query_schema(\"overview\")\n\n  Explore tools component:\n    result = await query_schema(\"component\", component=\"tools\")\n\n  Get specific field details:\n    result = await query_schema(\"field\", field_path=\"model.name\")"
  - signature: 'def extract_properties(obj: typing.Dict[str, typing.Any], prefix: str):'
- rank: 442
  id: google.adk.cli.built_in_agents.tools.query_schema.extract_properties
  name: extract_properties
  file_path: google/adk/cli/built_in_agents/tools/query_schema.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def extract_properties(obj: typing.Dict[str, typing.Any], prefix: str):'
- rank: 443
  id: google.adk.cli.built_in_agents.tools.query_schema.query_schema
  name: query_schema
  file_path: google/adk/cli/built_in_agents/tools/query_schema.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Dynamically query ADK AgentConfig schema for specific information.\n\nThis tool provides on-demand access to ADK AgentConfig schema details without\nembedding\nthe full schema in context. It's designed for \"query\" mode where\nagents need specific schema information without the memory overhead\nof the complete schema.\n\nArgs:\n  query_type: Type of schema query to perform. Supported values: - \"overview\":\n    Get high-level schema structure and main properties - \"component\": Get\n    detailed info about a specific top-level component - \"field\": Get details\n    about a specific field using dot notation - \"properties\": Get flat list of\n    all available properties\n  component: Component name to explore (required for \"component\" query_type).\n            Examples: \"name\", \"instruction\", \"tools\", \"model\", \"memory\"\n  field_path: Dot-separated path to specific field (required for \"field\"\n    query_type).\n             Examples: \"tools.function_tool.function_path\"\
    , \"model.name\"\n\nReturns:\n  Dict containing schema exploration results:\n    Always included:\n      - query_type: type of query performed\n      - success: bool indicating if exploration succeeded\n\n    Success cases vary by query_type:\n      overview: schema title, description, main properties list\n      component: component details, nested properties, type info\n      field: field traversal path, type, description, constraints\n      properties: complete flat property list with types\n\n    Error cases only (success=False):\n      - error: descriptive error message\n      - supported_queries: list of valid query types and usage\n\nExamples:\n  Get schema overview:\n    result = await query_schema(\"overview\")\n\n  Explore tools component:\n    result = await query_schema(\"component\", component=\"tools\")\n\n  Get specific field details:\n    result = await query_schema(\"field\", field_path=\"model.name\")"
  signature: 'def query_schema(query_type: str, component: typing.Optional[str], field_path: typing.Optional[str]) -> typing.Dict[str, typing.Any]:'
- rank: 444
  id: google.adk.cli.built_in_agents.tools.read_config_files
  name: read_config_files
  file_path: google/adk/cli/built_in_agents/tools/read_config_files.py
  type: MODULE
  group: Orphan
  usage_score: 0
  docstring: Configuration file reader tool for existing YAML configs.
  methods:
  - signature: 'def read_config_files(file_paths: typing.List[str], tool_context: google.adk.tools.tool_context.ToolContext) -> typing.Dict[str, typing.Any]:'
    docstring: "Read multiple YAML configuration files and extract metadata.\n\nArgs:\n  file_paths: List of absolute or relative paths to YAML configuration files\n\nReturns:\n  Dict containing:\n    - success: bool indicating if all files were processed\n    - total_files: number of files requested\n    - successful_reads: number of files read successfully\n    - files: dict mapping file_path to file analysis:\n      - success: bool for this specific file\n      - file_path: absolute path to the file\n      - file_size: size of file in characters\n      - line_count: number of lines in file\n      - content: parsed YAML content as dict (success only)\n      - agent_info: extracted agent metadata (success only)\n      - sub_agents: list of referenced sub-agent files (success only)\n      - tools: list of tools used by the agent (success only)\n      - error: error message (failure only)\n      - raw_yaml: original YAML string (parsing errors only)\n    - errors: list of general error messages"
- rank: 445
  id: google.adk.cli.built_in_agents.tools.read_config_files.read_config_files
  name: read_config_files
  file_path: google/adk/cli/built_in_agents/tools/read_config_files.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Read multiple YAML configuration files and extract metadata.\n\nArgs:\n  file_paths: List of absolute or relative paths to YAML configuration files\n\nReturns:\n  Dict containing:\n    - success: bool indicating if all files were processed\n    - total_files: number of files requested\n    - successful_reads: number of files read successfully\n    - files: dict mapping file_path to file analysis:\n      - success: bool for this specific file\n      - file_path: absolute path to the file\n      - file_size: size of file in characters\n      - line_count: number of lines in file\n      - content: parsed YAML content as dict (success only)\n      - agent_info: extracted agent metadata (success only)\n      - sub_agents: list of referenced sub-agent files (success only)\n      - tools: list of tools used by the agent (success only)\n      - error: error message (failure only)\n      - raw_yaml: original YAML string (parsing errors only)\n    - errors: list of general error messages"
  signature: 'def read_config_files(file_paths: typing.List[str], tool_context: google.adk.tools.tool_context.ToolContext) -> typing.Dict[str, typing.Any]:'
- rank: 446
  id: google.adk.cli.built_in_agents.tools.read_files
  name: read_files
  file_path: google/adk/cli/built_in_agents/tools/read_files.py
  type: MODULE
  group: Orphan
  usage_score: 0
  docstring: File reading tool for Agent Builder Assistant.
  methods:
  - signature: 'def read_files(file_paths: typing.List[str], tool_context: google.adk.tools.tool_context.ToolContext) -> typing.Dict[str, typing.Any]:'
    docstring: "Read content from multiple files.\n\nThis tool reads content from multiple files and returns their contents.\nIt's designed for reading Python tools, configuration files, and other text\nfiles.\n\nArgs:\n  file_paths: List of absolute or relative paths to files to read\n\nReturns:\n  Dict containing read operation results:\n    - success: bool indicating if all reads succeeded\n    - files: dict mapping file_path to file info:\n      - content: file content as string\n      - file_size: size of file in bytes\n      - exists: bool indicating if file exists\n      - error: error message if read failed for this file\n    - successful_reads: number of files read successfully\n    - total_files: total number of files requested\n    - errors: list of general error messages"
- rank: 447
  id: google.adk.cli.built_in_agents.tools.read_files.read_files
  name: read_files
  file_path: google/adk/cli/built_in_agents/tools/read_files.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Read content from multiple files.\n\nThis tool reads content from multiple files and returns their contents.\nIt's designed for reading Python tools, configuration files, and other text\nfiles.\n\nArgs:\n  file_paths: List of absolute or relative paths to files to read\n\nReturns:\n  Dict containing read operation results:\n    - success: bool indicating if all reads succeeded\n    - files: dict mapping file_path to file info:\n      - content: file content as string\n      - file_size: size of file in bytes\n      - exists: bool indicating if file exists\n      - error: error message if read failed for this file\n    - successful_reads: number of files read successfully\n    - total_files: total number of files requested\n    - errors: list of general error messages"
  signature: 'def read_files(file_paths: typing.List[str], tool_context: google.adk.tools.tool_context.ToolContext) -> typing.Dict[str, typing.Any]:'
- rank: 448
  id: google.adk.cli.built_in_agents.tools.search_adk_knowledge
  name: search_adk_knowledge
  file_path: google/adk/cli/built_in_agents/tools/search_adk_knowledge.py
  type: MODULE
  group: Orphan
  usage_score: 0
  docstring: ADK knowledge search tool.
  methods:
  - signature: 'def search_adk_knowledge(query: str) -> dict[str, typing.Any]:'
    docstring: "Searches ADK knowledge base for relevant information.\n\nArgs:\n  query: The query to search in ADK knowledge base.\n\nReturns:\n  A dict with status and the response from the knowledge service."
  - signature: 'def error_response(error_message: str) -> dict[str, typing.Any]:'
    docstring: Returns an error response.
  - signature: 'def post_request(url: str, payload: dict[str, typing.Any]) -> dict[str, typing.Any]:'
    docstring: Executes a POST request.
- rank: 449
  id: google.adk.cli.built_in_agents.tools.search_adk_knowledge.post_request
  name: post_request
  file_path: google/adk/cli/built_in_agents/tools/search_adk_knowledge.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: Executes a POST request.
  signature: 'def post_request(url: str, payload: dict[str, typing.Any]) -> dict[str, typing.Any]:'
- rank: 450
  id: google.adk.cli.built_in_agents.tools.search_adk_knowledge.search_adk_knowledge
  name: search_adk_knowledge
  file_path: google/adk/cli/built_in_agents/tools/search_adk_knowledge.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Searches ADK knowledge base for relevant information.\n\nArgs:\n  query: The query to search in ADK knowledge base.\n\nReturns:\n  A dict with status and the response from the knowledge service."
  signature: 'def search_adk_knowledge(query: str) -> dict[str, typing.Any]:'
- rank: 451
  id: google.adk.cli.built_in_agents.tools.search_adk_source
  name: search_adk_source
  file_path: google/adk/cli/built_in_agents/tools/search_adk_source.py
  type: MODULE
  group: Orphan
  usage_score: 0
  docstring: ADK source code search tool for Agent Builder Assistant.
  methods:
  - signature: 'def search_adk_source(search_pattern: str, file_patterns: typing.Optional[typing.List[str]], max_results: int, context_lines: int, case_sensitive: bool) -> typing.Dict[str, typing.Any]:'
    docstring: "Search ADK source code using regex patterns.\n\nThis tool provides a regex-based alternative to vector-based retrieval for\nfinding\nspecific code patterns, class definitions, function signatures, and\nimplementations\nin the ADK source code.\n\nArgs:\n  search_pattern: Regex pattern to search for (e.g., \"class FunctionTool\",\n    \"def __init__\")\n  file_patterns: List of glob patterns for files to search (default: [\"*.py\"])\n  max_results: Maximum number of results to return (default: 20)\n  context_lines: Number of context lines to include around matches (default:\n    3)\n  case_sensitive: Whether search should be case-sensitive (default: False)\n\nReturns:\n  Dict containing search results:\n    - success: bool indicating if search succeeded\n    - pattern: the regex pattern used\n    - total_matches: total number of matches found\n    - files_searched: number of files searched\n    - results: list of match results:\n      - file_path: path to file containing match\n\
      \      - line_number: line number of match\n      - match_text: the matched text\n      - context_before: lines before the match\n      - context_after: lines after the match\n      - full_match: complete context including before/match/after\n    - errors: list of error messages"
- rank: 452
  id: google.adk.cli.built_in_agents.tools.search_adk_source.search_adk_source
  name: search_adk_source
  file_path: google/adk/cli/built_in_agents/tools/search_adk_source.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Search ADK source code using regex patterns.\n\nThis tool provides a regex-based alternative to vector-based retrieval for\nfinding\nspecific code patterns, class definitions, function signatures, and\nimplementations\nin the ADK source code.\n\nArgs:\n  search_pattern: Regex pattern to search for (e.g., \"class FunctionTool\",\n    \"def __init__\")\n  file_patterns: List of glob patterns for files to search (default: [\"*.py\"])\n  max_results: Maximum number of results to return (default: 20)\n  context_lines: Number of context lines to include around matches (default:\n    3)\n  case_sensitive: Whether search should be case-sensitive (default: False)\n\nReturns:\n  Dict containing search results:\n    - success: bool indicating if search succeeded\n    - pattern: the regex pattern used\n    - total_matches: total number of matches found\n    - files_searched: number of files searched\n    - results: list of match results:\n      - file_path: path to file containing match\n\
    \      - line_number: line number of match\n      - match_text: the matched text\n      - context_before: lines before the match\n      - context_after: lines after the match\n      - full_match: complete context including before/match/after\n    - errors: list of error messages"
  signature: 'def search_adk_source(search_pattern: str, file_patterns: typing.Optional[typing.List[str]], max_results: int, context_lines: int, case_sensitive: bool) -> typing.Dict[str, typing.Any]:'
- rank: 453
  id: google.adk.cli.built_in_agents.tools.write_config_files
  name: write_config_files
  file_path: google/adk/cli/built_in_agents/tools/write_config_files.py
  type: MODULE
  group: Orphan
  usage_score: 0
  docstring: Configuration file writer tool with validation-before-write.
  methods:
  - signature: 'def write_config_files(configs: typing.Dict[str, str], tool_context: google.adk.tools.tool_context.ToolContext, backup_existing: bool, create_directories: bool) -> typing.Dict[str, typing.Any]:'
    docstring: "Write multiple YAML configurations with comprehensive validation-before-write.\n\nThis tool validates YAML syntax and AgentConfig schema compliance before\nwriting files to prevent invalid configurations from being saved. It\nprovides detailed error reporting and optional backup functionality.\n\nArgs:\n  configs: Dict mapping file_path to config_content (YAML as string)\n  backup_existing: Whether to create timestamped backup of existing files\n    before overwriting (default: False, User should decide)\n  create_directories: Whether to create parent directories if they don't exist\n    (default: True)\n\nReturns:\n  Dict containing write operation results:\n    Always included:\n      - success: bool indicating if all write operations succeeded\n      - total_files: number of files requested\n      - successful_writes: number of files written successfully\n      - files: dict mapping file_path to file results\n\n    Success cases only (success=True):\n      - file_size:\
      \ size of written file in bytes\n      - agent_name: extracted agent name from configuration\n      - agent_class: agent class type (e.g., \"LlmAgent\")\n      - warnings: list of warning messages for best practice violations.\n                 Empty list if no warnings. Common warning types:\n                 \u2022 Agent name formatting issues (special characters)\n                 \u2022 Empty instruction for LlmAgent\n                 \u2022 Missing sub-agent files\n                 \u2022 Incorrect file extensions (.yaml/.yml)\n                 \u2022 Mixed tool format consistency\n      - target_file_path: normalized path used for writing the config\n      - rename_applied: whether the file name was changed to match agent name\n      - written_file_path: absolute path that was ultimately written\n\n    Conditionally included:\n      - backup: dict with backup information (if backup was created).\n               Contains:\n               \u2022 \"backup_created\": True (always\
      \ True when present)\n               \u2022 \"backup_path\": absolute path to the timestamped backup file\n                               (format: \"original.yaml.backup.{timestamp}\")\n\n    Error cases only (success=False):\n      - error: descriptive error message explaining the failure\n      - error_type: categorized error type for programmatic handling\n      - validation_step: stage where validation process stopped.\n                        Possible values:\n                        \u2022 \"yaml_parsing\": YAML syntax is invalid\n                        \u2022 \"yaml_structure\": YAML is valid but not a\n                        dict/object\n                        \u2022 \"schema_validation\": YAML violates AgentConfig\n                        schema\n                        \u2022 Not present: Error during file operations\n      - validation_errors: detailed validation error list (for schema errors\n      only)\n      - retry_suggestion: helpful suggestions for fixing the error\n\
      \nExamples:\n  Write new configuration:\n    result = await write_config_files({\"my_agent.yaml\": yaml_content})\n\n  Write without backup:\n    result = await write_config_files(\n        {\"temp_agent.yaml\": yaml_content},\n        backup_existing=False\n    )\n\n  Check backup information:\n    result = await write_config_files({\"existing_agent.yaml\": new_content})\n    if result[\"success\"] and\n    result[\"files\"][\"existing_agent.yaml\"][\"backup_created\"]:\n        backup_path = result[\"files\"][\"existing_agent.yaml\"][\"backup_path\"]\n        print(f\"Original file backed up to: {backup_path}\")\n\n  Check validation warnings:\n    result = await write_config_files({\"agent.yaml\": yaml_content})\n    if result[\"success\"] and result[\"files\"][\"agent.yaml\"][\"warnings\"]:\n        for warning in result[\"files\"][\"agent.yaml\"][\"warnings\"]:\n            print(f\"Warning: {warning}\")\n\n  Handle validation errors:\n    result = await write_config_files({\"\
      agent.yaml\": invalid_yaml})\n    if not result[\"success\"]:\n        step = result.get(\"validation_step\", \"file_operation\")\n        if step == \"yaml_parsing\":\n            print(\"YAML syntax error:\", result[\"error\"])\n        elif step == \"schema_validation\":\n            print(\"Schema validation failed:\", result[\"retry_suggestion\"])\n        else:\n            print(\"Error:\", result[\"error\"])"
- rank: 454
  id: google.adk.cli.built_in_agents.tools.write_config_files.write_config_files
  name: write_config_files
  file_path: google/adk/cli/built_in_agents/tools/write_config_files.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Write multiple YAML configurations with comprehensive validation-before-write.\n\nThis tool validates YAML syntax and AgentConfig schema compliance before\nwriting files to prevent invalid configurations from being saved. It\nprovides detailed error reporting and optional backup functionality.\n\nArgs:\n  configs: Dict mapping file_path to config_content (YAML as string)\n  backup_existing: Whether to create timestamped backup of existing files\n    before overwriting (default: False, User should decide)\n  create_directories: Whether to create parent directories if they don't exist\n    (default: True)\n\nReturns:\n  Dict containing write operation results:\n    Always included:\n      - success: bool indicating if all write operations succeeded\n      - total_files: number of files requested\n      - successful_writes: number of files written successfully\n      - files: dict mapping file_path to file results\n\n    Success cases only (success=True):\n      - file_size: size\
    \ of written file in bytes\n      - agent_name: extracted agent name from configuration\n      - agent_class: agent class type (e.g., \"LlmAgent\")\n      - warnings: list of warning messages for best practice violations.\n                 Empty list if no warnings. Common warning types:\n                 \u2022 Agent name formatting issues (special characters)\n                 \u2022 Empty instruction for LlmAgent\n                 \u2022 Missing sub-agent files\n                 \u2022 Incorrect file extensions (.yaml/.yml)\n                 \u2022 Mixed tool format consistency\n      - target_file_path: normalized path used for writing the config\n      - rename_applied: whether the file name was changed to match agent name\n      - written_file_path: absolute path that was ultimately written\n\n    Conditionally included:\n      - backup: dict with backup information (if backup was created).\n               Contains:\n               \u2022 \"backup_created\": True (always True when\
    \ present)\n               \u2022 \"backup_path\": absolute path to the timestamped backup file\n                               (format: \"original.yaml.backup.{timestamp}\")\n\n    Error cases only (success=False):\n      - error: descriptive error message explaining the failure\n      - error_type: categorized error type for programmatic handling\n      - validation_step: stage where validation process stopped.\n                        Possible values:\n                        \u2022 \"yaml_parsing\": YAML syntax is invalid\n                        \u2022 \"yaml_structure\": YAML is valid but not a\n                        dict/object\n                        \u2022 \"schema_validation\": YAML violates AgentConfig\n                        schema\n                        \u2022 Not present: Error during file operations\n      - validation_errors: detailed validation error list (for schema errors\n      only)\n      - retry_suggestion: helpful suggestions for fixing the error\n\nExamples:\n\
    \  Write new configuration:\n    result = await write_config_files({\"my_agent.yaml\": yaml_content})\n\n  Write without backup:\n    result = await write_config_files(\n        {\"temp_agent.yaml\": yaml_content},\n        backup_existing=False\n    )\n\n  Check backup information:\n    result = await write_config_files({\"existing_agent.yaml\": new_content})\n    if result[\"success\"] and\n    result[\"files\"][\"existing_agent.yaml\"][\"backup_created\"]:\n        backup_path = result[\"files\"][\"existing_agent.yaml\"][\"backup_path\"]\n        print(f\"Original file backed up to: {backup_path}\")\n\n  Check validation warnings:\n    result = await write_config_files({\"agent.yaml\": yaml_content})\n    if result[\"success\"] and result[\"files\"][\"agent.yaml\"][\"warnings\"]:\n        for warning in result[\"files\"][\"agent.yaml\"][\"warnings\"]:\n            print(f\"Warning: {warning}\")\n\n  Handle validation errors:\n    result = await write_config_files({\"agent.yaml\":\
    \ invalid_yaml})\n    if not result[\"success\"]:\n        step = result.get(\"validation_step\", \"file_operation\")\n        if step == \"yaml_parsing\":\n            print(\"YAML syntax error:\", result[\"error\"])\n        elif step == \"schema_validation\":\n            print(\"Schema validation failed:\", result[\"retry_suggestion\"])\n        else:\n            print(\"Error:\", result[\"error\"])"
  signature: 'def write_config_files(configs: typing.Dict[str, str], tool_context: google.adk.tools.tool_context.ToolContext, backup_existing: bool, create_directories: bool) -> typing.Dict[str, typing.Any]:'
- rank: 455
  id: google.adk.cli.built_in_agents.tools.write_files
  name: write_files
  file_path: google/adk/cli/built_in_agents/tools/write_files.py
  type: MODULE
  group: Orphan
  usage_score: 0
  docstring: File writing tool for Agent Builder Assistant.
  methods:
  - signature: 'def write_files(files: typing.Dict[str, str], tool_context: google.adk.tools.tool_context.ToolContext, create_backup: bool, create_directories: bool) -> typing.Dict[str, typing.Any]:'
    docstring: "Write content to multiple files with optional backup creation.\n\nThis tool writes content to multiple files. It's designed for creating\nPython tools, callbacks, configuration files, and other code files.\n\nArgs:\n  files: Dict mapping file_path to content to write\n  create_backup: Whether to create backups of existing files (default: False)\n  create_directories: Whether to create parent directories (default: True)\n\nReturns:\n  Dict containing write operation results:\n    - success: bool indicating if all writes succeeded\n    - files: dict mapping file_path to file info:\n      - file_size: size of written file in bytes\n      - existed_before: bool indicating if file existed before write\n      - backup_created: bool indicating if backup was created\n      - backup_path: path to backup file if created\n      - error: error message if write failed for this file\n    - successful_writes: number of files written successfully\n    - total_files: total number of files\
      \ requested\n    - errors: list of general error messages"
- rank: 456
  id: google.adk.cli.built_in_agents.tools.write_files.write_files
  name: write_files
  file_path: google/adk/cli/built_in_agents/tools/write_files.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Write content to multiple files with optional backup creation.\n\nThis tool writes content to multiple files. It's designed for creating\nPython tools, callbacks, configuration files, and other code files.\n\nArgs:\n  files: Dict mapping file_path to content to write\n  create_backup: Whether to create backups of existing files (default: False)\n  create_directories: Whether to create parent directories (default: True)\n\nReturns:\n  Dict containing write operation results:\n    - success: bool indicating if all writes succeeded\n    - files: dict mapping file_path to file info:\n      - file_size: size of written file in bytes\n      - existed_before: bool indicating if file existed before write\n      - backup_created: bool indicating if backup was created\n      - backup_path: path to backup file if created\n      - error: error message if write failed for this file\n    - successful_writes: number of files written successfully\n    - total_files: total number of files requested\n\
    \    - errors: list of general error messages"
  signature: 'def write_files(files: typing.Dict[str, str], tool_context: google.adk.tools.tool_context.ToolContext, create_backup: bool, create_directories: bool) -> typing.Dict[str, typing.Any]:'
- rank: 457
  id: google.adk.cli.built_in_agents.utils
  name: utils
  file_path: google/adk/cli/built_in_agents/utils/__init__.py
  type: MODULE
  group: Orphan
  usage_score: 0
  docstring: Utility modules for Agent Builder Assistant.
- rank: 458
  id: google.adk.cli.built_in_agents.utils.adk_source_utils
  name: adk_source_utils
  file_path: google/adk/cli/built_in_agents/utils/adk_source_utils.py
  type: MODULE
  group: Orphan
  usage_score: 0
  docstring: Utilities for finding ADK source folder dynamically and loading schema.
  methods:
  - signature: 'def find_adk_source_folder(start_path: typing.Optional[str]) -> typing.Optional[str]:'
    docstring: "Find the ADK source folder by searching up the directory tree.\n\nSearches for either 'src/google/adk' or 'google/adk' directories starting\nfrom the given path and moving up the directory tree until the root.\n\nArgs:\n  start_path: Directory to start search from. If None, uses current directory.\n\nReturns:\n  Absolute path to the ADK source folder if found, None otherwise.\n\nExamples:\n  Find ADK source from current directory:\n    adk_path = find_adk_source_folder()\n\n  Find ADK source from specific directory:\n    adk_path = find_adk_source_folder(\"/path/to/project\")"
  - signature: 'def get_adk_schema_path(start_path: typing.Optional[str]) -> typing.Optional[str]:'
    docstring: "Find the path to the ADK AgentConfig schema file.\n\nArgs:\n  start_path: Directory to start search from. If None, uses current directory.\n\nReturns:\n  Absolute path to AgentConfig.json schema file if found, None otherwise."
  - signature: 'def load_agent_config_schema(raw_format: bool, escape_braces: bool) -> str | Dict[str, Any]:'
    docstring: "Load the ADK AgentConfig.json schema with various formatting options.\n\nThis function provides a centralized way to load the ADK AgentConfig schema\nand format it for different use cases across the Agent Builder Assistant.\n\nArgs:\n  raw_format: If True, return as JSON string. If False, return as parsed dict.\n  escape_braces: If True, replace { and } with {{ and }} for template\n    embedding. Only applies when raw_format=True.\n\nReturns:\n  Either the ADK AgentConfig schema as a Dict (raw_format=False) or as a\n  formatted string (raw_format=True), optionally with escaped braces for\n  template use.\n\nRaises:\n  FileNotFoundError: If ADK AgentConfig.json schema file is not found.\n\nExamples:\n  # Get parsed ADK AgentConfig schema dict for validation\n  schema_dict = load_agent_config_schema()\n\n  # Get raw ADK AgentConfig schema JSON string for display\n  schema_str = load_agent_config_schema(raw_format=True)\n\n  # Get template-safe ADK AgentConfig schema JSON string\
      \ for instruction\n  # embedding\n  schema_template = load_agent_config_schema(\n      raw_format=True, escape_braces=True\n  )"
  - signature: 'def clear_schema_cache() -> None:'
    docstring: 'Clear the cached schema data.


      This can be useful for testing or if the schema file has been updated

      and you need to reload it.'
- rank: 459
  id: google.adk.cli.built_in_agents.utils.adk_source_utils.clear_schema_cache
  name: clear_schema_cache
  file_path: google/adk/cli/built_in_agents/utils/adk_source_utils.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: 'Clear the cached schema data.


    This can be useful for testing or if the schema file has been updated

    and you need to reload it.'
  signature: 'def clear_schema_cache() -> None:'
- rank: 460
  id: google.adk.cli.built_in_agents.utils.adk_source_utils.find_adk_source_folder
  name: find_adk_source_folder
  file_path: google/adk/cli/built_in_agents/utils/adk_source_utils.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Find the ADK source folder by searching up the directory tree.\n\nSearches for either 'src/google/adk' or 'google/adk' directories starting\nfrom the given path and moving up the directory tree until the root.\n\nArgs:\n  start_path: Directory to start search from. If None, uses current directory.\n\nReturns:\n  Absolute path to the ADK source folder if found, None otherwise.\n\nExamples:\n  Find ADK source from current directory:\n    adk_path = find_adk_source_folder()\n\n  Find ADK source from specific directory:\n    adk_path = find_adk_source_folder(\"/path/to/project\")"
  signature: 'def find_adk_source_folder(start_path: typing.Optional[str]) -> typing.Optional[str]:'
  aliases:
  - google.adk.cli.built_in_agents.utils.find_adk_source_folder
- rank: 461
  id: google.adk.cli.built_in_agents.utils.adk_source_utils.get_adk_schema_path
  name: get_adk_schema_path
  file_path: google/adk/cli/built_in_agents/utils/adk_source_utils.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Find the path to the ADK AgentConfig schema file.\n\nArgs:\n  start_path: Directory to start search from. If None, uses current directory.\n\nReturns:\n  Absolute path to AgentConfig.json schema file if found, None otherwise."
  signature: 'def get_adk_schema_path(start_path: typing.Optional[str]) -> typing.Optional[str]:'
  aliases:
  - google.adk.cli.built_in_agents.utils.get_adk_schema_path
- rank: 462
  id: google.adk.cli.built_in_agents.utils.adk_source_utils.load_agent_config_schema
  name: load_agent_config_schema
  file_path: google/adk/cli/built_in_agents/utils/adk_source_utils.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Load the ADK AgentConfig.json schema with various formatting options.\n\nThis function provides a centralized way to load the ADK AgentConfig schema\nand format it for different use cases across the Agent Builder Assistant.\n\nArgs:\n  raw_format: If True, return as JSON string. If False, return as parsed dict.\n  escape_braces: If True, replace { and } with {{ and }} for template\n    embedding. Only applies when raw_format=True.\n\nReturns:\n  Either the ADK AgentConfig schema as a Dict (raw_format=False) or as a\n  formatted string (raw_format=True), optionally with escaped braces for\n  template use.\n\nRaises:\n  FileNotFoundError: If ADK AgentConfig.json schema file is not found.\n\nExamples:\n  # Get parsed ADK AgentConfig schema dict for validation\n  schema_dict = load_agent_config_schema()\n\n  # Get raw ADK AgentConfig schema JSON string for display\n  schema_str = load_agent_config_schema(raw_format=True)\n\n  # Get template-safe ADK AgentConfig schema JSON string\
    \ for instruction\n  # embedding\n  schema_template = load_agent_config_schema(\n      raw_format=True, escape_braces=True\n  )"
  signature: 'def load_agent_config_schema(raw_format: bool, escape_braces: bool) -> str | Dict[str, Any]:'
  aliases:
  - google.adk.cli.built_in_agents.utils.load_agent_config_schema
- rank: 463
  id: google.adk.cli.built_in_agents.utils.path_normalizer
  name: path_normalizer
  file_path: google/adk/cli/built_in_agents/utils/path_normalizer.py
  type: MODULE
  group: Orphan
  usage_score: 0
  docstring: Helpers for normalizing file path strings produced by the model.
  methods:
  - signature: 'def sanitize_generated_file_path(file_path: str) -> str:'
    docstring: "Strip stray quotes/whitespace around each path segment.\n\nThe agent occasionally emits quoted paths such as `'tools/web.yaml'` which\nwould otherwise create directories literally named `'<name>`. This helper\nremoves leading/trailing whitespace and quote-like characters from the path\nand from each path component while preserving intentional interior\ncharacters.\n\nArgs:\n  file_path: Path string provided by the model or user.\n\nReturns:\n  Sanitized path string safe to feed into pathlib.Path."
- rank: 464
  id: google.adk.cli.built_in_agents.utils.path_normalizer.sanitize_generated_file_path
  name: sanitize_generated_file_path
  file_path: google/adk/cli/built_in_agents/utils/path_normalizer.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Strip stray quotes/whitespace around each path segment.\n\nThe agent occasionally emits quoted paths such as `'tools/web.yaml'` which\nwould otherwise create directories literally named `'<name>`. This helper\nremoves leading/trailing whitespace and quote-like characters from the path\nand from each path component while preserving intentional interior\ncharacters.\n\nArgs:\n  file_path: Path string provided by the model or user.\n\nReturns:\n  Sanitized path string safe to feed into pathlib.Path."
  signature: 'def sanitize_generated_file_path(file_path: str) -> str:'
- rank: 465
  id: google.adk.cli.built_in_agents.utils.resolve_root_directory
  name: resolve_root_directory
  file_path: google/adk/cli/built_in_agents/utils/resolve_root_directory.py
  type: MODULE
  group: Orphan
  usage_score: 0
  docstring: Working directory helper tool to resolve path context issues.
  methods:
  - signature: 'def resolve_file_path(file_path: str, session_state: typing.Optional[typing.Dict[str, typing.Any]], working_directory: typing.Optional[str]) -> pathlib.Path:'
    docstring: "Resolve a file path using root directory from session state.\n\nThis is a helper function that other tools can use to resolve file paths\nwithout needing to be async or return detailed resolution information.\n\nArgs:\n  file_path: File path (relative or absolute)\n  session_state: Session state dict that may contain root_directory\n  working_directory: Working directory to use as base (defaults to cwd)\n\nReturns:\n  Resolved absolute Path object"
  - signature: 'def resolve_file_paths(file_paths: typing.List[str], session_state: typing.Optional[typing.Dict[str, typing.Any]], working_directory: typing.Optional[str]) -> typing.List[pathlib.Path]:'
    docstring: "Resolve multiple file paths using root directory from session state.\n\nArgs:\n  file_paths: List of file paths (relative or absolute)\n  session_state: Session state dict that may contain root_directory\n  working_directory: Working directory to use as base (defaults to cwd)\n\nReturns:\n  List of resolved absolute Path objects"
- rank: 466
  id: google.adk.cli.built_in_agents.utils.resolve_root_directory.resolve_file_path
  name: resolve_file_path
  file_path: google/adk/cli/built_in_agents/utils/resolve_root_directory.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Resolve a file path using root directory from session state.\n\nThis is a helper function that other tools can use to resolve file paths\nwithout needing to be async or return detailed resolution information.\n\nArgs:\n  file_path: File path (relative or absolute)\n  session_state: Session state dict that may contain root_directory\n  working_directory: Working directory to use as base (defaults to cwd)\n\nReturns:\n  Resolved absolute Path object"
  signature: 'def resolve_file_path(file_path: str, session_state: typing.Optional[typing.Dict[str, typing.Any]], working_directory: typing.Optional[str]) -> pathlib.Path:'
- rank: 467
  id: google.adk.cli.built_in_agents.utils.resolve_root_directory.resolve_file_paths
  name: resolve_file_paths
  file_path: google/adk/cli/built_in_agents/utils/resolve_root_directory.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Resolve multiple file paths using root directory from session state.\n\nArgs:\n  file_paths: List of file paths (relative or absolute)\n  session_state: Session state dict that may contain root_directory\n  working_directory: Working directory to use as base (defaults to cwd)\n\nReturns:\n  List of resolved absolute Path objects"
  signature: 'def resolve_file_paths(file_paths: typing.List[str], session_state: typing.Optional[typing.Dict[str, typing.Any]], working_directory: typing.Optional[str]) -> typing.List[pathlib.Path]:'
- rank: 468
  id: google.adk.cli.cli
  name: cli
  file_path: google/adk/cli/cli.py
  type: MODULE
  group: Orphan
  usage_score: 0
  methods:
  - signature: 'def run_input_file(app_name: str, user_id: str, agent_or_app: typing.Union[google.adk.agents.llm_agent.LlmAgent, google.adk.apps.app.App], artifact_service: google.adk.artifacts.base_artifact_service.BaseArtifactService, session_service: google.adk.sessions.base_session_service.BaseSessionService, credential_service: google.adk.auth.credential_service.base_credential_service.BaseCredentialService, input_path: str) -> google.adk.sessions.session.Session:'
  - signature: 'def run_interactively(root_agent_or_app: typing.Union[google.adk.agents.llm_agent.LlmAgent, google.adk.apps.app.App], artifact_service: google.adk.artifacts.base_artifact_service.BaseArtifactService, session: google.adk.sessions.session.Session, session_service: google.adk.sessions.base_session_service.BaseSessionService, credential_service: google.adk.auth.credential_service.base_credential_service.BaseCredentialService) -> None:'
  - signature: 'def run_cli(*, agent_parent_dir: str, agent_folder_name: str, input_file: typing.Optional[str]=None, saved_session_file: typing.Optional[str]=None, save_session: bool, session_id: typing.Optional[str]=None, session_service_uri: typing.Optional[str]=None, artifact_service_uri: typing.Optional[str]=None) -> None:'
    docstring: "Runs an interactive CLI for a certain agent.\n\nArgs:\n  agent_parent_dir: str, the absolute path of the parent folder of the agent\n    folder.\n  agent_folder_name: str, the name of the agent folder.\n  input_file: Optional[str], the absolute path to the json file that contains\n    the initial session state and user queries, exclusive with\n    saved_session_file.\n  saved_session_file: Optional[str], the absolute path to the json file that\n    contains a previously saved session, exclusive with input_file.\n  save_session: bool, whether to save the session on exit.\n  session_id: Optional[str], the session ID to save the session to on exit.\n  session_service_uri: Optional[str], custom session service URI.\n  artifact_service_uri: Optional[str], custom artifact service URI."
- rank: 469
  id: google.adk.cli.cli.InputFile
  name: InputFile
  file_path: google/adk/cli/cli.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: '[Note: Inherited members from pydantic.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, state: dict[str, object], queries: list[str]):'
  properties:
  - signature: 'state: dict[str, object]'
  - signature: 'queries: list[str]'
  inherited_properties:
    BaseModel:
    - signature: 'model_config: pydantic.ConfigDict'
  omitted_inherited_members_from:
  - pydantic.BaseModel
- rank: 470
  id: google.adk.cli.cli.run_cli
  name: run_cli
  file_path: google/adk/cli/cli.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Runs an interactive CLI for a certain agent.\n\nArgs:\n  agent_parent_dir: str, the absolute path of the parent folder of the agent\n    folder.\n  agent_folder_name: str, the name of the agent folder.\n  input_file: Optional[str], the absolute path to the json file that contains\n    the initial session state and user queries, exclusive with\n    saved_session_file.\n  saved_session_file: Optional[str], the absolute path to the json file that\n    contains a previously saved session, exclusive with input_file.\n  save_session: bool, whether to save the session on exit.\n  session_id: Optional[str], the session ID to save the session to on exit.\n  session_service_uri: Optional[str], custom session service URI.\n  artifact_service_uri: Optional[str], custom artifact service URI."
  signature: 'def run_cli(*, agent_parent_dir: str, agent_folder_name: str, input_file: typing.Optional[str]=None, saved_session_file: typing.Optional[str]=None, save_session: bool, session_id: typing.Optional[str]=None, session_service_uri: typing.Optional[str]=None, artifact_service_uri: typing.Optional[str]=None) -> None:'
- rank: 471
  id: google.adk.cli.cli.run_input_file
  name: run_input_file
  file_path: google/adk/cli/cli.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def run_input_file(app_name: str, user_id: str, agent_or_app: typing.Union[google.adk.agents.llm_agent.LlmAgent, google.adk.apps.app.App], artifact_service: google.adk.artifacts.base_artifact_service.BaseArtifactService, session_service: google.adk.sessions.base_session_service.BaseSessionService, credential_service: google.adk.auth.credential_service.base_credential_service.BaseCredentialService, input_path: str) -> google.adk.sessions.session.Session:'
- rank: 472
  id: google.adk.cli.cli.run_interactively
  name: run_interactively
  file_path: google/adk/cli/cli.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def run_interactively(root_agent_or_app: typing.Union[google.adk.agents.llm_agent.LlmAgent, google.adk.apps.app.App], artifact_service: google.adk.artifacts.base_artifact_service.BaseArtifactService, session: google.adk.sessions.session.Session, session_service: google.adk.sessions.base_session_service.BaseSessionService, credential_service: google.adk.auth.credential_service.base_credential_service.BaseCredentialService) -> None:'
- rank: 473
  id: google.adk.cli.cli_create
  name: cli_create
  file_path: google/adk/cli/cli_create.py
  type: MODULE
  group: Orphan
  usage_score: 0
  methods:
  - signature: 'def run_cmd(agent_name: str, *, model: typing.Optional[str], google_api_key: typing.Optional[str], google_cloud_project: typing.Optional[str], google_cloud_region: typing.Optional[str], type: typing.Optional[str]):'
    docstring: "Runs `adk create` command to create agent template.\n\nArgs:\n  agent_name: str, The name of the agent.\n  google_api_key: Optional[str], The Google API key for using Google AI as\n    backend.\n  google_cloud_project: Optional[str], The Google Cloud project for using\n    VertexAI as backend.\n  google_cloud_region: Optional[str], The Google Cloud region for using\n    VertexAI as backend.\n  type: Optional[str], Whether to define agent with config file or code."
- rank: 474
  id: google.adk.cli.cli_create.run_cmd
  name: run_cmd
  file_path: google/adk/cli/cli_create.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Runs `adk create` command to create agent template.\n\nArgs:\n  agent_name: str, The name of the agent.\n  google_api_key: Optional[str], The Google API key for using Google AI as\n    backend.\n  google_cloud_project: Optional[str], The Google Cloud project for using\n    VertexAI as backend.\n  google_cloud_region: Optional[str], The Google Cloud region for using\n    VertexAI as backend.\n  type: Optional[str], Whether to define agent with config file or code."
  signature: 'def run_cmd(agent_name: str, *, model: typing.Optional[str], google_api_key: typing.Optional[str], google_cloud_project: typing.Optional[str], google_cloud_region: typing.Optional[str], type: typing.Optional[str]):'
- rank: 475
  id: google.adk.cli.cli_deploy
  name: cli_deploy
  file_path: google/adk/cli/cli_deploy.py
  type: MODULE
  group: Orphan
  usage_score: 0
  methods:
  - signature: 'def to_cloud_run(*, agent_folder: str, project: typing.Optional[str], region: typing.Optional[str], service_name: str, app_name: str, temp_folder: str, port: int, trace_to_cloud: bool, with_ui: bool, log_level: str, verbosity: str, adk_version: str, allow_origins: typing.Optional[list[str]]=None, session_service_uri: typing.Optional[str]=None, artifact_service_uri: typing.Optional[str]=None, memory_service_uri: typing.Optional[str]=None, a2a: bool=False, extra_gcloud_args: typing.Optional[tuple[str, Ellipsis]]=None):'
    docstring: "Deploys an agent to Google Cloud Run.\n\n`agent_folder` should contain the following files:\n\n- __init__.py\n- agent.py\n- requirements.txt (optional, for additional dependencies)\n- ... (other required source files)\n\nThe folder structure of temp_folder will be\n\n* dist/[google_adk wheel file]\n* agents/[app_name]/\n  * agent source code from `agent_folder`\n\nArgs:\n  agent_folder: The folder (absolute path) containing the agent source code.\n  project: Google Cloud project id.\n  region: Google Cloud region.\n  service_name: The service name in Cloud Run.\n  app_name: The name of the app, by default, it's basename of `agent_folder`.\n  temp_folder: The temp folder for the generated Cloud Run source files.\n  port: The port of the ADK api server.\n  trace_to_cloud: Whether to enable Cloud Trace.\n  with_ui: Whether to deploy with UI.\n  verbosity: The verbosity level of the CLI.\n  adk_version: The ADK version to use in Cloud Run.\n  allow_origins: The list of allowed\
      \ origins for the ADK api server.\n  session_service_uri: The URI of the session service.\n  artifact_service_uri: The URI of the artifact service.\n  memory_service_uri: The URI of the memory service."
  - signature: 'def to_agent_engine(*, agent_folder: str, temp_folder: typing.Optional[str]=None, adk_app: str, staging_bucket: str, trace_to_cloud: typing.Optional[bool]=None, api_key: typing.Optional[str]=None, adk_app_object: typing.Optional[str]=None, agent_engine_id: typing.Optional[str]=None, absolutize_imports: bool=True, project: typing.Optional[str]=None, region: typing.Optional[str]=None, display_name: typing.Optional[str]=None, description: typing.Optional[str]=None, requirements_file: typing.Optional[str]=None, env_file: typing.Optional[str]=None, agent_engine_config_file: typing.Optional[str]=None):'
    docstring: "Deploys an agent to Vertex AI Agent Engine.\n\n`agent_folder` should contain the following files:\n\n- __init__.py\n- agent.py\n- <adk_app>.py (optional, for customization; will be autogenerated otherwise)\n- requirements.txt (optional, for additional dependencies)\n- .env (optional, for environment variables)\n- ... (other required source files)\n\nThe contents of `adk_app` should look something like:\n\n```\nfrom agent import <adk_app_object>\nfrom vertexai.agent_engines import AdkApp\n\nadk_app = AdkApp(\n  agent=<adk_app_object>,  # or `app=<adk_app_object>`\n)\n```\n\nArgs:\n  agent_folder (str): The folder (absolute path) containing the agent source\n    code.\n  temp_folder (str): The temp folder for the generated Agent Engine source\n    files. It will be replaced with the generated files if it already exists.\n  adk_app (str): The name of the file (without .py) containing the AdkApp\n    instance.\n  staging_bucket (str): The GCS bucket for staging the deployment\
      \ artifacts.\n  trace_to_cloud (bool): Whether to enable Cloud Trace.\n  api_key (str): Optional. The API key to use for Express Mode.\n    If not provided, the API key from the GOOGLE_API_KEY environment variable\n    will be used. It will only be used if GOOGLE_GENAI_USE_VERTEXAI is true.\n  adk_app_object (str): Optional. The Python object corresponding to the root\n    ADK agent or app. Defaults to `root_agent` if not specified.\n  agent_engine_id (str): Optional. The ID of the Agent Engine instance to\n    update. If not specified, a new Agent Engine instance will be created.\n  absolutize_imports (bool): Optional. Default is True. Whether to absolutize\n    imports. If True, all relative imports will be converted to absolute\n    import statements.\n  project (str): Optional. Google Cloud project id.\n  region (str): Optional. Google Cloud region.\n  display_name (str): Optional. The display name of the Agent Engine.\n  description (str): Optional. The description of the Agent\
      \ Engine.\n  requirements_file (str): Optional. The filepath to the `requirements.txt`\n    file to use. If not specified, the `requirements.txt` file in the\n    `agent_folder` will be used.\n  env_file (str): Optional. The filepath to the `.env` file for environment\n    variables. If not specified, the `.env` file in the `agent_folder` will be\n    used. The values of `GOOGLE_CLOUD_PROJECT` and `GOOGLE_CLOUD_LOCATION`\n    will be overridden by `project` and `region` if they are specified.\n  agent_engine_config_file (str): The filepath to the agent engine config file\n    to use. If not specified, the `.agent_engine_config.json` file in the\n    `agent_folder` will be used."
  - signature: 'def to_gke(*, agent_folder: str, project: typing.Optional[str], region: typing.Optional[str], cluster_name: str, service_name: str, app_name: str, temp_folder: str, port: int, trace_to_cloud: bool, with_ui: bool, log_level: str, adk_version: str, allow_origins: typing.Optional[list[str]]=None, session_service_uri: typing.Optional[str]=None, artifact_service_uri: typing.Optional[str]=None, memory_service_uri: typing.Optional[str]=None, a2a: bool=False):'
    docstring: "Deploys an agent to Google Kubernetes Engine(GKE).\n\nArgs:\n  agent_folder: The folder (absolute path) containing the agent source code.\n  project: Google Cloud project id.\n  region: Google Cloud region.\n  cluster_name: The name of the GKE cluster.\n  service_name: The service name in GKE.\n  app_name: The name of the app, by default, it's basename of `agent_folder`.\n  temp_folder: The local directory to use as a temporary workspace for\n    preparing deployment artifacts. The tool populates this folder with a copy\n    of the agent's source code and auto-generates necessary files like a\n    Dockerfile and deployment.yaml.\n  port: The port of the ADK api server.\n  trace_to_cloud: Whether to enable Cloud Trace.\n  with_ui: Whether to deploy with UI.\n  log_level: The logging level.\n  adk_version: The ADK version to use in GKE.\n  allow_origins: The list of allowed origins for the ADK api server.\n  session_service_uri: The URI of the session service.\n  artifact_service_uri:\
      \ The URI of the artifact service.\n  memory_service_uri: The URI of the memory service."
- rank: 476
  id: google.adk.cli.cli_deploy.to_agent_engine
  name: to_agent_engine
  file_path: google/adk/cli/cli_deploy.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Deploys an agent to Vertex AI Agent Engine.\n\n`agent_folder` should contain the following files:\n\n- __init__.py\n- agent.py\n- <adk_app>.py (optional, for customization; will be autogenerated otherwise)\n- requirements.txt (optional, for additional dependencies)\n- .env (optional, for environment variables)\n- ... (other required source files)\n\nThe contents of `adk_app` should look something like:\n\n```\nfrom agent import <adk_app_object>\nfrom vertexai.agent_engines import AdkApp\n\nadk_app = AdkApp(\n  agent=<adk_app_object>,  # or `app=<adk_app_object>`\n)\n```\n\nArgs:\n  agent_folder (str): The folder (absolute path) containing the agent source\n    code.\n  temp_folder (str): The temp folder for the generated Agent Engine source\n    files. It will be replaced with the generated files if it already exists.\n  adk_app (str): The name of the file (without .py) containing the AdkApp\n    instance.\n  staging_bucket (str): The GCS bucket for staging the deployment artifacts.\n\
    \  trace_to_cloud (bool): Whether to enable Cloud Trace.\n  api_key (str): Optional. The API key to use for Express Mode.\n    If not provided, the API key from the GOOGLE_API_KEY environment variable\n    will be used. It will only be used if GOOGLE_GENAI_USE_VERTEXAI is true.\n  adk_app_object (str): Optional. The Python object corresponding to the root\n    ADK agent or app. Defaults to `root_agent` if not specified.\n  agent_engine_id (str): Optional. The ID of the Agent Engine instance to\n    update. If not specified, a new Agent Engine instance will be created.\n  absolutize_imports (bool): Optional. Default is True. Whether to absolutize\n    imports. If True, all relative imports will be converted to absolute\n    import statements.\n  project (str): Optional. Google Cloud project id.\n  region (str): Optional. Google Cloud region.\n  display_name (str): Optional. The display name of the Agent Engine.\n  description (str): Optional. The description of the Agent Engine.\n  requirements_file\
    \ (str): Optional. The filepath to the `requirements.txt`\n    file to use. If not specified, the `requirements.txt` file in the\n    `agent_folder` will be used.\n  env_file (str): Optional. The filepath to the `.env` file for environment\n    variables. If not specified, the `.env` file in the `agent_folder` will be\n    used. The values of `GOOGLE_CLOUD_PROJECT` and `GOOGLE_CLOUD_LOCATION`\n    will be overridden by `project` and `region` if they are specified.\n  agent_engine_config_file (str): The filepath to the agent engine config file\n    to use. If not specified, the `.agent_engine_config.json` file in the\n    `agent_folder` will be used."
  signature: 'def to_agent_engine(*, agent_folder: str, temp_folder: typing.Optional[str]=None, adk_app: str, staging_bucket: str, trace_to_cloud: typing.Optional[bool]=None, api_key: typing.Optional[str]=None, adk_app_object: typing.Optional[str]=None, agent_engine_id: typing.Optional[str]=None, absolutize_imports: bool=True, project: typing.Optional[str]=None, region: typing.Optional[str]=None, display_name: typing.Optional[str]=None, description: typing.Optional[str]=None, requirements_file: typing.Optional[str]=None, env_file: typing.Optional[str]=None, agent_engine_config_file: typing.Optional[str]=None):'
- rank: 477
  id: google.adk.cli.cli_deploy.to_cloud_run
  name: to_cloud_run
  file_path: google/adk/cli/cli_deploy.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Deploys an agent to Google Cloud Run.\n\n`agent_folder` should contain the following files:\n\n- __init__.py\n- agent.py\n- requirements.txt (optional, for additional dependencies)\n- ... (other required source files)\n\nThe folder structure of temp_folder will be\n\n* dist/[google_adk wheel file]\n* agents/[app_name]/\n  * agent source code from `agent_folder`\n\nArgs:\n  agent_folder: The folder (absolute path) containing the agent source code.\n  project: Google Cloud project id.\n  region: Google Cloud region.\n  service_name: The service name in Cloud Run.\n  app_name: The name of the app, by default, it's basename of `agent_folder`.\n  temp_folder: The temp folder for the generated Cloud Run source files.\n  port: The port of the ADK api server.\n  trace_to_cloud: Whether to enable Cloud Trace.\n  with_ui: Whether to deploy with UI.\n  verbosity: The verbosity level of the CLI.\n  adk_version: The ADK version to use in Cloud Run.\n  allow_origins: The list of allowed\
    \ origins for the ADK api server.\n  session_service_uri: The URI of the session service.\n  artifact_service_uri: The URI of the artifact service.\n  memory_service_uri: The URI of the memory service."
  signature: 'def to_cloud_run(*, agent_folder: str, project: typing.Optional[str], region: typing.Optional[str], service_name: str, app_name: str, temp_folder: str, port: int, trace_to_cloud: bool, with_ui: bool, log_level: str, verbosity: str, adk_version: str, allow_origins: typing.Optional[list[str]]=None, session_service_uri: typing.Optional[str]=None, artifact_service_uri: typing.Optional[str]=None, memory_service_uri: typing.Optional[str]=None, a2a: bool=False, extra_gcloud_args: typing.Optional[tuple[str, Ellipsis]]=None):'
- rank: 478
  id: google.adk.cli.cli_deploy.to_gke
  name: to_gke
  file_path: google/adk/cli/cli_deploy.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Deploys an agent to Google Kubernetes Engine(GKE).\n\nArgs:\n  agent_folder: The folder (absolute path) containing the agent source code.\n  project: Google Cloud project id.\n  region: Google Cloud region.\n  cluster_name: The name of the GKE cluster.\n  service_name: The service name in GKE.\n  app_name: The name of the app, by default, it's basename of `agent_folder`.\n  temp_folder: The local directory to use as a temporary workspace for\n    preparing deployment artifacts. The tool populates this folder with a copy\n    of the agent's source code and auto-generates necessary files like a\n    Dockerfile and deployment.yaml.\n  port: The port of the ADK api server.\n  trace_to_cloud: Whether to enable Cloud Trace.\n  with_ui: Whether to deploy with UI.\n  log_level: The logging level.\n  adk_version: The ADK version to use in GKE.\n  allow_origins: The list of allowed origins for the ADK api server.\n  session_service_uri: The URI of the session service.\n  artifact_service_uri:\
    \ The URI of the artifact service.\n  memory_service_uri: The URI of the memory service."
  signature: 'def to_gke(*, agent_folder: str, project: typing.Optional[str], region: typing.Optional[str], cluster_name: str, service_name: str, app_name: str, temp_folder: str, port: int, trace_to_cloud: bool, with_ui: bool, log_level: str, adk_version: str, allow_origins: typing.Optional[list[str]]=None, session_service_uri: typing.Optional[str]=None, artifact_service_uri: typing.Optional[str]=None, memory_service_uri: typing.Optional[str]=None, a2a: bool=False):'
- rank: 479
  id: google.adk.cli.cli_eval
  name: cli_eval
  file_path: google/adk/cli/cli_eval.py
  type: MODULE
  group: Orphan
  usage_score: 0
  methods:
  - signature: 'def get_root_agent(agent_module_file_path: str) -> google.adk.agents.llm_agent.Agent:'
    docstring: Returns root agent given the agent module.
  - signature: 'def try_get_reset_func(agent_module_file_path: str) -> typing.Any:'
    docstring: Returns reset function for the agent, if present, given the agent module.
  - signature: 'def parse_and_get_evals_to_run(evals_to_run_info: list[str]) -> dict[str, list[str]]:'
    docstring: "Returns a dictionary of eval set info to evals that should be run.\n\nArgs:\n  evals_to_run_info: While the structure is quite simple, a list of string,\n    each string actually is formatted with the following convention:\n    <eval_set_file_path | eval_set_id>:[comma separated eval case ids]"
  - signature: 'def pretty_print_eval_result(eval_result: google.adk.evaluation.eval_result.EvalCaseResult):'
    docstring: Pretty prints eval result.
  - signature: 'def get_eval_sets_manager(eval_storage_uri: typing.Optional[str], agents_dir: str) -> google.adk.evaluation.eval_sets_manager.EvalSetsManager:'
    docstring: Returns an instance of EvalSetsManager.
- rank: 480
  id: google.adk.cli.cli_eval.get_eval_sets_manager
  name: get_eval_sets_manager
  file_path: google/adk/cli/cli_eval.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: Returns an instance of EvalSetsManager.
  signature: 'def get_eval_sets_manager(eval_storage_uri: typing.Optional[str], agents_dir: str) -> google.adk.evaluation.eval_sets_manager.EvalSetsManager:'
- rank: 481
  id: google.adk.cli.cli_eval.get_root_agent
  name: get_root_agent
  file_path: google/adk/cli/cli_eval.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: Returns root agent given the agent module.
  signature: 'def get_root_agent(agent_module_file_path: str) -> google.adk.agents.llm_agent.Agent:'
- rank: 482
  id: google.adk.cli.cli_eval.parse_and_get_evals_to_run
  name: parse_and_get_evals_to_run
  file_path: google/adk/cli/cli_eval.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Returns a dictionary of eval set info to evals that should be run.\n\nArgs:\n  evals_to_run_info: While the structure is quite simple, a list of string,\n    each string actually is formatted with the following convention:\n    <eval_set_file_path | eval_set_id>:[comma separated eval case ids]"
  signature: 'def parse_and_get_evals_to_run(evals_to_run_info: list[str]) -> dict[str, list[str]]:'
- rank: 483
  id: google.adk.cli.cli_eval.pretty_print_eval_result
  name: pretty_print_eval_result
  file_path: google/adk/cli/cli_eval.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: Pretty prints eval result.
  signature: 'def pretty_print_eval_result(eval_result: google.adk.evaluation.eval_result.EvalCaseResult):'
- rank: 484
  id: google.adk.cli.cli_eval.try_get_reset_func
  name: try_get_reset_func
  file_path: google/adk/cli/cli_eval.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: Returns reset function for the agent, if present, given the agent module.
  signature: 'def try_get_reset_func(agent_module_file_path: str) -> typing.Any:'
- rank: 485
  id: google.adk.cli.cli_tools_click
  name: cli_tools_click
  file_path: google/adk/cli/cli_tools_click.py
  type: MODULE
  group: Orphan
  usage_score: 0
  methods:
  - signature: 'def main():'
    docstring: Agent Development Kit CLI tools.
  - signature: 'def deploy():'
    docstring: Deploys agent to hosted environments.
  - signature: 'def conformance():'
    docstring: Conformance testing tools for ADK.
  - signature: 'def cli_conformance_record(ctx, paths: tuple[str, Ellipsis]):'
    docstring: 'Generate ADK conformance test YAML files from TestCaseInput specifications.


      NOTE: this is work in progress.


      This command reads TestCaseInput specifications from input.yaml files,

      executes the specified test cases against agents, and generates conformance

      test files with recorded agent interactions as test.yaml files.


      Expected directory structure:

      category/name/input.yaml (TestCaseInput) -> category/name/test.yaml (TestCase)


      PATHS: One or more directories containing test case specifications.

      If no paths are provided, defaults to ''tests/'' directory.


      Examples:


      Use default directory: adk conformance record


      Custom directories: adk conformance record tests/core tests/tools'
  - signature: 'def cli_conformance_test(ctx, paths: tuple[str, Ellipsis], mode: str):'
    docstring: "Run conformance tests to verify agent behavior consistency.\n\nValidates that agents produce consistent outputs by comparing against recorded\ninteractions or evaluating live execution results.\n\nPATHS can be any number of folder paths. Each folder can either:\n- Contain a spec.yaml file directly (single test case)\n- Contain subdirectories with spec.yaml files (multiple test cases)\n\nIf no paths are provided, defaults to searching the 'tests' folder.\n\nTEST MODES:\n\n\b\nreplay  : Verifies agent interactions match previously recorded behaviors\n          exactly. Compares LLM requests/responses and tool calls/results.\nlive    : Runs evaluation-based verification (not yet implemented)\n\nDIRECTORY STRUCTURE:\n\nTest cases must follow this structure:\n\n\b\ncategory/\n  test_name/\n    spec.yaml                    # Test specification\n    generated-recordings.yaml    # Recorded interactions (replay mode)\n    generated-session.yaml       # Session data (replay mode)\n\
      \nEXAMPLES:\n\n\b\n# Run all tests in current directory's 'tests' folder\nadk conformance test\n\n\b\n# Run tests from specific folders\nadk conformance test tests/core tests/tools\n\n\b\n# Run a single test case\nadk conformance test tests/core/description_001\n\n\b\n# Run in live mode (when available)\nadk conformance test --mode=live tests/core"
  - signature: 'def cli_create_cmd(app_name: str, model: typing.Optional[str], api_key: typing.Optional[str], project: typing.Optional[str], region: typing.Optional[str], type: typing.Optional[str]):'
    docstring: "Creates a new app in the current folder with prepopulated agent template.\n\nAPP_NAME: required, the folder of the agent source code.\n\nExample:\n\n  adk create path/to/my_app"
  - signature: 'def validate_exclusive(ctx, param, value):'
  - signature: 'def adk_services_options():'
    docstring: Decorator to add ADK services options to click commands.
  - signature: 'def decorator(func):'
  - signature: 'def wrapper(ctx):'
  - signature: 'def cli_run(agent: str, save_session: bool, session_id: typing.Optional[str], replay: typing.Optional[str], resume: typing.Optional[str], session_service_uri: typing.Optional[str], artifact_service_uri: typing.Optional[str], memory_service_uri: typing.Optional[str]):'
    docstring: "Runs an interactive CLI for a certain agent.\n\nAGENT: The path to the agent source code folder.\n\nExample:\n\n  adk run path/to/my_agent"
  - signature: 'def eval_options():'
    docstring: Decorator to add common eval options to click commands.
  - signature: 'def decorator(func):'
  - signature: 'def wrapper(ctx):'
  - signature: 'def cli_eval(agent_module_file_path: str, eval_set_file_path_or_id: list[str], config_file_path: str, print_detailed_results: bool, eval_storage_uri: typing.Optional[str], log_level: str):'
    docstring: "Evaluates an agent given the eval sets.\n\nAGENT_MODULE_FILE_PATH: The path to the __init__.py file that contains a\nmodule by the name \"agent\". \"agent\" module contains a root_agent.\n\nEVAL_SET_FILE_PATH_OR_ID: You can specify one or more eval set file paths or\neval set id.\n\nMixing of eval set file paths with eval set ids is not allowed.\n\n*Eval Set File Path*\nFor each file, all evals will be run by default.\n\nIf you want to run only specific evals from an eval set, first create a comma\nseparated list of eval names and then add that as a suffix to the eval set\nfile name, demarcated by a `:`.\n\nFor example, we have `sample_eval_set_file.json` file that has following the\neval cases:\nsample_eval_set_file.json:\n  |....... eval_1\n  |....... eval_2\n  |....... eval_3\n  |....... eval_4\n  |....... eval_5\n\nsample_eval_set_file.json:eval_1,eval_2,eval_3\n\nThis will only run eval_1, eval_2 and eval_3 from sample_eval_set_file.json.\n\n*Eval Set ID*\nFor each eval\
      \ set, all evals will be run by default.\n\nIf you want to run only specific evals from an eval set, first create a comma\nseparated list of eval names and then add that as a suffix to the eval set\nfile name, demarcated by a `:`.\n\nFor example, we have `sample_eval_set_id` that has following the eval cases:\nsample_eval_set_id:\n  |....... eval_1\n  |....... eval_2\n  |....... eval_3\n  |....... eval_4\n  |....... eval_5\n\nIf we did:\n    sample_eval_set_id:eval_1,eval_2,eval_3\n\nThis will only run eval_1, eval_2 and eval_3 from sample_eval_set_id.\n\nCONFIG_FILE_PATH: The path to config file.\n\nPRINT_DETAILED_RESULTS: Prints detailed results on the console."
  - signature: 'def eval_set():'
    docstring: Manage Eval Sets.
  - signature: 'def cli_create_eval_set(agent_module_file_path: str, eval_set_id: str, eval_storage_uri: typing.Optional[str], log_level: str):'
    docstring: Creates an empty EvalSet given the agent_module_file_path and eval_set_id.
  - signature: 'def cli_add_eval_case(agent_module_file_path: str, eval_set_id: str, scenarios_file: str, eval_storage_uri: typing.Optional[str], session_input_file: typing.Optional[str], log_level: str):'
    docstring: 'Adds eval cases to the given eval set.


      There are several ways that an eval case can be created, for now this method

      only supports adding one using a conversation scenarios file.


      If an eval case for the generated id already exists, then we skip adding it.'
  - signature: 'def web_options():'
    docstring: Decorator to add web UI options to click commands.
  - signature: 'def decorator(func):'
  - signature: 'def wrapper(ctx):'
  - signature: 'def deprecated_adk_services_options():'
    docstring: Deprecated ADK services options.
  - signature: 'def warn(alternative_param, ctx, param, value):'
  - signature: 'def decorator(func):'
  - signature: 'def wrapper(ctx):'
  - signature: 'def fast_api_common_options():'
    docstring: Decorator to add common fast api options to click commands.
  - signature: 'def decorator(func):'
  - signature: 'def wrapper(ctx):'
  - signature: 'def cli_web(agents_dir: str, eval_storage_uri: typing.Optional[str], log_level: str, allow_origins: typing.Optional[list[str]], host: str, port: int, url_prefix: typing.Optional[str], trace_to_cloud: bool, otel_to_cloud: bool, reload: bool, session_service_uri: typing.Optional[str], artifact_service_uri: typing.Optional[str], memory_service_uri: typing.Optional[str], session_db_url: typing.Optional[str], artifact_storage_uri: typing.Optional[str], a2a: bool, reload_agents: bool, extra_plugins: typing.Optional[list[str]], logo_text: typing.Optional[str], logo_image_url: typing.Optional[str]):'
    docstring: "Starts a FastAPI server with Web UI for agents.\n\nAGENTS_DIR: The directory of agents, where each sub-directory is a single\nagent, containing at least `__init__.py` and `agent.py` files.\n\nExample:\n\n  adk web --session_service_uri=[uri] --port=[port] path/to/agents_dir"
  - signature: 'def cli_api_server(agents_dir: str, eval_storage_uri: typing.Optional[str], log_level: str, allow_origins: typing.Optional[list[str]], host: str, port: int, url_prefix: typing.Optional[str], trace_to_cloud: bool, otel_to_cloud: bool, reload: bool, session_service_uri: typing.Optional[str], artifact_service_uri: typing.Optional[str], memory_service_uri: typing.Optional[str], session_db_url: typing.Optional[str], artifact_storage_uri: typing.Optional[str], a2a: bool, reload_agents: bool, extra_plugins: typing.Optional[list[str]]):'
    docstring: "Starts a FastAPI server for agents.\n\nAGENTS_DIR: The directory of agents, where each sub-directory is a single\nagent, containing at least `__init__.py` and `agent.py` files.\n\nExample:\n\n  adk api_server --session_service_uri=[uri] --port=[port] path/to/agents_dir"
  - signature: 'def cli_deploy_cloud_run(ctx, agent: str, project: typing.Optional[str], region: typing.Optional[str], service_name: str, app_name: str, temp_folder: str, port: int, trace_to_cloud: bool, with_ui: bool, adk_version: str, log_level: str, verbosity: typing.Optional[str], allow_origins: typing.Optional[list[str]], session_service_uri: typing.Optional[str], artifact_service_uri: typing.Optional[str], memory_service_uri: typing.Optional[str], session_db_url: typing.Optional[str], artifact_storage_uri: typing.Optional[str], a2a: bool):'
    docstring: "Deploys an agent to Cloud Run.\n\nAGENT: The path to the agent source code folder.\n\nUse '--' to separate gcloud arguments from adk arguments.\n\nExamples:\n\n  adk deploy cloud_run --project=[project] --region=[region] path/to/my_agent\n\n  adk deploy cloud_run --project=[project] --region=[region] path/to/my_agent\n    -- --no-allow-unauthenticated --min-instances=2"
  - signature: 'def cli_deploy_agent_engine(agent: str, project: typing.Optional[str], region: typing.Optional[str], staging_bucket: typing.Optional[str], agent_engine_id: typing.Optional[str], trace_to_cloud: typing.Optional[bool], api_key: typing.Optional[str], display_name: str, description: str, adk_app: str, adk_app_object: typing.Optional[str], temp_folder: typing.Optional[str], env_file: str, requirements_file: str, absolutize_imports: bool, agent_engine_config_file: str):'
    docstring: "Deploys an agent to Agent Engine.\n\nExample:\n\n  # With Express Mode API Key\n  adk deploy agent_engine --api_key=[api_key] my_agent\n\n  # With Google Cloud Project and Region\n  adk deploy agent_engine --project=[project] --region=[region]\n    --staging_bucket=[staging_bucket] --display_name=[app_name]\n    my_agent"
  - signature: 'def cli_deploy_gke(agent: str, project: typing.Optional[str], region: typing.Optional[str], cluster_name: str, service_name: str, app_name: str, temp_folder: str, port: int, trace_to_cloud: bool, with_ui: bool, adk_version: str, log_level: typing.Optional[str], session_service_uri: typing.Optional[str], artifact_service_uri: typing.Optional[str], memory_service_uri: typing.Optional[str]):'
    docstring: "Deploys an agent to GKE.\n\nAGENT: The path to the agent source code folder.\n\nExample:\n\n  adk deploy gke --project=[project] --region=[region]\n    --cluster_name=[cluster_name] path/to/my_agent"
- rank: 486
  id: google.adk.cli.cli_tools_click.HelpfulCommand
  name: HelpfulCommand
  file_path: google/adk/cli/cli_tools_click.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: "Command that shows full help on error instead of just the error message.\n\nA custom Click Command class that overrides the default error handling\nbehavior to display the full help text when a required argument is missing,\nfollowed by the error message. This provides users with better context\nabout command usage without needing to run a separate --help command.\n\nArgs:\n  *args: Variable length argument list to pass to the parent class.\n  **kwargs: Arbitrary keyword arguments to pass to the parent class.\n\nReturns:\n  None. Inherits behavior from the parent Click Command class.\n\nReturns:\n\n[Note: Inherited members from click.Command are omitted.]"
  constructor_signature: 'def __init__(self):'
  methods:
  - signature: 'def parse_args(self, ctx, args):'
    docstring: "Override the parse_args method to show help text on error.\n\nArgs:\n  ctx: Click context object for the current command.\n  args: List of command-line arguments to parse.\n\nReturns:\n  The parsed arguments as returned by the parent class's parse_args method.\n\nRaises:\n  click.MissingParameter: When a required parameter is missing, but this\n    is caught and handled by displaying the help text before exiting."
  omitted_inherited_members_from:
  - click.Command
- rank: 487
  id: google.adk.cli.cli_tools_click.HelpfulCommand.parse_args
  name: parse_args
  file_path: google/adk/cli/cli_tools_click.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Override the parse_args method to show help text on error.\n\nArgs:\n  ctx: Click context object for the current command.\n  args: List of command-line arguments to parse.\n\nReturns:\n  The parsed arguments as returned by the parent class's parse_args method.\n\nRaises:\n  click.MissingParameter: When a required parameter is missing, but this\n    is caught and handled by displaying the help text before exiting."
  signature: 'def parse_args(self, ctx, args):'
- rank: 488
  id: google.adk.cli.cli_tools_click.adk_services_options
  name: adk_services_options
  file_path: google/adk/cli/cli_tools_click.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: Decorator to add ADK services options to click commands.
  signature: 'def adk_services_options():'
- rank: 489
  id: google.adk.cli.cli_tools_click.cli_add_eval_case
  name: cli_add_eval_case
  file_path: google/adk/cli/cli_tools_click.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: 'Adds eval cases to the given eval set.


    There are several ways that an eval case can be created, for now this method

    only supports adding one using a conversation scenarios file.


    If an eval case for the generated id already exists, then we skip adding it.'
  signature: 'def cli_add_eval_case(agent_module_file_path: str, eval_set_id: str, scenarios_file: str, eval_storage_uri: typing.Optional[str], session_input_file: typing.Optional[str], log_level: str):'
- rank: 490
  id: google.adk.cli.cli_tools_click.cli_api_server
  name: cli_api_server
  file_path: google/adk/cli/cli_tools_click.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Starts a FastAPI server for agents.\n\nAGENTS_DIR: The directory of agents, where each sub-directory is a single\nagent, containing at least `__init__.py` and `agent.py` files.\n\nExample:\n\n  adk api_server --session_service_uri=[uri] --port=[port] path/to/agents_dir"
  signature: 'def cli_api_server(agents_dir: str, eval_storage_uri: typing.Optional[str], log_level: str, allow_origins: typing.Optional[list[str]], host: str, port: int, url_prefix: typing.Optional[str], trace_to_cloud: bool, otel_to_cloud: bool, reload: bool, session_service_uri: typing.Optional[str], artifact_service_uri: typing.Optional[str], memory_service_uri: typing.Optional[str], session_db_url: typing.Optional[str], artifact_storage_uri: typing.Optional[str], a2a: bool, reload_agents: bool, extra_plugins: typing.Optional[list[str]]):'
- rank: 491
  id: google.adk.cli.cli_tools_click.cli_conformance_record
  name: cli_conformance_record
  file_path: google/adk/cli/cli_tools_click.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: 'Generate ADK conformance test YAML files from TestCaseInput specifications.


    NOTE: this is work in progress.


    This command reads TestCaseInput specifications from input.yaml files,

    executes the specified test cases against agents, and generates conformance

    test files with recorded agent interactions as test.yaml files.


    Expected directory structure:

    category/name/input.yaml (TestCaseInput) -> category/name/test.yaml (TestCase)


    PATHS: One or more directories containing test case specifications.

    If no paths are provided, defaults to ''tests/'' directory.


    Examples:


    Use default directory: adk conformance record


    Custom directories: adk conformance record tests/core tests/tools'
  signature: 'def cli_conformance_record(ctx, paths: tuple[str, Ellipsis]):'
- rank: 492
  id: google.adk.cli.cli_tools_click.cli_conformance_test
  name: cli_conformance_test
  file_path: google/adk/cli/cli_tools_click.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Run conformance tests to verify agent behavior consistency.\n\nValidates that agents produce consistent outputs by comparing against recorded\ninteractions or evaluating live execution results.\n\nPATHS can be any number of folder paths. Each folder can either:\n- Contain a spec.yaml file directly (single test case)\n- Contain subdirectories with spec.yaml files (multiple test cases)\n\nIf no paths are provided, defaults to searching the 'tests' folder.\n\nTEST MODES:\n\n\b\nreplay  : Verifies agent interactions match previously recorded behaviors\n          exactly. Compares LLM requests/responses and tool calls/results.\nlive    : Runs evaluation-based verification (not yet implemented)\n\nDIRECTORY STRUCTURE:\n\nTest cases must follow this structure:\n\n\b\ncategory/\n  test_name/\n    spec.yaml                    # Test specification\n    generated-recordings.yaml    # Recorded interactions (replay mode)\n    generated-session.yaml       # Session data (replay mode)\n\n\
    EXAMPLES:\n\n\b\n# Run all tests in current directory's 'tests' folder\nadk conformance test\n\n\b\n# Run tests from specific folders\nadk conformance test tests/core tests/tools\n\n\b\n# Run a single test case\nadk conformance test tests/core/description_001\n\n\b\n# Run in live mode (when available)\nadk conformance test --mode=live tests/core"
  signature: 'def cli_conformance_test(ctx, paths: tuple[str, Ellipsis], mode: str):'
- rank: 493
  id: google.adk.cli.cli_tools_click.cli_create_cmd
  name: cli_create_cmd
  file_path: google/adk/cli/cli_tools_click.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Creates a new app in the current folder with prepopulated agent template.\n\nAPP_NAME: required, the folder of the agent source code.\n\nExample:\n\n  adk create path/to/my_app"
  signature: 'def cli_create_cmd(app_name: str, model: typing.Optional[str], api_key: typing.Optional[str], project: typing.Optional[str], region: typing.Optional[str], type: typing.Optional[str]):'
- rank: 494
  id: google.adk.cli.cli_tools_click.cli_create_eval_set
  name: cli_create_eval_set
  file_path: google/adk/cli/cli_tools_click.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: Creates an empty EvalSet given the agent_module_file_path and eval_set_id.
  signature: 'def cli_create_eval_set(agent_module_file_path: str, eval_set_id: str, eval_storage_uri: typing.Optional[str], log_level: str):'
- rank: 495
  id: google.adk.cli.cli_tools_click.cli_deploy_agent_engine
  name: cli_deploy_agent_engine
  file_path: google/adk/cli/cli_tools_click.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Deploys an agent to Agent Engine.\n\nExample:\n\n  # With Express Mode API Key\n  adk deploy agent_engine --api_key=[api_key] my_agent\n\n  # With Google Cloud Project and Region\n  adk deploy agent_engine --project=[project] --region=[region]\n    --staging_bucket=[staging_bucket] --display_name=[app_name]\n    my_agent"
  signature: 'def cli_deploy_agent_engine(agent: str, project: typing.Optional[str], region: typing.Optional[str], staging_bucket: typing.Optional[str], agent_engine_id: typing.Optional[str], trace_to_cloud: typing.Optional[bool], api_key: typing.Optional[str], display_name: str, description: str, adk_app: str, adk_app_object: typing.Optional[str], temp_folder: typing.Optional[str], env_file: str, requirements_file: str, absolutize_imports: bool, agent_engine_config_file: str):'
- rank: 496
  id: google.adk.cli.cli_tools_click.cli_deploy_cloud_run
  name: cli_deploy_cloud_run
  file_path: google/adk/cli/cli_tools_click.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Deploys an agent to Cloud Run.\n\nAGENT: The path to the agent source code folder.\n\nUse '--' to separate gcloud arguments from adk arguments.\n\nExamples:\n\n  adk deploy cloud_run --project=[project] --region=[region] path/to/my_agent\n\n  adk deploy cloud_run --project=[project] --region=[region] path/to/my_agent\n    -- --no-allow-unauthenticated --min-instances=2"
  signature: 'def cli_deploy_cloud_run(ctx, agent: str, project: typing.Optional[str], region: typing.Optional[str], service_name: str, app_name: str, temp_folder: str, port: int, trace_to_cloud: bool, with_ui: bool, adk_version: str, log_level: str, verbosity: typing.Optional[str], allow_origins: typing.Optional[list[str]], session_service_uri: typing.Optional[str], artifact_service_uri: typing.Optional[str], memory_service_uri: typing.Optional[str], session_db_url: typing.Optional[str], artifact_storage_uri: typing.Optional[str], a2a: bool):'
- rank: 497
  id: google.adk.cli.cli_tools_click.cli_deploy_gke
  name: cli_deploy_gke
  file_path: google/adk/cli/cli_tools_click.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Deploys an agent to GKE.\n\nAGENT: The path to the agent source code folder.\n\nExample:\n\n  adk deploy gke --project=[project] --region=[region]\n    --cluster_name=[cluster_name] path/to/my_agent"
  signature: 'def cli_deploy_gke(agent: str, project: typing.Optional[str], region: typing.Optional[str], cluster_name: str, service_name: str, app_name: str, temp_folder: str, port: int, trace_to_cloud: bool, with_ui: bool, adk_version: str, log_level: typing.Optional[str], session_service_uri: typing.Optional[str], artifact_service_uri: typing.Optional[str], memory_service_uri: typing.Optional[str]):'
- rank: 498
  id: google.adk.cli.cli_tools_click.cli_eval
  name: cli_eval
  file_path: google/adk/cli/cli_tools_click.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Evaluates an agent given the eval sets.\n\nAGENT_MODULE_FILE_PATH: The path to the __init__.py file that contains a\nmodule by the name \"agent\". \"agent\" module contains a root_agent.\n\nEVAL_SET_FILE_PATH_OR_ID: You can specify one or more eval set file paths or\neval set id.\n\nMixing of eval set file paths with eval set ids is not allowed.\n\n*Eval Set File Path*\nFor each file, all evals will be run by default.\n\nIf you want to run only specific evals from an eval set, first create a comma\nseparated list of eval names and then add that as a suffix to the eval set\nfile name, demarcated by a `:`.\n\nFor example, we have `sample_eval_set_file.json` file that has following the\neval cases:\nsample_eval_set_file.json:\n  |....... eval_1\n  |....... eval_2\n  |....... eval_3\n  |....... eval_4\n  |....... eval_5\n\nsample_eval_set_file.json:eval_1,eval_2,eval_3\n\nThis will only run eval_1, eval_2 and eval_3 from sample_eval_set_file.json.\n\n*Eval Set ID*\nFor each eval\
    \ set, all evals will be run by default.\n\nIf you want to run only specific evals from an eval set, first create a comma\nseparated list of eval names and then add that as a suffix to the eval set\nfile name, demarcated by a `:`.\n\nFor example, we have `sample_eval_set_id` that has following the eval cases:\nsample_eval_set_id:\n  |....... eval_1\n  |....... eval_2\n  |....... eval_3\n  |....... eval_4\n  |....... eval_5\n\nIf we did:\n    sample_eval_set_id:eval_1,eval_2,eval_3\n\nThis will only run eval_1, eval_2 and eval_3 from sample_eval_set_id.\n\nCONFIG_FILE_PATH: The path to config file.\n\nPRINT_DETAILED_RESULTS: Prints detailed results on the console."
  signature: 'def cli_eval(agent_module_file_path: str, eval_set_file_path_or_id: list[str], config_file_path: str, print_detailed_results: bool, eval_storage_uri: typing.Optional[str], log_level: str):'
- rank: 499
  id: google.adk.cli.cli_tools_click.cli_run
  name: cli_run
  file_path: google/adk/cli/cli_tools_click.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Runs an interactive CLI for a certain agent.\n\nAGENT: The path to the agent source code folder.\n\nExample:\n\n  adk run path/to/my_agent"
  signature: 'def cli_run(agent: str, save_session: bool, session_id: typing.Optional[str], replay: typing.Optional[str], resume: typing.Optional[str], session_service_uri: typing.Optional[str], artifact_service_uri: typing.Optional[str], memory_service_uri: typing.Optional[str]):'
- rank: 500
  id: google.adk.cli.cli_tools_click.cli_web
  name: cli_web
  file_path: google/adk/cli/cli_tools_click.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Starts a FastAPI server with Web UI for agents.\n\nAGENTS_DIR: The directory of agents, where each sub-directory is a single\nagent, containing at least `__init__.py` and `agent.py` files.\n\nExample:\n\n  adk web --session_service_uri=[uri] --port=[port] path/to/agents_dir"
  signature: 'def cli_web(agents_dir: str, eval_storage_uri: typing.Optional[str], log_level: str, allow_origins: typing.Optional[list[str]], host: str, port: int, url_prefix: typing.Optional[str], trace_to_cloud: bool, otel_to_cloud: bool, reload: bool, session_service_uri: typing.Optional[str], artifact_service_uri: typing.Optional[str], memory_service_uri: typing.Optional[str], session_db_url: typing.Optional[str], artifact_storage_uri: typing.Optional[str], a2a: bool, reload_agents: bool, extra_plugins: typing.Optional[list[str]], logo_text: typing.Optional[str], logo_image_url: typing.Optional[str]):'
- rank: 501
  id: google.adk.cli.cli_tools_click.decorator
  name: decorator
  file_path: google/adk/cli/cli_tools_click.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def decorator(func):'
- rank: 502
  id: google.adk.cli.cli_tools_click.decorator
  name: decorator
  file_path: google/adk/cli/cli_tools_click.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def decorator(func):'
- rank: 503
  id: google.adk.cli.cli_tools_click.decorator
  name: decorator
  file_path: google/adk/cli/cli_tools_click.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def decorator(func):'
- rank: 504
  id: google.adk.cli.cli_tools_click.decorator
  name: decorator
  file_path: google/adk/cli/cli_tools_click.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def decorator(func):'
- rank: 505
  id: google.adk.cli.cli_tools_click.decorator
  name: decorator
  file_path: google/adk/cli/cli_tools_click.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def decorator(func):'
- rank: 506
  id: google.adk.cli.cli_tools_click.deprecated_adk_services_options
  name: deprecated_adk_services_options
  file_path: google/adk/cli/cli_tools_click.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: Deprecated ADK services options.
  signature: 'def deprecated_adk_services_options():'
- rank: 507
  id: google.adk.cli.cli_tools_click.eval_options
  name: eval_options
  file_path: google/adk/cli/cli_tools_click.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: Decorator to add common eval options to click commands.
  signature: 'def eval_options():'
- rank: 508
  id: google.adk.cli.cli_tools_click.fast_api_common_options
  name: fast_api_common_options
  file_path: google/adk/cli/cli_tools_click.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: Decorator to add common fast api options to click commands.
  signature: 'def fast_api_common_options():'
- rank: 509
  id: google.adk.cli.cli_tools_click.validate_exclusive
  name: validate_exclusive
  file_path: google/adk/cli/cli_tools_click.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def validate_exclusive(ctx, param, value):'
- rank: 510
  id: google.adk.cli.cli_tools_click.warn
  name: warn
  file_path: google/adk/cli/cli_tools_click.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def warn(alternative_param, ctx, param, value):'
- rank: 511
  id: google.adk.cli.cli_tools_click.web_options
  name: web_options
  file_path: google/adk/cli/cli_tools_click.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: Decorator to add web UI options to click commands.
  signature: 'def web_options():'
- rank: 512
  id: google.adk.cli.cli_tools_click.wrapper
  name: wrapper
  file_path: google/adk/cli/cli_tools_click.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def wrapper(ctx):'
- rank: 513
  id: google.adk.cli.conformance
  name: conformance
  file_path: google/adk/cli/conformance/__init__.py
  type: MODULE
  group: Orphan
  usage_score: 0
- rank: 514
  id: google.adk.cli.conformance.adk_web_server_client
  name: adk_web_server_client
  file_path: google/adk/cli/conformance/adk_web_server_client.py
  type: MODULE
  group: Orphan
  usage_score: 0
  docstring: HTTP client for interacting with the ADK web server.
- rank: 515
  id: google.adk.cli.conformance.adk_web_server_client.AdkWebServerClient
  name: AdkWebServerClient
  file_path: google/adk/cli/conformance/adk_web_server_client.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: "HTTP client for interacting with the ADK web server for conformance tests.\n\nUsage patterns:\n\n  # Pattern 1: Manual lifecycle management\n  client = AdkWebServerClient()\n  session = await client.create_session(app_name=\"app\", user_id=\"user\")\n  async for event in client.run_agent(request):\n      # Process events...\n  await client.close()  # Optional explicit cleanup\n\n  # Pattern 2: Automatic cleanup with context manager (recommended)\n  async with AdkWebServerClient() as client:\n      session = await client.create_session(app_name=\"app\", user_id=\"user\")\n      async for event in client.run_agent(request):\n          # Process events...\n      # Client automatically closed here"
  constructor_signature: 'def __init__(self, base_url: str, timeout: float):'
  methods:
  - signature: 'def close(self) -> None:'
    docstring: Close the HTTP client and clean up resources.
  - signature: 'def get_session(self, *, app_name: str, user_id: str, session_id: str) -> google.adk.sessions.session.Session:'
    docstring: "Retrieve a specific session from the ADK web server.\n\nArgs:\n  app_name: Name of the application\n  user_id: User identifier\n  session_id: Session identifier\n\nReturns:\n  The requested Session object\n\nRaises:\n  httpx.HTTPStatusError: If the request fails or session not found"
  - signature: 'def create_session(self, *, app_name: str, user_id: str, state: typing.Optional[typing.Dict[str, typing.Any]]=None) -> google.adk.sessions.session.Session:'
    docstring: "Create a new session in the ADK web server.\n\nArgs:\n  app_name: Name of the application\n  user_id: User identifier\n  state: Optional initial state for the session\n\nReturns:\n  The newly created Session object\n\nRaises:\n  httpx.HTTPStatusError: If the request fails"
  - signature: 'def delete_session(self, *, app_name: str, user_id: str, session_id: str) -> None:'
    docstring: "Delete a session from the ADK web server.\n\nArgs:\n  app_name: Name of the application\n  user_id: User identifier\n  session_id: Session identifier to delete\n\nRaises:\n  httpx.HTTPStatusError: If the request fails or session not found"
  - signature: 'def update_session(self, *, app_name: str, user_id: str, session_id: str, state_delta: typing.Dict[str, typing.Any]) -> google.adk.sessions.session.Session:'
    docstring: "Update session state without running the agent.\n\nArgs:\n  app_name: Name of the application\n  user_id: User identifier\n  session_id: Session identifier to update\n  state_delta: The state changes to apply to the session\n\nReturns:\n  The updated Session object\n\nRaises:\n  httpx.HTTPStatusError: If the request fails or session not found"
  - signature: 'def run_agent(self, request: google.adk.cli.adk_web_server.RunAgentRequest, mode: typing.Optional[typing.Literal[record, replay]], test_case_dir: typing.Optional[str], user_message_index: typing.Optional[int]) -> typing.AsyncGenerator[google.adk.events.event.Event, None]:'
    docstring: "Run an agent with streaming Server-Sent Events response.\n\nArgs:\n  request: The RunAgentRequest containing agent execution parameters\n  mode: Optional conformance mode (\"record\" or \"replay\") to trigger recording\n  test_case_dir: Optional test case directory path for conformance recording\n  user_message_index: Optional user message index for conformance recording\n\nYields:\n  Event objects streamed from the agent execution\n\nRaises:\n  ValueError: If mode is provided but test_case_dir or user_message_index is None\n  httpx.HTTPStatusError: If the request fails\n  json.JSONDecodeError: If event data cannot be parsed"
- rank: 516
  id: google.adk.cli.conformance.adk_web_server_client.AdkWebServerClient.__init__
  name: __init__
  file_path: google/adk/cli/conformance/adk_web_server_client.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Initialize the ADK web server client for conformance testing.\n\nArgs:\n  base_url: Base URL of the ADK web server (default: http://127.0.0.1:8000)\n  timeout: Request timeout in seconds (default: 30.0)"
  signature: 'def __init__(self, base_url: str, timeout: float):'
- rank: 517
  id: google.adk.cli.conformance.adk_web_server_client.AdkWebServerClient.close
  name: close
  file_path: google/adk/cli/conformance/adk_web_server_client.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: Close the HTTP client and clean up resources.
  signature: 'def close(self) -> None:'
- rank: 518
  id: google.adk.cli.conformance.adk_web_server_client.AdkWebServerClient.create_session
  name: create_session
  file_path: google/adk/cli/conformance/adk_web_server_client.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Create a new session in the ADK web server.\n\nArgs:\n  app_name: Name of the application\n  user_id: User identifier\n  state: Optional initial state for the session\n\nReturns:\n  The newly created Session object\n\nRaises:\n  httpx.HTTPStatusError: If the request fails"
  signature: 'def create_session(self, *, app_name: str, user_id: str, state: typing.Optional[typing.Dict[str, typing.Any]]=None) -> google.adk.sessions.session.Session:'
- rank: 519
  id: google.adk.cli.conformance.adk_web_server_client.AdkWebServerClient.delete_session
  name: delete_session
  file_path: google/adk/cli/conformance/adk_web_server_client.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Delete a session from the ADK web server.\n\nArgs:\n  app_name: Name of the application\n  user_id: User identifier\n  session_id: Session identifier to delete\n\nRaises:\n  httpx.HTTPStatusError: If the request fails or session not found"
  signature: 'def delete_session(self, *, app_name: str, user_id: str, session_id: str) -> None:'
- rank: 520
  id: google.adk.cli.conformance.adk_web_server_client.AdkWebServerClient.get_session
  name: get_session
  file_path: google/adk/cli/conformance/adk_web_server_client.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Retrieve a specific session from the ADK web server.\n\nArgs:\n  app_name: Name of the application\n  user_id: User identifier\n  session_id: Session identifier\n\nReturns:\n  The requested Session object\n\nRaises:\n  httpx.HTTPStatusError: If the request fails or session not found"
  signature: 'def get_session(self, *, app_name: str, user_id: str, session_id: str) -> google.adk.sessions.session.Session:'
- rank: 521
  id: google.adk.cli.conformance.adk_web_server_client.AdkWebServerClient.run_agent
  name: run_agent
  file_path: google/adk/cli/conformance/adk_web_server_client.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Run an agent with streaming Server-Sent Events response.\n\nArgs:\n  request: The RunAgentRequest containing agent execution parameters\n  mode: Optional conformance mode (\"record\" or \"replay\") to trigger recording\n  test_case_dir: Optional test case directory path for conformance recording\n  user_message_index: Optional user message index for conformance recording\n\nYields:\n  Event objects streamed from the agent execution\n\nRaises:\n  ValueError: If mode is provided but test_case_dir or user_message_index is None\n  httpx.HTTPStatusError: If the request fails\n  json.JSONDecodeError: If event data cannot be parsed"
  signature: 'def run_agent(self, request: google.adk.cli.adk_web_server.RunAgentRequest, mode: typing.Optional[typing.Literal[record, replay]], test_case_dir: typing.Optional[str], user_message_index: typing.Optional[int]) -> typing.AsyncGenerator[google.adk.events.event.Event, None]:'
- rank: 522
  id: google.adk.cli.conformance.adk_web_server_client.AdkWebServerClient.update_session
  name: update_session
  file_path: google/adk/cli/conformance/adk_web_server_client.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Update session state without running the agent.\n\nArgs:\n  app_name: Name of the application\n  user_id: User identifier\n  session_id: Session identifier to update\n  state_delta: The state changes to apply to the session\n\nReturns:\n  The updated Session object\n\nRaises:\n  httpx.HTTPStatusError: If the request fails or session not found"
  signature: 'def update_session(self, *, app_name: str, user_id: str, session_id: str, state_delta: typing.Dict[str, typing.Any]) -> google.adk.sessions.session.Session:'
- rank: 523
  id: google.adk.cli.conformance.cli_record
  name: cli_record
  file_path: google/adk/cli/conformance/cli_record.py
  type: MODULE
  group: Orphan
  usage_score: 0
  docstring: CLI commands for ADK conformance testing.
  methods:
  - signature: 'def run_conformance_record(paths: list[pathlib.Path]) -> None:'
    docstring: "Generate conformance tests from TestCaseInput files.\n\nArgs:\n  paths: list of directories containing test cases input files (spec.yaml)."
- rank: 524
  id: google.adk.cli.conformance.cli_record.run_conformance_record
  name: run_conformance_record
  file_path: google/adk/cli/conformance/cli_record.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Generate conformance tests from TestCaseInput files.\n\nArgs:\n  paths: list of directories containing test cases input files (spec.yaml)."
  signature: 'def run_conformance_record(paths: list[pathlib.Path]) -> None:'
- rank: 525
  id: google.adk.cli.conformance.cli_test
  name: cli_test
  file_path: google/adk/cli/conformance/cli_test.py
  type: MODULE
  group: Orphan
  usage_score: 0
  docstring: CLI implementation for ADK conformance testing.
  methods:
  - signature: 'def run_conformance_test(test_paths: list[pathlib.Path], mode: str) -> None:'
    docstring: Run conformance tests.
- rank: 526
  id: google.adk.cli.conformance.cli_test.ConformanceTestRunner
  name: ConformanceTestRunner
  file_path: google/adk/cli/conformance/cli_test.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: Runs conformance tests in replay mode.
  constructor_signature: 'def __init__(self, test_paths: list[pathlib.Path], client: google.adk.cli.conformance.adk_web_server_client.AdkWebServerClient, mode: str, user_id: str):'
  methods:
  - signature: 'def run_all_tests(self) -> google.adk.cli.conformance.cli_test._ConformanceTestSummary:'
    docstring: Run all discovered test cases.
- rank: 527
  id: google.adk.cli.conformance.cli_test.ConformanceTestRunner.__init__
  name: __init__
  file_path: google/adk/cli/conformance/cli_test.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def __init__(self, test_paths: list[pathlib.Path], client: google.adk.cli.conformance.adk_web_server_client.AdkWebServerClient, mode: str, user_id: str):'
- rank: 528
  id: google.adk.cli.conformance.cli_test.ConformanceTestRunner.run_all_tests
  name: run_all_tests
  file_path: google/adk/cli/conformance/cli_test.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: Run all discovered test cases.
  signature: 'def run_all_tests(self) -> google.adk.cli.conformance.cli_test._ConformanceTestSummary:'
- rank: 529
  id: google.adk.cli.conformance.cli_test.run_conformance_test
  name: run_conformance_test
  file_path: google/adk/cli/conformance/cli_test.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: Run conformance tests.
  signature: 'def run_conformance_test(test_paths: list[pathlib.Path], mode: str) -> None:'
- rank: 530
  id: google.adk.cli.fast_api
  name: fast_api
  file_path: google/adk/cli/fast_api.py
  type: MODULE
  group: Orphan
  usage_score: 0
  methods:
  - signature: 'def get_fast_api_app(*, agents_dir: str, session_service_uri: typing.Optional[str]=None, session_db_kwargs: typing.Optional[typing.Mapping[str, typing.Any]]=None, artifact_service_uri: typing.Optional[str]=None, memory_service_uri: typing.Optional[str]=None, eval_storage_uri: typing.Optional[str]=None, allow_origins: typing.Optional[list[str]]=None, web: bool, a2a: bool=False, host: str=''127.0.0.1'', port: int=8000, url_prefix: typing.Optional[str]=None, trace_to_cloud: bool=False, otel_to_cloud: bool=False, reload_agents: bool=False, lifespan: typing.Optional[starlette.types.Lifespan[fastapi.FastAPI]]=None, extra_plugins: typing.Optional[list[str]]=None, logo_text: typing.Optional[str]=None, logo_image_url: typing.Optional[str]=None) -> fastapi.FastAPI:'
  - signature: 'def register_processors(provider: opentelemetry.sdk.trace.TracerProvider) -> None:'
  - signature: 'def setup_observer(observer: watchdog.observers.Observer, adk_web_server: google.adk.cli.adk_web_server.AdkWebServer):'
  - signature: 'def tear_down_observer(observer: watchdog.observers.Observer, _: google.adk.cli.adk_web_server.AdkWebServer):'
  - signature: 'def builder_build(files: list[fastapi.UploadFile], tmp: typing.Optional[bool]) -> bool:'
  - signature: 'def builder_cancel(app_name: str) -> bool:'
  - signature: 'def get_agent_builder(app_name: str, file_path: typing.Optional[str], tmp: typing.Optional[bool]):'
  - signature: 'def create_a2a_runner_loader(captured_app_name: str):'
    docstring: Factory function to create A2A runner with proper closure.
- rank: 531
  id: google.adk.cli.fast_api.builder_build
  name: builder_build
  file_path: google/adk/cli/fast_api.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def builder_build(files: list[fastapi.UploadFile], tmp: typing.Optional[bool]) -> bool:'
- rank: 532
  id: google.adk.cli.fast_api.builder_cancel
  name: builder_cancel
  file_path: google/adk/cli/fast_api.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def builder_cancel(app_name: str) -> bool:'
- rank: 533
  id: google.adk.cli.fast_api.create_a2a_runner_loader
  name: create_a2a_runner_loader
  file_path: google/adk/cli/fast_api.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: Factory function to create A2A runner with proper closure.
  signature: 'def create_a2a_runner_loader(captured_app_name: str):'
- rank: 534
  id: google.adk.cli.fast_api.get_agent_builder
  name: get_agent_builder
  file_path: google/adk/cli/fast_api.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def get_agent_builder(app_name: str, file_path: typing.Optional[str], tmp: typing.Optional[bool]):'
- rank: 535
  id: google.adk.cli.fast_api.get_fast_api_app
  name: get_fast_api_app
  file_path: google/adk/cli/fast_api.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def get_fast_api_app(*, agents_dir: str, session_service_uri: typing.Optional[str]=None, session_db_kwargs: typing.Optional[typing.Mapping[str, typing.Any]]=None, artifact_service_uri: typing.Optional[str]=None, memory_service_uri: typing.Optional[str]=None, eval_storage_uri: typing.Optional[str]=None, allow_origins: typing.Optional[list[str]]=None, web: bool, a2a: bool=False, host: str=''127.0.0.1'', port: int=8000, url_prefix: typing.Optional[str]=None, trace_to_cloud: bool=False, otel_to_cloud: bool=False, reload_agents: bool=False, lifespan: typing.Optional[starlette.types.Lifespan[fastapi.FastAPI]]=None, extra_plugins: typing.Optional[list[str]]=None, logo_text: typing.Optional[str]=None, logo_image_url: typing.Optional[str]=None) -> fastapi.FastAPI:'
- rank: 536
  id: google.adk.cli.fast_api.register_processors
  name: register_processors
  file_path: google/adk/cli/fast_api.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def register_processors(provider: opentelemetry.sdk.trace.TracerProvider) -> None:'
- rank: 537
  id: google.adk.cli.fast_api.setup_observer
  name: setup_observer
  file_path: google/adk/cli/fast_api.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def setup_observer(observer: watchdog.observers.Observer, adk_web_server: google.adk.cli.adk_web_server.AdkWebServer):'
- rank: 538
  id: google.adk.cli.plugins
  name: plugins
  file_path: google/adk/cli/plugins/__init__.py
  type: MODULE
  group: Orphan
  usage_score: 0
- rank: 539
  id: google.adk.cli.plugins.recordings_plugin
  name: recordings_plugin
  file_path: google/adk/cli/plugins/recordings_plugin.py
  type: MODULE
  group: Orphan
  usage_score: 0
  docstring: Recording plugin for ADK conformance testing.
- rank: 540
  id: google.adk.cli.plugins.recordings_plugin.RecordingsPlugin
  name: RecordingsPlugin
  file_path: google/adk/cli/plugins/recordings_plugin.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Plugin for recording ADK agent interactions.


    [Note: Inherited members from ABC are omitted.]'
  constructor_signature: 'def __init__(self, *, name: str=''adk_recordings'') -> None:'
  methods:
  - signature: 'def before_run_callback(self, *, invocation_context: google.adk.agents.invocation_context.InvocationContext) -> typing.Optional[google.genai.types.Content]:'
    docstring: Always create fresh per-invocation recording state when enabled.
  - signature: 'def before_model_callback(self, *, callback_context: google.adk.agents.callback_context.CallbackContext, llm_request: google.adk.models.llm_request.LlmRequest) -> typing.Optional[google.adk.models.llm_response.LlmResponse]:'
    docstring: 'Create pending LLM recording awaiting response.


      Uses per-invocation recording state. Assumes state was created in

      before_run; raises if missing to surface misuse.'
  - signature: 'def after_model_callback(self, *, callback_context: google.adk.agents.callback_context.CallbackContext, llm_response: google.adk.models.llm_response.LlmResponse) -> typing.Optional[google.adk.models.llm_response.LlmResponse]:'
    docstring: Complete pending LLM recording for the invocation specified in session state.
  - signature: 'def before_tool_callback(self, *, tool: google.adk.tools.base_tool.BaseTool, tool_args: dict[str, typing.Any], tool_context: google.adk.tools.tool_context.ToolContext) -> typing.Optional[dict]:'
    docstring: Create pending tool recording for the invocation specified in session state.
  - signature: 'def after_tool_callback(self, *, tool: google.adk.tools.base_tool.BaseTool, tool_args: dict[str, typing.Any], tool_context: google.adk.tools.tool_context.ToolContext, result: dict) -> typing.Optional[dict]:'
    docstring: Complete pending tool recording for the invocation specified in session state.
  - signature: 'def on_tool_error_callback(self, *, tool: google.adk.tools.base_tool.BaseTool, tool_args: dict[str, typing.Any], tool_context: google.adk.tools.tool_context.ToolContext, error: Exception) -> typing.Optional[dict]:'
    docstring: 'Handle tool error callback with state guard.


      Recording schema does not yet capture errors; we only validate state.'
  - signature: 'def after_run_callback(self, *, invocation_context: google.adk.agents.invocation_context.InvocationContext) -> None:'
    docstring: Finalize and persist recordings, then clean per-invocation state.
  inherited_methods:
    BasePlugin:
    - signature: 'def on_user_message_callback(self, *, invocation_context: google.adk.agents.invocation_context.InvocationContext, user_message: google.genai.types.Content) -> typing.Optional[google.genai.types.Content]:'
      docstring: "Callback executed when a user message is received before an invocation starts.\n\nThis callback helps logging and modifying the user message before the\nrunner starts the invocation.\n\nArgs:\n  invocation_context: The context for the entire invocation.\n  user_message: The message content input by user.\n\nReturns:\n  An optional `types.Content` to be returned to the ADK. Returning a\n  value to replace the user message. Returning `None` to proceed\n  normally."
    - signature: 'def before_run_callback(self, *, invocation_context: google.adk.agents.invocation_context.InvocationContext) -> typing.Optional[google.genai.types.Content]:'
      docstring: "Callback executed before the ADK runner runs.\n\nThis is the first callback to be called in the lifecycle, ideal for global\nsetup or initialization tasks.\n\nArgs:\n  invocation_context: The context for the entire invocation, containing\n    session information, the root agent, etc.\n\nReturns:\n  An optional `Event` to be returned to the ADK. Returning a value to\n  halt execution of the runner and ends the runner with that event. Return\n  `None` to proceed normally."
    - signature: 'def on_event_callback(self, *, invocation_context: google.adk.agents.invocation_context.InvocationContext, event: google.adk.events.event.Event) -> typing.Optional[google.adk.events.event.Event]:'
      docstring: "Callback executed after an event is yielded from runner.\n\nThis is the ideal place to make modification to the event before the event\nis handled by the underlying agent app.\n\nArgs:\n  invocation_context: The context for the entire invocation.\n  event: The event raised by the runner.\n\nReturns:\n  An optional value. A non-`None` return may be used by the framework to\n  modify or replace the response. Returning `None` allows the original\n  response to be used."
    - signature: 'def after_run_callback(self, *, invocation_context: google.adk.agents.invocation_context.InvocationContext) -> None:'
      docstring: "Callback executed after an ADK runner run has completed.\n\nThis is the final callback in the ADK lifecycle, suitable for cleanup, final\nlogging, or reporting tasks.\n\nArgs:\n  invocation_context: The context for the entire invocation.\n\nReturns:\n  None"
    - signature: 'def close(self) -> None:'
      docstring: 'Method executed when the runner is closed.


        This method is used for cleanup tasks such as closing network connections

        or releasing resources.'
    - signature: 'def before_agent_callback(self, *, agent: google.adk.agents.base_agent.BaseAgent, callback_context: google.adk.agents.callback_context.CallbackContext) -> typing.Optional[google.genai.types.Content]:'
      docstring: "Callback executed before an agent's primary logic is invoked.\n\nThis callback can be used for logging, setup, or to short-circuit the\nagent's execution by returning a value.\n\nArgs:\n  agent: The agent that is about to run.\n  callback_context: The context for the agent invocation.\n\nReturns:\n  An optional `types.Content` object. If a value is returned, it will bypass\n  the agent's callbacks and its execution, and return this value directly.\n  Returning `None` allows the agent to proceed normally."
    - signature: 'def after_agent_callback(self, *, agent: google.adk.agents.base_agent.BaseAgent, callback_context: google.adk.agents.callback_context.CallbackContext) -> typing.Optional[google.genai.types.Content]:'
      docstring: "Callback executed after an agent's primary logic has completed.\n\nArgs:\n  agent: The agent that has just run.\n  callback_context: The context for the agent invocation.\n\nReturns:\n  An optional `types.Content` object. The content to return to the user.\n  When the content is present, the provided content will be used as agent\n  response and appended to event history as agent response."
    - signature: 'def before_model_callback(self, *, callback_context: google.adk.agents.callback_context.CallbackContext, llm_request: google.adk.models.llm_request.LlmRequest) -> typing.Optional[google.adk.models.llm_response.LlmResponse]:'
      docstring: "Callback executed before a request is sent to the model.\n\nThis provides an opportunity to inspect, log, or modify the `LlmRequest`\nobject. It can also be used to implement caching by returning a cached\n`LlmResponse`, which would skip the actual model call.\n\nArgs:\n  callback_context: The context for the current agent call.\n  llm_request: The prepared request object to be sent to the model.\n\nReturns:\n  An optional value. The interpretation of a non-`None` trigger an early\n  exit and returns the response immediately. Returning `None` allows the LLM\n  request to proceed normally."
    - signature: 'def after_model_callback(self, *, callback_context: google.adk.agents.callback_context.CallbackContext, llm_response: google.adk.models.llm_response.LlmResponse) -> typing.Optional[google.adk.models.llm_response.LlmResponse]:'
      docstring: "Callback executed after a response is received from the model.\n\nThis is the ideal place to log model responses, collect metrics on token\nusage, or perform post-processing on the raw `LlmResponse`.\n\nArgs:\n  callback_context: The context for the current agent call.\n  llm_response: The response object received from the model.\n\nReturns:\n  An optional value. A non-`None` return may be used by the framework to\n  modify or replace the response. Returning `None` allows the original\n  response to be used."
    - signature: 'def on_model_error_callback(self, *, callback_context: google.adk.agents.callback_context.CallbackContext, llm_request: google.adk.models.llm_request.LlmRequest, error: Exception) -> typing.Optional[google.adk.models.llm_response.LlmResponse]:'
      docstring: "Callback executed when a model call encounters an error.\n\nThis callback provides an opportunity to handle model errors gracefully,\npotentially providing alternative responses or recovery mechanisms.\n\nArgs:\n  callback_context: The context for the current agent call.\n  llm_request: The request that was sent to the model when the error\n    occurred.\n  error: The exception that was raised during model execution.\n\nReturns:\n  An optional LlmResponse. If an LlmResponse is returned, it will be used\n  instead of propagating the error. Returning `None` allows the original\n  error to be raised."
    - signature: 'def before_tool_callback(self, *, tool: google.adk.tools.base_tool.BaseTool, tool_args: dict[str, typing.Any], tool_context: google.adk.tools.tool_context.ToolContext) -> typing.Optional[dict]:'
      docstring: "Callback executed before a tool is called.\n\nThis callback is useful for logging tool usage, input validation, or\nmodifying the arguments before they are passed to the tool.\n\nArgs:\n  tool: The tool instance that is about to be executed.\n  tool_args: The dictionary of arguments to be used for invoking the tool.\n  tool_context: The context specific to the tool execution.\n\nReturns:\n  An optional dictionary. If a dictionary is returned, it will stop the tool\n  execution and return this response immediately. Returning `None` uses the\n  original, unmodified arguments."
    - signature: 'def after_tool_callback(self, *, tool: google.adk.tools.base_tool.BaseTool, tool_args: dict[str, typing.Any], tool_context: google.adk.tools.tool_context.ToolContext, result: dict) -> typing.Optional[dict]:'
      docstring: "Callback executed after a tool has been called.\n\nThis callback allows for inspecting, logging, or modifying the result\nreturned by a tool.\n\nArgs:\n  tool: The tool instance that has just been executed.\n  tool_args: The original arguments that were passed to the tool.\n  tool_context: The context specific to the tool execution.\n  result: The dictionary returned by the tool invocation.\n\nReturns:\n  An optional dictionary. If a dictionary is returned, it will **replace**\n  the original result from the tool. This allows for post-processing or\n  altering tool outputs. Returning `None` uses the original, unmodified\n  result."
    - signature: 'def on_tool_error_callback(self, *, tool: google.adk.tools.base_tool.BaseTool, tool_args: dict[str, typing.Any], tool_context: google.adk.tools.tool_context.ToolContext, error: Exception) -> typing.Optional[dict]:'
      docstring: "Callback executed when a tool call encounters an error.\n\nThis callback provides an opportunity to handle tool errors gracefully,\npotentially providing alternative responses or recovery mechanisms.\n\nArgs:\n  tool: The tool instance that encountered an error.\n  tool_args: The arguments that were passed to the tool.\n  tool_context: The context specific to the tool execution.\n  error: The exception that was raised during tool execution.\n\nReturns:\n  An optional dictionary. If a dictionary is returned, it will be used as\n  the tool response instead of propagating the error. Returning `None`\n  allows the original error to be raised."
  omitted_inherited_members_from:
  - ABC
- rank: 541
  id: google.adk.cli.plugins.recordings_plugin.RecordingsPlugin.__init__
  name: __init__
  file_path: google/adk/cli/plugins/recordings_plugin.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def __init__(self, *, name: str=''adk_recordings'') -> None:'
- rank: 542
  id: google.adk.cli.plugins.recordings_plugin.RecordingsPlugin.after_model_callback
  name: after_model_callback
  file_path: google/adk/cli/plugins/recordings_plugin.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: Complete pending LLM recording for the invocation specified in session state.
  signature: 'def after_model_callback(self, *, callback_context: google.adk.agents.callback_context.CallbackContext, llm_response: google.adk.models.llm_response.LlmResponse) -> typing.Optional[google.adk.models.llm_response.LlmResponse]:'
- rank: 543
  id: google.adk.cli.plugins.recordings_plugin.RecordingsPlugin.after_run_callback
  name: after_run_callback
  file_path: google/adk/cli/plugins/recordings_plugin.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: Finalize and persist recordings, then clean per-invocation state.
  signature: 'def after_run_callback(self, *, invocation_context: google.adk.agents.invocation_context.InvocationContext) -> None:'
- rank: 544
  id: google.adk.cli.plugins.recordings_plugin.RecordingsPlugin.after_tool_callback
  name: after_tool_callback
  file_path: google/adk/cli/plugins/recordings_plugin.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: Complete pending tool recording for the invocation specified in session state.
  signature: 'def after_tool_callback(self, *, tool: google.adk.tools.base_tool.BaseTool, tool_args: dict[str, typing.Any], tool_context: google.adk.tools.tool_context.ToolContext, result: dict) -> typing.Optional[dict]:'
- rank: 545
  id: google.adk.cli.plugins.recordings_plugin.RecordingsPlugin.before_model_callback
  name: before_model_callback
  file_path: google/adk/cli/plugins/recordings_plugin.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: 'Create pending LLM recording awaiting response.


    Uses per-invocation recording state. Assumes state was created in

    before_run; raises if missing to surface misuse.'
  signature: 'def before_model_callback(self, *, callback_context: google.adk.agents.callback_context.CallbackContext, llm_request: google.adk.models.llm_request.LlmRequest) -> typing.Optional[google.adk.models.llm_response.LlmResponse]:'
- rank: 546
  id: google.adk.cli.plugins.recordings_plugin.RecordingsPlugin.before_run_callback
  name: before_run_callback
  file_path: google/adk/cli/plugins/recordings_plugin.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: Always create fresh per-invocation recording state when enabled.
  signature: 'def before_run_callback(self, *, invocation_context: google.adk.agents.invocation_context.InvocationContext) -> typing.Optional[google.genai.types.Content]:'
- rank: 547
  id: google.adk.cli.plugins.recordings_plugin.RecordingsPlugin.before_tool_callback
  name: before_tool_callback
  file_path: google/adk/cli/plugins/recordings_plugin.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: Create pending tool recording for the invocation specified in session state.
  signature: 'def before_tool_callback(self, *, tool: google.adk.tools.base_tool.BaseTool, tool_args: dict[str, typing.Any], tool_context: google.adk.tools.tool_context.ToolContext) -> typing.Optional[dict]:'
- rank: 548
  id: google.adk.cli.plugins.recordings_plugin.RecordingsPlugin.on_tool_error_callback
  name: on_tool_error_callback
  file_path: google/adk/cli/plugins/recordings_plugin.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: 'Handle tool error callback with state guard.


    Recording schema does not yet capture errors; we only validate state.'
  signature: 'def on_tool_error_callback(self, *, tool: google.adk.tools.base_tool.BaseTool, tool_args: dict[str, typing.Any], tool_context: google.adk.tools.tool_context.ToolContext, error: Exception) -> typing.Optional[dict]:'
- rank: 549
  id: google.adk.cli.plugins.recordings_schema
  name: recordings_schema
  file_path: google/adk/cli/plugins/recordings_schema.py
  type: MODULE
  group: Orphan
  usage_score: 0
  docstring: Pydantic models for ADK recordings.
- rank: 550
  id: google.adk.cli.plugins.recordings_schema.LlmRecording
  name: LlmRecording
  file_path: google/adk/cli/plugins/recordings_schema.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Paired LLM request and response.


    [Note: Inherited members from pydantic.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, llm_request: typing.Optional[google.adk.models.llm_request.LlmRequest] = None, llm_response: typing.Optional[google.adk.models.llm_response.LlmResponse] = None):'
  properties:
  - signature: 'model_config: pydantic.ConfigDict'
  - signature: 'llm_request: typing.Optional[google.adk.models.llm_request.LlmRequest]'
    docstring: Required. The LLM request.
  - signature: 'llm_response: typing.Optional[google.adk.models.llm_response.LlmResponse]'
    docstring: Required. The LLM response.
  inherited_properties:
    BaseModel:
    - signature: 'model_config: pydantic.ConfigDict'
  omitted_inherited_members_from:
  - pydantic.BaseModel
- rank: 551
  id: google.adk.cli.plugins.recordings_schema.Recording
  name: Recording
  file_path: google/adk/cli/plugins/recordings_schema.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Single interaction recording, ordered by request timestamp.


    [Note: Inherited members from pydantic.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, user_message_index: int, agent_name: str, llm_recording: typing.Optional[google.adk.cli.plugins.recordings_schema.LlmRecording] = None, tool_recording: typing.Optional[google.adk.cli.plugins.recordings_schema.ToolRecording] = None):'
  properties:
  - signature: 'model_config: pydantic.ConfigDict'
  - signature: 'user_message_index: int'
    docstring: Index of the user message this recording belongs to (0-based).
  - signature: 'agent_name: str'
    docstring: Name of the agent.
  - signature: 'llm_recording: typing.Optional[google.adk.cli.plugins.recordings_schema.LlmRecording]'
    docstring: LLM request-response pair.
  - signature: 'tool_recording: typing.Optional[google.adk.cli.plugins.recordings_schema.ToolRecording]'
    docstring: Tool call-response pair.
  inherited_properties:
    BaseModel:
    - signature: 'model_config: pydantic.ConfigDict'
  omitted_inherited_members_from:
  - pydantic.BaseModel
- rank: 552
  id: google.adk.cli.plugins.recordings_schema.Recordings
  name: Recordings
  file_path: google/adk/cli/plugins/recordings_schema.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'All recordings in chronological order.


    [Note: Inherited members from pydantic.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, recordings: list[google.adk.cli.plugins.recordings_schema.Recording] = list()):'
  properties:
  - signature: 'model_config: pydantic.ConfigDict'
  - signature: 'recordings: list[google.adk.cli.plugins.recordings_schema.Recording]'
    docstring: Chronological list of all recordings.
  inherited_properties:
    BaseModel:
    - signature: 'model_config: pydantic.ConfigDict'
  omitted_inherited_members_from:
  - pydantic.BaseModel
- rank: 553
  id: google.adk.cli.plugins.recordings_schema.ToolRecording
  name: ToolRecording
  file_path: google/adk/cli/plugins/recordings_schema.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Paired tool call and response.


    [Note: Inherited members from pydantic.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, tool_call: typing.Optional[google.genai.types.FunctionCall] = None, tool_response: typing.Optional[google.genai.types.FunctionResponse] = None):'
  properties:
  - signature: 'model_config: pydantic.ConfigDict'
  - signature: 'tool_call: typing.Optional[google.genai.types.FunctionCall]'
    docstring: Required. The tool call.
  - signature: 'tool_response: typing.Optional[google.genai.types.FunctionResponse]'
    docstring: Required. The tool response.
  inherited_properties:
    BaseModel:
    - signature: 'model_config: pydantic.ConfigDict'
  omitted_inherited_members_from:
  - pydantic.BaseModel
- rank: 554
  id: google.adk.cli.plugins.replay_plugin
  name: replay_plugin
  file_path: google/adk/cli/plugins/replay_plugin.py
  type: MODULE
  group: Orphan
  usage_score: 0
  docstring: Replay plugin for ADK conformance testing.
- rank: 555
  id: google.adk.cli.plugins.replay_plugin.ReplayConfigError
  name: ReplayConfigError
  file_path: google/adk/cli/plugins/replay_plugin.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Exception raised when replay configuration is invalid or missing.


    [Note: Inherited members from Exception are omitted.]'
  omitted_inherited_members_from:
  - Exception
- rank: 556
  id: google.adk.cli.plugins.replay_plugin.ReplayPlugin
  name: ReplayPlugin
  file_path: google/adk/cli/plugins/replay_plugin.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Plugin for replaying ADK agent interactions from recordings.


    [Note: Inherited members from ABC are omitted.]'
  constructor_signature: 'def __init__(self, *, name: str=''adk_replay'') -> None:'
  methods:
  - signature: 'def before_run_callback(self, *, invocation_context: google.adk.agents.invocation_context.InvocationContext) -> typing.Optional[google.genai.types.Content]:'
    docstring: Load replay recordings when enabled.
  - signature: 'def before_model_callback(self, *, callback_context: google.adk.agents.callback_context.CallbackContext, llm_request: google.adk.models.llm_request.LlmRequest) -> typing.Optional[google.adk.models.llm_response.LlmResponse]:'
    docstring: Replay LLM response from recordings instead of making real call.
  - signature: 'def before_tool_callback(self, *, tool: google.adk.tools.base_tool.BaseTool, tool_args: dict[str, typing.Any], tool_context: google.adk.tools.tool_context.ToolContext) -> typing.Optional[dict]:'
    docstring: Replay tool response from recordings instead of executing tool.
  - signature: 'def after_run_callback(self, *, invocation_context: google.adk.agents.invocation_context.InvocationContext) -> None:'
    docstring: Clean up replay state after invocation completes.
  inherited_methods:
    BasePlugin:
    - signature: 'def on_user_message_callback(self, *, invocation_context: google.adk.agents.invocation_context.InvocationContext, user_message: google.genai.types.Content) -> typing.Optional[google.genai.types.Content]:'
      docstring: "Callback executed when a user message is received before an invocation starts.\n\nThis callback helps logging and modifying the user message before the\nrunner starts the invocation.\n\nArgs:\n  invocation_context: The context for the entire invocation.\n  user_message: The message content input by user.\n\nReturns:\n  An optional `types.Content` to be returned to the ADK. Returning a\n  value to replace the user message. Returning `None` to proceed\n  normally."
    - signature: 'def before_run_callback(self, *, invocation_context: google.adk.agents.invocation_context.InvocationContext) -> typing.Optional[google.genai.types.Content]:'
      docstring: "Callback executed before the ADK runner runs.\n\nThis is the first callback to be called in the lifecycle, ideal for global\nsetup or initialization tasks.\n\nArgs:\n  invocation_context: The context for the entire invocation, containing\n    session information, the root agent, etc.\n\nReturns:\n  An optional `Event` to be returned to the ADK. Returning a value to\n  halt execution of the runner and ends the runner with that event. Return\n  `None` to proceed normally."
    - signature: 'def on_event_callback(self, *, invocation_context: google.adk.agents.invocation_context.InvocationContext, event: google.adk.events.event.Event) -> typing.Optional[google.adk.events.event.Event]:'
      docstring: "Callback executed after an event is yielded from runner.\n\nThis is the ideal place to make modification to the event before the event\nis handled by the underlying agent app.\n\nArgs:\n  invocation_context: The context for the entire invocation.\n  event: The event raised by the runner.\n\nReturns:\n  An optional value. A non-`None` return may be used by the framework to\n  modify or replace the response. Returning `None` allows the original\n  response to be used."
    - signature: 'def after_run_callback(self, *, invocation_context: google.adk.agents.invocation_context.InvocationContext) -> None:'
      docstring: "Callback executed after an ADK runner run has completed.\n\nThis is the final callback in the ADK lifecycle, suitable for cleanup, final\nlogging, or reporting tasks.\n\nArgs:\n  invocation_context: The context for the entire invocation.\n\nReturns:\n  None"
    - signature: 'def close(self) -> None:'
      docstring: 'Method executed when the runner is closed.


        This method is used for cleanup tasks such as closing network connections

        or releasing resources.'
    - signature: 'def before_agent_callback(self, *, agent: google.adk.agents.base_agent.BaseAgent, callback_context: google.adk.agents.callback_context.CallbackContext) -> typing.Optional[google.genai.types.Content]:'
      docstring: "Callback executed before an agent's primary logic is invoked.\n\nThis callback can be used for logging, setup, or to short-circuit the\nagent's execution by returning a value.\n\nArgs:\n  agent: The agent that is about to run.\n  callback_context: The context for the agent invocation.\n\nReturns:\n  An optional `types.Content` object. If a value is returned, it will bypass\n  the agent's callbacks and its execution, and return this value directly.\n  Returning `None` allows the agent to proceed normally."
    - signature: 'def after_agent_callback(self, *, agent: google.adk.agents.base_agent.BaseAgent, callback_context: google.adk.agents.callback_context.CallbackContext) -> typing.Optional[google.genai.types.Content]:'
      docstring: "Callback executed after an agent's primary logic has completed.\n\nArgs:\n  agent: The agent that has just run.\n  callback_context: The context for the agent invocation.\n\nReturns:\n  An optional `types.Content` object. The content to return to the user.\n  When the content is present, the provided content will be used as agent\n  response and appended to event history as agent response."
    - signature: 'def before_model_callback(self, *, callback_context: google.adk.agents.callback_context.CallbackContext, llm_request: google.adk.models.llm_request.LlmRequest) -> typing.Optional[google.adk.models.llm_response.LlmResponse]:'
      docstring: "Callback executed before a request is sent to the model.\n\nThis provides an opportunity to inspect, log, or modify the `LlmRequest`\nobject. It can also be used to implement caching by returning a cached\n`LlmResponse`, which would skip the actual model call.\n\nArgs:\n  callback_context: The context for the current agent call.\n  llm_request: The prepared request object to be sent to the model.\n\nReturns:\n  An optional value. The interpretation of a non-`None` trigger an early\n  exit and returns the response immediately. Returning `None` allows the LLM\n  request to proceed normally."
    - signature: 'def after_model_callback(self, *, callback_context: google.adk.agents.callback_context.CallbackContext, llm_response: google.adk.models.llm_response.LlmResponse) -> typing.Optional[google.adk.models.llm_response.LlmResponse]:'
      docstring: "Callback executed after a response is received from the model.\n\nThis is the ideal place to log model responses, collect metrics on token\nusage, or perform post-processing on the raw `LlmResponse`.\n\nArgs:\n  callback_context: The context for the current agent call.\n  llm_response: The response object received from the model.\n\nReturns:\n  An optional value. A non-`None` return may be used by the framework to\n  modify or replace the response. Returning `None` allows the original\n  response to be used."
    - signature: 'def on_model_error_callback(self, *, callback_context: google.adk.agents.callback_context.CallbackContext, llm_request: google.adk.models.llm_request.LlmRequest, error: Exception) -> typing.Optional[google.adk.models.llm_response.LlmResponse]:'
      docstring: "Callback executed when a model call encounters an error.\n\nThis callback provides an opportunity to handle model errors gracefully,\npotentially providing alternative responses or recovery mechanisms.\n\nArgs:\n  callback_context: The context for the current agent call.\n  llm_request: The request that was sent to the model when the error\n    occurred.\n  error: The exception that was raised during model execution.\n\nReturns:\n  An optional LlmResponse. If an LlmResponse is returned, it will be used\n  instead of propagating the error. Returning `None` allows the original\n  error to be raised."
    - signature: 'def before_tool_callback(self, *, tool: google.adk.tools.base_tool.BaseTool, tool_args: dict[str, typing.Any], tool_context: google.adk.tools.tool_context.ToolContext) -> typing.Optional[dict]:'
      docstring: "Callback executed before a tool is called.\n\nThis callback is useful for logging tool usage, input validation, or\nmodifying the arguments before they are passed to the tool.\n\nArgs:\n  tool: The tool instance that is about to be executed.\n  tool_args: The dictionary of arguments to be used for invoking the tool.\n  tool_context: The context specific to the tool execution.\n\nReturns:\n  An optional dictionary. If a dictionary is returned, it will stop the tool\n  execution and return this response immediately. Returning `None` uses the\n  original, unmodified arguments."
    - signature: 'def after_tool_callback(self, *, tool: google.adk.tools.base_tool.BaseTool, tool_args: dict[str, typing.Any], tool_context: google.adk.tools.tool_context.ToolContext, result: dict) -> typing.Optional[dict]:'
      docstring: "Callback executed after a tool has been called.\n\nThis callback allows for inspecting, logging, or modifying the result\nreturned by a tool.\n\nArgs:\n  tool: The tool instance that has just been executed.\n  tool_args: The original arguments that were passed to the tool.\n  tool_context: The context specific to the tool execution.\n  result: The dictionary returned by the tool invocation.\n\nReturns:\n  An optional dictionary. If a dictionary is returned, it will **replace**\n  the original result from the tool. This allows for post-processing or\n  altering tool outputs. Returning `None` uses the original, unmodified\n  result."
    - signature: 'def on_tool_error_callback(self, *, tool: google.adk.tools.base_tool.BaseTool, tool_args: dict[str, typing.Any], tool_context: google.adk.tools.tool_context.ToolContext, error: Exception) -> typing.Optional[dict]:'
      docstring: "Callback executed when a tool call encounters an error.\n\nThis callback provides an opportunity to handle tool errors gracefully,\npotentially providing alternative responses or recovery mechanisms.\n\nArgs:\n  tool: The tool instance that encountered an error.\n  tool_args: The arguments that were passed to the tool.\n  tool_context: The context specific to the tool execution.\n  error: The exception that was raised during tool execution.\n\nReturns:\n  An optional dictionary. If a dictionary is returned, it will be used as\n  the tool response instead of propagating the error. Returning `None`\n  allows the original error to be raised."
  omitted_inherited_members_from:
  - ABC
- rank: 557
  id: google.adk.cli.plugins.replay_plugin.ReplayPlugin.__init__
  name: __init__
  file_path: google/adk/cli/plugins/replay_plugin.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def __init__(self, *, name: str=''adk_replay'') -> None:'
- rank: 558
  id: google.adk.cli.plugins.replay_plugin.ReplayPlugin.after_run_callback
  name: after_run_callback
  file_path: google/adk/cli/plugins/replay_plugin.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: Clean up replay state after invocation completes.
  signature: 'def after_run_callback(self, *, invocation_context: google.adk.agents.invocation_context.InvocationContext) -> None:'
- rank: 559
  id: google.adk.cli.plugins.replay_plugin.ReplayPlugin.before_model_callback
  name: before_model_callback
  file_path: google/adk/cli/plugins/replay_plugin.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: Replay LLM response from recordings instead of making real call.
  signature: 'def before_model_callback(self, *, callback_context: google.adk.agents.callback_context.CallbackContext, llm_request: google.adk.models.llm_request.LlmRequest) -> typing.Optional[google.adk.models.llm_response.LlmResponse]:'
- rank: 560
  id: google.adk.cli.plugins.replay_plugin.ReplayPlugin.before_run_callback
  name: before_run_callback
  file_path: google/adk/cli/plugins/replay_plugin.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: Load replay recordings when enabled.
  signature: 'def before_run_callback(self, *, invocation_context: google.adk.agents.invocation_context.InvocationContext) -> typing.Optional[google.genai.types.Content]:'
- rank: 561
  id: google.adk.cli.plugins.replay_plugin.ReplayPlugin.before_tool_callback
  name: before_tool_callback
  file_path: google/adk/cli/plugins/replay_plugin.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: Replay tool response from recordings instead of executing tool.
  signature: 'def before_tool_callback(self, *, tool: google.adk.tools.base_tool.BaseTool, tool_args: dict[str, typing.Any], tool_context: google.adk.tools.tool_context.ToolContext) -> typing.Optional[dict]:'
- rank: 562
  id: google.adk.cli.plugins.replay_plugin.ReplayVerificationError
  name: ReplayVerificationError
  file_path: google/adk/cli/plugins/replay_plugin.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Exception raised when replay verification fails.


    [Note: Inherited members from Exception are omitted.]'
  omitted_inherited_members_from:
  - Exception
- rank: 563
  id: google.adk.cli.service_registry
  name: service_registry
  file_path: google/adk/cli/service_registry.py
  type: MODULE
  group: Orphan
  usage_score: 0
  docstring: "ADK Service Registry.\n\nThis module manages pluggable backend services for sessions, artifacts, and memory.\nADK includes built-in support for common backends like SQLite, PostgreSQL,\nGCS, and Vertex AI Agent Engine. You can also extend ADK by registering\ncustom services.\n\nThere are two ways to register custom services:\n\n1. YAML Configuration (Recommended for simple cases)\n   If your custom service can be instantiated with `MyService(uri=\"...\", **kwargs)`,\n   you can register it without writing Python code by creating a `services.yaml`\n   or `services.yml` file in your agent directory (e.g., `my_agent/services.yaml`).\n\n   Example `services.yaml`:\n   ```yaml\n   services:\n     - scheme: mysession\n       type: session\n       class: my_package.my_module.MyCustomSessionService\n     - scheme: mymemory\n       type: memory\n       class: my_package.other_module.MyCustomMemoryService\n   ```\n\n2. Python Registration (`services.py`)\n   For more complex initialization\
    \ logic, create a `services.py` file in your\n   agent directory (e.g., `my_agent/services.py`). In this file, get the\n   registry instance and register your custom factory functions. This file can\n   be used for registration in addition to, or instead of, `services.yaml`.\n\n   Example `services.py`:\n   ```python\n   from google.adk.cli.service_registry import get_service_registry\n   from my_package.my_module import MyCustomSessionService\n\n   def my_session_factory(uri: str, **kwargs):\n       # custom logic\n       return MyCustomSessionService(...)\n\n   get_service_registry().register_session_service(\"mysession\", my_session_factory)\n   ```\n\nNote: If both `services.yaml` (or `.yml`) and `services.py` are present in the\nsame directory, services from **both** files will be loaded. YAML files are\nprocessed first, then `services.py`. If the same service scheme is defined in\nboth, the definition in `services.py` will overwrite the one from YAML."
  methods:
  - signature: 'def get_service_registry() -> google.adk.cli.service_registry.ServiceRegistry:'
    docstring: Gets the singleton ServiceRegistry instance, initializing it if needed.
  - signature: 'def load_services_module(agents_dir: str) -> None:'
    docstring: 'Load services.py or services.yaml from agents_dir for custom service registration.


      If services.yaml or services.yml is found, it will be loaded first,

      followed by services.py if it exists.


      Skip if neither services.yaml/yml nor services.py is not found.'
  - signature: 'def memory_session_factory(uri: str):'
  - signature: 'def agentengine_session_factory(uri: str):'
  - signature: 'def database_session_factory(uri: str):'
  - signature: 'def sqlite_session_factory(uri: str):'
  - signature: 'def memory_artifact_factory(uri: str):'
  - signature: 'def gcs_artifact_factory(uri: str):'
  - signature: 'def file_artifact_factory(uri: str):'
  - signature: 'def rag_memory_factory(uri: str):'
  - signature: 'def agentengine_memory_factory(uri: str):'
  - signature: 'def factory(uri: str):'
- rank: 564
  id: google.adk.cli.service_registry.ServiceFactory
  name: ServiceFactory
  file_path: google/adk/cli/service_registry.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Protocol for service factory functions.


    [Note: Inherited members from Protocol are omitted.]'
  omitted_inherited_members_from:
  - Protocol
- rank: 565
  id: google.adk.cli.service_registry.ServiceRegistry
  name: ServiceRegistry
  file_path: google/adk/cli/service_registry.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: Registry for custom service URI schemes.
  constructor_signature: 'def __init__(self):'
  methods:
  - signature: 'def register_session_service(self, scheme: str, factory: google.adk.cli.service_registry.ServiceFactory) -> None:'
    docstring: "Register a factory for a custom session service URI scheme.\n\nArgs:\n    scheme: URI scheme (e.g., 'custom')\n    factory: Callable that takes (uri, **kwargs) and returns\n      BaseSessionService"
  - signature: 'def register_artifact_service(self, scheme: str, factory: google.adk.cli.service_registry.ServiceFactory) -> None:'
    docstring: Register a factory for a custom artifact service URI scheme.
  - signature: 'def register_memory_service(self, scheme: str, factory: google.adk.cli.service_registry.ServiceFactory) -> None:'
    docstring: Register a factory for a custom memory service URI scheme.
  - signature: 'def create_session_service(self, uri: str) -> BaseSessionService | None:'
    docstring: Create session service from URI using registered factories.
  - signature: 'def create_artifact_service(self, uri: str) -> BaseArtifactService | None:'
    docstring: Create artifact service from URI using registered factories.
  - signature: 'def create_memory_service(self, uri: str) -> BaseMemoryService | None:'
    docstring: Create memory service from URI using registered factories.
- rank: 566
  id: google.adk.cli.service_registry.ServiceRegistry.__init__
  name: __init__
  file_path: google/adk/cli/service_registry.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def __init__(self):'
- rank: 567
  id: google.adk.cli.service_registry.ServiceRegistry.create_artifact_service
  name: create_artifact_service
  file_path: google/adk/cli/service_registry.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: Create artifact service from URI using registered factories.
  signature: 'def create_artifact_service(self, uri: str) -> BaseArtifactService | None:'
- rank: 568
  id: google.adk.cli.service_registry.ServiceRegistry.create_memory_service
  name: create_memory_service
  file_path: google/adk/cli/service_registry.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: Create memory service from URI using registered factories.
  signature: 'def create_memory_service(self, uri: str) -> BaseMemoryService | None:'
- rank: 569
  id: google.adk.cli.service_registry.ServiceRegistry.create_session_service
  name: create_session_service
  file_path: google/adk/cli/service_registry.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: Create session service from URI using registered factories.
  signature: 'def create_session_service(self, uri: str) -> BaseSessionService | None:'
- rank: 570
  id: google.adk.cli.service_registry.ServiceRegistry.register_artifact_service
  name: register_artifact_service
  file_path: google/adk/cli/service_registry.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: Register a factory for a custom artifact service URI scheme.
  signature: 'def register_artifact_service(self, scheme: str, factory: google.adk.cli.service_registry.ServiceFactory) -> None:'
- rank: 571
  id: google.adk.cli.service_registry.ServiceRegistry.register_memory_service
  name: register_memory_service
  file_path: google/adk/cli/service_registry.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: Register a factory for a custom memory service URI scheme.
  signature: 'def register_memory_service(self, scheme: str, factory: google.adk.cli.service_registry.ServiceFactory) -> None:'
- rank: 572
  id: google.adk.cli.service_registry.ServiceRegistry.register_session_service
  name: register_session_service
  file_path: google/adk/cli/service_registry.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Register a factory for a custom session service URI scheme.\n\nArgs:\n    scheme: URI scheme (e.g., 'custom')\n    factory: Callable that takes (uri, **kwargs) and returns\n      BaseSessionService"
  signature: 'def register_session_service(self, scheme: str, factory: google.adk.cli.service_registry.ServiceFactory) -> None:'
- rank: 573
  id: google.adk.cli.service_registry.agentengine_memory_factory
  name: agentengine_memory_factory
  file_path: google/adk/cli/service_registry.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def agentengine_memory_factory(uri: str):'
- rank: 574
  id: google.adk.cli.service_registry.agentengine_session_factory
  name: agentengine_session_factory
  file_path: google/adk/cli/service_registry.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def agentengine_session_factory(uri: str):'
- rank: 575
  id: google.adk.cli.service_registry.database_session_factory
  name: database_session_factory
  file_path: google/adk/cli/service_registry.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def database_session_factory(uri: str):'
- rank: 576
  id: google.adk.cli.service_registry.file_artifact_factory
  name: file_artifact_factory
  file_path: google/adk/cli/service_registry.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def file_artifact_factory(uri: str):'
- rank: 577
  id: google.adk.cli.service_registry.gcs_artifact_factory
  name: gcs_artifact_factory
  file_path: google/adk/cli/service_registry.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def gcs_artifact_factory(uri: str):'
- rank: 578
  id: google.adk.cli.service_registry.get_service_registry
  name: get_service_registry
  file_path: google/adk/cli/service_registry.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: Gets the singleton ServiceRegistry instance, initializing it if needed.
  signature: 'def get_service_registry() -> google.adk.cli.service_registry.ServiceRegistry:'
- rank: 579
  id: google.adk.cli.service_registry.load_services_module
  name: load_services_module
  file_path: google/adk/cli/service_registry.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: 'Load services.py or services.yaml from agents_dir for custom service registration.


    If services.yaml or services.yml is found, it will be loaded first,

    followed by services.py if it exists.


    Skip if neither services.yaml/yml nor services.py is not found.'
  signature: 'def load_services_module(agents_dir: str) -> None:'
- rank: 580
  id: google.adk.cli.service_registry.memory_artifact_factory
  name: memory_artifact_factory
  file_path: google/adk/cli/service_registry.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def memory_artifact_factory(uri: str):'
- rank: 581
  id: google.adk.cli.service_registry.memory_session_factory
  name: memory_session_factory
  file_path: google/adk/cli/service_registry.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def memory_session_factory(uri: str):'
- rank: 582
  id: google.adk.cli.service_registry.rag_memory_factory
  name: rag_memory_factory
  file_path: google/adk/cli/service_registry.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def rag_memory_factory(uri: str):'
- rank: 583
  id: google.adk.cli.service_registry.sqlite_session_factory
  name: sqlite_session_factory
  file_path: google/adk/cli/service_registry.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def sqlite_session_factory(uri: str):'
- rank: 584
  id: google.adk.cli.utils
  name: utils
  file_path: google/adk/cli/utils/__init__.py
  type: MODULE
  group: Orphan
  usage_score: 0
- rank: 585
  id: google.adk.cli.utils.agent_change_handler
  name: agent_change_handler
  file_path: google/adk/cli/utils/agent_change_handler.py
  type: MODULE
  group: Orphan
  usage_score: 0
  docstring: File system event handler for agent changes to trigger hot reload for agents.
- rank: 586
  id: google.adk.cli.utils.agent_change_handler.AgentChangeEventHandler
  name: AgentChangeEventHandler
  file_path: google/adk/cli/utils/agent_change_handler.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: '[Note: Inherited members from FileSystemEventHandler are omitted.]'
  constructor_signature: 'def __init__(self, agent_loader: google.adk.cli.utils.agent_loader.AgentLoader, runners_to_clean: set[str], current_app_name_ref: google.adk.cli.utils.shared_value.SharedValue[str]):'
  methods:
  - signature: 'def on_modified(self, event):'
  omitted_inherited_members_from:
  - FileSystemEventHandler
- rank: 587
  id: google.adk.cli.utils.agent_change_handler.AgentChangeEventHandler.__init__
  name: __init__
  file_path: google/adk/cli/utils/agent_change_handler.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def __init__(self, agent_loader: google.adk.cli.utils.agent_loader.AgentLoader, runners_to_clean: set[str], current_app_name_ref: google.adk.cli.utils.shared_value.SharedValue[str]):'
- rank: 588
  id: google.adk.cli.utils.agent_change_handler.AgentChangeEventHandler.on_modified
  name: on_modified
  file_path: google/adk/cli/utils/agent_change_handler.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def on_modified(self, event):'
- rank: 589
  id: google.adk.cli.utils.agent_loader
  name: agent_loader
  file_path: google/adk/cli/utils/agent_loader.py
  type: MODULE
  group: Orphan
  usage_score: 0
- rank: 590
  id: google.adk.cli.utils.agent_loader.AgentLoader
  name: AgentLoader
  file_path: google/adk/cli/utils/agent_loader.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: "Centralized agent loading with proper isolation, caching, and .env loading.\nSupport loading agents from below folder/file structures:\na)  {agent_name}.agent as a module name:\n    agents_dir/{agent_name}/agent.py (with root_agent defined in the module)\nb)  {agent_name} as a module name\n    agents_dir/{agent_name}.py (with root_agent defined in the module)\nc)  {agent_name} as a package name\n    agents_dir/{agent_name}/__init__.py (with root_agent in the package)\nd)  {agent_name} as a YAML config folder:\n    agents_dir/{agent_name}/root_agent.yaml defines the root agent\n\n[Note: Inherited members from ABC are omitted.]"
  constructor_signature: 'def __init__(self, agents_dir: str):'
  methods:
  - signature: 'def load_agent(self, agent_name: str) -> typing.Union[google.adk.agents.base_agent.BaseAgent, google.adk.apps.app.App]:'
    docstring: Load an agent module (with caching & .env) and return its root_agent.
  - signature: 'def list_agents(self) -> list[str]:'
    docstring: Lists all agents available in the agent loader (sorted alphabetically).
  - signature: 'def list_agents_detailed(self) -> list[dict[str, typing.Any]]:'
    docstring: Lists all agents with detailed metadata (name, description, type).
  - signature: 'def remove_agent_from_cache(self, agent_name: str):'
  inherited_methods:
    BaseAgentLoader:
    - signature: 'def load_agent(self, agent_name: str) -> typing.Union[google.adk.agents.base_agent.BaseAgent, google.adk.apps.app.App]:'
      docstring: Loads an instance of an agent with the given name.
    - signature: 'def list_agents(self) -> list[str]:'
      docstring: Lists all agents available in the agent loader in alphabetical order.
    - signature: 'def list_agents_detailed(self) -> list[dict[str, typing.Any]]:'
  omitted_inherited_members_from:
  - ABC
- rank: 591
  id: google.adk.cli.utils.agent_loader.AgentLoader.__init__
  name: __init__
  file_path: google/adk/cli/utils/agent_loader.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def __init__(self, agents_dir: str):'
- rank: 592
  id: google.adk.cli.utils.agent_loader.AgentLoader.list_agents
  name: list_agents
  file_path: google/adk/cli/utils/agent_loader.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: Lists all agents available in the agent loader (sorted alphabetically).
  signature: 'def list_agents(self) -> list[str]:'
- rank: 593
  id: google.adk.cli.utils.agent_loader.AgentLoader.list_agents_detailed
  name: list_agents_detailed
  file_path: google/adk/cli/utils/agent_loader.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: Lists all agents with detailed metadata (name, description, type).
  signature: 'def list_agents_detailed(self) -> list[dict[str, typing.Any]]:'
- rank: 594
  id: google.adk.cli.utils.agent_loader.AgentLoader.load_agent
  name: load_agent
  file_path: google/adk/cli/utils/agent_loader.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: Load an agent module (with caching & .env) and return its root_agent.
  signature: 'def load_agent(self, agent_name: str) -> typing.Union[google.adk.agents.base_agent.BaseAgent, google.adk.apps.app.App]:'
- rank: 595
  id: google.adk.cli.utils.agent_loader.AgentLoader.remove_agent_from_cache
  name: remove_agent_from_cache
  file_path: google/adk/cli/utils/agent_loader.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def remove_agent_from_cache(self, agent_name: str):'
- rank: 596
  id: google.adk.cli.utils.base_agent_loader
  name: base_agent_loader
  file_path: google/adk/cli/utils/base_agent_loader.py
  type: MODULE
  group: Orphan
  usage_score: 0
  docstring: Base class for agent loaders.
- rank: 597
  id: google.adk.cli.utils.base_agent_loader.BaseAgentLoader
  name: BaseAgentLoader
  file_path: google/adk/cli/utils/base_agent_loader.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Abstract base class for agent loaders.


    [Note: Inherited members from ABC are omitted.]'
  methods:
  - signature: 'def load_agent(self, agent_name: str) -> typing.Union[google.adk.agents.base_agent.BaseAgent, google.adk.apps.app.App]:'
    docstring: Loads an instance of an agent with the given name.
  - signature: 'def list_agents(self) -> list[str]:'
    docstring: Lists all agents available in the agent loader in alphabetical order.
  - signature: 'def list_agents_detailed(self) -> list[dict[str, typing.Any]]:'
  omitted_inherited_members_from:
  - ABC
- rank: 598
  id: google.adk.cli.utils.base_agent_loader.BaseAgentLoader.list_agents_detailed
  name: list_agents_detailed
  file_path: google/adk/cli/utils/base_agent_loader.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def list_agents_detailed(self) -> list[dict[str, typing.Any]]:'
- rank: 599
  id: google.adk.cli.utils.cleanup
  name: cleanup
  file_path: google/adk/cli/utils/cleanup.py
  type: MODULE
  group: Orphan
  usage_score: 0
  methods:
  - signature: 'def close_runners(runners: typing.List[google.adk.runners.Runner]) -> None:'
- rank: 600
  id: google.adk.cli.utils.cleanup.close_runners
  name: close_runners
  file_path: google/adk/cli/utils/cleanup.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def close_runners(runners: typing.List[google.adk.runners.Runner]) -> None:'
- rank: 601
  id: google.adk.cli.utils.common
  name: common
  file_path: google/adk/cli/utils/common.py
  type: MODULE
  group: Orphan
  usage_score: 0
- rank: 602
  id: google.adk.cli.utils.common.BaseModel
  name: BaseModel
  file_path: google/adk/cli/utils/common.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: '[Note: Inherited members from pydantic.BaseModel are omitted.]'
  properties:
  - signature: 'model_config: pydantic.ConfigDict'
  omitted_inherited_members_from:
  - pydantic.BaseModel
- rank: 603
  id: google.adk.cli.utils.dot_adk_folder
  name: dot_adk_folder
  file_path: google/adk/cli/utils/dot_adk_folder.py
  type: MODULE
  group: Orphan
  usage_score: 0
  docstring: Helpers for managing an agent's `.adk` folder.
  methods:
  - signature: 'def dot_adk_folder_for_agent(*, agents_root: Path | str, app_name: str) -> google.adk.cli.utils.dot_adk_folder.DotAdkFolder:'
    docstring: "Creates a manager for an agent rooted under `agents_root`.\n\nArgs:\n  agents_root: Directory that contains all agents.\n  app_name: Name of the agent directory.\n\nReturns:\n  A `DotAdkFolder` scoped to the given agent.\n\nRaises:\n  ValueError: If `app_name` traverses outside of `agents_root`."
- rank: 604
  id: google.adk.cli.utils.dot_adk_folder.DotAdkFolder
  name: DotAdkFolder
  file_path: google/adk/cli/utils/dot_adk_folder.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: Manages the lifecycle of the `.adk` folder for a single agent.
  constructor_signature: 'def __init__(self, agent_dir: Path | str):'
  methods:
  - signature: 'def agent_dir(self) -> pathlib.Path:'
  - signature: 'def dot_adk_dir(self) -> pathlib.Path:'
  - signature: 'def artifacts_dir(self) -> pathlib.Path:'
  - signature: 'def session_db_path(self) -> pathlib.Path:'
- rank: 605
  id: google.adk.cli.utils.dot_adk_folder.dot_adk_folder_for_agent
  name: dot_adk_folder_for_agent
  file_path: google/adk/cli/utils/dot_adk_folder.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Creates a manager for an agent rooted under `agents_root`.\n\nArgs:\n  agents_root: Directory that contains all agents.\n  app_name: Name of the agent directory.\n\nReturns:\n  A `DotAdkFolder` scoped to the given agent.\n\nRaises:\n  ValueError: If `app_name` traverses outside of `agents_root`."
  signature: 'def dot_adk_folder_for_agent(*, agents_root: Path | str, app_name: str) -> google.adk.cli.utils.dot_adk_folder.DotAdkFolder:'
- rank: 606
  id: google.adk.cli.utils.envs
  name: envs
  file_path: google/adk/cli/utils/envs.py
  type: MODULE
  group: Orphan
  usage_score: 0
  methods:
  - signature: 'def load_dotenv_for_agent(agent_name: str, agent_parent_folder: str, filename: str):'
    docstring: Loads the .env file for the agent module.
- rank: 607
  id: google.adk.cli.utils.envs.load_dotenv_for_agent
  name: load_dotenv_for_agent
  file_path: google/adk/cli/utils/envs.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: Loads the .env file for the agent module.
  signature: 'def load_dotenv_for_agent(agent_name: str, agent_parent_folder: str, filename: str):'
- rank: 608
  id: google.adk.cli.utils.evals
  name: evals
  file_path: google/adk/cli/utils/evals.py
  type: MODULE
  group: Orphan
  usage_score: 0
  methods:
  - signature: 'def convert_session_to_eval_invocations(session: google.adk.sessions.session.Session) -> list[google.adk.evaluation.eval_case.Invocation]:'
    docstring: "Converts a session data into a list of Invocation.\n\nArgs:\n    session: The session that should be converted.\n\nReturns:\n    list: A list of invocation."
  - signature: 'def create_gcs_eval_managers_from_uri(eval_storage_uri: str) -> google.adk.cli.utils.evals.GcsEvalManagers:'
    docstring: "Creates GcsEvalManagers from eval_storage_uri.\n\nArgs:\n    eval_storage_uri: The evals storage URI to use. Supported URIs:\n      gs://<bucket name>. If a path is provided, the bucket will be extracted.\n\nReturns:\n    GcsEvalManagers: The GcsEvalManagers object.\n\nRaises:\n    ValueError: If the eval_storage_uri is not supported."
- rank: 609
  id: google.adk.cli.utils.evals.GcsEvalManagers
  name: GcsEvalManagers
  file_path: google/adk/cli/utils/evals.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: '[Note: Inherited members from pydantic.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, eval_sets_manager: google.adk.evaluation.gcs_eval_sets_manager.GcsEvalSetsManager, eval_set_results_manager: google.adk.evaluation.gcs_eval_set_results_manager.GcsEvalSetResultsManager):'
  properties:
  - signature: 'model_config: pydantic.ConfigDict'
  - signature: 'eval_sets_manager: google.adk.evaluation.gcs_eval_sets_manager.GcsEvalSetsManager'
  - signature: 'eval_set_results_manager: google.adk.evaluation.gcs_eval_set_results_manager.GcsEvalSetResultsManager'
  inherited_properties:
    BaseModel:
    - signature: 'model_config: pydantic.ConfigDict'
  omitted_inherited_members_from:
  - pydantic.BaseModel
- rank: 610
  id: google.adk.cli.utils.evals.convert_session_to_eval_invocations
  name: convert_session_to_eval_invocations
  file_path: google/adk/cli/utils/evals.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Converts a session data into a list of Invocation.\n\nArgs:\n    session: The session that should be converted.\n\nReturns:\n    list: A list of invocation."
  signature: 'def convert_session_to_eval_invocations(session: google.adk.sessions.session.Session) -> list[google.adk.evaluation.eval_case.Invocation]:'
- rank: 611
  id: google.adk.cli.utils.evals.create_gcs_eval_managers_from_uri
  name: create_gcs_eval_managers_from_uri
  file_path: google/adk/cli/utils/evals.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Creates GcsEvalManagers from eval_storage_uri.\n\nArgs:\n    eval_storage_uri: The evals storage URI to use. Supported URIs:\n      gs://<bucket name>. If a path is provided, the bucket will be extracted.\n\nReturns:\n    GcsEvalManagers: The GcsEvalManagers object.\n\nRaises:\n    ValueError: If the eval_storage_uri is not supported."
  signature: 'def create_gcs_eval_managers_from_uri(eval_storage_uri: str) -> google.adk.cli.utils.evals.GcsEvalManagers:'
- rank: 612
  id: google.adk.cli.utils.local_storage
  name: local_storage
  file_path: google/adk/cli/utils/local_storage.py
  type: MODULE
  group: Orphan
  usage_score: 0
  docstring: Utilities for local .adk folder persistence.
  methods:
  - signature: 'def create_local_database_session_service(*, base_dir: Path | str) -> google.adk.sessions.base_session_service.BaseSessionService:'
    docstring: "Creates a SQLite-backed session service at .adk/session.db.\n\nArgs:\n  base_dir: The base directory for the agent (parent of .adk folder).\n\nReturns:\n  A SqliteSessionService instance."
  - signature: 'def create_local_session_service(*, base_dir: Path | str, per_agent: bool=False) -> google.adk.sessions.base_session_service.BaseSessionService:'
    docstring: "Creates a local SQLite-backed session service.\n\nArgs:\n  base_dir: The base directory for the agent(s).\n  per_agent: If True, creates a PerAgentDatabaseSessionService that stores\n    sessions in each agent's .adk folder. If False, creates a single\n    SqliteSessionService at base_dir/.adk/session.db.\n\nReturns:\n  A BaseSessionService instance backed by SQLite."
  - signature: 'def create_local_artifact_service(*, base_dir: Path | str) -> google.adk.artifacts.base_artifact_service.BaseArtifactService:'
    docstring: "Creates a file-backed artifact service rooted in `.adk/artifacts`.\n\nArgs:\n  base_dir: Directory whose `.adk` folder will store artifacts.\n\nReturns:\n  A `FileArtifactService` scoped to the derived root directory."
- rank: 613
  id: google.adk.cli.utils.local_storage.PerAgentDatabaseSessionService
  name: PerAgentDatabaseSessionService
  file_path: google/adk/cli/utils/local_storage.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Routes session storage to per-agent `.adk/session.db` files.


    [Note: Inherited members from abc.ABC are omitted.]'
  constructor_signature: 'def __init__(self, *, agents_root: Path | str):'
  methods:
  - signature: 'def create_session(self, *, app_name: str, user_id: str, state: typing.Optional[dict[str, object]]=None, session_id: typing.Optional[str]=None) -> google.adk.sessions.session.Session:'
  - signature: 'def get_session(self, *, app_name: str, user_id: str, session_id: str, config: typing.Optional[google.adk.sessions.base_session_service.GetSessionConfig]=None) -> typing.Optional[google.adk.sessions.session.Session]:'
  - signature: 'def list_sessions(self, *, app_name: str, user_id: typing.Optional[str]=None) -> google.adk.sessions.base_session_service.ListSessionsResponse:'
  - signature: 'def delete_session(self, *, app_name: str, user_id: str, session_id: str) -> None:'
  - signature: 'def append_event(self, session: google.adk.sessions.session.Session, event: google.adk.events.event.Event) -> google.adk.events.event.Event:'
  inherited_methods:
    BaseSessionService:
    - signature: 'def create_session(self, *, app_name: str, user_id: str, state: typing.Optional[dict[str, typing.Any]]=None, session_id: typing.Optional[str]=None) -> google.adk.sessions.session.Session:'
      docstring: "Creates a new session.\n\nArgs:\n  app_name: the name of the app.\n  user_id: the id of the user.\n  state: the initial state of the session.\n  session_id: the client-provided id of the session. If not provided, a\n    generated ID will be used.\n\nReturns:\n  session: The newly created session instance."
    - signature: 'def get_session(self, *, app_name: str, user_id: str, session_id: str, config: typing.Optional[google.adk.sessions.base_session_service.GetSessionConfig]=None) -> typing.Optional[google.adk.sessions.session.Session]:'
      docstring: Gets a session.
    - signature: 'def list_sessions(self, *, app_name: str, user_id: typing.Optional[str]=None) -> google.adk.sessions.base_session_service.ListSessionsResponse:'
      docstring: "Lists all the sessions for a user.\n\nArgs:\n  app_name: The name of the app.\n  user_id: The ID of the user. If not provided, lists all sessions for all\n    users.\n\nReturns:\n  A ListSessionsResponse containing the sessions."
    - signature: 'def delete_session(self, *, app_name: str, user_id: str, session_id: str) -> None:'
      docstring: Deletes a session.
    - signature: 'def append_event(self, session: google.adk.sessions.session.Session, event: google.adk.events.event.Event) -> google.adk.events.event.Event:'
      docstring: Appends an event to a session object.
  omitted_inherited_members_from:
  - abc.ABC
- rank: 614
  id: google.adk.cli.utils.local_storage.PerAgentDatabaseSessionService.__init__
  name: __init__
  file_path: google/adk/cli/utils/local_storage.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def __init__(self, *, agents_root: Path | str):'
- rank: 615
  id: google.adk.cli.utils.local_storage.PerAgentDatabaseSessionService.create_session
  name: create_session
  file_path: google/adk/cli/utils/local_storage.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def create_session(self, *, app_name: str, user_id: str, state: typing.Optional[dict[str, object]]=None, session_id: typing.Optional[str]=None) -> google.adk.sessions.session.Session:'
- rank: 616
  id: google.adk.cli.utils.local_storage.PerAgentDatabaseSessionService.delete_session
  name: delete_session
  file_path: google/adk/cli/utils/local_storage.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def delete_session(self, *, app_name: str, user_id: str, session_id: str) -> None:'
- rank: 617
  id: google.adk.cli.utils.local_storage.PerAgentDatabaseSessionService.get_session
  name: get_session
  file_path: google/adk/cli/utils/local_storage.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def get_session(self, *, app_name: str, user_id: str, session_id: str, config: typing.Optional[google.adk.sessions.base_session_service.GetSessionConfig]=None) -> typing.Optional[google.adk.sessions.session.Session]:'
- rank: 618
  id: google.adk.cli.utils.local_storage.PerAgentDatabaseSessionService.list_sessions
  name: list_sessions
  file_path: google/adk/cli/utils/local_storage.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def list_sessions(self, *, app_name: str, user_id: typing.Optional[str]=None) -> google.adk.sessions.base_session_service.ListSessionsResponse:'
- rank: 619
  id: google.adk.cli.utils.local_storage.create_local_artifact_service
  name: create_local_artifact_service
  file_path: google/adk/cli/utils/local_storage.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Creates a file-backed artifact service rooted in `.adk/artifacts`.\n\nArgs:\n  base_dir: Directory whose `.adk` folder will store artifacts.\n\nReturns:\n  A `FileArtifactService` scoped to the derived root directory."
  signature: 'def create_local_artifact_service(*, base_dir: Path | str) -> google.adk.artifacts.base_artifact_service.BaseArtifactService:'
- rank: 620
  id: google.adk.cli.utils.local_storage.create_local_database_session_service
  name: create_local_database_session_service
  file_path: google/adk/cli/utils/local_storage.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Creates a SQLite-backed session service at .adk/session.db.\n\nArgs:\n  base_dir: The base directory for the agent (parent of .adk folder).\n\nReturns:\n  A SqliteSessionService instance."
  signature: 'def create_local_database_session_service(*, base_dir: Path | str) -> google.adk.sessions.base_session_service.BaseSessionService:'
- rank: 621
  id: google.adk.cli.utils.local_storage.create_local_session_service
  name: create_local_session_service
  file_path: google/adk/cli/utils/local_storage.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Creates a local SQLite-backed session service.\n\nArgs:\n  base_dir: The base directory for the agent(s).\n  per_agent: If True, creates a PerAgentDatabaseSessionService that stores\n    sessions in each agent's .adk folder. If False, creates a single\n    SqliteSessionService at base_dir/.adk/session.db.\n\nReturns:\n  A BaseSessionService instance backed by SQLite."
  signature: 'def create_local_session_service(*, base_dir: Path | str, per_agent: bool=False) -> google.adk.sessions.base_session_service.BaseSessionService:'
- rank: 622
  id: google.adk.cli.utils.logs
  name: logs
  file_path: google/adk/cli/utils/logs.py
  type: MODULE
  group: Orphan
  usage_score: 0
  methods:
  - signature: 'def setup_adk_logger(level):'
  - signature: 'def log_to_tmp_folder(level, *, sub_folder: str=''agents_log'', log_file_prefix: str=''agent'', log_file_timestamp: str=time.strftime(''%Y%m%d_%H%M%S'')):'
    docstring: "Logs to system temp folder, instead of logging to stderr.\n\nArgs\n  sub_folder: str = 'agents_log',\n  log_file_prefix: str = 'agent',\n  log_file_timestamp: str = time.strftime('%Y%m%d_%H%M%S'),\n\nReturns\n  the log file path."
- rank: 623
  id: google.adk.cli.utils.service_factory
  name: service_factory
  file_path: google/adk/cli/utils/service_factory.py
  type: MODULE
  group: Orphan
  usage_score: 0
  methods:
  - signature: 'def create_session_service_from_options(*, base_dir: Path | str, session_service_uri: typing.Optional[str]=None, session_db_kwargs: typing.Optional[dict[str, typing.Any]]=None) -> google.adk.sessions.base_session_service.BaseSessionService:'
    docstring: Creates a session service based on CLI/web options.
  - signature: 'def create_memory_service_from_options(*, base_dir: Path | str, memory_service_uri: typing.Optional[str]=None) -> google.adk.memory.base_memory_service.BaseMemoryService:'
    docstring: Creates a memory service based on CLI/web options.
  - signature: 'def create_artifact_service_from_options(*, base_dir: Path | str, artifact_service_uri: typing.Optional[str]=None) -> google.adk.artifacts.base_artifact_service.BaseArtifactService:'
    docstring: Creates an artifact service based on CLI/web options.
- rank: 624
  id: google.adk.cli.utils.service_factory.create_artifact_service_from_options
  name: create_artifact_service_from_options
  file_path: google/adk/cli/utils/service_factory.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: Creates an artifact service based on CLI/web options.
  signature: 'def create_artifact_service_from_options(*, base_dir: Path | str, artifact_service_uri: typing.Optional[str]=None) -> google.adk.artifacts.base_artifact_service.BaseArtifactService:'
- rank: 625
  id: google.adk.cli.utils.service_factory.create_memory_service_from_options
  name: create_memory_service_from_options
  file_path: google/adk/cli/utils/service_factory.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: Creates a memory service based on CLI/web options.
  signature: 'def create_memory_service_from_options(*, base_dir: Path | str, memory_service_uri: typing.Optional[str]=None) -> google.adk.memory.base_memory_service.BaseMemoryService:'
- rank: 626
  id: google.adk.cli.utils.service_factory.create_session_service_from_options
  name: create_session_service_from_options
  file_path: google/adk/cli/utils/service_factory.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: Creates a session service based on CLI/web options.
  signature: 'def create_session_service_from_options(*, base_dir: Path | str, session_service_uri: typing.Optional[str]=None, session_db_kwargs: typing.Optional[dict[str, typing.Any]]=None) -> google.adk.sessions.base_session_service.BaseSessionService:'
- rank: 627
  id: google.adk.cli.utils.shared_value
  name: shared_value
  file_path: google/adk/cli/utils/shared_value.py
  type: MODULE
  group: Orphan
  usage_score: 0
- rank: 628
  id: google.adk.cli.utils.shared_value.SharedValue
  name: SharedValue
  file_path: google/adk/cli/utils/shared_value.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Simple wrapper around a value to allow modifying it from callbacks.


    [Note: Inherited members from pydantic.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, value: google.adk.cli.utils.shared_value.T):'
  properties:
  - signature: 'model_config: pydantic.ConfigDict'
  - signature: 'value: google.adk.cli.utils.shared_value.T'
  omitted_inherited_members_from:
  - pydantic.BaseModel
- rank: 629
  id: google.adk.cli.utils.state
  name: state
  file_path: google/adk/cli/utils/state.py
  type: MODULE
  group: Orphan
  usage_score: 0
  methods:
  - signature: 'def create_empty_state(agent: google.adk.agents.base_agent.BaseAgent, initialized_states: typing.Optional[dict[str, typing.Any]]) -> dict[str, typing.Any]:'
    docstring: Creates empty str for non-initialized states.
- rank: 630
  id: google.adk.cli.utils.state.create_empty_state
  name: create_empty_state
  file_path: google/adk/cli/utils/state.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: Creates empty str for non-initialized states.
  signature: 'def create_empty_state(agent: google.adk.agents.base_agent.BaseAgent, initialized_states: typing.Optional[dict[str, typing.Any]]) -> dict[str, typing.Any]:'
- rank: 631
  id: google.adk.code_executors
  name: code_executors
  file_path: google/adk/code_executors/__init__.py
  type: MODULE
  group: Orphan
  usage_score: 0
- rank: 632
  id: google.adk.code_executors.agent_engine_sandbox_code_executor
  name: agent_engine_sandbox_code_executor
  file_path: google/adk/code_executors/agent_engine_sandbox_code_executor.py
  type: MODULE
  group: Orphan
  usage_score: 0
- rank: 633
  id: google.adk.code_executors.agent_engine_sandbox_code_executor.AgentEngineSandboxCodeExecutor
  name: AgentEngineSandboxCodeExecutor
  file_path: google/adk/code_executors/agent_engine_sandbox_code_executor.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: "A code executor that uses Agent Engine Code Execution Sandbox to execute code.\n\nAttributes:\n  sandbox_resource_name: If set, load the existing resource name of the code\n    interpreter extension instead of creating a new one. Format:\n    projects/123/locations/us-central1/reasoningEngines/456/sandboxEnvironments/789\n\n[Note: Inherited members from pydantic.BaseModel are omitted.]"
  constructor_signature: 'def __init__(self, sandbox_resource_name: typing.Optional[str], agent_engine_resource_name: typing.Optional[str]):'
  methods:
  - signature: 'def execute_code(self, invocation_context: google.adk.agents.invocation_context.InvocationContext, code_execution_input: google.adk.code_executors.code_execution_utils.CodeExecutionInput) -> google.adk.code_executors.code_execution_utils.CodeExecutionResult:'
  properties:
  - signature: 'sandbox_resource_name: str'
  inherited_methods:
    BaseCodeExecutor:
    - signature: 'def execute_code(self, invocation_context: google.adk.agents.invocation_context.InvocationContext, code_execution_input: google.adk.code_executors.code_execution_utils.CodeExecutionInput) -> google.adk.code_executors.code_execution_utils.CodeExecutionResult:'
      docstring: "Executes code and return the code execution result.\n\nArgs:\n  invocation_context: The invocation context of the code execution.\n  code_execution_input: The code execution input.\n\nReturns:\n  The code execution result."
  inherited_properties:
    BaseCodeExecutor:
    - signature: 'optimize_data_file: bool'
      docstring: 'If true, extract and process data files from the model request

        and attach them to the code executor.


        Supported data file MimeTypes are [text/csv].

        Default to False.'
    - signature: 'stateful: bool'
      docstring: Whether the code executor is stateful. Default to False.
    - signature: 'error_retry_attempts: int'
      docstring: The number of attempts to retry on consecutive code execution errors. Default to 2.
    - signature: 'code_block_delimiters: typing.List[tuple[str, str]]'
      docstring: "The list of the enclosing delimiters to identify the code blocks.\n\nFor example, the delimiter ('```python\\n', '\\n```') can be\nused to identify code blocks with the following format::\n\n    ```python\n    print(\"hello\")\n    ```"
    - signature: 'execution_result_delimiters: tuple[str, str]'
      docstring: The delimiters to format the code execution result.
    BaseModel:
    - signature: 'model_config: pydantic.ConfigDict'
  omitted_inherited_members_from:
  - pydantic.BaseModel
- rank: 634
  id: google.adk.code_executors.agent_engine_sandbox_code_executor.AgentEngineSandboxCodeExecutor.__init__
  name: __init__
  file_path: google/adk/code_executors/agent_engine_sandbox_code_executor.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Initializes the AgentEngineSandboxCodeExecutor.\n\nArgs:\n  sandbox_resource_name: If set, load the existing resource name of code\n    execution sandbox, if not set, create a new one. Format:\n    projects/123/locations/us-central1/reasoningEngines/456/\n    sandboxEnvironments/789\n  agent_engine_resource_name: The resource name of the agent engine to use\n    to create the code execution sandbox. Format:\n    projects/123/locations/us-central1/reasoningEngines/456, when both\n    sandbox_resource_name and agent_engine_resource_name are set,\n    agent_engine_resource_name will be ignored.\n  **data: Additional keyword arguments to be passed to the base class."
  signature: 'def __init__(self, sandbox_resource_name: typing.Optional[str], agent_engine_resource_name: typing.Optional[str]):'
- rank: 635
  id: google.adk.code_executors.agent_engine_sandbox_code_executor.AgentEngineSandboxCodeExecutor.execute_code
  name: execute_code
  file_path: google/adk/code_executors/agent_engine_sandbox_code_executor.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def execute_code(self, invocation_context: google.adk.agents.invocation_context.InvocationContext, code_execution_input: google.adk.code_executors.code_execution_utils.CodeExecutionInput) -> google.adk.code_executors.code_execution_utils.CodeExecutionResult:'
- rank: 636
  id: google.adk.code_executors.base_code_executor
  name: base_code_executor
  file_path: google/adk/code_executors/base_code_executor.py
  type: MODULE
  group: Orphan
  usage_score: 0
- rank: 637
  id: google.adk.code_executors.base_code_executor.BaseCodeExecutor
  name: BaseCodeExecutor
  file_path: google/adk/code_executors/base_code_executor.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: "Abstract base class for all code executors.\n\nThe code executor allows the agent to execute code blocks from model responses\nand incorporate the execution results into the final response.\n\nAttributes:\n  optimize_data_file: If true, extract and process data files from the model\n    request and attach them to the code executor. Supported data file\n    MimeTypes are [text/csv]. Default to False.\n  stateful: Whether the code executor is stateful. Default to False.\n  error_retry_attempts: The number of attempts to retry on consecutive code\n    execution errors. Default to 2.\n  code_block_delimiters: The list of the enclosing delimiters to identify the\n    code blocks.\n  execution_result_delimiters: The delimiters to format the code execution\n    result.\n\n[Note: Inherited members from pydantic.BaseModel are omitted.]"
  constructor_signature: 'def __init__(self, *, optimize_data_file: bool = False, stateful: bool = False, error_retry_attempts: int = 2, code_block_delimiters: typing.List[tuple[str, str]] = [(''```tool_code\n'', ''\n```''), (''```python\n'', ''\n```'')], execution_result_delimiters: tuple[str, str] = (''```tool_output\n'', ''\n```'')):'
  methods:
  - signature: 'def execute_code(self, invocation_context: google.adk.agents.invocation_context.InvocationContext, code_execution_input: google.adk.code_executors.code_execution_utils.CodeExecutionInput) -> google.adk.code_executors.code_execution_utils.CodeExecutionResult:'
    docstring: "Executes code and return the code execution result.\n\nArgs:\n  invocation_context: The invocation context of the code execution.\n  code_execution_input: The code execution input.\n\nReturns:\n  The code execution result."
  properties:
  - signature: 'optimize_data_file: bool'
    docstring: 'If true, extract and process data files from the model request

      and attach them to the code executor.


      Supported data file MimeTypes are [text/csv].

      Default to False.'
  - signature: 'stateful: bool'
    docstring: Whether the code executor is stateful. Default to False.
  - signature: 'error_retry_attempts: int'
    docstring: The number of attempts to retry on consecutive code execution errors. Default to 2.
  - signature: 'code_block_delimiters: typing.List[tuple[str, str]]'
    docstring: "The list of the enclosing delimiters to identify the code blocks.\n\nFor example, the delimiter ('```python\\n', '\\n```') can be\nused to identify code blocks with the following format::\n\n    ```python\n    print(\"hello\")\n    ```"
  - signature: 'execution_result_delimiters: tuple[str, str]'
    docstring: The delimiters to format the code execution result.
  inherited_properties:
    BaseModel:
    - signature: 'model_config: pydantic.ConfigDict'
  omitted_inherited_members_from:
  - pydantic.BaseModel
- rank: 638
  id: google.adk.code_executors.base_code_executor.BaseCodeExecutor.execute_code
  name: execute_code
  file_path: google/adk/code_executors/base_code_executor.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Executes code and return the code execution result.\n\nArgs:\n  invocation_context: The invocation context of the code execution.\n  code_execution_input: The code execution input.\n\nReturns:\n  The code execution result."
  signature: 'def execute_code(self, invocation_context: google.adk.agents.invocation_context.InvocationContext, code_execution_input: google.adk.code_executors.code_execution_utils.CodeExecutionInput) -> google.adk.code_executors.code_execution_utils.CodeExecutionResult:'
- rank: 639
  id: google.adk.code_executors.built_in_code_executor
  name: built_in_code_executor
  file_path: google/adk/code_executors/built_in_code_executor.py
  type: MODULE
  group: Orphan
  usage_score: 0
- rank: 640
  id: google.adk.code_executors.built_in_code_executor.BuiltInCodeExecutor
  name: BuiltInCodeExecutor
  file_path: google/adk/code_executors/built_in_code_executor.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'A code executor that uses the Model''s built-in code executor.


    Currently only supports Gemini 2.0+ models, but will be expanded to

    other models.


    [Note: Inherited members from pydantic.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, optimize_data_file: bool = False, stateful: bool = False, error_retry_attempts: int = 2, code_block_delimiters: typing.List[tuple[str, str]] = [(''```tool_code\n'', ''\n```''), (''```python\n'', ''\n```'')], execution_result_delimiters: tuple[str, str] = (''```tool_output\n'', ''\n```'')):'
  methods:
  - signature: 'def execute_code(self, invocation_context: google.adk.agents.invocation_context.InvocationContext, code_execution_input: google.adk.code_executors.code_execution_utils.CodeExecutionInput) -> google.adk.code_executors.code_execution_utils.CodeExecutionResult:'
  - signature: 'def process_llm_request(self, llm_request: google.adk.models.LlmRequest) -> None:'
    docstring: Pre-process the LLM request for Gemini 2.0+ models to use the code execution tool.
  inherited_methods:
    BaseCodeExecutor:
    - signature: 'def execute_code(self, invocation_context: google.adk.agents.invocation_context.InvocationContext, code_execution_input: google.adk.code_executors.code_execution_utils.CodeExecutionInput) -> google.adk.code_executors.code_execution_utils.CodeExecutionResult:'
      docstring: "Executes code and return the code execution result.\n\nArgs:\n  invocation_context: The invocation context of the code execution.\n  code_execution_input: The code execution input.\n\nReturns:\n  The code execution result."
  inherited_properties:
    BaseCodeExecutor:
    - signature: 'optimize_data_file: bool'
      docstring: 'If true, extract and process data files from the model request

        and attach them to the code executor.


        Supported data file MimeTypes are [text/csv].

        Default to False.'
    - signature: 'stateful: bool'
      docstring: Whether the code executor is stateful. Default to False.
    - signature: 'error_retry_attempts: int'
      docstring: The number of attempts to retry on consecutive code execution errors. Default to 2.
    - signature: 'code_block_delimiters: typing.List[tuple[str, str]]'
      docstring: "The list of the enclosing delimiters to identify the code blocks.\n\nFor example, the delimiter ('```python\\n', '\\n```') can be\nused to identify code blocks with the following format::\n\n    ```python\n    print(\"hello\")\n    ```"
    - signature: 'execution_result_delimiters: tuple[str, str]'
      docstring: The delimiters to format the code execution result.
    BaseModel:
    - signature: 'model_config: pydantic.ConfigDict'
  omitted_inherited_members_from:
  - pydantic.BaseModel
- rank: 641
  id: google.adk.code_executors.built_in_code_executor.BuiltInCodeExecutor.execute_code
  name: execute_code
  file_path: google/adk/code_executors/built_in_code_executor.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def execute_code(self, invocation_context: google.adk.agents.invocation_context.InvocationContext, code_execution_input: google.adk.code_executors.code_execution_utils.CodeExecutionInput) -> google.adk.code_executors.code_execution_utils.CodeExecutionResult:'
- rank: 642
  id: google.adk.code_executors.built_in_code_executor.BuiltInCodeExecutor.process_llm_request
  name: process_llm_request
  file_path: google/adk/code_executors/built_in_code_executor.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: Pre-process the LLM request for Gemini 2.0+ models to use the code execution tool.
  signature: 'def process_llm_request(self, llm_request: google.adk.models.LlmRequest) -> None:'
- rank: 643
  id: google.adk.code_executors.code_execution_utils
  name: code_execution_utils
  file_path: google/adk/code_executors/code_execution_utils.py
  type: MODULE
  group: Orphan
  usage_score: 0
  docstring: Utility functions for code execution.
- rank: 644
  id: google.adk.code_executors.code_execution_utils.CodeExecutionInput
  name: CodeExecutionInput
  file_path: google/adk/code_executors/code_execution_utils.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: A structure that contains the input of code execution.
  constructor_signature: 'def __init__(self, *, code: str, input_files: list[google.adk.code_executors.code_execution_utils.File] = list(), execution_id: typing.Optional[str] = None):'
  properties:
  - signature: 'code: str'
    docstring: The code to execute.
  - signature: 'input_files: list[google.adk.code_executors.code_execution_utils.File]'
    docstring: The input files available to the code.
  - signature: 'execution_id: typing.Optional[str]'
    docstring: The execution ID for the stateful code execution.
- rank: 645
  id: google.adk.code_executors.code_execution_utils.CodeExecutionResult
  name: CodeExecutionResult
  file_path: google/adk/code_executors/code_execution_utils.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: A structure that contains the result of code execution.
  constructor_signature: 'def __init__(self, *, stdout: str = '''', stderr: str = '''', output_files: list[google.adk.code_executors.code_execution_utils.File] = list()):'
  properties:
  - signature: 'stdout: str'
    docstring: The standard output of the code execution.
  - signature: 'stderr: str'
    docstring: The standard error of the code execution.
  - signature: 'output_files: list[google.adk.code_executors.code_execution_utils.File]'
    docstring: The output files from the code execution.
- rank: 646
  id: google.adk.code_executors.code_execution_utils.CodeExecutionUtils
  name: CodeExecutionUtils
  file_path: google/adk/code_executors/code_execution_utils.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: Utility functions for code execution.
  methods:
  - signature: 'def get_encoded_file_content(data: bytes) -> bytes:'
    docstring: "Gets the file content as a base64-encoded bytes.\n\nArgs:\n  data: The file content bytes.\n\nReturns:\n  The file content as a base64-encoded bytes."
  - signature: 'def extract_code_and_truncate_content(content: google.genai.types.Content, code_block_delimiters: typing.List[tuple[str, str]]) -> typing.Optional[str]:'
    docstring: "Extracts the first code block from the content and truncate everything after it.\n\nArgs:\n  content: The mutable content to extract the code from.\n  code_block_delimiters: The list of the enclosing delimiters to identify\n    the code blocks.\n\nReturns:\n  The first code block if found; otherwise, None."
  - signature: 'def build_executable_code_part(code: str) -> google.genai.types.Part:'
    docstring: "Builds an executable code part with code string.\n\nArgs:\n  code: The code string.\n\nReturns:\n  The constructed executable code part."
  - signature: 'def build_code_execution_result_part(code_execution_result: google.adk.code_executors.code_execution_utils.CodeExecutionResult) -> google.genai.types.Part:'
    docstring: "Builds the code execution result part from the code execution result.\n\nArgs:\n  code_execution_result: The code execution result.\n\nReturns:\n  The constructed code execution result part."
  - signature: 'def convert_code_execution_parts(content: google.genai.types.Content, code_block_delimiter: tuple[str, str], execution_result_delimiters: tuple[str, str]):'
    docstring: "Converts the code execution parts to text parts in a Content.\n\nArgs:\n  content: The mutable content to convert the code execution parts to text\n    parts.\n  code_block_delimiter: The delimiter to format the code block.\n  execution_result_delimiters: The delimiter to format the code execution\n    result."
- rank: 647
  id: google.adk.code_executors.code_execution_utils.CodeExecutionUtils.build_code_execution_result_part
  name: build_code_execution_result_part
  file_path: google/adk/code_executors/code_execution_utils.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Builds the code execution result part from the code execution result.\n\nArgs:\n  code_execution_result: The code execution result.\n\nReturns:\n  The constructed code execution result part."
  signature: 'def build_code_execution_result_part(code_execution_result: google.adk.code_executors.code_execution_utils.CodeExecutionResult) -> google.genai.types.Part:'
- rank: 648
  id: google.adk.code_executors.code_execution_utils.CodeExecutionUtils.build_executable_code_part
  name: build_executable_code_part
  file_path: google/adk/code_executors/code_execution_utils.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Builds an executable code part with code string.\n\nArgs:\n  code: The code string.\n\nReturns:\n  The constructed executable code part."
  signature: 'def build_executable_code_part(code: str) -> google.genai.types.Part:'
- rank: 649
  id: google.adk.code_executors.code_execution_utils.CodeExecutionUtils.convert_code_execution_parts
  name: convert_code_execution_parts
  file_path: google/adk/code_executors/code_execution_utils.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Converts the code execution parts to text parts in a Content.\n\nArgs:\n  content: The mutable content to convert the code execution parts to text\n    parts.\n  code_block_delimiter: The delimiter to format the code block.\n  execution_result_delimiters: The delimiter to format the code execution\n    result."
  signature: 'def convert_code_execution_parts(content: google.genai.types.Content, code_block_delimiter: tuple[str, str], execution_result_delimiters: tuple[str, str]):'
- rank: 650
  id: google.adk.code_executors.code_execution_utils.CodeExecutionUtils.extract_code_and_truncate_content
  name: extract_code_and_truncate_content
  file_path: google/adk/code_executors/code_execution_utils.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Extracts the first code block from the content and truncate everything after it.\n\nArgs:\n  content: The mutable content to extract the code from.\n  code_block_delimiters: The list of the enclosing delimiters to identify\n    the code blocks.\n\nReturns:\n  The first code block if found; otherwise, None."
  signature: 'def extract_code_and_truncate_content(content: google.genai.types.Content, code_block_delimiters: typing.List[tuple[str, str]]) -> typing.Optional[str]:'
- rank: 651
  id: google.adk.code_executors.code_execution_utils.CodeExecutionUtils.get_encoded_file_content
  name: get_encoded_file_content
  file_path: google/adk/code_executors/code_execution_utils.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Gets the file content as a base64-encoded bytes.\n\nArgs:\n  data: The file content bytes.\n\nReturns:\n  The file content as a base64-encoded bytes."
  signature: 'def get_encoded_file_content(data: bytes) -> bytes:'
- rank: 652
  id: google.adk.code_executors.code_execution_utils.File
  name: File
  file_path: google/adk/code_executors/code_execution_utils.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: A structure that contains a file name and its content.
  constructor_signature: 'def __init__(self, *, name: str, content: str | bytes, mime_type: str = ''text/plain''):'
  properties:
  - signature: 'name: str'
    docstring: The name of the file with file extension (e.g., "file.csv").
  - signature: 'content: str | bytes'
    docstring: The base64-encoded bytes of the file content or the original bytes of the file content.
  - signature: 'mime_type: str'
    docstring: The mime type of the file (e.g., "image/png").
- rank: 653
  id: google.adk.code_executors.code_executor_context
  name: code_executor_context
  file_path: google/adk/code_executors/code_executor_context.py
  type: MODULE
  group: Orphan
  usage_score: 0
  docstring: The persistent context used to configure the code executor.
- rank: 654
  id: google.adk.code_executors.code_executor_context.CodeExecutorContext
  name: CodeExecutorContext
  file_path: google/adk/code_executors/code_executor_context.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: The persistent context used to configure the code executor.
  constructor_signature: 'def __init__(self, session_state: google.adk.sessions.state.State):'
  methods:
  - signature: 'def get_state_delta(self) -> dict[str, typing.Any]:'
    docstring: "Gets the state delta to update in the persistent session state.\n\nReturns:\n  The state delta to update in the persistent session state."
  - signature: 'def get_execution_id(self) -> typing.Optional[str]:'
    docstring: "Gets the session ID for the code executor.\n\nReturns:\n  The session ID for the code executor context."
  - signature: 'def set_execution_id(self, session_id: str):'
    docstring: "Sets the session ID for the code executor.\n\nArgs:\n  session_id: The session ID for the code executor."
  - signature: 'def get_processed_file_names(self) -> list[str]:'
    docstring: "Gets the processed file names from the session state.\n\nReturns:\n  A list of processed file names in the code executor context."
  - signature: 'def add_processed_file_names(self, file_names: [str]):'
    docstring: "Adds the processed file name to the session state.\n\nArgs:\n  file_names: The processed file names to add to the session state."
  - signature: 'def get_input_files(self) -> list[google.adk.code_executors.code_execution_utils.File]:'
    docstring: "Gets the code executor input file names from the session state.\n\nReturns:\n  A list of input files in the code executor context."
  - signature: 'def add_input_files(self, input_files: list[google.adk.code_executors.code_execution_utils.File]):'
    docstring: "Adds the input files to the code executor context.\n\nArgs:\n  input_files: The input files to add to the code executor context."
  - signature: 'def clear_input_files(self):'
    docstring: Removes the input files and processed file names to the code executor context.
  - signature: 'def get_error_count(self, invocation_id: str) -> int:'
    docstring: "Gets the error count from the session state.\n\nArgs:\n  invocation_id: The invocation ID to get the error count for.\n\nReturns:\n  The error count for the given invocation ID."
  - signature: 'def increment_error_count(self, invocation_id: str):'
    docstring: "Increments the error count from the session state.\n\nArgs:\n  invocation_id: The invocation ID to increment the error count for."
  - signature: 'def reset_error_count(self, invocation_id: str):'
    docstring: "Resets the error count from the session state.\n\nArgs:\n  invocation_id: The invocation ID to reset the error count for."
  - signature: 'def update_code_execution_result(self, invocation_id: str, code: str, result_stdout: str, result_stderr: str):'
    docstring: "Updates the code execution result.\n\nArgs:\n  invocation_id: The invocation ID to update the code execution result for.\n  code: The code to execute.\n  result_stdout: The standard output of the code execution.\n  result_stderr: The standard error of the code execution."
- rank: 655
  id: google.adk.code_executors.code_executor_context.CodeExecutorContext.__init__
  name: __init__
  file_path: google/adk/code_executors/code_executor_context.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Initializes the code executor context.\n\nArgs:\n  session_state: The session state to get the code executor context from."
  signature: 'def __init__(self, session_state: google.adk.sessions.state.State):'
- rank: 656
  id: google.adk.code_executors.code_executor_context.CodeExecutorContext.add_input_files
  name: add_input_files
  file_path: google/adk/code_executors/code_executor_context.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Adds the input files to the code executor context.\n\nArgs:\n  input_files: The input files to add to the code executor context."
  signature: 'def add_input_files(self, input_files: list[google.adk.code_executors.code_execution_utils.File]):'
- rank: 657
  id: google.adk.code_executors.code_executor_context.CodeExecutorContext.add_processed_file_names
  name: add_processed_file_names
  file_path: google/adk/code_executors/code_executor_context.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Adds the processed file name to the session state.\n\nArgs:\n  file_names: The processed file names to add to the session state."
  signature: 'def add_processed_file_names(self, file_names: [str]):'
- rank: 658
  id: google.adk.code_executors.code_executor_context.CodeExecutorContext.clear_input_files
  name: clear_input_files
  file_path: google/adk/code_executors/code_executor_context.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: Removes the input files and processed file names to the code executor context.
  signature: 'def clear_input_files(self):'
- rank: 659
  id: google.adk.code_executors.code_executor_context.CodeExecutorContext.get_error_count
  name: get_error_count
  file_path: google/adk/code_executors/code_executor_context.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Gets the error count from the session state.\n\nArgs:\n  invocation_id: The invocation ID to get the error count for.\n\nReturns:\n  The error count for the given invocation ID."
  signature: 'def get_error_count(self, invocation_id: str) -> int:'
- rank: 660
  id: google.adk.code_executors.code_executor_context.CodeExecutorContext.get_execution_id
  name: get_execution_id
  file_path: google/adk/code_executors/code_executor_context.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Gets the session ID for the code executor.\n\nReturns:\n  The session ID for the code executor context."
  signature: 'def get_execution_id(self) -> typing.Optional[str]:'
- rank: 661
  id: google.adk.code_executors.code_executor_context.CodeExecutorContext.get_input_files
  name: get_input_files
  file_path: google/adk/code_executors/code_executor_context.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Gets the code executor input file names from the session state.\n\nReturns:\n  A list of input files in the code executor context."
  signature: 'def get_input_files(self) -> list[google.adk.code_executors.code_execution_utils.File]:'
- rank: 662
  id: google.adk.code_executors.code_executor_context.CodeExecutorContext.get_processed_file_names
  name: get_processed_file_names
  file_path: google/adk/code_executors/code_executor_context.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Gets the processed file names from the session state.\n\nReturns:\n  A list of processed file names in the code executor context."
  signature: 'def get_processed_file_names(self) -> list[str]:'
- rank: 663
  id: google.adk.code_executors.code_executor_context.CodeExecutorContext.get_state_delta
  name: get_state_delta
  file_path: google/adk/code_executors/code_executor_context.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Gets the state delta to update in the persistent session state.\n\nReturns:\n  The state delta to update in the persistent session state."
  signature: 'def get_state_delta(self) -> dict[str, typing.Any]:'
- rank: 664
  id: google.adk.code_executors.code_executor_context.CodeExecutorContext.increment_error_count
  name: increment_error_count
  file_path: google/adk/code_executors/code_executor_context.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Increments the error count from the session state.\n\nArgs:\n  invocation_id: The invocation ID to increment the error count for."
  signature: 'def increment_error_count(self, invocation_id: str):'
- rank: 665
  id: google.adk.code_executors.code_executor_context.CodeExecutorContext.reset_error_count
  name: reset_error_count
  file_path: google/adk/code_executors/code_executor_context.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Resets the error count from the session state.\n\nArgs:\n  invocation_id: The invocation ID to reset the error count for."
  signature: 'def reset_error_count(self, invocation_id: str):'
- rank: 666
  id: google.adk.code_executors.code_executor_context.CodeExecutorContext.set_execution_id
  name: set_execution_id
  file_path: google/adk/code_executors/code_executor_context.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Sets the session ID for the code executor.\n\nArgs:\n  session_id: The session ID for the code executor."
  signature: 'def set_execution_id(self, session_id: str):'
- rank: 667
  id: google.adk.code_executors.code_executor_context.CodeExecutorContext.update_code_execution_result
  name: update_code_execution_result
  file_path: google/adk/code_executors/code_executor_context.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Updates the code execution result.\n\nArgs:\n  invocation_id: The invocation ID to update the code execution result for.\n  code: The code to execute.\n  result_stdout: The standard output of the code execution.\n  result_stderr: The standard error of the code execution."
  signature: 'def update_code_execution_result(self, invocation_id: str, code: str, result_stdout: str, result_stderr: str):'
- rank: 668
  id: google.adk.code_executors.container_code_executor
  name: container_code_executor
  file_path: google/adk/code_executors/container_code_executor.py
  type: MODULE
  group: Orphan
  usage_score: 0
- rank: 669
  id: google.adk.code_executors.container_code_executor.ContainerCodeExecutor
  name: ContainerCodeExecutor
  file_path: google/adk/code_executors/container_code_executor.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: "A code executor that uses a custom container to execute code.\n\nAttributes:\n  base_url: Optional. The base url of the user hosted Docker client.\n  image: The tag of the predefined image or custom image to run on the\n    container. Either docker_path or image must be set.\n  docker_path: The path to the directory containing the Dockerfile. If set,\n    build the image from the dockerfile path instead of using the predefined\n    image. Either docker_path or image must be set.\n\n[Note: Inherited members from pydantic.BaseModel are omitted.]"
  constructor_signature: 'def __init__(self, base_url: typing.Optional[str], image: typing.Optional[str], docker_path: typing.Optional[str]):'
  methods:
  - signature: 'def execute_code(self, invocation_context: google.adk.agents.invocation_context.InvocationContext, code_execution_input: google.adk.code_executors.code_execution_utils.CodeExecutionInput) -> google.adk.code_executors.code_execution_utils.CodeExecutionResult:'
  properties:
  - signature: 'base_url: typing.Optional[str]'
    docstring: Optional. The base url of the user hosted Docker client.
  - signature: 'image: str'
    docstring: 'The tag of the predefined image or custom image to run on the container.

      Either docker_path or image must be set.'
  - signature: 'docker_path: str'
    docstring: 'The path to the directory containing the Dockerfile.

      If set, build the image from the dockerfile path instead of using the

      predefined image. Either docker_path or image must be set.'
  - signature: 'stateful: bool'
  - signature: 'optimize_data_file: bool'
  inherited_methods:
    BaseCodeExecutor:
    - signature: 'def execute_code(self, invocation_context: google.adk.agents.invocation_context.InvocationContext, code_execution_input: google.adk.code_executors.code_execution_utils.CodeExecutionInput) -> google.adk.code_executors.code_execution_utils.CodeExecutionResult:'
      docstring: "Executes code and return the code execution result.\n\nArgs:\n  invocation_context: The invocation context of the code execution.\n  code_execution_input: The code execution input.\n\nReturns:\n  The code execution result."
  inherited_properties:
    BaseCodeExecutor:
    - signature: 'optimize_data_file: bool'
      docstring: 'If true, extract and process data files from the model request

        and attach them to the code executor.


        Supported data file MimeTypes are [text/csv].

        Default to False.'
    - signature: 'stateful: bool'
      docstring: Whether the code executor is stateful. Default to False.
    - signature: 'error_retry_attempts: int'
      docstring: The number of attempts to retry on consecutive code execution errors. Default to 2.
    - signature: 'code_block_delimiters: typing.List[tuple[str, str]]'
      docstring: "The list of the enclosing delimiters to identify the code blocks.\n\nFor example, the delimiter ('```python\\n', '\\n```') can be\nused to identify code blocks with the following format::\n\n    ```python\n    print(\"hello\")\n    ```"
    - signature: 'execution_result_delimiters: tuple[str, str]'
      docstring: The delimiters to format the code execution result.
    BaseModel:
    - signature: 'model_config: pydantic.ConfigDict'
  omitted_inherited_members_from:
  - pydantic.BaseModel
- rank: 670
  id: google.adk.code_executors.container_code_executor.ContainerCodeExecutor.__init__
  name: __init__
  file_path: google/adk/code_executors/container_code_executor.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Initializes the ContainerCodeExecutor.\n\nArgs:\n  base_url: Optional. The base url of the user hosted Docker client.\n  image: The tag of the predefined image or custom image to run on the\n    container. Either docker_path or image must be set.\n  docker_path: The path to the directory containing the Dockerfile. If set,\n    build the image from the dockerfile path instead of using the predefined\n    image. Either docker_path or image must be set.\n  **data: The data to initialize the ContainerCodeExecutor."
  signature: 'def __init__(self, base_url: typing.Optional[str], image: typing.Optional[str], docker_path: typing.Optional[str]):'
- rank: 671
  id: google.adk.code_executors.container_code_executor.ContainerCodeExecutor.execute_code
  name: execute_code
  file_path: google/adk/code_executors/container_code_executor.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def execute_code(self, invocation_context: google.adk.agents.invocation_context.InvocationContext, code_execution_input: google.adk.code_executors.code_execution_utils.CodeExecutionInput) -> google.adk.code_executors.code_execution_utils.CodeExecutionResult:'
- rank: 672
  id: google.adk.code_executors.gke_code_executor
  name: gke_code_executor
  file_path: google/adk/code_executors/gke_code_executor.py
  type: MODULE
  group: Orphan
  usage_score: 0
- rank: 673
  id: google.adk.code_executors.gke_code_executor.GkeCodeExecutor
  name: GkeCodeExecutor
  file_path: google/adk/code_executors/gke_code_executor.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Executes Python code in a secure gVisor-sandboxed Pod on GKE.


    This executor securely runs code by dynamically creating a Kubernetes Job for

    each execution request. The user''s code is mounted via a ConfigMap, and the

    Pod is hardened with a strict security context and resource limits.


    Key Features:

    - Sandboxed execution using the gVisor runtime.

    - Ephemeral, per-execution environments using Kubernetes Jobs.

    - Secure-by-default Pod configuration (non-root, no privileges).

    - Automatic garbage collection of completed Jobs and Pods via TTL.

    - Efficient, event-driven waiting using the Kubernetes watch API.


    RBAC Permissions:

    This executor requires a ServiceAccount with specific RBAC permissions. The

    Role granted to the ServiceAccount must include rules to manage Jobs,

    ConfigMaps, and Pod logs. Below is a minimal set of required permissions:


    rules:

    # For creating/deleting code ConfigMaps and patching ownerReferences

    - apiGroups: [""] # Core API Group

    resources: ["configmaps"]

    verbs: ["create", "delete", "get", "patch"]

    # For watching Job completion status

    - apiGroups: ["batch"]

    resources: ["jobs"]

    verbs: ["get", "list", "watch", "create", "delete"]

    # For retrieving logs from the completed Job''s Pod

    - apiGroups: [""] # Core API Group

    resources: ["pods", "pods/log"]

    verbs: ["get", "list"]


    [Note: Inherited members from pydantic.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, kubeconfig_path: str | None, kubeconfig_context: str | None):'
  aliases:
  - google.adk.code_executors.GkeCodeExecutor
  methods:
  - signature: 'def execute_code(self, invocation_context: google.adk.agents.invocation_context.InvocationContext, code_execution_input: google.adk.code_executors.code_execution_utils.CodeExecutionInput) -> google.adk.code_executors.code_execution_utils.CodeExecutionResult:'
    docstring: Orchestrates the secure execution of a code snippet on GKE.
  properties:
  - signature: 'namespace: str'
  - signature: 'image: str'
  - signature: 'timeout_seconds: int'
  - signature: 'cpu_requested: str'
  - signature: 'mem_requested: str'
  - signature: 'cpu_limit: str'
  - signature: 'mem_limit: str'
  - signature: 'kubeconfig_path: str | None'
  - signature: 'kubeconfig_context: str | None'
  inherited_methods:
    BaseCodeExecutor:
    - signature: 'def execute_code(self, invocation_context: google.adk.agents.invocation_context.InvocationContext, code_execution_input: google.adk.code_executors.code_execution_utils.CodeExecutionInput) -> google.adk.code_executors.code_execution_utils.CodeExecutionResult:'
      docstring: "Executes code and return the code execution result.\n\nArgs:\n  invocation_context: The invocation context of the code execution.\n  code_execution_input: The code execution input.\n\nReturns:\n  The code execution result."
  inherited_properties:
    BaseCodeExecutor:
    - signature: 'optimize_data_file: bool'
      docstring: 'If true, extract and process data files from the model request

        and attach them to the code executor.


        Supported data file MimeTypes are [text/csv].

        Default to False.'
    - signature: 'stateful: bool'
      docstring: Whether the code executor is stateful. Default to False.
    - signature: 'error_retry_attempts: int'
      docstring: The number of attempts to retry on consecutive code execution errors. Default to 2.
    - signature: 'code_block_delimiters: typing.List[tuple[str, str]]'
      docstring: "The list of the enclosing delimiters to identify the code blocks.\n\nFor example, the delimiter ('```python\\n', '\\n```') can be\nused to identify code blocks with the following format::\n\n    ```python\n    print(\"hello\")\n    ```"
    - signature: 'execution_result_delimiters: tuple[str, str]'
      docstring: The delimiters to format the code execution result.
    BaseModel:
    - signature: 'model_config: pydantic.ConfigDict'
  omitted_inherited_members_from:
  - pydantic.BaseModel
- rank: 674
  id: google.adk.code_executors.gke_code_executor.GkeCodeExecutor.__init__
  name: __init__
  file_path: google/adk/code_executors/gke_code_executor.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: 'Initializes the executor and the Kubernetes API clients.


    This constructor supports multiple authentication methods:

    1. Explicitly via a kubeconfig file path and context.

    2. Automatically via in-cluster service account (when running in GKE).

    3. Automatically via the default local kubeconfig file (~/.kube/config).'
  signature: 'def __init__(self, kubeconfig_path: str | None, kubeconfig_context: str | None):'
- rank: 675
  id: google.adk.code_executors.gke_code_executor.GkeCodeExecutor.execute_code
  name: execute_code
  file_path: google/adk/code_executors/gke_code_executor.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: Orchestrates the secure execution of a code snippet on GKE.
  signature: 'def execute_code(self, invocation_context: google.adk.agents.invocation_context.InvocationContext, code_execution_input: google.adk.code_executors.code_execution_utils.CodeExecutionInput) -> google.adk.code_executors.code_execution_utils.CodeExecutionResult:'
- rank: 676
  id: google.adk.code_executors.unsafe_local_code_executor
  name: unsafe_local_code_executor
  file_path: google/adk/code_executors/unsafe_local_code_executor.py
  type: MODULE
  group: Orphan
  usage_score: 0
- rank: 677
  id: google.adk.code_executors.unsafe_local_code_executor.UnsafeLocalCodeExecutor
  name: UnsafeLocalCodeExecutor
  file_path: google/adk/code_executors/unsafe_local_code_executor.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'A code executor that unsafely execute code in the current local context.


    [Note: Inherited members from pydantic.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self):'
  aliases:
  - google.adk.code_executors.UnsafeLocalCodeExecutor
  methods:
  - signature: 'def execute_code(self, invocation_context: google.adk.agents.invocation_context.InvocationContext, code_execution_input: google.adk.code_executors.code_execution_utils.CodeExecutionInput) -> google.adk.code_executors.code_execution_utils.CodeExecutionResult:'
  properties:
  - signature: 'stateful: bool'
  - signature: 'optimize_data_file: bool'
  inherited_methods:
    BaseCodeExecutor:
    - signature: 'def execute_code(self, invocation_context: google.adk.agents.invocation_context.InvocationContext, code_execution_input: google.adk.code_executors.code_execution_utils.CodeExecutionInput) -> google.adk.code_executors.code_execution_utils.CodeExecutionResult:'
      docstring: "Executes code and return the code execution result.\n\nArgs:\n  invocation_context: The invocation context of the code execution.\n  code_execution_input: The code execution input.\n\nReturns:\n  The code execution result."
  inherited_properties:
    BaseCodeExecutor:
    - signature: 'optimize_data_file: bool'
      docstring: 'If true, extract and process data files from the model request

        and attach them to the code executor.


        Supported data file MimeTypes are [text/csv].

        Default to False.'
    - signature: 'stateful: bool'
      docstring: Whether the code executor is stateful. Default to False.
    - signature: 'error_retry_attempts: int'
      docstring: The number of attempts to retry on consecutive code execution errors. Default to 2.
    - signature: 'code_block_delimiters: typing.List[tuple[str, str]]'
      docstring: "The list of the enclosing delimiters to identify the code blocks.\n\nFor example, the delimiter ('```python\\n', '\\n```') can be\nused to identify code blocks with the following format::\n\n    ```python\n    print(\"hello\")\n    ```"
    - signature: 'execution_result_delimiters: tuple[str, str]'
      docstring: The delimiters to format the code execution result.
    BaseModel:
    - signature: 'model_config: pydantic.ConfigDict'
  omitted_inherited_members_from:
  - pydantic.BaseModel
- rank: 678
  id: google.adk.code_executors.unsafe_local_code_executor.UnsafeLocalCodeExecutor.__init__
  name: __init__
  file_path: google/adk/code_executors/unsafe_local_code_executor.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: Initializes the UnsafeLocalCodeExecutor.
  signature: 'def __init__(self):'
- rank: 679
  id: google.adk.code_executors.unsafe_local_code_executor.UnsafeLocalCodeExecutor.execute_code
  name: execute_code
  file_path: google/adk/code_executors/unsafe_local_code_executor.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def execute_code(self, invocation_context: google.adk.agents.invocation_context.InvocationContext, code_execution_input: google.adk.code_executors.code_execution_utils.CodeExecutionInput) -> google.adk.code_executors.code_execution_utils.CodeExecutionResult:'
- rank: 680
  id: google.adk.code_executors.vertex_ai_code_executor
  name: vertex_ai_code_executor
  file_path: google/adk/code_executors/vertex_ai_code_executor.py
  type: MODULE
  group: Orphan
  usage_score: 0
- rank: 681
  id: google.adk.code_executors.vertex_ai_code_executor.VertexAiCodeExecutor
  name: VertexAiCodeExecutor
  file_path: google/adk/code_executors/vertex_ai_code_executor.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: "A code executor that uses Vertex Code Interpreter Extension to execute code.\n\nAttributes:\n  resource_name: If set, load the existing resource name of the code\n    interpreter extension instead of creating a new one. Format:\n    projects/123/locations/us-central1/extensions/456\n\n[Note: Inherited members from pydantic.BaseModel are omitted.]"
  constructor_signature: 'def __init__(self, resource_name: str):'
  aliases:
  - google.adk.code_executors.VertexAiCodeExecutor
  methods:
  - signature: 'def execute_code(self, invocation_context: google.adk.agents.invocation_context.InvocationContext, code_execution_input: google.adk.code_executors.code_execution_utils.CodeExecutionInput) -> google.adk.code_executors.code_execution_utils.CodeExecutionResult:'
  properties:
  - signature: 'resource_name: str'
    docstring: 'If set, load the existing resource name of the code interpreter extension

      instead of creating a new one.

      Format: projects/123/locations/us-central1/extensions/456'
  inherited_methods:
    BaseCodeExecutor:
    - signature: 'def execute_code(self, invocation_context: google.adk.agents.invocation_context.InvocationContext, code_execution_input: google.adk.code_executors.code_execution_utils.CodeExecutionInput) -> google.adk.code_executors.code_execution_utils.CodeExecutionResult:'
      docstring: "Executes code and return the code execution result.\n\nArgs:\n  invocation_context: The invocation context of the code execution.\n  code_execution_input: The code execution input.\n\nReturns:\n  The code execution result."
  inherited_properties:
    BaseCodeExecutor:
    - signature: 'optimize_data_file: bool'
      docstring: 'If true, extract and process data files from the model request

        and attach them to the code executor.


        Supported data file MimeTypes are [text/csv].

        Default to False.'
    - signature: 'stateful: bool'
      docstring: Whether the code executor is stateful. Default to False.
    - signature: 'error_retry_attempts: int'
      docstring: The number of attempts to retry on consecutive code execution errors. Default to 2.
    - signature: 'code_block_delimiters: typing.List[tuple[str, str]]'
      docstring: "The list of the enclosing delimiters to identify the code blocks.\n\nFor example, the delimiter ('```python\\n', '\\n```') can be\nused to identify code blocks with the following format::\n\n    ```python\n    print(\"hello\")\n    ```"
    - signature: 'execution_result_delimiters: tuple[str, str]'
      docstring: The delimiters to format the code execution result.
    BaseModel:
    - signature: 'model_config: pydantic.ConfigDict'
  omitted_inherited_members_from:
  - pydantic.BaseModel
- rank: 682
  id: google.adk.code_executors.vertex_ai_code_executor.VertexAiCodeExecutor.__init__
  name: __init__
  file_path: google/adk/code_executors/vertex_ai_code_executor.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Initializes the VertexAiCodeExecutor.\n\nArgs:\n  resource_name: If set, load the existing resource name of the code\n    interpreter extension instead of creating a new one. Format:\n    projects/123/locations/us-central1/extensions/456\n  **data: Additional keyword arguments to be passed to the base class."
  signature: 'def __init__(self, resource_name: str):'
- rank: 683
  id: google.adk.code_executors.vertex_ai_code_executor.VertexAiCodeExecutor.execute_code
  name: execute_code
  file_path: google/adk/code_executors/vertex_ai_code_executor.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def execute_code(self, invocation_context: google.adk.agents.invocation_context.InvocationContext, code_execution_input: google.adk.code_executors.code_execution_utils.CodeExecutionInput) -> google.adk.code_executors.code_execution_utils.CodeExecutionResult:'
- rank: 684
  id: google.adk.dependencies
  name: dependencies
  file_path: google/adk/dependencies/__init__.py
  type: MODULE
  group: Orphan
  usage_score: 0
- rank: 685
  id: google.adk.dependencies.rouge_scorer
  name: rouge_scorer
  file_path: google/adk/dependencies/rouge_scorer.py
  type: MODULE
  group: Orphan
  usage_score: 0
- rank: 686
  id: google.adk.dependencies.vertexai
  name: vertexai
  file_path: google/adk/dependencies/vertexai.py
  type: MODULE
  group: Orphan
  usage_score: 0
- rank: 687
  id: google.adk.errors
  name: errors
  file_path: google/adk/errors/__init__.py
  type: MODULE
  group: Orphan
  usage_score: 0
- rank: 688
  id: google.adk.errors.already_exists_error
  name: already_exists_error
  file_path: google/adk/errors/already_exists_error.py
  type: MODULE
  group: Orphan
  usage_score: 0
- rank: 689
  id: google.adk.errors.already_exists_error.AlreadyExistsError
  name: AlreadyExistsError
  file_path: google/adk/errors/already_exists_error.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Represents an error that occurs when an entity already exists.


    [Note: Inherited members from Exception are omitted.]'
  constructor_signature: 'def __init__(self, message):'
  omitted_inherited_members_from:
  - Exception
- rank: 690
  id: google.adk.errors.already_exists_error.AlreadyExistsError.__init__
  name: __init__
  file_path: google/adk/errors/already_exists_error.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Initializes the AlreadyExistsError exception.\n\nArgs:\n    message (str): An optional custom message to describe the error."
  signature: 'def __init__(self, message):'
- rank: 691
  id: google.adk.errors.input_validation_error
  name: input_validation_error
  file_path: google/adk/errors/input_validation_error.py
  type: MODULE
  group: Orphan
  usage_score: 0
- rank: 692
  id: google.adk.errors.input_validation_error.InputValidationError
  name: InputValidationError
  file_path: google/adk/errors/input_validation_error.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Represents an error raised when user input fails validation.


    [Note: Inherited members from ValueError are omitted.]'
  constructor_signature: 'def __init__(self, message):'
  omitted_inherited_members_from:
  - ValueError
- rank: 693
  id: google.adk.errors.input_validation_error.InputValidationError.__init__
  name: __init__
  file_path: google/adk/errors/input_validation_error.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Initializes the InputValidationError exception.\n\nArgs:\n    message (str): A message describing why the input is invalid."
  signature: 'def __init__(self, message):'
- rank: 694
  id: google.adk.errors.not_found_error
  name: not_found_error
  file_path: google/adk/errors/not_found_error.py
  type: MODULE
  group: Orphan
  usage_score: 0
- rank: 695
  id: google.adk.errors.not_found_error.NotFoundError
  name: NotFoundError
  file_path: google/adk/errors/not_found_error.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Represents an error that occurs when an entity is not found.


    [Note: Inherited members from Exception are omitted.]'
  constructor_signature: 'def __init__(self, message):'
  omitted_inherited_members_from:
  - Exception
- rank: 696
  id: google.adk.errors.not_found_error.NotFoundError.__init__
  name: __init__
  file_path: google/adk/errors/not_found_error.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Initializes the NotFoundError exception.\n\nArgs:\n    message (str): An optional custom message to describe the error."
  signature: 'def __init__(self, message):'
- rank: 697
  id: google.adk.evaluation
  name: evaluation
  file_path: google/adk/evaluation/__init__.py
  type: MODULE
  group: Orphan
  usage_score: 0
- rank: 698
  id: google.adk.evaluation.agent_evaluator
  name: agent_evaluator
  file_path: google/adk/evaluation/agent_evaluator.py
  type: MODULE
  group: Orphan
  usage_score: 0
  methods:
  - signature: 'def load_json(file_path: str) -> typing.Union[typing.Dict, typing.List]:'
- rank: 699
  id: google.adk.evaluation.agent_evaluator.AgentEvaluator
  name: AgentEvaluator
  file_path: google/adk/evaluation/agent_evaluator.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: An evaluator for Agents, mainly intended for helping with test cases.
  methods:
  - signature: 'def find_config_for_test_file(test_file: str) -> google.adk.evaluation.eval_config.EvalConfig:'
    docstring: Find the test_config.json file in the same folder as the test file.
  - signature: 'def evaluate_eval_set(agent_module: str, eval_set: google.adk.evaluation.eval_set.EvalSet, criteria: typing.Optional[dict[str, float]], eval_config: typing.Optional[google.adk.evaluation.eval_config.EvalConfig], num_runs: int, agent_name: typing.Optional[str], print_detailed_results: bool):'
    docstring: "Evaluates an agent using the given EvalSet.\n\nArgs:\n  agent_module: The path to python module that contains the definition of\n    the agent. There is convention in place here, where the code is going to\n    look for 'root_agent' or `get_agent_async` in the loaded module.\n  eval_set: The eval set.\n  criteria: Evaluation criteria, a dictionary of metric names to their\n    respective thresholds. This field is deprecated.\n  eval_config: The evaluation config.\n  num_runs: Number of times all entries in the eval dataset should be\n    assessed.\n  agent_name: The name of the agent, if trying to evaluate something other\n    than root agent. If left empty or none, then root agent is evaluated.\n  print_detailed_results: Whether to print detailed results for each metric\n    evaluation."
  - signature: 'def evaluate(agent_module: str, eval_dataset_file_path_or_dir: str, num_runs: int, agent_name: typing.Optional[str], initial_session_file: typing.Optional[str], print_detailed_results: bool):'
    docstring: "Evaluates an Agent given eval data.\n\nArgs:\n  agent_module: The path to python module that contains the definition of\n    the agent. There is convention in place here, where the code is going to\n    look for 'root_agent' or 'get_agent_async' in the loaded module.\n  eval_dataset_file_path_or_dir: The eval data set. This can be either a\n    string representing full path to the file containing eval dataset, or a\n    directory that is recursively explored for all files that have a\n    `.test.json` suffix.\n  num_runs: Number of times all entries in the eval dataset should be\n    assessed.\n  agent_name: The name of the agent.\n  initial_session_file: File that contains initial session state that is\n    needed by all the evals in the eval dataset.\n  print_detailed_results: Whether to print detailed results for each metric\n    evaluation."
  - signature: 'def migrate_eval_data_to_new_schema(old_eval_data_file: str, new_eval_data_file: str, initial_session_file: typing.Optional[str]):'
    docstring: A utility for migrating eval data to new schema backed by EvalSet.
  - signature: 'def load_json_file(file_path: str) -> typing.List[typing.Dict]:'
- rank: 700
  id: google.adk.evaluation.agent_evaluator.AgentEvaluator.evaluate_eval_set
  name: evaluate_eval_set
  file_path: google/adk/evaluation/agent_evaluator.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Evaluates an agent using the given EvalSet.\n\nArgs:\n  agent_module: The path to python module that contains the definition of\n    the agent. There is convention in place here, where the code is going to\n    look for 'root_agent' or `get_agent_async` in the loaded module.\n  eval_set: The eval set.\n  criteria: Evaluation criteria, a dictionary of metric names to their\n    respective thresholds. This field is deprecated.\n  eval_config: The evaluation config.\n  num_runs: Number of times all entries in the eval dataset should be\n    assessed.\n  agent_name: The name of the agent, if trying to evaluate something other\n    than root agent. If left empty or none, then root agent is evaluated.\n  print_detailed_results: Whether to print detailed results for each metric\n    evaluation."
  signature: 'def evaluate_eval_set(agent_module: str, eval_set: google.adk.evaluation.eval_set.EvalSet, criteria: typing.Optional[dict[str, float]], eval_config: typing.Optional[google.adk.evaluation.eval_config.EvalConfig], num_runs: int, agent_name: typing.Optional[str], print_detailed_results: bool):'
- rank: 701
  id: google.adk.evaluation.agent_evaluator.AgentEvaluator.find_config_for_test_file
  name: find_config_for_test_file
  file_path: google/adk/evaluation/agent_evaluator.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: Find the test_config.json file in the same folder as the test file.
  signature: 'def find_config_for_test_file(test_file: str) -> google.adk.evaluation.eval_config.EvalConfig:'
- rank: 702
  id: google.adk.evaluation.agent_evaluator.AgentEvaluator.load_json_file
  name: load_json_file
  file_path: google/adk/evaluation/agent_evaluator.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def load_json_file(file_path: str) -> typing.List[typing.Dict]:'
- rank: 703
  id: google.adk.evaluation.agent_evaluator.AgentEvaluator.migrate_eval_data_to_new_schema
  name: migrate_eval_data_to_new_schema
  file_path: google/adk/evaluation/agent_evaluator.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: A utility for migrating eval data to new schema backed by EvalSet.
  signature: 'def migrate_eval_data_to_new_schema(old_eval_data_file: str, new_eval_data_file: str, initial_session_file: typing.Optional[str]):'
- rank: 704
  id: google.adk.evaluation.app_details
  name: app_details
  file_path: google/adk/evaluation/app_details.py
  type: MODULE
  group: Orphan
  usage_score: 0
- rank: 705
  id: google.adk.evaluation.app_details.AgentDetails
  name: AgentDetails
  file_path: google/adk/evaluation/app_details.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Details about the individual agent in the App.


    This could be a root agent or the sub-agents in the Agent Tree.


    [Note: Inherited members from pydantic.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, name: str, instructions: str = '''', tool_declarations: google.genai.types.ToolListUnion = list()):'
  properties:
  - signature: 'name: str'
    docstring: The name of the Agent that uniquely identifies it in the App.
  - signature: 'instructions: str'
    docstring: The instructions set on the Agent.
  - signature: 'tool_declarations: google.genai.types.ToolListUnion'
    docstring: A list of tools available to the Agent.
  inherited_properties:
    EvalBaseModel:
    - signature: 'model_config: pydantic.ConfigDict'
  omitted_inherited_members_from:
  - pydantic.BaseModel
- rank: 706
  id: google.adk.evaluation.app_details.AppDetails
  name: AppDetails
  file_path: google/adk/evaluation/app_details.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Contains details about the App (the agentic system).


    This structure is only a projection of the actual app. Only details

    that are relevant to the Eval System are captured here.


    [Note: Inherited members from pydantic.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, agent_details: dict[str, google.adk.evaluation.app_details.AgentDetails] = dict()):'
  methods:
  - signature: 'def get_developer_instructions(self, agent_name: str) -> str:'
    docstring: Returns a string containing the developer instructions.
  - signature: 'def get_tools_by_agent_name(self) -> dict[str, google.genai.types.ToolListUnion]:'
    docstring: Returns a dictionary of tools available to an agent in the App, keyed to the name of the Agent.
  properties:
  - signature: 'agent_details: dict[str, google.adk.evaluation.app_details.AgentDetails]'
    docstring: A mapping from the agent name to the details of that agent.
  inherited_properties:
    EvalBaseModel:
    - signature: 'model_config: pydantic.ConfigDict'
  omitted_inherited_members_from:
  - pydantic.BaseModel
- rank: 707
  id: google.adk.evaluation.app_details.AppDetails.get_developer_instructions
  name: get_developer_instructions
  file_path: google/adk/evaluation/app_details.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: Returns a string containing the developer instructions.
  signature: 'def get_developer_instructions(self, agent_name: str) -> str:'
- rank: 708
  id: google.adk.evaluation.app_details.AppDetails.get_tools_by_agent_name
  name: get_tools_by_agent_name
  file_path: google/adk/evaluation/app_details.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: Returns a dictionary of tools available to an agent in the App, keyed to the name of the Agent.
  signature: 'def get_tools_by_agent_name(self) -> dict[str, google.genai.types.ToolListUnion]:'
- rank: 709
  id: google.adk.evaluation.base_eval_service
  name: base_eval_service
  file_path: google/adk/evaluation/base_eval_service.py
  type: MODULE
  group: Orphan
  usage_score: 0
- rank: 710
  id: google.adk.evaluation.base_eval_service.BaseEvalService
  name: BaseEvalService
  file_path: google/adk/evaluation/base_eval_service.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'A service to run Evals for an ADK agent.


    [Note: Inherited members from ABC are omitted.]'
  methods:
  - signature: 'def perform_inference(self, inference_request: google.adk.evaluation.base_eval_service.InferenceRequest) -> typing.AsyncGenerator[google.adk.evaluation.base_eval_service.InferenceResult, None]:'
    docstring: "Returns InferenceResult obtained from the Agent as and when they are available.\n\nArgs:\n  inference_request: The request for generating inferences."
  - signature: 'def evaluate(self, evaluate_request: google.adk.evaluation.base_eval_service.EvaluateRequest) -> typing.AsyncGenerator[google.adk.evaluation.eval_result.EvalCaseResult, None]:'
    docstring: "Returns EvalCaseResult for each item as and when they are available.\n\nArgs:\n  evaluate_request: The request to perform metric evaluations on the\n    inferences."
  omitted_inherited_members_from:
  - ABC
- rank: 711
  id: google.adk.evaluation.base_eval_service.BaseEvalService.evaluate
  name: evaluate
  file_path: google/adk/evaluation/base_eval_service.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Returns EvalCaseResult for each item as and when they are available.\n\nArgs:\n  evaluate_request: The request to perform metric evaluations on the\n    inferences."
  signature: 'def evaluate(self, evaluate_request: google.adk.evaluation.base_eval_service.EvaluateRequest) -> typing.AsyncGenerator[google.adk.evaluation.eval_result.EvalCaseResult, None]:'
- rank: 712
  id: google.adk.evaluation.base_eval_service.BaseEvalService.perform_inference
  name: perform_inference
  file_path: google/adk/evaluation/base_eval_service.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Returns InferenceResult obtained from the Agent as and when they are available.\n\nArgs:\n  inference_request: The request for generating inferences."
  signature: 'def perform_inference(self, inference_request: google.adk.evaluation.base_eval_service.InferenceRequest) -> typing.AsyncGenerator[google.adk.evaluation.base_eval_service.InferenceResult, None]:'
- rank: 713
  id: google.adk.evaluation.base_eval_service.EvaluateConfig
  name: EvaluateConfig
  file_path: google/adk/evaluation/base_eval_service.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Contains configurations needed to run evaluations.


    [Note: Inherited members from pydantic.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, eval_metrics: list[google.adk.evaluation.eval_metrics.EvalMetric], parallelism: int = 4):'
  properties:
  - signature: 'model_config: pydantic.ConfigDict'
  - signature: 'eval_metrics: list[google.adk.evaluation.eval_metrics.EvalMetric]'
  - signature: 'parallelism: int'
  inherited_properties:
    BaseModel:
    - signature: 'model_config: pydantic.ConfigDict'
  omitted_inherited_members_from:
  - pydantic.BaseModel
- rank: 714
  id: google.adk.evaluation.base_eval_service.EvaluateRequest
  name: EvaluateRequest
  file_path: google/adk/evaluation/base_eval_service.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: '[Note: Inherited members from pydantic.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, inference_results: list[google.adk.evaluation.base_eval_service.InferenceResult], evaluate_config: google.adk.evaluation.base_eval_service.EvaluateConfig):'
  properties:
  - signature: 'model_config: pydantic.ConfigDict'
  - signature: 'inference_results: list[google.adk.evaluation.base_eval_service.InferenceResult]'
  - signature: 'evaluate_config: google.adk.evaluation.base_eval_service.EvaluateConfig'
  inherited_properties:
    BaseModel:
    - signature: 'model_config: pydantic.ConfigDict'
  omitted_inherited_members_from:
  - pydantic.BaseModel
- rank: 715
  id: google.adk.evaluation.base_eval_service.InferenceConfig
  name: InferenceConfig
  file_path: google/adk/evaluation/base_eval_service.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Contains configurations need to run inferences.


    [Note: Inherited members from pydantic.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, labels: typing.Optional[dict[str, str]] = None, parallelism: int = 4):'
  properties:
  - signature: 'model_config: pydantic.ConfigDict'
  - signature: 'labels: typing.Optional[dict[str, str]]'
  - signature: 'parallelism: int'
  inherited_properties:
    BaseModel:
    - signature: 'model_config: pydantic.ConfigDict'
  omitted_inherited_members_from:
  - pydantic.BaseModel
- rank: 716
  id: google.adk.evaluation.base_eval_service.InferenceRequest
  name: InferenceRequest
  file_path: google/adk/evaluation/base_eval_service.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Represent a request to perform inferences for the eval cases in an eval set.


    [Note: Inherited members from pydantic.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, app_name: str, eval_set_id: str, eval_case_ids: typing.Optional[list[str]] = None, inference_config: google.adk.evaluation.base_eval_service.InferenceConfig):'
  properties:
  - signature: 'model_config: pydantic.ConfigDict'
  - signature: 'app_name: str'
  - signature: 'eval_set_id: str'
  - signature: 'eval_case_ids: typing.Optional[list[str]]'
  - signature: 'inference_config: google.adk.evaluation.base_eval_service.InferenceConfig'
  inherited_properties:
    BaseModel:
    - signature: 'model_config: pydantic.ConfigDict'
  omitted_inherited_members_from:
  - pydantic.BaseModel
- rank: 717
  id: google.adk.evaluation.base_eval_service.InferenceResult
  name: InferenceResult
  file_path: google/adk/evaluation/base_eval_service.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Contains inference results for a single eval case.


    [Note: Inherited members from pydantic.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, app_name: str, eval_set_id: str, eval_case_id: str, inferences: typing.Optional[list[google.adk.evaluation.eval_case.Invocation]] = None, session_id: typing.Optional[str], status: google.adk.evaluation.base_eval_service.InferenceStatus = InferenceStatus.UNKNOWN, error_message: typing.Optional[str] = None):'
  properties:
  - signature: 'model_config: pydantic.ConfigDict'
  - signature: 'app_name: str'
  - signature: 'eval_set_id: str'
  - signature: 'eval_case_id: str'
  - signature: 'inferences: typing.Optional[list[google.adk.evaluation.eval_case.Invocation]]'
  - signature: 'session_id: typing.Optional[str]'
  - signature: 'status: google.adk.evaluation.base_eval_service.InferenceStatus'
  - signature: 'error_message: typing.Optional[str]'
  inherited_properties:
    BaseModel:
    - signature: 'model_config: pydantic.ConfigDict'
  omitted_inherited_members_from:
  - pydantic.BaseModel
- rank: 718
  id: google.adk.evaluation.base_eval_service.InferenceStatus
  name: InferenceStatus
  file_path: google/adk/evaluation/base_eval_service.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Status of the inference.


    [Note: Inherited members from Enum are omitted.]'
  properties:
  - signature: 'UNKNOWN: int'
  - signature: 'SUCCESS: int'
  - signature: 'FAILURE: int'
  omitted_inherited_members_from:
  - Enum
- rank: 719
  id: google.adk.evaluation.common
  name: common
  file_path: google/adk/evaluation/common.py
  type: MODULE
  group: Orphan
  usage_score: 0
- rank: 720
  id: google.adk.evaluation.common.EvalBaseModel
  name: EvalBaseModel
  file_path: google/adk/evaluation/common.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: '[Note: Inherited members from pydantic.BaseModel are omitted.]'
  properties:
  - signature: 'model_config: pydantic.ConfigDict'
  omitted_inherited_members_from:
  - pydantic.BaseModel
- rank: 721
  id: google.adk.evaluation.constants
  name: constants
  file_path: google/adk/evaluation/constants.py
  type: MODULE
  group: Orphan
  usage_score: 0
- rank: 722
  id: google.adk.evaluation.conversation_scenarios
  name: conversation_scenarios
  file_path: google/adk/evaluation/conversation_scenarios.py
  type: MODULE
  group: Orphan
  usage_score: 0
- rank: 723
  id: google.adk.evaluation.conversation_scenarios.ConversationScenario
  name: ConversationScenario
  file_path: google/adk/evaluation/conversation_scenarios.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Scenario for a conversation between a simulated user and the Agent under test.


    [Note: Inherited members from pydantic.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, starting_prompt: str, conversation_plan: str):'
  properties:
  - signature: 'starting_prompt: str'
    docstring: 'Starting prompt for the conversation.


      This prompt acts as the fixed first user message that is given to the Agent.

      Any subsequent user messages are obtained by the system that is simulating the

      user.'
  - signature: 'conversation_plan: str'
    docstring: 'A plan that user simulation system needs to follow as it plays out the conversation.


      Example:

      For a Travel Agent that has tools that let it book a flight and car, a sample

      starting prompt could be:


      `I need to book a flight.`


      A conversation plan could look like:


      First, you want to book a one-way flight from SFO to LAX for next Tuesday.

      You prefer a morning flight and your budget is under $150. If the agent finds

      a valid flight, confirm the booking. Once confirmed, your next goal is to rent

      a standard-size car for three days from the airport. Once both tasks are done,

      your overall goal is complete.'
  inherited_properties:
    EvalBaseModel:
    - signature: 'model_config: pydantic.ConfigDict'
  omitted_inherited_members_from:
  - pydantic.BaseModel
- rank: 724
  id: google.adk.evaluation.conversation_scenarios.ConversationScenarios
  name: ConversationScenarios
  file_path: google/adk/evaluation/conversation_scenarios.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'A simple container for the list of ConversationScenario.


    Mainly serves the purpose of helping with serialization and deserialization.


    [Note: Inherited members from pydantic.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, scenarios: list[google.adk.evaluation.conversation_scenarios.ConversationScenario] = list()):'
  properties:
  - signature: 'scenarios: list[google.adk.evaluation.conversation_scenarios.ConversationScenario]'
  inherited_properties:
    EvalBaseModel:
    - signature: 'model_config: pydantic.ConfigDict'
  omitted_inherited_members_from:
  - pydantic.BaseModel
- rank: 725
  id: google.adk.evaluation.eval_case
  name: eval_case
  file_path: google/adk/evaluation/eval_case.py
  type: MODULE
  group: Orphan
  usage_score: 0
  methods:
  - signature: 'def get_all_tool_calls(intermediate_data: typing.Optional[google.adk.evaluation.eval_case.IntermediateDataType]) -> list[google.genai.types.FunctionCall]:'
    docstring: A utility method to retrieve tools calls from intermediate data.
  - signature: 'def get_all_tool_responses(intermediate_data: typing.Optional[google.adk.evaluation.eval_case.IntermediateDataType]) -> list[google.genai.types.FunctionResponse]:'
    docstring: A utility method to retrieve tools responses from intermediate data.
  - signature: 'def get_all_tool_calls_with_responses(intermediate_data: typing.Optional[google.adk.evaluation.eval_case.IntermediateDataType]) -> list[google.adk.evaluation.eval_case.ToolCallAndResponse]:'
    docstring: Returns tool calls with the corresponding responses, if available.
- rank: 726
  id: google.adk.evaluation.eval_case.EvalCase
  name: EvalCase
  file_path: google/adk/evaluation/eval_case.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'An eval case.


    [Note: Inherited members from pydantic.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, eval_id: str, conversation: typing.Optional[google.adk.evaluation.eval_case.StaticConversation] = None, conversation_scenario: typing.Optional[google.adk.evaluation.conversation_scenarios.ConversationScenario] = None, session_input: typing.Optional[google.adk.evaluation.eval_case.SessionInput] = None, creation_timestamp: float = 0.0, rubrics: typing.Optional[list[google.adk.evaluation.eval_rubrics.Rubric]] = None, final_session_state: typing.Optional[google.adk.evaluation.eval_case.SessionState] = dict()):'
  methods:
  - signature: 'def ensure_conversation_xor_conversation_scenario(self) -> google.adk.evaluation.eval_case.EvalCase:'
  properties:
  - signature: 'eval_id: str'
    docstring: Unique identifier for the evaluation case.
  - signature: 'conversation: typing.Optional[google.adk.evaluation.eval_case.StaticConversation]'
    docstring: "A static conversation between the user and the Agent.\n\n While creating an eval case you should specify either a `conversation` or a\n`conversation_scenario`, but not both."
  - signature: 'conversation_scenario: typing.Optional[google.adk.evaluation.conversation_scenarios.ConversationScenario]'
    docstring: 'A conversation scenario that should be used by a UserSimulator.


      While creating an eval case you should specify either a `conversation` or a

      `conversation_scenario`, but not both.'
  - signature: 'session_input: typing.Optional[google.adk.evaluation.eval_case.SessionInput]'
    docstring: 'Session input that will be passed on to the Agent during eval.

      It is common for Agents state to be initialized to some initial/default value,

      for example, your agent may need to know today''s date.'
  - signature: 'creation_timestamp: float'
    docstring: The time at which this eval case was created.
  - signature: 'rubrics: typing.Optional[list[google.adk.evaluation.eval_rubrics.Rubric]]'
    docstring: A list of rubrics that are applicable to all the invocations in the conversation of this eval case.
  - signature: 'final_session_state: typing.Optional[google.adk.evaluation.eval_case.SessionState]'
    docstring: The expected final session state at the end of the conversation.
  inherited_properties:
    EvalBaseModel:
    - signature: 'model_config: pydantic.ConfigDict'
  omitted_inherited_members_from:
  - pydantic.BaseModel
- rank: 727
  id: google.adk.evaluation.eval_case.EvalCase.ensure_conversation_xor_conversation_scenario
  name: ensure_conversation_xor_conversation_scenario
  file_path: google/adk/evaluation/eval_case.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def ensure_conversation_xor_conversation_scenario(self) -> google.adk.evaluation.eval_case.EvalCase:'
- rank: 728
  id: google.adk.evaluation.eval_case.IntermediateData
  name: IntermediateData
  file_path: google/adk/evaluation/eval_case.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Container for intermediate data that an agent would generate as it responds with a final answer.


    [Note: Inherited members from pydantic.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, tool_uses: list[google.genai.types.FunctionCall] = [], tool_responses: list[google.genai.types.FunctionResponse] = [], intermediate_responses: list[tuple[str, list[google.genai.types.Part]]] = []):'
  properties:
  - signature: 'tool_uses: list[google.genai.types.FunctionCall]'
    docstring: Tool use trajectory in chronological order.
  - signature: 'tool_responses: list[google.genai.types.FunctionResponse]'
    docstring: Tool response trajectory in chronological order.
  - signature: 'intermediate_responses: list[tuple[str, list[google.genai.types.Part]]]'
    docstring: "Intermediate responses generated by sub-agents to convey progress or status\nin a multi-agent system, distinct from the final response.\n\nThis is expressed as a tuple of:\n  - Author: Usually the sub-agent name that generated the intermediate\n    response.\n\n  - A list of Parts that comprise of the response."
  inherited_properties:
    EvalBaseModel:
    - signature: 'model_config: pydantic.ConfigDict'
  omitted_inherited_members_from:
  - pydantic.BaseModel
- rank: 729
  id: google.adk.evaluation.eval_case.Invocation
  name: Invocation
  file_path: google/adk/evaluation/eval_case.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Represents a single invocation.


    [Note: Inherited members from pydantic.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, user_content: google.genai.types.Content, final_response: typing.Optional[google.genai.types.Content] = None, intermediate_data: typing.Optional[google.adk.evaluation.eval_case.IntermediateDataType] = None, creation_timestamp: float = 0.0, rubrics: typing.Optional[list[google.adk.evaluation.eval_rubrics.Rubric]] = None, app_details: typing.Optional[google.adk.evaluation.app_details.AppDetails] = None):'
  properties:
  - signature: 'invocation_id: str'
    docstring: Unique identifier for the invocation.
  - signature: 'user_content: google.genai.types.Content'
    docstring: Content provided by the user in this invocation.
  - signature: 'final_response: typing.Optional[google.genai.types.Content]'
    docstring: Final response from the agent.
  - signature: 'intermediate_data: typing.Optional[google.adk.evaluation.eval_case.IntermediateDataType]'
    docstring: 'Intermediate steps generated as a part of Agent execution.


      For a multi-agent system, it is also helpful to inspect the route that

      the agent took to generate final response.'
  - signature: 'creation_timestamp: float'
    docstring: Timestamp for the current invocation, primarily intended for debugging purposes.
  - signature: 'rubrics: typing.Optional[list[google.adk.evaluation.eval_rubrics.Rubric]]'
    docstring: A list of rubrics that are applicable to only this invocation.
  - signature: 'app_details: typing.Optional[google.adk.evaluation.app_details.AppDetails]'
    docstring: Details about the App that was used for this invocation.
  inherited_properties:
    EvalBaseModel:
    - signature: 'model_config: pydantic.ConfigDict'
  omitted_inherited_members_from:
  - pydantic.BaseModel
- rank: 730
  id: google.adk.evaluation.eval_case.InvocationEvent
  name: InvocationEvent
  file_path: google/adk/evaluation/eval_case.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'An immutable record representing a specific point in the agent''s invocation.


    It captures agent''s replies, requests to use tools (function calls), and tool

    results.


    This structure is a simple projection of the actual `Event` datamodel that

    is intended for the Eval System.


    [Note: Inherited members from pydantic.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, author: str, content: typing.Optional[google.genai.types.Content]):'
  properties:
  - signature: 'author: str'
    docstring: The name of the agent that authored/owned this event.
  - signature: 'content: typing.Optional[google.genai.types.Content]'
    docstring: The content of the event.
  inherited_properties:
    EvalBaseModel:
    - signature: 'model_config: pydantic.ConfigDict'
  omitted_inherited_members_from:
  - pydantic.BaseModel
- rank: 731
  id: google.adk.evaluation.eval_case.InvocationEvents
  name: InvocationEvents
  file_path: google/adk/evaluation/eval_case.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'A container for events that occur during the course of an invocation.


    [Note: Inherited members from pydantic.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, invocation_events: list[google.adk.evaluation.eval_case.InvocationEvent] = list()):'
  properties:
  - signature: 'invocation_events: list[google.adk.evaluation.eval_case.InvocationEvent]'
    docstring: A list of invocation events.
  inherited_properties:
    EvalBaseModel:
    - signature: 'model_config: pydantic.ConfigDict'
  omitted_inherited_members_from:
  - pydantic.BaseModel
- rank: 732
  id: google.adk.evaluation.eval_case.SessionInput
  name: SessionInput
  file_path: google/adk/evaluation/eval_case.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Values that help initialize a Session.


    [Note: Inherited members from pydantic.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, app_name: str, user_id: str, state: google.adk.evaluation.eval_case.SessionState = dict()):'
  properties:
  - signature: 'app_name: str'
    docstring: The name of the app.
  - signature: 'user_id: str'
    docstring: The user id.
  - signature: 'state: google.adk.evaluation.eval_case.SessionState'
    docstring: The state of the session.
  inherited_properties:
    EvalBaseModel:
    - signature: 'model_config: pydantic.ConfigDict'
  omitted_inherited_members_from:
  - pydantic.BaseModel
- rank: 733
  id: google.adk.evaluation.eval_case.get_all_tool_calls
  name: get_all_tool_calls
  file_path: google/adk/evaluation/eval_case.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: A utility method to retrieve tools calls from intermediate data.
  signature: 'def get_all_tool_calls(intermediate_data: typing.Optional[google.adk.evaluation.eval_case.IntermediateDataType]) -> list[google.genai.types.FunctionCall]:'
- rank: 734
  id: google.adk.evaluation.eval_case.get_all_tool_calls_with_responses
  name: get_all_tool_calls_with_responses
  file_path: google/adk/evaluation/eval_case.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: Returns tool calls with the corresponding responses, if available.
  signature: 'def get_all_tool_calls_with_responses(intermediate_data: typing.Optional[google.adk.evaluation.eval_case.IntermediateDataType]) -> list[google.adk.evaluation.eval_case.ToolCallAndResponse]:'
- rank: 735
  id: google.adk.evaluation.eval_case.get_all_tool_responses
  name: get_all_tool_responses
  file_path: google/adk/evaluation/eval_case.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: A utility method to retrieve tools responses from intermediate data.
  signature: 'def get_all_tool_responses(intermediate_data: typing.Optional[google.adk.evaluation.eval_case.IntermediateDataType]) -> list[google.genai.types.FunctionResponse]:'
- rank: 736
  id: google.adk.evaluation.eval_config
  name: eval_config
  file_path: google/adk/evaluation/eval_config.py
  type: MODULE
  group: Orphan
  usage_score: 0
  methods:
  - signature: 'def get_evaluation_criteria_or_default(eval_config_file_path: typing.Optional[str]) -> google.adk.evaluation.eval_config.EvalConfig:'
    docstring: 'Returns EvalConfig read from the config file, if present.


      Otherwise a default one is returned.'
  - signature: 'def get_eval_metrics_from_config(eval_config: google.adk.evaluation.eval_config.EvalConfig) -> list[google.adk.evaluation.eval_metrics.EvalMetric]:'
    docstring: Returns a list of EvalMetrics mapped from the EvalConfig.
- rank: 737
  id: google.adk.evaluation.eval_config.EvalConfig
  name: EvalConfig
  file_path: google/adk/evaluation/eval_config.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Configurations needed to run an Eval.


    Allows users to specify metrics, their thresholds and other properties.


    [Note: Inherited members from pydantic.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, criteria: dict[str, typing.Union[google.adk.evaluation.eval_metrics.Threshold, google.adk.evaluation.eval_metrics.BaseCriterion]] = dict(), user_simulator_config: typing.Optional[google.adk.evaluation.simulation.user_simulator.BaseUserSimulatorConfig] = None):'
  properties:
  - signature: 'model_config: pydantic.ConfigDict'
  - signature: 'criteria: dict[str, typing.Union[google.adk.evaluation.eval_metrics.Threshold, google.adk.evaluation.eval_metrics.BaseCriterion]]'
  - signature: 'user_simulator_config: typing.Optional[google.adk.evaluation.simulation.user_simulator.BaseUserSimulatorConfig]'
  inherited_properties:
    BaseModel:
    - signature: 'model_config: pydantic.ConfigDict'
  omitted_inherited_members_from:
  - pydantic.BaseModel
- rank: 738
  id: google.adk.evaluation.eval_config.get_eval_metrics_from_config
  name: get_eval_metrics_from_config
  file_path: google/adk/evaluation/eval_config.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: Returns a list of EvalMetrics mapped from the EvalConfig.
  signature: 'def get_eval_metrics_from_config(eval_config: google.adk.evaluation.eval_config.EvalConfig) -> list[google.adk.evaluation.eval_metrics.EvalMetric]:'
- rank: 739
  id: google.adk.evaluation.eval_config.get_evaluation_criteria_or_default
  name: get_evaluation_criteria_or_default
  file_path: google/adk/evaluation/eval_config.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: 'Returns EvalConfig read from the config file, if present.


    Otherwise a default one is returned.'
  signature: 'def get_evaluation_criteria_or_default(eval_config_file_path: typing.Optional[str]) -> google.adk.evaluation.eval_config.EvalConfig:'
- rank: 740
  id: google.adk.evaluation.eval_metrics
  name: eval_metrics
  file_path: google/adk/evaluation/eval_metrics.py
  type: MODULE
  group: Orphan
  usage_score: 0
- rank: 741
  id: google.adk.evaluation.eval_metrics.BaseCriterion
  name: BaseCriterion
  file_path: google/adk/evaluation/eval_metrics.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Base criterion to use for an Eval Metric.


    [Note: Inherited members from pydantic.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, threshold: google.adk.evaluation.eval_metrics.Threshold):'
  properties:
  - signature: 'model_config: pydantic.ConfigDict'
  - signature: 'threshold: google.adk.evaluation.eval_metrics.Threshold'
  inherited_properties:
    BaseModel:
    - signature: 'model_config: pydantic.ConfigDict'
  omitted_inherited_members_from:
  - pydantic.BaseModel
- rank: 742
  id: google.adk.evaluation.eval_metrics.EvalMetric
  name: EvalMetric
  file_path: google/adk/evaluation/eval_metrics.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'A metric used to evaluate a particular aspect of an eval case.


    [Note: Inherited members from pydantic.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, metric_name: str, threshold: float, judge_model_options: typing.Optional[google.adk.evaluation.eval_metrics.JudgeModelOptions] = None, criterion: typing.Optional[google.adk.evaluation.eval_metrics.BaseCriterion] = None):'
  properties:
  - signature: 'metric_name: str'
  - signature: 'threshold: float'
  - signature: 'judge_model_options: typing.Optional[google.adk.evaluation.eval_metrics.JudgeModelOptions]'
  - signature: 'criterion: typing.Optional[google.adk.evaluation.eval_metrics.BaseCriterion]'
  inherited_properties:
    EvalBaseModel:
    - signature: 'model_config: pydantic.ConfigDict'
  omitted_inherited_members_from:
  - pydantic.BaseModel
- rank: 743
  id: google.adk.evaluation.eval_metrics.EvalMetricResult
  name: EvalMetricResult
  file_path: google/adk/evaluation/eval_metrics.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'The actual computed score/value of a particular EvalMetric.


    [Note: Inherited members from pydantic.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, metric_name: str, threshold: float, judge_model_options: typing.Optional[google.adk.evaluation.eval_metrics.JudgeModelOptions] = None, criterion: typing.Optional[google.adk.evaluation.eval_metrics.BaseCriterion] = None, score: typing.Optional[float] = None, eval_status: google.adk.evaluation.eval_metrics.EvalStatus, details: google.adk.evaluation.eval_metrics.EvalMetricResultDetails = Factory(EvalMetricResultDetails)):'
  properties:
  - signature: 'score: typing.Optional[float]'
  - signature: 'eval_status: google.adk.evaluation.eval_metrics.EvalStatus'
  - signature: 'details: google.adk.evaluation.eval_metrics.EvalMetricResultDetails'
  inherited_properties:
    EvalMetric:
    - signature: 'metric_name: str'
    - signature: 'threshold: float'
    - signature: 'judge_model_options: typing.Optional[google.adk.evaluation.eval_metrics.JudgeModelOptions]'
    - signature: 'criterion: typing.Optional[google.adk.evaluation.eval_metrics.BaseCriterion]'
    EvalBaseModel:
    - signature: 'model_config: pydantic.ConfigDict'
  omitted_inherited_members_from:
  - pydantic.BaseModel
- rank: 744
  id: google.adk.evaluation.eval_metrics.EvalMetricResultDetails
  name: EvalMetricResultDetails
  file_path: google/adk/evaluation/eval_metrics.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: '[Note: Inherited members from pydantic.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, rubric_scores: typing.Optional[list[google.adk.evaluation.eval_rubrics.RubricScore]] = None):'
  properties:
  - signature: 'rubric_scores: typing.Optional[list[google.adk.evaluation.eval_rubrics.RubricScore]]'
  inherited_properties:
    EvalBaseModel:
    - signature: 'model_config: pydantic.ConfigDict'
  omitted_inherited_members_from:
  - pydantic.BaseModel
- rank: 745
  id: google.adk.evaluation.eval_metrics.EvalMetricResultPerInvocation
  name: EvalMetricResultPerInvocation
  file_path: google/adk/evaluation/eval_metrics.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Eval metric results per invocation.


    [Note: Inherited members from pydantic.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, actual_invocation: google.adk.evaluation.eval_case.Invocation, expected_invocation: typing.Optional[google.adk.evaluation.eval_case.Invocation] = None, eval_metric_results: list[google.adk.evaluation.eval_metrics.EvalMetricResult] = []):'
  properties:
  - signature: 'actual_invocation: google.adk.evaluation.eval_case.Invocation'
  - signature: 'expected_invocation: typing.Optional[google.adk.evaluation.eval_case.Invocation]'
  - signature: 'eval_metric_results: list[google.adk.evaluation.eval_metrics.EvalMetricResult]'
  inherited_properties:
    EvalBaseModel:
    - signature: 'model_config: pydantic.ConfigDict'
  omitted_inherited_members_from:
  - pydantic.BaseModel
- rank: 746
  id: google.adk.evaluation.eval_metrics.EvalStatus
  name: EvalStatus
  file_path: google/adk/evaluation/eval_metrics.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: '[Note: Inherited members from Enum are omitted.]'
  properties:
  - signature: 'PASSED: int'
  - signature: 'FAILED: int'
  - signature: 'NOT_EVALUATED: int'
  omitted_inherited_members_from:
  - Enum
- rank: 747
  id: google.adk.evaluation.eval_metrics.HallucinationsCriterion
  name: HallucinationsCriterion
  file_path: google/adk/evaluation/eval_metrics.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Criterion to use when evaluating agents response for hallucinations.


    [Note: Inherited members from pydantic.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, threshold: google.adk.evaluation.eval_metrics.Threshold, judge_model_options: google.adk.evaluation.eval_metrics.JudgeModelOptions = Factory(JudgeModelOptions), evaluate_intermediate_nl_responses: bool = False):'
  properties:
  - signature: 'judge_model_options: google.adk.evaluation.eval_metrics.JudgeModelOptions'
  - signature: 'evaluate_intermediate_nl_responses: bool'
  inherited_properties:
    BaseCriterion:
    - signature: 'model_config: pydantic.ConfigDict'
    - signature: 'threshold: google.adk.evaluation.eval_metrics.Threshold'
    BaseModel:
    - signature: 'model_config: pydantic.ConfigDict'
  omitted_inherited_members_from:
  - pydantic.BaseModel
- rank: 748
  id: google.adk.evaluation.eval_metrics.Interval
  name: Interval
  file_path: google/adk/evaluation/eval_metrics.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Represents a range of numeric values, e.g. [0 ,1] or (2,3) or [-1, 6).


    [Note: Inherited members from pydantic.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, min_value: float, open_at_min: bool = False, max_value: float, open_at_max: bool = False):'
  properties:
  - signature: 'min_value: float'
  - signature: 'open_at_min: bool'
  - signature: 'max_value: float'
  - signature: 'open_at_max: bool'
  inherited_properties:
    EvalBaseModel:
    - signature: 'model_config: pydantic.ConfigDict'
  omitted_inherited_members_from:
  - pydantic.BaseModel
- rank: 749
  id: google.adk.evaluation.eval_metrics.JudgeModelOptions
  name: JudgeModelOptions
  file_path: google/adk/evaluation/eval_metrics.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Options for an eval metric''s judge model.


    [Note: Inherited members from pydantic.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, judge_model: str = ''gemini-2.5-flash'', judge_model_config: typing.Optional[google.genai.types.GenerateContentConfig] = genai_types.GenerateContentConfig, num_samples: int = 5):'
  properties:
  - signature: 'judge_model: str'
  - signature: 'judge_model_config: typing.Optional[google.genai.types.GenerateContentConfig]'
  - signature: 'num_samples: int'
  inherited_properties:
    EvalBaseModel:
    - signature: 'model_config: pydantic.ConfigDict'
  omitted_inherited_members_from:
  - pydantic.BaseModel
- rank: 750
  id: google.adk.evaluation.eval_metrics.LlmAsAJudgeCriterion
  name: LlmAsAJudgeCriterion
  file_path: google/adk/evaluation/eval_metrics.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Criterion when using LLM-As-A-Judge metric.


    [Note: Inherited members from pydantic.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, threshold: google.adk.evaluation.eval_metrics.Threshold, judge_model_options: google.adk.evaluation.eval_metrics.JudgeModelOptions = Factory(JudgeModelOptions)):'
  properties:
  - signature: 'judge_model_options: google.adk.evaluation.eval_metrics.JudgeModelOptions'
  inherited_properties:
    BaseCriterion:
    - signature: 'model_config: pydantic.ConfigDict'
    - signature: 'threshold: google.adk.evaluation.eval_metrics.Threshold'
    BaseModel:
    - signature: 'model_config: pydantic.ConfigDict'
  omitted_inherited_members_from:
  - pydantic.BaseModel
- rank: 751
  id: google.adk.evaluation.eval_metrics.MatchType
  name: MatchType
  file_path: google/adk/evaluation/eval_metrics.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'The type of Match between actual and expected tool call trajectories.


    [Note: Inherited members from Enum are omitted.]'
  properties:
  - signature: 'EXACT: int'
    docstring: Requires a perfect match between the actual and expected tool calls.
  - signature: 'IN_ORDER: int'
    docstring: "Requires the actual tool calls to be in the same order as expected tools,\nwith allowance for extra tool calls to have happened.\n\nThis criteria is useful in assuring if certain key actions/tool calls\noccur and in certain order, leaving some scope for other tools calls to\nhappen as well.\n\nExample 1: Set of actual vs expected tool calls that satisfies the criteria:\n\n  Expected tools calls: [T1, T2, T3]\n  Actual tool calls: [T1, T1.1, T2, T2.1, T2.2, T3, T3.1]\n\n  This satisfies, as the tools T1, T2 and T3 happened in the \"Actual\" and in\n  the same order.\n\nExample 2: Set of actual vs expected tool calls that don't satisfy the\ncriteria:\n\n  Expected tools calls: [T1, T2, T3, T4]\n  Actual tool calls: [T1, T1.1, T2, T2.1, T2.2, T3, T3.1]\n\n  While the tool calls T1, T2 and T3 happened in the \"Actual\" and in\n  the same order as \"Expected\", but the the tool calls T4 is missing."
  - signature: 'ANY_ORDER: int'
    docstring: "Requires the actual tool calls to be in the any order as expected tools,\nwith allowance for extra tool calls to have happened.\n\nThis criteria is helpful for cases where multiple tool calls about the same\nconcept occur, like your agent issues 5 search queries. You don't really\ncare the order in which the search queries are issues, till they occur.\n\nExample 1: Set of actual vs expected tool calls that satisfies the criteria:\n\n  Expected tools calls: [T1, T2, T3]\n  Actual tool calls: [T2, T2.1, T1, T1.1, T1.2, T3, T3.1]\n\n  This satisfies, as the tools T1, T2 and T3 happened in the \"Actual\" and\n  are also present in expected. Note that the order is different.\n\nExample 2: Set of actual vs expected tool calls that don't satisfy the\ncriteria:\n\n  Expected tools calls: [T1, T2, T3, T4]\n  Actual tool calls: [T1, T1.1, T2, T2.1, T2.2, T3, T3.1]\n\n  While the tool calls T1, T2 and T3 happened in the \"Actual\" and in\n  the same order as \"Expected\", but the the\
      \ tool calls T4 is missing."
  omitted_inherited_members_from:
  - Enum
- rank: 752
  id: google.adk.evaluation.eval_metrics.MetricInfo
  name: MetricInfo
  file_path: google/adk/evaluation/eval_metrics.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Information about the metric that are used for Evals.


    [Note: Inherited members from pydantic.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, metric_name: str, description: str = None, metric_value_info: google.adk.evaluation.eval_metrics.MetricValueInfo):'
  properties:
  - signature: 'metric_name: str'
  - signature: 'description: str'
  - signature: 'metric_value_info: google.adk.evaluation.eval_metrics.MetricValueInfo'
  inherited_properties:
    EvalBaseModel:
    - signature: 'model_config: pydantic.ConfigDict'
  omitted_inherited_members_from:
  - pydantic.BaseModel
- rank: 753
  id: google.adk.evaluation.eval_metrics.MetricValueInfo
  name: MetricValueInfo
  file_path: google/adk/evaluation/eval_metrics.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Information about the type of metric value.


    [Note: Inherited members from pydantic.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, interval: typing.Optional[google.adk.evaluation.eval_metrics.Interval] = None):'
  properties:
  - signature: 'interval: typing.Optional[google.adk.evaluation.eval_metrics.Interval]'
  inherited_properties:
    EvalBaseModel:
    - signature: 'model_config: pydantic.ConfigDict'
  omitted_inherited_members_from:
  - pydantic.BaseModel
- rank: 754
  id: google.adk.evaluation.eval_metrics.PrebuiltMetrics
  name: PrebuiltMetrics
  file_path: google/adk/evaluation/eval_metrics.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: '[Note: Inherited members from Enum are omitted.]'
  properties:
  - signature: 'TOOL_TRAJECTORY_AVG_SCORE: str'
  - signature: 'RESPONSE_EVALUATION_SCORE: str'
  - signature: 'RESPONSE_MATCH_SCORE: str'
  - signature: 'SAFETY_V1: str'
  - signature: 'FINAL_RESPONSE_MATCH_V2: str'
  - signature: 'RUBRIC_BASED_FINAL_RESPONSE_QUALITY_V1: str'
  - signature: 'HALLUCINATIONS_V1: str'
  - signature: 'RUBRIC_BASED_TOOL_USE_QUALITY_V1: str'
  omitted_inherited_members_from:
  - Enum
- rank: 755
  id: google.adk.evaluation.eval_metrics.RubricsBasedCriterion
  name: RubricsBasedCriterion
  file_path: google/adk/evaluation/eval_metrics.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Criterion when using a rubric based metric.


    [Note: Inherited members from pydantic.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, threshold: google.adk.evaluation.eval_metrics.Threshold, judge_model_options: google.adk.evaluation.eval_metrics.JudgeModelOptions = Factory(JudgeModelOptions), rubrics: list[google.adk.evaluation.eval_rubrics.Rubric] = list()):'
  properties:
  - signature: 'judge_model_options: google.adk.evaluation.eval_metrics.JudgeModelOptions'
  - signature: 'rubrics: list[google.adk.evaluation.eval_rubrics.Rubric]'
  inherited_properties:
    BaseCriterion:
    - signature: 'model_config: pydantic.ConfigDict'
    - signature: 'threshold: google.adk.evaluation.eval_metrics.Threshold'
    BaseModel:
    - signature: 'model_config: pydantic.ConfigDict'
  omitted_inherited_members_from:
  - pydantic.BaseModel
- rank: 756
  id: google.adk.evaluation.eval_metrics.ToolTrajectoryCriterion
  name: ToolTrajectoryCriterion
  file_path: google/adk/evaluation/eval_metrics.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Criterion to use when evaluating agent''s tool trajectories with a reference one.


    [Note: Inherited members from pydantic.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, threshold: google.adk.evaluation.eval_metrics.Threshold, match_type: MatchType = MatchType.EXACT):'
  properties:
  - signature: 'match_type: MatchType'
  inherited_properties:
    BaseCriterion:
    - signature: 'model_config: pydantic.ConfigDict'
    - signature: 'threshold: google.adk.evaluation.eval_metrics.Threshold'
    BaseModel:
    - signature: 'model_config: pydantic.ConfigDict'
  omitted_inherited_members_from:
  - pydantic.BaseModel
- rank: 757
  id: google.adk.evaluation.eval_result
  name: eval_result
  file_path: google/adk/evaluation/eval_result.py
  type: MODULE
  group: Orphan
  usage_score: 0
- rank: 758
  id: google.adk.evaluation.eval_result.EvalCaseResult
  name: EvalCaseResult
  file_path: google/adk/evaluation/eval_result.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Case level evaluation results.


    [Note: Inherited members from pydantic.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, eval_set_file: typing.Optional[str] = None, eval_set_id: str = '''', eval_id: str = '''', final_eval_status: google.adk.evaluation.evaluator.EvalStatus, eval_metric_results: typing.Optional[list[tuple[google.adk.evaluation.eval_metrics.EvalMetric, google.adk.evaluation.eval_metrics.EvalMetricResult]]] = None, overall_eval_metric_results: list[google.adk.evaluation.eval_metrics.EvalMetricResult], eval_metric_result_per_invocation: list[google.adk.evaluation.eval_metrics.EvalMetricResultPerInvocation], session_id: str, session_details: typing.Optional[google.adk.sessions.session.Session] = None, user_id: typing.Optional[str] = None):'
  properties:
  - signature: 'model_config: pydantic.ConfigDict'
  - signature: 'eval_set_file: typing.Optional[str]'
  - signature: 'eval_set_id: str'
    docstring: The eval set id.
  - signature: 'eval_id: str'
    docstring: The eval case id.
  - signature: 'final_eval_status: google.adk.evaluation.evaluator.EvalStatus'
    docstring: Final eval status for this eval case.
  - signature: 'eval_metric_results: typing.Optional[list[tuple[google.adk.evaluation.eval_metrics.EvalMetric, google.adk.evaluation.eval_metrics.EvalMetricResult]]]'
  - signature: 'overall_eval_metric_results: list[google.adk.evaluation.eval_metrics.EvalMetricResult]'
    docstring: Overall result for each metric for the entire eval case.
  - signature: 'eval_metric_result_per_invocation: list[google.adk.evaluation.eval_metrics.EvalMetricResultPerInvocation]'
    docstring: Result for each metric on a per invocation basis.
  - signature: 'session_id: str'
    docstring: Session id of the session generated as result of inferencing/scraping stage of the eval.
  - signature: 'session_details: typing.Optional[google.adk.sessions.session.Session]'
    docstring: Session generated as result of inferencing/scraping stage of the eval.
  - signature: 'user_id: typing.Optional[str]'
    docstring: User id used during inferencing/scraping stage of the eval.
  inherited_properties:
    BaseModel:
    - signature: 'model_config: pydantic.ConfigDict'
  omitted_inherited_members_from:
  - pydantic.BaseModel
- rank: 759
  id: google.adk.evaluation.eval_result.EvalSetResult
  name: EvalSetResult
  file_path: google/adk/evaluation/eval_result.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Eval set level evaluation results.


    [Note: Inherited members from pydantic.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, eval_set_result_id: str, eval_set_result_name: typing.Optional[str] = None, eval_set_id: str, eval_case_results: list[google.adk.evaluation.eval_result.EvalCaseResult] = list(), creation_timestamp: float = 0.0):'
  properties:
  - signature: 'model_config: pydantic.ConfigDict'
  - signature: 'eval_set_result_id: str'
  - signature: 'eval_set_result_name: typing.Optional[str]'
  - signature: 'eval_set_id: str'
  - signature: 'eval_case_results: list[google.adk.evaluation.eval_result.EvalCaseResult]'
  - signature: 'creation_timestamp: float'
  inherited_properties:
    BaseModel:
    - signature: 'model_config: pydantic.ConfigDict'
  omitted_inherited_members_from:
  - pydantic.BaseModel
- rank: 760
  id: google.adk.evaluation.eval_rubrics
  name: eval_rubrics
  file_path: google/adk/evaluation/eval_rubrics.py
  type: MODULE
  group: Orphan
  usage_score: 0
- rank: 761
  id: google.adk.evaluation.eval_rubrics.Rubric
  name: Rubric
  file_path: google/adk/evaluation/eval_rubrics.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'This class represents a single Rubric.


    [Note: Inherited members from pydantic.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, rubric_id: str, rubric_content: google.adk.evaluation.eval_rubrics.RubricContent, description: typing.Optional[str] = None, type: typing.Optional[str] = None):'
  properties:
  - signature: 'rubric_id: str'
  - signature: 'rubric_content: google.adk.evaluation.eval_rubrics.RubricContent'
  - signature: 'description: typing.Optional[str]'
  - signature: 'type: typing.Optional[str]'
  inherited_properties:
    EvalBaseModel:
    - signature: 'model_config: pydantic.ConfigDict'
  omitted_inherited_members_from:
  - pydantic.BaseModel
- rank: 762
  id: google.adk.evaluation.eval_rubrics.RubricContent
  name: RubricContent
  file_path: google/adk/evaluation/eval_rubrics.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'The content of a rubric.


    [Note: Inherited members from pydantic.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, text_property: typing.Optional[str]):'
  properties:
  - signature: 'text_property: typing.Optional[str]'
  inherited_properties:
    EvalBaseModel:
    - signature: 'model_config: pydantic.ConfigDict'
  omitted_inherited_members_from:
  - pydantic.BaseModel
- rank: 763
  id: google.adk.evaluation.eval_rubrics.RubricScore
  name: RubricScore
  file_path: google/adk/evaluation/eval_rubrics.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'The score obtained after applying the rubric to the Agent''s response.


    [Note: Inherited members from pydantic.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, rubric_id: str, rationale: typing.Optional[str] = None, score: typing.Optional[float] = None):'
  properties:
  - signature: 'rubric_id: str'
  - signature: 'rationale: typing.Optional[str]'
  - signature: 'score: typing.Optional[float]'
  inherited_properties:
    EvalBaseModel:
    - signature: 'model_config: pydantic.ConfigDict'
  omitted_inherited_members_from:
  - pydantic.BaseModel
- rank: 764
  id: google.adk.evaluation.eval_set
  name: eval_set
  file_path: google/adk/evaluation/eval_set.py
  type: MODULE
  group: Orphan
  usage_score: 0
- rank: 765
  id: google.adk.evaluation.eval_set.EvalSet
  name: EvalSet
  file_path: google/adk/evaluation/eval_set.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'A set of eval cases.


    [Note: Inherited members from pydantic.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, eval_set_id: str, name: typing.Optional[str] = None, description: typing.Optional[str] = None, eval_cases: list[google.adk.evaluation.eval_case.EvalCase], creation_timestamp: float = 0.0):'
  properties:
  - signature: 'eval_set_id: str'
    docstring: Unique identifier for the eval set.
  - signature: 'name: typing.Optional[str]'
    docstring: Name of the dataset.
  - signature: 'description: typing.Optional[str]'
    docstring: Description of the dataset.
  - signature: 'eval_cases: list[google.adk.evaluation.eval_case.EvalCase]'
    docstring: 'List of eval cases in the dataset. Each case represents a single

      interaction to be evaluated.'
  - signature: 'creation_timestamp: float'
    docstring: The time at which this eval set was created.
  inherited_properties:
    BaseModel:
    - signature: 'model_config: pydantic.ConfigDict'
  omitted_inherited_members_from:
  - pydantic.BaseModel
- rank: 766
  id: google.adk.evaluation.eval_set_results_manager
  name: eval_set_results_manager
  file_path: google/adk/evaluation/eval_set_results_manager.py
  type: MODULE
  group: Orphan
  usage_score: 0
- rank: 767
  id: google.adk.evaluation.eval_set_results_manager.EvalSetResultsManager
  name: EvalSetResultsManager
  file_path: google/adk/evaluation/eval_set_results_manager.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'An interface to manage Eval Set Results.


    [Note: Inherited members from ABC are omitted.]'
  methods:
  - signature: 'def save_eval_set_result(self, app_name: str, eval_set_id: str, eval_case_results: list[google.adk.evaluation.eval_result.EvalCaseResult]) -> None:'
    docstring: Creates and saves a new EvalSetResult given eval_case_results.
  - signature: 'def get_eval_set_result(self, app_name: str, eval_set_result_id: str) -> google.adk.evaluation.eval_result.EvalSetResult:'
    docstring: "Returns the EvalSetResult from app_name and eval_set_result_id.\n\nRaises:\n  NotFoundError: If the EvalSetResult is not found."
  - signature: 'def list_eval_set_results(self, app_name: str) -> list[str]:'
    docstring: Returns the eval result ids that belong to the given app_name.
  omitted_inherited_members_from:
  - ABC
- rank: 768
  id: google.adk.evaluation.eval_set_results_manager.EvalSetResultsManager.get_eval_set_result
  name: get_eval_set_result
  file_path: google/adk/evaluation/eval_set_results_manager.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Returns the EvalSetResult from app_name and eval_set_result_id.\n\nRaises:\n  NotFoundError: If the EvalSetResult is not found."
  signature: 'def get_eval_set_result(self, app_name: str, eval_set_result_id: str) -> google.adk.evaluation.eval_result.EvalSetResult:'
- rank: 769
  id: google.adk.evaluation.eval_set_results_manager.EvalSetResultsManager.save_eval_set_result
  name: save_eval_set_result
  file_path: google/adk/evaluation/eval_set_results_manager.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: Creates and saves a new EvalSetResult given eval_case_results.
  signature: 'def save_eval_set_result(self, app_name: str, eval_set_id: str, eval_case_results: list[google.adk.evaluation.eval_result.EvalCaseResult]) -> None:'
- rank: 770
  id: google.adk.evaluation.eval_sets_manager
  name: eval_sets_manager
  file_path: google/adk/evaluation/eval_sets_manager.py
  type: MODULE
  group: Orphan
  usage_score: 0
- rank: 771
  id: google.adk.evaluation.eval_sets_manager.EvalSetsManager
  name: EvalSetsManager
  file_path: google/adk/evaluation/eval_sets_manager.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'An interface to manage Eval Sets.


    [Note: Inherited members from ABC are omitted.]'
  methods:
  - signature: 'def get_eval_set(self, app_name: str, eval_set_id: str) -> typing.Optional[google.adk.evaluation.eval_set.EvalSet]:'
    docstring: Returns an EvalSet identified by an app_name and eval_set_id.
  - signature: 'def create_eval_set(self, app_name: str, eval_set_id: str) -> google.adk.evaluation.eval_set.EvalSet:'
    docstring: "Creates and returns an empty EvalSet given the app_name and eval_set_id.\n\nRaises:\n  ValueError: If eval set id is not valid or an eval set already exists. A\n  valid eval set id is string that has one or more of following characters:\n    - Lower case characters\n    - Upper case characters\n    - 0-9\n    - Underscore"
  - signature: 'def list_eval_sets(self, app_name: str) -> list[str]:'
    docstring: "Returns a list of EvalSets that belong to the given app_name.\n\nRaises:\n  NotFoundError: If the app_name doesn't exist."
  - signature: 'def get_eval_case(self, app_name: str, eval_set_id: str, eval_case_id: str) -> typing.Optional[google.adk.evaluation.eval_case.EvalCase]:'
    docstring: Returns an EvalCase if found; otherwise, None.
  - signature: 'def add_eval_case(self, app_name: str, eval_set_id: str, eval_case: google.adk.evaluation.eval_case.EvalCase):'
    docstring: "Adds the given EvalCase to an existing EvalSet identified by app_name and eval_set_id.\n\nRaises:\n  NotFoundError: If the eval set is not found."
  - signature: 'def update_eval_case(self, app_name: str, eval_set_id: str, updated_eval_case: google.adk.evaluation.eval_case.EvalCase):'
    docstring: "Updates an existing EvalCase give the app_name and eval_set_id.\n\nRaises:\n  NotFoundError: If the eval set or the eval case is not found."
  - signature: 'def delete_eval_case(self, app_name: str, eval_set_id: str, eval_case_id: str):'
    docstring: "Deletes the given EvalCase identified by app_name, eval_set_id and eval_case_id.\n\nRaises:\n  NotFoundError: If the eval set or the eval case to delete is not found."
  omitted_inherited_members_from:
  - ABC
- rank: 772
  id: google.adk.evaluation.eval_sets_manager.EvalSetsManager.add_eval_case
  name: add_eval_case
  file_path: google/adk/evaluation/eval_sets_manager.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Adds the given EvalCase to an existing EvalSet identified by app_name and eval_set_id.\n\nRaises:\n  NotFoundError: If the eval set is not found."
  signature: 'def add_eval_case(self, app_name: str, eval_set_id: str, eval_case: google.adk.evaluation.eval_case.EvalCase):'
- rank: 773
  id: google.adk.evaluation.eval_sets_manager.EvalSetsManager.create_eval_set
  name: create_eval_set
  file_path: google/adk/evaluation/eval_sets_manager.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Creates and returns an empty EvalSet given the app_name and eval_set_id.\n\nRaises:\n  ValueError: If eval set id is not valid or an eval set already exists. A\n  valid eval set id is string that has one or more of following characters:\n    - Lower case characters\n    - Upper case characters\n    - 0-9\n    - Underscore"
  signature: 'def create_eval_set(self, app_name: str, eval_set_id: str) -> google.adk.evaluation.eval_set.EvalSet:'
- rank: 774
  id: google.adk.evaluation.eval_sets_manager.EvalSetsManager.delete_eval_case
  name: delete_eval_case
  file_path: google/adk/evaluation/eval_sets_manager.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Deletes the given EvalCase identified by app_name, eval_set_id and eval_case_id.\n\nRaises:\n  NotFoundError: If the eval set or the eval case to delete is not found."
  signature: 'def delete_eval_case(self, app_name: str, eval_set_id: str, eval_case_id: str):'
- rank: 775
  id: google.adk.evaluation.eval_sets_manager.EvalSetsManager.get_eval_case
  name: get_eval_case
  file_path: google/adk/evaluation/eval_sets_manager.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: Returns an EvalCase if found; otherwise, None.
  signature: 'def get_eval_case(self, app_name: str, eval_set_id: str, eval_case_id: str) -> typing.Optional[google.adk.evaluation.eval_case.EvalCase]:'
- rank: 776
  id: google.adk.evaluation.eval_sets_manager.EvalSetsManager.list_eval_sets
  name: list_eval_sets
  file_path: google/adk/evaluation/eval_sets_manager.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Returns a list of EvalSets that belong to the given app_name.\n\nRaises:\n  NotFoundError: If the app_name doesn't exist."
  signature: 'def list_eval_sets(self, app_name: str) -> list[str]:'
- rank: 777
  id: google.adk.evaluation.eval_sets_manager.EvalSetsManager.update_eval_case
  name: update_eval_case
  file_path: google/adk/evaluation/eval_sets_manager.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Updates an existing EvalCase give the app_name and eval_set_id.\n\nRaises:\n  NotFoundError: If the eval set or the eval case is not found."
  signature: 'def update_eval_case(self, app_name: str, eval_set_id: str, updated_eval_case: google.adk.evaluation.eval_case.EvalCase):'
- rank: 778
  id: google.adk.evaluation.evaluation_constants
  name: evaluation_constants
  file_path: google/adk/evaluation/evaluation_constants.py
  type: MODULE
  group: Orphan
  usage_score: 0
- rank: 779
  id: google.adk.evaluation.evaluation_constants.EvalConstants
  name: EvalConstants
  file_path: google/adk/evaluation/evaluation_constants.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: Holds constants for evaluation file constants.
  properties:
  - signature: 'QUERY: str'
  - signature: 'EXPECTED_TOOL_USE: str'
  - signature: 'RESPONSE: str'
  - signature: 'REFERENCE: str'
  - signature: 'TOOL_NAME: str'
  - signature: 'TOOL_INPUT: str'
  - signature: 'MOCK_TOOL_OUTPUT: str'
- rank: 780
  id: google.adk.evaluation.evaluation_generator
  name: evaluation_generator
  file_path: google/adk/evaluation/evaluation_generator.py
  type: MODULE
  group: Orphan
  usage_score: 0
- rank: 781
  id: google.adk.evaluation.evaluation_generator.EvalCaseResponses
  name: EvalCaseResponses
  file_path: google/adk/evaluation/evaluation_generator.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Contains multiple responses associated with an EvalCase.


    Multiple responses are a result of repeated requests to generate inferences.


    [Note: Inherited members from pydantic.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, eval_case: google.adk.evaluation.eval_case.EvalCase, responses: list[list[google.adk.evaluation.eval_case.Invocation]]):'
  properties:
  - signature: 'eval_case: google.adk.evaluation.eval_case.EvalCase'
  - signature: 'responses: list[list[google.adk.evaluation.eval_case.Invocation]]'
  inherited_properties:
    BaseModel:
    - signature: 'model_config: pydantic.ConfigDict'
  omitted_inherited_members_from:
  - pydantic.BaseModel
- rank: 782
  id: google.adk.evaluation.evaluation_generator.EvaluationGenerator
  name: EvaluationGenerator
  file_path: google/adk/evaluation/evaluation_generator.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: Generates evaluation responses for agents.
  methods:
  - signature: 'def generate_responses(eval_set: google.adk.evaluation.eval_set.EvalSet, agent_module_path: str, repeat_num: int, agent_name: str) -> list[google.adk.evaluation.evaluation_generator.EvalCaseResponses]:'
    docstring: "Returns evaluation responses for the given dataset and agent.\n\nArgs:\n  eval_set: The eval set that needs to be scraped for responses.\n  agent_module_path: Path to the module that contains the root agent.\n  repeat_num: Number of time the eval dataset should be repeated. This is\n    usually done to remove uncertainty that a single run may bring.\n  agent_name: The name of the agent that should be evaluated. This is\n    usually the sub-agent."
  - signature: 'def generate_responses_from_session(session_path, eval_dataset):'
    docstring: "Returns evaluation responses by combining session data with eval data.\n\nArgs:\n  session_path: Path to a json file that contains session data.\n  eval_dataset: The eval data set that should be combined with the session\n    data."
  - signature: 'def convert_events_to_eval_invocations(events: list[google.adk.events.event.Event], app_details_per_invocation: typing.Optional[dict[str, google.adk.evaluation.app_details.AppDetails]]) -> list[google.adk.evaluation.eval_case.Invocation]:'
    docstring: Converts a list of events to eval invocations.
- rank: 783
  id: google.adk.evaluation.evaluation_generator.EvaluationGenerator.convert_events_to_eval_invocations
  name: convert_events_to_eval_invocations
  file_path: google/adk/evaluation/evaluation_generator.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: Converts a list of events to eval invocations.
  signature: 'def convert_events_to_eval_invocations(events: list[google.adk.events.event.Event], app_details_per_invocation: typing.Optional[dict[str, google.adk.evaluation.app_details.AppDetails]]) -> list[google.adk.evaluation.eval_case.Invocation]:'
- rank: 784
  id: google.adk.evaluation.evaluation_generator.EvaluationGenerator.generate_responses
  name: generate_responses
  file_path: google/adk/evaluation/evaluation_generator.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Returns evaluation responses for the given dataset and agent.\n\nArgs:\n  eval_set: The eval set that needs to be scraped for responses.\n  agent_module_path: Path to the module that contains the root agent.\n  repeat_num: Number of time the eval dataset should be repeated. This is\n    usually done to remove uncertainty that a single run may bring.\n  agent_name: The name of the agent that should be evaluated. This is\n    usually the sub-agent."
  signature: 'def generate_responses(eval_set: google.adk.evaluation.eval_set.EvalSet, agent_module_path: str, repeat_num: int, agent_name: str) -> list[google.adk.evaluation.evaluation_generator.EvalCaseResponses]:'
- rank: 785
  id: google.adk.evaluation.evaluation_generator.EvaluationGenerator.generate_responses_from_session
  name: generate_responses_from_session
  file_path: google/adk/evaluation/evaluation_generator.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Returns evaluation responses by combining session data with eval data.\n\nArgs:\n  session_path: Path to a json file that contains session data.\n  eval_dataset: The eval data set that should be combined with the session\n    data."
  signature: 'def generate_responses_from_session(session_path, eval_dataset):'
- rank: 786
  id: google.adk.evaluation.evaluator
  name: evaluator
  file_path: google/adk/evaluation/evaluator.py
  type: MODULE
  group: Orphan
  usage_score: 0
- rank: 787
  id: google.adk.evaluation.evaluator.EvaluationResult
  name: EvaluationResult
  file_path: google/adk/evaluation/evaluator.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: '[Note: Inherited members from pydantic.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, overall_score: typing.Optional[float] = None, overall_eval_status: google.adk.evaluation.eval_metrics.EvalStatus = EvalStatus.NOT_EVALUATED, per_invocation_results: list[google.adk.evaluation.evaluator.PerInvocationResult] = [], overall_rubric_scores: typing.Optional[list[google.adk.evaluation.eval_rubrics.RubricScore]] = None):'
  properties:
  - signature: 'overall_score: typing.Optional[float]'
    docstring: Overall score, based on each invocation.
  - signature: 'overall_eval_status: google.adk.evaluation.eval_metrics.EvalStatus'
    docstring: Overall status, based on each invocation.
  - signature: 'per_invocation_results: list[google.adk.evaluation.evaluator.PerInvocationResult]'
    docstring: Detailed results per invocation.
  - signature: 'overall_rubric_scores: typing.Optional[list[google.adk.evaluation.eval_rubrics.RubricScore]]'
    docstring: Overall rubric, based on each invocation.
  inherited_properties:
    BaseModel:
    - signature: 'model_config: pydantic.ConfigDict'
  omitted_inherited_members_from:
  - pydantic.BaseModel
- rank: 788
  id: google.adk.evaluation.evaluator.Evaluator
  name: Evaluator
  file_path: google/adk/evaluation/evaluator.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'A metrics evaluator interface.


    [Note: Inherited members from ABC are omitted.]'
  methods:
  - signature: 'def evaluate_invocations(self, actual_invocations: list[google.adk.evaluation.eval_case.Invocation], expected_invocations: typing.Optional[list[google.adk.evaluation.eval_case.Invocation]]) -> google.adk.evaluation.evaluator.EvaluationResult:'
    docstring: "Returns EvaluationResult after performing evaluations using actual and expected invocations.\n\nArgs:\n  actual_invocations: These are the invocations that are obtained from the\n    agent under test.\n  expected_invocations: An optional list of invocations, if specified,\n    usually act as a benchmark/golden response. If these are specified\n    usually the expectation is that the length of this list and actual\n    invocation is the same."
  properties:
  - signature: 'criterion_type: typing.ClassVar[type[google.adk.evaluation.eval_metrics.BaseCriterion]]'
  omitted_inherited_members_from:
  - ABC
- rank: 789
  id: google.adk.evaluation.evaluator.Evaluator.evaluate_invocations
  name: evaluate_invocations
  file_path: google/adk/evaluation/evaluator.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Returns EvaluationResult after performing evaluations using actual and expected invocations.\n\nArgs:\n  actual_invocations: These are the invocations that are obtained from the\n    agent under test.\n  expected_invocations: An optional list of invocations, if specified,\n    usually act as a benchmark/golden response. If these are specified\n    usually the expectation is that the length of this list and actual\n    invocation is the same."
  signature: 'def evaluate_invocations(self, actual_invocations: list[google.adk.evaluation.eval_case.Invocation], expected_invocations: typing.Optional[list[google.adk.evaluation.eval_case.Invocation]]) -> google.adk.evaluation.evaluator.EvaluationResult:'
- rank: 790
  id: google.adk.evaluation.evaluator.PerInvocationResult
  name: PerInvocationResult
  file_path: google/adk/evaluation/evaluator.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Metric evaluation score per invocation.


    [Note: Inherited members from pydantic.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, actual_invocation: google.adk.evaluation.eval_case.Invocation, expected_invocation: typing.Optional[google.adk.evaluation.eval_case.Invocation] = None, score: typing.Optional[float] = None, eval_status: google.adk.evaluation.eval_metrics.EvalStatus = EvalStatus.NOT_EVALUATED, rubric_scores: typing.Optional[list[google.adk.evaluation.eval_rubrics.RubricScore]] = None):'
  properties:
  - signature: 'actual_invocation: google.adk.evaluation.eval_case.Invocation'
  - signature: 'expected_invocation: typing.Optional[google.adk.evaluation.eval_case.Invocation]'
  - signature: 'score: typing.Optional[float]'
  - signature: 'eval_status: google.adk.evaluation.eval_metrics.EvalStatus'
  - signature: 'rubric_scores: typing.Optional[list[google.adk.evaluation.eval_rubrics.RubricScore]]'
  inherited_properties:
    BaseModel:
    - signature: 'model_config: pydantic.ConfigDict'
  omitted_inherited_members_from:
  - pydantic.BaseModel
- rank: 791
  id: google.adk.evaluation.final_response_match_v1
  name: final_response_match_v1
  file_path: google/adk/evaluation/final_response_match_v1.py
  type: MODULE
  group: Orphan
  usage_score: 0
- rank: 792
  id: google.adk.evaluation.final_response_match_v1.RougeEvaluator
  name: RougeEvaluator
  file_path: google/adk/evaluation/final_response_match_v1.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Evaluates if agent''s final response matches a golden/expected final response using Rouge_1 metric.


    Value range for this metric is [0,1], with values closer to 1 more desirable.


    [Note: Inherited members from ABC are omitted.]'
  constructor_signature: 'def __init__(self, eval_metric: google.adk.evaluation.eval_metrics.EvalMetric):'
  methods:
  - signature: 'def get_metric_info() -> google.adk.evaluation.eval_metrics.MetricInfo:'
  - signature: 'def evaluate_invocations(self, actual_invocations: list[google.adk.evaluation.eval_case.Invocation], expected_invocations: typing.Optional[list[google.adk.evaluation.eval_case.Invocation]]) -> google.adk.evaluation.evaluator.EvaluationResult:'
  inherited_methods:
    Evaluator:
    - signature: 'def evaluate_invocations(self, actual_invocations: list[google.adk.evaluation.eval_case.Invocation], expected_invocations: typing.Optional[list[google.adk.evaluation.eval_case.Invocation]]) -> google.adk.evaluation.evaluator.EvaluationResult:'
      docstring: "Returns EvaluationResult after performing evaluations using actual and expected invocations.\n\nArgs:\n  actual_invocations: These are the invocations that are obtained from the\n    agent under test.\n  expected_invocations: An optional list of invocations, if specified,\n    usually act as a benchmark/golden response. If these are specified\n    usually the expectation is that the length of this list and actual\n    invocation is the same."
  inherited_properties:
    Evaluator:
    - signature: 'criterion_type: typing.ClassVar[type[google.adk.evaluation.eval_metrics.BaseCriterion]]'
  omitted_inherited_members_from:
  - ABC
- rank: 793
  id: google.adk.evaluation.final_response_match_v1.RougeEvaluator.evaluate_invocations
  name: evaluate_invocations
  file_path: google/adk/evaluation/final_response_match_v1.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def evaluate_invocations(self, actual_invocations: list[google.adk.evaluation.eval_case.Invocation], expected_invocations: typing.Optional[list[google.adk.evaluation.eval_case.Invocation]]) -> google.adk.evaluation.evaluator.EvaluationResult:'
- rank: 794
  id: google.adk.evaluation.final_response_match_v1.RougeEvaluator.get_metric_info
  name: get_metric_info
  file_path: google/adk/evaluation/final_response_match_v1.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def get_metric_info() -> google.adk.evaluation.eval_metrics.MetricInfo:'
- rank: 795
  id: google.adk.evaluation.final_response_match_v2
  name: final_response_match_v2
  file_path: google/adk/evaluation/final_response_match_v2.py
  type: MODULE
  group: Orphan
  usage_score: 0
- rank: 796
  id: google.adk.evaluation.final_response_match_v2.FinalResponseMatchV2Evaluator
  name: FinalResponseMatchV2Evaluator
  file_path: google/adk/evaluation/final_response_match_v2.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'V2 final response match evaluator which uses an LLM to judge responses.


    The evaluator prompts the LLM to output whether the agent final response is

    valid or invalid, hence outputs a score of 0 or 1. Repeated invocation samples

    are aggregated by taking majority vote, and then the overall score is the

    fraction, ranging from 0 to 1, of valid samples. Higher values of overall

    score indicate better final response performance of the agent.


    [Note: Inherited members from ABC are omitted.]'
  constructor_signature: 'def __init__(self, eval_metric: google.adk.evaluation.eval_metrics.EvalMetric):'
  methods:
  - signature: 'def get_metric_info() -> google.adk.evaluation.eval_metrics.MetricInfo:'
  - signature: 'def format_auto_rater_prompt(self, actual_invocation: google.adk.evaluation.eval_case.Invocation, expected_invocation: typing.Optional[google.adk.evaluation.eval_case.Invocation]) -> str:'
  - signature: 'def convert_auto_rater_response_to_score(self, llm_response: google.adk.models.llm_response.LlmResponse) -> google.adk.evaluation.llm_as_judge.AutoRaterScore:'
  - signature: 'def aggregate_per_invocation_samples(self, per_invocation_samples: list[google.adk.evaluation.evaluator.PerInvocationResult]) -> google.adk.evaluation.evaluator.PerInvocationResult:'
    docstring: "Aggregates samples of per-invocation results by taking majority vote.\n\nOnly consider results that were successfully evaluated. In the case of a\ntie, consider the result to be invalid.\n\nArgs:\n  per_invocation_samples: Samples of per-invocation results to aggregate.\n\nReturns:\n  If there is a majority of valid results, return the first valid result.\n  Otherwise, return the first invalid result. If no results were\n  successfully evaluated, return the first sample."
  - signature: 'def aggregate_invocation_results(self, per_invocation_results: list[google.adk.evaluation.evaluator.PerInvocationResult]) -> google.adk.evaluation.evaluator.EvaluationResult:'
    docstring: Computes the fraction of invocation results that are valid.
  properties:
  - signature: 'criterion_type: typing.ClassVar[type[google.adk.evaluation.eval_metrics.LlmAsAJudgeCriterion]]'
  inherited_methods:
    LlmAsJudge:
    - signature: 'def format_auto_rater_prompt(self, actual: google.adk.evaluation.eval_case.Invocation, expected: typing.Optional[google.adk.evaluation.eval_case.Invocation]) -> str:'
      docstring: Formats the auto-rater prompt to evaluate the given invocation.
    - signature: 'def convert_auto_rater_response_to_score(self, auto_rater_response: google.adk.models.llm_response.LlmResponse) -> google.adk.evaluation.llm_as_judge.AutoRaterScore:'
      docstring: Parses auto_rater_response and returns the corresponding score, or None if the score cannot be determined.
    - signature: 'def aggregate_per_invocation_samples(self, per_invocation_samples: list[google.adk.evaluation.evaluator.PerInvocationResult]) -> google.adk.evaluation.evaluator.PerInvocationResult:'
      docstring: Aggregates repeated per-invocation samples to get the final result for the invocation.
    - signature: 'def aggregate_invocation_results(self, per_invocation_results: list[google.adk.evaluation.evaluator.PerInvocationResult]) -> google.adk.evaluation.evaluator.EvaluationResult:'
      docstring: Aggregates the per invocation results to get the overall score.
    - signature: 'def evaluate_invocations(self, actual_invocations: list[google.adk.evaluation.eval_case.Invocation], expected_invocations: typing.Optional[list[google.adk.evaluation.eval_case.Invocation]]) -> google.adk.evaluation.evaluator.EvaluationResult:'
    Evaluator:
    - signature: 'def evaluate_invocations(self, actual_invocations: list[google.adk.evaluation.eval_case.Invocation], expected_invocations: typing.Optional[list[google.adk.evaluation.eval_case.Invocation]]) -> google.adk.evaluation.evaluator.EvaluationResult:'
      docstring: "Returns EvaluationResult after performing evaluations using actual and expected invocations.\n\nArgs:\n  actual_invocations: These are the invocations that are obtained from the\n    agent under test.\n  expected_invocations: An optional list of invocations, if specified,\n    usually act as a benchmark/golden response. If these are specified\n    usually the expectation is that the length of this list and actual\n    invocation is the same."
  inherited_properties:
    Evaluator:
    - signature: 'criterion_type: typing.ClassVar[type[google.adk.evaluation.eval_metrics.BaseCriterion]]'
  omitted_inherited_members_from:
  - ABC
- rank: 797
  id: google.adk.evaluation.final_response_match_v2.FinalResponseMatchV2Evaluator.__init__
  name: __init__
  file_path: google/adk/evaluation/final_response_match_v2.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def __init__(self, eval_metric: google.adk.evaluation.eval_metrics.EvalMetric):'
- rank: 798
  id: google.adk.evaluation.final_response_match_v2.FinalResponseMatchV2Evaluator.aggregate_invocation_results
  name: aggregate_invocation_results
  file_path: google/adk/evaluation/final_response_match_v2.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: Computes the fraction of invocation results that are valid.
  signature: 'def aggregate_invocation_results(self, per_invocation_results: list[google.adk.evaluation.evaluator.PerInvocationResult]) -> google.adk.evaluation.evaluator.EvaluationResult:'
- rank: 799
  id: google.adk.evaluation.final_response_match_v2.FinalResponseMatchV2Evaluator.aggregate_per_invocation_samples
  name: aggregate_per_invocation_samples
  file_path: google/adk/evaluation/final_response_match_v2.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Aggregates samples of per-invocation results by taking majority vote.\n\nOnly consider results that were successfully evaluated. In the case of a\ntie, consider the result to be invalid.\n\nArgs:\n  per_invocation_samples: Samples of per-invocation results to aggregate.\n\nReturns:\n  If there is a majority of valid results, return the first valid result.\n  Otherwise, return the first invalid result. If no results were\n  successfully evaluated, return the first sample."
  signature: 'def aggregate_per_invocation_samples(self, per_invocation_samples: list[google.adk.evaluation.evaluator.PerInvocationResult]) -> google.adk.evaluation.evaluator.PerInvocationResult:'
- rank: 800
  id: google.adk.evaluation.final_response_match_v2.FinalResponseMatchV2Evaluator.convert_auto_rater_response_to_score
  name: convert_auto_rater_response_to_score
  file_path: google/adk/evaluation/final_response_match_v2.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def convert_auto_rater_response_to_score(self, llm_response: google.adk.models.llm_response.LlmResponse) -> google.adk.evaluation.llm_as_judge.AutoRaterScore:'
- rank: 801
  id: google.adk.evaluation.final_response_match_v2.FinalResponseMatchV2Evaluator.format_auto_rater_prompt
  name: format_auto_rater_prompt
  file_path: google/adk/evaluation/final_response_match_v2.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def format_auto_rater_prompt(self, actual_invocation: google.adk.evaluation.eval_case.Invocation, expected_invocation: typing.Optional[google.adk.evaluation.eval_case.Invocation]) -> str:'
- rank: 802
  id: google.adk.evaluation.final_response_match_v2.FinalResponseMatchV2Evaluator.get_metric_info
  name: get_metric_info
  file_path: google/adk/evaluation/final_response_match_v2.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def get_metric_info() -> google.adk.evaluation.eval_metrics.MetricInfo:'
- rank: 803
  id: google.adk.evaluation.gcs_eval_set_results_manager
  name: gcs_eval_set_results_manager
  file_path: google/adk/evaluation/gcs_eval_set_results_manager.py
  type: MODULE
  group: Orphan
  usage_score: 0
- rank: 804
  id: google.adk.evaluation.gcs_eval_set_results_manager.GcsEvalSetResultsManager
  name: GcsEvalSetResultsManager
  file_path: google/adk/evaluation/gcs_eval_set_results_manager.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'An EvalSetResultsManager that stores eval results in a GCS bucket.


    [Note: Inherited members from ABC are omitted.]'
  constructor_signature: 'def __init__(self, bucket_name: str):'
  methods:
  - signature: 'def save_eval_set_result(self, app_name: str, eval_set_id: str, eval_case_results: list[google.adk.evaluation.eval_result.EvalCaseResult]) -> None:'
    docstring: Creates and saves a new EvalSetResult given eval_case_results.
  - signature: 'def get_eval_set_result(self, app_name: str, eval_set_result_id: str) -> google.adk.evaluation.eval_result.EvalSetResult:'
    docstring: Returns an EvalSetResult from app_name and eval_set_result_id.
  - signature: 'def list_eval_set_results(self, app_name: str) -> list[str]:'
    docstring: Returns the eval result ids that belong to the given app_name.
  inherited_methods:
    EvalSetResultsManager:
    - signature: 'def save_eval_set_result(self, app_name: str, eval_set_id: str, eval_case_results: list[google.adk.evaluation.eval_result.EvalCaseResult]) -> None:'
      docstring: Creates and saves a new EvalSetResult given eval_case_results.
    - signature: 'def get_eval_set_result(self, app_name: str, eval_set_result_id: str) -> google.adk.evaluation.eval_result.EvalSetResult:'
      docstring: "Returns the EvalSetResult from app_name and eval_set_result_id.\n\nRaises:\n  NotFoundError: If the EvalSetResult is not found."
    - signature: 'def list_eval_set_results(self, app_name: str) -> list[str]:'
      docstring: Returns the eval result ids that belong to the given app_name.
  omitted_inherited_members_from:
  - ABC
- rank: 805
  id: google.adk.evaluation.gcs_eval_set_results_manager.GcsEvalSetResultsManager.__init__
  name: __init__
  file_path: google/adk/evaluation/gcs_eval_set_results_manager.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Initializes the GcsEvalSetsManager.\n\nArgs:\n    bucket_name: The name of the bucket to use.\n    **kwargs: Keyword arguments to pass to the Google Cloud Storage client."
  signature: 'def __init__(self, bucket_name: str):'
- rank: 806
  id: google.adk.evaluation.gcs_eval_set_results_manager.GcsEvalSetResultsManager.get_eval_set_result
  name: get_eval_set_result
  file_path: google/adk/evaluation/gcs_eval_set_results_manager.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: Returns an EvalSetResult from app_name and eval_set_result_id.
  signature: 'def get_eval_set_result(self, app_name: str, eval_set_result_id: str) -> google.adk.evaluation.eval_result.EvalSetResult:'
- rank: 807
  id: google.adk.evaluation.gcs_eval_set_results_manager.GcsEvalSetResultsManager.list_eval_set_results
  name: list_eval_set_results
  file_path: google/adk/evaluation/gcs_eval_set_results_manager.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: Returns the eval result ids that belong to the given app_name.
  signature: 'def list_eval_set_results(self, app_name: str) -> list[str]:'
- rank: 808
  id: google.adk.evaluation.gcs_eval_set_results_manager.GcsEvalSetResultsManager.save_eval_set_result
  name: save_eval_set_result
  file_path: google/adk/evaluation/gcs_eval_set_results_manager.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: Creates and saves a new EvalSetResult given eval_case_results.
  signature: 'def save_eval_set_result(self, app_name: str, eval_set_id: str, eval_case_results: list[google.adk.evaluation.eval_result.EvalCaseResult]) -> None:'
- rank: 809
  id: google.adk.evaluation.gcs_eval_sets_manager
  name: gcs_eval_sets_manager
  file_path: google/adk/evaluation/gcs_eval_sets_manager.py
  type: MODULE
  group: Orphan
  usage_score: 0
- rank: 810
  id: google.adk.evaluation.gcs_eval_sets_manager.GcsEvalSetsManager
  name: GcsEvalSetsManager
  file_path: google/adk/evaluation/gcs_eval_sets_manager.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'An EvalSetsManager that stores eval sets in a GCS bucket.


    [Note: Inherited members from ABC are omitted.]'
  constructor_signature: 'def __init__(self, bucket_name: str):'
  methods:
  - signature: 'def get_eval_set(self, app_name: str, eval_set_id: str) -> typing.Optional[google.adk.evaluation.eval_set.EvalSet]:'
    docstring: Returns an EvalSet identified by an app_name and eval_set_id.
  - signature: 'def create_eval_set(self, app_name: str, eval_set_id: str) -> google.adk.evaluation.eval_set.EvalSet:'
    docstring: "Creates an empty EvalSet and saves it to GCS.\n\nRaises:\n  ValueError: If Eval Set ID is not valid or an eval set already exists."
  - signature: 'def list_eval_sets(self, app_name: str) -> list[str]:'
    docstring: Returns a list of EvalSet ids that belong to the given app_name.
  - signature: 'def get_eval_case(self, app_name: str, eval_set_id: str, eval_case_id: str) -> typing.Optional[google.adk.evaluation.eval_case.EvalCase]:'
    docstring: Returns an EvalCase identified by an app_name, eval_set_id and eval_case_id.
  - signature: 'def add_eval_case(self, app_name: str, eval_set_id: str, eval_case: google.adk.evaluation.eval_case.EvalCase):'
    docstring: "Adds the given EvalCase to an existing EvalSet.\n\nArgs:\n  app_name: The name of the app.\n  eval_set_id: The id of the eval set containing the eval case to update.\n  eval_case: The EvalCase to add.\n\nRaises:\n  NotFoundError: If the eval set is not found.\n  ValueError: If the eval case already exists in the eval set."
  - signature: 'def update_eval_case(self, app_name: str, eval_set_id: str, updated_eval_case: google.adk.evaluation.eval_case.EvalCase):'
    docstring: "Updates an existing EvalCase.\n\nArgs:\n  app_name: The name of the app.\n  eval_set_id: The id of the eval set containing the eval case to update.\n  updated_eval_case: The updated EvalCase. Overwrites the existing EvalCase\n    using the eval_id field.\n\nRaises:\n  NotFoundError: If the eval set or the eval case is not found."
  - signature: 'def delete_eval_case(self, app_name: str, eval_set_id: str, eval_case_id: str):'
    docstring: "Deletes the EvalCase with the given eval_case_id from the given EvalSet.\n\nArgs:\n  app_name: The name of the app.\n  eval_set_id: The id of the eval set containing the eval case to delete.\n  eval_case_id: The id of the eval case to delete.\n\nRaises:\n  NotFoundError: If the eval set or the eval case to delete is not found."
  inherited_methods:
    EvalSetsManager:
    - signature: 'def get_eval_set(self, app_name: str, eval_set_id: str) -> typing.Optional[google.adk.evaluation.eval_set.EvalSet]:'
      docstring: Returns an EvalSet identified by an app_name and eval_set_id.
    - signature: 'def create_eval_set(self, app_name: str, eval_set_id: str) -> google.adk.evaluation.eval_set.EvalSet:'
      docstring: "Creates and returns an empty EvalSet given the app_name and eval_set_id.\n\nRaises:\n  ValueError: If eval set id is not valid or an eval set already exists. A\n  valid eval set id is string that has one or more of following characters:\n    - Lower case characters\n    - Upper case characters\n    - 0-9\n    - Underscore"
    - signature: 'def list_eval_sets(self, app_name: str) -> list[str]:'
      docstring: "Returns a list of EvalSets that belong to the given app_name.\n\nRaises:\n  NotFoundError: If the app_name doesn't exist."
    - signature: 'def get_eval_case(self, app_name: str, eval_set_id: str, eval_case_id: str) -> typing.Optional[google.adk.evaluation.eval_case.EvalCase]:'
      docstring: Returns an EvalCase if found; otherwise, None.
    - signature: 'def add_eval_case(self, app_name: str, eval_set_id: str, eval_case: google.adk.evaluation.eval_case.EvalCase):'
      docstring: "Adds the given EvalCase to an existing EvalSet identified by app_name and eval_set_id.\n\nRaises:\n  NotFoundError: If the eval set is not found."
    - signature: 'def update_eval_case(self, app_name: str, eval_set_id: str, updated_eval_case: google.adk.evaluation.eval_case.EvalCase):'
      docstring: "Updates an existing EvalCase give the app_name and eval_set_id.\n\nRaises:\n  NotFoundError: If the eval set or the eval case is not found."
    - signature: 'def delete_eval_case(self, app_name: str, eval_set_id: str, eval_case_id: str):'
      docstring: "Deletes the given EvalCase identified by app_name, eval_set_id and eval_case_id.\n\nRaises:\n  NotFoundError: If the eval set or the eval case to delete is not found."
  omitted_inherited_members_from:
  - ABC
- rank: 811
  id: google.adk.evaluation.gcs_eval_sets_manager.GcsEvalSetsManager.__init__
  name: __init__
  file_path: google/adk/evaluation/gcs_eval_sets_manager.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Initializes the GcsEvalSetsManager.\n\nArgs:\n  bucket_name: The name of the bucket to use.\n  **kwargs: Keyword arguments to pass to the Google Cloud Storage client."
  signature: 'def __init__(self, bucket_name: str):'
- rank: 812
  id: google.adk.evaluation.gcs_eval_sets_manager.GcsEvalSetsManager.add_eval_case
  name: add_eval_case
  file_path: google/adk/evaluation/gcs_eval_sets_manager.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Adds the given EvalCase to an existing EvalSet.\n\nArgs:\n  app_name: The name of the app.\n  eval_set_id: The id of the eval set containing the eval case to update.\n  eval_case: The EvalCase to add.\n\nRaises:\n  NotFoundError: If the eval set is not found.\n  ValueError: If the eval case already exists in the eval set."
  signature: 'def add_eval_case(self, app_name: str, eval_set_id: str, eval_case: google.adk.evaluation.eval_case.EvalCase):'
- rank: 813
  id: google.adk.evaluation.gcs_eval_sets_manager.GcsEvalSetsManager.create_eval_set
  name: create_eval_set
  file_path: google/adk/evaluation/gcs_eval_sets_manager.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Creates an empty EvalSet and saves it to GCS.\n\nRaises:\n  ValueError: If Eval Set ID is not valid or an eval set already exists."
  signature: 'def create_eval_set(self, app_name: str, eval_set_id: str) -> google.adk.evaluation.eval_set.EvalSet:'
- rank: 814
  id: google.adk.evaluation.gcs_eval_sets_manager.GcsEvalSetsManager.delete_eval_case
  name: delete_eval_case
  file_path: google/adk/evaluation/gcs_eval_sets_manager.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Deletes the EvalCase with the given eval_case_id from the given EvalSet.\n\nArgs:\n  app_name: The name of the app.\n  eval_set_id: The id of the eval set containing the eval case to delete.\n  eval_case_id: The id of the eval case to delete.\n\nRaises:\n  NotFoundError: If the eval set or the eval case to delete is not found."
  signature: 'def delete_eval_case(self, app_name: str, eval_set_id: str, eval_case_id: str):'
- rank: 815
  id: google.adk.evaluation.gcs_eval_sets_manager.GcsEvalSetsManager.get_eval_case
  name: get_eval_case
  file_path: google/adk/evaluation/gcs_eval_sets_manager.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: Returns an EvalCase identified by an app_name, eval_set_id and eval_case_id.
  signature: 'def get_eval_case(self, app_name: str, eval_set_id: str, eval_case_id: str) -> typing.Optional[google.adk.evaluation.eval_case.EvalCase]:'
- rank: 816
  id: google.adk.evaluation.gcs_eval_sets_manager.GcsEvalSetsManager.get_eval_set
  name: get_eval_set
  file_path: google/adk/evaluation/gcs_eval_sets_manager.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: Returns an EvalSet identified by an app_name and eval_set_id.
  signature: 'def get_eval_set(self, app_name: str, eval_set_id: str) -> typing.Optional[google.adk.evaluation.eval_set.EvalSet]:'
- rank: 817
  id: google.adk.evaluation.gcs_eval_sets_manager.GcsEvalSetsManager.list_eval_sets
  name: list_eval_sets
  file_path: google/adk/evaluation/gcs_eval_sets_manager.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: Returns a list of EvalSet ids that belong to the given app_name.
  signature: 'def list_eval_sets(self, app_name: str) -> list[str]:'
- rank: 818
  id: google.adk.evaluation.gcs_eval_sets_manager.GcsEvalSetsManager.update_eval_case
  name: update_eval_case
  file_path: google/adk/evaluation/gcs_eval_sets_manager.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Updates an existing EvalCase.\n\nArgs:\n  app_name: The name of the app.\n  eval_set_id: The id of the eval set containing the eval case to update.\n  updated_eval_case: The updated EvalCase. Overwrites the existing EvalCase\n    using the eval_id field.\n\nRaises:\n  NotFoundError: If the eval set or the eval case is not found."
  signature: 'def update_eval_case(self, app_name: str, eval_set_id: str, updated_eval_case: google.adk.evaluation.eval_case.EvalCase):'
- rank: 819
  id: google.adk.evaluation.hallucinations_v1
  name: hallucinations_v1
  file_path: google/adk/evaluation/hallucinations_v1.py
  type: MODULE
  group: Orphan
  usage_score: 0
- rank: 820
  id: google.adk.evaluation.hallucinations_v1.EvaluationStep
  name: EvaluationStep
  file_path: google/adk/evaluation/hallucinations_v1.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: The context and natural language response to be evaluated at a step.
  constructor_signature: 'def __init__(self, *, context: str, nl_response: str):'
  properties:
  - signature: 'context: str'
  - signature: 'nl_response: str'
- rank: 821
  id: google.adk.evaluation.hallucinations_v1.HallucinationsV1Evaluator
  name: HallucinationsV1Evaluator
  file_path: google/adk/evaluation/hallucinations_v1.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Evaluates whether a model response contains any false, contradictory, or unsupported claims.


    The metric follows a two-step process:

    1. Segmenter: Segments the agent response into individual sentences.

    2. Sentence Validator: Evaluates each segmented sentence against the provided

    context for grounding.


    The metric computes the Accuracy Score (AS): the percentage of sentences that

    are supported or not_applicable.


    [Note: Inherited members from ABC are omitted.]'
  constructor_signature: 'def __init__(self, eval_metric: google.adk.evaluation.eval_metrics.EvalMetric):'
  methods:
  - signature: 'def get_metric_info() -> google.adk.evaluation.eval_metrics.MetricInfo:'
  - signature: 'def evaluate_invocations(self, actual_invocations: list[google.adk.evaluation.eval_case.Invocation], expected_invocations: typing.Optional[list[google.adk.evaluation.eval_case.Invocation]]) -> google.adk.evaluation.evaluator.EvaluationResult:'
  properties:
  - signature: 'criterion_type: typing.ClassVar[type[google.adk.evaluation.eval_metrics.HallucinationsCriterion]]'
  inherited_methods:
    Evaluator:
    - signature: 'def evaluate_invocations(self, actual_invocations: list[google.adk.evaluation.eval_case.Invocation], expected_invocations: typing.Optional[list[google.adk.evaluation.eval_case.Invocation]]) -> google.adk.evaluation.evaluator.EvaluationResult:'
      docstring: "Returns EvaluationResult after performing evaluations using actual and expected invocations.\n\nArgs:\n  actual_invocations: These are the invocations that are obtained from the\n    agent under test.\n  expected_invocations: An optional list of invocations, if specified,\n    usually act as a benchmark/golden response. If these are specified\n    usually the expectation is that the length of this list and actual\n    invocation is the same."
  inherited_properties:
    Evaluator:
    - signature: 'criterion_type: typing.ClassVar[type[google.adk.evaluation.eval_metrics.BaseCriterion]]'
  omitted_inherited_members_from:
  - ABC
- rank: 822
  id: google.adk.evaluation.hallucinations_v1.HallucinationsV1Evaluator.__init__
  name: __init__
  file_path: google/adk/evaluation/hallucinations_v1.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def __init__(self, eval_metric: google.adk.evaluation.eval_metrics.EvalMetric):'
- rank: 823
  id: google.adk.evaluation.hallucinations_v1.HallucinationsV1Evaluator.evaluate_invocations
  name: evaluate_invocations
  file_path: google/adk/evaluation/hallucinations_v1.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def evaluate_invocations(self, actual_invocations: list[google.adk.evaluation.eval_case.Invocation], expected_invocations: typing.Optional[list[google.adk.evaluation.eval_case.Invocation]]) -> google.adk.evaluation.evaluator.EvaluationResult:'
- rank: 824
  id: google.adk.evaluation.hallucinations_v1.HallucinationsV1Evaluator.get_metric_info
  name: get_metric_info
  file_path: google/adk/evaluation/hallucinations_v1.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def get_metric_info() -> google.adk.evaluation.eval_metrics.MetricInfo:'
- rank: 825
  id: google.adk.evaluation.in_memory_eval_sets_manager
  name: in_memory_eval_sets_manager
  file_path: google/adk/evaluation/in_memory_eval_sets_manager.py
  type: MODULE
  group: Orphan
  usage_score: 0
- rank: 826
  id: google.adk.evaluation.in_memory_eval_sets_manager.InMemoryEvalSetsManager
  name: InMemoryEvalSetsManager
  file_path: google/adk/evaluation/in_memory_eval_sets_manager.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'An in-memory implementation of EvalSetsManager using dictionaries.


    You can use this class:

    1) As a part of your testcase.

    2) For cases where other implementations of EvalSetsManager are too expensive

    to use.


    [Note: Inherited members from ABC are omitted.]'
  constructor_signature: 'def __init__(self):'
  methods:
  - signature: 'def get_eval_set(self, app_name: str, eval_set_id: str) -> typing.Optional[google.adk.evaluation.eval_set.EvalSet]:'
  - signature: 'def create_eval_set(self, app_name: str, eval_set_id: str):'
  - signature: 'def list_eval_sets(self, app_name: str) -> list[str]:'
  - signature: 'def get_eval_case(self, app_name: str, eval_set_id: str, eval_case_id: str) -> typing.Optional[google.adk.evaluation.eval_case.EvalCase]:'
  - signature: 'def add_eval_case(self, app_name: str, eval_set_id: str, eval_case: google.adk.evaluation.eval_case.EvalCase):'
  - signature: 'def update_eval_case(self, app_name: str, eval_set_id: str, updated_eval_case: google.adk.evaluation.eval_case.EvalCase):'
  - signature: 'def delete_eval_case(self, app_name: str, eval_set_id: str, eval_case_id: str):'
  inherited_methods:
    EvalSetsManager:
    - signature: 'def get_eval_set(self, app_name: str, eval_set_id: str) -> typing.Optional[google.adk.evaluation.eval_set.EvalSet]:'
      docstring: Returns an EvalSet identified by an app_name and eval_set_id.
    - signature: 'def create_eval_set(self, app_name: str, eval_set_id: str) -> google.adk.evaluation.eval_set.EvalSet:'
      docstring: "Creates and returns an empty EvalSet given the app_name and eval_set_id.\n\nRaises:\n  ValueError: If eval set id is not valid or an eval set already exists. A\n  valid eval set id is string that has one or more of following characters:\n    - Lower case characters\n    - Upper case characters\n    - 0-9\n    - Underscore"
    - signature: 'def list_eval_sets(self, app_name: str) -> list[str]:'
      docstring: "Returns a list of EvalSets that belong to the given app_name.\n\nRaises:\n  NotFoundError: If the app_name doesn't exist."
    - signature: 'def get_eval_case(self, app_name: str, eval_set_id: str, eval_case_id: str) -> typing.Optional[google.adk.evaluation.eval_case.EvalCase]:'
      docstring: Returns an EvalCase if found; otherwise, None.
    - signature: 'def add_eval_case(self, app_name: str, eval_set_id: str, eval_case: google.adk.evaluation.eval_case.EvalCase):'
      docstring: "Adds the given EvalCase to an existing EvalSet identified by app_name and eval_set_id.\n\nRaises:\n  NotFoundError: If the eval set is not found."
    - signature: 'def update_eval_case(self, app_name: str, eval_set_id: str, updated_eval_case: google.adk.evaluation.eval_case.EvalCase):'
      docstring: "Updates an existing EvalCase give the app_name and eval_set_id.\n\nRaises:\n  NotFoundError: If the eval set or the eval case is not found."
    - signature: 'def delete_eval_case(self, app_name: str, eval_set_id: str, eval_case_id: str):'
      docstring: "Deletes the given EvalCase identified by app_name, eval_set_id and eval_case_id.\n\nRaises:\n  NotFoundError: If the eval set or the eval case to delete is not found."
  omitted_inherited_members_from:
  - ABC
- rank: 827
  id: google.adk.evaluation.in_memory_eval_sets_manager.InMemoryEvalSetsManager.__init__
  name: __init__
  file_path: google/adk/evaluation/in_memory_eval_sets_manager.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def __init__(self):'
- rank: 828
  id: google.adk.evaluation.in_memory_eval_sets_manager.InMemoryEvalSetsManager.add_eval_case
  name: add_eval_case
  file_path: google/adk/evaluation/in_memory_eval_sets_manager.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def add_eval_case(self, app_name: str, eval_set_id: str, eval_case: google.adk.evaluation.eval_case.EvalCase):'
- rank: 829
  id: google.adk.evaluation.in_memory_eval_sets_manager.InMemoryEvalSetsManager.create_eval_set
  name: create_eval_set
  file_path: google/adk/evaluation/in_memory_eval_sets_manager.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def create_eval_set(self, app_name: str, eval_set_id: str):'
- rank: 830
  id: google.adk.evaluation.in_memory_eval_sets_manager.InMemoryEvalSetsManager.delete_eval_case
  name: delete_eval_case
  file_path: google/adk/evaluation/in_memory_eval_sets_manager.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def delete_eval_case(self, app_name: str, eval_set_id: str, eval_case_id: str):'
- rank: 831
  id: google.adk.evaluation.in_memory_eval_sets_manager.InMemoryEvalSetsManager.get_eval_case
  name: get_eval_case
  file_path: google/adk/evaluation/in_memory_eval_sets_manager.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def get_eval_case(self, app_name: str, eval_set_id: str, eval_case_id: str) -> typing.Optional[google.adk.evaluation.eval_case.EvalCase]:'
- rank: 832
  id: google.adk.evaluation.in_memory_eval_sets_manager.InMemoryEvalSetsManager.list_eval_sets
  name: list_eval_sets
  file_path: google/adk/evaluation/in_memory_eval_sets_manager.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def list_eval_sets(self, app_name: str) -> list[str]:'
- rank: 833
  id: google.adk.evaluation.in_memory_eval_sets_manager.InMemoryEvalSetsManager.update_eval_case
  name: update_eval_case
  file_path: google/adk/evaluation/in_memory_eval_sets_manager.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def update_eval_case(self, app_name: str, eval_set_id: str, updated_eval_case: google.adk.evaluation.eval_case.EvalCase):'
- rank: 834
  id: google.adk.evaluation.llm_as_judge
  name: llm_as_judge
  file_path: google/adk/evaluation/llm_as_judge.py
  type: MODULE
  group: Orphan
  usage_score: 0
- rank: 835
  id: google.adk.evaluation.llm_as_judge.AutoRaterScore
  name: AutoRaterScore
  file_path: google/adk/evaluation/llm_as_judge.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: '[Note: Inherited members from pydantic.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, score: typing.Optional[float] = None, rubric_scores: typing.Optional[list[google.adk.evaluation.eval_metrics.RubricScore]] = None):'
  properties:
  - signature: 'score: typing.Optional[float]'
  - signature: 'rubric_scores: typing.Optional[list[google.adk.evaluation.eval_metrics.RubricScore]]'
  inherited_properties:
    EvalBaseModel:
    - signature: 'model_config: pydantic.ConfigDict'
  omitted_inherited_members_from:
  - pydantic.BaseModel
- rank: 836
  id: google.adk.evaluation.llm_as_judge.LlmAsJudge
  name: LlmAsJudge
  file_path: google/adk/evaluation/llm_as_judge.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: "Evaluator based on a LLM.\n\nIt is meant to be extended by specific auto-raters for different evaluation\ntasks:\n  - Provide the prompt template, and implement format_auto_rater_prompt to\n    format the auto-rater prompt for a given invocation.\n  - Implement convert_auto_rater_response_to_score to parse the auto-rater\n    response and return the corresponding score.\n  - Implement aggregate_invocation_results to aggregate the per-invocation\n    results to get the overall score.\n  - (Optional) Override aggregate_per_invocation_result_samples to aggregate\n    multiple auto-rater samples of the same invocation.\n\n[Note: Inherited members from ABC are omitted.]"
  constructor_signature: 'def __init__(self, eval_metric: google.adk.evaluation.eval_metrics.EvalMetric, criterion_type: type[google.adk.evaluation.eval_metrics.BaseCriterion], expected_invocations_required):'
  methods:
  - signature: 'def format_auto_rater_prompt(self, actual: google.adk.evaluation.eval_case.Invocation, expected: typing.Optional[google.adk.evaluation.eval_case.Invocation]) -> str:'
    docstring: Formats the auto-rater prompt to evaluate the given invocation.
  - signature: 'def convert_auto_rater_response_to_score(self, auto_rater_response: google.adk.models.llm_response.LlmResponse) -> google.adk.evaluation.llm_as_judge.AutoRaterScore:'
    docstring: Parses auto_rater_response and returns the corresponding score, or None if the score cannot be determined.
  - signature: 'def aggregate_per_invocation_samples(self, per_invocation_samples: list[google.adk.evaluation.evaluator.PerInvocationResult]) -> google.adk.evaluation.evaluator.PerInvocationResult:'
    docstring: Aggregates repeated per-invocation samples to get the final result for the invocation.
  - signature: 'def aggregate_invocation_results(self, per_invocation_results: list[google.adk.evaluation.evaluator.PerInvocationResult]) -> google.adk.evaluation.evaluator.EvaluationResult:'
    docstring: Aggregates the per invocation results to get the overall score.
  - signature: 'def evaluate_invocations(self, actual_invocations: list[google.adk.evaluation.eval_case.Invocation], expected_invocations: typing.Optional[list[google.adk.evaluation.eval_case.Invocation]]) -> google.adk.evaluation.evaluator.EvaluationResult:'
  inherited_methods:
    Evaluator:
    - signature: 'def evaluate_invocations(self, actual_invocations: list[google.adk.evaluation.eval_case.Invocation], expected_invocations: typing.Optional[list[google.adk.evaluation.eval_case.Invocation]]) -> google.adk.evaluation.evaluator.EvaluationResult:'
      docstring: "Returns EvaluationResult after performing evaluations using actual and expected invocations.\n\nArgs:\n  actual_invocations: These are the invocations that are obtained from the\n    agent under test.\n  expected_invocations: An optional list of invocations, if specified,\n    usually act as a benchmark/golden response. If these are specified\n    usually the expectation is that the length of this list and actual\n    invocation is the same."
  inherited_properties:
    Evaluator:
    - signature: 'criterion_type: typing.ClassVar[type[google.adk.evaluation.eval_metrics.BaseCriterion]]'
  omitted_inherited_members_from:
  - ABC
- rank: 837
  id: google.adk.evaluation.llm_as_judge.LlmAsJudge.__init__
  name: __init__
  file_path: google/adk/evaluation/llm_as_judge.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def __init__(self, eval_metric: google.adk.evaluation.eval_metrics.EvalMetric, criterion_type: type[google.adk.evaluation.eval_metrics.BaseCriterion], expected_invocations_required):'
- rank: 838
  id: google.adk.evaluation.llm_as_judge.LlmAsJudge.aggregate_invocation_results
  name: aggregate_invocation_results
  file_path: google/adk/evaluation/llm_as_judge.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: Aggregates the per invocation results to get the overall score.
  signature: 'def aggregate_invocation_results(self, per_invocation_results: list[google.adk.evaluation.evaluator.PerInvocationResult]) -> google.adk.evaluation.evaluator.EvaluationResult:'
- rank: 839
  id: google.adk.evaluation.llm_as_judge.LlmAsJudge.aggregate_per_invocation_samples
  name: aggregate_per_invocation_samples
  file_path: google/adk/evaluation/llm_as_judge.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: Aggregates repeated per-invocation samples to get the final result for the invocation.
  signature: 'def aggregate_per_invocation_samples(self, per_invocation_samples: list[google.adk.evaluation.evaluator.PerInvocationResult]) -> google.adk.evaluation.evaluator.PerInvocationResult:'
- rank: 840
  id: google.adk.evaluation.llm_as_judge.LlmAsJudge.convert_auto_rater_response_to_score
  name: convert_auto_rater_response_to_score
  file_path: google/adk/evaluation/llm_as_judge.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: Parses auto_rater_response and returns the corresponding score, or None if the score cannot be determined.
  signature: 'def convert_auto_rater_response_to_score(self, auto_rater_response: google.adk.models.llm_response.LlmResponse) -> google.adk.evaluation.llm_as_judge.AutoRaterScore:'
- rank: 841
  id: google.adk.evaluation.llm_as_judge.LlmAsJudge.evaluate_invocations
  name: evaluate_invocations
  file_path: google/adk/evaluation/llm_as_judge.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def evaluate_invocations(self, actual_invocations: list[google.adk.evaluation.eval_case.Invocation], expected_invocations: typing.Optional[list[google.adk.evaluation.eval_case.Invocation]]) -> google.adk.evaluation.evaluator.EvaluationResult:'
- rank: 842
  id: google.adk.evaluation.llm_as_judge.LlmAsJudge.format_auto_rater_prompt
  name: format_auto_rater_prompt
  file_path: google/adk/evaluation/llm_as_judge.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: Formats the auto-rater prompt to evaluate the given invocation.
  signature: 'def format_auto_rater_prompt(self, actual: google.adk.evaluation.eval_case.Invocation, expected: typing.Optional[google.adk.evaluation.eval_case.Invocation]) -> str:'
- rank: 843
  id: google.adk.evaluation.llm_as_judge_utils
  name: llm_as_judge_utils
  file_path: google/adk/evaluation/llm_as_judge_utils.py
  type: MODULE
  group: Orphan
  usage_score: 0
  methods:
  - signature: 'def get_text_from_content(content: typing.Optional[google.genai.types.Content]) -> typing.Optional[str]:'
  - signature: 'def get_eval_status(score: typing.Optional[float], threshold: float) -> google.adk.evaluation.evaluator.EvalStatus:'
  - signature: 'def get_average_rubric_score(rubric_scores: list[google.adk.evaluation.eval_metrics.RubricScore]) -> typing.Optional[float]:'
    docstring: 'Returns a single score value from the given list of rubric scores.


      It is possible that none of the rubric score actually contain a score value,

      if that happens then None is returned.


      If non-zero score values are present, then a mean value is returned as the

      aggregated value.'
  - signature: 'def get_tool_declarations_as_json_str(app_details: google.adk.evaluation.app_details.AppDetails) -> str:'
    docstring: 'Returns a JSON string representation of Tool declarations.


      The output of this method is usually intended to be sent to the LLM.'
  - signature: 'def get_tool_calls_and_responses_as_json_str(intermediate_data: typing.Optional[google.adk.evaluation.eval_case.IntermediateDataType]) -> str:'
    docstring: 'Returns a JSON string representation of tool calls and corresponding responses.


      The output of this method is usually intended to be sent to the LLM.'
- rank: 844
  id: google.adk.evaluation.llm_as_judge_utils.Label
  name: Label
  file_path: google/adk/evaluation/llm_as_judge_utils.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Labels for auto rater response.


    [Note: Inherited members from enum.Enum are omitted.]'
  properties:
  - signature: 'TRUE: str'
  - signature: 'INVALID: str'
  - signature: 'VALID: str'
  - signature: 'PARTIALLY_VALID: Any'
  - signature: 'ALMOST: str'
  - signature: 'FALSE: str'
  - signature: 'NOT_FOUND: str'
  omitted_inherited_members_from:
  - enum.Enum
- rank: 845
  id: google.adk.evaluation.llm_as_judge_utils.get_average_rubric_score
  name: get_average_rubric_score
  file_path: google/adk/evaluation/llm_as_judge_utils.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: 'Returns a single score value from the given list of rubric scores.


    It is possible that none of the rubric score actually contain a score value,

    if that happens then None is returned.


    If non-zero score values are present, then a mean value is returned as the

    aggregated value.'
  signature: 'def get_average_rubric_score(rubric_scores: list[google.adk.evaluation.eval_metrics.RubricScore]) -> typing.Optional[float]:'
- rank: 846
  id: google.adk.evaluation.llm_as_judge_utils.get_eval_status
  name: get_eval_status
  file_path: google/adk/evaluation/llm_as_judge_utils.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def get_eval_status(score: typing.Optional[float], threshold: float) -> google.adk.evaluation.evaluator.EvalStatus:'
- rank: 847
  id: google.adk.evaluation.llm_as_judge_utils.get_text_from_content
  name: get_text_from_content
  file_path: google/adk/evaluation/llm_as_judge_utils.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def get_text_from_content(content: typing.Optional[google.genai.types.Content]) -> typing.Optional[str]:'
- rank: 848
  id: google.adk.evaluation.llm_as_judge_utils.get_tool_calls_and_responses_as_json_str
  name: get_tool_calls_and_responses_as_json_str
  file_path: google/adk/evaluation/llm_as_judge_utils.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: 'Returns a JSON string representation of tool calls and corresponding responses.


    The output of this method is usually intended to be sent to the LLM.'
  signature: 'def get_tool_calls_and_responses_as_json_str(intermediate_data: typing.Optional[google.adk.evaluation.eval_case.IntermediateDataType]) -> str:'
- rank: 849
  id: google.adk.evaluation.llm_as_judge_utils.get_tool_declarations_as_json_str
  name: get_tool_declarations_as_json_str
  file_path: google/adk/evaluation/llm_as_judge_utils.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: 'Returns a JSON string representation of Tool declarations.


    The output of this method is usually intended to be sent to the LLM.'
  signature: 'def get_tool_declarations_as_json_str(app_details: google.adk.evaluation.app_details.AppDetails) -> str:'
- rank: 850
  id: google.adk.evaluation.local_eval_service
  name: local_eval_service
  file_path: google/adk/evaluation/local_eval_service.py
  type: MODULE
  group: Orphan
  usage_score: 0
- rank: 851
  id: google.adk.evaluation.local_eval_service.LocalEvalService
  name: LocalEvalService
  file_path: google/adk/evaluation/local_eval_service.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'An implementation of BaseEvalService, that runs the evals locally.


    [Note: Inherited members from ABC are omitted.]'
  constructor_signature: 'def __init__(self, root_agent: google.adk.agents.base_agent.BaseAgent, eval_sets_manager: google.adk.evaluation.eval_sets_manager.EvalSetsManager, metric_evaluator_registry: typing.Optional[google.adk.evaluation.metric_evaluator_registry.MetricEvaluatorRegistry], session_service: typing.Optional[google.adk.sessions.base_session_service.BaseSessionService], artifact_service: typing.Optional[google.adk.artifacts.base_artifact_service.BaseArtifactService], eval_set_results_manager: typing.Optional[google.adk.evaluation.eval_set_results_manager.EvalSetResultsManager], session_id_supplier: typing.Callable[[], str], user_simulator_provider: google.adk.evaluation.simulation.user_simulator_provider.UserSimulatorProvider, memory_service: typing.Optional[google.adk.memory.base_memory_service.BaseMemoryService]):'
  methods:
  - signature: 'def perform_inference(self, inference_request: google.adk.evaluation.base_eval_service.InferenceRequest) -> typing.AsyncGenerator[google.adk.evaluation.base_eval_service.InferenceResult, None]:'
    docstring: "Returns InferenceResult obtained from the Agent as and when they are available.\n\nArgs:\n  inference_request: The request for generating inferences."
  - signature: 'def run_inference(eval_case):'
  - signature: 'def evaluate(self, evaluate_request: google.adk.evaluation.base_eval_service.EvaluateRequest) -> typing.AsyncGenerator[google.adk.evaluation.eval_result.EvalCaseResult, None]:'
    docstring: "Returns EvalCaseResult for each item as and when they are available.\n\nArgs:\n  evaluate_request: The request to perform metric evaluations on the\n    inferences."
  - signature: 'def run_evaluation(inference_result):'
  inherited_methods:
    BaseEvalService:
    - signature: 'def perform_inference(self, inference_request: google.adk.evaluation.base_eval_service.InferenceRequest) -> typing.AsyncGenerator[google.adk.evaluation.base_eval_service.InferenceResult, None]:'
      docstring: "Returns InferenceResult obtained from the Agent as and when they are available.\n\nArgs:\n  inference_request: The request for generating inferences."
    - signature: 'def evaluate(self, evaluate_request: google.adk.evaluation.base_eval_service.EvaluateRequest) -> typing.AsyncGenerator[google.adk.evaluation.eval_result.EvalCaseResult, None]:'
      docstring: "Returns EvalCaseResult for each item as and when they are available.\n\nArgs:\n  evaluate_request: The request to perform metric evaluations on the\n    inferences."
  omitted_inherited_members_from:
  - ABC
- rank: 852
  id: google.adk.evaluation.local_eval_service.LocalEvalService.__init__
  name: __init__
  file_path: google/adk/evaluation/local_eval_service.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def __init__(self, root_agent: google.adk.agents.base_agent.BaseAgent, eval_sets_manager: google.adk.evaluation.eval_sets_manager.EvalSetsManager, metric_evaluator_registry: typing.Optional[google.adk.evaluation.metric_evaluator_registry.MetricEvaluatorRegistry], session_service: typing.Optional[google.adk.sessions.base_session_service.BaseSessionService], artifact_service: typing.Optional[google.adk.artifacts.base_artifact_service.BaseArtifactService], eval_set_results_manager: typing.Optional[google.adk.evaluation.eval_set_results_manager.EvalSetResultsManager], session_id_supplier: typing.Callable[[], str], user_simulator_provider: google.adk.evaluation.simulation.user_simulator_provider.UserSimulatorProvider, memory_service: typing.Optional[google.adk.memory.base_memory_service.BaseMemoryService]):'
- rank: 853
  id: google.adk.evaluation.local_eval_service.LocalEvalService.evaluate
  name: evaluate
  file_path: google/adk/evaluation/local_eval_service.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Returns EvalCaseResult for each item as and when they are available.\n\nArgs:\n  evaluate_request: The request to perform metric evaluations on the\n    inferences."
  signature: 'def evaluate(self, evaluate_request: google.adk.evaluation.base_eval_service.EvaluateRequest) -> typing.AsyncGenerator[google.adk.evaluation.eval_result.EvalCaseResult, None]:'
- rank: 854
  id: google.adk.evaluation.local_eval_service.LocalEvalService.perform_inference
  name: perform_inference
  file_path: google/adk/evaluation/local_eval_service.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Returns InferenceResult obtained from the Agent as and when they are available.\n\nArgs:\n  inference_request: The request for generating inferences."
  signature: 'def perform_inference(self, inference_request: google.adk.evaluation.base_eval_service.InferenceRequest) -> typing.AsyncGenerator[google.adk.evaluation.base_eval_service.InferenceResult, None]:'
- rank: 855
  id: google.adk.evaluation.local_eval_service.LocalEvalService.run_evaluation
  name: run_evaluation
  file_path: google/adk/evaluation/local_eval_service.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def run_evaluation(inference_result):'
- rank: 856
  id: google.adk.evaluation.local_eval_service.LocalEvalService.run_inference
  name: run_inference
  file_path: google/adk/evaluation/local_eval_service.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def run_inference(eval_case):'
- rank: 857
  id: google.adk.evaluation.local_eval_set_results_manager
  name: local_eval_set_results_manager
  file_path: google/adk/evaluation/local_eval_set_results_manager.py
  type: MODULE
  group: Orphan
  usage_score: 0
- rank: 858
  id: google.adk.evaluation.local_eval_set_results_manager.LocalEvalSetResultsManager
  name: LocalEvalSetResultsManager
  file_path: google/adk/evaluation/local_eval_set_results_manager.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'An EvalSetResult manager that stores eval set results locally on disk.


    [Note: Inherited members from ABC are omitted.]'
  constructor_signature: 'def __init__(self, agents_dir: str):'
  methods:
  - signature: 'def save_eval_set_result(self, app_name: str, eval_set_id: str, eval_case_results: list[google.adk.evaluation.eval_result.EvalCaseResult]) -> None:'
    docstring: Creates and saves a new EvalSetResult given eval_case_results.
  - signature: 'def get_eval_set_result(self, app_name: str, eval_set_result_id: str) -> google.adk.evaluation.eval_result.EvalSetResult:'
    docstring: Returns an EvalSetResult identified by app_name and eval_set_result_id.
  - signature: 'def list_eval_set_results(self, app_name: str) -> list[str]:'
    docstring: Returns the eval result ids that belong to the given app_name.
  inherited_methods:
    EvalSetResultsManager:
    - signature: 'def save_eval_set_result(self, app_name: str, eval_set_id: str, eval_case_results: list[google.adk.evaluation.eval_result.EvalCaseResult]) -> None:'
      docstring: Creates and saves a new EvalSetResult given eval_case_results.
    - signature: 'def get_eval_set_result(self, app_name: str, eval_set_result_id: str) -> google.adk.evaluation.eval_result.EvalSetResult:'
      docstring: "Returns the EvalSetResult from app_name and eval_set_result_id.\n\nRaises:\n  NotFoundError: If the EvalSetResult is not found."
    - signature: 'def list_eval_set_results(self, app_name: str) -> list[str]:'
      docstring: Returns the eval result ids that belong to the given app_name.
  omitted_inherited_members_from:
  - ABC
- rank: 859
  id: google.adk.evaluation.local_eval_set_results_manager.LocalEvalSetResultsManager.get_eval_set_result
  name: get_eval_set_result
  file_path: google/adk/evaluation/local_eval_set_results_manager.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: Returns an EvalSetResult identified by app_name and eval_set_result_id.
  signature: 'def get_eval_set_result(self, app_name: str, eval_set_result_id: str) -> google.adk.evaluation.eval_result.EvalSetResult:'
- rank: 860
  id: google.adk.evaluation.local_eval_set_results_manager.LocalEvalSetResultsManager.list_eval_set_results
  name: list_eval_set_results
  file_path: google/adk/evaluation/local_eval_set_results_manager.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: Returns the eval result ids that belong to the given app_name.
  signature: 'def list_eval_set_results(self, app_name: str) -> list[str]:'
- rank: 861
  id: google.adk.evaluation.local_eval_set_results_manager.LocalEvalSetResultsManager.save_eval_set_result
  name: save_eval_set_result
  file_path: google/adk/evaluation/local_eval_set_results_manager.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: Creates and saves a new EvalSetResult given eval_case_results.
  signature: 'def save_eval_set_result(self, app_name: str, eval_set_id: str, eval_case_results: list[google.adk.evaluation.eval_result.EvalCaseResult]) -> None:'
- rank: 862
  id: google.adk.evaluation.local_eval_sets_manager
  name: local_eval_sets_manager
  file_path: google/adk/evaluation/local_eval_sets_manager.py
  type: MODULE
  group: Orphan
  usage_score: 0
  methods:
  - signature: 'def convert_eval_set_to_pydantic_schema(eval_set_id: str, eval_set_in_json_format: list[dict[str, typing.Any]]) -> google.adk.evaluation.eval_set.EvalSet:'
    docstring: "Returns a pydantic EvalSet generated from the json representation.\n\n  Args:\n    eval_set_id: Eval set id.\n    eval_set_in_json_format: Eval set specified in JSON format.\n\n  Here is a sample eval set in JSON format:\n[\n  {\n    \"name\": \"roll_17_sided_dice_twice\",\n    \"data\": [\n      {\n        \"query\": \"What can you do?\",\n        \"expected_tool_use\": [],\n        \"expected_intermediate_agent_responses\": [],\n        \"reference\": \"I can roll dice of different sizes and check if a number\n          is prime. I can also use multiple tools in parallel.\\n\"\n      },\n      {\n        \"query\": \"Roll a 17 sided dice twice for me\",\n        \"expected_tool_use\": [\n          {\n            \"tool_name\": \"roll_die\",\n            \"tool_input\": {\n              \"sides\": 17\n            }\n          },\n          {\n            \"tool_name\": \"roll_die\",\n            \"tool_input\": {\n              \"sides\": 17\n            }\n          }\n\
      \        ],\n        \"expected_intermediate_agent_responses\": [],\n        \"reference\": \"I have rolled a 17 sided die twice. The first roll was\n          13 and the second roll was 4.\\n\"\n      }\n    ],\n    \"initial_session\": {\n      \"state\": {},\n      \"app_name\": \"hello_world\",\n      \"user_id\": \"user\"\n    }\n  }\n]"
  - signature: 'def load_eval_set_from_file(eval_set_file_path: str, eval_set_id: str) -> google.adk.evaluation.eval_set.EvalSet:'
    docstring: Returns an EvalSet that is read from the given file.
- rank: 863
  id: google.adk.evaluation.local_eval_sets_manager.LocalEvalSetsManager
  name: LocalEvalSetsManager
  file_path: google/adk/evaluation/local_eval_sets_manager.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'An EvalSets manager that stores eval sets locally on disk.


    [Note: Inherited members from ABC are omitted.]'
  constructor_signature: 'def __init__(self, agents_dir: str):'
  methods:
  - signature: 'def get_eval_set(self, app_name: str, eval_set_id: str) -> typing.Optional[google.adk.evaluation.eval_set.EvalSet]:'
    docstring: Returns an EvalSet identified by an app_name and eval_set_id.
  - signature: 'def create_eval_set(self, app_name: str, eval_set_id: str) -> google.adk.evaluation.eval_set.EvalSet:'
    docstring: "Creates and returns an empty EvalSet given the app_name and eval_set_id.\n\nRaises:\n  ValueError: If Eval Set ID is not valid or an eval set already exists."
  - signature: 'def list_eval_sets(self, app_name: str) -> list[str]:'
    docstring: "Returns a list of EvalSets that belong to the given app_name.\n\nArgs:\n  app_name: The app name to list the eval sets for.\n\nReturns:\n  A list of EvalSet ids.\n\nRaises:\n  NotFoundError: If the eval directory for the app is not found."
  - signature: 'def get_eval_case(self, app_name: str, eval_set_id: str, eval_case_id: str) -> typing.Optional[google.adk.evaluation.eval_case.EvalCase]:'
    docstring: Returns an EvalCase if found; otherwise, None.
  - signature: 'def add_eval_case(self, app_name: str, eval_set_id: str, eval_case: google.adk.evaluation.eval_case.EvalCase):'
    docstring: "Adds the given EvalCase to an existing EvalSet identified by app_name and eval_set_id.\n\nRaises:\n  NotFoundError: If the eval set is not found."
  - signature: 'def update_eval_case(self, app_name: str, eval_set_id: str, updated_eval_case: google.adk.evaluation.eval_case.EvalCase):'
    docstring: "Updates an existing EvalCase give the app_name and eval_set_id.\n\nRaises:\n  NotFoundError: If the eval set or the eval case is not found."
  - signature: 'def delete_eval_case(self, app_name: str, eval_set_id: str, eval_case_id: str):'
    docstring: "Deletes the given EvalCase identified by app_name, eval_set_id and eval_case_id.\n\nRaises:\n  NotFoundError: If the eval set or the eval case to delete is not found."
  inherited_methods:
    EvalSetsManager:
    - signature: 'def get_eval_set(self, app_name: str, eval_set_id: str) -> typing.Optional[google.adk.evaluation.eval_set.EvalSet]:'
      docstring: Returns an EvalSet identified by an app_name and eval_set_id.
    - signature: 'def create_eval_set(self, app_name: str, eval_set_id: str) -> google.adk.evaluation.eval_set.EvalSet:'
      docstring: "Creates and returns an empty EvalSet given the app_name and eval_set_id.\n\nRaises:\n  ValueError: If eval set id is not valid or an eval set already exists. A\n  valid eval set id is string that has one or more of following characters:\n    - Lower case characters\n    - Upper case characters\n    - 0-9\n    - Underscore"
    - signature: 'def list_eval_sets(self, app_name: str) -> list[str]:'
      docstring: "Returns a list of EvalSets that belong to the given app_name.\n\nRaises:\n  NotFoundError: If the app_name doesn't exist."
    - signature: 'def get_eval_case(self, app_name: str, eval_set_id: str, eval_case_id: str) -> typing.Optional[google.adk.evaluation.eval_case.EvalCase]:'
      docstring: Returns an EvalCase if found; otherwise, None.
    - signature: 'def add_eval_case(self, app_name: str, eval_set_id: str, eval_case: google.adk.evaluation.eval_case.EvalCase):'
      docstring: "Adds the given EvalCase to an existing EvalSet identified by app_name and eval_set_id.\n\nRaises:\n  NotFoundError: If the eval set is not found."
    - signature: 'def update_eval_case(self, app_name: str, eval_set_id: str, updated_eval_case: google.adk.evaluation.eval_case.EvalCase):'
      docstring: "Updates an existing EvalCase give the app_name and eval_set_id.\n\nRaises:\n  NotFoundError: If the eval set or the eval case is not found."
    - signature: 'def delete_eval_case(self, app_name: str, eval_set_id: str, eval_case_id: str):'
      docstring: "Deletes the given EvalCase identified by app_name, eval_set_id and eval_case_id.\n\nRaises:\n  NotFoundError: If the eval set or the eval case to delete is not found."
  omitted_inherited_members_from:
  - ABC
- rank: 864
  id: google.adk.evaluation.local_eval_sets_manager.LocalEvalSetsManager.add_eval_case
  name: add_eval_case
  file_path: google/adk/evaluation/local_eval_sets_manager.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Adds the given EvalCase to an existing EvalSet identified by app_name and eval_set_id.\n\nRaises:\n  NotFoundError: If the eval set is not found."
  signature: 'def add_eval_case(self, app_name: str, eval_set_id: str, eval_case: google.adk.evaluation.eval_case.EvalCase):'
- rank: 865
  id: google.adk.evaluation.local_eval_sets_manager.LocalEvalSetsManager.create_eval_set
  name: create_eval_set
  file_path: google/adk/evaluation/local_eval_sets_manager.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Creates and returns an empty EvalSet given the app_name and eval_set_id.\n\nRaises:\n  ValueError: If Eval Set ID is not valid or an eval set already exists."
  signature: 'def create_eval_set(self, app_name: str, eval_set_id: str) -> google.adk.evaluation.eval_set.EvalSet:'
- rank: 866
  id: google.adk.evaluation.local_eval_sets_manager.LocalEvalSetsManager.delete_eval_case
  name: delete_eval_case
  file_path: google/adk/evaluation/local_eval_sets_manager.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Deletes the given EvalCase identified by app_name, eval_set_id and eval_case_id.\n\nRaises:\n  NotFoundError: If the eval set or the eval case to delete is not found."
  signature: 'def delete_eval_case(self, app_name: str, eval_set_id: str, eval_case_id: str):'
- rank: 867
  id: google.adk.evaluation.local_eval_sets_manager.LocalEvalSetsManager.get_eval_case
  name: get_eval_case
  file_path: google/adk/evaluation/local_eval_sets_manager.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: Returns an EvalCase if found; otherwise, None.
  signature: 'def get_eval_case(self, app_name: str, eval_set_id: str, eval_case_id: str) -> typing.Optional[google.adk.evaluation.eval_case.EvalCase]:'
- rank: 868
  id: google.adk.evaluation.local_eval_sets_manager.LocalEvalSetsManager.get_eval_set
  name: get_eval_set
  file_path: google/adk/evaluation/local_eval_sets_manager.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: Returns an EvalSet identified by an app_name and eval_set_id.
  signature: 'def get_eval_set(self, app_name: str, eval_set_id: str) -> typing.Optional[google.adk.evaluation.eval_set.EvalSet]:'
- rank: 869
  id: google.adk.evaluation.local_eval_sets_manager.LocalEvalSetsManager.list_eval_sets
  name: list_eval_sets
  file_path: google/adk/evaluation/local_eval_sets_manager.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Returns a list of EvalSets that belong to the given app_name.\n\nArgs:\n  app_name: The app name to list the eval sets for.\n\nReturns:\n  A list of EvalSet ids.\n\nRaises:\n  NotFoundError: If the eval directory for the app is not found."
  signature: 'def list_eval_sets(self, app_name: str) -> list[str]:'
- rank: 870
  id: google.adk.evaluation.local_eval_sets_manager.LocalEvalSetsManager.update_eval_case
  name: update_eval_case
  file_path: google/adk/evaluation/local_eval_sets_manager.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Updates an existing EvalCase give the app_name and eval_set_id.\n\nRaises:\n  NotFoundError: If the eval set or the eval case is not found."
  signature: 'def update_eval_case(self, app_name: str, eval_set_id: str, updated_eval_case: google.adk.evaluation.eval_case.EvalCase):'
- rank: 871
  id: google.adk.evaluation.local_eval_sets_manager.convert_eval_set_to_pydantic_schema
  name: convert_eval_set_to_pydantic_schema
  file_path: google/adk/evaluation/local_eval_sets_manager.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Returns a pydantic EvalSet generated from the json representation.\n\n  Args:\n    eval_set_id: Eval set id.\n    eval_set_in_json_format: Eval set specified in JSON format.\n\n  Here is a sample eval set in JSON format:\n[\n  {\n    \"name\": \"roll_17_sided_dice_twice\",\n    \"data\": [\n      {\n        \"query\": \"What can you do?\",\n        \"expected_tool_use\": [],\n        \"expected_intermediate_agent_responses\": [],\n        \"reference\": \"I can roll dice of different sizes and check if a number\n          is prime. I can also use multiple tools in parallel.\\n\"\n      },\n      {\n        \"query\": \"Roll a 17 sided dice twice for me\",\n        \"expected_tool_use\": [\n          {\n            \"tool_name\": \"roll_die\",\n            \"tool_input\": {\n              \"sides\": 17\n            }\n          },\n          {\n            \"tool_name\": \"roll_die\",\n            \"tool_input\": {\n              \"sides\": 17\n            }\n          }\n \
    \       ],\n        \"expected_intermediate_agent_responses\": [],\n        \"reference\": \"I have rolled a 17 sided die twice. The first roll was\n          13 and the second roll was 4.\\n\"\n      }\n    ],\n    \"initial_session\": {\n      \"state\": {},\n      \"app_name\": \"hello_world\",\n      \"user_id\": \"user\"\n    }\n  }\n]"
  signature: 'def convert_eval_set_to_pydantic_schema(eval_set_id: str, eval_set_in_json_format: list[dict[str, typing.Any]]) -> google.adk.evaluation.eval_set.EvalSet:'
- rank: 872
  id: google.adk.evaluation.local_eval_sets_manager.load_eval_set_from_file
  name: load_eval_set_from_file
  file_path: google/adk/evaluation/local_eval_sets_manager.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: Returns an EvalSet that is read from the given file.
  signature: 'def load_eval_set_from_file(eval_set_file_path: str, eval_set_id: str) -> google.adk.evaluation.eval_set.EvalSet:'
- rank: 873
  id: google.adk.evaluation.metric_evaluator_registry
  name: metric_evaluator_registry
  file_path: google/adk/evaluation/metric_evaluator_registry.py
  type: MODULE
  group: Orphan
  usage_score: 0
- rank: 874
  id: google.adk.evaluation.metric_evaluator_registry.MetricEvaluatorRegistry
  name: MetricEvaluatorRegistry
  file_path: google/adk/evaluation/metric_evaluator_registry.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: A registry for metric Evaluators.
  methods:
  - signature: 'def get_evaluator(self, eval_metric: google.adk.evaluation.eval_metrics.EvalMetric) -> google.adk.evaluation.evaluator.Evaluator:'
    docstring: "Returns an Evaluator for the given metric.\n\nA new instance of the Evaluator is returned.\n\nArgs:\n  eval_metric: The metric for which we need the Evaluator.\n\nRaises:\n  NotFoundError: If there is no evaluator for the metric."
  - signature: 'def register_evaluator(self, metric_info: google.adk.evaluation.eval_metrics.MetricInfo, evaluator: type[google.adk.evaluation.evaluator.Evaluator]):'
    docstring: 'Registers an evaluator given the metric info.


      If a mapping already exist, then it is updated.'
  - signature: 'def get_registered_metrics(self) -> list[google.adk.evaluation.eval_metrics.MetricInfo]:'
    docstring: Returns a list of MetricInfo about the metrics registered so far.
- rank: 875
  id: google.adk.evaluation.metric_evaluator_registry.MetricEvaluatorRegistry.get_evaluator
  name: get_evaluator
  file_path: google/adk/evaluation/metric_evaluator_registry.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Returns an Evaluator for the given metric.\n\nA new instance of the Evaluator is returned.\n\nArgs:\n  eval_metric: The metric for which we need the Evaluator.\n\nRaises:\n  NotFoundError: If there is no evaluator for the metric."
  signature: 'def get_evaluator(self, eval_metric: google.adk.evaluation.eval_metrics.EvalMetric) -> google.adk.evaluation.evaluator.Evaluator:'
- rank: 876
  id: google.adk.evaluation.metric_evaluator_registry.MetricEvaluatorRegistry.get_registered_metrics
  name: get_registered_metrics
  file_path: google/adk/evaluation/metric_evaluator_registry.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: Returns a list of MetricInfo about the metrics registered so far.
  signature: 'def get_registered_metrics(self) -> list[google.adk.evaluation.eval_metrics.MetricInfo]:'
- rank: 877
  id: google.adk.evaluation.metric_evaluator_registry.MetricEvaluatorRegistry.register_evaluator
  name: register_evaluator
  file_path: google/adk/evaluation/metric_evaluator_registry.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: 'Registers an evaluator given the metric info.


    If a mapping already exist, then it is updated.'
  signature: 'def register_evaluator(self, metric_info: google.adk.evaluation.eval_metrics.MetricInfo, evaluator: type[google.adk.evaluation.evaluator.Evaluator]):'
- rank: 878
  id: google.adk.evaluation.request_intercepter_plugin
  name: request_intercepter_plugin
  file_path: google/adk/evaluation/request_intercepter_plugin.py
  type: MODULE
  group: Orphan
  usage_score: 0
- rank: 879
  id: google.adk.evaluation.response_evaluator
  name: response_evaluator
  file_path: google/adk/evaluation/response_evaluator.py
  type: MODULE
  group: Orphan
  usage_score: 0
- rank: 880
  id: google.adk.evaluation.response_evaluator.ResponseEvaluator
  name: ResponseEvaluator
  file_path: google/adk/evaluation/response_evaluator.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Evaluates Agent''s responses.


    This class supports two metrics:

    1) response_evaluation_score

    This metric evaluates how coherent agent''s response was.


    Value range of this metric is [1,5], with values closer to 5 more desirable.


    2) response_match_score:

    This metric evaluates if agent''s final response matches a golden/expected

    final response using Rouge_1 metric.


    Value range for this metric is [0,1], with values closer to 1 more desirable.


    [Note: Inherited members from ABC are omitted.]'
  constructor_signature: 'def __init__(self, threshold: typing.Optional[float], metric_name: typing.Optional[str], eval_metric: typing.Optional[google.adk.evaluation.eval_metrics.EvalMetric]):'
  methods:
  - signature: 'def get_metric_info(metric_name: str) -> google.adk.evaluation.eval_metrics.MetricInfo:'
    docstring: Returns MetricInfo for the given metric name.
  - signature: 'def evaluate_invocations(self, actual_invocations: list[google.adk.evaluation.eval_case.Invocation], expected_invocations: typing.Optional[list[google.adk.evaluation.eval_case.Invocation]]) -> google.adk.evaluation.evaluator.EvaluationResult:'
  inherited_methods:
    Evaluator:
    - signature: 'def evaluate_invocations(self, actual_invocations: list[google.adk.evaluation.eval_case.Invocation], expected_invocations: typing.Optional[list[google.adk.evaluation.eval_case.Invocation]]) -> google.adk.evaluation.evaluator.EvaluationResult:'
      docstring: "Returns EvaluationResult after performing evaluations using actual and expected invocations.\n\nArgs:\n  actual_invocations: These are the invocations that are obtained from the\n    agent under test.\n  expected_invocations: An optional list of invocations, if specified,\n    usually act as a benchmark/golden response. If these are specified\n    usually the expectation is that the length of this list and actual\n    invocation is the same."
  inherited_properties:
    Evaluator:
    - signature: 'criterion_type: typing.ClassVar[type[google.adk.evaluation.eval_metrics.BaseCriterion]]'
  omitted_inherited_members_from:
  - ABC
- rank: 881
  id: google.adk.evaluation.response_evaluator.ResponseEvaluator.__init__
  name: __init__
  file_path: google/adk/evaluation/response_evaluator.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def __init__(self, threshold: typing.Optional[float], metric_name: typing.Optional[str], eval_metric: typing.Optional[google.adk.evaluation.eval_metrics.EvalMetric]):'
- rank: 882
  id: google.adk.evaluation.response_evaluator.ResponseEvaluator.evaluate_invocations
  name: evaluate_invocations
  file_path: google/adk/evaluation/response_evaluator.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def evaluate_invocations(self, actual_invocations: list[google.adk.evaluation.eval_case.Invocation], expected_invocations: typing.Optional[list[google.adk.evaluation.eval_case.Invocation]]) -> google.adk.evaluation.evaluator.EvaluationResult:'
- rank: 883
  id: google.adk.evaluation.response_evaluator.ResponseEvaluator.get_metric_info
  name: get_metric_info
  file_path: google/adk/evaluation/response_evaluator.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: Returns MetricInfo for the given metric name.
  signature: 'def get_metric_info(metric_name: str) -> google.adk.evaluation.eval_metrics.MetricInfo:'
- rank: 884
  id: google.adk.evaluation.rubric_based_evaluator
  name: rubric_based_evaluator
  file_path: google/adk/evaluation/rubric_based_evaluator.py
  type: MODULE
  group: Orphan
  usage_score: 0
- rank: 885
  id: google.adk.evaluation.rubric_based_evaluator.AutoRaterResponseParser
  name: AutoRaterResponseParser
  file_path: google/adk/evaluation/rubric_based_evaluator.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'An interface for parsing auto rater''s response.


    [Note: Inherited members from abc.ABC are omitted.]'
  methods:
  - signature: 'def parse(self, auto_rater_response: str) -> list[google.adk.evaluation.rubric_based_evaluator.RubricResponse]:'
    docstring: Parses the auto rater's response.
  omitted_inherited_members_from:
  - abc.ABC
- rank: 886
  id: google.adk.evaluation.rubric_based_evaluator.DefaultAutoRaterResponseParser
  name: DefaultAutoRaterResponseParser
  file_path: google/adk/evaluation/rubric_based_evaluator.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'The default implementation of the AutoRaterResponseParser.


    [Note: Inherited members from abc.ABC are omitted.]'
  methods:
  - signature: 'def parse(self, auto_rater_response: str) -> list[google.adk.evaluation.rubric_based_evaluator.RubricResponse]:'
    docstring: Returns a list of RubricResponse parsed from the AutoRater's response.
  inherited_methods:
    AutoRaterResponseParser:
    - signature: 'def parse(self, auto_rater_response: str) -> list[google.adk.evaluation.rubric_based_evaluator.RubricResponse]:'
      docstring: Parses the auto rater's response.
  omitted_inherited_members_from:
  - abc.ABC
- rank: 887
  id: google.adk.evaluation.rubric_based_evaluator.DefaultAutoRaterResponseParser.parse
  name: parse
  file_path: google/adk/evaluation/rubric_based_evaluator.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: Returns a list of RubricResponse parsed from the AutoRater's response.
  signature: 'def parse(self, auto_rater_response: str) -> list[google.adk.evaluation.rubric_based_evaluator.RubricResponse]:'
- rank: 888
  id: google.adk.evaluation.rubric_based_evaluator.InvocationResultsSummarizer
  name: InvocationResultsSummarizer
  file_path: google/adk/evaluation/rubric_based_evaluator.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'An interface for summarizing per invocation results.


    [Note: Inherited members from abc.ABC are omitted.]'
  methods:
  - signature: 'def summarize(self, per_invocation_results: list[google.adk.evaluation.evaluator.PerInvocationResult], threshold: float) -> google.adk.evaluation.evaluator.EvaluationResult:'
    docstring: Summaries per invocation results into a single result.
  omitted_inherited_members_from:
  - abc.ABC
- rank: 889
  id: google.adk.evaluation.rubric_based_evaluator.InvocationResultsSummarizer.summarize
  name: summarize
  file_path: google/adk/evaluation/rubric_based_evaluator.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: Summaries per invocation results into a single result.
  signature: 'def summarize(self, per_invocation_results: list[google.adk.evaluation.evaluator.PerInvocationResult], threshold: float) -> google.adk.evaluation.evaluator.EvaluationResult:'
- rank: 890
  id: google.adk.evaluation.rubric_based_evaluator.MajorityVotePerInvocationResultsAggregator
  name: MajorityVotePerInvocationResultsAggregator
  file_path: google/adk/evaluation/rubric_based_evaluator.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Aggregates per invocation samples using majority vote.


    [Note: Inherited members from abc.ABC are omitted.]'
  methods:
  - signature: 'def aggregate(self, per_invocation_samples: list[google.adk.evaluation.evaluator.PerInvocationResult], threshold: float) -> google.adk.evaluation.evaluator.PerInvocationResult:'
    docstring: "Returns a combined result for the invocation using majority vote.\n\nThis method takes all those samples for a single invocation and combines\nthem to generate one single result for the invocation.\n\nThis method specifically uses majority vote to aggregate scores for a\nrubric. Take following Invocation and Rubric for example:\n\n  Invocation:\n     User: Is it going to be cold in Seattle tomorrow?\n     Weather Agent: No, it will be moderately warm as predicted temperature\n     for Seattle, WA tomorrow is 88F.\n\n  Rubric: Agent's response was concise and to the point.\n\n  We will sample the AutoRater 5 times, and the AutoRater responds\n  with (skipping the rationale field for now):\n    Sample 1:\n      Verdict: Yes\n    Sample 2:\n      Verdict: No\n    Sample 3:\n      Verdict: Yes\n    Sample 4:\n      Verdict: Yes\n    Sample 5:\n      Verdict: No\n\n  This method will use majority vote and combine the results of 5 samples\n  into one, and it will report \"Yes\"\
      \ as the final verdict."
  inherited_methods:
    PerInvocationResultsAggregator:
    - signature: 'def aggregate(self, per_invocation_samples: list[google.adk.evaluation.evaluator.PerInvocationResult], threshold: float) -> google.adk.evaluation.evaluator.PerInvocationResult:'
      docstring: Aggregates per invocation samples into a single result.
  omitted_inherited_members_from:
  - abc.ABC
- rank: 891
  id: google.adk.evaluation.rubric_based_evaluator.MajorityVotePerInvocationResultsAggregator.aggregate
  name: aggregate
  file_path: google/adk/evaluation/rubric_based_evaluator.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Returns a combined result for the invocation using majority vote.\n\nThis method takes all those samples for a single invocation and combines\nthem to generate one single result for the invocation.\n\nThis method specifically uses majority vote to aggregate scores for a\nrubric. Take following Invocation and Rubric for example:\n\n  Invocation:\n     User: Is it going to be cold in Seattle tomorrow?\n     Weather Agent: No, it will be moderately warm as predicted temperature\n     for Seattle, WA tomorrow is 88F.\n\n  Rubric: Agent's response was concise and to the point.\n\n  We will sample the AutoRater 5 times, and the AutoRater responds\n  with (skipping the rationale field for now):\n    Sample 1:\n      Verdict: Yes\n    Sample 2:\n      Verdict: No\n    Sample 3:\n      Verdict: Yes\n    Sample 4:\n      Verdict: Yes\n    Sample 5:\n      Verdict: No\n\n  This method will use majority vote and combine the results of 5 samples\n  into one, and it will report \"Yes\" as\
    \ the final verdict."
  signature: 'def aggregate(self, per_invocation_samples: list[google.adk.evaluation.evaluator.PerInvocationResult], threshold: float) -> google.adk.evaluation.evaluator.PerInvocationResult:'
- rank: 892
  id: google.adk.evaluation.rubric_based_evaluator.MeanInvocationResultsSummarizer
  name: MeanInvocationResultsSummarizer
  file_path: google/adk/evaluation/rubric_based_evaluator.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Summarizes per invocation results using mean score.


    [Note: Inherited members from abc.ABC are omitted.]'
  methods:
  - signature: 'def summarize(self, per_invocation_results: list[google.adk.evaluation.evaluator.PerInvocationResult], threshold: float) -> google.adk.evaluation.evaluator.EvaluationResult:'
    docstring: 'Summarizes per invocation evaluation results into a single score.


      A single eval case can have multiple invocations and the eval metric is

      assessed for each invocation. But, we do want to summarize and make a

      statement on how the eval case as a whole performed on the metric.


      This method helps us aggregate rubric scores across invocation.


      This method calculates the mean score of a rubric across several

      invocations.'
  inherited_methods:
    InvocationResultsSummarizer:
    - signature: 'def summarize(self, per_invocation_results: list[google.adk.evaluation.evaluator.PerInvocationResult], threshold: float) -> google.adk.evaluation.evaluator.EvaluationResult:'
      docstring: Summaries per invocation results into a single result.
  omitted_inherited_members_from:
  - abc.ABC
- rank: 893
  id: google.adk.evaluation.rubric_based_evaluator.MeanInvocationResultsSummarizer.summarize
  name: summarize
  file_path: google/adk/evaluation/rubric_based_evaluator.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: 'Summarizes per invocation evaluation results into a single score.


    A single eval case can have multiple invocations and the eval metric is

    assessed for each invocation. But, we do want to summarize and make a

    statement on how the eval case as a whole performed on the metric.


    This method helps us aggregate rubric scores across invocation.


    This method calculates the mean score of a rubric across several

    invocations.'
  signature: 'def summarize(self, per_invocation_results: list[google.adk.evaluation.evaluator.PerInvocationResult], threshold: float) -> google.adk.evaluation.evaluator.EvaluationResult:'
- rank: 894
  id: google.adk.evaluation.rubric_based_evaluator.PerInvocationResultsAggregator
  name: PerInvocationResultsAggregator
  file_path: google/adk/evaluation/rubric_based_evaluator.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'An interface for aggregating per invocation samples.


    AutoRaters that are backed by an LLM are known to have certain degree of

    unreliabilty to their responses. In order to counter that we sample the

    autorater more than once for a single invocation.


    The aggregator helps convert those multiple samples into a single result.


    [Note: Inherited members from abc.ABC are omitted.]'
  methods:
  - signature: 'def aggregate(self, per_invocation_samples: list[google.adk.evaluation.evaluator.PerInvocationResult], threshold: float) -> google.adk.evaluation.evaluator.PerInvocationResult:'
    docstring: Aggregates per invocation samples into a single result.
  omitted_inherited_members_from:
  - abc.ABC
- rank: 895
  id: google.adk.evaluation.rubric_based_evaluator.PerInvocationResultsAggregator.aggregate
  name: aggregate
  file_path: google/adk/evaluation/rubric_based_evaluator.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: Aggregates per invocation samples into a single result.
  signature: 'def aggregate(self, per_invocation_samples: list[google.adk.evaluation.evaluator.PerInvocationResult], threshold: float) -> google.adk.evaluation.evaluator.PerInvocationResult:'
- rank: 896
  id: google.adk.evaluation.rubric_based_evaluator.RubricBasedEvaluator
  name: RubricBasedEvaluator
  file_path: google/adk/evaluation/rubric_based_evaluator.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'A base class for rubric based evaluators.


    [Note: Inherited members from ABC are omitted.]'
  constructor_signature: 'def __init__(self, eval_metric: google.adk.evaluation.eval_metrics.EvalMetric, criterion_type: type[google.adk.evaluation.eval_metrics.BaseCriterion], auto_rater_response_parser: google.adk.evaluation.rubric_based_evaluator.AutoRaterResponseParser, per_invocation_results_aggregator: google.adk.evaluation.rubric_based_evaluator.PerInvocationResultsAggregator, invocation_results_summarizer: google.adk.evaluation.rubric_based_evaluator.InvocationResultsSummarizer):'
  methods:
  - signature: 'def convert_auto_rater_response_to_score(self, auto_rater_response: google.adk.models.llm_response.LlmResponse) -> google.adk.evaluation.llm_as_judge.AutoRaterScore:'
    docstring: Returns an AutoRaterScore generated from AutoRater's response.
  - signature: 'def aggregate_per_invocation_samples(self, per_invocation_samples: list[google.adk.evaluation.evaluator.PerInvocationResult]) -> google.adk.evaluation.evaluator.PerInvocationResult:'
    docstring: 'Returns a combined result by aggregating multiple samples for the same invocation.


      AutoRaters that are backed by an LLM are known to have certain degree of

      unreliabilty to their responses. In order to counter that we sample the

      autorater more than once for a single invocation.


      The aggregator helps convert those multiple samples into a single result.'
  - signature: 'def aggregate_invocation_results(self, per_invocation_results: list[google.adk.evaluation.evaluator.PerInvocationResult]) -> google.adk.evaluation.evaluator.EvaluationResult:'
    docstring: Summarizes per invocation evaluation results into a single score.
  inherited_methods:
    LlmAsJudge:
    - signature: 'def format_auto_rater_prompt(self, actual: google.adk.evaluation.eval_case.Invocation, expected: typing.Optional[google.adk.evaluation.eval_case.Invocation]) -> str:'
      docstring: Formats the auto-rater prompt to evaluate the given invocation.
    - signature: 'def convert_auto_rater_response_to_score(self, auto_rater_response: google.adk.models.llm_response.LlmResponse) -> google.adk.evaluation.llm_as_judge.AutoRaterScore:'
      docstring: Parses auto_rater_response and returns the corresponding score, or None if the score cannot be determined.
    - signature: 'def aggregate_per_invocation_samples(self, per_invocation_samples: list[google.adk.evaluation.evaluator.PerInvocationResult]) -> google.adk.evaluation.evaluator.PerInvocationResult:'
      docstring: Aggregates repeated per-invocation samples to get the final result for the invocation.
    - signature: 'def aggregate_invocation_results(self, per_invocation_results: list[google.adk.evaluation.evaluator.PerInvocationResult]) -> google.adk.evaluation.evaluator.EvaluationResult:'
      docstring: Aggregates the per invocation results to get the overall score.
    - signature: 'def evaluate_invocations(self, actual_invocations: list[google.adk.evaluation.eval_case.Invocation], expected_invocations: typing.Optional[list[google.adk.evaluation.eval_case.Invocation]]) -> google.adk.evaluation.evaluator.EvaluationResult:'
    Evaluator:
    - signature: 'def evaluate_invocations(self, actual_invocations: list[google.adk.evaluation.eval_case.Invocation], expected_invocations: typing.Optional[list[google.adk.evaluation.eval_case.Invocation]]) -> google.adk.evaluation.evaluator.EvaluationResult:'
      docstring: "Returns EvaluationResult after performing evaluations using actual and expected invocations.\n\nArgs:\n  actual_invocations: These are the invocations that are obtained from the\n    agent under test.\n  expected_invocations: An optional list of invocations, if specified,\n    usually act as a benchmark/golden response. If these are specified\n    usually the expectation is that the length of this list and actual\n    invocation is the same."
  inherited_properties:
    Evaluator:
    - signature: 'criterion_type: typing.ClassVar[type[google.adk.evaluation.eval_metrics.BaseCriterion]]'
  omitted_inherited_members_from:
  - ABC
- rank: 897
  id: google.adk.evaluation.rubric_based_evaluator.RubricBasedEvaluator.__init__
  name: __init__
  file_path: google/adk/evaluation/rubric_based_evaluator.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Initializes the RubricBasedEvaluator.\n\nArgs:\n  eval_metric: The evaluation metric configuration.\n  criterion_type: The type of the criterion used for this evaluator.\n  auto_rater_response_parser: An object that parses the auto-rater's\n    response text and extracts rubric scores.\n  per_invocation_results_aggregator: An object that aggregates multiple\n    samples for a single invocation into a single result. This is useful in\n    cases where the auto-rater is an LLM and multiple samples are generated\n    to account for the unreliability of the LLM.\n  invocation_results_summarizer: An object that summarizes the results of\n    all invocations in an eval case into a single result."
  signature: 'def __init__(self, eval_metric: google.adk.evaluation.eval_metrics.EvalMetric, criterion_type: type[google.adk.evaluation.eval_metrics.BaseCriterion], auto_rater_response_parser: google.adk.evaluation.rubric_based_evaluator.AutoRaterResponseParser, per_invocation_results_aggregator: google.adk.evaluation.rubric_based_evaluator.PerInvocationResultsAggregator, invocation_results_summarizer: google.adk.evaluation.rubric_based_evaluator.InvocationResultsSummarizer):'
- rank: 898
  id: google.adk.evaluation.rubric_based_evaluator.RubricBasedEvaluator.aggregate_invocation_results
  name: aggregate_invocation_results
  file_path: google/adk/evaluation/rubric_based_evaluator.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: Summarizes per invocation evaluation results into a single score.
  signature: 'def aggregate_invocation_results(self, per_invocation_results: list[google.adk.evaluation.evaluator.PerInvocationResult]) -> google.adk.evaluation.evaluator.EvaluationResult:'
- rank: 899
  id: google.adk.evaluation.rubric_based_evaluator.RubricBasedEvaluator.aggregate_per_invocation_samples
  name: aggregate_per_invocation_samples
  file_path: google/adk/evaluation/rubric_based_evaluator.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: 'Returns a combined result by aggregating multiple samples for the same invocation.


    AutoRaters that are backed by an LLM are known to have certain degree of

    unreliabilty to their responses. In order to counter that we sample the

    autorater more than once for a single invocation.


    The aggregator helps convert those multiple samples into a single result.'
  signature: 'def aggregate_per_invocation_samples(self, per_invocation_samples: list[google.adk.evaluation.evaluator.PerInvocationResult]) -> google.adk.evaluation.evaluator.PerInvocationResult:'
- rank: 900
  id: google.adk.evaluation.rubric_based_evaluator.RubricBasedEvaluator.convert_auto_rater_response_to_score
  name: convert_auto_rater_response_to_score
  file_path: google/adk/evaluation/rubric_based_evaluator.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: Returns an AutoRaterScore generated from AutoRater's response.
  signature: 'def convert_auto_rater_response_to_score(self, auto_rater_response: google.adk.models.llm_response.LlmResponse) -> google.adk.evaluation.llm_as_judge.AutoRaterScore:'
- rank: 901
  id: google.adk.evaluation.rubric_based_evaluator.RubricResponse
  name: RubricResponse
  file_path: google/adk/evaluation/rubric_based_evaluator.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Internal data model to represent a rubric''s response from the auto-rater.


    [Note: Inherited members from pydantic.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, property_text: typing.Optional[str] = None, rationale: typing.Optional[str] = None, score: typing.Optional[float] = None):'
  properties:
  - signature: 'property_text: typing.Optional[str]'
  - signature: 'rationale: typing.Optional[str]'
  - signature: 'score: typing.Optional[float]'
  inherited_properties:
    EvalBaseModel:
    - signature: 'model_config: pydantic.ConfigDict'
  omitted_inherited_members_from:
  - pydantic.BaseModel
- rank: 902
  id: google.adk.evaluation.rubric_based_final_response_quality_v1
  name: rubric_based_final_response_quality_v1
  file_path: google/adk/evaluation/rubric_based_final_response_quality_v1.py
  type: MODULE
  group: Orphan
  usage_score: 0
- rank: 903
  id: google.adk.evaluation.rubric_based_final_response_quality_v1.RubricBasedFinalResponseQualityV1Evaluator
  name: RubricBasedFinalResponseQualityV1Evaluator
  file_path: google/adk/evaluation/rubric_based_final_response_quality_v1.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'An Evaluator for rubric based assessment of the agent''s final response using a LLM.


    The evaluator uses a set of rubrics to assess the quality of the agent''s

    final response.


    Example: For a weather agent that responds to weather related queries of the

    user, one could specify following rubrics:


    Rubric 1: Agent''s response is direct and to the point.

    Rubric 2: Agent''s response accurately inferred user''s underlying goal from

    ambiguous queries (e.g. "is it a beach weather?" would mean sun, warmth and

    low wind)


    For each rubric, this evaluator will generate a confidence score between 0

    and 1, where 0 means that agent''s response did not satisfy the rubric at all

    and 1 means complete adherence. Value closer to 1 are desirable.


    A combined score using individual rubric confidences will also be generated.

    Like individual rubric confidence scores, the range for this value will be

    between 0 and 1, and it will have the same interpretation.


    [Note: Inherited members from ABC are omitted.]'
  constructor_signature: 'def __init__(self, eval_metric: google.adk.evaluation.eval_metrics.EvalMetric):'
  methods:
  - signature: 'def get_metric_info() -> google.adk.evaluation.eval_metrics.MetricInfo:'
  - signature: 'def format_auto_rater_prompt(self, actual_invocation: google.adk.evaluation.eval_case.Invocation, _: typing.Optional[google.adk.evaluation.eval_case.Invocation]) -> str:'
    docstring: Returns the autorater prompt.
  properties:
  - signature: 'criterion_type: typing.ClassVar[type[google.adk.evaluation.eval_metrics.RubricsBasedCriterion]]'
  inherited_methods:
    RubricBasedEvaluator:
    - signature: 'def convert_auto_rater_response_to_score(self, auto_rater_response: google.adk.models.llm_response.LlmResponse) -> google.adk.evaluation.llm_as_judge.AutoRaterScore:'
      docstring: Returns an AutoRaterScore generated from AutoRater's response.
    - signature: 'def aggregate_per_invocation_samples(self, per_invocation_samples: list[google.adk.evaluation.evaluator.PerInvocationResult]) -> google.adk.evaluation.evaluator.PerInvocationResult:'
      docstring: 'Returns a combined result by aggregating multiple samples for the same invocation.


        AutoRaters that are backed by an LLM are known to have certain degree of

        unreliabilty to their responses. In order to counter that we sample the

        autorater more than once for a single invocation.


        The aggregator helps convert those multiple samples into a single result.'
    - signature: 'def aggregate_invocation_results(self, per_invocation_results: list[google.adk.evaluation.evaluator.PerInvocationResult]) -> google.adk.evaluation.evaluator.EvaluationResult:'
      docstring: Summarizes per invocation evaluation results into a single score.
    LlmAsJudge:
    - signature: 'def format_auto_rater_prompt(self, actual: google.adk.evaluation.eval_case.Invocation, expected: typing.Optional[google.adk.evaluation.eval_case.Invocation]) -> str:'
      docstring: Formats the auto-rater prompt to evaluate the given invocation.
    - signature: 'def convert_auto_rater_response_to_score(self, auto_rater_response: google.adk.models.llm_response.LlmResponse) -> google.adk.evaluation.llm_as_judge.AutoRaterScore:'
      docstring: Parses auto_rater_response and returns the corresponding score, or None if the score cannot be determined.
    - signature: 'def aggregate_per_invocation_samples(self, per_invocation_samples: list[google.adk.evaluation.evaluator.PerInvocationResult]) -> google.adk.evaluation.evaluator.PerInvocationResult:'
      docstring: Aggregates repeated per-invocation samples to get the final result for the invocation.
    - signature: 'def aggregate_invocation_results(self, per_invocation_results: list[google.adk.evaluation.evaluator.PerInvocationResult]) -> google.adk.evaluation.evaluator.EvaluationResult:'
      docstring: Aggregates the per invocation results to get the overall score.
    - signature: 'def evaluate_invocations(self, actual_invocations: list[google.adk.evaluation.eval_case.Invocation], expected_invocations: typing.Optional[list[google.adk.evaluation.eval_case.Invocation]]) -> google.adk.evaluation.evaluator.EvaluationResult:'
    Evaluator:
    - signature: 'def evaluate_invocations(self, actual_invocations: list[google.adk.evaluation.eval_case.Invocation], expected_invocations: typing.Optional[list[google.adk.evaluation.eval_case.Invocation]]) -> google.adk.evaluation.evaluator.EvaluationResult:'
      docstring: "Returns EvaluationResult after performing evaluations using actual and expected invocations.\n\nArgs:\n  actual_invocations: These are the invocations that are obtained from the\n    agent under test.\n  expected_invocations: An optional list of invocations, if specified,\n    usually act as a benchmark/golden response. If these are specified\n    usually the expectation is that the length of this list and actual\n    invocation is the same."
  inherited_properties:
    Evaluator:
    - signature: 'criterion_type: typing.ClassVar[type[google.adk.evaluation.eval_metrics.BaseCriterion]]'
  omitted_inherited_members_from:
  - ABC
- rank: 904
  id: google.adk.evaluation.rubric_based_final_response_quality_v1.RubricBasedFinalResponseQualityV1Evaluator.__init__
  name: __init__
  file_path: google/adk/evaluation/rubric_based_final_response_quality_v1.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def __init__(self, eval_metric: google.adk.evaluation.eval_metrics.EvalMetric):'
- rank: 905
  id: google.adk.evaluation.rubric_based_final_response_quality_v1.RubricBasedFinalResponseQualityV1Evaluator.format_auto_rater_prompt
  name: format_auto_rater_prompt
  file_path: google/adk/evaluation/rubric_based_final_response_quality_v1.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: Returns the autorater prompt.
  signature: 'def format_auto_rater_prompt(self, actual_invocation: google.adk.evaluation.eval_case.Invocation, _: typing.Optional[google.adk.evaluation.eval_case.Invocation]) -> str:'
- rank: 906
  id: google.adk.evaluation.rubric_based_final_response_quality_v1.RubricBasedFinalResponseQualityV1Evaluator.get_metric_info
  name: get_metric_info
  file_path: google/adk/evaluation/rubric_based_final_response_quality_v1.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def get_metric_info() -> google.adk.evaluation.eval_metrics.MetricInfo:'
- rank: 907
  id: google.adk.evaluation.rubric_based_tool_use_quality_v1
  name: rubric_based_tool_use_quality_v1
  file_path: google/adk/evaluation/rubric_based_tool_use_quality_v1.py
  type: MODULE
  group: Orphan
  usage_score: 0
- rank: 908
  id: google.adk.evaluation.rubric_based_tool_use_quality_v1.RubricBasedToolUseV1Evaluator
  name: RubricBasedToolUseV1Evaluator
  file_path: google/adk/evaluation/rubric_based_tool_use_quality_v1.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'An Evaluator for rubric based assessment of the agent''s usage of Tools.


    Example: Lets take an example of a Weather Agent that has access to two tools:

    1: GeoCoding Tool: Coverts a city name, address or zip code into geographic

    coordinates.

    2: GetWeather Tool: Gets weather for the next 10 days for the given geographic

    coordinates.


    For this agent, one can create following Rubrics that could focus on tool use


    Rubric 1: A call is made to GeoCoding Tool.

    Rubric 2: A call is made to GetWeather Tool.

    Rubric 3: The call to GetWeather Tool happens after the GeoCoding Tool.

    Rubric 4: The input to GeoCoding Tool can be mapped back to user prompt.

    Rubric 5: The input to GetWeather Tool comes from the output of GeoCoding

    Tool.)


    For each rubric, this evaluator will generate a confidence score between 0

    and 1, where 0 means that agent''s response did not satisfy the rubric at all

    and 1 means complete adherence. Value closer to 1 are desirable.


    A combined score using individual rubric confidences will also be generated.

    Like individual rubric confidence scores, the range for this value will be

    between 0 and 1, and it will have the same interpretation.


    [Note: Inherited members from ABC are omitted.]'
  constructor_signature: 'def __init__(self, eval_metric: google.adk.evaluation.eval_metrics.EvalMetric):'
  methods:
  - signature: 'def get_metric_info() -> google.adk.evaluation.eval_metrics.MetricInfo:'
  - signature: 'def format_auto_rater_prompt(self, actual_invocation: google.adk.evaluation.eval_case.Invocation, _: typing.Optional[google.adk.evaluation.eval_case.Invocation]) -> str:'
    docstring: Returns the autorater prompt.
  properties:
  - signature: 'criterion_type: typing.ClassVar[type[google.adk.evaluation.eval_metrics.RubricsBasedCriterion]]'
  inherited_methods:
    RubricBasedEvaluator:
    - signature: 'def convert_auto_rater_response_to_score(self, auto_rater_response: google.adk.models.llm_response.LlmResponse) -> google.adk.evaluation.llm_as_judge.AutoRaterScore:'
      docstring: Returns an AutoRaterScore generated from AutoRater's response.
    - signature: 'def aggregate_per_invocation_samples(self, per_invocation_samples: list[google.adk.evaluation.evaluator.PerInvocationResult]) -> google.adk.evaluation.evaluator.PerInvocationResult:'
      docstring: 'Returns a combined result by aggregating multiple samples for the same invocation.


        AutoRaters that are backed by an LLM are known to have certain degree of

        unreliabilty to their responses. In order to counter that we sample the

        autorater more than once for a single invocation.


        The aggregator helps convert those multiple samples into a single result.'
    - signature: 'def aggregate_invocation_results(self, per_invocation_results: list[google.adk.evaluation.evaluator.PerInvocationResult]) -> google.adk.evaluation.evaluator.EvaluationResult:'
      docstring: Summarizes per invocation evaluation results into a single score.
    LlmAsJudge:
    - signature: 'def format_auto_rater_prompt(self, actual: google.adk.evaluation.eval_case.Invocation, expected: typing.Optional[google.adk.evaluation.eval_case.Invocation]) -> str:'
      docstring: Formats the auto-rater prompt to evaluate the given invocation.
    - signature: 'def convert_auto_rater_response_to_score(self, auto_rater_response: google.adk.models.llm_response.LlmResponse) -> google.adk.evaluation.llm_as_judge.AutoRaterScore:'
      docstring: Parses auto_rater_response and returns the corresponding score, or None if the score cannot be determined.
    - signature: 'def aggregate_per_invocation_samples(self, per_invocation_samples: list[google.adk.evaluation.evaluator.PerInvocationResult]) -> google.adk.evaluation.evaluator.PerInvocationResult:'
      docstring: Aggregates repeated per-invocation samples to get the final result for the invocation.
    - signature: 'def aggregate_invocation_results(self, per_invocation_results: list[google.adk.evaluation.evaluator.PerInvocationResult]) -> google.adk.evaluation.evaluator.EvaluationResult:'
      docstring: Aggregates the per invocation results to get the overall score.
    - signature: 'def evaluate_invocations(self, actual_invocations: list[google.adk.evaluation.eval_case.Invocation], expected_invocations: typing.Optional[list[google.adk.evaluation.eval_case.Invocation]]) -> google.adk.evaluation.evaluator.EvaluationResult:'
    Evaluator:
    - signature: 'def evaluate_invocations(self, actual_invocations: list[google.adk.evaluation.eval_case.Invocation], expected_invocations: typing.Optional[list[google.adk.evaluation.eval_case.Invocation]]) -> google.adk.evaluation.evaluator.EvaluationResult:'
      docstring: "Returns EvaluationResult after performing evaluations using actual and expected invocations.\n\nArgs:\n  actual_invocations: These are the invocations that are obtained from the\n    agent under test.\n  expected_invocations: An optional list of invocations, if specified,\n    usually act as a benchmark/golden response. If these are specified\n    usually the expectation is that the length of this list and actual\n    invocation is the same."
  inherited_properties:
    Evaluator:
    - signature: 'criterion_type: typing.ClassVar[type[google.adk.evaluation.eval_metrics.BaseCriterion]]'
  omitted_inherited_members_from:
  - ABC
- rank: 909
  id: google.adk.evaluation.rubric_based_tool_use_quality_v1.RubricBasedToolUseV1Evaluator.__init__
  name: __init__
  file_path: google/adk/evaluation/rubric_based_tool_use_quality_v1.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def __init__(self, eval_metric: google.adk.evaluation.eval_metrics.EvalMetric):'
- rank: 910
  id: google.adk.evaluation.rubric_based_tool_use_quality_v1.RubricBasedToolUseV1Evaluator.format_auto_rater_prompt
  name: format_auto_rater_prompt
  file_path: google/adk/evaluation/rubric_based_tool_use_quality_v1.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: Returns the autorater prompt.
  signature: 'def format_auto_rater_prompt(self, actual_invocation: google.adk.evaluation.eval_case.Invocation, _: typing.Optional[google.adk.evaluation.eval_case.Invocation]) -> str:'
- rank: 911
  id: google.adk.evaluation.rubric_based_tool_use_quality_v1.RubricBasedToolUseV1Evaluator.get_metric_info
  name: get_metric_info
  file_path: google/adk/evaluation/rubric_based_tool_use_quality_v1.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def get_metric_info() -> google.adk.evaluation.eval_metrics.MetricInfo:'
- rank: 912
  id: google.adk.evaluation.safety_evaluator
  name: safety_evaluator
  file_path: google/adk/evaluation/safety_evaluator.py
  type: MODULE
  group: Orphan
  usage_score: 0
- rank: 913
  id: google.adk.evaluation.safety_evaluator.SafetyEvaluatorV1
  name: SafetyEvaluatorV1
  file_path: google/adk/evaluation/safety_evaluator.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Evaluates safety (harmlessness) of an Agent''s Response.


    The class delegates the responsibility to Vertex Gen AI Eval SDK. The V1

    suffix in the class name is added to convey that there could be other versions

    of the safety metric as well, and those metrics could use a different strategy

    to evaluate safety.


    Using this class requires a GCP project. Please set GOOGLE_CLOUD_PROJECT and

    GOOGLE_CLOUD_LOCATION in your .env file.


    Value range of the metric is [0, 1], with values closer to 1 to be more

    desirable (safe).


    [Note: Inherited members from ABC are omitted.]'
  constructor_signature: 'def __init__(self, eval_metric: google.adk.evaluation.eval_metrics.EvalMetric):'
  methods:
  - signature: 'def get_metric_info() -> google.adk.evaluation.eval_metrics.MetricInfo:'
  - signature: 'def evaluate_invocations(self, actual_invocations: list[google.adk.evaluation.eval_case.Invocation], expected_invocations: typing.Optional[list[google.adk.evaluation.eval_case.Invocation]]) -> google.adk.evaluation.evaluator.EvaluationResult:'
  inherited_methods:
    Evaluator:
    - signature: 'def evaluate_invocations(self, actual_invocations: list[google.adk.evaluation.eval_case.Invocation], expected_invocations: typing.Optional[list[google.adk.evaluation.eval_case.Invocation]]) -> google.adk.evaluation.evaluator.EvaluationResult:'
      docstring: "Returns EvaluationResult after performing evaluations using actual and expected invocations.\n\nArgs:\n  actual_invocations: These are the invocations that are obtained from the\n    agent under test.\n  expected_invocations: An optional list of invocations, if specified,\n    usually act as a benchmark/golden response. If these are specified\n    usually the expectation is that the length of this list and actual\n    invocation is the same."
  inherited_properties:
    Evaluator:
    - signature: 'criterion_type: typing.ClassVar[type[google.adk.evaluation.eval_metrics.BaseCriterion]]'
  omitted_inherited_members_from:
  - ABC
- rank: 914
  id: google.adk.evaluation.safety_evaluator.SafetyEvaluatorV1.evaluate_invocations
  name: evaluate_invocations
  file_path: google/adk/evaluation/safety_evaluator.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def evaluate_invocations(self, actual_invocations: list[google.adk.evaluation.eval_case.Invocation], expected_invocations: typing.Optional[list[google.adk.evaluation.eval_case.Invocation]]) -> google.adk.evaluation.evaluator.EvaluationResult:'
- rank: 915
  id: google.adk.evaluation.safety_evaluator.SafetyEvaluatorV1.get_metric_info
  name: get_metric_info
  file_path: google/adk/evaluation/safety_evaluator.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def get_metric_info() -> google.adk.evaluation.eval_metrics.MetricInfo:'
- rank: 916
  id: google.adk.evaluation.simulation
  name: simulation
  file_path: google/adk/evaluation/simulation/__init__.py
  type: MODULE
  group: Orphan
  usage_score: 0
- rank: 917
  id: google.adk.evaluation.simulation.llm_backed_user_simulator
  name: llm_backed_user_simulator
  file_path: google/adk/evaluation/simulation/llm_backed_user_simulator.py
  type: MODULE
  group: Orphan
  usage_score: 0
- rank: 918
  id: google.adk.evaluation.simulation.llm_backed_user_simulator.LlmBackedUserSimulator
  name: LlmBackedUserSimulator
  file_path: google/adk/evaluation/simulation/llm_backed_user_simulator.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'A UserSimulator that uses an LLM to generate messages on behalf of the user.


    [Note: Inherited members from ABC are omitted.]'
  constructor_signature: 'def __init__(self, *, config: google.adk.evaluation.simulation.user_simulator.BaseUserSimulatorConfig, conversation_scenario: google.adk.evaluation.conversation_scenarios.ConversationScenario):'
  methods:
  - signature: 'def get_next_user_message(self, events: list[google.adk.events.event.Event]) -> google.adk.evaluation.simulation.user_simulator.NextUserMessage:'
    docstring: "Returns the next user message to send to the agent with help from a LLM.\n\nArgs:\n  events: The unaltered conversation history between the user and the\n    agent(s) under evaluation.\n\nReturns:\n  A NextUserMessage object containing the next user message to send to the\n  agent, or a status indicating why no message was generated.\n\nRaises:\n  RuntimeError: If the user agent fails to generate a message. This is not a\n  valid result for the LLM backed user simulator and is different from the\n  NO_MESSAGE_GENERATED status."
  - signature: 'def get_simulation_evaluator(self) -> typing.Optional[google.adk.evaluation.evaluator.Evaluator]:'
    docstring: Returns an Evaluator that evaluates if the simulation was successful or not.
  properties:
  - signature: 'config_type: typing.ClassVar[type[google.adk.evaluation.simulation.llm_backed_user_simulator.LlmBackedUserSimulatorConfig]]'
  inherited_methods:
    UserSimulator:
    - signature: 'def get_next_user_message(self, events: list[google.adk.events.event.Event]) -> google.adk.evaluation.simulation.user_simulator.NextUserMessage:'
      docstring: "Returns the next user message to send to the agent.\n\nArgs:\n  events: The unaltered conversation history between the user and the\n    agent(s) under evaluation.\n\nReturns:\n  A NextUserMessage object containing the next user message to send to the\n  agent, or a status indicating why no message was generated."
    - signature: 'def get_simulation_evaluator(self) -> typing.Optional[google.adk.evaluation.evaluator.Evaluator]:'
      docstring: Returns an instance of an Evaluator that evaluates if the user simulation was successful or not.
  omitted_inherited_members_from:
  - ABC
- rank: 919
  id: google.adk.evaluation.simulation.llm_backed_user_simulator.LlmBackedUserSimulator.__init__
  name: __init__
  file_path: google/adk/evaluation/simulation/llm_backed_user_simulator.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def __init__(self, *, config: google.adk.evaluation.simulation.user_simulator.BaseUserSimulatorConfig, conversation_scenario: google.adk.evaluation.conversation_scenarios.ConversationScenario):'
- rank: 920
  id: google.adk.evaluation.simulation.llm_backed_user_simulator.LlmBackedUserSimulator.get_next_user_message
  name: get_next_user_message
  file_path: google/adk/evaluation/simulation/llm_backed_user_simulator.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Returns the next user message to send to the agent with help from a LLM.\n\nArgs:\n  events: The unaltered conversation history between the user and the\n    agent(s) under evaluation.\n\nReturns:\n  A NextUserMessage object containing the next user message to send to the\n  agent, or a status indicating why no message was generated.\n\nRaises:\n  RuntimeError: If the user agent fails to generate a message. This is not a\n  valid result for the LLM backed user simulator and is different from the\n  NO_MESSAGE_GENERATED status."
  signature: 'def get_next_user_message(self, events: list[google.adk.events.event.Event]) -> google.adk.evaluation.simulation.user_simulator.NextUserMessage:'
- rank: 921
  id: google.adk.evaluation.simulation.llm_backed_user_simulator.LlmBackedUserSimulator.get_simulation_evaluator
  name: get_simulation_evaluator
  file_path: google/adk/evaluation/simulation/llm_backed_user_simulator.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: Returns an Evaluator that evaluates if the simulation was successful or not.
  signature: 'def get_simulation_evaluator(self) -> typing.Optional[google.adk.evaluation.evaluator.Evaluator]:'
- rank: 922
  id: google.adk.evaluation.simulation.llm_backed_user_simulator.LlmBackedUserSimulatorConfig
  name: LlmBackedUserSimulatorConfig
  file_path: google/adk/evaluation/simulation/llm_backed_user_simulator.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Contains configurations required by an LLM backed user simulator.


    [Note: Inherited members from pydantic.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, model: str = ''gemini-2.5-flash'', model_configuration: google.genai.types.GenerateContentConfig = Factory(lambda: genai_types.GenerateContentConfig(thinking_config=genai_types.ThinkingConfig(include_thoughts=True, thinking_budget=10240))), max_allowed_invocations: int = 20):'
  properties:
  - signature: 'model: str'
  - signature: 'model_configuration: google.genai.types.GenerateContentConfig'
  - signature: 'max_allowed_invocations: int'
  inherited_properties:
    BaseUserSimulatorConfig:
    - signature: 'model_config: pydantic.ConfigDict'
    BaseModel:
    - signature: 'model_config: pydantic.ConfigDict'
  omitted_inherited_members_from:
  - pydantic.BaseModel
- rank: 923
  id: google.adk.evaluation.simulation.static_user_simulator
  name: static_user_simulator
  file_path: google/adk/evaluation/simulation/static_user_simulator.py
  type: MODULE
  group: Orphan
  usage_score: 0
- rank: 924
  id: google.adk.evaluation.simulation.static_user_simulator.StaticUserSimulator
  name: StaticUserSimulator
  file_path: google/adk/evaluation/simulation/static_user_simulator.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'A UserSimulator that returns a static list of user messages.


    [Note: Inherited members from ABC are omitted.]'
  constructor_signature: 'def __init__(self, *, static_conversation: google.adk.evaluation.eval_case.StaticConversation):'
  methods:
  - signature: 'def get_next_user_message(self, events: list[google.adk.events.event.Event]) -> google.adk.evaluation.simulation.user_simulator.NextUserMessage:'
    docstring: "Returns the next user message to send to the agent from a static list.\n\nArgs:\n  events: The unaltered conversation history between the user and the\n    agent(s) under evaluation.\n\nReturns:\n  A NextUserMessage object containing the next user message to send to the\n  agent, or a status indicating why no message was generated."
  - signature: 'def get_simulation_evaluator(self) -> typing.Optional[google.adk.evaluation.evaluator.Evaluator]:'
    docstring: The StaticUserSimulator does not require an evaluator.
  inherited_methods:
    UserSimulator:
    - signature: 'def get_next_user_message(self, events: list[google.adk.events.event.Event]) -> google.adk.evaluation.simulation.user_simulator.NextUserMessage:'
      docstring: "Returns the next user message to send to the agent.\n\nArgs:\n  events: The unaltered conversation history between the user and the\n    agent(s) under evaluation.\n\nReturns:\n  A NextUserMessage object containing the next user message to send to the\n  agent, or a status indicating why no message was generated."
    - signature: 'def get_simulation_evaluator(self) -> typing.Optional[google.adk.evaluation.evaluator.Evaluator]:'
      docstring: Returns an instance of an Evaluator that evaluates if the user simulation was successful or not.
  omitted_inherited_members_from:
  - ABC
- rank: 925
  id: google.adk.evaluation.simulation.static_user_simulator.StaticUserSimulator.__init__
  name: __init__
  file_path: google/adk/evaluation/simulation/static_user_simulator.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def __init__(self, *, static_conversation: google.adk.evaluation.eval_case.StaticConversation):'
- rank: 926
  id: google.adk.evaluation.simulation.static_user_simulator.StaticUserSimulator.get_next_user_message
  name: get_next_user_message
  file_path: google/adk/evaluation/simulation/static_user_simulator.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Returns the next user message to send to the agent from a static list.\n\nArgs:\n  events: The unaltered conversation history between the user and the\n    agent(s) under evaluation.\n\nReturns:\n  A NextUserMessage object containing the next user message to send to the\n  agent, or a status indicating why no message was generated."
  signature: 'def get_next_user_message(self, events: list[google.adk.events.event.Event]) -> google.adk.evaluation.simulation.user_simulator.NextUserMessage:'
- rank: 927
  id: google.adk.evaluation.simulation.static_user_simulator.StaticUserSimulator.get_simulation_evaluator
  name: get_simulation_evaluator
  file_path: google/adk/evaluation/simulation/static_user_simulator.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: The StaticUserSimulator does not require an evaluator.
  signature: 'def get_simulation_evaluator(self) -> typing.Optional[google.adk.evaluation.evaluator.Evaluator]:'
- rank: 928
  id: google.adk.evaluation.simulation.user_simulator
  name: user_simulator
  file_path: google/adk/evaluation/simulation/user_simulator.py
  type: MODULE
  group: Orphan
  usage_score: 0
- rank: 929
  id: google.adk.evaluation.simulation.user_simulator.BaseUserSimulatorConfig
  name: BaseUserSimulatorConfig
  file_path: google/adk/evaluation/simulation/user_simulator.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Base class for configurations pertaining to user simulator.


    [Note: Inherited members from pydantic.BaseModel are omitted.]'
  properties:
  - signature: 'model_config: pydantic.ConfigDict'
  inherited_properties:
    BaseModel:
    - signature: 'model_config: pydantic.ConfigDict'
  omitted_inherited_members_from:
  - pydantic.BaseModel
- rank: 930
  id: google.adk.evaluation.simulation.user_simulator.NextUserMessage
  name: NextUserMessage
  file_path: google/adk/evaluation/simulation/user_simulator.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: '[Note: Inherited members from pydantic.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, status: google.adk.evaluation.simulation.user_simulator.Status, user_message: typing.Optional[google.genai.types.Content] = None):'
  methods:
  - signature: 'def ensure_user_message_iff_success(self) -> google.adk.evaluation.simulation.user_simulator.NextUserMessage:'
  properties:
  - signature: 'status: google.adk.evaluation.simulation.user_simulator.Status'
  - signature: 'user_message: typing.Optional[google.genai.types.Content]'
  inherited_properties:
    EvalBaseModel:
    - signature: 'model_config: pydantic.ConfigDict'
  omitted_inherited_members_from:
  - pydantic.BaseModel
- rank: 931
  id: google.adk.evaluation.simulation.user_simulator.NextUserMessage.ensure_user_message_iff_success
  name: ensure_user_message_iff_success
  file_path: google/adk/evaluation/simulation/user_simulator.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def ensure_user_message_iff_success(self) -> google.adk.evaluation.simulation.user_simulator.NextUserMessage:'
- rank: 932
  id: google.adk.evaluation.simulation.user_simulator.Status
  name: Status
  file_path: google/adk/evaluation/simulation/user_simulator.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'The resulting status of get_next_user_message().


    [Note: Inherited members from enum.Enum are omitted.]'
  properties:
  - signature: 'SUCCESS: str'
  - signature: 'TURN_LIMIT_REACHED: str'
  - signature: 'STOP_SIGNAL_DETECTED: str'
  - signature: 'NO_MESSAGE_GENERATED: str'
  omitted_inherited_members_from:
  - enum.Enum
- rank: 933
  id: google.adk.evaluation.simulation.user_simulator.UserSimulator
  name: UserSimulator
  file_path: google/adk/evaluation/simulation/user_simulator.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'A user simulator for the purposes of automating interaction with an Agent.


    Typically, you must create one user simulator instance per eval case.


    [Note: Inherited members from ABC are omitted.]'
  constructor_signature: 'def __init__(self, config: google.adk.evaluation.simulation.user_simulator.BaseUserSimulatorConfig, config_type: type[google.adk.evaluation.simulation.user_simulator.BaseUserSimulatorConfig]):'
  methods:
  - signature: 'def get_next_user_message(self, events: list[google.adk.events.event.Event]) -> google.adk.evaluation.simulation.user_simulator.NextUserMessage:'
    docstring: "Returns the next user message to send to the agent.\n\nArgs:\n  events: The unaltered conversation history between the user and the\n    agent(s) under evaluation.\n\nReturns:\n  A NextUserMessage object containing the next user message to send to the\n  agent, or a status indicating why no message was generated."
  - signature: 'def get_simulation_evaluator(self) -> typing.Optional[google.adk.evaluation.evaluator.Evaluator]:'
    docstring: Returns an instance of an Evaluator that evaluates if the user simulation was successful or not.
  omitted_inherited_members_from:
  - ABC
- rank: 934
  id: google.adk.evaluation.simulation.user_simulator.UserSimulator.__init__
  name: __init__
  file_path: google/adk/evaluation/simulation/user_simulator.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def __init__(self, config: google.adk.evaluation.simulation.user_simulator.BaseUserSimulatorConfig, config_type: type[google.adk.evaluation.simulation.user_simulator.BaseUserSimulatorConfig]):'
- rank: 935
  id: google.adk.evaluation.simulation.user_simulator.UserSimulator.get_next_user_message
  name: get_next_user_message
  file_path: google/adk/evaluation/simulation/user_simulator.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Returns the next user message to send to the agent.\n\nArgs:\n  events: The unaltered conversation history between the user and the\n    agent(s) under evaluation.\n\nReturns:\n  A NextUserMessage object containing the next user message to send to the\n  agent, or a status indicating why no message was generated."
  signature: 'def get_next_user_message(self, events: list[google.adk.events.event.Event]) -> google.adk.evaluation.simulation.user_simulator.NextUserMessage:'
- rank: 936
  id: google.adk.evaluation.simulation.user_simulator.UserSimulator.get_simulation_evaluator
  name: get_simulation_evaluator
  file_path: google/adk/evaluation/simulation/user_simulator.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: Returns an instance of an Evaluator that evaluates if the user simulation was successful or not.
  signature: 'def get_simulation_evaluator(self) -> typing.Optional[google.adk.evaluation.evaluator.Evaluator]:'
- rank: 937
  id: google.adk.evaluation.simulation.user_simulator_provider
  name: user_simulator_provider
  file_path: google/adk/evaluation/simulation/user_simulator_provider.py
  type: MODULE
  group: Orphan
  usage_score: 0
- rank: 938
  id: google.adk.evaluation.simulation.user_simulator_provider.UserSimulatorProvider
  name: UserSimulatorProvider
  file_path: google/adk/evaluation/simulation/user_simulator_provider.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Provides a UserSimulator instance per EvalCase, mixing configuration data

    from the EvalConfig with per-EvalCase conversation data.'
  constructor_signature: 'def __init__(self, user_simulator_config: typing.Optional[google.adk.evaluation.simulation.user_simulator.BaseUserSimulatorConfig]):'
  methods:
  - signature: 'def provide(self, eval_case: google.adk.evaluation.eval_case.EvalCase) -> google.adk.evaluation.simulation.user_simulator.UserSimulator:'
    docstring: "Provide an appropriate user simulator based on the type of conversation data in the EvalCase\n\nArgs:\n  eval_case: An EvalCase containing a `conversation` xor a\n    `conversation_scenario`.\n\nReturns:\n  A StaticUserSimulator or an LlmBackedUserSimulator based on the type of\n  the conversation data.\n\nRaises:\n  ValueError: If no conversation data or multiple types of conversation data\n  are provided."
- rank: 939
  id: google.adk.evaluation.simulation.user_simulator_provider.UserSimulatorProvider.__init__
  name: __init__
  file_path: google/adk/evaluation/simulation/user_simulator_provider.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def __init__(self, user_simulator_config: typing.Optional[google.adk.evaluation.simulation.user_simulator.BaseUserSimulatorConfig]):'
- rank: 940
  id: google.adk.evaluation.simulation.user_simulator_provider.UserSimulatorProvider.provide
  name: provide
  file_path: google/adk/evaluation/simulation/user_simulator_provider.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Provide an appropriate user simulator based on the type of conversation data in the EvalCase\n\nArgs:\n  eval_case: An EvalCase containing a `conversation` xor a\n    `conversation_scenario`.\n\nReturns:\n  A StaticUserSimulator or an LlmBackedUserSimulator based on the type of\n  the conversation data.\n\nRaises:\n  ValueError: If no conversation data or multiple types of conversation data\n  are provided."
  signature: 'def provide(self, eval_case: google.adk.evaluation.eval_case.EvalCase) -> google.adk.evaluation.simulation.user_simulator.UserSimulator:'
- rank: 941
  id: google.adk.evaluation.trajectory_evaluator
  name: trajectory_evaluator
  file_path: google/adk/evaluation/trajectory_evaluator.py
  type: MODULE
  group: Orphan
  usage_score: 0
- rank: 942
  id: google.adk.evaluation.trajectory_evaluator.TrajectoryEvaluator
  name: TrajectoryEvaluator
  file_path: google/adk/evaluation/trajectory_evaluator.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: "Evaluates tool use trajectories for accuracy.\n\nThis evaluator compares the sequence of tools called by the agent against a\nlist of expected calls and computes an average score based on one of the match\ntypes: `EXACT`, `IN_ORDER`, or `ANY_ORDER`.\n\nFor each invocation being evaluated, this evaluator compares the list of\ntool calls produced by the agent with the list of expected tool calls using\none of three match types. If the tool calls match based on the selected match\ntype, a score of 1.0 is awarded for that invocation, otherwise the score is\n0.0. The final value is the average of these scores across all\ninvocations in the eval case.\n\nThe comparison can be done using one of following match types:\n  - `EXACT`: Requires a perfect match between the actual and expected tool\n    calls, with no extra or missing tool calls.\n  - `IN_ORDER`: Requires all tool calls from the expected list to be present\n    in the actual list, in the same order, but allows for other\
    \ tool calls\n    to appear in between.\n  - `ANY_ORDER`: Requires all tool calls from the expected list to be\n    present in the actual list, in any order, and allows for other tool\n    calls to appear in between.\n\n[Note: Inherited members from ABC are omitted.]"
  constructor_signature: 'def __init__(self, threshold: typing.Optional[float], eval_metric: typing.Optional[google.adk.evaluation.eval_metrics.EvalMetric]):'
  methods:
  - signature: 'def get_metric_info() -> google.adk.evaluation.eval_metrics.MetricInfo:'
  - signature: 'def evaluate_invocations(self, actual_invocations: list[google.adk.evaluation.eval_case.Invocation], expected_invocations: typing.Optional[list[google.adk.evaluation.eval_case.Invocation]]) -> google.adk.evaluation.evaluator.EvaluationResult:'
    docstring: Returns EvaluationResult after performing evaluations using actual and expected invocations.
  properties:
  - signature: 'criterion_type: typing.ClassVar[type[google.adk.evaluation.eval_metrics.ToolTrajectoryCriterion]]'
  inherited_methods:
    Evaluator:
    - signature: 'def evaluate_invocations(self, actual_invocations: list[google.adk.evaluation.eval_case.Invocation], expected_invocations: typing.Optional[list[google.adk.evaluation.eval_case.Invocation]]) -> google.adk.evaluation.evaluator.EvaluationResult:'
      docstring: "Returns EvaluationResult after performing evaluations using actual and expected invocations.\n\nArgs:\n  actual_invocations: These are the invocations that are obtained from the\n    agent under test.\n  expected_invocations: An optional list of invocations, if specified,\n    usually act as a benchmark/golden response. If these are specified\n    usually the expectation is that the length of this list and actual\n    invocation is the same."
  inherited_properties:
    Evaluator:
    - signature: 'criterion_type: typing.ClassVar[type[google.adk.evaluation.eval_metrics.BaseCriterion]]'
  omitted_inherited_members_from:
  - ABC
- rank: 943
  id: google.adk.evaluation.trajectory_evaluator.TrajectoryEvaluator.__init__
  name: __init__
  file_path: google/adk/evaluation/trajectory_evaluator.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def __init__(self, threshold: typing.Optional[float], eval_metric: typing.Optional[google.adk.evaluation.eval_metrics.EvalMetric]):'
- rank: 944
  id: google.adk.evaluation.trajectory_evaluator.TrajectoryEvaluator.evaluate_invocations
  name: evaluate_invocations
  file_path: google/adk/evaluation/trajectory_evaluator.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: Returns EvaluationResult after performing evaluations using actual and expected invocations.
  signature: 'def evaluate_invocations(self, actual_invocations: list[google.adk.evaluation.eval_case.Invocation], expected_invocations: typing.Optional[list[google.adk.evaluation.eval_case.Invocation]]) -> google.adk.evaluation.evaluator.EvaluationResult:'
- rank: 945
  id: google.adk.evaluation.trajectory_evaluator.TrajectoryEvaluator.get_metric_info
  name: get_metric_info
  file_path: google/adk/evaluation/trajectory_evaluator.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def get_metric_info() -> google.adk.evaluation.eval_metrics.MetricInfo:'
- rank: 946
  id: google.adk.evaluation.vertex_ai_eval_facade
  name: vertex_ai_eval_facade
  file_path: google/adk/evaluation/vertex_ai_eval_facade.py
  type: MODULE
  group: Orphan
  usage_score: 0
- rank: 947
  id: google.adk.events
  name: events
  file_path: google/adk/events/__init__.py
  type: MODULE
  group: Orphan
  usage_score: 0
- rank: 948
  id: google.adk.events.event
  name: event
  file_path: google/adk/events/event.py
  type: MODULE
  group: Orphan
  usage_score: 0
- rank: 949
  id: google.adk.events.event.Event.get_function_calls
  name: get_function_calls
  file_path: google/adk/events/event.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: Returns the function calls in the event.
  signature: 'def get_function_calls(self) -> list[google.genai.types.FunctionCall]:'
- rank: 950
  id: google.adk.events.event.Event.get_function_responses
  name: get_function_responses
  file_path: google/adk/events/event.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: Returns the function responses in the event.
  signature: 'def get_function_responses(self) -> list[google.genai.types.FunctionResponse]:'
- rank: 951
  id: google.adk.events.event.Event.has_trailing_code_execution_result
  name: has_trailing_code_execution_result
  file_path: google/adk/events/event.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: Returns whether the event has a trailing code execution result.
  signature: 'def has_trailing_code_execution_result(self) -> bool:'
- rank: 952
  id: google.adk.events.event.Event.is_final_response
  name: is_final_response
  file_path: google/adk/events/event.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: 'Returns whether the event is the final response of an agent.


    NOTE: This method is ONLY for use by Agent Development Kit.


    Note that when multiple agents participate in one invocation, there could be

    one event has `is_final_response()` as True for each participating agent.'
  signature: 'def is_final_response(self) -> bool:'
- rank: 953
  id: google.adk.events.event.Event.model_post_init
  name: model_post_init
  file_path: google/adk/events/event.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: Post initialization logic for the event.
  signature: 'def model_post_init(self, __context):'
- rank: 954
  id: google.adk.events.event_actions
  name: event_actions
  file_path: google/adk/events/event_actions.py
  type: MODULE
  group: Orphan
  usage_score: 0
- rank: 955
  id: google.adk.events.event_actions.EventCompaction
  name: EventCompaction
  file_path: google/adk/events/event_actions.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'The compaction of the events.


    [Note: Inherited members from pydantic.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, start_timestamp: float, end_timestamp: float, compacted_content: google.genai.types.Content):'
  properties:
  - signature: 'model_config: pydantic.ConfigDict'
    docstring: The pydantic model config.
  - signature: 'start_timestamp: float'
    docstring: The start timestamp of the compacted events, in seconds.
  - signature: 'end_timestamp: float'
    docstring: The end timestamp of the compacted events, in seconds.
  - signature: 'compacted_content: google.genai.types.Content'
    docstring: The compacted content of the events.
  inherited_properties:
    BaseModel:
    - signature: 'model_config: pydantic.ConfigDict'
  omitted_inherited_members_from:
  - pydantic.BaseModel
- rank: 956
  id: google.adk.examples
  name: examples
  file_path: google/adk/examples/__init__.py
  type: MODULE
  group: Orphan
  usage_score: 0
- rank: 957
  id: google.adk.examples.base_example_provider
  name: base_example_provider
  file_path: google/adk/examples/base_example_provider.py
  type: MODULE
  group: Orphan
  usage_score: 0
- rank: 958
  id: google.adk.examples.base_example_provider.BaseExampleProvider
  name: BaseExampleProvider
  file_path: google/adk/examples/base_example_provider.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Base class for example providers.


    This class defines the interface for providing examples for a given query.


    [Note: Inherited members from abc.ABC are omitted.]'
  methods:
  - signature: 'def get_examples(self, query: str) -> list[google.adk.examples.example.Example]:'
    docstring: "Returns a list of examples for a given query.\n\nArgs:\n    query: The query to get examples for.\n\nReturns:\n    A list of Example objects."
  omitted_inherited_members_from:
  - abc.ABC
- rank: 959
  id: google.adk.examples.base_example_provider.BaseExampleProvider.get_examples
  name: get_examples
  file_path: google/adk/examples/base_example_provider.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Returns a list of examples for a given query.\n\nArgs:\n    query: The query to get examples for.\n\nReturns:\n    A list of Example objects."
  signature: 'def get_examples(self, query: str) -> list[google.adk.examples.example.Example]:'
- rank: 960
  id: google.adk.examples.example
  name: example
  file_path: google/adk/examples/example.py
  type: MODULE
  group: Orphan
  usage_score: 0
- rank: 961
  id: google.adk.examples.example_util
  name: example_util
  file_path: google/adk/examples/example_util.py
  type: MODULE
  group: Orphan
  usage_score: 0
  docstring: Utility functions for converting examples to a string that can be used in system instructions in the prompt.
  methods:
  - signature: 'def convert_examples_to_text(examples: list[google.adk.examples.example.Example], model: typing.Optional[str]) -> str:'
    docstring: Converts a list of examples to a string that can be used in a system instruction.
  - signature: 'def build_example_si(examples: typing.Union[list[google.adk.examples.example.Example], google.adk.examples.base_example_provider.BaseExampleProvider], query: str, model: typing.Optional[str]) -> str:'
- rank: 962
  id: google.adk.examples.example_util.build_example_si
  name: build_example_si
  file_path: google/adk/examples/example_util.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def build_example_si(examples: typing.Union[list[google.adk.examples.example.Example], google.adk.examples.base_example_provider.BaseExampleProvider], query: str, model: typing.Optional[str]) -> str:'
- rank: 963
  id: google.adk.examples.example_util.convert_examples_to_text
  name: convert_examples_to_text
  file_path: google/adk/examples/example_util.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: Converts a list of examples to a string that can be used in a system instruction.
  signature: 'def convert_examples_to_text(examples: list[google.adk.examples.example.Example], model: typing.Optional[str]) -> str:'
- rank: 964
  id: google.adk.examples.vertex_ai_example_store
  name: vertex_ai_example_store
  file_path: google/adk/examples/vertex_ai_example_store.py
  type: MODULE
  group: Orphan
  usage_score: 0
- rank: 965
  id: google.adk.examples.vertex_ai_example_store.VertexAiExampleStore
  name: VertexAiExampleStore
  file_path: google/adk/examples/vertex_ai_example_store.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Provides examples from Vertex example store.


    [Note: Inherited members from abc.ABC are omitted.]'
  constructor_signature: 'def __init__(self, examples_store_name: str):'
  methods:
  - signature: 'def get_examples(self, query: str) -> list[google.adk.examples.example.Example]:'
  inherited_methods:
    BaseExampleProvider:
    - signature: 'def get_examples(self, query: str) -> list[google.adk.examples.example.Example]:'
      docstring: "Returns a list of examples for a given query.\n\nArgs:\n    query: The query to get examples for.\n\nReturns:\n    A list of Example objects."
  omitted_inherited_members_from:
  - abc.ABC
- rank: 966
  id: google.adk.examples.vertex_ai_example_store.VertexAiExampleStore.__init__
  name: __init__
  file_path: google/adk/examples/vertex_ai_example_store.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Initializes the VertexAiExampleStore.\n\nArgs:\n    examples_store_name: The resource name of the vertex example store, in\n      the format of\n      ``projects/{project}/locations/{location}/exampleStores/{example_store}``."
  signature: 'def __init__(self, examples_store_name: str):'
- rank: 967
  id: google.adk.examples.vertex_ai_example_store.VertexAiExampleStore.get_examples
  name: get_examples
  file_path: google/adk/examples/vertex_ai_example_store.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def get_examples(self, query: str) -> list[google.adk.examples.example.Example]:'
- rank: 968
  id: google.adk.features
  name: features
  file_path: google/adk/features/__init__.py
  type: MODULE
  group: Orphan
  usage_score: 0
- rank: 969
  id: google.adk.flows
  name: flows
  file_path: google/adk/flows/__init__.py
  type: MODULE
  group: Orphan
  usage_score: 0
- rank: 970
  id: google.adk.flows.llm_flows
  name: llm_flows
  file_path: google/adk/flows/llm_flows/__init__.py
  type: MODULE
  group: Orphan
  usage_score: 0
- rank: 971
  id: google.adk.flows.llm_flows.agent_transfer
  name: agent_transfer
  file_path: google/adk/flows/llm_flows/agent_transfer.py
  type: MODULE
  group: Orphan
  usage_score: 0
  docstring: Handles agent transfer for LLM flow.
- rank: 972
  id: google.adk.flows.llm_flows.audio_cache_manager
  name: audio_cache_manager
  file_path: google/adk/flows/llm_flows/audio_cache_manager.py
  type: MODULE
  group: Orphan
  usage_score: 0
- rank: 973
  id: google.adk.flows.llm_flows.audio_cache_manager.AudioCacheConfig
  name: AudioCacheConfig
  file_path: google/adk/flows/llm_flows/audio_cache_manager.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: Configuration for audio caching behavior.
  constructor_signature: 'def __init__(self, max_cache_size_bytes: int, max_cache_duration_seconds: float, auto_flush_threshold: int):'
- rank: 974
  id: google.adk.flows.llm_flows.audio_cache_manager.AudioCacheConfig.__init__
  name: __init__
  file_path: google/adk/flows/llm_flows/audio_cache_manager.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Initialize audio cache configuration.\n\nArgs:\n  max_cache_size_bytes: Maximum cache size in bytes before auto-flush.\n  max_cache_duration_seconds: Maximum duration to keep data in cache.\n  auto_flush_threshold: Number of chunks that triggers auto-flush."
  signature: 'def __init__(self, max_cache_size_bytes: int, max_cache_duration_seconds: float, auto_flush_threshold: int):'
- rank: 975
  id: google.adk.flows.llm_flows.audio_cache_manager.AudioCacheManager
  name: AudioCacheManager
  file_path: google/adk/flows/llm_flows/audio_cache_manager.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: Manages audio caching and flushing for live streaming flows.
  constructor_signature: 'def __init__(self, config: AudioCacheConfig | None):'
  methods:
  - signature: 'def cache_audio(self, invocation_context: google.adk.agents.invocation_context.InvocationContext, audio_blob: google.genai.types.Blob, cache_type: str) -> None:'
    docstring: "Cache incoming user or outgoing model audio data.\n\nArgs:\n  invocation_context: The current invocation context.\n  audio_blob: The audio data to cache.\n  cache_type: Type of audio to cache, either 'input' or 'output'.\n\nRaises:\n  ValueError: If cache_type is not 'input' or 'output'."
  - signature: 'def flush_caches(self, invocation_context: google.adk.agents.invocation_context.InvocationContext, flush_user_audio: bool, flush_model_audio: bool) -> list[google.adk.events.event.Event]:'
    docstring: "Flush audio caches to artifact services.\n\nThe multimodality data is saved in artifact service in the format of\naudio file. The file data reference is added to the session as an event.\nThe audio file follows the naming convention: artifact_ref =\nf\"artifact://{invocation_context.app_name}/{invocation_context.user_id}/\n{invocation_context.session.id}/_adk_live/{filename}#{revision_id}\"\n\nNote: video data is not supported yet.\n\nArgs:\n  invocation_context: The invocation context containing audio caches.\n  flush_user_audio: Whether to flush the input (user) audio cache.\n  flush_model_audio: Whether to flush the output (model) audio cache.\n\nReturns:\n  A list of Event objects created from the flushed caches."
  - signature: 'def get_cache_stats(self, invocation_context: google.adk.agents.invocation_context.InvocationContext) -> dict[str, int]:'
    docstring: "Get statistics about current cache state.\n\nArgs:\n  invocation_context: The invocation context.\n\nReturns:\n  Dictionary containing cache statistics."
- rank: 976
  id: google.adk.flows.llm_flows.audio_cache_manager.AudioCacheManager.__init__
  name: __init__
  file_path: google/adk/flows/llm_flows/audio_cache_manager.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Initialize the audio cache manager.\n\nArgs:\n  config: Configuration for audio caching behavior."
  signature: 'def __init__(self, config: AudioCacheConfig | None):'
- rank: 977
  id: google.adk.flows.llm_flows.audio_cache_manager.AudioCacheManager.cache_audio
  name: cache_audio
  file_path: google/adk/flows/llm_flows/audio_cache_manager.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Cache incoming user or outgoing model audio data.\n\nArgs:\n  invocation_context: The current invocation context.\n  audio_blob: The audio data to cache.\n  cache_type: Type of audio to cache, either 'input' or 'output'.\n\nRaises:\n  ValueError: If cache_type is not 'input' or 'output'."
  signature: 'def cache_audio(self, invocation_context: google.adk.agents.invocation_context.InvocationContext, audio_blob: google.genai.types.Blob, cache_type: str) -> None:'
- rank: 978
  id: google.adk.flows.llm_flows.audio_cache_manager.AudioCacheManager.flush_caches
  name: flush_caches
  file_path: google/adk/flows/llm_flows/audio_cache_manager.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Flush audio caches to artifact services.\n\nThe multimodality data is saved in artifact service in the format of\naudio file. The file data reference is added to the session as an event.\nThe audio file follows the naming convention: artifact_ref =\nf\"artifact://{invocation_context.app_name}/{invocation_context.user_id}/\n{invocation_context.session.id}/_adk_live/{filename}#{revision_id}\"\n\nNote: video data is not supported yet.\n\nArgs:\n  invocation_context: The invocation context containing audio caches.\n  flush_user_audio: Whether to flush the input (user) audio cache.\n  flush_model_audio: Whether to flush the output (model) audio cache.\n\nReturns:\n  A list of Event objects created from the flushed caches."
  signature: 'def flush_caches(self, invocation_context: google.adk.agents.invocation_context.InvocationContext, flush_user_audio: bool, flush_model_audio: bool) -> list[google.adk.events.event.Event]:'
- rank: 979
  id: google.adk.flows.llm_flows.audio_cache_manager.AudioCacheManager.get_cache_stats
  name: get_cache_stats
  file_path: google/adk/flows/llm_flows/audio_cache_manager.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Get statistics about current cache state.\n\nArgs:\n  invocation_context: The invocation context.\n\nReturns:\n  Dictionary containing cache statistics."
  signature: 'def get_cache_stats(self, invocation_context: google.adk.agents.invocation_context.InvocationContext) -> dict[str, int]:'
- rank: 980
  id: google.adk.flows.llm_flows.audio_transcriber
  name: audio_transcriber
  file_path: google/adk/flows/llm_flows/audio_transcriber.py
  type: MODULE
  group: Orphan
  usage_score: 0
- rank: 981
  id: google.adk.flows.llm_flows.audio_transcriber.AudioTranscriber
  name: AudioTranscriber
  file_path: google/adk/flows/llm_flows/audio_transcriber.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: Transcribes audio using Google Cloud Speech-to-Text.
  constructor_signature: 'def __init__(self, init_client):'
  methods:
  - signature: 'def transcribe_file(self, invocation_context: google.adk.agents.invocation_context.InvocationContext) -> list[google.genai.types.Content]:'
    docstring: "Transcribe audio, bundling consecutive segments from the same speaker.\n\nThe ordering of speakers will be preserved. Audio blobs will be merged for\nthe same speaker as much as we can do reduce the transcription latency.\n\nArgs:\n    invocation_context: The invocation context to access the transcription\n      cache.\n\nReturns:\n    A list of Content objects containing the transcribed text."
- rank: 982
  id: google.adk.flows.llm_flows.audio_transcriber.AudioTranscriber.transcribe_file
  name: transcribe_file
  file_path: google/adk/flows/llm_flows/audio_transcriber.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Transcribe audio, bundling consecutive segments from the same speaker.\n\nThe ordering of speakers will be preserved. Audio blobs will be merged for\nthe same speaker as much as we can do reduce the transcription latency.\n\nArgs:\n    invocation_context: The invocation context to access the transcription\n      cache.\n\nReturns:\n    A list of Content objects containing the transcribed text."
  signature: 'def transcribe_file(self, invocation_context: google.adk.agents.invocation_context.InvocationContext) -> list[google.genai.types.Content]:'
- rank: 983
  id: google.adk.flows.llm_flows.auto_flow
  name: auto_flow
  file_path: google/adk/flows/llm_flows/auto_flow.py
  type: MODULE
  group: Orphan
  usage_score: 0
  docstring: Implementation of AutoFlow.
- rank: 984
  id: google.adk.flows.llm_flows.auto_flow.AutoFlow
  name: AutoFlow
  file_path: google/adk/flows/llm_flows/auto_flow.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'AutoFlow is SingleFlow with agent transfer capability.


    Agent transfer is allowed in the following direction:


    1. from parent to sub-agent;

    2. from sub-agent to parent;

    3. from sub-agent to its peer agents;


    For peer-agent transfers, it''s only enabled when all below conditions are met:


    - The parent agent is also an LlmAgent.

    - `disallow_transfer_to_peers` option of this agent is False (default).


    Depending on the target agent type, the transfer may be automatically

    reversed. (see Runner._find_agent_to_run method for which agent will remain

    active to handle next user message.)


    [Note: Inherited members from ABC are omitted.]'
  constructor_signature: 'def __init__(self):'
  inherited_methods:
    BaseLlmFlow:
    - signature: 'def run_live(self, invocation_context: google.adk.agents.invocation_context.InvocationContext) -> typing.AsyncGenerator[google.adk.events.event.Event, None]:'
      docstring: Runs the flow using live api.
    - signature: 'def get_author_for_event(llm_response):'
      docstring: "Get the author of the event.\n\nWhen the model returns transcription, the author is \"user\". Otherwise, the\nauthor is the agent name(not 'model').\n\nArgs:\n  llm_response: The LLM response from the LLM call."
    - signature: 'def run_async(self, invocation_context: google.adk.agents.invocation_context.InvocationContext) -> typing.AsyncGenerator[google.adk.events.event.Event, None]:'
      docstring: Runs the flow.
  omitted_inherited_members_from:
  - ABC
- rank: 985
  id: google.adk.flows.llm_flows.base_llm_flow
  name: base_llm_flow
  file_path: google/adk/flows/llm_flows/base_llm_flow.py
  type: MODULE
  group: Orphan
  usage_score: 0
- rank: 986
  id: google.adk.flows.llm_flows.base_llm_flow.BaseLlmFlow
  name: BaseLlmFlow
  file_path: google/adk/flows/llm_flows/base_llm_flow.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'A basic flow that calls the LLM in a loop until a final response is generated.


    This flow ends when it transfer to another agent.


    [Note: Inherited members from ABC are omitted.]'
  constructor_signature: 'def __init__(self):'
  methods:
  - signature: 'def run_live(self, invocation_context: google.adk.agents.invocation_context.InvocationContext) -> typing.AsyncGenerator[google.adk.events.event.Event, None]:'
    docstring: Runs the flow using live api.
  - signature: 'def get_author_for_event(llm_response):'
    docstring: "Get the author of the event.\n\nWhen the model returns transcription, the author is \"user\". Otherwise, the\nauthor is the agent name(not 'model').\n\nArgs:\n  llm_response: The LLM response from the LLM call."
  - signature: 'def run_async(self, invocation_context: google.adk.agents.invocation_context.InvocationContext) -> typing.AsyncGenerator[google.adk.events.event.Event, None]:'
    docstring: Runs the flow.
  omitted_inherited_members_from:
  - ABC
- rank: 987
  id: google.adk.flows.llm_flows.base_llm_flow.BaseLlmFlow.__init__
  name: __init__
  file_path: google/adk/flows/llm_flows/base_llm_flow.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def __init__(self):'
- rank: 988
  id: google.adk.flows.llm_flows.base_llm_flow.BaseLlmFlow.get_author_for_event
  name: get_author_for_event
  file_path: google/adk/flows/llm_flows/base_llm_flow.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Get the author of the event.\n\nWhen the model returns transcription, the author is \"user\". Otherwise, the\nauthor is the agent name(not 'model').\n\nArgs:\n  llm_response: The LLM response from the LLM call."
  signature: 'def get_author_for_event(llm_response):'
- rank: 989
  id: google.adk.flows.llm_flows.base_llm_flow.BaseLlmFlow.run_async
  name: run_async
  file_path: google/adk/flows/llm_flows/base_llm_flow.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: Runs the flow.
  signature: 'def run_async(self, invocation_context: google.adk.agents.invocation_context.InvocationContext) -> typing.AsyncGenerator[google.adk.events.event.Event, None]:'
- rank: 990
  id: google.adk.flows.llm_flows.base_llm_flow.BaseLlmFlow.run_live
  name: run_live
  file_path: google/adk/flows/llm_flows/base_llm_flow.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: Runs the flow using live api.
  signature: 'def run_live(self, invocation_context: google.adk.agents.invocation_context.InvocationContext) -> typing.AsyncGenerator[google.adk.events.event.Event, None]:'
- rank: 991
  id: google.adk.flows.llm_flows.basic
  name: basic
  file_path: google/adk/flows/llm_flows/basic.py
  type: MODULE
  group: Orphan
  usage_score: 0
  docstring: Handles basic information to build the LLM request.
- rank: 992
  id: google.adk.flows.llm_flows.contents
  name: contents
  file_path: google/adk/flows/llm_flows/contents.py
  type: MODULE
  group: Orphan
  usage_score: 0
- rank: 993
  id: google.adk.flows.llm_flows.context_cache_processor
  name: context_cache_processor
  file_path: google/adk/flows/llm_flows/context_cache_processor.py
  type: MODULE
  group: Orphan
  usage_score: 0
  docstring: Context cache processor for LLM requests.
- rank: 994
  id: google.adk.flows.llm_flows.context_cache_processor.ContextCacheRequestProcessor
  name: ContextCacheRequestProcessor
  file_path: google/adk/flows/llm_flows/context_cache_processor.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Request processor that enables context caching for LLM requests.


    This processor sets up context caching configuration for agents that have

    context caching enabled and finds the latest cache metadata from session

    events. The actual cache management is handled by the model-specific cache

    managers (e.g., GeminiContextCacheManager).


    [Note: Inherited members from BaseLlmRequestProcessor are omitted.]'
  methods:
  - signature: 'def run_async(self, invocation_context: google.adk.agents.invocation_context.InvocationContext, llm_request: google.adk.models.llm_request.LlmRequest) -> typing.AsyncGenerator[google.adk.events.event.Event, None]:'
    docstring: "Process LLM request to enable context caching.\n\nArgs:\n    invocation_context: Invocation context containing agent and session info\n    llm_request: Request to process for caching\n\nYields:\n    Event: No events are yielded by this processor"
  omitted_inherited_members_from:
  - BaseLlmRequestProcessor
- rank: 995
  id: google.adk.flows.llm_flows.context_cache_processor.ContextCacheRequestProcessor.run_async
  name: run_async
  file_path: google/adk/flows/llm_flows/context_cache_processor.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Process LLM request to enable context caching.\n\nArgs:\n    invocation_context: Invocation context containing agent and session info\n    llm_request: Request to process for caching\n\nYields:\n    Event: No events are yielded by this processor"
  signature: 'def run_async(self, invocation_context: google.adk.agents.invocation_context.InvocationContext, llm_request: google.adk.models.llm_request.LlmRequest) -> typing.AsyncGenerator[google.adk.events.event.Event, None]:'
- rank: 996
  id: google.adk.flows.llm_flows.functions
  name: functions
  file_path: google/adk/flows/llm_flows/functions.py
  type: MODULE
  group: Orphan
  usage_score: 0
  docstring: Handles function calling for LLM flow.
  methods:
  - signature: 'def generate_client_function_call_id() -> str:'
  - signature: 'def populate_client_function_call_id(model_response_event: google.adk.events.event.Event) -> None:'
  - signature: 'def remove_client_function_call_id(content: typing.Optional[google.genai.types.Content]) -> None:'
    docstring: "Removes ADK-generated function call IDs from content before sending to LLM.\n\nStrips client-side function call/response IDs that start with 'adk-' prefix\nto avoid sending internal tracking IDs to the model.\n\nArgs:\n  content: Content containing function calls/responses to clean."
  - signature: 'def get_long_running_function_calls(function_calls: list[google.genai.types.FunctionCall], tools_dict: dict[str, google.adk.tools.base_tool.BaseTool]) -> set[str]:'
  - signature: 'def generate_auth_event(invocation_context: google.adk.agents.invocation_context.InvocationContext, function_response_event: google.adk.events.event.Event) -> typing.Optional[google.adk.events.event.Event]:'
  - signature: 'def generate_request_confirmation_event(invocation_context: google.adk.agents.invocation_context.InvocationContext, function_call_event: google.adk.events.event.Event, function_response_event: google.adk.events.event.Event) -> typing.Optional[google.adk.events.event.Event]:'
    docstring: Generates a request confirmation event from a function response event.
  - signature: 'def handle_function_calls_async(invocation_context: google.adk.agents.invocation_context.InvocationContext, function_call_event: google.adk.events.event.Event, tools_dict: dict[str, google.adk.tools.base_tool.BaseTool], filters: typing.Optional[set[str]], tool_confirmation_dict: typing.Optional[dict[str, google.adk.tools.tool_confirmation.ToolConfirmation]]) -> typing.Optional[google.adk.events.event.Event]:'
    docstring: Calls the functions and returns the function response event.
  - signature: 'def handle_function_call_list_async(invocation_context: google.adk.agents.invocation_context.InvocationContext, function_calls: list[google.genai.types.FunctionCall], tools_dict: dict[str, google.adk.tools.base_tool.BaseTool], filters: typing.Optional[set[str]], tool_confirmation_dict: typing.Optional[dict[str, google.adk.tools.tool_confirmation.ToolConfirmation]]) -> typing.Optional[google.adk.events.event.Event]:'
    docstring: Calls the functions and returns the function response event.
  - signature: 'def handle_function_calls_live(invocation_context: google.adk.agents.invocation_context.InvocationContext, function_call_event: google.adk.events.event.Event, tools_dict: dict[str, google.adk.tools.base_tool.BaseTool]) -> google.adk.events.event.Event:'
    docstring: Calls the functions and returns the function response event.
  - signature: 'def run_tool_and_update_queue(tool, function_args, tool_context):'
  - signature: 'def deep_merge_dicts(d1: dict, d2: dict) -> dict:'
    docstring: Recursively merges d2 into d1.
  - signature: 'def merge_parallel_function_response_events(function_response_events: list[google.adk.events.event.Event]) -> google.adk.events.event.Event:'
  - signature: 'def find_matching_function_call(events: list[google.adk.events.event.Event]) -> typing.Optional[google.adk.events.event.Event]:'
    docstring: Finds the function call event that matches the function response id of the last event.
- rank: 997
  id: google.adk.flows.llm_flows.functions.deep_merge_dicts
  name: deep_merge_dicts
  file_path: google/adk/flows/llm_flows/functions.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: Recursively merges d2 into d1.
  signature: 'def deep_merge_dicts(d1: dict, d2: dict) -> dict:'
- rank: 998
  id: google.adk.flows.llm_flows.functions.find_matching_function_call
  name: find_matching_function_call
  file_path: google/adk/flows/llm_flows/functions.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: Finds the function call event that matches the function response id of the last event.
  signature: 'def find_matching_function_call(events: list[google.adk.events.event.Event]) -> typing.Optional[google.adk.events.event.Event]:'
- rank: 999
  id: google.adk.flows.llm_flows.functions.generate_auth_event
  name: generate_auth_event
  file_path: google/adk/flows/llm_flows/functions.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def generate_auth_event(invocation_context: google.adk.agents.invocation_context.InvocationContext, function_response_event: google.adk.events.event.Event) -> typing.Optional[google.adk.events.event.Event]:'
- rank: 1000
  id: google.adk.flows.llm_flows.functions.generate_request_confirmation_event
  name: generate_request_confirmation_event
  file_path: google/adk/flows/llm_flows/functions.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: Generates a request confirmation event from a function response event.
  signature: 'def generate_request_confirmation_event(invocation_context: google.adk.agents.invocation_context.InvocationContext, function_call_event: google.adk.events.event.Event, function_response_event: google.adk.events.event.Event) -> typing.Optional[google.adk.events.event.Event]:'
- rank: 1001
  id: google.adk.flows.llm_flows.functions.get_long_running_function_calls
  name: get_long_running_function_calls
  file_path: google/adk/flows/llm_flows/functions.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def get_long_running_function_calls(function_calls: list[google.genai.types.FunctionCall], tools_dict: dict[str, google.adk.tools.base_tool.BaseTool]) -> set[str]:'
- rank: 1002
  id: google.adk.flows.llm_flows.functions.handle_function_call_list_async
  name: handle_function_call_list_async
  file_path: google/adk/flows/llm_flows/functions.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: Calls the functions and returns the function response event.
  signature: 'def handle_function_call_list_async(invocation_context: google.adk.agents.invocation_context.InvocationContext, function_calls: list[google.genai.types.FunctionCall], tools_dict: dict[str, google.adk.tools.base_tool.BaseTool], filters: typing.Optional[set[str]], tool_confirmation_dict: typing.Optional[dict[str, google.adk.tools.tool_confirmation.ToolConfirmation]]) -> typing.Optional[google.adk.events.event.Event]:'
- rank: 1003
  id: google.adk.flows.llm_flows.functions.handle_function_calls_async
  name: handle_function_calls_async
  file_path: google/adk/flows/llm_flows/functions.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: Calls the functions and returns the function response event.
  signature: 'def handle_function_calls_async(invocation_context: google.adk.agents.invocation_context.InvocationContext, function_call_event: google.adk.events.event.Event, tools_dict: dict[str, google.adk.tools.base_tool.BaseTool], filters: typing.Optional[set[str]], tool_confirmation_dict: typing.Optional[dict[str, google.adk.tools.tool_confirmation.ToolConfirmation]]) -> typing.Optional[google.adk.events.event.Event]:'
- rank: 1004
  id: google.adk.flows.llm_flows.functions.handle_function_calls_live
  name: handle_function_calls_live
  file_path: google/adk/flows/llm_flows/functions.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: Calls the functions and returns the function response event.
  signature: 'def handle_function_calls_live(invocation_context: google.adk.agents.invocation_context.InvocationContext, function_call_event: google.adk.events.event.Event, tools_dict: dict[str, google.adk.tools.base_tool.BaseTool]) -> google.adk.events.event.Event:'
- rank: 1005
  id: google.adk.flows.llm_flows.functions.merge_parallel_function_response_events
  name: merge_parallel_function_response_events
  file_path: google/adk/flows/llm_flows/functions.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def merge_parallel_function_response_events(function_response_events: list[google.adk.events.event.Event]) -> google.adk.events.event.Event:'
- rank: 1006
  id: google.adk.flows.llm_flows.functions.populate_client_function_call_id
  name: populate_client_function_call_id
  file_path: google/adk/flows/llm_flows/functions.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def populate_client_function_call_id(model_response_event: google.adk.events.event.Event) -> None:'
- rank: 1007
  id: google.adk.flows.llm_flows.functions.remove_client_function_call_id
  name: remove_client_function_call_id
  file_path: google/adk/flows/llm_flows/functions.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Removes ADK-generated function call IDs from content before sending to LLM.\n\nStrips client-side function call/response IDs that start with 'adk-' prefix\nto avoid sending internal tracking IDs to the model.\n\nArgs:\n  content: Content containing function calls/responses to clean."
  signature: 'def remove_client_function_call_id(content: typing.Optional[google.genai.types.Content]) -> None:'
- rank: 1008
  id: google.adk.flows.llm_flows.functions.run_tool_and_update_queue
  name: run_tool_and_update_queue
  file_path: google/adk/flows/llm_flows/functions.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def run_tool_and_update_queue(tool, function_args, tool_context):'
- rank: 1009
  id: google.adk.flows.llm_flows.identity
  name: identity
  file_path: google/adk/flows/llm_flows/identity.py
  type: MODULE
  group: Orphan
  usage_score: 0
  docstring: Gives the agent identity from the framework.
- rank: 1010
  id: google.adk.flows.llm_flows.instructions
  name: instructions
  file_path: google/adk/flows/llm_flows/instructions.py
  type: MODULE
  group: Orphan
  usage_score: 0
  docstring: Handles instructions and global instructions for LLM flow.
- rank: 1011
  id: google.adk.flows.llm_flows.request_confirmation
  name: request_confirmation
  file_path: google/adk/flows/llm_flows/request_confirmation.py
  type: MODULE
  group: Orphan
  usage_score: 0
- rank: 1012
  id: google.adk.flows.llm_flows.single_flow
  name: single_flow
  file_path: google/adk/flows/llm_flows/single_flow.py
  type: MODULE
  group: Orphan
  usage_score: 0
  docstring: Implementation of single flow.
- rank: 1013
  id: google.adk.flows.llm_flows.single_flow.SingleFlow
  name: SingleFlow
  file_path: google/adk/flows/llm_flows/single_flow.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'SingleFlow is the LLM flows that handles tools calls.


    A single flow only consider an agent itself and tools.

    No sub-agents are allowed for single flow.


    [Note: Inherited members from ABC are omitted.]'
  constructor_signature: 'def __init__(self):'
  inherited_methods:
    BaseLlmFlow:
    - signature: 'def run_live(self, invocation_context: google.adk.agents.invocation_context.InvocationContext) -> typing.AsyncGenerator[google.adk.events.event.Event, None]:'
      docstring: Runs the flow using live api.
    - signature: 'def get_author_for_event(llm_response):'
      docstring: "Get the author of the event.\n\nWhen the model returns transcription, the author is \"user\". Otherwise, the\nauthor is the agent name(not 'model').\n\nArgs:\n  llm_response: The LLM response from the LLM call."
    - signature: 'def run_async(self, invocation_context: google.adk.agents.invocation_context.InvocationContext) -> typing.AsyncGenerator[google.adk.events.event.Event, None]:'
      docstring: Runs the flow.
  omitted_inherited_members_from:
  - ABC
- rank: 1014
  id: google.adk.flows.llm_flows.single_flow.SingleFlow.__init__
  name: __init__
  file_path: google/adk/flows/llm_flows/single_flow.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def __init__(self):'
- rank: 1015
  id: google.adk.flows.llm_flows.transcription_manager
  name: transcription_manager
  file_path: google/adk/flows/llm_flows/transcription_manager.py
  type: MODULE
  group: Orphan
  usage_score: 0
- rank: 1016
  id: google.adk.flows.llm_flows.transcription_manager.TranscriptionManager
  name: TranscriptionManager
  file_path: google/adk/flows/llm_flows/transcription_manager.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: Manages transcription events for live streaming flows.
  methods:
  - signature: 'def handle_input_transcription(self, invocation_context: google.adk.agents.invocation_context.InvocationContext, transcription: google.genai.types.Transcription) -> None:'
    docstring: "Handle user input transcription events.\n\nArgs:\n  invocation_context: The current invocation context.\n  transcription: The transcription data from user input."
  - signature: 'def handle_output_transcription(self, invocation_context: google.adk.agents.invocation_context.InvocationContext, transcription: google.genai.types.Transcription) -> None:'
    docstring: "Handle model output transcription events.\n\nArgs:\n  invocation_context: The current invocation context.\n  transcription: The transcription data from model output."
  - signature: 'def get_transcription_stats(self, invocation_context: google.adk.agents.invocation_context.InvocationContext) -> dict[str, int]:'
    docstring: "Get statistics about transcription events in the session.\n\nArgs:\n  invocation_context: The current invocation context.\n\nReturns:\n  Dictionary containing transcription statistics."
- rank: 1017
  id: google.adk.flows.llm_flows.transcription_manager.TranscriptionManager.get_transcription_stats
  name: get_transcription_stats
  file_path: google/adk/flows/llm_flows/transcription_manager.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Get statistics about transcription events in the session.\n\nArgs:\n  invocation_context: The current invocation context.\n\nReturns:\n  Dictionary containing transcription statistics."
  signature: 'def get_transcription_stats(self, invocation_context: google.adk.agents.invocation_context.InvocationContext) -> dict[str, int]:'
- rank: 1018
  id: google.adk.flows.llm_flows.transcription_manager.TranscriptionManager.handle_input_transcription
  name: handle_input_transcription
  file_path: google/adk/flows/llm_flows/transcription_manager.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Handle user input transcription events.\n\nArgs:\n  invocation_context: The current invocation context.\n  transcription: The transcription data from user input."
  signature: 'def handle_input_transcription(self, invocation_context: google.adk.agents.invocation_context.InvocationContext, transcription: google.genai.types.Transcription) -> None:'
- rank: 1019
  id: google.adk.flows.llm_flows.transcription_manager.TranscriptionManager.handle_output_transcription
  name: handle_output_transcription
  file_path: google/adk/flows/llm_flows/transcription_manager.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Handle model output transcription events.\n\nArgs:\n  invocation_context: The current invocation context.\n  transcription: The transcription data from model output."
  signature: 'def handle_output_transcription(self, invocation_context: google.adk.agents.invocation_context.InvocationContext, transcription: google.genai.types.Transcription) -> None:'
- rank: 1020
  id: google.adk.memory
  name: memory
  file_path: google/adk/memory/__init__.py
  type: MODULE
  group: Orphan
  usage_score: 0
- rank: 1021
  id: google.adk.memory.base_memory_service
  name: base_memory_service
  file_path: google/adk/memory/base_memory_service.py
  type: MODULE
  group: Orphan
  usage_score: 0
- rank: 1022
  id: google.adk.memory.base_memory_service.BaseMemoryService
  name: BaseMemoryService
  file_path: google/adk/memory/base_memory_service.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Base class for memory services.


    The service provides functionalities to ingest sessions into memory so that

    the memory can be used for user queries.


    [Note: Inherited members from ABC are omitted.]'
  aliases:
  - google.adk.memory.BaseMemoryService
  methods:
  - signature: 'def add_session_to_memory(self, session: google.adk.sessions.session.Session):'
    docstring: "Adds a session to the memory service.\n\nA session may be added multiple times during its lifetime.\n\nArgs:\n    session: The session to add."
  - signature: 'def search_memory(self, *, app_name: str, user_id: str, query: str) -> google.adk.memory.base_memory_service.SearchMemoryResponse:'
    docstring: "Searches for sessions that match the query.\n\nArgs:\n    app_name: The name of the application.\n    user_id: The id of the user.\n    query: The query to search for.\n\nReturns:\n    A SearchMemoryResponse containing the matching memories."
  omitted_inherited_members_from:
  - ABC
- rank: 1023
  id: google.adk.memory.base_memory_service.BaseMemoryService.add_session_to_memory
  name: add_session_to_memory
  file_path: google/adk/memory/base_memory_service.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Adds a session to the memory service.\n\nA session may be added multiple times during its lifetime.\n\nArgs:\n    session: The session to add."
  signature: 'def add_session_to_memory(self, session: google.adk.sessions.session.Session):'
- rank: 1024
  id: google.adk.memory.base_memory_service.BaseMemoryService.search_memory
  name: search_memory
  file_path: google/adk/memory/base_memory_service.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Searches for sessions that match the query.\n\nArgs:\n    app_name: The name of the application.\n    user_id: The id of the user.\n    query: The query to search for.\n\nReturns:\n    A SearchMemoryResponse containing the matching memories."
  signature: 'def search_memory(self, *, app_name: str, user_id: str, query: str) -> google.adk.memory.base_memory_service.SearchMemoryResponse:'
- rank: 1025
  id: google.adk.memory.in_memory_memory_service
  name: in_memory_memory_service
  file_path: google/adk/memory/in_memory_memory_service.py
  type: MODULE
  group: Orphan
  usage_score: 0
- rank: 1026
  id: google.adk.memory.in_memory_memory_service.InMemoryMemoryService
  name: InMemoryMemoryService
  file_path: google/adk/memory/in_memory_memory_service.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'An in-memory memory service for prototyping purpose only.


    Uses keyword matching instead of semantic search.


    This class is thread-safe, however, it should be used for testing and

    development only.


    [Note: Inherited members from ABC are omitted.]'
  constructor_signature: 'def __init__(self):'
  methods:
  - signature: 'def add_session_to_memory(self, session: google.adk.sessions.session.Session):'
  - signature: 'def search_memory(self, *, app_name: str, user_id: str, query: str) -> google.adk.memory.base_memory_service.SearchMemoryResponse:'
  inherited_methods:
    BaseMemoryService:
    - signature: 'def add_session_to_memory(self, session: google.adk.sessions.session.Session):'
      docstring: "Adds a session to the memory service.\n\nA session may be added multiple times during its lifetime.\n\nArgs:\n    session: The session to add."
    - signature: 'def search_memory(self, *, app_name: str, user_id: str, query: str) -> google.adk.memory.base_memory_service.SearchMemoryResponse:'
      docstring: "Searches for sessions that match the query.\n\nArgs:\n    app_name: The name of the application.\n    user_id: The id of the user.\n    query: The query to search for.\n\nReturns:\n    A SearchMemoryResponse containing the matching memories."
  omitted_inherited_members_from:
  - ABC
- rank: 1027
  id: google.adk.memory.in_memory_memory_service.InMemoryMemoryService.__init__
  name: __init__
  file_path: google/adk/memory/in_memory_memory_service.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def __init__(self):'
- rank: 1028
  id: google.adk.memory.in_memory_memory_service.InMemoryMemoryService.add_session_to_memory
  name: add_session_to_memory
  file_path: google/adk/memory/in_memory_memory_service.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def add_session_to_memory(self, session: google.adk.sessions.session.Session):'
- rank: 1029
  id: google.adk.memory.in_memory_memory_service.InMemoryMemoryService.search_memory
  name: search_memory
  file_path: google/adk/memory/in_memory_memory_service.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def search_memory(self, *, app_name: str, user_id: str, query: str) -> google.adk.memory.base_memory_service.SearchMemoryResponse:'
- rank: 1030
  id: google.adk.memory.memory_entry
  name: memory_entry
  file_path: google/adk/memory/memory_entry.py
  type: MODULE
  group: Orphan
  usage_score: 0
- rank: 1031
  id: google.adk.memory.vertex_ai_memory_bank_service
  name: vertex_ai_memory_bank_service
  file_path: google/adk/memory/vertex_ai_memory_bank_service.py
  type: MODULE
  group: Orphan
  usage_score: 0
- rank: 1032
  id: google.adk.memory.vertex_ai_memory_bank_service.VertexAiMemoryBankService
  name: VertexAiMemoryBankService
  file_path: google/adk/memory/vertex_ai_memory_bank_service.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Implementation of the BaseMemoryService using Vertex AI Memory Bank.


    [Note: Inherited members from ABC are omitted.]'
  constructor_signature: 'def __init__(self, project: typing.Optional[str], location: typing.Optional[str], agent_engine_id: typing.Optional[str], *, express_mode_api_key: typing.Optional[str]=None):'
  methods:
  - signature: 'def add_session_to_memory(self, session: google.adk.sessions.session.Session):'
  - signature: 'def search_memory(self, *, app_name: str, user_id: str, query: str):'
  inherited_methods:
    BaseMemoryService:
    - signature: 'def add_session_to_memory(self, session: google.adk.sessions.session.Session):'
      docstring: "Adds a session to the memory service.\n\nA session may be added multiple times during its lifetime.\n\nArgs:\n    session: The session to add."
    - signature: 'def search_memory(self, *, app_name: str, user_id: str, query: str) -> google.adk.memory.base_memory_service.SearchMemoryResponse:'
      docstring: "Searches for sessions that match the query.\n\nArgs:\n    app_name: The name of the application.\n    user_id: The id of the user.\n    query: The query to search for.\n\nReturns:\n    A SearchMemoryResponse containing the matching memories."
  omitted_inherited_members_from:
  - ABC
- rank: 1033
  id: google.adk.memory.vertex_ai_memory_bank_service.VertexAiMemoryBankService.__init__
  name: __init__
  file_path: google/adk/memory/vertex_ai_memory_bank_service.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Initializes a VertexAiMemoryBankService.\n\nArgs:\n  project: The project ID of the Memory Bank to use.\n  location: The location of the Memory Bank to use.\n  agent_engine_id: The ID of the agent engine to use for the Memory Bank,\n    e.g. '456' in\n    'projects/my-project/locations/us-central1/reasoningEngines/456'. To\n    extract from api_resource.name, use:\n    ``agent_engine.api_resource.name.split('/')[-1]``\n  express_mode_api_key: The API key to use for Express Mode. If not\n    provided, the API key from the GOOGLE_API_KEY environment variable will\n    be used. It will only be used if GOOGLE_GENAI_USE_VERTEXAI is true. Do\n    not use Google AI Studio API key for this field. For more details, visit\n    https://cloud.google.com/vertex-ai/generative-ai/docs/start/express-mode/overview"
  signature: 'def __init__(self, project: typing.Optional[str], location: typing.Optional[str], agent_engine_id: typing.Optional[str], *, express_mode_api_key: typing.Optional[str]=None):'
- rank: 1034
  id: google.adk.memory.vertex_ai_memory_bank_service.VertexAiMemoryBankService.add_session_to_memory
  name: add_session_to_memory
  file_path: google/adk/memory/vertex_ai_memory_bank_service.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def add_session_to_memory(self, session: google.adk.sessions.session.Session):'
- rank: 1035
  id: google.adk.memory.vertex_ai_memory_bank_service.VertexAiMemoryBankService.search_memory
  name: search_memory
  file_path: google/adk/memory/vertex_ai_memory_bank_service.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def search_memory(self, *, app_name: str, user_id: str, query: str):'
- rank: 1036
  id: google.adk.memory.vertex_ai_rag_memory_service
  name: vertex_ai_rag_memory_service
  file_path: google/adk/memory/vertex_ai_rag_memory_service.py
  type: MODULE
  group: Orphan
  usage_score: 0
- rank: 1037
  id: google.adk.memory.vertex_ai_rag_memory_service.VertexAiRagMemoryService
  name: VertexAiRagMemoryService
  file_path: google/adk/memory/vertex_ai_rag_memory_service.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'A memory service that uses Vertex AI RAG for storage and retrieval.


    [Note: Inherited members from ABC are omitted.]'
  constructor_signature: 'def __init__(self, rag_corpus: typing.Optional[str], similarity_top_k: typing.Optional[int], vector_distance_threshold: float):'
  methods:
  - signature: 'def add_session_to_memory(self, session: google.adk.sessions.session.Session):'
  - signature: 'def search_memory(self, *, app_name: str, user_id: str, query: str) -> google.adk.memory.base_memory_service.SearchMemoryResponse:'
    docstring: Searches for sessions that match the query using rag.retrieval_query.
  inherited_methods:
    BaseMemoryService:
    - signature: 'def add_session_to_memory(self, session: google.adk.sessions.session.Session):'
      docstring: "Adds a session to the memory service.\n\nA session may be added multiple times during its lifetime.\n\nArgs:\n    session: The session to add."
    - signature: 'def search_memory(self, *, app_name: str, user_id: str, query: str) -> google.adk.memory.base_memory_service.SearchMemoryResponse:'
      docstring: "Searches for sessions that match the query.\n\nArgs:\n    app_name: The name of the application.\n    user_id: The id of the user.\n    query: The query to search for.\n\nReturns:\n    A SearchMemoryResponse containing the matching memories."
  omitted_inherited_members_from:
  - ABC
- rank: 1038
  id: google.adk.memory.vertex_ai_rag_memory_service.VertexAiRagMemoryService.__init__
  name: __init__
  file_path: google/adk/memory/vertex_ai_rag_memory_service.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Initializes a VertexAiRagMemoryService.\n\nArgs:\n    rag_corpus: The name of the Vertex AI RAG corpus to use. Format:\n      ``projects/{project}/locations/{location}/ragCorpora/{rag_corpus_id}``\n      or ``{rag_corpus_id}``\n    similarity_top_k: The number of contexts to retrieve.\n    vector_distance_threshold: Only returns contexts with vector distance\n      smaller than the threshold.."
  signature: 'def __init__(self, rag_corpus: typing.Optional[str], similarity_top_k: typing.Optional[int], vector_distance_threshold: float):'
- rank: 1039
  id: google.adk.memory.vertex_ai_rag_memory_service.VertexAiRagMemoryService.add_session_to_memory
  name: add_session_to_memory
  file_path: google/adk/memory/vertex_ai_rag_memory_service.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def add_session_to_memory(self, session: google.adk.sessions.session.Session):'
- rank: 1040
  id: google.adk.memory.vertex_ai_rag_memory_service.VertexAiRagMemoryService.search_memory
  name: search_memory
  file_path: google/adk/memory/vertex_ai_rag_memory_service.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: Searches for sessions that match the query using rag.retrieval_query.
  signature: 'def search_memory(self, *, app_name: str, user_id: str, query: str) -> google.adk.memory.base_memory_service.SearchMemoryResponse:'
- rank: 1041
  id: google.adk.models
  name: models
  file_path: google/adk/models/__init__.py
  type: MODULE
  group: Orphan
  usage_score: 0
  docstring: Defines the interface to support a model.
- rank: 1042
  id: google.adk.models.anthropic_llm
  name: anthropic_llm
  file_path: google/adk/models/anthropic_llm.py
  type: MODULE
  group: Orphan
  usage_score: 0
  docstring: Anthropic integration for Claude models.
  methods:
  - signature: 'def to_claude_role(role: typing.Optional[str]) -> typing.Literal[user, assistant]:'
  - signature: 'def to_google_genai_finish_reason(anthropic_stop_reason: typing.Optional[str]) -> google.genai.types.FinishReason:'
  - signature: 'def part_to_message_block(part: google.genai.types.Part) -> typing.Union[anthropic.types.TextBlockParam, anthropic.types.ImageBlockParam, anthropic.types.ToolUseBlockParam, anthropic.types.ToolResultBlockParam]:'
  - signature: 'def content_to_message_param(content: google.genai.types.Content) -> anthropic.types.MessageParam:'
  - signature: 'def content_block_to_part(content_block: anthropic.types.ContentBlock) -> google.genai.types.Part:'
  - signature: 'def message_to_generate_content_response(message: anthropic.types.Message) -> google.adk.models.llm_response.LlmResponse:'
  - signature: 'def function_declaration_to_tool_param(function_declaration: google.genai.types.FunctionDeclaration) -> anthropic.types.ToolParam:'
    docstring: Converts a function declaration to an Anthropic tool param.
- rank: 1043
  id: google.adk.models.anthropic_llm.AnthropicLlm
  name: AnthropicLlm
  file_path: google/adk/models/anthropic_llm.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: "Integration with Claude models via the Anthropic API.\n\nAttributes:\n  model: The name of the Claude model.\n  max_tokens: The maximum number of tokens to generate.\n\n[Note: Inherited members from pydantic.BaseModel are omitted.]"
  constructor_signature: 'def __init__(self, *, model: str, max_tokens: int = 8192):'
  methods:
  - signature: 'def supported_models(cls) -> list[str]:'
  - signature: 'def generate_content_async(self, llm_request: google.adk.models.llm_request.LlmRequest, stream: bool) -> typing.AsyncGenerator[google.adk.models.llm_response.LlmResponse, None]:'
  properties:
  - signature: 'model: str'
  - signature: 'max_tokens: int'
  inherited_methods:
    BaseLlm:
    - signature: 'def supported_models(cls) -> list[str]:'
      docstring: Returns a list of supported models in regex for LlmRegistry.
    - signature: 'def generate_content_async(self, llm_request: google.adk.models.llm_request.LlmRequest, stream: bool) -> typing.AsyncGenerator[google.adk.models.llm_response.LlmResponse, None]:'
      docstring: "Generates content for a single model turn.\n\n    This method handles Server-Sent Events (SSE) streaming for unidirectional\n    content generation. For bidirectional streaming (e.g., Gemini Live API),\n    use the `connect()` method instead.\n\n    Args:\n      llm_request: LlmRequest, the request to send to the LLM.\n      stream: bool = False, whether to enable SSE streaming mode.\n\n    Yields:\n      LlmResponse objects representing the model's response for one turn.\n\n      **Non-streaming mode (stream=False):**\n\n        Yields exactly one LlmResponse containing the complete model output\n        (text, function calls, bytes, etc.). This response has `partial=False`.\n\n      **Streaming mode (stream=True):**\n\n        Yields multiple LlmResponse objects as chunks arrive:\n\n        - Intermediate chunks: `partial=True` (progressive updates)\n        - Final chunk: `partial=False` (aggregated content from entire turn,\n          identical to stream=False output)\n\
        \        - Text consolidation: Consecutive text parts of the same type\n          (thought/non-thought) SHOULD merge without separator, but client\n          code must not rely on this - unconsolidated parts are unusual but also\n          valid\n\n      **Common content in partial chunks:**\n\n        All intermediate chunks have `partial=True` regardless of content type.\n        Common examples include:\n\n        - Text: Streams incrementally as tokens arrive\n        - Function calls: May arrive in separate chunks\n        - Bytes (e.g., images): Typically arrive as single chunk, interleaved\n          with text\n        - Thoughts: Stream incrementally when thinking_config is enabled\n\n      **Examples:**\n\n      1. Simple text streaming::\n\n           LlmResponse(partial=True,  parts=[\"The weather\"])\n           LlmResponse(partial=True,  parts=[\" in Tokyo is\"])\n           LlmResponse(partial=True,  parts=[\" sunny.\"])\n           LlmResponse(partial=False, parts=[\"\
        The weather in Tokyo is sunny.\"])\n\n      2. Text + function call::\n\n           LlmResponse(partial=True,  parts=[Text(\"Let me check...\")])\n           LlmResponse(partial=True,  parts=[FunctionCall(\"get_weather\", ...)])\n           LlmResponse(partial=False, parts=[Text(\"Let me check...\"),\n                                             FunctionCall(\"get_weather\", ...)])\n\n      3. Parallel function calls across chunks::\n\n           LlmResponse(partial=True,  parts=[Text(\"Checking both cities...\")])\n           LlmResponse(partial=True,  parts=[FunctionCall(\"get_weather\", Tokyo)])\n           LlmResponse(partial=True,  parts=[FunctionCall(\"get_weather\", NYC)])\n           LlmResponse(partial=False, parts=[Text(\"Checking both cities...\"),\n                                             FunctionCall(\"get_weather\", Tokyo),\n                                             FunctionCall(\"get_weather\", NYC)])\n\n      4. Text + bytes (image generation with gemini-2.5-flash-image)::\n\
        \n           LlmResponse(partial=True,  parts=[Text(\"Here's an image of a dog.\")])\n           LlmResponse(partial=True,  parts=[Text(\"\n\")])\n           LlmResponse(partial=True,  parts=[Blob(image/png, 1.6MB)])\n           LlmResponse(partial=True,  parts=[Text(\"It carries a bone\")])\n           LlmResponse(partial=True,  parts=[Text(\" and running around.\")])\n           LlmResponse(partial=False, parts=[Text(\"Here's an image of a dog.\n\"),\n                                             Blob(image/png, 1.6MB),\n                                             Text(\"It carries a bone and running around.\")])\n\n         Note: Consecutive text parts before and after blob merge separately.\n\n      5. Text with thinking (gemini-2.5-flash with thinking_config)::\n\n           LlmResponse(partial=True,  parts=[Thought(\"Let me analyze...\")])\n           LlmResponse(partial=True,  parts=[Thought(\"The user wants...\")])\n           LlmResponse(partial=True,  parts=[Text(\"Based\
        \ on my analysis,\")])\n           LlmResponse(partial=True,  parts=[Text(\" the answer is 42.\")])\n           LlmResponse(partial=False, parts=[Thought(\"Let me analyze...The user wants...\"),\n                                             Text(\"Based on my analysis, the answer is 42.\")])\n\n         Note: Consecutive parts of same type merge (thoughts\u2192thought, text\u2192text).\n\n      **Important:** All yielded responses represent one logical model turn.\n      The final response with `partial=False` should be identical to the\n      response that would be received with `stream=False`.\n    "
    - signature: 'def connect(self, llm_request: google.adk.models.llm_request.LlmRequest) -> google.adk.models.base_llm_connection.BaseLlmConnection:'
      docstring: "Creates a live connection to the LLM.\n\nArgs:\n  llm_request: LlmRequest, the request to send to the LLM.\n\nReturns:\n  BaseLlmConnection, the connection to the LLM."
  inherited_properties:
    BaseLlm:
    - signature: 'model_config: pydantic.ConfigDict'
      docstring: The pydantic model config.
    - signature: 'model: str'
      docstring: The name of the LLM, e.g. gemini-2.5-flash or gemini-2.5-pro.
    BaseModel:
    - signature: 'model_config: pydantic.ConfigDict'
  omitted_inherited_members_from:
  - pydantic.BaseModel
- rank: 1044
  id: google.adk.models.anthropic_llm.AnthropicLlm.generate_content_async
  name: generate_content_async
  file_path: google/adk/models/anthropic_llm.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def generate_content_async(self, llm_request: google.adk.models.llm_request.LlmRequest, stream: bool) -> typing.AsyncGenerator[google.adk.models.llm_response.LlmResponse, None]:'
- rank: 1045
  id: google.adk.models.anthropic_llm.ClaudeRequest
  name: ClaudeRequest
  file_path: google/adk/models/anthropic_llm.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: '[Note: Inherited members from pydantic.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, system_instruction: str, messages: typing.Iterable[anthropic.types.MessageParam], tools: list[anthropic.types.ToolParam]):'
  properties:
  - signature: 'system_instruction: str'
  - signature: 'messages: typing.Iterable[anthropic.types.MessageParam]'
  - signature: 'tools: list[anthropic.types.ToolParam]'
  inherited_properties:
    BaseModel:
    - signature: 'model_config: pydantic.ConfigDict'
  omitted_inherited_members_from:
  - pydantic.BaseModel
- rank: 1046
  id: google.adk.models.anthropic_llm.content_block_to_part
  name: content_block_to_part
  file_path: google/adk/models/anthropic_llm.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def content_block_to_part(content_block: anthropic.types.ContentBlock) -> google.genai.types.Part:'
- rank: 1047
  id: google.adk.models.anthropic_llm.content_to_message_param
  name: content_to_message_param
  file_path: google/adk/models/anthropic_llm.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def content_to_message_param(content: google.genai.types.Content) -> anthropic.types.MessageParam:'
- rank: 1048
  id: google.adk.models.anthropic_llm.function_declaration_to_tool_param
  name: function_declaration_to_tool_param
  file_path: google/adk/models/anthropic_llm.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: Converts a function declaration to an Anthropic tool param.
  signature: 'def function_declaration_to_tool_param(function_declaration: google.genai.types.FunctionDeclaration) -> anthropic.types.ToolParam:'
- rank: 1049
  id: google.adk.models.anthropic_llm.message_to_generate_content_response
  name: message_to_generate_content_response
  file_path: google/adk/models/anthropic_llm.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def message_to_generate_content_response(message: anthropic.types.Message) -> google.adk.models.llm_response.LlmResponse:'
- rank: 1050
  id: google.adk.models.anthropic_llm.part_to_message_block
  name: part_to_message_block
  file_path: google/adk/models/anthropic_llm.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def part_to_message_block(part: google.genai.types.Part) -> typing.Union[anthropic.types.TextBlockParam, anthropic.types.ImageBlockParam, anthropic.types.ToolUseBlockParam, anthropic.types.ToolResultBlockParam]:'
- rank: 1051
  id: google.adk.models.anthropic_llm.to_claude_role
  name: to_claude_role
  file_path: google/adk/models/anthropic_llm.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def to_claude_role(role: typing.Optional[str]) -> typing.Literal[user, assistant]:'
- rank: 1052
  id: google.adk.models.anthropic_llm.to_google_genai_finish_reason
  name: to_google_genai_finish_reason
  file_path: google/adk/models/anthropic_llm.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def to_google_genai_finish_reason(anthropic_stop_reason: typing.Optional[str]) -> google.genai.types.FinishReason:'
- rank: 1053
  id: google.adk.models.apigee_llm
  name: apigee_llm
  file_path: google/adk/models/apigee_llm.py
  type: MODULE
  group: Orphan
  usage_score: 0
- rank: 1054
  id: google.adk.models.apigee_llm.ApigeeLlm
  name: ApigeeLlm
  file_path: google/adk/models/apigee_llm.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: "A BaseLlm implementation for calling Apigee proxy.\n\nAttributes:\n  model: The name of the Gemini model.\n\n[Note: Inherited members from pydantic.BaseModel are omitted.]"
  constructor_signature: 'def __init__(self, *, model: str, proxy_url: str | None=None, custom_headers: dict[str, str] | None=None, retry_options: typing.Optional[google.genai.types.HttpRetryOptions]=None):'
  methods:
  - signature: 'def supported_models(cls) -> list[str]:'
    docstring: "Provides the list of supported models.\n\nReturns:\n  A list of supported models."
  - signature: 'def api_client(self) -> google.genai.Client:'
    docstring: "Provides the api client.\n\nReturns:\n  The api client."
  inherited_methods:
    Gemini:
    - signature: 'def supported_models(cls) -> list[str]:'
      docstring: "Provides the list of supported models.\n\nReturns:\n  A list of supported models."
    - signature: 'def generate_content_async(self, llm_request: google.adk.models.llm_request.LlmRequest, stream: bool) -> typing.AsyncGenerator[google.adk.models.llm_response.LlmResponse, None]:'
      docstring: "Sends a request to the Gemini model.\n\nArgs:\n  llm_request: LlmRequest, the request to send to the Gemini model.\n  stream: bool = False, whether to do streaming call.\n\nYields:\n  LlmResponse: The model response."
    - signature: 'def api_client(self) -> google.genai.Client:'
      docstring: "Provides the api client.\n\nReturns:\n  The api client."
    - signature: 'def connect(self, llm_request: google.adk.models.llm_request.LlmRequest) -> google.adk.models.base_llm_connection.BaseLlmConnection:'
      docstring: "Connects to the Gemini model and returns an llm connection.\n\nArgs:\n  llm_request: LlmRequest, the request to send to the Gemini model.\n\nYields:\n  BaseLlmConnection, the connection to the Gemini model."
    - signature: 'def convert_wait_to_wait_5_seconds(wait_func):'
    - signature: 'def wait_5_seconds():'
    BaseLlm:
    - signature: 'def supported_models(cls) -> list[str]:'
      docstring: Returns a list of supported models in regex for LlmRegistry.
    - signature: 'def generate_content_async(self, llm_request: google.adk.models.llm_request.LlmRequest, stream: bool) -> typing.AsyncGenerator[google.adk.models.llm_response.LlmResponse, None]:'
      docstring: "Generates content for a single model turn.\n\n    This method handles Server-Sent Events (SSE) streaming for unidirectional\n    content generation. For bidirectional streaming (e.g., Gemini Live API),\n    use the `connect()` method instead.\n\n    Args:\n      llm_request: LlmRequest, the request to send to the LLM.\n      stream: bool = False, whether to enable SSE streaming mode.\n\n    Yields:\n      LlmResponse objects representing the model's response for one turn.\n\n      **Non-streaming mode (stream=False):**\n\n        Yields exactly one LlmResponse containing the complete model output\n        (text, function calls, bytes, etc.). This response has `partial=False`.\n\n      **Streaming mode (stream=True):**\n\n        Yields multiple LlmResponse objects as chunks arrive:\n\n        - Intermediate chunks: `partial=True` (progressive updates)\n        - Final chunk: `partial=False` (aggregated content from entire turn,\n          identical to stream=False output)\n\
        \        - Text consolidation: Consecutive text parts of the same type\n          (thought/non-thought) SHOULD merge without separator, but client\n          code must not rely on this - unconsolidated parts are unusual but also\n          valid\n\n      **Common content in partial chunks:**\n\n        All intermediate chunks have `partial=True` regardless of content type.\n        Common examples include:\n\n        - Text: Streams incrementally as tokens arrive\n        - Function calls: May arrive in separate chunks\n        - Bytes (e.g., images): Typically arrive as single chunk, interleaved\n          with text\n        - Thoughts: Stream incrementally when thinking_config is enabled\n\n      **Examples:**\n\n      1. Simple text streaming::\n\n           LlmResponse(partial=True,  parts=[\"The weather\"])\n           LlmResponse(partial=True,  parts=[\" in Tokyo is\"])\n           LlmResponse(partial=True,  parts=[\" sunny.\"])\n           LlmResponse(partial=False, parts=[\"\
        The weather in Tokyo is sunny.\"])\n\n      2. Text + function call::\n\n           LlmResponse(partial=True,  parts=[Text(\"Let me check...\")])\n           LlmResponse(partial=True,  parts=[FunctionCall(\"get_weather\", ...)])\n           LlmResponse(partial=False, parts=[Text(\"Let me check...\"),\n                                             FunctionCall(\"get_weather\", ...)])\n\n      3. Parallel function calls across chunks::\n\n           LlmResponse(partial=True,  parts=[Text(\"Checking both cities...\")])\n           LlmResponse(partial=True,  parts=[FunctionCall(\"get_weather\", Tokyo)])\n           LlmResponse(partial=True,  parts=[FunctionCall(\"get_weather\", NYC)])\n           LlmResponse(partial=False, parts=[Text(\"Checking both cities...\"),\n                                             FunctionCall(\"get_weather\", Tokyo),\n                                             FunctionCall(\"get_weather\", NYC)])\n\n      4. Text + bytes (image generation with gemini-2.5-flash-image)::\n\
        \n           LlmResponse(partial=True,  parts=[Text(\"Here's an image of a dog.\")])\n           LlmResponse(partial=True,  parts=[Text(\"\n\")])\n           LlmResponse(partial=True,  parts=[Blob(image/png, 1.6MB)])\n           LlmResponse(partial=True,  parts=[Text(\"It carries a bone\")])\n           LlmResponse(partial=True,  parts=[Text(\" and running around.\")])\n           LlmResponse(partial=False, parts=[Text(\"Here's an image of a dog.\n\"),\n                                             Blob(image/png, 1.6MB),\n                                             Text(\"It carries a bone and running around.\")])\n\n         Note: Consecutive text parts before and after blob merge separately.\n\n      5. Text with thinking (gemini-2.5-flash with thinking_config)::\n\n           LlmResponse(partial=True,  parts=[Thought(\"Let me analyze...\")])\n           LlmResponse(partial=True,  parts=[Thought(\"The user wants...\")])\n           LlmResponse(partial=True,  parts=[Text(\"Based\
        \ on my analysis,\")])\n           LlmResponse(partial=True,  parts=[Text(\" the answer is 42.\")])\n           LlmResponse(partial=False, parts=[Thought(\"Let me analyze...The user wants...\"),\n                                             Text(\"Based on my analysis, the answer is 42.\")])\n\n         Note: Consecutive parts of same type merge (thoughts\u2192thought, text\u2192text).\n\n      **Important:** All yielded responses represent one logical model turn.\n      The final response with `partial=False` should be identical to the\n      response that would be received with `stream=False`.\n    "
    - signature: 'def connect(self, llm_request: google.adk.models.llm_request.LlmRequest) -> google.adk.models.base_llm_connection.BaseLlmConnection:'
      docstring: "Creates a live connection to the LLM.\n\nArgs:\n  llm_request: LlmRequest, the request to send to the LLM.\n\nReturns:\n  BaseLlmConnection, the connection to the LLM."
  inherited_properties:
    Gemini:
    - signature: 'model: str'
    - signature: 'speech_config: typing.Optional[google.genai.types.SpeechConfig]'
    - signature: 'retry_options: typing.Optional[google.genai.types.HttpRetryOptions]'
      docstring: "Allow Gemini to retry failed responses.\n\nSample:\n```python\nfrom google.genai import types\n\n# ...\n\nagent = Agent(\n  model=Gemini(\n    retry_options=types.HttpRetryOptions(initial_delay=1, attempts=2),\n  )\n)\n```"
    BaseLlm:
    - signature: 'model_config: pydantic.ConfigDict'
      docstring: The pydantic model config.
    - signature: 'model: str'
      docstring: The name of the LLM, e.g. gemini-2.5-flash or gemini-2.5-pro.
    BaseModel:
    - signature: 'model_config: pydantic.ConfigDict'
  omitted_inherited_members_from:
  - pydantic.BaseModel
- rank: 1055
  id: google.adk.models.apigee_llm.ApigeeLlm.__init__
  name: __init__
  file_path: google/adk/models/apigee_llm.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Initializes the Apigee LLM backend.\n\nArgs:\n  model: The model string specifies the LLM provider (e.g., Vertex AI,\n    Gemini), API version, and the model ID. Supported format:\n    `apigee/[<provider>/][<version>/]<model_id>`\n\n    Components\n      `provider` (optional): `vertex_ai` or `gemini`. If omitted, behavior\n        depends on the `GOOGLE_GENAI_USE_VERTEXAI` environment variable. If\n        that is not set to TRUE or 1, it defaults to `gemini`. `provider`\n        takes precedence over `GOOGLE_GENAI_USE_VERTEXAI`.\n      `version` (optional): The API version (e.g., `v1`, `v1beta`). If\n        omitted, the default version for the provider is used.\n      `model_id` (required): The model identifier (e.g.,\n        `gemini-2.5-flash`).\n\n    Examples\n      - `apigee/gemini-2.5-flash`\n      - `apigee/v1/gemini-2.5-flash`\n      - `apigee/vertex_ai/gemini-2.5-flash`\n      - `apigee/gemini/v1/gemini-2.5-flash`\n      - `apigee/vertex_ai/v1beta/gemini-2.5-flash`\n\
    \n  proxy_url: The URL of the Apigee proxy.\n  custom_headers: A dictionary of headers to be sent with the request.\n  retry_options: Allow google-genai to retry failed responses."
  signature: 'def __init__(self, *, model: str, proxy_url: str | None=None, custom_headers: dict[str, str] | None=None, retry_options: typing.Optional[google.genai.types.HttpRetryOptions]=None):'
- rank: 1056
  id: google.adk.models.apigee_llm.ApigeeLlm.api_client
  name: api_client
  file_path: google/adk/models/apigee_llm.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Provides the api client.\n\nReturns:\n  The api client."
  signature: 'def api_client(self) -> google.genai.Client:'
- rank: 1057
  id: google.adk.models.apigee_llm.ApigeeLlm.supported_models
  name: supported_models
  file_path: google/adk/models/apigee_llm.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Provides the list of supported models.\n\nReturns:\n  A list of supported models."
  signature: 'def supported_models(cls) -> list[str]:'
- rank: 1058
  id: google.adk.models.base_llm
  name: base_llm
  file_path: google/adk/models/base_llm.py
  type: MODULE
  group: Orphan
  usage_score: 0
- rank: 1059
  id: google.adk.models.base_llm.BaseLlm
  name: BaseLlm
  file_path: google/adk/models/base_llm.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'The BaseLLM class.


    [Note: Inherited members from pydantic.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, model: str):'
  methods:
  - signature: 'def supported_models(cls) -> list[str]:'
    docstring: Returns a list of supported models in regex for LlmRegistry.
  - signature: 'def generate_content_async(self, llm_request: google.adk.models.llm_request.LlmRequest, stream: bool) -> typing.AsyncGenerator[google.adk.models.llm_response.LlmResponse, None]:'
    docstring: "Generates content for a single model turn.\n\n    This method handles Server-Sent Events (SSE) streaming for unidirectional\n    content generation. For bidirectional streaming (e.g., Gemini Live API),\n    use the `connect()` method instead.\n\n    Args:\n      llm_request: LlmRequest, the request to send to the LLM.\n      stream: bool = False, whether to enable SSE streaming mode.\n\n    Yields:\n      LlmResponse objects representing the model's response for one turn.\n\n      **Non-streaming mode (stream=False):**\n\n        Yields exactly one LlmResponse containing the complete model output\n        (text, function calls, bytes, etc.). This response has `partial=False`.\n\n      **Streaming mode (stream=True):**\n\n        Yields multiple LlmResponse objects as chunks arrive:\n\n        - Intermediate chunks: `partial=True` (progressive updates)\n        - Final chunk: `partial=False` (aggregated content from entire turn,\n          identical to stream=False output)\n\
      \        - Text consolidation: Consecutive text parts of the same type\n          (thought/non-thought) SHOULD merge without separator, but client\n          code must not rely on this - unconsolidated parts are unusual but also\n          valid\n\n      **Common content in partial chunks:**\n\n        All intermediate chunks have `partial=True` regardless of content type.\n        Common examples include:\n\n        - Text: Streams incrementally as tokens arrive\n        - Function calls: May arrive in separate chunks\n        - Bytes (e.g., images): Typically arrive as single chunk, interleaved\n          with text\n        - Thoughts: Stream incrementally when thinking_config is enabled\n\n      **Examples:**\n\n      1. Simple text streaming::\n\n           LlmResponse(partial=True,  parts=[\"The weather\"])\n           LlmResponse(partial=True,  parts=[\" in Tokyo is\"])\n           LlmResponse(partial=True,  parts=[\" sunny.\"])\n           LlmResponse(partial=False, parts=[\"\
      The weather in Tokyo is sunny.\"])\n\n      2. Text + function call::\n\n           LlmResponse(partial=True,  parts=[Text(\"Let me check...\")])\n           LlmResponse(partial=True,  parts=[FunctionCall(\"get_weather\", ...)])\n           LlmResponse(partial=False, parts=[Text(\"Let me check...\"),\n                                             FunctionCall(\"get_weather\", ...)])\n\n      3. Parallel function calls across chunks::\n\n           LlmResponse(partial=True,  parts=[Text(\"Checking both cities...\")])\n           LlmResponse(partial=True,  parts=[FunctionCall(\"get_weather\", Tokyo)])\n           LlmResponse(partial=True,  parts=[FunctionCall(\"get_weather\", NYC)])\n           LlmResponse(partial=False, parts=[Text(\"Checking both cities...\"),\n                                             FunctionCall(\"get_weather\", Tokyo),\n                                             FunctionCall(\"get_weather\", NYC)])\n\n      4. Text + bytes (image generation with gemini-2.5-flash-image)::\n\
      \n           LlmResponse(partial=True,  parts=[Text(\"Here's an image of a dog.\")])\n           LlmResponse(partial=True,  parts=[Text(\"\n\")])\n           LlmResponse(partial=True,  parts=[Blob(image/png, 1.6MB)])\n           LlmResponse(partial=True,  parts=[Text(\"It carries a bone\")])\n           LlmResponse(partial=True,  parts=[Text(\" and running around.\")])\n           LlmResponse(partial=False, parts=[Text(\"Here's an image of a dog.\n\"),\n                                             Blob(image/png, 1.6MB),\n                                             Text(\"It carries a bone and running around.\")])\n\n         Note: Consecutive text parts before and after blob merge separately.\n\n      5. Text with thinking (gemini-2.5-flash with thinking_config)::\n\n           LlmResponse(partial=True,  parts=[Thought(\"Let me analyze...\")])\n           LlmResponse(partial=True,  parts=[Thought(\"The user wants...\")])\n           LlmResponse(partial=True,  parts=[Text(\"Based\
      \ on my analysis,\")])\n           LlmResponse(partial=True,  parts=[Text(\" the answer is 42.\")])\n           LlmResponse(partial=False, parts=[Thought(\"Let me analyze...The user wants...\"),\n                                             Text(\"Based on my analysis, the answer is 42.\")])\n\n         Note: Consecutive parts of same type merge (thoughts\u2192thought, text\u2192text).\n\n      **Important:** All yielded responses represent one logical model turn.\n      The final response with `partial=False` should be identical to the\n      response that would be received with `stream=False`.\n    "
  - signature: 'def connect(self, llm_request: google.adk.models.llm_request.LlmRequest) -> google.adk.models.base_llm_connection.BaseLlmConnection:'
    docstring: "Creates a live connection to the LLM.\n\nArgs:\n  llm_request: LlmRequest, the request to send to the LLM.\n\nReturns:\n  BaseLlmConnection, the connection to the LLM."
  properties:
  - signature: 'model_config: pydantic.ConfigDict'
    docstring: The pydantic model config.
  - signature: 'model: str'
    docstring: The name of the LLM, e.g. gemini-2.5-flash or gemini-2.5-pro.
  inherited_properties:
    BaseModel:
    - signature: 'model_config: pydantic.ConfigDict'
  omitted_inherited_members_from:
  - pydantic.BaseModel
- rank: 1060
  id: google.adk.models.base_llm.BaseLlm.connect
  name: connect
  file_path: google/adk/models/base_llm.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Creates a live connection to the LLM.\n\nArgs:\n  llm_request: LlmRequest, the request to send to the LLM.\n\nReturns:\n  BaseLlmConnection, the connection to the LLM."
  signature: 'def connect(self, llm_request: google.adk.models.llm_request.LlmRequest) -> google.adk.models.base_llm_connection.BaseLlmConnection:'
- rank: 1061
  id: google.adk.models.base_llm.BaseLlm.generate_content_async
  name: generate_content_async
  file_path: google/adk/models/base_llm.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Generates content for a single model turn.\n\n    This method handles Server-Sent Events (SSE) streaming for unidirectional\n    content generation. For bidirectional streaming (e.g., Gemini Live API),\n    use the `connect()` method instead.\n\n    Args:\n      llm_request: LlmRequest, the request to send to the LLM.\n      stream: bool = False, whether to enable SSE streaming mode.\n\n    Yields:\n      LlmResponse objects representing the model's response for one turn.\n\n      **Non-streaming mode (stream=False):**\n\n        Yields exactly one LlmResponse containing the complete model output\n        (text, function calls, bytes, etc.). This response has `partial=False`.\n\n      **Streaming mode (stream=True):**\n\n        Yields multiple LlmResponse objects as chunks arrive:\n\n        - Intermediate chunks: `partial=True` (progressive updates)\n        - Final chunk: `partial=False` (aggregated content from entire turn,\n          identical to stream=False output)\n\
    \        - Text consolidation: Consecutive text parts of the same type\n          (thought/non-thought) SHOULD merge without separator, but client\n          code must not rely on this - unconsolidated parts are unusual but also\n          valid\n\n      **Common content in partial chunks:**\n\n        All intermediate chunks have `partial=True` regardless of content type.\n        Common examples include:\n\n        - Text: Streams incrementally as tokens arrive\n        - Function calls: May arrive in separate chunks\n        - Bytes (e.g., images): Typically arrive as single chunk, interleaved\n          with text\n        - Thoughts: Stream incrementally when thinking_config is enabled\n\n      **Examples:**\n\n      1. Simple text streaming::\n\n           LlmResponse(partial=True,  parts=[\"The weather\"])\n           LlmResponse(partial=True,  parts=[\" in Tokyo is\"])\n           LlmResponse(partial=True,  parts=[\" sunny.\"])\n           LlmResponse(partial=False, parts=[\"\
    The weather in Tokyo is sunny.\"])\n\n      2. Text + function call::\n\n           LlmResponse(partial=True,  parts=[Text(\"Let me check...\")])\n           LlmResponse(partial=True,  parts=[FunctionCall(\"get_weather\", ...)])\n           LlmResponse(partial=False, parts=[Text(\"Let me check...\"),\n                                             FunctionCall(\"get_weather\", ...)])\n\n      3. Parallel function calls across chunks::\n\n           LlmResponse(partial=True,  parts=[Text(\"Checking both cities...\")])\n           LlmResponse(partial=True,  parts=[FunctionCall(\"get_weather\", Tokyo)])\n           LlmResponse(partial=True,  parts=[FunctionCall(\"get_weather\", NYC)])\n           LlmResponse(partial=False, parts=[Text(\"Checking both cities...\"),\n                                             FunctionCall(\"get_weather\", Tokyo),\n                                             FunctionCall(\"get_weather\", NYC)])\n\n      4. Text + bytes (image generation with gemini-2.5-flash-image)::\n\
    \n           LlmResponse(partial=True,  parts=[Text(\"Here's an image of a dog.\")])\n           LlmResponse(partial=True,  parts=[Text(\"\n\")])\n           LlmResponse(partial=True,  parts=[Blob(image/png, 1.6MB)])\n           LlmResponse(partial=True,  parts=[Text(\"It carries a bone\")])\n           LlmResponse(partial=True,  parts=[Text(\" and running around.\")])\n           LlmResponse(partial=False, parts=[Text(\"Here's an image of a dog.\n\"),\n                                             Blob(image/png, 1.6MB),\n                                             Text(\"It carries a bone and running around.\")])\n\n         Note: Consecutive text parts before and after blob merge separately.\n\n      5. Text with thinking (gemini-2.5-flash with thinking_config)::\n\n           LlmResponse(partial=True,  parts=[Thought(\"Let me analyze...\")])\n           LlmResponse(partial=True,  parts=[Thought(\"The user wants...\")])\n           LlmResponse(partial=True,  parts=[Text(\"Based on\
    \ my analysis,\")])\n           LlmResponse(partial=True,  parts=[Text(\" the answer is 42.\")])\n           LlmResponse(partial=False, parts=[Thought(\"Let me analyze...The user wants...\"),\n                                             Text(\"Based on my analysis, the answer is 42.\")])\n\n         Note: Consecutive parts of same type merge (thoughts\u2192thought, text\u2192text).\n\n      **Important:** All yielded responses represent one logical model turn.\n      The final response with `partial=False` should be identical to the\n      response that would be received with `stream=False`.\n    "
  signature: 'def generate_content_async(self, llm_request: google.adk.models.llm_request.LlmRequest, stream: bool) -> typing.AsyncGenerator[google.adk.models.llm_response.LlmResponse, None]:'
- rank: 1062
  id: google.adk.models.base_llm_connection
  name: base_llm_connection
  file_path: google/adk/models/base_llm_connection.py
  type: MODULE
  group: Orphan
  usage_score: 0
- rank: 1063
  id: google.adk.models.base_llm_connection.BaseLlmConnection
  name: BaseLlmConnection
  file_path: google/adk/models/base_llm_connection.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: The base class for a live model connection.
  methods:
  - signature: 'def send_history(self, history: list[google.genai.types.Content]):'
    docstring: "Sends the conversation history to the model.\n\nYou call this method right after setting up the model connection.\nThe model will respond if the last content is from user; otherwise, it will\nwait for new user input before responding.\n\nArgs:\n  history: The conversation history to send to the model."
  - signature: 'def send_content(self, content: google.genai.types.Content):'
    docstring: "Sends a user content to the model.\n\nThe model will respond immediately upon receiving the content.\nIf you send function responses, all parts in the content should be function\nresponses.\n\nArgs:\n  content: The content to send to the model."
  - signature: 'def send_realtime(self, blob: google.genai.types.Blob):'
    docstring: "Sends a chunk of audio or a frame of video to the model in realtime.\n\nThe model may not respond immediately upon receiving the blob. It will do\nvoice activity detection and decide when to respond.\n\nArgs:\n  blob: The blob to send to the model."
  - signature: 'def receive(self) -> typing.AsyncGenerator[google.adk.models.llm_response.LlmResponse, None]:'
    docstring: "Receives the model response using the llm server connection.\n\nArgs: None.\n\nYields:\n  LlmResponse: The model response."
  - signature: 'def close(self):'
    docstring: Closes the llm server connection.
- rank: 1064
  id: google.adk.models.base_llm_connection.BaseLlmConnection.receive
  name: receive
  file_path: google/adk/models/base_llm_connection.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Receives the model response using the llm server connection.\n\nArgs: None.\n\nYields:\n  LlmResponse: The model response."
  signature: 'def receive(self) -> typing.AsyncGenerator[google.adk.models.llm_response.LlmResponse, None]:'
- rank: 1065
  id: google.adk.models.base_llm_connection.BaseLlmConnection.send_content
  name: send_content
  file_path: google/adk/models/base_llm_connection.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Sends a user content to the model.\n\nThe model will respond immediately upon receiving the content.\nIf you send function responses, all parts in the content should be function\nresponses.\n\nArgs:\n  content: The content to send to the model."
  signature: 'def send_content(self, content: google.genai.types.Content):'
- rank: 1066
  id: google.adk.models.base_llm_connection.BaseLlmConnection.send_history
  name: send_history
  file_path: google/adk/models/base_llm_connection.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Sends the conversation history to the model.\n\nYou call this method right after setting up the model connection.\nThe model will respond if the last content is from user; otherwise, it will\nwait for new user input before responding.\n\nArgs:\n  history: The conversation history to send to the model."
  signature: 'def send_history(self, history: list[google.genai.types.Content]):'
- rank: 1067
  id: google.adk.models.base_llm_connection.BaseLlmConnection.send_realtime
  name: send_realtime
  file_path: google/adk/models/base_llm_connection.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Sends a chunk of audio or a frame of video to the model in realtime.\n\nThe model may not respond immediately upon receiving the blob. It will do\nvoice activity detection and decide when to respond.\n\nArgs:\n  blob: The blob to send to the model."
  signature: 'def send_realtime(self, blob: google.genai.types.Blob):'
- rank: 1068
  id: google.adk.models.cache_metadata
  name: cache_metadata
  file_path: google/adk/models/cache_metadata.py
  type: MODULE
  group: Orphan
  usage_score: 0
- rank: 1069
  id: google.adk.models.cache_metadata.CacheMetadata
  name: CacheMetadata
  file_path: google/adk/models/cache_metadata.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: "Metadata for context cache associated with LLM responses.\n\nThis class stores cache identification, usage tracking, and lifecycle\ninformation for a particular cache instance. It can be in two states:\n\n1. Active cache state: cache_name is set, all fields populated\n2. Fingerprint-only state: cache_name is None, only fingerprint and\n   contents_count are set for prefix matching\n\nToken counts (cached and total) are available in the LlmResponse.usage_metadata\nand should be accessed from there to avoid duplication.\n\nAttributes:\n    cache_name: The full resource name of the cached content (e.g.,\n        'projects/123/locations/us-central1/cachedContents/456').\n        None when no active cache exists (fingerprint-only state).\n    expire_time: Unix timestamp when the cache expires. None when no\n        active cache exists.\n    fingerprint: Hash of cacheable contents (instruction + tools + contents).\n        Always present for prefix matching.\n    invocations_used:\
    \ Number of invocations this cache has been used for.\n        None when no active cache exists.\n    contents_count: Number of contents. When active cache exists, this is\n        the count of cached contents. When no active cache exists, this is\n        the total count of contents in the request.\n    created_at: Unix timestamp when the cache was created. None when\n        no active cache exists.\n\n[Note: Inherited members from pydantic.BaseModel are omitted.]"
  constructor_signature: 'def __init__(self, *, cache_name: typing.Optional[str] = None, expire_time: typing.Optional[float] = None, fingerprint: str, invocations_used: typing.Optional[int] = None, contents_count: int, created_at: typing.Optional[float] = None):'
  methods:
  - signature: 'def expire_soon(self) -> bool:'
    docstring: Check if the cache will expire soon (with 2-minute buffer).
  properties:
  - signature: 'model_config: pydantic.ConfigDict'
  - signature: 'cache_name: typing.Optional[str]'
  - signature: 'expire_time: typing.Optional[float]'
  - signature: 'fingerprint: str'
  - signature: 'invocations_used: typing.Optional[int]'
  - signature: 'contents_count: int'
  - signature: 'created_at: typing.Optional[float]'
  inherited_properties:
    BaseModel:
    - signature: 'model_config: pydantic.ConfigDict'
  omitted_inherited_members_from:
  - pydantic.BaseModel
- rank: 1070
  id: google.adk.models.cache_metadata.CacheMetadata.expire_soon
  name: expire_soon
  file_path: google/adk/models/cache_metadata.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: Check if the cache will expire soon (with 2-minute buffer).
  signature: 'def expire_soon(self) -> bool:'
- rank: 1071
  id: google.adk.models.gemini_context_cache_manager
  name: gemini_context_cache_manager
  file_path: google/adk/models/gemini_context_cache_manager.py
  type: MODULE
  group: Orphan
  usage_score: 0
  docstring: Manages context cache lifecycle for Gemini models.
- rank: 1072
  id: google.adk.models.gemini_context_cache_manager.GeminiContextCacheManager
  name: GeminiContextCacheManager
  file_path: google/adk/models/gemini_context_cache_manager.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Manages context cache lifecycle for Gemini models.


    This manager handles cache creation, validation, cleanup, and metadata

    population for Gemini context caching. It uses content hashing to determine

    cache compatibility and implements efficient caching strategies.'
  constructor_signature: 'def __init__(self, genai_client: google.genai.Client):'
  methods:
  - signature: 'def handle_context_caching(self, llm_request: google.adk.models.llm_request.LlmRequest) -> typing.Optional[google.adk.models.cache_metadata.CacheMetadata]:'
    docstring: "Handle context caching for Gemini models.\n\nValidates existing cache or creates a new one if needed. Applies\nthe cache to the request by setting cached_content and removing cached\ncontents from the request.\n\nArgs:\n    llm_request: Request that may contain cache config and metadata.\n                Modified in-place to use the cache.\n\nReturns:\n    Cache metadata to be included in response, or None if caching failed"
  - signature: 'def cleanup_cache(self, cache_name: str) -> None:'
    docstring: "Clean up cache by deleting it.\n\nArgs:\n    cache_name: Name of cache to delete"
  - signature: 'def populate_cache_metadata_in_response(self, llm_response: google.adk.models.llm_response.LlmResponse, cache_metadata: google.adk.models.cache_metadata.CacheMetadata) -> None:'
    docstring: "Populate cache metadata in LLM response.\n\nArgs:\n    llm_response: Response to populate metadata in\n    cache_metadata: Cache metadata to copy into response"
- rank: 1073
  id: google.adk.models.gemini_context_cache_manager.GeminiContextCacheManager.__init__
  name: __init__
  file_path: google/adk/models/gemini_context_cache_manager.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Initialize cache manager with shared client.\n\nArgs:\n    genai_client: The GenAI client to use for cache operations."
  signature: 'def __init__(self, genai_client: google.genai.Client):'
- rank: 1074
  id: google.adk.models.gemini_context_cache_manager.GeminiContextCacheManager.cleanup_cache
  name: cleanup_cache
  file_path: google/adk/models/gemini_context_cache_manager.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Clean up cache by deleting it.\n\nArgs:\n    cache_name: Name of cache to delete"
  signature: 'def cleanup_cache(self, cache_name: str) -> None:'
- rank: 1075
  id: google.adk.models.gemini_context_cache_manager.GeminiContextCacheManager.handle_context_caching
  name: handle_context_caching
  file_path: google/adk/models/gemini_context_cache_manager.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Handle context caching for Gemini models.\n\nValidates existing cache or creates a new one if needed. Applies\nthe cache to the request by setting cached_content and removing cached\ncontents from the request.\n\nArgs:\n    llm_request: Request that may contain cache config and metadata.\n                Modified in-place to use the cache.\n\nReturns:\n    Cache metadata to be included in response, or None if caching failed"
  signature: 'def handle_context_caching(self, llm_request: google.adk.models.llm_request.LlmRequest) -> typing.Optional[google.adk.models.cache_metadata.CacheMetadata]:'
- rank: 1076
  id: google.adk.models.gemini_context_cache_manager.GeminiContextCacheManager.populate_cache_metadata_in_response
  name: populate_cache_metadata_in_response
  file_path: google/adk/models/gemini_context_cache_manager.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Populate cache metadata in LLM response.\n\nArgs:\n    llm_response: Response to populate metadata in\n    cache_metadata: Cache metadata to copy into response"
  signature: 'def populate_cache_metadata_in_response(self, llm_response: google.adk.models.llm_response.LlmResponse, cache_metadata: google.adk.models.cache_metadata.CacheMetadata) -> None:'
- rank: 1077
  id: google.adk.models.gemini_llm_connection
  name: gemini_llm_connection
  file_path: google/adk/models/gemini_llm_connection.py
  type: MODULE
  group: Orphan
  usage_score: 0
- rank: 1078
  id: google.adk.models.gemini_llm_connection.GeminiLlmConnection
  name: GeminiLlmConnection
  file_path: google/adk/models/gemini_llm_connection.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: The Gemini model connection.
  constructor_signature: 'def __init__(self, gemini_session: google.genai.live.AsyncSession, api_backend: google.adk.utils.variant_utils.GoogleLLMVariant):'
  methods:
  - signature: 'def send_history(self, history: list[google.genai.types.Content]):'
    docstring: "Sends the conversation history to the gemini model.\n\nYou call this method right after setting up the model connection.\nThe model will respond if the last content is from user; otherwise, it will\nwait for new user input before responding.\n\nArgs:\n  history: The conversation history to send to the model."
  - signature: 'def send_content(self, content: google.genai.types.Content):'
    docstring: "Sends a user content to the gemini model.\n\nThe model will respond immediately upon receiving the content.\nIf you send function responses, all parts in the content should be function\nresponses.\n\nArgs:\n  content: The content to send to the model."
  - signature: 'def send_realtime(self, input: google.adk.models.gemini_llm_connection.RealtimeInput):'
    docstring: "Sends a chunk of audio or a frame of video to the model in realtime.\n\nArgs:\n  input: The input to send to the model."
  - signature: 'def receive(self) -> typing.AsyncGenerator[google.adk.models.llm_response.LlmResponse, None]:'
    docstring: "Receives the model response using the llm server connection.\n\nYields:\n  LlmResponse: The model response."
  - signature: 'def close(self):'
    docstring: Closes the llm server connection.
  inherited_methods:
    BaseLlmConnection:
    - signature: 'def send_history(self, history: list[google.genai.types.Content]):'
      docstring: "Sends the conversation history to the model.\n\nYou call this method right after setting up the model connection.\nThe model will respond if the last content is from user; otherwise, it will\nwait for new user input before responding.\n\nArgs:\n  history: The conversation history to send to the model."
    - signature: 'def send_content(self, content: google.genai.types.Content):'
      docstring: "Sends a user content to the model.\n\nThe model will respond immediately upon receiving the content.\nIf you send function responses, all parts in the content should be function\nresponses.\n\nArgs:\n  content: The content to send to the model."
    - signature: 'def send_realtime(self, blob: google.genai.types.Blob):'
      docstring: "Sends a chunk of audio or a frame of video to the model in realtime.\n\nThe model may not respond immediately upon receiving the blob. It will do\nvoice activity detection and decide when to respond.\n\nArgs:\n  blob: The blob to send to the model."
    - signature: 'def receive(self) -> typing.AsyncGenerator[google.adk.models.llm_response.LlmResponse, None]:'
      docstring: "Receives the model response using the llm server connection.\n\nArgs: None.\n\nYields:\n  LlmResponse: The model response."
    - signature: 'def close(self):'
      docstring: Closes the llm server connection.
- rank: 1079
  id: google.adk.models.gemini_llm_connection.GeminiLlmConnection.__init__
  name: __init__
  file_path: google/adk/models/gemini_llm_connection.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def __init__(self, gemini_session: google.genai.live.AsyncSession, api_backend: google.adk.utils.variant_utils.GoogleLLMVariant):'
- rank: 1080
  id: google.adk.models.gemini_llm_connection.GeminiLlmConnection.close
  name: close
  file_path: google/adk/models/gemini_llm_connection.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: Closes the llm server connection.
  signature: 'def close(self):'
- rank: 1081
  id: google.adk.models.gemini_llm_connection.GeminiLlmConnection.receive
  name: receive
  file_path: google/adk/models/gemini_llm_connection.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Receives the model response using the llm server connection.\n\nYields:\n  LlmResponse: The model response."
  signature: 'def receive(self) -> typing.AsyncGenerator[google.adk.models.llm_response.LlmResponse, None]:'
- rank: 1082
  id: google.adk.models.gemini_llm_connection.GeminiLlmConnection.send_content
  name: send_content
  file_path: google/adk/models/gemini_llm_connection.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Sends a user content to the gemini model.\n\nThe model will respond immediately upon receiving the content.\nIf you send function responses, all parts in the content should be function\nresponses.\n\nArgs:\n  content: The content to send to the model."
  signature: 'def send_content(self, content: google.genai.types.Content):'
- rank: 1083
  id: google.adk.models.gemini_llm_connection.GeminiLlmConnection.send_history
  name: send_history
  file_path: google/adk/models/gemini_llm_connection.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Sends the conversation history to the gemini model.\n\nYou call this method right after setting up the model connection.\nThe model will respond if the last content is from user; otherwise, it will\nwait for new user input before responding.\n\nArgs:\n  history: The conversation history to send to the model."
  signature: 'def send_history(self, history: list[google.genai.types.Content]):'
- rank: 1084
  id: google.adk.models.gemini_llm_connection.GeminiLlmConnection.send_realtime
  name: send_realtime
  file_path: google/adk/models/gemini_llm_connection.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Sends a chunk of audio or a frame of video to the model in realtime.\n\nArgs:\n  input: The input to send to the model."
  signature: 'def send_realtime(self, input: google.adk.models.gemini_llm_connection.RealtimeInput):'
- rank: 1085
  id: google.adk.models.gemma_llm
  name: gemma_llm
  file_path: google/adk/models/gemma_llm.py
  type: MODULE
  group: Orphan
  usage_score: 0
- rank: 1086
  id: google.adk.models.gemma_llm.Gemma
  name: Gemma
  file_path: google/adk/models/gemma_llm.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Integration for Gemma models exposed via the Gemini API.


    Only Gemma 3 models are supported at this time. For agentic use cases,

    use of gemma-3-27b-it and gemma-3-12b-it are strongly recommended.


    For full documentation, see: https://ai.google.dev/gemma/docs/core/


    NOTE: Gemma does **NOT** support system instructions. Any system instructions

    will be replaced with an initial *user* prompt in the LLM request. If system

    instructions change over the course of agent execution, the initial content

    **SHOULD** be replaced. Special care is warranted here.

    See: https://ai.google.dev/gemma/docs/core/prompt-structure#system-instructions


    NOTE: Gemma''s function calling support is limited. It does not have full access to the

    same built-in tools as Gemini. It also does not have special API support for tools and

    functions. Rather, tools must be passed in via a `user` prompt, and extracted from model

    responses based on approximate shape.


    NOTE: Vertex AI API support for Gemma is not currently included. This **ONLY** supports

    usage via the Gemini API.


    [Note: Inherited members from pydantic.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, model: str, speech_config: typing.Optional[google.genai.types.SpeechConfig] = None, retry_options: typing.Optional[google.genai.types.HttpRetryOptions] = None):'
  methods:
  - signature: 'def supported_models(cls) -> list[str]:'
    docstring: 'Provides the list of supported models.


      Returns:

      A list of supported models.'
  - signature: 'def generate_content_async(self, llm_request: google.adk.models.llm_request.LlmRequest, stream: bool) -> typing.AsyncGenerator[google.adk.models.llm_response.LlmResponse, None]:'
    docstring: "Sends a request to the Gemma model.\n\nArgs:\n  llm_request: LlmRequest, the request to send to the Gemini model.\n  stream: bool = False, whether to do streaming call.\n\nYields:\n  LlmResponse: The model response."
  properties:
  - signature: 'model: str'
  inherited_methods:
    Gemini:
    - signature: 'def supported_models(cls) -> list[str]:'
      docstring: "Provides the list of supported models.\n\nReturns:\n  A list of supported models."
    - signature: 'def generate_content_async(self, llm_request: google.adk.models.llm_request.LlmRequest, stream: bool) -> typing.AsyncGenerator[google.adk.models.llm_response.LlmResponse, None]:'
      docstring: "Sends a request to the Gemini model.\n\nArgs:\n  llm_request: LlmRequest, the request to send to the Gemini model.\n  stream: bool = False, whether to do streaming call.\n\nYields:\n  LlmResponse: The model response."
    - signature: 'def api_client(self) -> google.genai.Client:'
      docstring: "Provides the api client.\n\nReturns:\n  The api client."
    - signature: 'def connect(self, llm_request: google.adk.models.llm_request.LlmRequest) -> google.adk.models.base_llm_connection.BaseLlmConnection:'
      docstring: "Connects to the Gemini model and returns an llm connection.\n\nArgs:\n  llm_request: LlmRequest, the request to send to the Gemini model.\n\nYields:\n  BaseLlmConnection, the connection to the Gemini model."
    - signature: 'def convert_wait_to_wait_5_seconds(wait_func):'
    - signature: 'def wait_5_seconds():'
    BaseLlm:
    - signature: 'def supported_models(cls) -> list[str]:'
      docstring: Returns a list of supported models in regex for LlmRegistry.
    - signature: 'def generate_content_async(self, llm_request: google.adk.models.llm_request.LlmRequest, stream: bool) -> typing.AsyncGenerator[google.adk.models.llm_response.LlmResponse, None]:'
      docstring: "Generates content for a single model turn.\n\n    This method handles Server-Sent Events (SSE) streaming for unidirectional\n    content generation. For bidirectional streaming (e.g., Gemini Live API),\n    use the `connect()` method instead.\n\n    Args:\n      llm_request: LlmRequest, the request to send to the LLM.\n      stream: bool = False, whether to enable SSE streaming mode.\n\n    Yields:\n      LlmResponse objects representing the model's response for one turn.\n\n      **Non-streaming mode (stream=False):**\n\n        Yields exactly one LlmResponse containing the complete model output\n        (text, function calls, bytes, etc.). This response has `partial=False`.\n\n      **Streaming mode (stream=True):**\n\n        Yields multiple LlmResponse objects as chunks arrive:\n\n        - Intermediate chunks: `partial=True` (progressive updates)\n        - Final chunk: `partial=False` (aggregated content from entire turn,\n          identical to stream=False output)\n\
        \        - Text consolidation: Consecutive text parts of the same type\n          (thought/non-thought) SHOULD merge without separator, but client\n          code must not rely on this - unconsolidated parts are unusual but also\n          valid\n\n      **Common content in partial chunks:**\n\n        All intermediate chunks have `partial=True` regardless of content type.\n        Common examples include:\n\n        - Text: Streams incrementally as tokens arrive\n        - Function calls: May arrive in separate chunks\n        - Bytes (e.g., images): Typically arrive as single chunk, interleaved\n          with text\n        - Thoughts: Stream incrementally when thinking_config is enabled\n\n      **Examples:**\n\n      1. Simple text streaming::\n\n           LlmResponse(partial=True,  parts=[\"The weather\"])\n           LlmResponse(partial=True,  parts=[\" in Tokyo is\"])\n           LlmResponse(partial=True,  parts=[\" sunny.\"])\n           LlmResponse(partial=False, parts=[\"\
        The weather in Tokyo is sunny.\"])\n\n      2. Text + function call::\n\n           LlmResponse(partial=True,  parts=[Text(\"Let me check...\")])\n           LlmResponse(partial=True,  parts=[FunctionCall(\"get_weather\", ...)])\n           LlmResponse(partial=False, parts=[Text(\"Let me check...\"),\n                                             FunctionCall(\"get_weather\", ...)])\n\n      3. Parallel function calls across chunks::\n\n           LlmResponse(partial=True,  parts=[Text(\"Checking both cities...\")])\n           LlmResponse(partial=True,  parts=[FunctionCall(\"get_weather\", Tokyo)])\n           LlmResponse(partial=True,  parts=[FunctionCall(\"get_weather\", NYC)])\n           LlmResponse(partial=False, parts=[Text(\"Checking both cities...\"),\n                                             FunctionCall(\"get_weather\", Tokyo),\n                                             FunctionCall(\"get_weather\", NYC)])\n\n      4. Text + bytes (image generation with gemini-2.5-flash-image)::\n\
        \n           LlmResponse(partial=True,  parts=[Text(\"Here's an image of a dog.\")])\n           LlmResponse(partial=True,  parts=[Text(\"\n\")])\n           LlmResponse(partial=True,  parts=[Blob(image/png, 1.6MB)])\n           LlmResponse(partial=True,  parts=[Text(\"It carries a bone\")])\n           LlmResponse(partial=True,  parts=[Text(\" and running around.\")])\n           LlmResponse(partial=False, parts=[Text(\"Here's an image of a dog.\n\"),\n                                             Blob(image/png, 1.6MB),\n                                             Text(\"It carries a bone and running around.\")])\n\n         Note: Consecutive text parts before and after blob merge separately.\n\n      5. Text with thinking (gemini-2.5-flash with thinking_config)::\n\n           LlmResponse(partial=True,  parts=[Thought(\"Let me analyze...\")])\n           LlmResponse(partial=True,  parts=[Thought(\"The user wants...\")])\n           LlmResponse(partial=True,  parts=[Text(\"Based\
        \ on my analysis,\")])\n           LlmResponse(partial=True,  parts=[Text(\" the answer is 42.\")])\n           LlmResponse(partial=False, parts=[Thought(\"Let me analyze...The user wants...\"),\n                                             Text(\"Based on my analysis, the answer is 42.\")])\n\n         Note: Consecutive parts of same type merge (thoughts\u2192thought, text\u2192text).\n\n      **Important:** All yielded responses represent one logical model turn.\n      The final response with `partial=False` should be identical to the\n      response that would be received with `stream=False`.\n    "
    - signature: 'def connect(self, llm_request: google.adk.models.llm_request.LlmRequest) -> google.adk.models.base_llm_connection.BaseLlmConnection:'
      docstring: "Creates a live connection to the LLM.\n\nArgs:\n  llm_request: LlmRequest, the request to send to the LLM.\n\nReturns:\n  BaseLlmConnection, the connection to the LLM."
  inherited_properties:
    Gemini:
    - signature: 'model: str'
    - signature: 'speech_config: typing.Optional[google.genai.types.SpeechConfig]'
    - signature: 'retry_options: typing.Optional[google.genai.types.HttpRetryOptions]'
      docstring: "Allow Gemini to retry failed responses.\n\nSample:\n```python\nfrom google.genai import types\n\n# ...\n\nagent = Agent(\n  model=Gemini(\n    retry_options=types.HttpRetryOptions(initial_delay=1, attempts=2),\n  )\n)\n```"
    BaseLlm:
    - signature: 'model_config: pydantic.ConfigDict'
      docstring: The pydantic model config.
    - signature: 'model: str'
      docstring: The name of the LLM, e.g. gemini-2.5-flash or gemini-2.5-pro.
    BaseModel:
    - signature: 'model_config: pydantic.ConfigDict'
  omitted_inherited_members_from:
  - pydantic.BaseModel
- rank: 1087
  id: google.adk.models.gemma_llm.Gemma.generate_content_async
  name: generate_content_async
  file_path: google/adk/models/gemma_llm.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Sends a request to the Gemma model.\n\nArgs:\n  llm_request: LlmRequest, the request to send to the Gemini model.\n  stream: bool = False, whether to do streaming call.\n\nYields:\n  LlmResponse: The model response."
  signature: 'def generate_content_async(self, llm_request: google.adk.models.llm_request.LlmRequest, stream: bool) -> typing.AsyncGenerator[google.adk.models.llm_response.LlmResponse, None]:'
- rank: 1088
  id: google.adk.models.gemma_llm.Gemma.supported_models
  name: supported_models
  file_path: google/adk/models/gemma_llm.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: 'Provides the list of supported models.


    Returns:

    A list of supported models.'
  signature: 'def supported_models(cls) -> list[str]:'
- rank: 1089
  id: google.adk.models.gemma_llm.GemmaFunctionCallModel
  name: GemmaFunctionCallModel
  file_path: google/adk/models/gemma_llm.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Flexible Pydantic model for parsing inline Gemma function call responses.


    [Note: Inherited members from pydantic.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, name: str, parameters: dict[str, typing.Any]):'
  properties:
  - signature: 'name: str'
  - signature: 'parameters: dict[str, typing.Any]'
  inherited_properties:
    BaseModel:
    - signature: 'model_config: pydantic.ConfigDict'
  omitted_inherited_members_from:
  - pydantic.BaseModel
- rank: 1090
  id: google.adk.models.google_llm
  name: google_llm
  file_path: google/adk/models/google_llm.py
  type: MODULE
  group: Orphan
  usage_score: 0
- rank: 1091
  id: google.adk.models.google_llm.Gemini.api_client
  name: api_client
  file_path: google/adk/models/google_llm.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Provides the api client.\n\nReturns:\n  The api client."
  signature: 'def api_client(self) -> google.genai.Client:'
- rank: 1092
  id: google.adk.models.google_llm.Gemini.connect
  name: connect
  file_path: google/adk/models/google_llm.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Connects to the Gemini model and returns an llm connection.\n\nArgs:\n  llm_request: LlmRequest, the request to send to the Gemini model.\n\nYields:\n  BaseLlmConnection, the connection to the Gemini model."
  signature: 'def connect(self, llm_request: google.adk.models.llm_request.LlmRequest) -> google.adk.models.base_llm_connection.BaseLlmConnection:'
- rank: 1093
  id: google.adk.models.google_llm.Gemini.convert_wait_to_wait_5_seconds
  name: convert_wait_to_wait_5_seconds
  file_path: google/adk/models/google_llm.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def convert_wait_to_wait_5_seconds(wait_func):'
- rank: 1094
  id: google.adk.models.google_llm.Gemini.generate_content_async
  name: generate_content_async
  file_path: google/adk/models/google_llm.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Sends a request to the Gemini model.\n\nArgs:\n  llm_request: LlmRequest, the request to send to the Gemini model.\n  stream: bool = False, whether to do streaming call.\n\nYields:\n  LlmResponse: The model response."
  signature: 'def generate_content_async(self, llm_request: google.adk.models.llm_request.LlmRequest, stream: bool) -> typing.AsyncGenerator[google.adk.models.llm_response.LlmResponse, None]:'
- rank: 1095
  id: google.adk.models.google_llm.Gemini.supported_models
  name: supported_models
  file_path: google/adk/models/google_llm.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Provides the list of supported models.\n\nReturns:\n  A list of supported models."
  signature: 'def supported_models(cls) -> list[str]:'
- rank: 1096
  id: google.adk.models.lite_llm
  name: lite_llm
  file_path: google/adk/models/lite_llm.py
  type: MODULE
  group: Orphan
  usage_score: 0
- rank: 1097
  id: google.adk.models.lite_llm.ChatCompletionFileUrlObject
  name: ChatCompletionFileUrlObject
  file_path: google/adk/models/lite_llm.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: '[Note: Inherited members from TypedDict are omitted.]'
  properties:
  - signature: 'file_data: str'
  - signature: 'file_id: str'
  - signature: 'format: str'
  omitted_inherited_members_from:
  - TypedDict
- rank: 1098
  id: google.adk.models.lite_llm.FunctionChunk
  name: FunctionChunk
  file_path: google/adk/models/lite_llm.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: '[Note: Inherited members from pydantic.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, id: typing.Optional[str], name: typing.Optional[str], args: typing.Optional[str], index: typing.Optional[int] = 0):'
  properties:
  - signature: 'id: typing.Optional[str]'
  - signature: 'name: typing.Optional[str]'
  - signature: 'args: typing.Optional[str]'
  - signature: 'index: typing.Optional[int]'
  inherited_properties:
    BaseModel:
    - signature: 'model_config: pydantic.ConfigDict'
  omitted_inherited_members_from:
  - pydantic.BaseModel
- rank: 1099
  id: google.adk.models.lite_llm.LiteLLMClient
  name: LiteLLMClient
  file_path: google/adk/models/lite_llm.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: Provides acompletion method (for better testability).
  methods:
  - signature: 'def acompletion(self, model, messages, tools) -> typing.Union[litellm.ModelResponse, litellm.CustomStreamWrapper]:'
    docstring: "Asynchronously calls acompletion.\n\nArgs:\n  model: The model name.\n  messages: The messages to send to the model.\n  tools: The tools to use for the model.\n  **kwargs: Additional arguments to pass to acompletion.\n\nReturns:\n  The model response as a message."
  - signature: 'def completion(self, model, messages, tools, stream) -> typing.Union[litellm.ModelResponse, litellm.CustomStreamWrapper]:'
    docstring: "Synchronously calls completion. This is used for streaming only.\n\nArgs:\n  model: The model to use.\n  messages: The messages to send.\n  tools: The tools to use for the model.\n  stream: Whether to stream the response.\n  **kwargs: Additional arguments to pass to completion.\n\nReturns:\n  The response from the model."
- rank: 1100
  id: google.adk.models.lite_llm.LiteLLMClient.acompletion
  name: acompletion
  file_path: google/adk/models/lite_llm.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Asynchronously calls acompletion.\n\nArgs:\n  model: The model name.\n  messages: The messages to send to the model.\n  tools: The tools to use for the model.\n  **kwargs: Additional arguments to pass to acompletion.\n\nReturns:\n  The model response as a message."
  signature: 'def acompletion(self, model, messages, tools) -> typing.Union[litellm.ModelResponse, litellm.CustomStreamWrapper]:'
- rank: 1101
  id: google.adk.models.lite_llm.LiteLLMClient.completion
  name: completion
  file_path: google/adk/models/lite_llm.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Synchronously calls completion. This is used for streaming only.\n\nArgs:\n  model: The model to use.\n  messages: The messages to send.\n  tools: The tools to use for the model.\n  stream: Whether to stream the response.\n  **kwargs: Additional arguments to pass to completion.\n\nReturns:\n  The response from the model."
  signature: 'def completion(self, model, messages, tools, stream) -> typing.Union[litellm.ModelResponse, litellm.CustomStreamWrapper]:'
- rank: 1102
  id: google.adk.models.lite_llm.LiteLlm.__init__
  name: __init__
  file_path: google/adk/models/lite_llm.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Initializes the LiteLlm class.\n\nArgs:\n  model: The name of the LiteLlm model.\n  **kwargs: Additional arguments to pass to the litellm completion api."
  signature: 'def __init__(self, model: str):'
- rank: 1103
  id: google.adk.models.lite_llm.LiteLlm.generate_content_async
  name: generate_content_async
  file_path: google/adk/models/lite_llm.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Generates content asynchronously.\n\nArgs:\n  llm_request: LlmRequest, the request to send to the LiteLlm model.\n  stream: bool = False, whether to do streaming call.\n\nYields:\n  LlmResponse: The model response."
  signature: 'def generate_content_async(self, llm_request: google.adk.models.llm_request.LlmRequest, stream: bool) -> typing.AsyncGenerator[google.adk.models.llm_response.LlmResponse, None]:'
- rank: 1104
  id: google.adk.models.lite_llm.LiteLlm.supported_models
  name: supported_models
  file_path: google/adk/models/lite_llm.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Provides the list of supported models.\n\nThis registers common provider prefixes. LiteLlm can handle many more,\nbut these patterns activate the integration for the most common use cases.\nSee https://docs.litellm.ai/docs/providers for a full list.\n\nReturns:\n  A list of supported models."
  signature: 'def supported_models(cls) -> list[str]:'
- rank: 1105
  id: google.adk.models.lite_llm.ReasoningChunk
  name: ReasoningChunk
  file_path: google/adk/models/lite_llm.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: '[Note: Inherited members from pydantic.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, parts: typing.List[google.genai.types.Part]):'
  properties:
  - signature: 'parts: typing.List[google.genai.types.Part]'
  inherited_properties:
    BaseModel:
    - signature: 'model_config: pydantic.ConfigDict'
  omitted_inherited_members_from:
  - pydantic.BaseModel
- rank: 1106
  id: google.adk.models.lite_llm.TextChunk
  name: TextChunk
  file_path: google/adk/models/lite_llm.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: '[Note: Inherited members from pydantic.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, text: str):'
  properties:
  - signature: 'text: str'
  inherited_properties:
    BaseModel:
    - signature: 'model_config: pydantic.ConfigDict'
  omitted_inherited_members_from:
  - pydantic.BaseModel
- rank: 1107
  id: google.adk.models.lite_llm.UsageMetadataChunk
  name: UsageMetadataChunk
  file_path: google/adk/models/lite_llm.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: '[Note: Inherited members from pydantic.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, prompt_tokens: int, completion_tokens: int, total_tokens: int, cached_prompt_tokens: int = 0):'
  properties:
  - signature: 'prompt_tokens: int'
  - signature: 'completion_tokens: int'
  - signature: 'total_tokens: int'
  - signature: 'cached_prompt_tokens: int'
  inherited_properties:
    BaseModel:
    - signature: 'model_config: pydantic.ConfigDict'
  omitted_inherited_members_from:
  - pydantic.BaseModel
- rank: 1108
  id: google.adk.models.llm_request
  name: llm_request
  file_path: google/adk/models/llm_request.py
  type: MODULE
  group: Orphan
  usage_score: 0
- rank: 1109
  id: google.adk.models.llm_request.LlmRequest
  name: LlmRequest
  file_path: google/adk/models/llm_request.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: "LLM request class that allows passing in tools, output schema and system\n\ninstructions to the model.\n\nAttributes:\n  model: The model name.\n  contents: The contents to send to the model.\n  config: Additional config for the generate content request.\n  tools_dict: The tools dictionary.\n  cache_config: Context cache configuration for this request.\n  cache_metadata: Cache metadata from previous requests, used for cache management.\n\n[Note: Inherited members from pydantic.BaseModel are omitted.]"
  constructor_signature: 'def __init__(self, *, model: typing.Optional[str] = None, contents: list[google.genai.types.Content] = list(), config: google.genai.types.GenerateContentConfig = Factory(types.GenerateContentConfig), live_connect_config: google.genai.types.LiveConnectConfig = Factory(types.LiveConnectConfig), tools_dict: dict[str, google.adk.tools.base_tool.BaseTool] = dict(), cache_config: typing.Optional[google.adk.agents.context_cache_config.ContextCacheConfig] = None, cache_metadata: typing.Optional[google.adk.models.cache_metadata.CacheMetadata] = None, cacheable_contents_token_count: typing.Optional[int] = None):'
  methods:
  - signature: 'def append_instructions(self, instructions: typing.Union[list[str], google.genai.types.Content]) -> list[google.genai.types.Content]:'
    docstring: "Appends instructions to the system instruction.\n\nArgs:\n  instructions: The instructions to append. Can be:\n    - list[str]: Strings to append/concatenate to system instruction\n    - types.Content: Content object to append to system instruction\n\nReturns:\n  List of user contents from non-text parts (when instructions is types.Content\n  with non-text parts). Empty list otherwise.\n\nNote: Model API requires system_instruction to be a string. Non-text parts\nin Content are processed with references in system_instruction and returned\nas user contents.\n\nBehavior:\n  - list[str]: concatenates with existing system_instruction using \\n\\n\n  - types.Content: extracts text parts with references to non-text parts,\n    returns non-text parts as user contents"
  - signature: 'def append_tools(self, tools: list[google.adk.tools.base_tool.BaseTool]) -> None:'
    docstring: "Appends tools to the request.\n\nArgs:\n  tools: The tools to append."
  - signature: 'def set_output_schema(self, base_model: type[pydantic.BaseModel]) -> None:'
    docstring: "Sets the output schema for the request.\n\nArgs:\n  base_model: The pydantic base model to set the output schema to."
  properties:
  - signature: 'model_config: pydantic.ConfigDict'
    docstring: The pydantic model config.
  - signature: 'model: typing.Optional[str]'
    docstring: The model name.
  - signature: 'contents: list[google.genai.types.Content]'
    docstring: The contents to send to the model.
  - signature: 'config: google.genai.types.GenerateContentConfig'
  - signature: 'live_connect_config: google.genai.types.LiveConnectConfig'
    docstring: 'Additional config for the generate content request.


      tools in generate_content_config should not be set.'
  - signature: 'tools_dict: dict[str, google.adk.tools.base_tool.BaseTool]'
    docstring: The tools dictionary.
  - signature: 'cache_config: typing.Optional[google.adk.agents.context_cache_config.ContextCacheConfig]'
    docstring: Context cache configuration for this request.
  - signature: 'cache_metadata: typing.Optional[google.adk.models.cache_metadata.CacheMetadata]'
    docstring: Cache metadata from previous requests, used for cache management.
  - signature: 'cacheable_contents_token_count: typing.Optional[int]'
    docstring: Token count from previous request's prompt, used for cache size validation.
  inherited_properties:
    BaseModel:
    - signature: 'model_config: pydantic.ConfigDict'
  omitted_inherited_members_from:
  - pydantic.BaseModel
- rank: 1110
  id: google.adk.models.llm_request.LlmRequest.append_instructions
  name: append_instructions
  file_path: google/adk/models/llm_request.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Appends instructions to the system instruction.\n\nArgs:\n  instructions: The instructions to append. Can be:\n    - list[str]: Strings to append/concatenate to system instruction\n    - types.Content: Content object to append to system instruction\n\nReturns:\n  List of user contents from non-text parts (when instructions is types.Content\n  with non-text parts). Empty list otherwise.\n\nNote: Model API requires system_instruction to be a string. Non-text parts\nin Content are processed with references in system_instruction and returned\nas user contents.\n\nBehavior:\n  - list[str]: concatenates with existing system_instruction using \\n\\n\n  - types.Content: extracts text parts with references to non-text parts,\n    returns non-text parts as user contents"
  signature: 'def append_instructions(self, instructions: typing.Union[list[str], google.genai.types.Content]) -> list[google.genai.types.Content]:'
- rank: 1111
  id: google.adk.models.llm_request.LlmRequest.append_tools
  name: append_tools
  file_path: google/adk/models/llm_request.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Appends tools to the request.\n\nArgs:\n  tools: The tools to append."
  signature: 'def append_tools(self, tools: list[google.adk.tools.base_tool.BaseTool]) -> None:'
- rank: 1112
  id: google.adk.models.llm_request.LlmRequest.set_output_schema
  name: set_output_schema
  file_path: google/adk/models/llm_request.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Sets the output schema for the request.\n\nArgs:\n  base_model: The pydantic base model to set the output schema to."
  signature: 'def set_output_schema(self, base_model: type[pydantic.BaseModel]) -> None:'
- rank: 1113
  id: google.adk.models.llm_response
  name: llm_response
  file_path: google/adk/models/llm_response.py
  type: MODULE
  group: Orphan
  usage_score: 0
- rank: 1114
  id: google.adk.models.llm_response.LlmResponse.create
  name: create
  file_path: google/adk/models/llm_response.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Creates an LlmResponse from a GenerateContentResponse.\n\nArgs:\n  generate_content_response: The GenerateContentResponse to create the\n    LlmResponse from.\n\nReturns:\n  The LlmResponse."
  signature: 'def create(generate_content_response: google.genai.types.GenerateContentResponse) -> google.adk.models.llm_response.LlmResponse:'
- rank: 1115
  id: google.adk.models.registry
  name: registry
  file_path: google/adk/models/registry.py
  type: MODULE
  group: Orphan
  usage_score: 0
  docstring: The registry class for model.
- rank: 1116
  id: google.adk.models.registry.LLMRegistry
  name: LLMRegistry
  file_path: google/adk/models/registry.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: Registry for LLMs.
  aliases:
  - google.adk.models.LLMRegistry
  methods:
  - signature: 'def new_llm(model: str) -> google.adk.models.base_llm.BaseLlm:'
    docstring: "Creates a new LLM instance.\n\nArgs:\n    model: The model name.\n\nReturns:\n    The LLM instance."
  - signature: 'def register(llm_cls: type[google.adk.models.base_llm.BaseLlm]):'
    docstring: "Registers a new LLM class.\n\nArgs:\n    llm_cls: The class that implements the model."
  - signature: 'def resolve(model: str) -> type[google.adk.models.base_llm.BaseLlm]:'
    docstring: "Resolves the model to a BaseLlm subclass.\n\nArgs:\n    model: The model name.\n\nReturns:\n    The BaseLlm subclass.\nRaises:\n    ValueError: If the model is not found."
- rank: 1117
  id: google.adk.models.registry.LLMRegistry.new_llm
  name: new_llm
  file_path: google/adk/models/registry.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Creates a new LLM instance.\n\nArgs:\n    model: The model name.\n\nReturns:\n    The LLM instance."
  signature: 'def new_llm(model: str) -> google.adk.models.base_llm.BaseLlm:'
- rank: 1118
  id: google.adk.models.registry.LLMRegistry.register
  name: register
  file_path: google/adk/models/registry.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Registers a new LLM class.\n\nArgs:\n    llm_cls: The class that implements the model."
  signature: 'def register(llm_cls: type[google.adk.models.base_llm.BaseLlm]):'
- rank: 1119
  id: google.adk.models.registry.LLMRegistry.resolve
  name: resolve
  file_path: google/adk/models/registry.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Resolves the model to a BaseLlm subclass.\n\nArgs:\n    model: The model name.\n\nReturns:\n    The BaseLlm subclass.\nRaises:\n    ValueError: If the model is not found."
  signature: 'def resolve(model: str) -> type[google.adk.models.base_llm.BaseLlm]:'
- rank: 1120
  id: google.adk.planners
  name: planners
  file_path: google/adk/planners/__init__.py
  type: MODULE
  group: Orphan
  usage_score: 0
- rank: 1121
  id: google.adk.planners.base_planner
  name: base_planner
  file_path: google/adk/planners/base_planner.py
  type: MODULE
  group: Orphan
  usage_score: 0
- rank: 1122
  id: google.adk.planners.base_planner.BasePlanner
  name: BasePlanner
  file_path: google/adk/planners/base_planner.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Abstract base class for all planners.


    The planner allows the agent to generate plans for the queries to guide its

    action.


    [Note: Inherited members from ABC are omitted.]'
  methods:
  - signature: 'def build_planning_instruction(self, readonly_context: google.adk.agents.readonly_context.ReadonlyContext, llm_request: google.adk.models.llm_request.LlmRequest) -> typing.Optional[str]:'
    docstring: "Builds the system instruction to be appended to the LLM request for planning.\n\nArgs:\n    readonly_context: The readonly context of the invocation.\n    llm_request: The LLM request. Readonly.\n\nReturns:\n    The planning system instruction, or None if no instruction is needed."
  - signature: 'def process_planning_response(self, callback_context: google.adk.agents.callback_context.CallbackContext, response_parts: typing.List[google.genai.types.Part]) -> typing.Optional[typing.List[google.genai.types.Part]]:'
    docstring: "Processes the LLM response for planning.\n\nArgs:\n    callback_context: The callback context of the invocation.\n    response_parts: The LLM response parts. Readonly.\n\nReturns:\n    The processed response parts, or None if no processing is needed."
  omitted_inherited_members_from:
  - ABC
- rank: 1123
  id: google.adk.planners.base_planner.BasePlanner.build_planning_instruction
  name: build_planning_instruction
  file_path: google/adk/planners/base_planner.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Builds the system instruction to be appended to the LLM request for planning.\n\nArgs:\n    readonly_context: The readonly context of the invocation.\n    llm_request: The LLM request. Readonly.\n\nReturns:\n    The planning system instruction, or None if no instruction is needed."
  signature: 'def build_planning_instruction(self, readonly_context: google.adk.agents.readonly_context.ReadonlyContext, llm_request: google.adk.models.llm_request.LlmRequest) -> typing.Optional[str]:'
- rank: 1124
  id: google.adk.planners.base_planner.BasePlanner.process_planning_response
  name: process_planning_response
  file_path: google/adk/planners/base_planner.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Processes the LLM response for planning.\n\nArgs:\n    callback_context: The callback context of the invocation.\n    response_parts: The LLM response parts. Readonly.\n\nReturns:\n    The processed response parts, or None if no processing is needed."
  signature: 'def process_planning_response(self, callback_context: google.adk.agents.callback_context.CallbackContext, response_parts: typing.List[google.genai.types.Part]) -> typing.Optional[typing.List[google.genai.types.Part]]:'
- rank: 1125
  id: google.adk.planners.built_in_planner
  name: built_in_planner
  file_path: google/adk/planners/built_in_planner.py
  type: MODULE
  group: Orphan
  usage_score: 0
- rank: 1126
  id: google.adk.planners.built_in_planner.BuiltInPlanner.__init__
  name: __init__
  file_path: google/adk/planners/built_in_planner.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Initializes the built-in planner.\n\nArgs:\n  thinking_config: Config for model built-in thinking features. An error\n    will be returned if this field is set for models that don't support\n    thinking."
  signature: 'def __init__(self, *, thinking_config: google.genai.types.ThinkingConfig):'
- rank: 1127
  id: google.adk.planners.built_in_planner.BuiltInPlanner.apply_thinking_config
  name: apply_thinking_config
  file_path: google/adk/planners/built_in_planner.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Applies the thinking config to the LLM request.\n\nArgs:\n  llm_request: The LLM request to apply the thinking config to."
  signature: 'def apply_thinking_config(self, llm_request: google.adk.models.llm_request.LlmRequest) -> None:'
- rank: 1128
  id: google.adk.planners.built_in_planner.BuiltInPlanner.build_planning_instruction
  name: build_planning_instruction
  file_path: google/adk/planners/built_in_planner.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def build_planning_instruction(self, readonly_context: google.adk.agents.readonly_context.ReadonlyContext, llm_request: google.adk.models.llm_request.LlmRequest) -> typing.Optional[str]:'
- rank: 1129
  id: google.adk.planners.built_in_planner.BuiltInPlanner.process_planning_response
  name: process_planning_response
  file_path: google/adk/planners/built_in_planner.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def process_planning_response(self, callback_context: google.adk.agents.callback_context.CallbackContext, response_parts: typing.List[google.genai.types.Part]) -> typing.Optional[typing.List[google.genai.types.Part]]:'
- rank: 1130
  id: google.adk.planners.plan_re_act_planner
  name: plan_re_act_planner
  file_path: google/adk/planners/plan_re_act_planner.py
  type: MODULE
  group: Orphan
  usage_score: 0
- rank: 1131
  id: google.adk.planners.plan_re_act_planner.PlanReActPlanner
  name: PlanReActPlanner
  file_path: google/adk/planners/plan_re_act_planner.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Plan-Re-Act planner that constrains the LLM response to generate a plan before any action/observation.


    Note: this planner does not require the model to support built-in thinking

    features or setting the thinking config.


    [Note: Inherited members from ABC are omitted.]'
  aliases:
  - google.adk.planners.PlanReActPlanner
  methods:
  - signature: 'def build_planning_instruction(self, readonly_context: google.adk.agents.readonly_context.ReadonlyContext, llm_request: google.adk.models.llm_request.LlmRequest) -> str:'
  - signature: 'def process_planning_response(self, callback_context: google.adk.agents.callback_context.CallbackContext, response_parts: typing.List[google.genai.types.Part]) -> typing.Optional[typing.List[google.genai.types.Part]]:'
  inherited_methods:
    BasePlanner:
    - signature: 'def build_planning_instruction(self, readonly_context: google.adk.agents.readonly_context.ReadonlyContext, llm_request: google.adk.models.llm_request.LlmRequest) -> typing.Optional[str]:'
      docstring: "Builds the system instruction to be appended to the LLM request for planning.\n\nArgs:\n    readonly_context: The readonly context of the invocation.\n    llm_request: The LLM request. Readonly.\n\nReturns:\n    The planning system instruction, or None if no instruction is needed."
    - signature: 'def process_planning_response(self, callback_context: google.adk.agents.callback_context.CallbackContext, response_parts: typing.List[google.genai.types.Part]) -> typing.Optional[typing.List[google.genai.types.Part]]:'
      docstring: "Processes the LLM response for planning.\n\nArgs:\n    callback_context: The callback context of the invocation.\n    response_parts: The LLM response parts. Readonly.\n\nReturns:\n    The processed response parts, or None if no processing is needed."
  omitted_inherited_members_from:
  - ABC
- rank: 1132
  id: google.adk.planners.plan_re_act_planner.PlanReActPlanner.build_planning_instruction
  name: build_planning_instruction
  file_path: google/adk/planners/plan_re_act_planner.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def build_planning_instruction(self, readonly_context: google.adk.agents.readonly_context.ReadonlyContext, llm_request: google.adk.models.llm_request.LlmRequest) -> str:'
- rank: 1133
  id: google.adk.planners.plan_re_act_planner.PlanReActPlanner.process_planning_response
  name: process_planning_response
  file_path: google/adk/planners/plan_re_act_planner.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def process_planning_response(self, callback_context: google.adk.agents.callback_context.CallbackContext, response_parts: typing.List[google.genai.types.Part]) -> typing.Optional[typing.List[google.genai.types.Part]]:'
- rank: 1134
  id: google.adk.platform
  name: platform
  file_path: google/adk/platform/__init__.py
  type: MODULE
  group: Orphan
  usage_score: 0
- rank: 1135
  id: google.adk.platform.internal
  name: internal
  file_path: google/adk/platform/internal/__init__.py
  type: MODULE
  group: Orphan
  usage_score: 0
- rank: 1136
  id: google.adk.platform.internal.thread
  name: thread
  file_path: google/adk/platform/internal/thread.py
  type: MODULE
  group: Orphan
  usage_score: 0
  methods:
  - signature: 'def create_thread(target: typing.Callable[Ellipsis, None]):'
    docstring: Creates a thread.
- rank: 1137
  id: google.adk.platform.thread
  name: thread
  file_path: google/adk/platform/thread.py
  type: MODULE
  group: Orphan
  usage_score: 0
  methods:
  - signature: 'def create_thread(target: typing.Callable[Ellipsis, None]):'
    docstring: Creates a thread.
- rank: 1138
  id: google.adk.platform.thread.create_thread
  name: create_thread
  file_path: google/adk/platform/thread.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: Creates a thread.
  signature: 'def create_thread(target: typing.Callable[Ellipsis, None]):'
- rank: 1139
  id: google.adk.plugins
  name: plugins
  file_path: google/adk/plugins/__init__.py
  type: MODULE
  group: Orphan
  usage_score: 0
- rank: 1140
  id: google.adk.plugins.base_plugin
  name: base_plugin
  file_path: google/adk/plugins/base_plugin.py
  type: MODULE
  group: Orphan
  usage_score: 0
- rank: 1141
  id: google.adk.plugins.base_plugin.BasePlugin
  name: BasePlugin
  file_path: google/adk/plugins/base_plugin.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: "Base class for creating plugins.\n\nPlugins provide a structured way to intercept and modify agent, tool, and\nLLM behaviors at critical execution points in a callback manner. While agent\ncallbacks apply to a particular agent, plugins applies globally to all\nagents added in the runner. Plugins are best used for adding custom behaviors\nlike logging, monitoring, caching, or modifying requests and responses at key\nstages.\n\nA plugin can implement one or more methods of callbacks, but should not\nimplement the same method of callback for multiple times.\n\nRelation with [Agent callbacks](https://google.github.io/adk-docs/callbacks/):\n\n**Execution Order**\nSimilar to Agent callbacks, Plugins are executed in the order they are\nregistered. However, Plugin and Agent Callbacks are executed sequentially,\nwith Plugins takes precedence over agent callbacks. When the callback in a\nplugin returns a value, it will short circuit all remaining plugins and\nagent callbacks, causing\
    \ all remaining plugins and agent callbacks\nto be skipped.\n\n**Change Propagation**\nPlugins and agent callbacks can both modify the value of the input parameters,\nincluding agent input, tool input, and LLM request/response, etc. They work in\nthe exactly same way. The modifications will be visible and passed to the next\ncallback in the chain. For example, if a plugin modifies the tool input with\nbefore_tool_callback, the modified tool input will be passed to the\nbefore_tool_callback of the next plugin, and further passed to the agent\ncallbacks if not short circuited.\n\nTo use a plugin, implement the desired callback methods and pass an instance\nof your custom plugin class to the ADK Runner.\n\nExamples:\n    A simple plugin that logs every tool call.\n\n    >>> class ToolLoggerPlugin(BasePlugin):\n    ..   def __init__(self):\n    ..     super().__init__(name=\"tool_logger\")\n    ..\n    ..   async def before_tool_callback(\n    ..       self, *, tool: BaseTool, tool_args:\
    \ dict[str, Any],\n    tool_context:\n    ToolContext\n    ..   ):\n    ..     print(f\"[{self.name}] Calling tool '{tool.name}' with args:\n    {tool_args}\")\n    ..\n    ..   async def after_tool_callback(\n    ..       self, *, tool: BaseTool, tool_args: dict, tool_context:\n    ToolContext, result: dict\n    ..   ):\n    ..     print(f\"[{self.name}] Tool '{tool.name}' finished with result:\n    {result}\")\n    ..\n    >>> # Add the plugin to ADK Runner\n    >>> # runner = Runner(\n    >>> #     ...\n    >>> #     plugins=[ToolLoggerPlugin(), AgentPolicyPlugin()],\n    >>> # )\n\n[Note: Inherited members from ABC are omitted.]"
  constructor_signature: 'def __init__(self, name: str):'
  methods:
  - signature: 'def on_user_message_callback(self, *, invocation_context: google.adk.agents.invocation_context.InvocationContext, user_message: google.genai.types.Content) -> typing.Optional[google.genai.types.Content]:'
    docstring: "Callback executed when a user message is received before an invocation starts.\n\nThis callback helps logging and modifying the user message before the\nrunner starts the invocation.\n\nArgs:\n  invocation_context: The context for the entire invocation.\n  user_message: The message content input by user.\n\nReturns:\n  An optional `types.Content` to be returned to the ADK. Returning a\n  value to replace the user message. Returning `None` to proceed\n  normally."
  - signature: 'def before_run_callback(self, *, invocation_context: google.adk.agents.invocation_context.InvocationContext) -> typing.Optional[google.genai.types.Content]:'
    docstring: "Callback executed before the ADK runner runs.\n\nThis is the first callback to be called in the lifecycle, ideal for global\nsetup or initialization tasks.\n\nArgs:\n  invocation_context: The context for the entire invocation, containing\n    session information, the root agent, etc.\n\nReturns:\n  An optional `Event` to be returned to the ADK. Returning a value to\n  halt execution of the runner and ends the runner with that event. Return\n  `None` to proceed normally."
  - signature: 'def on_event_callback(self, *, invocation_context: google.adk.agents.invocation_context.InvocationContext, event: google.adk.events.event.Event) -> typing.Optional[google.adk.events.event.Event]:'
    docstring: "Callback executed after an event is yielded from runner.\n\nThis is the ideal place to make modification to the event before the event\nis handled by the underlying agent app.\n\nArgs:\n  invocation_context: The context for the entire invocation.\n  event: The event raised by the runner.\n\nReturns:\n  An optional value. A non-`None` return may be used by the framework to\n  modify or replace the response. Returning `None` allows the original\n  response to be used."
  - signature: 'def after_run_callback(self, *, invocation_context: google.adk.agents.invocation_context.InvocationContext) -> None:'
    docstring: "Callback executed after an ADK runner run has completed.\n\nThis is the final callback in the ADK lifecycle, suitable for cleanup, final\nlogging, or reporting tasks.\n\nArgs:\n  invocation_context: The context for the entire invocation.\n\nReturns:\n  None"
  - signature: 'def close(self) -> None:'
    docstring: 'Method executed when the runner is closed.


      This method is used for cleanup tasks such as closing network connections

      or releasing resources.'
  - signature: 'def before_agent_callback(self, *, agent: google.adk.agents.base_agent.BaseAgent, callback_context: google.adk.agents.callback_context.CallbackContext) -> typing.Optional[google.genai.types.Content]:'
    docstring: "Callback executed before an agent's primary logic is invoked.\n\nThis callback can be used for logging, setup, or to short-circuit the\nagent's execution by returning a value.\n\nArgs:\n  agent: The agent that is about to run.\n  callback_context: The context for the agent invocation.\n\nReturns:\n  An optional `types.Content` object. If a value is returned, it will bypass\n  the agent's callbacks and its execution, and return this value directly.\n  Returning `None` allows the agent to proceed normally."
  - signature: 'def after_agent_callback(self, *, agent: google.adk.agents.base_agent.BaseAgent, callback_context: google.adk.agents.callback_context.CallbackContext) -> typing.Optional[google.genai.types.Content]:'
    docstring: "Callback executed after an agent's primary logic has completed.\n\nArgs:\n  agent: The agent that has just run.\n  callback_context: The context for the agent invocation.\n\nReturns:\n  An optional `types.Content` object. The content to return to the user.\n  When the content is present, the provided content will be used as agent\n  response and appended to event history as agent response."
  - signature: 'def before_model_callback(self, *, callback_context: google.adk.agents.callback_context.CallbackContext, llm_request: google.adk.models.llm_request.LlmRequest) -> typing.Optional[google.adk.models.llm_response.LlmResponse]:'
    docstring: "Callback executed before a request is sent to the model.\n\nThis provides an opportunity to inspect, log, or modify the `LlmRequest`\nobject. It can also be used to implement caching by returning a cached\n`LlmResponse`, which would skip the actual model call.\n\nArgs:\n  callback_context: The context for the current agent call.\n  llm_request: The prepared request object to be sent to the model.\n\nReturns:\n  An optional value. The interpretation of a non-`None` trigger an early\n  exit and returns the response immediately. Returning `None` allows the LLM\n  request to proceed normally."
  - signature: 'def after_model_callback(self, *, callback_context: google.adk.agents.callback_context.CallbackContext, llm_response: google.adk.models.llm_response.LlmResponse) -> typing.Optional[google.adk.models.llm_response.LlmResponse]:'
    docstring: "Callback executed after a response is received from the model.\n\nThis is the ideal place to log model responses, collect metrics on token\nusage, or perform post-processing on the raw `LlmResponse`.\n\nArgs:\n  callback_context: The context for the current agent call.\n  llm_response: The response object received from the model.\n\nReturns:\n  An optional value. A non-`None` return may be used by the framework to\n  modify or replace the response. Returning `None` allows the original\n  response to be used."
  - signature: 'def on_model_error_callback(self, *, callback_context: google.adk.agents.callback_context.CallbackContext, llm_request: google.adk.models.llm_request.LlmRequest, error: Exception) -> typing.Optional[google.adk.models.llm_response.LlmResponse]:'
    docstring: "Callback executed when a model call encounters an error.\n\nThis callback provides an opportunity to handle model errors gracefully,\npotentially providing alternative responses or recovery mechanisms.\n\nArgs:\n  callback_context: The context for the current agent call.\n  llm_request: The request that was sent to the model when the error\n    occurred.\n  error: The exception that was raised during model execution.\n\nReturns:\n  An optional LlmResponse. If an LlmResponse is returned, it will be used\n  instead of propagating the error. Returning `None` allows the original\n  error to be raised."
  - signature: 'def before_tool_callback(self, *, tool: google.adk.tools.base_tool.BaseTool, tool_args: dict[str, typing.Any], tool_context: google.adk.tools.tool_context.ToolContext) -> typing.Optional[dict]:'
    docstring: "Callback executed before a tool is called.\n\nThis callback is useful for logging tool usage, input validation, or\nmodifying the arguments before they are passed to the tool.\n\nArgs:\n  tool: The tool instance that is about to be executed.\n  tool_args: The dictionary of arguments to be used for invoking the tool.\n  tool_context: The context specific to the tool execution.\n\nReturns:\n  An optional dictionary. If a dictionary is returned, it will stop the tool\n  execution and return this response immediately. Returning `None` uses the\n  original, unmodified arguments."
  - signature: 'def after_tool_callback(self, *, tool: google.adk.tools.base_tool.BaseTool, tool_args: dict[str, typing.Any], tool_context: google.adk.tools.tool_context.ToolContext, result: dict) -> typing.Optional[dict]:'
    docstring: "Callback executed after a tool has been called.\n\nThis callback allows for inspecting, logging, or modifying the result\nreturned by a tool.\n\nArgs:\n  tool: The tool instance that has just been executed.\n  tool_args: The original arguments that were passed to the tool.\n  tool_context: The context specific to the tool execution.\n  result: The dictionary returned by the tool invocation.\n\nReturns:\n  An optional dictionary. If a dictionary is returned, it will **replace**\n  the original result from the tool. This allows for post-processing or\n  altering tool outputs. Returning `None` uses the original, unmodified\n  result."
  - signature: 'def on_tool_error_callback(self, *, tool: google.adk.tools.base_tool.BaseTool, tool_args: dict[str, typing.Any], tool_context: google.adk.tools.tool_context.ToolContext, error: Exception) -> typing.Optional[dict]:'
    docstring: "Callback executed when a tool call encounters an error.\n\nThis callback provides an opportunity to handle tool errors gracefully,\npotentially providing alternative responses or recovery mechanisms.\n\nArgs:\n  tool: The tool instance that encountered an error.\n  tool_args: The arguments that were passed to the tool.\n  tool_context: The context specific to the tool execution.\n  error: The exception that was raised during tool execution.\n\nReturns:\n  An optional dictionary. If a dictionary is returned, it will be used as\n  the tool response instead of propagating the error. Returning `None`\n  allows the original error to be raised."
  omitted_inherited_members_from:
  - ABC
- rank: 1142
  id: google.adk.plugins.base_plugin.BasePlugin.__init__
  name: __init__
  file_path: google/adk/plugins/base_plugin.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Initializes the plugin.\n\nArgs:\n  name: A unique identifier for this plugin instance."
  signature: 'def __init__(self, name: str):'
- rank: 1143
  id: google.adk.plugins.base_plugin.BasePlugin.after_agent_callback
  name: after_agent_callback
  file_path: google/adk/plugins/base_plugin.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Callback executed after an agent's primary logic has completed.\n\nArgs:\n  agent: The agent that has just run.\n  callback_context: The context for the agent invocation.\n\nReturns:\n  An optional `types.Content` object. The content to return to the user.\n  When the content is present, the provided content will be used as agent\n  response and appended to event history as agent response."
  signature: 'def after_agent_callback(self, *, agent: google.adk.agents.base_agent.BaseAgent, callback_context: google.adk.agents.callback_context.CallbackContext) -> typing.Optional[google.genai.types.Content]:'
- rank: 1144
  id: google.adk.plugins.base_plugin.BasePlugin.after_model_callback
  name: after_model_callback
  file_path: google/adk/plugins/base_plugin.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Callback executed after a response is received from the model.\n\nThis is the ideal place to log model responses, collect metrics on token\nusage, or perform post-processing on the raw `LlmResponse`.\n\nArgs:\n  callback_context: The context for the current agent call.\n  llm_response: The response object received from the model.\n\nReturns:\n  An optional value. A non-`None` return may be used by the framework to\n  modify or replace the response. Returning `None` allows the original\n  response to be used."
  signature: 'def after_model_callback(self, *, callback_context: google.adk.agents.callback_context.CallbackContext, llm_response: google.adk.models.llm_response.LlmResponse) -> typing.Optional[google.adk.models.llm_response.LlmResponse]:'
- rank: 1145
  id: google.adk.plugins.base_plugin.BasePlugin.after_run_callback
  name: after_run_callback
  file_path: google/adk/plugins/base_plugin.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Callback executed after an ADK runner run has completed.\n\nThis is the final callback in the ADK lifecycle, suitable for cleanup, final\nlogging, or reporting tasks.\n\nArgs:\n  invocation_context: The context for the entire invocation.\n\nReturns:\n  None"
  signature: 'def after_run_callback(self, *, invocation_context: google.adk.agents.invocation_context.InvocationContext) -> None:'
- rank: 1146
  id: google.adk.plugins.base_plugin.BasePlugin.after_tool_callback
  name: after_tool_callback
  file_path: google/adk/plugins/base_plugin.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Callback executed after a tool has been called.\n\nThis callback allows for inspecting, logging, or modifying the result\nreturned by a tool.\n\nArgs:\n  tool: The tool instance that has just been executed.\n  tool_args: The original arguments that were passed to the tool.\n  tool_context: The context specific to the tool execution.\n  result: The dictionary returned by the tool invocation.\n\nReturns:\n  An optional dictionary. If a dictionary is returned, it will **replace**\n  the original result from the tool. This allows for post-processing or\n  altering tool outputs. Returning `None` uses the original, unmodified\n  result."
  signature: 'def after_tool_callback(self, *, tool: google.adk.tools.base_tool.BaseTool, tool_args: dict[str, typing.Any], tool_context: google.adk.tools.tool_context.ToolContext, result: dict) -> typing.Optional[dict]:'
- rank: 1147
  id: google.adk.plugins.base_plugin.BasePlugin.before_agent_callback
  name: before_agent_callback
  file_path: google/adk/plugins/base_plugin.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Callback executed before an agent's primary logic is invoked.\n\nThis callback can be used for logging, setup, or to short-circuit the\nagent's execution by returning a value.\n\nArgs:\n  agent: The agent that is about to run.\n  callback_context: The context for the agent invocation.\n\nReturns:\n  An optional `types.Content` object. If a value is returned, it will bypass\n  the agent's callbacks and its execution, and return this value directly.\n  Returning `None` allows the agent to proceed normally."
  signature: 'def before_agent_callback(self, *, agent: google.adk.agents.base_agent.BaseAgent, callback_context: google.adk.agents.callback_context.CallbackContext) -> typing.Optional[google.genai.types.Content]:'
- rank: 1148
  id: google.adk.plugins.base_plugin.BasePlugin.before_model_callback
  name: before_model_callback
  file_path: google/adk/plugins/base_plugin.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Callback executed before a request is sent to the model.\n\nThis provides an opportunity to inspect, log, or modify the `LlmRequest`\nobject. It can also be used to implement caching by returning a cached\n`LlmResponse`, which would skip the actual model call.\n\nArgs:\n  callback_context: The context for the current agent call.\n  llm_request: The prepared request object to be sent to the model.\n\nReturns:\n  An optional value. The interpretation of a non-`None` trigger an early\n  exit and returns the response immediately. Returning `None` allows the LLM\n  request to proceed normally."
  signature: 'def before_model_callback(self, *, callback_context: google.adk.agents.callback_context.CallbackContext, llm_request: google.adk.models.llm_request.LlmRequest) -> typing.Optional[google.adk.models.llm_response.LlmResponse]:'
- rank: 1149
  id: google.adk.plugins.base_plugin.BasePlugin.before_run_callback
  name: before_run_callback
  file_path: google/adk/plugins/base_plugin.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Callback executed before the ADK runner runs.\n\nThis is the first callback to be called in the lifecycle, ideal for global\nsetup or initialization tasks.\n\nArgs:\n  invocation_context: The context for the entire invocation, containing\n    session information, the root agent, etc.\n\nReturns:\n  An optional `Event` to be returned to the ADK. Returning a value to\n  halt execution of the runner and ends the runner with that event. Return\n  `None` to proceed normally."
  signature: 'def before_run_callback(self, *, invocation_context: google.adk.agents.invocation_context.InvocationContext) -> typing.Optional[google.genai.types.Content]:'
- rank: 1150
  id: google.adk.plugins.base_plugin.BasePlugin.before_tool_callback
  name: before_tool_callback
  file_path: google/adk/plugins/base_plugin.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Callback executed before a tool is called.\n\nThis callback is useful for logging tool usage, input validation, or\nmodifying the arguments before they are passed to the tool.\n\nArgs:\n  tool: The tool instance that is about to be executed.\n  tool_args: The dictionary of arguments to be used for invoking the tool.\n  tool_context: The context specific to the tool execution.\n\nReturns:\n  An optional dictionary. If a dictionary is returned, it will stop the tool\n  execution and return this response immediately. Returning `None` uses the\n  original, unmodified arguments."
  signature: 'def before_tool_callback(self, *, tool: google.adk.tools.base_tool.BaseTool, tool_args: dict[str, typing.Any], tool_context: google.adk.tools.tool_context.ToolContext) -> typing.Optional[dict]:'
- rank: 1151
  id: google.adk.plugins.base_plugin.BasePlugin.close
  name: close
  file_path: google/adk/plugins/base_plugin.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: 'Method executed when the runner is closed.


    This method is used for cleanup tasks such as closing network connections

    or releasing resources.'
  signature: 'def close(self) -> None:'
- rank: 1152
  id: google.adk.plugins.base_plugin.BasePlugin.on_event_callback
  name: on_event_callback
  file_path: google/adk/plugins/base_plugin.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Callback executed after an event is yielded from runner.\n\nThis is the ideal place to make modification to the event before the event\nis handled by the underlying agent app.\n\nArgs:\n  invocation_context: The context for the entire invocation.\n  event: The event raised by the runner.\n\nReturns:\n  An optional value. A non-`None` return may be used by the framework to\n  modify or replace the response. Returning `None` allows the original\n  response to be used."
  signature: 'def on_event_callback(self, *, invocation_context: google.adk.agents.invocation_context.InvocationContext, event: google.adk.events.event.Event) -> typing.Optional[google.adk.events.event.Event]:'
- rank: 1153
  id: google.adk.plugins.base_plugin.BasePlugin.on_model_error_callback
  name: on_model_error_callback
  file_path: google/adk/plugins/base_plugin.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Callback executed when a model call encounters an error.\n\nThis callback provides an opportunity to handle model errors gracefully,\npotentially providing alternative responses or recovery mechanisms.\n\nArgs:\n  callback_context: The context for the current agent call.\n  llm_request: The request that was sent to the model when the error\n    occurred.\n  error: The exception that was raised during model execution.\n\nReturns:\n  An optional LlmResponse. If an LlmResponse is returned, it will be used\n  instead of propagating the error. Returning `None` allows the original\n  error to be raised."
  signature: 'def on_model_error_callback(self, *, callback_context: google.adk.agents.callback_context.CallbackContext, llm_request: google.adk.models.llm_request.LlmRequest, error: Exception) -> typing.Optional[google.adk.models.llm_response.LlmResponse]:'
- rank: 1154
  id: google.adk.plugins.base_plugin.BasePlugin.on_tool_error_callback
  name: on_tool_error_callback
  file_path: google/adk/plugins/base_plugin.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Callback executed when a tool call encounters an error.\n\nThis callback provides an opportunity to handle tool errors gracefully,\npotentially providing alternative responses or recovery mechanisms.\n\nArgs:\n  tool: The tool instance that encountered an error.\n  tool_args: The arguments that were passed to the tool.\n  tool_context: The context specific to the tool execution.\n  error: The exception that was raised during tool execution.\n\nReturns:\n  An optional dictionary. If a dictionary is returned, it will be used as\n  the tool response instead of propagating the error. Returning `None`\n  allows the original error to be raised."
  signature: 'def on_tool_error_callback(self, *, tool: google.adk.tools.base_tool.BaseTool, tool_args: dict[str, typing.Any], tool_context: google.adk.tools.tool_context.ToolContext, error: Exception) -> typing.Optional[dict]:'
- rank: 1155
  id: google.adk.plugins.base_plugin.BasePlugin.on_user_message_callback
  name: on_user_message_callback
  file_path: google/adk/plugins/base_plugin.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Callback executed when a user message is received before an invocation starts.\n\nThis callback helps logging and modifying the user message before the\nrunner starts the invocation.\n\nArgs:\n  invocation_context: The context for the entire invocation.\n  user_message: The message content input by user.\n\nReturns:\n  An optional `types.Content` to be returned to the ADK. Returning a\n  value to replace the user message. Returning `None` to proceed\n  normally."
  signature: 'def on_user_message_callback(self, *, invocation_context: google.adk.agents.invocation_context.InvocationContext, user_message: google.genai.types.Content) -> typing.Optional[google.genai.types.Content]:'
- rank: 1156
  id: google.adk.plugins.bigquery_agent_analytics_plugin
  name: bigquery_agent_analytics_plugin
  file_path: google/adk/plugins/bigquery_agent_analytics_plugin.py
  type: MODULE
  group: Orphan
  usage_score: 0
  methods:
  - signature: 'def to_arrow_schema(bq_schema_list):'
    docstring: Converts a list of BigQuery SchemaFields to a PyArrow Schema.
- rank: 1157
  id: google.adk.plugins.bigquery_agent_analytics_plugin.BigQueryAgentAnalyticsPlugin
  name: BigQueryAgentAnalyticsPlugin
  file_path: google/adk/plugins/bigquery_agent_analytics_plugin.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: "A plugin that logs agent analytic events to Google BigQuery.\n\nThis plugin captures key events during an agent's lifecycle\u2014such as user\ninteractions, tool executions, LLM requests/responses, and errors\u2014and\nstreams them to a BigQuery table for analysis and monitoring.\n\nIt uses the BigQuery Write API for efficient, high-throughput streaming\ningestion and is designed to be non-blocking, ensuring that logging\noperations do not impact agent performance. If the destination table does\nnot exist, the plugin will attempt to create it based on a predefined\nschema.\n\n[Note: Inherited members from ABC are omitted.]"
  constructor_signature: 'def __init__(self, project_id: str, dataset_id: str, table_id: str, config: typing.Optional[google.adk.plugins.bigquery_agent_analytics_plugin.BigQueryLoggerConfig]):'
  methods:
  - signature: 'def create_resources():'
  - signature: 'def close(self):'
    docstring: Flushes pending logs and closes client.
  - signature: 'def on_user_message_callback(self, *, invocation_context: google.adk.agents.invocation_context.InvocationContext, user_message: google.genai.types.Content) -> None:'
    docstring: 'Callback for user messages.


      Logs the user message details including:

      1. User content (text)


      The content is formatted as ''User Content: {content}''.

      If the content length exceeds `max_content_length`, it is truncated.'
  - signature: 'def before_run_callback(self, *, invocation_context: google.adk.agents.invocation_context.InvocationContext) -> None:'
    docstring: 'Callback before agent invocation.


      Logs the start of an agent invocation.

      No specific content payload is logged for this event, but standard metadata

      (agent name, session ID, invocation ID, user ID) is captured.'
  - signature: 'def on_event_callback(self, *, invocation_context: google.adk.agents.invocation_context.InvocationContext, event: google.adk.events.event.Event) -> None:'
    docstring: 'Callback for agent events.


      Logs generic agent events including:

      1. Event type (determined from event properties)

      2. Event content (text, function calls, or responses)

      3. Error messages (if any)


      The content is formatted based on the event type.

      If the content length exceeds `max_content_length`, it is truncated.'
  - signature: 'def after_run_callback(self, *, invocation_context: google.adk.agents.invocation_context.InvocationContext) -> None:'
    docstring: 'Callback after agent invocation.


      Logs the completion of an agent invocation.

      No specific content payload is logged for this event, but standard metadata

      (agent name, session ID, invocation ID, user ID) is captured.'
  - signature: 'def before_agent_callback(self, *, agent: google.adk.agents.base_agent.BaseAgent, callback_context: google.adk.agents.callback_context.CallbackContext) -> None:'
    docstring: 'Callback before an agent starts.


      Logs the start of a specific agent execution.

      Content includes:

      1. Agent Name (from callback context)'
  - signature: 'def after_agent_callback(self, *, agent: google.adk.agents.base_agent.BaseAgent, callback_context: google.adk.agents.callback_context.CallbackContext) -> None:'
    docstring: 'Callback after an agent completes.


      Logs the completion of a specific agent execution.

      Content includes:

      1. Agent Name (from callback context)'
  - signature: 'def before_model_callback(self, *, callback_context: google.adk.agents.callback_context.CallbackContext, llm_request: google.adk.models.llm_request.LlmRequest) -> None:'
    docstring: 'Callback before LLM call.


      Logs the LLM request details including:

      1. Model name

      2. Configuration parameters (temperature, top_p, top_k, max_output_tokens)

      3. Available tool names

      4. Prompt content (user/model messages)

      5. System instructions


      The content is formatted as a single string with fields separated by '' | ''.

      If the total length exceeds `max_content_length`, the string is truncated,

      prioritizing the metadata (Model, Params, Tools) over the Prompt and System

      Prompt.'
  - signature: 'def after_model_callback(self, *, callback_context: google.adk.agents.callback_context.CallbackContext, llm_response: google.adk.models.llm_response.LlmResponse) -> None:'
    docstring: 'Callback after LLM call.


      Logs the LLM response details including:

      1. Tool calls (if any)

      2. Text response (if no tool calls)

      3. Token usage statistics (prompt, candidates, total)


      The content is formatted as a single string with fields separated by '' | ''.

      If the content length exceeds `max_content_length`, it is truncated.'
  - signature: 'def before_tool_callback(self, *, tool: google.adk.tools.base_tool.BaseTool, tool_args: dict[str, typing.Any], tool_context: google.adk.tools.tool_context.ToolContext) -> None:'
    docstring: 'Callback before tool call.


      Logs the tool execution start details including:

      1. Tool name

      2. Tool description

      3. Tool arguments


      The content is formatted as ''Tool Name: ..., Description: ..., Arguments:

      ...''.

      If the content length exceeds `max_content_length`, it is truncated.'
  - signature: 'def after_tool_callback(self, *, tool: google.adk.tools.base_tool.BaseTool, tool_args: dict[str, typing.Any], tool_context: google.adk.tools.tool_context.ToolContext, result: dict[str, typing.Any]) -> None:'
    docstring: 'Callback after tool call.


      Logs the tool execution result details including:

      1. Tool name

      2. Tool result


      The content is formatted as ''Tool Name: ..., Result: ...''.

      If the content length exceeds `max_content_length`, it is truncated.'
  - signature: 'def on_model_error_callback(self, *, callback_context: google.adk.agents.callback_context.CallbackContext, llm_request: google.adk.models.llm_request.LlmRequest, error: Exception) -> None:'
    docstring: 'Callback for model errors.


      Logs errors that occur during LLM calls.

      No specific content payload is logged, but the error message is captured

      in the `error_message` field.'
  - signature: 'def on_tool_error_callback(self, *, tool: google.adk.tools.base_tool.BaseTool, tool_args: dict[str, typing.Any], tool_context: google.adk.tools.tool_context.ToolContext, error: Exception) -> None:'
    docstring: 'Callback for tool errors.


      Logs errors that occur during tool execution.

      Content includes:

      1. Tool name

      2. Tool arguments


      The error message is captured in the `error_message` field.

      If the content length exceeds `max_content_length`, it is truncated.'
  inherited_methods:
    BasePlugin:
    - signature: 'def on_user_message_callback(self, *, invocation_context: google.adk.agents.invocation_context.InvocationContext, user_message: google.genai.types.Content) -> typing.Optional[google.genai.types.Content]:'
      docstring: "Callback executed when a user message is received before an invocation starts.\n\nThis callback helps logging and modifying the user message before the\nrunner starts the invocation.\n\nArgs:\n  invocation_context: The context for the entire invocation.\n  user_message: The message content input by user.\n\nReturns:\n  An optional `types.Content` to be returned to the ADK. Returning a\n  value to replace the user message. Returning `None` to proceed\n  normally."
    - signature: 'def before_run_callback(self, *, invocation_context: google.adk.agents.invocation_context.InvocationContext) -> typing.Optional[google.genai.types.Content]:'
      docstring: "Callback executed before the ADK runner runs.\n\nThis is the first callback to be called in the lifecycle, ideal for global\nsetup or initialization tasks.\n\nArgs:\n  invocation_context: The context for the entire invocation, containing\n    session information, the root agent, etc.\n\nReturns:\n  An optional `Event` to be returned to the ADK. Returning a value to\n  halt execution of the runner and ends the runner with that event. Return\n  `None` to proceed normally."
    - signature: 'def on_event_callback(self, *, invocation_context: google.adk.agents.invocation_context.InvocationContext, event: google.adk.events.event.Event) -> typing.Optional[google.adk.events.event.Event]:'
      docstring: "Callback executed after an event is yielded from runner.\n\nThis is the ideal place to make modification to the event before the event\nis handled by the underlying agent app.\n\nArgs:\n  invocation_context: The context for the entire invocation.\n  event: The event raised by the runner.\n\nReturns:\n  An optional value. A non-`None` return may be used by the framework to\n  modify or replace the response. Returning `None` allows the original\n  response to be used."
    - signature: 'def after_run_callback(self, *, invocation_context: google.adk.agents.invocation_context.InvocationContext) -> None:'
      docstring: "Callback executed after an ADK runner run has completed.\n\nThis is the final callback in the ADK lifecycle, suitable for cleanup, final\nlogging, or reporting tasks.\n\nArgs:\n  invocation_context: The context for the entire invocation.\n\nReturns:\n  None"
    - signature: 'def close(self) -> None:'
      docstring: 'Method executed when the runner is closed.


        This method is used for cleanup tasks such as closing network connections

        or releasing resources.'
    - signature: 'def before_agent_callback(self, *, agent: google.adk.agents.base_agent.BaseAgent, callback_context: google.adk.agents.callback_context.CallbackContext) -> typing.Optional[google.genai.types.Content]:'
      docstring: "Callback executed before an agent's primary logic is invoked.\n\nThis callback can be used for logging, setup, or to short-circuit the\nagent's execution by returning a value.\n\nArgs:\n  agent: The agent that is about to run.\n  callback_context: The context for the agent invocation.\n\nReturns:\n  An optional `types.Content` object. If a value is returned, it will bypass\n  the agent's callbacks and its execution, and return this value directly.\n  Returning `None` allows the agent to proceed normally."
    - signature: 'def after_agent_callback(self, *, agent: google.adk.agents.base_agent.BaseAgent, callback_context: google.adk.agents.callback_context.CallbackContext) -> typing.Optional[google.genai.types.Content]:'
      docstring: "Callback executed after an agent's primary logic has completed.\n\nArgs:\n  agent: The agent that has just run.\n  callback_context: The context for the agent invocation.\n\nReturns:\n  An optional `types.Content` object. The content to return to the user.\n  When the content is present, the provided content will be used as agent\n  response and appended to event history as agent response."
    - signature: 'def before_model_callback(self, *, callback_context: google.adk.agents.callback_context.CallbackContext, llm_request: google.adk.models.llm_request.LlmRequest) -> typing.Optional[google.adk.models.llm_response.LlmResponse]:'
      docstring: "Callback executed before a request is sent to the model.\n\nThis provides an opportunity to inspect, log, or modify the `LlmRequest`\nobject. It can also be used to implement caching by returning a cached\n`LlmResponse`, which would skip the actual model call.\n\nArgs:\n  callback_context: The context for the current agent call.\n  llm_request: The prepared request object to be sent to the model.\n\nReturns:\n  An optional value. The interpretation of a non-`None` trigger an early\n  exit and returns the response immediately. Returning `None` allows the LLM\n  request to proceed normally."
    - signature: 'def after_model_callback(self, *, callback_context: google.adk.agents.callback_context.CallbackContext, llm_response: google.adk.models.llm_response.LlmResponse) -> typing.Optional[google.adk.models.llm_response.LlmResponse]:'
      docstring: "Callback executed after a response is received from the model.\n\nThis is the ideal place to log model responses, collect metrics on token\nusage, or perform post-processing on the raw `LlmResponse`.\n\nArgs:\n  callback_context: The context for the current agent call.\n  llm_response: The response object received from the model.\n\nReturns:\n  An optional value. A non-`None` return may be used by the framework to\n  modify or replace the response. Returning `None` allows the original\n  response to be used."
    - signature: 'def on_model_error_callback(self, *, callback_context: google.adk.agents.callback_context.CallbackContext, llm_request: google.adk.models.llm_request.LlmRequest, error: Exception) -> typing.Optional[google.adk.models.llm_response.LlmResponse]:'
      docstring: "Callback executed when a model call encounters an error.\n\nThis callback provides an opportunity to handle model errors gracefully,\npotentially providing alternative responses or recovery mechanisms.\n\nArgs:\n  callback_context: The context for the current agent call.\n  llm_request: The request that was sent to the model when the error\n    occurred.\n  error: The exception that was raised during model execution.\n\nReturns:\n  An optional LlmResponse. If an LlmResponse is returned, it will be used\n  instead of propagating the error. Returning `None` allows the original\n  error to be raised."
    - signature: 'def before_tool_callback(self, *, tool: google.adk.tools.base_tool.BaseTool, tool_args: dict[str, typing.Any], tool_context: google.adk.tools.tool_context.ToolContext) -> typing.Optional[dict]:'
      docstring: "Callback executed before a tool is called.\n\nThis callback is useful for logging tool usage, input validation, or\nmodifying the arguments before they are passed to the tool.\n\nArgs:\n  tool: The tool instance that is about to be executed.\n  tool_args: The dictionary of arguments to be used for invoking the tool.\n  tool_context: The context specific to the tool execution.\n\nReturns:\n  An optional dictionary. If a dictionary is returned, it will stop the tool\n  execution and return this response immediately. Returning `None` uses the\n  original, unmodified arguments."
    - signature: 'def after_tool_callback(self, *, tool: google.adk.tools.base_tool.BaseTool, tool_args: dict[str, typing.Any], tool_context: google.adk.tools.tool_context.ToolContext, result: dict) -> typing.Optional[dict]:'
      docstring: "Callback executed after a tool has been called.\n\nThis callback allows for inspecting, logging, or modifying the result\nreturned by a tool.\n\nArgs:\n  tool: The tool instance that has just been executed.\n  tool_args: The original arguments that were passed to the tool.\n  tool_context: The context specific to the tool execution.\n  result: The dictionary returned by the tool invocation.\n\nReturns:\n  An optional dictionary. If a dictionary is returned, it will **replace**\n  the original result from the tool. This allows for post-processing or\n  altering tool outputs. Returning `None` uses the original, unmodified\n  result."
    - signature: 'def on_tool_error_callback(self, *, tool: google.adk.tools.base_tool.BaseTool, tool_args: dict[str, typing.Any], tool_context: google.adk.tools.tool_context.ToolContext, error: Exception) -> typing.Optional[dict]:'
      docstring: "Callback executed when a tool call encounters an error.\n\nThis callback provides an opportunity to handle tool errors gracefully,\npotentially providing alternative responses or recovery mechanisms.\n\nArgs:\n  tool: The tool instance that encountered an error.\n  tool_args: The arguments that were passed to the tool.\n  tool_context: The context specific to the tool execution.\n  error: The exception that was raised during tool execution.\n\nReturns:\n  An optional dictionary. If a dictionary is returned, it will be used as\n  the tool response instead of propagating the error. Returning `None`\n  allows the original error to be raised."
  omitted_inherited_members_from:
  - ABC
- rank: 1158
  id: google.adk.plugins.bigquery_agent_analytics_plugin.BigQueryAgentAnalyticsPlugin.__init__
  name: __init__
  file_path: google/adk/plugins/bigquery_agent_analytics_plugin.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Initializes the BigQueryAgentAnalyticsPlugin.\n\nArgs:\n  project_id: Google Cloud project ID.\n  dataset_id: BigQuery dataset ID.\n  table_id: BigQuery table ID for agent events.\n  config: Plugin configuration.\n  **kwargs: Additional arguments."
  signature: 'def __init__(self, project_id: str, dataset_id: str, table_id: str, config: typing.Optional[google.adk.plugins.bigquery_agent_analytics_plugin.BigQueryLoggerConfig]):'
- rank: 1159
  id: google.adk.plugins.bigquery_agent_analytics_plugin.BigQueryAgentAnalyticsPlugin.after_agent_callback
  name: after_agent_callback
  file_path: google/adk/plugins/bigquery_agent_analytics_plugin.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: 'Callback after an agent completes.


    Logs the completion of a specific agent execution.

    Content includes:

    1. Agent Name (from callback context)'
  signature: 'def after_agent_callback(self, *, agent: google.adk.agents.base_agent.BaseAgent, callback_context: google.adk.agents.callback_context.CallbackContext) -> None:'
- rank: 1160
  id: google.adk.plugins.bigquery_agent_analytics_plugin.BigQueryAgentAnalyticsPlugin.after_model_callback
  name: after_model_callback
  file_path: google/adk/plugins/bigquery_agent_analytics_plugin.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: 'Callback after LLM call.


    Logs the LLM response details including:

    1. Tool calls (if any)

    2. Text response (if no tool calls)

    3. Token usage statistics (prompt, candidates, total)


    The content is formatted as a single string with fields separated by '' | ''.

    If the content length exceeds `max_content_length`, it is truncated.'
  signature: 'def after_model_callback(self, *, callback_context: google.adk.agents.callback_context.CallbackContext, llm_response: google.adk.models.llm_response.LlmResponse) -> None:'
- rank: 1161
  id: google.adk.plugins.bigquery_agent_analytics_plugin.BigQueryAgentAnalyticsPlugin.after_run_callback
  name: after_run_callback
  file_path: google/adk/plugins/bigquery_agent_analytics_plugin.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: 'Callback after agent invocation.


    Logs the completion of an agent invocation.

    No specific content payload is logged for this event, but standard metadata

    (agent name, session ID, invocation ID, user ID) is captured.'
  signature: 'def after_run_callback(self, *, invocation_context: google.adk.agents.invocation_context.InvocationContext) -> None:'
- rank: 1162
  id: google.adk.plugins.bigquery_agent_analytics_plugin.BigQueryAgentAnalyticsPlugin.after_tool_callback
  name: after_tool_callback
  file_path: google/adk/plugins/bigquery_agent_analytics_plugin.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: 'Callback after tool call.


    Logs the tool execution result details including:

    1. Tool name

    2. Tool result


    The content is formatted as ''Tool Name: ..., Result: ...''.

    If the content length exceeds `max_content_length`, it is truncated.'
  signature: 'def after_tool_callback(self, *, tool: google.adk.tools.base_tool.BaseTool, tool_args: dict[str, typing.Any], tool_context: google.adk.tools.tool_context.ToolContext, result: dict[str, typing.Any]) -> None:'
- rank: 1163
  id: google.adk.plugins.bigquery_agent_analytics_plugin.BigQueryAgentAnalyticsPlugin.before_agent_callback
  name: before_agent_callback
  file_path: google/adk/plugins/bigquery_agent_analytics_plugin.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: 'Callback before an agent starts.


    Logs the start of a specific agent execution.

    Content includes:

    1. Agent Name (from callback context)'
  signature: 'def before_agent_callback(self, *, agent: google.adk.agents.base_agent.BaseAgent, callback_context: google.adk.agents.callback_context.CallbackContext) -> None:'
- rank: 1164
  id: google.adk.plugins.bigquery_agent_analytics_plugin.BigQueryAgentAnalyticsPlugin.before_model_callback
  name: before_model_callback
  file_path: google/adk/plugins/bigquery_agent_analytics_plugin.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: 'Callback before LLM call.


    Logs the LLM request details including:

    1. Model name

    2. Configuration parameters (temperature, top_p, top_k, max_output_tokens)

    3. Available tool names

    4. Prompt content (user/model messages)

    5. System instructions


    The content is formatted as a single string with fields separated by '' | ''.

    If the total length exceeds `max_content_length`, the string is truncated,

    prioritizing the metadata (Model, Params, Tools) over the Prompt and System

    Prompt.'
  signature: 'def before_model_callback(self, *, callback_context: google.adk.agents.callback_context.CallbackContext, llm_request: google.adk.models.llm_request.LlmRequest) -> None:'
- rank: 1165
  id: google.adk.plugins.bigquery_agent_analytics_plugin.BigQueryAgentAnalyticsPlugin.before_run_callback
  name: before_run_callback
  file_path: google/adk/plugins/bigquery_agent_analytics_plugin.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: 'Callback before agent invocation.


    Logs the start of an agent invocation.

    No specific content payload is logged for this event, but standard metadata

    (agent name, session ID, invocation ID, user ID) is captured.'
  signature: 'def before_run_callback(self, *, invocation_context: google.adk.agents.invocation_context.InvocationContext) -> None:'
- rank: 1166
  id: google.adk.plugins.bigquery_agent_analytics_plugin.BigQueryAgentAnalyticsPlugin.before_tool_callback
  name: before_tool_callback
  file_path: google/adk/plugins/bigquery_agent_analytics_plugin.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: 'Callback before tool call.


    Logs the tool execution start details including:

    1. Tool name

    2. Tool description

    3. Tool arguments


    The content is formatted as ''Tool Name: ..., Description: ..., Arguments:

    ...''.

    If the content length exceeds `max_content_length`, it is truncated.'
  signature: 'def before_tool_callback(self, *, tool: google.adk.tools.base_tool.BaseTool, tool_args: dict[str, typing.Any], tool_context: google.adk.tools.tool_context.ToolContext) -> None:'
- rank: 1167
  id: google.adk.plugins.bigquery_agent_analytics_plugin.BigQueryAgentAnalyticsPlugin.close
  name: close
  file_path: google/adk/plugins/bigquery_agent_analytics_plugin.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: Flushes pending logs and closes client.
  signature: 'def close(self):'
- rank: 1168
  id: google.adk.plugins.bigquery_agent_analytics_plugin.BigQueryAgentAnalyticsPlugin.create_resources
  name: create_resources
  file_path: google/adk/plugins/bigquery_agent_analytics_plugin.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def create_resources():'
- rank: 1169
  id: google.adk.plugins.bigquery_agent_analytics_plugin.BigQueryAgentAnalyticsPlugin.on_event_callback
  name: on_event_callback
  file_path: google/adk/plugins/bigquery_agent_analytics_plugin.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: 'Callback for agent events.


    Logs generic agent events including:

    1. Event type (determined from event properties)

    2. Event content (text, function calls, or responses)

    3. Error messages (if any)


    The content is formatted based on the event type.

    If the content length exceeds `max_content_length`, it is truncated.'
  signature: 'def on_event_callback(self, *, invocation_context: google.adk.agents.invocation_context.InvocationContext, event: google.adk.events.event.Event) -> None:'
- rank: 1170
  id: google.adk.plugins.bigquery_agent_analytics_plugin.BigQueryAgentAnalyticsPlugin.on_model_error_callback
  name: on_model_error_callback
  file_path: google/adk/plugins/bigquery_agent_analytics_plugin.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: 'Callback for model errors.


    Logs errors that occur during LLM calls.

    No specific content payload is logged, but the error message is captured

    in the `error_message` field.'
  signature: 'def on_model_error_callback(self, *, callback_context: google.adk.agents.callback_context.CallbackContext, llm_request: google.adk.models.llm_request.LlmRequest, error: Exception) -> None:'
- rank: 1171
  id: google.adk.plugins.bigquery_agent_analytics_plugin.BigQueryAgentAnalyticsPlugin.on_tool_error_callback
  name: on_tool_error_callback
  file_path: google/adk/plugins/bigquery_agent_analytics_plugin.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: 'Callback for tool errors.


    Logs errors that occur during tool execution.

    Content includes:

    1. Tool name

    2. Tool arguments


    The error message is captured in the `error_message` field.

    If the content length exceeds `max_content_length`, it is truncated.'
  signature: 'def on_tool_error_callback(self, *, tool: google.adk.tools.base_tool.BaseTool, tool_args: dict[str, typing.Any], tool_context: google.adk.tools.tool_context.ToolContext, error: Exception) -> None:'
- rank: 1172
  id: google.adk.plugins.bigquery_agent_analytics_plugin.BigQueryAgentAnalyticsPlugin.on_user_message_callback
  name: on_user_message_callback
  file_path: google/adk/plugins/bigquery_agent_analytics_plugin.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: 'Callback for user messages.


    Logs the user message details including:

    1. User content (text)


    The content is formatted as ''User Content: {content}''.

    If the content length exceeds `max_content_length`, it is truncated.'
  signature: 'def on_user_message_callback(self, *, invocation_context: google.adk.agents.invocation_context.InvocationContext, user_message: google.genai.types.Content) -> None:'
- rank: 1173
  id: google.adk.plugins.bigquery_agent_analytics_plugin.BigQueryLoggerConfig
  name: BigQueryLoggerConfig
  file_path: google/adk/plugins/bigquery_agent_analytics_plugin.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: "Configuration for BigQueryAgentAnalyticsPlugin.\n\nAttributes:\n  enabled: Whether logging is enabled.\n  event_allowlist: A list of event types to log. If None, all events are\n    logged except those in event_denylist.\n  event_denylist: A list of event types to skip logging.\n  content_formatter: An optional function to format event content before\n    logging.\n  shutdown_timeout: Seconds to wait for logs to flush during shutdown.\n  client_close_timeout: Seconds to wait for BQ client to close.\n  max_content_length: The maximum length of content parts before truncation."
  constructor_signature: 'def __init__(self, *, enabled: bool = True, event_allowlist: typing.Optional[typing.List[str]] = None, event_denylist: typing.Optional[typing.List[str]] = None, content_formatter: typing.Optional[typing.Callable[[Any], str]] = None, shutdown_timeout: float = 5.0, client_close_timeout: float = 2.0, max_content_length: int = 500):'
  properties:
  - signature: 'enabled: bool'
  - signature: 'event_allowlist: typing.Optional[typing.List[str]]'
  - signature: 'event_denylist: typing.Optional[typing.List[str]]'
  - signature: 'content_formatter: typing.Optional[typing.Callable[[Any], str]]'
  - signature: 'shutdown_timeout: float'
  - signature: 'client_close_timeout: float'
  - signature: 'max_content_length: int'
- rank: 1174
  id: google.adk.plugins.bigquery_agent_analytics_plugin.to_arrow_schema
  name: to_arrow_schema
  file_path: google/adk/plugins/bigquery_agent_analytics_plugin.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: Converts a list of BigQuery SchemaFields to a PyArrow Schema.
  signature: 'def to_arrow_schema(bq_schema_list):'
- rank: 1175
  id: google.adk.plugins.context_filter_plugin
  name: context_filter_plugin
  file_path: google/adk/plugins/context_filter_plugin.py
  type: MODULE
  group: Orphan
  usage_score: 0
- rank: 1176
  id: google.adk.plugins.context_filter_plugin.ContextFilterPlugin
  name: ContextFilterPlugin
  file_path: google/adk/plugins/context_filter_plugin.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'A plugin that filters the LLM context to reduce its size.


    [Note: Inherited members from ABC are omitted.]'
  constructor_signature: 'def __init__(self, num_invocations_to_keep: typing.Optional[int], custom_filter: typing.Optional[typing.Callable[[List[Event]], typing.List[google.adk.events.event.Event]]], name: str):'
  methods:
  - signature: 'def before_model_callback(self, *, callback_context: google.adk.agents.callback_context.CallbackContext, llm_request: google.adk.models.llm_request.LlmRequest) -> typing.Optional[google.adk.models.llm_response.LlmResponse]:'
    docstring: Filters the LLM request's context before it is sent to the model.
  inherited_methods:
    BasePlugin:
    - signature: 'def on_user_message_callback(self, *, invocation_context: google.adk.agents.invocation_context.InvocationContext, user_message: google.genai.types.Content) -> typing.Optional[google.genai.types.Content]:'
      docstring: "Callback executed when a user message is received before an invocation starts.\n\nThis callback helps logging and modifying the user message before the\nrunner starts the invocation.\n\nArgs:\n  invocation_context: The context for the entire invocation.\n  user_message: The message content input by user.\n\nReturns:\n  An optional `types.Content` to be returned to the ADK. Returning a\n  value to replace the user message. Returning `None` to proceed\n  normally."
    - signature: 'def before_run_callback(self, *, invocation_context: google.adk.agents.invocation_context.InvocationContext) -> typing.Optional[google.genai.types.Content]:'
      docstring: "Callback executed before the ADK runner runs.\n\nThis is the first callback to be called in the lifecycle, ideal for global\nsetup or initialization tasks.\n\nArgs:\n  invocation_context: The context for the entire invocation, containing\n    session information, the root agent, etc.\n\nReturns:\n  An optional `Event` to be returned to the ADK. Returning a value to\n  halt execution of the runner and ends the runner with that event. Return\n  `None` to proceed normally."
    - signature: 'def on_event_callback(self, *, invocation_context: google.adk.agents.invocation_context.InvocationContext, event: google.adk.events.event.Event) -> typing.Optional[google.adk.events.event.Event]:'
      docstring: "Callback executed after an event is yielded from runner.\n\nThis is the ideal place to make modification to the event before the event\nis handled by the underlying agent app.\n\nArgs:\n  invocation_context: The context for the entire invocation.\n  event: The event raised by the runner.\n\nReturns:\n  An optional value. A non-`None` return may be used by the framework to\n  modify or replace the response. Returning `None` allows the original\n  response to be used."
    - signature: 'def after_run_callback(self, *, invocation_context: google.adk.agents.invocation_context.InvocationContext) -> None:'
      docstring: "Callback executed after an ADK runner run has completed.\n\nThis is the final callback in the ADK lifecycle, suitable for cleanup, final\nlogging, or reporting tasks.\n\nArgs:\n  invocation_context: The context for the entire invocation.\n\nReturns:\n  None"
    - signature: 'def close(self) -> None:'
      docstring: 'Method executed when the runner is closed.


        This method is used for cleanup tasks such as closing network connections

        or releasing resources.'
    - signature: 'def before_agent_callback(self, *, agent: google.adk.agents.base_agent.BaseAgent, callback_context: google.adk.agents.callback_context.CallbackContext) -> typing.Optional[google.genai.types.Content]:'
      docstring: "Callback executed before an agent's primary logic is invoked.\n\nThis callback can be used for logging, setup, or to short-circuit the\nagent's execution by returning a value.\n\nArgs:\n  agent: The agent that is about to run.\n  callback_context: The context for the agent invocation.\n\nReturns:\n  An optional `types.Content` object. If a value is returned, it will bypass\n  the agent's callbacks and its execution, and return this value directly.\n  Returning `None` allows the agent to proceed normally."
    - signature: 'def after_agent_callback(self, *, agent: google.adk.agents.base_agent.BaseAgent, callback_context: google.adk.agents.callback_context.CallbackContext) -> typing.Optional[google.genai.types.Content]:'
      docstring: "Callback executed after an agent's primary logic has completed.\n\nArgs:\n  agent: The agent that has just run.\n  callback_context: The context for the agent invocation.\n\nReturns:\n  An optional `types.Content` object. The content to return to the user.\n  When the content is present, the provided content will be used as agent\n  response and appended to event history as agent response."
    - signature: 'def before_model_callback(self, *, callback_context: google.adk.agents.callback_context.CallbackContext, llm_request: google.adk.models.llm_request.LlmRequest) -> typing.Optional[google.adk.models.llm_response.LlmResponse]:'
      docstring: "Callback executed before a request is sent to the model.\n\nThis provides an opportunity to inspect, log, or modify the `LlmRequest`\nobject. It can also be used to implement caching by returning a cached\n`LlmResponse`, which would skip the actual model call.\n\nArgs:\n  callback_context: The context for the current agent call.\n  llm_request: The prepared request object to be sent to the model.\n\nReturns:\n  An optional value. The interpretation of a non-`None` trigger an early\n  exit and returns the response immediately. Returning `None` allows the LLM\n  request to proceed normally."
    - signature: 'def after_model_callback(self, *, callback_context: google.adk.agents.callback_context.CallbackContext, llm_response: google.adk.models.llm_response.LlmResponse) -> typing.Optional[google.adk.models.llm_response.LlmResponse]:'
      docstring: "Callback executed after a response is received from the model.\n\nThis is the ideal place to log model responses, collect metrics on token\nusage, or perform post-processing on the raw `LlmResponse`.\n\nArgs:\n  callback_context: The context for the current agent call.\n  llm_response: The response object received from the model.\n\nReturns:\n  An optional value. A non-`None` return may be used by the framework to\n  modify or replace the response. Returning `None` allows the original\n  response to be used."
    - signature: 'def on_model_error_callback(self, *, callback_context: google.adk.agents.callback_context.CallbackContext, llm_request: google.adk.models.llm_request.LlmRequest, error: Exception) -> typing.Optional[google.adk.models.llm_response.LlmResponse]:'
      docstring: "Callback executed when a model call encounters an error.\n\nThis callback provides an opportunity to handle model errors gracefully,\npotentially providing alternative responses or recovery mechanisms.\n\nArgs:\n  callback_context: The context for the current agent call.\n  llm_request: The request that was sent to the model when the error\n    occurred.\n  error: The exception that was raised during model execution.\n\nReturns:\n  An optional LlmResponse. If an LlmResponse is returned, it will be used\n  instead of propagating the error. Returning `None` allows the original\n  error to be raised."
    - signature: 'def before_tool_callback(self, *, tool: google.adk.tools.base_tool.BaseTool, tool_args: dict[str, typing.Any], tool_context: google.adk.tools.tool_context.ToolContext) -> typing.Optional[dict]:'
      docstring: "Callback executed before a tool is called.\n\nThis callback is useful for logging tool usage, input validation, or\nmodifying the arguments before they are passed to the tool.\n\nArgs:\n  tool: The tool instance that is about to be executed.\n  tool_args: The dictionary of arguments to be used for invoking the tool.\n  tool_context: The context specific to the tool execution.\n\nReturns:\n  An optional dictionary. If a dictionary is returned, it will stop the tool\n  execution and return this response immediately. Returning `None` uses the\n  original, unmodified arguments."
    - signature: 'def after_tool_callback(self, *, tool: google.adk.tools.base_tool.BaseTool, tool_args: dict[str, typing.Any], tool_context: google.adk.tools.tool_context.ToolContext, result: dict) -> typing.Optional[dict]:'
      docstring: "Callback executed after a tool has been called.\n\nThis callback allows for inspecting, logging, or modifying the result\nreturned by a tool.\n\nArgs:\n  tool: The tool instance that has just been executed.\n  tool_args: The original arguments that were passed to the tool.\n  tool_context: The context specific to the tool execution.\n  result: The dictionary returned by the tool invocation.\n\nReturns:\n  An optional dictionary. If a dictionary is returned, it will **replace**\n  the original result from the tool. This allows for post-processing or\n  altering tool outputs. Returning `None` uses the original, unmodified\n  result."
    - signature: 'def on_tool_error_callback(self, *, tool: google.adk.tools.base_tool.BaseTool, tool_args: dict[str, typing.Any], tool_context: google.adk.tools.tool_context.ToolContext, error: Exception) -> typing.Optional[dict]:'
      docstring: "Callback executed when a tool call encounters an error.\n\nThis callback provides an opportunity to handle tool errors gracefully,\npotentially providing alternative responses or recovery mechanisms.\n\nArgs:\n  tool: The tool instance that encountered an error.\n  tool_args: The arguments that were passed to the tool.\n  tool_context: The context specific to the tool execution.\n  error: The exception that was raised during tool execution.\n\nReturns:\n  An optional dictionary. If a dictionary is returned, it will be used as\n  the tool response instead of propagating the error. Returning `None`\n  allows the original error to be raised."
  omitted_inherited_members_from:
  - ABC
- rank: 1177
  id: google.adk.plugins.context_filter_plugin.ContextFilterPlugin.__init__
  name: __init__
  file_path: google/adk/plugins/context_filter_plugin.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Initializes the context management plugin.\n\nArgs:\n  num_invocations_to_keep: The number of last invocations to keep. An\n    invocation is defined as one or more consecutive user messages followed\n    by a model response.\n  custom_filter: A function to filter the context.\n  name: The name of the plugin instance."
  signature: 'def __init__(self, num_invocations_to_keep: typing.Optional[int], custom_filter: typing.Optional[typing.Callable[[List[Event]], typing.List[google.adk.events.event.Event]]], name: str):'
- rank: 1178
  id: google.adk.plugins.context_filter_plugin.ContextFilterPlugin.before_model_callback
  name: before_model_callback
  file_path: google/adk/plugins/context_filter_plugin.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: Filters the LLM request's context before it is sent to the model.
  signature: 'def before_model_callback(self, *, callback_context: google.adk.agents.callback_context.CallbackContext, llm_request: google.adk.models.llm_request.LlmRequest) -> typing.Optional[google.adk.models.llm_response.LlmResponse]:'
- rank: 1179
  id: google.adk.plugins.global_instruction_plugin
  name: global_instruction_plugin
  file_path: google/adk/plugins/global_instruction_plugin.py
  type: MODULE
  group: Orphan
  usage_score: 0
- rank: 1180
  id: google.adk.plugins.global_instruction_plugin.GlobalInstructionPlugin
  name: GlobalInstructionPlugin
  file_path: google/adk/plugins/global_instruction_plugin.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Plugin that provides global instructions functionality at the App level.


    This plugin replaces the deprecated global_instruction field on LlmAgent.

    Global instructions are applied to all agents in the application, providing

    a consistent way to set application-wide instructions, identity, or

    personality.


    The plugin operates through the before_model_callback, allowing it to modify

    LLM requests before they are sent to the model.


    [Note: Inherited members from ABC are omitted.]'
  constructor_signature: 'def __init__(self, global_instruction: typing.Union[str, google.adk.agents.llm_agent.InstructionProvider], name: str) -> None:'
  methods:
  - signature: 'def before_model_callback(self, *, callback_context: google.adk.agents.callback_context.CallbackContext, llm_request: google.adk.models.llm_request.LlmRequest) -> typing.Optional[google.adk.models.llm_response.LlmResponse]:'
    docstring: "Apply global instructions to the LLM request.\n\nThis callback is executed before each request is sent to the model,\nallowing the plugin to inject global instructions into the request.\n\nArgs:\n  callback_context: The context for the current agent call.\n  llm_request: The prepared request object to be sent to the model.\n\nReturns:\n  None to allow the LLM request to proceed normally."
  inherited_methods:
    BasePlugin:
    - signature: 'def on_user_message_callback(self, *, invocation_context: google.adk.agents.invocation_context.InvocationContext, user_message: google.genai.types.Content) -> typing.Optional[google.genai.types.Content]:'
      docstring: "Callback executed when a user message is received before an invocation starts.\n\nThis callback helps logging and modifying the user message before the\nrunner starts the invocation.\n\nArgs:\n  invocation_context: The context for the entire invocation.\n  user_message: The message content input by user.\n\nReturns:\n  An optional `types.Content` to be returned to the ADK. Returning a\n  value to replace the user message. Returning `None` to proceed\n  normally."
    - signature: 'def before_run_callback(self, *, invocation_context: google.adk.agents.invocation_context.InvocationContext) -> typing.Optional[google.genai.types.Content]:'
      docstring: "Callback executed before the ADK runner runs.\n\nThis is the first callback to be called in the lifecycle, ideal for global\nsetup or initialization tasks.\n\nArgs:\n  invocation_context: The context for the entire invocation, containing\n    session information, the root agent, etc.\n\nReturns:\n  An optional `Event` to be returned to the ADK. Returning a value to\n  halt execution of the runner and ends the runner with that event. Return\n  `None` to proceed normally."
    - signature: 'def on_event_callback(self, *, invocation_context: google.adk.agents.invocation_context.InvocationContext, event: google.adk.events.event.Event) -> typing.Optional[google.adk.events.event.Event]:'
      docstring: "Callback executed after an event is yielded from runner.\n\nThis is the ideal place to make modification to the event before the event\nis handled by the underlying agent app.\n\nArgs:\n  invocation_context: The context for the entire invocation.\n  event: The event raised by the runner.\n\nReturns:\n  An optional value. A non-`None` return may be used by the framework to\n  modify or replace the response. Returning `None` allows the original\n  response to be used."
    - signature: 'def after_run_callback(self, *, invocation_context: google.adk.agents.invocation_context.InvocationContext) -> None:'
      docstring: "Callback executed after an ADK runner run has completed.\n\nThis is the final callback in the ADK lifecycle, suitable for cleanup, final\nlogging, or reporting tasks.\n\nArgs:\n  invocation_context: The context for the entire invocation.\n\nReturns:\n  None"
    - signature: 'def close(self) -> None:'
      docstring: 'Method executed when the runner is closed.


        This method is used for cleanup tasks such as closing network connections

        or releasing resources.'
    - signature: 'def before_agent_callback(self, *, agent: google.adk.agents.base_agent.BaseAgent, callback_context: google.adk.agents.callback_context.CallbackContext) -> typing.Optional[google.genai.types.Content]:'
      docstring: "Callback executed before an agent's primary logic is invoked.\n\nThis callback can be used for logging, setup, or to short-circuit the\nagent's execution by returning a value.\n\nArgs:\n  agent: The agent that is about to run.\n  callback_context: The context for the agent invocation.\n\nReturns:\n  An optional `types.Content` object. If a value is returned, it will bypass\n  the agent's callbacks and its execution, and return this value directly.\n  Returning `None` allows the agent to proceed normally."
    - signature: 'def after_agent_callback(self, *, agent: google.adk.agents.base_agent.BaseAgent, callback_context: google.adk.agents.callback_context.CallbackContext) -> typing.Optional[google.genai.types.Content]:'
      docstring: "Callback executed after an agent's primary logic has completed.\n\nArgs:\n  agent: The agent that has just run.\n  callback_context: The context for the agent invocation.\n\nReturns:\n  An optional `types.Content` object. The content to return to the user.\n  When the content is present, the provided content will be used as agent\n  response and appended to event history as agent response."
    - signature: 'def before_model_callback(self, *, callback_context: google.adk.agents.callback_context.CallbackContext, llm_request: google.adk.models.llm_request.LlmRequest) -> typing.Optional[google.adk.models.llm_response.LlmResponse]:'
      docstring: "Callback executed before a request is sent to the model.\n\nThis provides an opportunity to inspect, log, or modify the `LlmRequest`\nobject. It can also be used to implement caching by returning a cached\n`LlmResponse`, which would skip the actual model call.\n\nArgs:\n  callback_context: The context for the current agent call.\n  llm_request: The prepared request object to be sent to the model.\n\nReturns:\n  An optional value. The interpretation of a non-`None` trigger an early\n  exit and returns the response immediately. Returning `None` allows the LLM\n  request to proceed normally."
    - signature: 'def after_model_callback(self, *, callback_context: google.adk.agents.callback_context.CallbackContext, llm_response: google.adk.models.llm_response.LlmResponse) -> typing.Optional[google.adk.models.llm_response.LlmResponse]:'
      docstring: "Callback executed after a response is received from the model.\n\nThis is the ideal place to log model responses, collect metrics on token\nusage, or perform post-processing on the raw `LlmResponse`.\n\nArgs:\n  callback_context: The context for the current agent call.\n  llm_response: The response object received from the model.\n\nReturns:\n  An optional value. A non-`None` return may be used by the framework to\n  modify or replace the response. Returning `None` allows the original\n  response to be used."
    - signature: 'def on_model_error_callback(self, *, callback_context: google.adk.agents.callback_context.CallbackContext, llm_request: google.adk.models.llm_request.LlmRequest, error: Exception) -> typing.Optional[google.adk.models.llm_response.LlmResponse]:'
      docstring: "Callback executed when a model call encounters an error.\n\nThis callback provides an opportunity to handle model errors gracefully,\npotentially providing alternative responses or recovery mechanisms.\n\nArgs:\n  callback_context: The context for the current agent call.\n  llm_request: The request that was sent to the model when the error\n    occurred.\n  error: The exception that was raised during model execution.\n\nReturns:\n  An optional LlmResponse. If an LlmResponse is returned, it will be used\n  instead of propagating the error. Returning `None` allows the original\n  error to be raised."
    - signature: 'def before_tool_callback(self, *, tool: google.adk.tools.base_tool.BaseTool, tool_args: dict[str, typing.Any], tool_context: google.adk.tools.tool_context.ToolContext) -> typing.Optional[dict]:'
      docstring: "Callback executed before a tool is called.\n\nThis callback is useful for logging tool usage, input validation, or\nmodifying the arguments before they are passed to the tool.\n\nArgs:\n  tool: The tool instance that is about to be executed.\n  tool_args: The dictionary of arguments to be used for invoking the tool.\n  tool_context: The context specific to the tool execution.\n\nReturns:\n  An optional dictionary. If a dictionary is returned, it will stop the tool\n  execution and return this response immediately. Returning `None` uses the\n  original, unmodified arguments."
    - signature: 'def after_tool_callback(self, *, tool: google.adk.tools.base_tool.BaseTool, tool_args: dict[str, typing.Any], tool_context: google.adk.tools.tool_context.ToolContext, result: dict) -> typing.Optional[dict]:'
      docstring: "Callback executed after a tool has been called.\n\nThis callback allows for inspecting, logging, or modifying the result\nreturned by a tool.\n\nArgs:\n  tool: The tool instance that has just been executed.\n  tool_args: The original arguments that were passed to the tool.\n  tool_context: The context specific to the tool execution.\n  result: The dictionary returned by the tool invocation.\n\nReturns:\n  An optional dictionary. If a dictionary is returned, it will **replace**\n  the original result from the tool. This allows for post-processing or\n  altering tool outputs. Returning `None` uses the original, unmodified\n  result."
    - signature: 'def on_tool_error_callback(self, *, tool: google.adk.tools.base_tool.BaseTool, tool_args: dict[str, typing.Any], tool_context: google.adk.tools.tool_context.ToolContext, error: Exception) -> typing.Optional[dict]:'
      docstring: "Callback executed when a tool call encounters an error.\n\nThis callback provides an opportunity to handle tool errors gracefully,\npotentially providing alternative responses or recovery mechanisms.\n\nArgs:\n  tool: The tool instance that encountered an error.\n  tool_args: The arguments that were passed to the tool.\n  tool_context: The context specific to the tool execution.\n  error: The exception that was raised during tool execution.\n\nReturns:\n  An optional dictionary. If a dictionary is returned, it will be used as\n  the tool response instead of propagating the error. Returning `None`\n  allows the original error to be raised."
  omitted_inherited_members_from:
  - ABC
- rank: 1181
  id: google.adk.plugins.global_instruction_plugin.GlobalInstructionPlugin.__init__
  name: __init__
  file_path: google/adk/plugins/global_instruction_plugin.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Initialize the GlobalInstructionPlugin.\n\nArgs:\n  global_instruction: The instruction to apply globally. Can be a string or\n    an InstructionProvider function that takes ReadonlyContext and returns a\n    string (sync or async).\n  name: The name of the plugin (defaults to \"global_instruction\")."
  signature: 'def __init__(self, global_instruction: typing.Union[str, google.adk.agents.llm_agent.InstructionProvider], name: str) -> None:'
- rank: 1182
  id: google.adk.plugins.global_instruction_plugin.GlobalInstructionPlugin.before_model_callback
  name: before_model_callback
  file_path: google/adk/plugins/global_instruction_plugin.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Apply global instructions to the LLM request.\n\nThis callback is executed before each request is sent to the model,\nallowing the plugin to inject global instructions into the request.\n\nArgs:\n  callback_context: The context for the current agent call.\n  llm_request: The prepared request object to be sent to the model.\n\nReturns:\n  None to allow the LLM request to proceed normally."
  signature: 'def before_model_callback(self, *, callback_context: google.adk.agents.callback_context.CallbackContext, llm_request: google.adk.models.llm_request.LlmRequest) -> typing.Optional[google.adk.models.llm_response.LlmResponse]:'
- rank: 1183
  id: google.adk.plugins.logging_plugin
  name: logging_plugin
  file_path: google/adk/plugins/logging_plugin.py
  type: MODULE
  group: Orphan
  usage_score: 0
- rank: 1184
  id: google.adk.plugins.logging_plugin.LoggingPlugin
  name: LoggingPlugin
  file_path: google/adk/plugins/logging_plugin.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: "A plugin that logs important information at each callback point.\n\nThis plugin helps printing all critical events in the console. It is not a\nreplacement of existing logging in ADK. It rather helps terminal based\ndebugging by showing all logs in the console, and serves as a simple demo for\neveryone to leverage when developing new plugins.\n\nThis plugin helps users track the invocation status by logging:\n- User messages and invocation context\n- Agent execution flow\n- LLM requests and responses\n- Tool calls with arguments and results\n- Events and final responses\n- Errors during model and tool execution\n\nExample:\n    >>> logging_plugin = LoggingPlugin()\n    >>> runner = Runner(\n    ...     agents=[my_agent],\n    ...     # ...\n    ...     plugins=[logging_plugin],\n    ... )\n\n[Note: Inherited members from ABC are omitted.]"
  constructor_signature: 'def __init__(self, name: str):'
  methods:
  - signature: 'def on_user_message_callback(self, *, invocation_context: google.adk.agents.invocation_context.InvocationContext, user_message: google.genai.types.Content) -> typing.Optional[google.genai.types.Content]:'
    docstring: Log user message and invocation start.
  - signature: 'def before_run_callback(self, *, invocation_context: google.adk.agents.invocation_context.InvocationContext) -> typing.Optional[google.genai.types.Content]:'
    docstring: Log invocation start.
  - signature: 'def on_event_callback(self, *, invocation_context: google.adk.agents.invocation_context.InvocationContext, event: google.adk.events.event.Event) -> typing.Optional[google.adk.events.event.Event]:'
    docstring: Log events yielded from the runner.
  - signature: 'def after_run_callback(self, *, invocation_context: google.adk.agents.invocation_context.InvocationContext) -> typing.Optional[None]:'
    docstring: Log invocation completion.
  - signature: 'def before_agent_callback(self, *, agent: google.adk.agents.base_agent.BaseAgent, callback_context: google.adk.agents.callback_context.CallbackContext) -> typing.Optional[google.genai.types.Content]:'
    docstring: Log agent execution start.
  - signature: 'def after_agent_callback(self, *, agent: google.adk.agents.base_agent.BaseAgent, callback_context: google.adk.agents.callback_context.CallbackContext) -> typing.Optional[google.genai.types.Content]:'
    docstring: Log agent execution completion.
  - signature: 'def before_model_callback(self, *, callback_context: google.adk.agents.callback_context.CallbackContext, llm_request: google.adk.models.llm_request.LlmRequest) -> typing.Optional[google.adk.models.llm_response.LlmResponse]:'
    docstring: Log LLM request before sending to model.
  - signature: 'def after_model_callback(self, *, callback_context: google.adk.agents.callback_context.CallbackContext, llm_response: google.adk.models.llm_response.LlmResponse) -> typing.Optional[google.adk.models.llm_response.LlmResponse]:'
    docstring: Log LLM response after receiving from model.
  - signature: 'def before_tool_callback(self, *, tool: google.adk.tools.base_tool.BaseTool, tool_args: dict[str, typing.Any], tool_context: google.adk.tools.tool_context.ToolContext) -> typing.Optional[dict]:'
    docstring: Log tool execution start.
  - signature: 'def after_tool_callback(self, *, tool: google.adk.tools.base_tool.BaseTool, tool_args: dict[str, typing.Any], tool_context: google.adk.tools.tool_context.ToolContext, result: dict) -> typing.Optional[dict]:'
    docstring: Log tool execution completion.
  - signature: 'def on_model_error_callback(self, *, callback_context: google.adk.agents.callback_context.CallbackContext, llm_request: google.adk.models.llm_request.LlmRequest, error: Exception) -> typing.Optional[google.adk.models.llm_response.LlmResponse]:'
    docstring: Log LLM error.
  - signature: 'def on_tool_error_callback(self, *, tool: google.adk.tools.base_tool.BaseTool, tool_args: dict[str, typing.Any], tool_context: google.adk.tools.tool_context.ToolContext, error: Exception) -> typing.Optional[dict]:'
    docstring: Log tool error.
  inherited_methods:
    BasePlugin:
    - signature: 'def on_user_message_callback(self, *, invocation_context: google.adk.agents.invocation_context.InvocationContext, user_message: google.genai.types.Content) -> typing.Optional[google.genai.types.Content]:'
      docstring: "Callback executed when a user message is received before an invocation starts.\n\nThis callback helps logging and modifying the user message before the\nrunner starts the invocation.\n\nArgs:\n  invocation_context: The context for the entire invocation.\n  user_message: The message content input by user.\n\nReturns:\n  An optional `types.Content` to be returned to the ADK. Returning a\n  value to replace the user message. Returning `None` to proceed\n  normally."
    - signature: 'def before_run_callback(self, *, invocation_context: google.adk.agents.invocation_context.InvocationContext) -> typing.Optional[google.genai.types.Content]:'
      docstring: "Callback executed before the ADK runner runs.\n\nThis is the first callback to be called in the lifecycle, ideal for global\nsetup or initialization tasks.\n\nArgs:\n  invocation_context: The context for the entire invocation, containing\n    session information, the root agent, etc.\n\nReturns:\n  An optional `Event` to be returned to the ADK. Returning a value to\n  halt execution of the runner and ends the runner with that event. Return\n  `None` to proceed normally."
    - signature: 'def on_event_callback(self, *, invocation_context: google.adk.agents.invocation_context.InvocationContext, event: google.adk.events.event.Event) -> typing.Optional[google.adk.events.event.Event]:'
      docstring: "Callback executed after an event is yielded from runner.\n\nThis is the ideal place to make modification to the event before the event\nis handled by the underlying agent app.\n\nArgs:\n  invocation_context: The context for the entire invocation.\n  event: The event raised by the runner.\n\nReturns:\n  An optional value. A non-`None` return may be used by the framework to\n  modify or replace the response. Returning `None` allows the original\n  response to be used."
    - signature: 'def after_run_callback(self, *, invocation_context: google.adk.agents.invocation_context.InvocationContext) -> None:'
      docstring: "Callback executed after an ADK runner run has completed.\n\nThis is the final callback in the ADK lifecycle, suitable for cleanup, final\nlogging, or reporting tasks.\n\nArgs:\n  invocation_context: The context for the entire invocation.\n\nReturns:\n  None"
    - signature: 'def close(self) -> None:'
      docstring: 'Method executed when the runner is closed.


        This method is used for cleanup tasks such as closing network connections

        or releasing resources.'
    - signature: 'def before_agent_callback(self, *, agent: google.adk.agents.base_agent.BaseAgent, callback_context: google.adk.agents.callback_context.CallbackContext) -> typing.Optional[google.genai.types.Content]:'
      docstring: "Callback executed before an agent's primary logic is invoked.\n\nThis callback can be used for logging, setup, or to short-circuit the\nagent's execution by returning a value.\n\nArgs:\n  agent: The agent that is about to run.\n  callback_context: The context for the agent invocation.\n\nReturns:\n  An optional `types.Content` object. If a value is returned, it will bypass\n  the agent's callbacks and its execution, and return this value directly.\n  Returning `None` allows the agent to proceed normally."
    - signature: 'def after_agent_callback(self, *, agent: google.adk.agents.base_agent.BaseAgent, callback_context: google.adk.agents.callback_context.CallbackContext) -> typing.Optional[google.genai.types.Content]:'
      docstring: "Callback executed after an agent's primary logic has completed.\n\nArgs:\n  agent: The agent that has just run.\n  callback_context: The context for the agent invocation.\n\nReturns:\n  An optional `types.Content` object. The content to return to the user.\n  When the content is present, the provided content will be used as agent\n  response and appended to event history as agent response."
    - signature: 'def before_model_callback(self, *, callback_context: google.adk.agents.callback_context.CallbackContext, llm_request: google.adk.models.llm_request.LlmRequest) -> typing.Optional[google.adk.models.llm_response.LlmResponse]:'
      docstring: "Callback executed before a request is sent to the model.\n\nThis provides an opportunity to inspect, log, or modify the `LlmRequest`\nobject. It can also be used to implement caching by returning a cached\n`LlmResponse`, which would skip the actual model call.\n\nArgs:\n  callback_context: The context for the current agent call.\n  llm_request: The prepared request object to be sent to the model.\n\nReturns:\n  An optional value. The interpretation of a non-`None` trigger an early\n  exit and returns the response immediately. Returning `None` allows the LLM\n  request to proceed normally."
    - signature: 'def after_model_callback(self, *, callback_context: google.adk.agents.callback_context.CallbackContext, llm_response: google.adk.models.llm_response.LlmResponse) -> typing.Optional[google.adk.models.llm_response.LlmResponse]:'
      docstring: "Callback executed after a response is received from the model.\n\nThis is the ideal place to log model responses, collect metrics on token\nusage, or perform post-processing on the raw `LlmResponse`.\n\nArgs:\n  callback_context: The context for the current agent call.\n  llm_response: The response object received from the model.\n\nReturns:\n  An optional value. A non-`None` return may be used by the framework to\n  modify or replace the response. Returning `None` allows the original\n  response to be used."
    - signature: 'def on_model_error_callback(self, *, callback_context: google.adk.agents.callback_context.CallbackContext, llm_request: google.adk.models.llm_request.LlmRequest, error: Exception) -> typing.Optional[google.adk.models.llm_response.LlmResponse]:'
      docstring: "Callback executed when a model call encounters an error.\n\nThis callback provides an opportunity to handle model errors gracefully,\npotentially providing alternative responses or recovery mechanisms.\n\nArgs:\n  callback_context: The context for the current agent call.\n  llm_request: The request that was sent to the model when the error\n    occurred.\n  error: The exception that was raised during model execution.\n\nReturns:\n  An optional LlmResponse. If an LlmResponse is returned, it will be used\n  instead of propagating the error. Returning `None` allows the original\n  error to be raised."
    - signature: 'def before_tool_callback(self, *, tool: google.adk.tools.base_tool.BaseTool, tool_args: dict[str, typing.Any], tool_context: google.adk.tools.tool_context.ToolContext) -> typing.Optional[dict]:'
      docstring: "Callback executed before a tool is called.\n\nThis callback is useful for logging tool usage, input validation, or\nmodifying the arguments before they are passed to the tool.\n\nArgs:\n  tool: The tool instance that is about to be executed.\n  tool_args: The dictionary of arguments to be used for invoking the tool.\n  tool_context: The context specific to the tool execution.\n\nReturns:\n  An optional dictionary. If a dictionary is returned, it will stop the tool\n  execution and return this response immediately. Returning `None` uses the\n  original, unmodified arguments."
    - signature: 'def after_tool_callback(self, *, tool: google.adk.tools.base_tool.BaseTool, tool_args: dict[str, typing.Any], tool_context: google.adk.tools.tool_context.ToolContext, result: dict) -> typing.Optional[dict]:'
      docstring: "Callback executed after a tool has been called.\n\nThis callback allows for inspecting, logging, or modifying the result\nreturned by a tool.\n\nArgs:\n  tool: The tool instance that has just been executed.\n  tool_args: The original arguments that were passed to the tool.\n  tool_context: The context specific to the tool execution.\n  result: The dictionary returned by the tool invocation.\n\nReturns:\n  An optional dictionary. If a dictionary is returned, it will **replace**\n  the original result from the tool. This allows for post-processing or\n  altering tool outputs. Returning `None` uses the original, unmodified\n  result."
    - signature: 'def on_tool_error_callback(self, *, tool: google.adk.tools.base_tool.BaseTool, tool_args: dict[str, typing.Any], tool_context: google.adk.tools.tool_context.ToolContext, error: Exception) -> typing.Optional[dict]:'
      docstring: "Callback executed when a tool call encounters an error.\n\nThis callback provides an opportunity to handle tool errors gracefully,\npotentially providing alternative responses or recovery mechanisms.\n\nArgs:\n  tool: The tool instance that encountered an error.\n  tool_args: The arguments that were passed to the tool.\n  tool_context: The context specific to the tool execution.\n  error: The exception that was raised during tool execution.\n\nReturns:\n  An optional dictionary. If a dictionary is returned, it will be used as\n  the tool response instead of propagating the error. Returning `None`\n  allows the original error to be raised."
  omitted_inherited_members_from:
  - ABC
- rank: 1185
  id: google.adk.plugins.logging_plugin.LoggingPlugin.__init__
  name: __init__
  file_path: google/adk/plugins/logging_plugin.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Initialize the logging plugin.\n\nArgs:\n  name: The name of the plugin instance."
  signature: 'def __init__(self, name: str):'
- rank: 1186
  id: google.adk.plugins.logging_plugin.LoggingPlugin.after_agent_callback
  name: after_agent_callback
  file_path: google/adk/plugins/logging_plugin.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: Log agent execution completion.
  signature: 'def after_agent_callback(self, *, agent: google.adk.agents.base_agent.BaseAgent, callback_context: google.adk.agents.callback_context.CallbackContext) -> typing.Optional[google.genai.types.Content]:'
- rank: 1187
  id: google.adk.plugins.logging_plugin.LoggingPlugin.after_model_callback
  name: after_model_callback
  file_path: google/adk/plugins/logging_plugin.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: Log LLM response after receiving from model.
  signature: 'def after_model_callback(self, *, callback_context: google.adk.agents.callback_context.CallbackContext, llm_response: google.adk.models.llm_response.LlmResponse) -> typing.Optional[google.adk.models.llm_response.LlmResponse]:'
- rank: 1188
  id: google.adk.plugins.logging_plugin.LoggingPlugin.after_run_callback
  name: after_run_callback
  file_path: google/adk/plugins/logging_plugin.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: Log invocation completion.
  signature: 'def after_run_callback(self, *, invocation_context: google.adk.agents.invocation_context.InvocationContext) -> typing.Optional[None]:'
- rank: 1189
  id: google.adk.plugins.logging_plugin.LoggingPlugin.after_tool_callback
  name: after_tool_callback
  file_path: google/adk/plugins/logging_plugin.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: Log tool execution completion.
  signature: 'def after_tool_callback(self, *, tool: google.adk.tools.base_tool.BaseTool, tool_args: dict[str, typing.Any], tool_context: google.adk.tools.tool_context.ToolContext, result: dict) -> typing.Optional[dict]:'
- rank: 1190
  id: google.adk.plugins.logging_plugin.LoggingPlugin.before_agent_callback
  name: before_agent_callback
  file_path: google/adk/plugins/logging_plugin.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: Log agent execution start.
  signature: 'def before_agent_callback(self, *, agent: google.adk.agents.base_agent.BaseAgent, callback_context: google.adk.agents.callback_context.CallbackContext) -> typing.Optional[google.genai.types.Content]:'
- rank: 1191
  id: google.adk.plugins.logging_plugin.LoggingPlugin.before_model_callback
  name: before_model_callback
  file_path: google/adk/plugins/logging_plugin.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: Log LLM request before sending to model.
  signature: 'def before_model_callback(self, *, callback_context: google.adk.agents.callback_context.CallbackContext, llm_request: google.adk.models.llm_request.LlmRequest) -> typing.Optional[google.adk.models.llm_response.LlmResponse]:'
- rank: 1192
  id: google.adk.plugins.logging_plugin.LoggingPlugin.before_run_callback
  name: before_run_callback
  file_path: google/adk/plugins/logging_plugin.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: Log invocation start.
  signature: 'def before_run_callback(self, *, invocation_context: google.adk.agents.invocation_context.InvocationContext) -> typing.Optional[google.genai.types.Content]:'
- rank: 1193
  id: google.adk.plugins.logging_plugin.LoggingPlugin.before_tool_callback
  name: before_tool_callback
  file_path: google/adk/plugins/logging_plugin.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: Log tool execution start.
  signature: 'def before_tool_callback(self, *, tool: google.adk.tools.base_tool.BaseTool, tool_args: dict[str, typing.Any], tool_context: google.adk.tools.tool_context.ToolContext) -> typing.Optional[dict]:'
- rank: 1194
  id: google.adk.plugins.logging_plugin.LoggingPlugin.on_event_callback
  name: on_event_callback
  file_path: google/adk/plugins/logging_plugin.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: Log events yielded from the runner.
  signature: 'def on_event_callback(self, *, invocation_context: google.adk.agents.invocation_context.InvocationContext, event: google.adk.events.event.Event) -> typing.Optional[google.adk.events.event.Event]:'
- rank: 1195
  id: google.adk.plugins.logging_plugin.LoggingPlugin.on_model_error_callback
  name: on_model_error_callback
  file_path: google/adk/plugins/logging_plugin.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: Log LLM error.
  signature: 'def on_model_error_callback(self, *, callback_context: google.adk.agents.callback_context.CallbackContext, llm_request: google.adk.models.llm_request.LlmRequest, error: Exception) -> typing.Optional[google.adk.models.llm_response.LlmResponse]:'
- rank: 1196
  id: google.adk.plugins.logging_plugin.LoggingPlugin.on_tool_error_callback
  name: on_tool_error_callback
  file_path: google/adk/plugins/logging_plugin.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: Log tool error.
  signature: 'def on_tool_error_callback(self, *, tool: google.adk.tools.base_tool.BaseTool, tool_args: dict[str, typing.Any], tool_context: google.adk.tools.tool_context.ToolContext, error: Exception) -> typing.Optional[dict]:'
- rank: 1197
  id: google.adk.plugins.logging_plugin.LoggingPlugin.on_user_message_callback
  name: on_user_message_callback
  file_path: google/adk/plugins/logging_plugin.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: Log user message and invocation start.
  signature: 'def on_user_message_callback(self, *, invocation_context: google.adk.agents.invocation_context.InvocationContext, user_message: google.genai.types.Content) -> typing.Optional[google.genai.types.Content]:'
- rank: 1198
  id: google.adk.plugins.multimodal_tool_results_plugin
  name: multimodal_tool_results_plugin
  file_path: google/adk/plugins/multimodal_tool_results_plugin.py
  type: MODULE
  group: Orphan
  usage_score: 0
- rank: 1199
  id: google.adk.plugins.multimodal_tool_results_plugin.MultimodalToolResultsPlugin
  name: MultimodalToolResultsPlugin
  file_path: google/adk/plugins/multimodal_tool_results_plugin.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'A plugin that modifies function tool responses to support returning list of parts directly.


    Should be removed in favor of directly supporting FunctionResponsePart when these

    are supported outside of computer use tool.

    For context see: https://github.com/google/adk-python/issues/3064#issuecomment-3463067459


    [Note: Inherited members from ABC are omitted.]'
  constructor_signature: 'def __init__(self, name: str):'
  methods:
  - signature: 'def after_tool_callback(self, *, tool: google.adk.tools.base_tool.BaseTool, tool_args: dict[str, typing.Any], tool_context: google.adk.tools.tool_context.ToolContext, result: dict) -> typing.Optional[dict]:'
    docstring: 'Saves parts returned by the tool in ToolContext.


      Later these are passed to LLM''s context as-is.

      No-op if tool doesn''t return list[google.genai.types.Part] or google.genai.types.Part.'
  - signature: 'def before_model_callback(self, *, callback_context: google.adk.agents.callback_context.CallbackContext, llm_request: google.adk.models.llm_request.LlmRequest) -> typing.Optional[google.adk.models.llm_response.LlmResponse]:'
    docstring: Attach saved list[google.genai.types.Part] returned by the tool to llm_request.
  inherited_methods:
    BasePlugin:
    - signature: 'def on_user_message_callback(self, *, invocation_context: google.adk.agents.invocation_context.InvocationContext, user_message: google.genai.types.Content) -> typing.Optional[google.genai.types.Content]:'
      docstring: "Callback executed when a user message is received before an invocation starts.\n\nThis callback helps logging and modifying the user message before the\nrunner starts the invocation.\n\nArgs:\n  invocation_context: The context for the entire invocation.\n  user_message: The message content input by user.\n\nReturns:\n  An optional `types.Content` to be returned to the ADK. Returning a\n  value to replace the user message. Returning `None` to proceed\n  normally."
    - signature: 'def before_run_callback(self, *, invocation_context: google.adk.agents.invocation_context.InvocationContext) -> typing.Optional[google.genai.types.Content]:'
      docstring: "Callback executed before the ADK runner runs.\n\nThis is the first callback to be called in the lifecycle, ideal for global\nsetup or initialization tasks.\n\nArgs:\n  invocation_context: The context for the entire invocation, containing\n    session information, the root agent, etc.\n\nReturns:\n  An optional `Event` to be returned to the ADK. Returning a value to\n  halt execution of the runner and ends the runner with that event. Return\n  `None` to proceed normally."
    - signature: 'def on_event_callback(self, *, invocation_context: google.adk.agents.invocation_context.InvocationContext, event: google.adk.events.event.Event) -> typing.Optional[google.adk.events.event.Event]:'
      docstring: "Callback executed after an event is yielded from runner.\n\nThis is the ideal place to make modification to the event before the event\nis handled by the underlying agent app.\n\nArgs:\n  invocation_context: The context for the entire invocation.\n  event: The event raised by the runner.\n\nReturns:\n  An optional value. A non-`None` return may be used by the framework to\n  modify or replace the response. Returning `None` allows the original\n  response to be used."
    - signature: 'def after_run_callback(self, *, invocation_context: google.adk.agents.invocation_context.InvocationContext) -> None:'
      docstring: "Callback executed after an ADK runner run has completed.\n\nThis is the final callback in the ADK lifecycle, suitable for cleanup, final\nlogging, or reporting tasks.\n\nArgs:\n  invocation_context: The context for the entire invocation.\n\nReturns:\n  None"
    - signature: 'def close(self) -> None:'
      docstring: 'Method executed when the runner is closed.


        This method is used for cleanup tasks such as closing network connections

        or releasing resources.'
    - signature: 'def before_agent_callback(self, *, agent: google.adk.agents.base_agent.BaseAgent, callback_context: google.adk.agents.callback_context.CallbackContext) -> typing.Optional[google.genai.types.Content]:'
      docstring: "Callback executed before an agent's primary logic is invoked.\n\nThis callback can be used for logging, setup, or to short-circuit the\nagent's execution by returning a value.\n\nArgs:\n  agent: The agent that is about to run.\n  callback_context: The context for the agent invocation.\n\nReturns:\n  An optional `types.Content` object. If a value is returned, it will bypass\n  the agent's callbacks and its execution, and return this value directly.\n  Returning `None` allows the agent to proceed normally."
    - signature: 'def after_agent_callback(self, *, agent: google.adk.agents.base_agent.BaseAgent, callback_context: google.adk.agents.callback_context.CallbackContext) -> typing.Optional[google.genai.types.Content]:'
      docstring: "Callback executed after an agent's primary logic has completed.\n\nArgs:\n  agent: The agent that has just run.\n  callback_context: The context for the agent invocation.\n\nReturns:\n  An optional `types.Content` object. The content to return to the user.\n  When the content is present, the provided content will be used as agent\n  response and appended to event history as agent response."
    - signature: 'def before_model_callback(self, *, callback_context: google.adk.agents.callback_context.CallbackContext, llm_request: google.adk.models.llm_request.LlmRequest) -> typing.Optional[google.adk.models.llm_response.LlmResponse]:'
      docstring: "Callback executed before a request is sent to the model.\n\nThis provides an opportunity to inspect, log, or modify the `LlmRequest`\nobject. It can also be used to implement caching by returning a cached\n`LlmResponse`, which would skip the actual model call.\n\nArgs:\n  callback_context: The context for the current agent call.\n  llm_request: The prepared request object to be sent to the model.\n\nReturns:\n  An optional value. The interpretation of a non-`None` trigger an early\n  exit and returns the response immediately. Returning `None` allows the LLM\n  request to proceed normally."
    - signature: 'def after_model_callback(self, *, callback_context: google.adk.agents.callback_context.CallbackContext, llm_response: google.adk.models.llm_response.LlmResponse) -> typing.Optional[google.adk.models.llm_response.LlmResponse]:'
      docstring: "Callback executed after a response is received from the model.\n\nThis is the ideal place to log model responses, collect metrics on token\nusage, or perform post-processing on the raw `LlmResponse`.\n\nArgs:\n  callback_context: The context for the current agent call.\n  llm_response: The response object received from the model.\n\nReturns:\n  An optional value. A non-`None` return may be used by the framework to\n  modify or replace the response. Returning `None` allows the original\n  response to be used."
    - signature: 'def on_model_error_callback(self, *, callback_context: google.adk.agents.callback_context.CallbackContext, llm_request: google.adk.models.llm_request.LlmRequest, error: Exception) -> typing.Optional[google.adk.models.llm_response.LlmResponse]:'
      docstring: "Callback executed when a model call encounters an error.\n\nThis callback provides an opportunity to handle model errors gracefully,\npotentially providing alternative responses or recovery mechanisms.\n\nArgs:\n  callback_context: The context for the current agent call.\n  llm_request: The request that was sent to the model when the error\n    occurred.\n  error: The exception that was raised during model execution.\n\nReturns:\n  An optional LlmResponse. If an LlmResponse is returned, it will be used\n  instead of propagating the error. Returning `None` allows the original\n  error to be raised."
    - signature: 'def before_tool_callback(self, *, tool: google.adk.tools.base_tool.BaseTool, tool_args: dict[str, typing.Any], tool_context: google.adk.tools.tool_context.ToolContext) -> typing.Optional[dict]:'
      docstring: "Callback executed before a tool is called.\n\nThis callback is useful for logging tool usage, input validation, or\nmodifying the arguments before they are passed to the tool.\n\nArgs:\n  tool: The tool instance that is about to be executed.\n  tool_args: The dictionary of arguments to be used for invoking the tool.\n  tool_context: The context specific to the tool execution.\n\nReturns:\n  An optional dictionary. If a dictionary is returned, it will stop the tool\n  execution and return this response immediately. Returning `None` uses the\n  original, unmodified arguments."
    - signature: 'def after_tool_callback(self, *, tool: google.adk.tools.base_tool.BaseTool, tool_args: dict[str, typing.Any], tool_context: google.adk.tools.tool_context.ToolContext, result: dict) -> typing.Optional[dict]:'
      docstring: "Callback executed after a tool has been called.\n\nThis callback allows for inspecting, logging, or modifying the result\nreturned by a tool.\n\nArgs:\n  tool: The tool instance that has just been executed.\n  tool_args: The original arguments that were passed to the tool.\n  tool_context: The context specific to the tool execution.\n  result: The dictionary returned by the tool invocation.\n\nReturns:\n  An optional dictionary. If a dictionary is returned, it will **replace**\n  the original result from the tool. This allows for post-processing or\n  altering tool outputs. Returning `None` uses the original, unmodified\n  result."
    - signature: 'def on_tool_error_callback(self, *, tool: google.adk.tools.base_tool.BaseTool, tool_args: dict[str, typing.Any], tool_context: google.adk.tools.tool_context.ToolContext, error: Exception) -> typing.Optional[dict]:'
      docstring: "Callback executed when a tool call encounters an error.\n\nThis callback provides an opportunity to handle tool errors gracefully,\npotentially providing alternative responses or recovery mechanisms.\n\nArgs:\n  tool: The tool instance that encountered an error.\n  tool_args: The arguments that were passed to the tool.\n  tool_context: The context specific to the tool execution.\n  error: The exception that was raised during tool execution.\n\nReturns:\n  An optional dictionary. If a dictionary is returned, it will be used as\n  the tool response instead of propagating the error. Returning `None`\n  allows the original error to be raised."
  omitted_inherited_members_from:
  - ABC
- rank: 1200
  id: google.adk.plugins.multimodal_tool_results_plugin.MultimodalToolResultsPlugin.__init__
  name: __init__
  file_path: google/adk/plugins/multimodal_tool_results_plugin.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Initialize the multimodal tool results plugin.\n\nArgs:\n  name: The name of the plugin instance."
  signature: 'def __init__(self, name: str):'
- rank: 1201
  id: google.adk.plugins.multimodal_tool_results_plugin.MultimodalToolResultsPlugin.after_tool_callback
  name: after_tool_callback
  file_path: google/adk/plugins/multimodal_tool_results_plugin.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: 'Saves parts returned by the tool in ToolContext.


    Later these are passed to LLM''s context as-is.

    No-op if tool doesn''t return list[google.genai.types.Part] or google.genai.types.Part.'
  signature: 'def after_tool_callback(self, *, tool: google.adk.tools.base_tool.BaseTool, tool_args: dict[str, typing.Any], tool_context: google.adk.tools.tool_context.ToolContext, result: dict) -> typing.Optional[dict]:'
- rank: 1202
  id: google.adk.plugins.multimodal_tool_results_plugin.MultimodalToolResultsPlugin.before_model_callback
  name: before_model_callback
  file_path: google/adk/plugins/multimodal_tool_results_plugin.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: Attach saved list[google.genai.types.Part] returned by the tool to llm_request.
  signature: 'def before_model_callback(self, *, callback_context: google.adk.agents.callback_context.CallbackContext, llm_request: google.adk.models.llm_request.LlmRequest) -> typing.Optional[google.adk.models.llm_response.LlmResponse]:'
- rank: 1203
  id: google.adk.plugins.plugin_manager
  name: plugin_manager
  file_path: google/adk/plugins/plugin_manager.py
  type: MODULE
  group: Orphan
  usage_score: 0
- rank: 1204
  id: google.adk.plugins.plugin_manager.PluginManager
  name: PluginManager
  file_path: google/adk/plugins/plugin_manager.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Manages the registration and execution of plugins.


    The PluginManager is an internal class that orchestrates the invocation of

    plugin callbacks at key points in the SDK''s execution lifecycle. It maintains

    a list of registered plugins and ensures they are called in the order they

    were registered.


    The core execution logic implements an "early exit" strategy: if any plugin

    callback returns a non-`None` value, the execution of subsequent plugins for

    that specific event is halted, and the returned value is propagated up the

    call stack. This allows plugins to short-circuit operations like agent runs,

    tool calls, or model requests.'
  constructor_signature: 'def __init__(self, plugins: typing.Optional[typing.List[google.adk.plugins.base_plugin.BasePlugin]], close_timeout: float):'
  methods:
  - signature: 'def register_plugin(self, plugin: google.adk.plugins.base_plugin.BasePlugin) -> None:'
    docstring: "Registers a new plugin.\n\nArgs:\n  plugin: The plugin instance to register.\n\nRaises:\n  ValueError: If a plugin with the same name is already registered."
  - signature: 'def get_plugin(self, plugin_name: str) -> typing.Optional[google.adk.plugins.base_plugin.BasePlugin]:'
    docstring: "Retrieves a registered plugin by its name.\n\nArgs:\n  plugin_name: The name of the plugin to retrieve.\n\nReturns:\n  The plugin instance if found; otherwise, `None`."
  - signature: 'def run_on_user_message_callback(self, *, user_message: google.genai.types.Content, invocation_context: google.adk.agents.invocation_context.InvocationContext) -> typing.Optional[google.genai.types.Content]:'
    docstring: Runs the `on_user_message_callback` for all plugins.
  - signature: 'def run_before_run_callback(self, *, invocation_context: google.adk.agents.invocation_context.InvocationContext) -> typing.Optional[google.genai.types.Content]:'
    docstring: Runs the `before_run_callback` for all plugins.
  - signature: 'def run_after_run_callback(self, *, invocation_context: google.adk.agents.invocation_context.InvocationContext) -> typing.Optional[None]:'
    docstring: Runs the `after_run_callback` for all plugins.
  - signature: 'def run_on_event_callback(self, *, invocation_context: google.adk.agents.invocation_context.InvocationContext, event: google.adk.events.event.Event) -> typing.Optional[google.adk.events.event.Event]:'
    docstring: Runs the `on_event_callback` for all plugins.
  - signature: 'def run_before_agent_callback(self, *, agent: google.adk.agents.base_agent.BaseAgent, callback_context: google.adk.agents.callback_context.CallbackContext) -> typing.Optional[google.genai.types.Content]:'
    docstring: Runs the `before_agent_callback` for all plugins.
  - signature: 'def run_after_agent_callback(self, *, agent: google.adk.agents.base_agent.BaseAgent, callback_context: google.adk.agents.callback_context.CallbackContext) -> typing.Optional[google.genai.types.Content]:'
    docstring: Runs the `after_agent_callback` for all plugins.
  - signature: 'def run_before_tool_callback(self, *, tool: google.adk.tools.base_tool.BaseTool, tool_args: dict[str, typing.Any], tool_context: google.adk.tools.tool_context.ToolContext) -> typing.Optional[dict]:'
    docstring: Runs the `before_tool_callback` for all plugins.
  - signature: 'def run_after_tool_callback(self, *, tool: google.adk.tools.base_tool.BaseTool, tool_args: dict[str, typing.Any], tool_context: google.adk.tools.tool_context.ToolContext, result: dict) -> typing.Optional[dict]:'
    docstring: Runs the `after_tool_callback` for all plugins.
  - signature: 'def run_on_model_error_callback(self, *, callback_context: google.adk.agents.callback_context.CallbackContext, llm_request: google.adk.models.llm_request.LlmRequest, error: Exception) -> typing.Optional[google.adk.models.llm_response.LlmResponse]:'
    docstring: Runs the `on_model_error_callback` for all plugins.
  - signature: 'def run_before_model_callback(self, *, callback_context: google.adk.agents.callback_context.CallbackContext, llm_request: google.adk.models.llm_request.LlmRequest) -> typing.Optional[google.adk.models.llm_response.LlmResponse]:'
    docstring: Runs the `before_model_callback` for all plugins.
  - signature: 'def run_after_model_callback(self, *, callback_context: google.adk.agents.callback_context.CallbackContext, llm_response: google.adk.models.llm_response.LlmResponse) -> typing.Optional[google.adk.models.llm_response.LlmResponse]:'
    docstring: Runs the `after_model_callback` for all plugins.
  - signature: 'def run_on_tool_error_callback(self, *, tool: google.adk.tools.base_tool.BaseTool, tool_args: dict[str, typing.Any], tool_context: google.adk.tools.tool_context.ToolContext, error: Exception) -> typing.Optional[dict]:'
    docstring: Runs the `on_tool_error_callback` for all plugins.
  - signature: 'def close(self) -> None:'
    docstring: "Calls the close method on all registered plugins concurrently.\n\nRaises:\n  RuntimeError: If one or more plugins failed to close, containing\n    details of all failures."
- rank: 1205
  id: google.adk.plugins.plugin_manager.PluginManager.__init__
  name: __init__
  file_path: google/adk/plugins/plugin_manager.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Initializes the plugin service.\n\nArgs:\n  plugins: An optional list of plugins to register upon initialization.\n  close_timeout: The timeout in seconds for each plugin's close method."
  signature: 'def __init__(self, plugins: typing.Optional[typing.List[google.adk.plugins.base_plugin.BasePlugin]], close_timeout: float):'
- rank: 1206
  id: google.adk.plugins.plugin_manager.PluginManager.close
  name: close
  file_path: google/adk/plugins/plugin_manager.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Calls the close method on all registered plugins concurrently.\n\nRaises:\n  RuntimeError: If one or more plugins failed to close, containing\n    details of all failures."
  signature: 'def close(self) -> None:'
- rank: 1207
  id: google.adk.plugins.plugin_manager.PluginManager.get_plugin
  name: get_plugin
  file_path: google/adk/plugins/plugin_manager.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Retrieves a registered plugin by its name.\n\nArgs:\n  plugin_name: The name of the plugin to retrieve.\n\nReturns:\n  The plugin instance if found; otherwise, `None`."
  signature: 'def get_plugin(self, plugin_name: str) -> typing.Optional[google.adk.plugins.base_plugin.BasePlugin]:'
- rank: 1208
  id: google.adk.plugins.plugin_manager.PluginManager.register_plugin
  name: register_plugin
  file_path: google/adk/plugins/plugin_manager.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Registers a new plugin.\n\nArgs:\n  plugin: The plugin instance to register.\n\nRaises:\n  ValueError: If a plugin with the same name is already registered."
  signature: 'def register_plugin(self, plugin: google.adk.plugins.base_plugin.BasePlugin) -> None:'
- rank: 1209
  id: google.adk.plugins.plugin_manager.PluginManager.run_after_agent_callback
  name: run_after_agent_callback
  file_path: google/adk/plugins/plugin_manager.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: Runs the `after_agent_callback` for all plugins.
  signature: 'def run_after_agent_callback(self, *, agent: google.adk.agents.base_agent.BaseAgent, callback_context: google.adk.agents.callback_context.CallbackContext) -> typing.Optional[google.genai.types.Content]:'
- rank: 1210
  id: google.adk.plugins.plugin_manager.PluginManager.run_after_model_callback
  name: run_after_model_callback
  file_path: google/adk/plugins/plugin_manager.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: Runs the `after_model_callback` for all plugins.
  signature: 'def run_after_model_callback(self, *, callback_context: google.adk.agents.callback_context.CallbackContext, llm_response: google.adk.models.llm_response.LlmResponse) -> typing.Optional[google.adk.models.llm_response.LlmResponse]:'
- rank: 1211
  id: google.adk.plugins.plugin_manager.PluginManager.run_after_run_callback
  name: run_after_run_callback
  file_path: google/adk/plugins/plugin_manager.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: Runs the `after_run_callback` for all plugins.
  signature: 'def run_after_run_callback(self, *, invocation_context: google.adk.agents.invocation_context.InvocationContext) -> typing.Optional[None]:'
- rank: 1212
  id: google.adk.plugins.plugin_manager.PluginManager.run_after_tool_callback
  name: run_after_tool_callback
  file_path: google/adk/plugins/plugin_manager.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: Runs the `after_tool_callback` for all plugins.
  signature: 'def run_after_tool_callback(self, *, tool: google.adk.tools.base_tool.BaseTool, tool_args: dict[str, typing.Any], tool_context: google.adk.tools.tool_context.ToolContext, result: dict) -> typing.Optional[dict]:'
- rank: 1213
  id: google.adk.plugins.plugin_manager.PluginManager.run_before_agent_callback
  name: run_before_agent_callback
  file_path: google/adk/plugins/plugin_manager.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: Runs the `before_agent_callback` for all plugins.
  signature: 'def run_before_agent_callback(self, *, agent: google.adk.agents.base_agent.BaseAgent, callback_context: google.adk.agents.callback_context.CallbackContext) -> typing.Optional[google.genai.types.Content]:'
- rank: 1214
  id: google.adk.plugins.plugin_manager.PluginManager.run_before_model_callback
  name: run_before_model_callback
  file_path: google/adk/plugins/plugin_manager.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: Runs the `before_model_callback` for all plugins.
  signature: 'def run_before_model_callback(self, *, callback_context: google.adk.agents.callback_context.CallbackContext, llm_request: google.adk.models.llm_request.LlmRequest) -> typing.Optional[google.adk.models.llm_response.LlmResponse]:'
- rank: 1215
  id: google.adk.plugins.plugin_manager.PluginManager.run_before_run_callback
  name: run_before_run_callback
  file_path: google/adk/plugins/plugin_manager.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: Runs the `before_run_callback` for all plugins.
  signature: 'def run_before_run_callback(self, *, invocation_context: google.adk.agents.invocation_context.InvocationContext) -> typing.Optional[google.genai.types.Content]:'
- rank: 1216
  id: google.adk.plugins.plugin_manager.PluginManager.run_before_tool_callback
  name: run_before_tool_callback
  file_path: google/adk/plugins/plugin_manager.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: Runs the `before_tool_callback` for all plugins.
  signature: 'def run_before_tool_callback(self, *, tool: google.adk.tools.base_tool.BaseTool, tool_args: dict[str, typing.Any], tool_context: google.adk.tools.tool_context.ToolContext) -> typing.Optional[dict]:'
- rank: 1217
  id: google.adk.plugins.plugin_manager.PluginManager.run_on_event_callback
  name: run_on_event_callback
  file_path: google/adk/plugins/plugin_manager.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: Runs the `on_event_callback` for all plugins.
  signature: 'def run_on_event_callback(self, *, invocation_context: google.adk.agents.invocation_context.InvocationContext, event: google.adk.events.event.Event) -> typing.Optional[google.adk.events.event.Event]:'
- rank: 1218
  id: google.adk.plugins.plugin_manager.PluginManager.run_on_model_error_callback
  name: run_on_model_error_callback
  file_path: google/adk/plugins/plugin_manager.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: Runs the `on_model_error_callback` for all plugins.
  signature: 'def run_on_model_error_callback(self, *, callback_context: google.adk.agents.callback_context.CallbackContext, llm_request: google.adk.models.llm_request.LlmRequest, error: Exception) -> typing.Optional[google.adk.models.llm_response.LlmResponse]:'
- rank: 1219
  id: google.adk.plugins.plugin_manager.PluginManager.run_on_tool_error_callback
  name: run_on_tool_error_callback
  file_path: google/adk/plugins/plugin_manager.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: Runs the `on_tool_error_callback` for all plugins.
  signature: 'def run_on_tool_error_callback(self, *, tool: google.adk.tools.base_tool.BaseTool, tool_args: dict[str, typing.Any], tool_context: google.adk.tools.tool_context.ToolContext, error: Exception) -> typing.Optional[dict]:'
- rank: 1220
  id: google.adk.plugins.plugin_manager.PluginManager.run_on_user_message_callback
  name: run_on_user_message_callback
  file_path: google/adk/plugins/plugin_manager.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: Runs the `on_user_message_callback` for all plugins.
  signature: 'def run_on_user_message_callback(self, *, user_message: google.genai.types.Content, invocation_context: google.adk.agents.invocation_context.InvocationContext) -> typing.Optional[google.genai.types.Content]:'
- rank: 1221
  id: google.adk.plugins.reflect_retry_tool_plugin
  name: reflect_retry_tool_plugin
  file_path: google/adk/plugins/reflect_retry_tool_plugin.py
  type: MODULE
  group: Orphan
  usage_score: 0
- rank: 1222
  id: google.adk.plugins.reflect_retry_tool_plugin.ReflectAndRetryToolPlugin
  name: ReflectAndRetryToolPlugin
  file_path: google/adk/plugins/reflect_retry_tool_plugin.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: "Provides self-healing, concurrent-safe error recovery for tool failures.\n\nThis plugin intercepts tool failures, provides structured guidance to the LLM\nfor reflection and correction, and retries the operation up to a configurable\nlimit.\n\n**Key Features:**\n\n- **Concurrency Safe:** Uses locking to safely handle parallel tool\nexecutions\n- **Configurable Scope:** Tracks failures per-invocation (default) or globally\n  using the `TrackingScope` enum.\n- **Extensible Scoping:** The `_get_scope_key` method can be overridden to\n  implement custom tracking logic (e.g., per-user or per-session).\n- **Granular Tracking:** Failure counts are tracked per-tool within the\n  defined scope. A success with one tool resets its counter without affecting\n  others.\n- **Custom Error Extraction:** Supports detecting errors in normal tool\nresponses\nthat\n  don't throw exceptions, by overriding the `extract_error_from_result`\n  method.\n\n**Example:**\n```python\nfrom my_project.plugins\
    \ import ReflectAndRetryToolPlugin, TrackingScope\n\n# Example 1: (MOST COMMON USAGE):\n# Track failures only within the current agent invocation (default).\nerror_handling_plugin = ReflectAndRetryToolPlugin(max_retries=3)\n\n# Example 2:\n# Track failures globally across all turns and users.\nglobal_error_handling_plugin = ReflectAndRetryToolPlugin(max_retries=5,\nscope=TrackingScope.GLOBAL)\n\n# Example 3:\n# Retry on failures but do not throw exceptions.\nerror_handling_plugin =\n  ReflectAndRetryToolPlugin(max_retries=3,\n  throw_exception_if_retry_exceeded=False)\n\n# Example 4:\n# Track failures in successful tool responses that contain errors.\nclass CustomRetryPlugin(ReflectAndRetryToolPlugin):\n  async def extract_error_from_result(self, *, tool, tool_args,tool_context,\n  result):\n    # Detect error based on response content\n    if result.get('status') == 'error':\n        return result\n    return None  # No error detected\nerror_handling_plugin = CustomRetryPlugin(max_retries=5)\n\
    ```\n\n[Note: Inherited members from ABC are omitted.]"
  constructor_signature: 'def __init__(self, name: str, max_retries: int, throw_exception_if_retry_exceeded: bool, tracking_scope: google.adk.plugins.reflect_retry_tool_plugin.TrackingScope):'
  aliases:
  - google.adk.plugins.ReflectAndRetryToolPlugin
  methods:
  - signature: 'def after_tool_callback(self, *, tool: google.adk.tools.base_tool.BaseTool, tool_args: dict[str, typing.Any], tool_context: google.adk.tools.tool_context.ToolContext, result: typing.Any) -> typing.Optional[dict[str, typing.Any]]:'
    docstring: "Handles successful tool calls or extracts and processes errors.\n\nArgs:\n  tool: The tool that was called.\n  tool_args: The arguments passed to the tool.\n  tool_context: The context of the tool call.\n  result: The result of the tool call.\n\nReturns:\n  An optional dictionary containing reflection guidance if an error is\n  detected, or None if the tool call was successful or the\n  response is already a reflection message."
  - signature: 'def extract_error_from_result(self, *, tool: google.adk.tools.base_tool.BaseTool, tool_args: dict[str, typing.Any], tool_context: google.adk.tools.tool_context.ToolContext, result: typing.Any) -> typing.Optional[dict[str, typing.Any]]:'
    docstring: "Extracts an error from a successful tool result and triggers retry logic.\n\nThis is useful when tool call finishes successfully but the result contains\nan error object like {\"error\": ...} that should be handled by the plugin.\n\nBy overriding this method, you can trigger retry logic on these successful\nresults that contain errors.\n\nArgs:\n  tool: The tool that was called.\n  tool_args: The arguments passed to the tool.\n  tool_context: The context of the tool call.\n  result: The result of the tool call.\n\nReturns:\n  The extracted error if any, or None if no error was detected."
  - signature: 'def on_tool_error_callback(self, *, tool: google.adk.tools.base_tool.BaseTool, tool_args: dict[str, typing.Any], tool_context: google.adk.tools.tool_context.ToolContext, error: Exception) -> typing.Optional[dict[str, typing.Any]]:'
    docstring: "Handles tool exceptions by providing reflection guidance.\n\nArgs:\n  tool: The tool that was called.\n  tool_args: The arguments passed to the tool.\n  tool_context: The context of the tool call.\n  error: The exception raised by the tool.\n\nReturns:\n  An optional dictionary containing reflection guidance for the error."
  inherited_methods:
    BasePlugin:
    - signature: 'def on_user_message_callback(self, *, invocation_context: google.adk.agents.invocation_context.InvocationContext, user_message: google.genai.types.Content) -> typing.Optional[google.genai.types.Content]:'
      docstring: "Callback executed when a user message is received before an invocation starts.\n\nThis callback helps logging and modifying the user message before the\nrunner starts the invocation.\n\nArgs:\n  invocation_context: The context for the entire invocation.\n  user_message: The message content input by user.\n\nReturns:\n  An optional `types.Content` to be returned to the ADK. Returning a\n  value to replace the user message. Returning `None` to proceed\n  normally."
    - signature: 'def before_run_callback(self, *, invocation_context: google.adk.agents.invocation_context.InvocationContext) -> typing.Optional[google.genai.types.Content]:'
      docstring: "Callback executed before the ADK runner runs.\n\nThis is the first callback to be called in the lifecycle, ideal for global\nsetup or initialization tasks.\n\nArgs:\n  invocation_context: The context for the entire invocation, containing\n    session information, the root agent, etc.\n\nReturns:\n  An optional `Event` to be returned to the ADK. Returning a value to\n  halt execution of the runner and ends the runner with that event. Return\n  `None` to proceed normally."
    - signature: 'def on_event_callback(self, *, invocation_context: google.adk.agents.invocation_context.InvocationContext, event: google.adk.events.event.Event) -> typing.Optional[google.adk.events.event.Event]:'
      docstring: "Callback executed after an event is yielded from runner.\n\nThis is the ideal place to make modification to the event before the event\nis handled by the underlying agent app.\n\nArgs:\n  invocation_context: The context for the entire invocation.\n  event: The event raised by the runner.\n\nReturns:\n  An optional value. A non-`None` return may be used by the framework to\n  modify or replace the response. Returning `None` allows the original\n  response to be used."
    - signature: 'def after_run_callback(self, *, invocation_context: google.adk.agents.invocation_context.InvocationContext) -> None:'
      docstring: "Callback executed after an ADK runner run has completed.\n\nThis is the final callback in the ADK lifecycle, suitable for cleanup, final\nlogging, or reporting tasks.\n\nArgs:\n  invocation_context: The context for the entire invocation.\n\nReturns:\n  None"
    - signature: 'def close(self) -> None:'
      docstring: 'Method executed when the runner is closed.


        This method is used for cleanup tasks such as closing network connections

        or releasing resources.'
    - signature: 'def before_agent_callback(self, *, agent: google.adk.agents.base_agent.BaseAgent, callback_context: google.adk.agents.callback_context.CallbackContext) -> typing.Optional[google.genai.types.Content]:'
      docstring: "Callback executed before an agent's primary logic is invoked.\n\nThis callback can be used for logging, setup, or to short-circuit the\nagent's execution by returning a value.\n\nArgs:\n  agent: The agent that is about to run.\n  callback_context: The context for the agent invocation.\n\nReturns:\n  An optional `types.Content` object. If a value is returned, it will bypass\n  the agent's callbacks and its execution, and return this value directly.\n  Returning `None` allows the agent to proceed normally."
    - signature: 'def after_agent_callback(self, *, agent: google.adk.agents.base_agent.BaseAgent, callback_context: google.adk.agents.callback_context.CallbackContext) -> typing.Optional[google.genai.types.Content]:'
      docstring: "Callback executed after an agent's primary logic has completed.\n\nArgs:\n  agent: The agent that has just run.\n  callback_context: The context for the agent invocation.\n\nReturns:\n  An optional `types.Content` object. The content to return to the user.\n  When the content is present, the provided content will be used as agent\n  response and appended to event history as agent response."
    - signature: 'def before_model_callback(self, *, callback_context: google.adk.agents.callback_context.CallbackContext, llm_request: google.adk.models.llm_request.LlmRequest) -> typing.Optional[google.adk.models.llm_response.LlmResponse]:'
      docstring: "Callback executed before a request is sent to the model.\n\nThis provides an opportunity to inspect, log, or modify the `LlmRequest`\nobject. It can also be used to implement caching by returning a cached\n`LlmResponse`, which would skip the actual model call.\n\nArgs:\n  callback_context: The context for the current agent call.\n  llm_request: The prepared request object to be sent to the model.\n\nReturns:\n  An optional value. The interpretation of a non-`None` trigger an early\n  exit and returns the response immediately. Returning `None` allows the LLM\n  request to proceed normally."
    - signature: 'def after_model_callback(self, *, callback_context: google.adk.agents.callback_context.CallbackContext, llm_response: google.adk.models.llm_response.LlmResponse) -> typing.Optional[google.adk.models.llm_response.LlmResponse]:'
      docstring: "Callback executed after a response is received from the model.\n\nThis is the ideal place to log model responses, collect metrics on token\nusage, or perform post-processing on the raw `LlmResponse`.\n\nArgs:\n  callback_context: The context for the current agent call.\n  llm_response: The response object received from the model.\n\nReturns:\n  An optional value. A non-`None` return may be used by the framework to\n  modify or replace the response. Returning `None` allows the original\n  response to be used."
    - signature: 'def on_model_error_callback(self, *, callback_context: google.adk.agents.callback_context.CallbackContext, llm_request: google.adk.models.llm_request.LlmRequest, error: Exception) -> typing.Optional[google.adk.models.llm_response.LlmResponse]:'
      docstring: "Callback executed when a model call encounters an error.\n\nThis callback provides an opportunity to handle model errors gracefully,\npotentially providing alternative responses or recovery mechanisms.\n\nArgs:\n  callback_context: The context for the current agent call.\n  llm_request: The request that was sent to the model when the error\n    occurred.\n  error: The exception that was raised during model execution.\n\nReturns:\n  An optional LlmResponse. If an LlmResponse is returned, it will be used\n  instead of propagating the error. Returning `None` allows the original\n  error to be raised."
    - signature: 'def before_tool_callback(self, *, tool: google.adk.tools.base_tool.BaseTool, tool_args: dict[str, typing.Any], tool_context: google.adk.tools.tool_context.ToolContext) -> typing.Optional[dict]:'
      docstring: "Callback executed before a tool is called.\n\nThis callback is useful for logging tool usage, input validation, or\nmodifying the arguments before they are passed to the tool.\n\nArgs:\n  tool: The tool instance that is about to be executed.\n  tool_args: The dictionary of arguments to be used for invoking the tool.\n  tool_context: The context specific to the tool execution.\n\nReturns:\n  An optional dictionary. If a dictionary is returned, it will stop the tool\n  execution and return this response immediately. Returning `None` uses the\n  original, unmodified arguments."
    - signature: 'def after_tool_callback(self, *, tool: google.adk.tools.base_tool.BaseTool, tool_args: dict[str, typing.Any], tool_context: google.adk.tools.tool_context.ToolContext, result: dict) -> typing.Optional[dict]:'
      docstring: "Callback executed after a tool has been called.\n\nThis callback allows for inspecting, logging, or modifying the result\nreturned by a tool.\n\nArgs:\n  tool: The tool instance that has just been executed.\n  tool_args: The original arguments that were passed to the tool.\n  tool_context: The context specific to the tool execution.\n  result: The dictionary returned by the tool invocation.\n\nReturns:\n  An optional dictionary. If a dictionary is returned, it will **replace**\n  the original result from the tool. This allows for post-processing or\n  altering tool outputs. Returning `None` uses the original, unmodified\n  result."
    - signature: 'def on_tool_error_callback(self, *, tool: google.adk.tools.base_tool.BaseTool, tool_args: dict[str, typing.Any], tool_context: google.adk.tools.tool_context.ToolContext, error: Exception) -> typing.Optional[dict]:'
      docstring: "Callback executed when a tool call encounters an error.\n\nThis callback provides an opportunity to handle tool errors gracefully,\npotentially providing alternative responses or recovery mechanisms.\n\nArgs:\n  tool: The tool instance that encountered an error.\n  tool_args: The arguments that were passed to the tool.\n  tool_context: The context specific to the tool execution.\n  error: The exception that was raised during tool execution.\n\nReturns:\n  An optional dictionary. If a dictionary is returned, it will be used as\n  the tool response instead of propagating the error. Returning `None`\n  allows the original error to be raised."
  omitted_inherited_members_from:
  - ABC
- rank: 1223
  id: google.adk.plugins.reflect_retry_tool_plugin.ReflectAndRetryToolPlugin.__init__
  name: __init__
  file_path: google/adk/plugins/reflect_retry_tool_plugin.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Initializes the ReflectAndRetryToolPlugin.\n\nArgs:\n    name: Plugin instance identifier.\n    max_retries: Maximum consecutive failures before giving up (0 = no\n      retries).\n    throw_exception_if_retry_exceeded: If True, raises the final exception\n      when the retry limit is reached. If False, returns guidance instead.\n    tracking_scope: Determines the lifecycle of the error tracking state.\n      Defaults to `TrackingScope.INVOCATION` tracking per-invocation."
  signature: 'def __init__(self, name: str, max_retries: int, throw_exception_if_retry_exceeded: bool, tracking_scope: google.adk.plugins.reflect_retry_tool_plugin.TrackingScope):'
- rank: 1224
  id: google.adk.plugins.reflect_retry_tool_plugin.ReflectAndRetryToolPlugin.after_tool_callback
  name: after_tool_callback
  file_path: google/adk/plugins/reflect_retry_tool_plugin.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Handles successful tool calls or extracts and processes errors.\n\nArgs:\n  tool: The tool that was called.\n  tool_args: The arguments passed to the tool.\n  tool_context: The context of the tool call.\n  result: The result of the tool call.\n\nReturns:\n  An optional dictionary containing reflection guidance if an error is\n  detected, or None if the tool call was successful or the\n  response is already a reflection message."
  signature: 'def after_tool_callback(self, *, tool: google.adk.tools.base_tool.BaseTool, tool_args: dict[str, typing.Any], tool_context: google.adk.tools.tool_context.ToolContext, result: typing.Any) -> typing.Optional[dict[str, typing.Any]]:'
- rank: 1225
  id: google.adk.plugins.reflect_retry_tool_plugin.ReflectAndRetryToolPlugin.extract_error_from_result
  name: extract_error_from_result
  file_path: google/adk/plugins/reflect_retry_tool_plugin.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Extracts an error from a successful tool result and triggers retry logic.\n\nThis is useful when tool call finishes successfully but the result contains\nan error object like {\"error\": ...} that should be handled by the plugin.\n\nBy overriding this method, you can trigger retry logic on these successful\nresults that contain errors.\n\nArgs:\n  tool: The tool that was called.\n  tool_args: The arguments passed to the tool.\n  tool_context: The context of the tool call.\n  result: The result of the tool call.\n\nReturns:\n  The extracted error if any, or None if no error was detected."
  signature: 'def extract_error_from_result(self, *, tool: google.adk.tools.base_tool.BaseTool, tool_args: dict[str, typing.Any], tool_context: google.adk.tools.tool_context.ToolContext, result: typing.Any) -> typing.Optional[dict[str, typing.Any]]:'
- rank: 1226
  id: google.adk.plugins.reflect_retry_tool_plugin.ReflectAndRetryToolPlugin.on_tool_error_callback
  name: on_tool_error_callback
  file_path: google/adk/plugins/reflect_retry_tool_plugin.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Handles tool exceptions by providing reflection guidance.\n\nArgs:\n  tool: The tool that was called.\n  tool_args: The arguments passed to the tool.\n  tool_context: The context of the tool call.\n  error: The exception raised by the tool.\n\nReturns:\n  An optional dictionary containing reflection guidance for the error."
  signature: 'def on_tool_error_callback(self, *, tool: google.adk.tools.base_tool.BaseTool, tool_args: dict[str, typing.Any], tool_context: google.adk.tools.tool_context.ToolContext, error: Exception) -> typing.Optional[dict[str, typing.Any]]:'
- rank: 1227
  id: google.adk.plugins.reflect_retry_tool_plugin.ToolFailureResponse
  name: ToolFailureResponse
  file_path: google/adk/plugins/reflect_retry_tool_plugin.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Response containing tool failure details and retry guidance.


    [Note: Inherited members from pydantic.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, response_type: str = REFLECT_AND_RETRY_RESPONSE_TYPE, error_type: str = '''', error_details: str = '''', retry_count: int = 0, reflection_guidance: str = ''''):'
  properties:
  - signature: 'response_type: str'
  - signature: 'error_type: str'
  - signature: 'error_details: str'
  - signature: 'retry_count: int'
  - signature: 'reflection_guidance: str'
  inherited_properties:
    BaseModel:
    - signature: 'model_config: pydantic.ConfigDict'
  omitted_inherited_members_from:
  - pydantic.BaseModel
- rank: 1228
  id: google.adk.plugins.reflect_retry_tool_plugin.TrackingScope
  name: TrackingScope
  file_path: google/adk/plugins/reflect_retry_tool_plugin.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Defines the lifecycle scope for tracking tool failure counts.


    [Note: Inherited members from Enum are omitted.]'
  properties:
  - signature: 'INVOCATION: str'
  - signature: 'GLOBAL: str'
  omitted_inherited_members_from:
  - Enum
- rank: 1229
  id: google.adk.plugins.save_files_as_artifacts_plugin
  name: save_files_as_artifacts_plugin
  file_path: google/adk/plugins/save_files_as_artifacts_plugin.py
  type: MODULE
  group: Orphan
  usage_score: 0
- rank: 1230
  id: google.adk.plugins.save_files_as_artifacts_plugin.SaveFilesAsArtifactsPlugin
  name: SaveFilesAsArtifactsPlugin
  file_path: google/adk/plugins/save_files_as_artifacts_plugin.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'A plugin that saves files embedded in user messages as artifacts.


    This is useful to allow users to upload files in the chat experience and have

    those files available to the agent within the current session.


    We use Blob.display_name to determine the file name. By default, artifacts are

    session-scoped. For cross-session persistence, prefix the filename with

    "user:".

    Artifacts with the same name will be overwritten. A placeholder with the

    artifact name will be put in place of the embedded file in the user message

    so the model knows where to find the file. You may want to add load_artifacts

    tool to the agent, or load the artifacts in your own tool to use the files.


    [Note: Inherited members from ABC are omitted.]'
  constructor_signature: 'def __init__(self, name: str):'
  methods:
  - signature: 'def on_user_message_callback(self, *, invocation_context: google.adk.agents.invocation_context.InvocationContext, user_message: google.genai.types.Content) -> typing.Optional[google.genai.types.Content]:'
    docstring: Process user message and save any attached files as artifacts.
  inherited_methods:
    BasePlugin:
    - signature: 'def on_user_message_callback(self, *, invocation_context: google.adk.agents.invocation_context.InvocationContext, user_message: google.genai.types.Content) -> typing.Optional[google.genai.types.Content]:'
      docstring: "Callback executed when a user message is received before an invocation starts.\n\nThis callback helps logging and modifying the user message before the\nrunner starts the invocation.\n\nArgs:\n  invocation_context: The context for the entire invocation.\n  user_message: The message content input by user.\n\nReturns:\n  An optional `types.Content` to be returned to the ADK. Returning a\n  value to replace the user message. Returning `None` to proceed\n  normally."
    - signature: 'def before_run_callback(self, *, invocation_context: google.adk.agents.invocation_context.InvocationContext) -> typing.Optional[google.genai.types.Content]:'
      docstring: "Callback executed before the ADK runner runs.\n\nThis is the first callback to be called in the lifecycle, ideal for global\nsetup or initialization tasks.\n\nArgs:\n  invocation_context: The context for the entire invocation, containing\n    session information, the root agent, etc.\n\nReturns:\n  An optional `Event` to be returned to the ADK. Returning a value to\n  halt execution of the runner and ends the runner with that event. Return\n  `None` to proceed normally."
    - signature: 'def on_event_callback(self, *, invocation_context: google.adk.agents.invocation_context.InvocationContext, event: google.adk.events.event.Event) -> typing.Optional[google.adk.events.event.Event]:'
      docstring: "Callback executed after an event is yielded from runner.\n\nThis is the ideal place to make modification to the event before the event\nis handled by the underlying agent app.\n\nArgs:\n  invocation_context: The context for the entire invocation.\n  event: The event raised by the runner.\n\nReturns:\n  An optional value. A non-`None` return may be used by the framework to\n  modify or replace the response. Returning `None` allows the original\n  response to be used."
    - signature: 'def after_run_callback(self, *, invocation_context: google.adk.agents.invocation_context.InvocationContext) -> None:'
      docstring: "Callback executed after an ADK runner run has completed.\n\nThis is the final callback in the ADK lifecycle, suitable for cleanup, final\nlogging, or reporting tasks.\n\nArgs:\n  invocation_context: The context for the entire invocation.\n\nReturns:\n  None"
    - signature: 'def close(self) -> None:'
      docstring: 'Method executed when the runner is closed.


        This method is used for cleanup tasks such as closing network connections

        or releasing resources.'
    - signature: 'def before_agent_callback(self, *, agent: google.adk.agents.base_agent.BaseAgent, callback_context: google.adk.agents.callback_context.CallbackContext) -> typing.Optional[google.genai.types.Content]:'
      docstring: "Callback executed before an agent's primary logic is invoked.\n\nThis callback can be used for logging, setup, or to short-circuit the\nagent's execution by returning a value.\n\nArgs:\n  agent: The agent that is about to run.\n  callback_context: The context for the agent invocation.\n\nReturns:\n  An optional `types.Content` object. If a value is returned, it will bypass\n  the agent's callbacks and its execution, and return this value directly.\n  Returning `None` allows the agent to proceed normally."
    - signature: 'def after_agent_callback(self, *, agent: google.adk.agents.base_agent.BaseAgent, callback_context: google.adk.agents.callback_context.CallbackContext) -> typing.Optional[google.genai.types.Content]:'
      docstring: "Callback executed after an agent's primary logic has completed.\n\nArgs:\n  agent: The agent that has just run.\n  callback_context: The context for the agent invocation.\n\nReturns:\n  An optional `types.Content` object. The content to return to the user.\n  When the content is present, the provided content will be used as agent\n  response and appended to event history as agent response."
    - signature: 'def before_model_callback(self, *, callback_context: google.adk.agents.callback_context.CallbackContext, llm_request: google.adk.models.llm_request.LlmRequest) -> typing.Optional[google.adk.models.llm_response.LlmResponse]:'
      docstring: "Callback executed before a request is sent to the model.\n\nThis provides an opportunity to inspect, log, or modify the `LlmRequest`\nobject. It can also be used to implement caching by returning a cached\n`LlmResponse`, which would skip the actual model call.\n\nArgs:\n  callback_context: The context for the current agent call.\n  llm_request: The prepared request object to be sent to the model.\n\nReturns:\n  An optional value. The interpretation of a non-`None` trigger an early\n  exit and returns the response immediately. Returning `None` allows the LLM\n  request to proceed normally."
    - signature: 'def after_model_callback(self, *, callback_context: google.adk.agents.callback_context.CallbackContext, llm_response: google.adk.models.llm_response.LlmResponse) -> typing.Optional[google.adk.models.llm_response.LlmResponse]:'
      docstring: "Callback executed after a response is received from the model.\n\nThis is the ideal place to log model responses, collect metrics on token\nusage, or perform post-processing on the raw `LlmResponse`.\n\nArgs:\n  callback_context: The context for the current agent call.\n  llm_response: The response object received from the model.\n\nReturns:\n  An optional value. A non-`None` return may be used by the framework to\n  modify or replace the response. Returning `None` allows the original\n  response to be used."
    - signature: 'def on_model_error_callback(self, *, callback_context: google.adk.agents.callback_context.CallbackContext, llm_request: google.adk.models.llm_request.LlmRequest, error: Exception) -> typing.Optional[google.adk.models.llm_response.LlmResponse]:'
      docstring: "Callback executed when a model call encounters an error.\n\nThis callback provides an opportunity to handle model errors gracefully,\npotentially providing alternative responses or recovery mechanisms.\n\nArgs:\n  callback_context: The context for the current agent call.\n  llm_request: The request that was sent to the model when the error\n    occurred.\n  error: The exception that was raised during model execution.\n\nReturns:\n  An optional LlmResponse. If an LlmResponse is returned, it will be used\n  instead of propagating the error. Returning `None` allows the original\n  error to be raised."
    - signature: 'def before_tool_callback(self, *, tool: google.adk.tools.base_tool.BaseTool, tool_args: dict[str, typing.Any], tool_context: google.adk.tools.tool_context.ToolContext) -> typing.Optional[dict]:'
      docstring: "Callback executed before a tool is called.\n\nThis callback is useful for logging tool usage, input validation, or\nmodifying the arguments before they are passed to the tool.\n\nArgs:\n  tool: The tool instance that is about to be executed.\n  tool_args: The dictionary of arguments to be used for invoking the tool.\n  tool_context: The context specific to the tool execution.\n\nReturns:\n  An optional dictionary. If a dictionary is returned, it will stop the tool\n  execution and return this response immediately. Returning `None` uses the\n  original, unmodified arguments."
    - signature: 'def after_tool_callback(self, *, tool: google.adk.tools.base_tool.BaseTool, tool_args: dict[str, typing.Any], tool_context: google.adk.tools.tool_context.ToolContext, result: dict) -> typing.Optional[dict]:'
      docstring: "Callback executed after a tool has been called.\n\nThis callback allows for inspecting, logging, or modifying the result\nreturned by a tool.\n\nArgs:\n  tool: The tool instance that has just been executed.\n  tool_args: The original arguments that were passed to the tool.\n  tool_context: The context specific to the tool execution.\n  result: The dictionary returned by the tool invocation.\n\nReturns:\n  An optional dictionary. If a dictionary is returned, it will **replace**\n  the original result from the tool. This allows for post-processing or\n  altering tool outputs. Returning `None` uses the original, unmodified\n  result."
    - signature: 'def on_tool_error_callback(self, *, tool: google.adk.tools.base_tool.BaseTool, tool_args: dict[str, typing.Any], tool_context: google.adk.tools.tool_context.ToolContext, error: Exception) -> typing.Optional[dict]:'
      docstring: "Callback executed when a tool call encounters an error.\n\nThis callback provides an opportunity to handle tool errors gracefully,\npotentially providing alternative responses or recovery mechanisms.\n\nArgs:\n  tool: The tool instance that encountered an error.\n  tool_args: The arguments that were passed to the tool.\n  tool_context: The context specific to the tool execution.\n  error: The exception that was raised during tool execution.\n\nReturns:\n  An optional dictionary. If a dictionary is returned, it will be used as\n  the tool response instead of propagating the error. Returning `None`\n  allows the original error to be raised."
  omitted_inherited_members_from:
  - ABC
- rank: 1231
  id: google.adk.plugins.save_files_as_artifacts_plugin.SaveFilesAsArtifactsPlugin.__init__
  name: __init__
  file_path: google/adk/plugins/save_files_as_artifacts_plugin.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Initialize the save files as artifacts plugin.\n\nArgs:\n  name: The name of the plugin instance."
  signature: 'def __init__(self, name: str):'
- rank: 1232
  id: google.adk.plugins.save_files_as_artifacts_plugin.SaveFilesAsArtifactsPlugin.on_user_message_callback
  name: on_user_message_callback
  file_path: google/adk/plugins/save_files_as_artifacts_plugin.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: Process user message and save any attached files as artifacts.
  signature: 'def on_user_message_callback(self, *, invocation_context: google.adk.agents.invocation_context.InvocationContext, user_message: google.genai.types.Content) -> typing.Optional[google.genai.types.Content]:'
- rank: 1233
  id: google.adk.runners
  name: runners
  file_path: google/adk/runners.py
  type: MODULE
  group: Orphan
  usage_score: 0
- rank: 1234
  id: google.adk.runners.InMemoryRunner.__init__
  name: __init__
  file_path: google/adk/runners.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Initializes the InMemoryRunner.\n\nArgs:\n    agent: The root agent to run.\n    app_name: The application name of the runner. Defaults to\n      'InMemoryRunner'.\n    plugins: Optional list of plugins for the runner.\n    app: Optional App instance.\n    plugin_close_timeout: The timeout in seconds for plugin close methods."
  signature: 'def __init__(self, agent: typing.Optional[google.adk.agents.base_agent.BaseAgent], *, app_name: typing.Optional[str]=None, plugins: typing.Optional[list[google.adk.plugins.base_plugin.BasePlugin]]=None, app: typing.Optional[google.adk.apps.app.App]=None, plugin_close_timeout: float=5.0):'
- rank: 1235
  id: google.adk.runners.Runner.__init__
  name: __init__
  file_path: google/adk/runners.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Initializes the Runner.\n\nDevelopers should provide either an `app` instance or both `app_name` and\n`agent`. Providing a mix of `app` and `app_name`/`agent` will result in a\n`ValueError`. Providing `app` is the recommended way to create a runner.\n\nArgs:\n    app: An optional `App` instance. If provided, `app_name` and `agent`\n      should not be specified.\n    app_name: The application name of the runner. Required if `app` is not\n      provided.\n    agent: The root agent to run. Required if `app` is not provided.\n    plugins: Deprecated. A list of plugins for the runner. Please use the\n      `app` argument to provide plugins instead.\n    artifact_service: The artifact service for the runner.\n    session_service: The session service for the runner.\n    memory_service: The memory service for the runner.\n    credential_service: The credential service for the runner.\n    plugin_close_timeout: The timeout in seconds for plugin close methods.\n\nRaises:\n    ValueError:\
    \ If `app` is provided along with `app_name` or `plugins`, or\n      if `app` is not provided but either `app_name` or `agent` is missing."
  signature: 'def __init__(self, *, app: typing.Optional[google.adk.apps.app.App]=None, app_name: typing.Optional[str]=None, agent: typing.Optional[google.adk.agents.base_agent.BaseAgent]=None, plugins: typing.Optional[typing.List[google.adk.plugins.base_plugin.BasePlugin]]=None, artifact_service: typing.Optional[google.adk.artifacts.base_artifact_service.BaseArtifactService]=None, session_service: google.adk.sessions.base_session_service.BaseSessionService, memory_service: typing.Optional[google.adk.memory.base_memory_service.BaseMemoryService]=None, credential_service: typing.Optional[google.adk.auth.credential_service.base_credential_service.BaseCredentialService]=None, plugin_close_timeout: float=5.0):'
- rank: 1236
  id: google.adk.runners.Runner.close
  name: close
  file_path: google/adk/runners.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: Closes the runner.
  signature: 'def close(self):'
- rank: 1237
  id: google.adk.runners.Runner.execute
  name: execute
  file_path: google/adk/runners.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def execute(ctx: google.adk.agents.invocation_context.InvocationContext) -> typing.AsyncGenerator[google.adk.events.event.Event]:'
- rank: 1238
  id: google.adk.runners.Runner.execute
  name: execute
  file_path: google/adk/runners.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def execute(ctx: google.adk.agents.invocation_context.InvocationContext) -> typing.AsyncGenerator[google.adk.events.event.Event]:'
- rank: 1239
  id: google.adk.runners.Runner.rewind_async
  name: rewind_async
  file_path: google/adk/runners.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: Rewinds the session to before the specified invocation.
  signature: 'def rewind_async(self, *, user_id: str, session_id: str, rewind_before_invocation_id: str) -> None:'
- rank: 1240
  id: google.adk.runners.Runner.run
  name: run
  file_path: google/adk/runners.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Runs the agent.\n\nNOTE:\n  This sync interface is only for local testing and convenience purpose.\n  Consider using `run_async` for production usage.\n\nIf event compaction is enabled in the App configuration, it will be\nperformed after all agent events for the current invocation have been\nyielded. The generator will only finish iterating after event\ncompaction is complete.\n\nArgs:\n  user_id: The user ID of the session.\n  session_id: The session ID of the session.\n  new_message: A new message to append to the session.\n  run_config: The run config for the agent.\n\nYields:\n  The events generated by the agent."
  signature: 'def run(self, *, user_id: str, session_id: str, new_message: google.genai.types.Content, run_config: typing.Optional[google.adk.agents.run_config.RunConfig]=None) -> typing.Generator[google.adk.events.event.Event, None, None]:'
- rank: 1241
  id: google.adk.runners.Runner.run_async
  name: run_async
  file_path: google/adk/runners.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Main entry method to run the agent in this runner.\n\nIf event compaction is enabled in the App configuration, it will be\nperformed after all agent events for the current invocation have been\nyielded. The async generator will only finish iterating after event\ncompaction is complete. However, this does not block new `run_async`\ncalls for subsequent user queries, which can be started concurrently.\n\nArgs:\n  user_id: The user ID of the session.\n  session_id: The session ID of the session.\n  invocation_id: The invocation ID of the session, set this to resume an\n    interrupted invocation.\n  new_message: A new message to append to the session.\n  state_delta: Optional state changes to apply to the session.\n  run_config: The run config for the agent.\n\nYields:\n  The events generated by the agent.\n\nRaises:\n  ValueError: If the session is not found; If both invocation_id and\n    new_message are None."
  signature: 'def run_async(self, *, user_id: str, session_id: str, invocation_id: typing.Optional[str]=None, new_message: typing.Optional[google.genai.types.Content]=None, state_delta: typing.Optional[dict[str, typing.Any]]=None, run_config: typing.Optional[google.adk.agents.run_config.RunConfig]=None) -> typing.AsyncGenerator[google.adk.events.event.Event, None]:'
- rank: 1242
  id: google.adk.runners.Runner.run_debug
  name: run_debug
  file_path: google/adk/runners.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Debug helper for quick agent experimentation and testing.\n\nThis convenience method is designed for developers getting started with ADK\nwho want to quickly test agents without dealing with session management,\ncontent formatting, or event streaming. It automatically handles common\nboilerplate while hiding complexity.\n\nIMPORTANT: This is for debugging and experimentation only. For production\nuse, please use the standard run_async() method which provides full control\nover session management, event streaming, and error handling.\n\nArgs:\n    user_messages: Message(s) to send to the agent. Can be: - Single string:\n      \"What is 2+2?\" - List of strings: [\"Hello!\", \"What's my name?\"]\n    user_id: User identifier. Defaults to \"debug_user_id\".\n    session_id: Session identifier for conversation persistence. Defaults to\n      \"debug_session_id\". Reuse the same ID to continue a conversation.\n    run_config: Optional configuration for the agent execution.\n   \
    \ quiet: If True, suppresses console output. Defaults to False (output\n      shown).\n    verbose: If True, shows detailed tool calls and responses. Defaults to\n      False for cleaner output showing only final agent responses.\n\nReturns:\n    list[Event]: All events from all messages.\n\nRaises:\n    ValueError: If session creation/retrieval fails.\n\nExamples:\n    Quick debugging:\n    >>> runner = InMemoryRunner(agent=my_agent)\n    >>> await runner.run_debug(\"What is 2+2?\")\n\n    Multiple queries in conversation:\n    >>> await runner.run_debug([\"Hello!\", \"What's my name?\"])\n\n    Continue a debug session:\n    >>> await runner.run_debug(\"What did we discuss?\")  # Continues default\n    session\n\n    Separate debug sessions:\n    >>> await runner.run_debug(\"Hi\", user_id=\"alice\", session_id=\"debug1\")\n    >>> await runner.run_debug(\"Hi\", user_id=\"bob\", session_id=\"debug2\")\n\n    Capture events for inspection:\n    >>> events = await runner.run_debug(\"\
    Analyze this\")\n    >>> for event in events:\n    ...     inspect_event(event)\n\nNote:\n    For production applications requiring:\n    - Custom session/memory services (Spanner, Cloud SQL, etc.)\n    - Fine-grained event processing and streaming\n    - Error recovery and resumability\n    - Performance optimization\n    Please use run_async() with proper configuration."
  signature: 'def run_debug(self, user_messages: str | list[str], *, user_id: str=''debug_user_id'', session_id: str=''debug_session_id'', run_config: RunConfig | None=None, quiet: bool=False, verbose: bool=False) -> list[google.adk.events.event.Event]:'
- rank: 1243
  id: google.adk.runners.Runner.run_live
  name: run_live
  file_path: google/adk/runners.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Runs the agent in live mode (experimental feature).\n\nThe `run_live` method yields a stream of `Event` objects, but not all\nyielded events are saved to the session. Here's a breakdown:\n\n**Events Yielded to Callers:**\n*   **Live Model Audio Events with Inline Data:** Events containing raw\n    audio `Blob` data(`inline_data`).\n*   **Live Model Audio Events with File Data:** Both input and ouput audio\n    data are aggregated into a audio file saved into artifacts. The\n    reference to the file is saved in the event as `file_data`.\n*   **Usage Metadata:** Events containing token usage.\n*   **Transcription Events:** Both partial and non-partial transcription\n    events are yielded.\n*   **Function Call and Response Events:** Always saved.\n*   **Other Control Events:** Most control events are saved.\n\n**Events Saved to the Session:**\n*   **Live Model Audio Events with File Data:** Both input and ouput audio\n    data are aggregated into a audio file saved into artifacts.\
    \ The\n    reference to the file is saved as event in the `file_data` to session\n    if RunConfig.save_live_model_audio_to_session is True.\n*   **Usage Metadata Events:** Saved to the session.\n*   **Non-Partial Transcription Events:** Non-partial transcription events\n    are saved.\n*   **Function Call and Response Events:** Always saved.\n*   **Other Control Events:** Most control events are saved.\n\n**Events Not Saved to the Session:**\n*   **Live Model Audio Events with Inline Data:** Events containing raw\n    audio `Blob` data are **not** saved to the session.\n\nArgs:\n    user_id: The user ID for the session. Required if `session` is None.\n    session_id: The session ID for the session. Required if `session` is\n      None.\n    live_request_queue: The queue for live requests.\n    run_config: The run config for the agent.\n    session: The session to use. This parameter is deprecated, please use\n      `user_id` and `session_id` instead.\n\nYields:\n    AsyncGenerator[Event,\
    \ None]: An asynchronous generator that yields\n    `Event`\n    objects as they are produced by the agent during its live execution.\n\n.. warning::\n    This feature is **experimental** and its API or behavior may change\n    in future releases.\n\n.. NOTE::\n    Either `session` or both `user_id` and `session_id` must be provided."
  signature: 'def run_live(self, *, user_id: typing.Optional[str]=None, session_id: typing.Optional[str]=None, live_request_queue: google.adk.agents.live_request_queue.LiveRequestQueue, run_config: typing.Optional[google.adk.agents.run_config.RunConfig]=None, session: typing.Optional[google.adk.sessions.session.Session]=None) -> typing.AsyncGenerator[google.adk.events.event.Event, None]:'
- rank: 1244
  id: google.adk.sessions
  name: sessions
  file_path: google/adk/sessions/__init__.py
  type: MODULE
  group: Orphan
  usage_score: 0
- rank: 1245
  id: google.adk.sessions.base_session_service
  name: base_session_service
  file_path: google/adk/sessions/base_session_service.py
  type: MODULE
  group: Orphan
  usage_score: 0
- rank: 1246
  id: google.adk.sessions.base_session_service.BaseSessionService
  name: BaseSessionService
  file_path: google/adk/sessions/base_session_service.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Base class for session services.


    The service provides a set of methods for managing sessions and events.


    [Note: Inherited members from abc.ABC are omitted.]'
  methods:
  - signature: 'def create_session(self, *, app_name: str, user_id: str, state: typing.Optional[dict[str, typing.Any]]=None, session_id: typing.Optional[str]=None) -> google.adk.sessions.session.Session:'
    docstring: "Creates a new session.\n\nArgs:\n  app_name: the name of the app.\n  user_id: the id of the user.\n  state: the initial state of the session.\n  session_id: the client-provided id of the session. If not provided, a\n    generated ID will be used.\n\nReturns:\n  session: The newly created session instance."
  - signature: 'def get_session(self, *, app_name: str, user_id: str, session_id: str, config: typing.Optional[google.adk.sessions.base_session_service.GetSessionConfig]=None) -> typing.Optional[google.adk.sessions.session.Session]:'
    docstring: Gets a session.
  - signature: 'def list_sessions(self, *, app_name: str, user_id: typing.Optional[str]=None) -> google.adk.sessions.base_session_service.ListSessionsResponse:'
    docstring: "Lists all the sessions for a user.\n\nArgs:\n  app_name: The name of the app.\n  user_id: The ID of the user. If not provided, lists all sessions for all\n    users.\n\nReturns:\n  A ListSessionsResponse containing the sessions."
  - signature: 'def delete_session(self, *, app_name: str, user_id: str, session_id: str) -> None:'
    docstring: Deletes a session.
  - signature: 'def append_event(self, session: google.adk.sessions.session.Session, event: google.adk.events.event.Event) -> google.adk.events.event.Event:'
    docstring: Appends an event to a session object.
  omitted_inherited_members_from:
  - abc.ABC
- rank: 1247
  id: google.adk.sessions.base_session_service.BaseSessionService.append_event
  name: append_event
  file_path: google/adk/sessions/base_session_service.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: Appends an event to a session object.
  signature: 'def append_event(self, session: google.adk.sessions.session.Session, event: google.adk.events.event.Event) -> google.adk.events.event.Event:'
- rank: 1248
  id: google.adk.sessions.base_session_service.BaseSessionService.create_session
  name: create_session
  file_path: google/adk/sessions/base_session_service.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Creates a new session.\n\nArgs:\n  app_name: the name of the app.\n  user_id: the id of the user.\n  state: the initial state of the session.\n  session_id: the client-provided id of the session. If not provided, a\n    generated ID will be used.\n\nReturns:\n  session: The newly created session instance."
  signature: 'def create_session(self, *, app_name: str, user_id: str, state: typing.Optional[dict[str, typing.Any]]=None, session_id: typing.Optional[str]=None) -> google.adk.sessions.session.Session:'
- rank: 1249
  id: google.adk.sessions.base_session_service.BaseSessionService.delete_session
  name: delete_session
  file_path: google/adk/sessions/base_session_service.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: Deletes a session.
  signature: 'def delete_session(self, *, app_name: str, user_id: str, session_id: str) -> None:'
- rank: 1250
  id: google.adk.sessions.base_session_service.BaseSessionService.get_session
  name: get_session
  file_path: google/adk/sessions/base_session_service.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: Gets a session.
  signature: 'def get_session(self, *, app_name: str, user_id: str, session_id: str, config: typing.Optional[google.adk.sessions.base_session_service.GetSessionConfig]=None) -> typing.Optional[google.adk.sessions.session.Session]:'
- rank: 1251
  id: google.adk.sessions.base_session_service.BaseSessionService.list_sessions
  name: list_sessions
  file_path: google/adk/sessions/base_session_service.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Lists all the sessions for a user.\n\nArgs:\n  app_name: The name of the app.\n  user_id: The ID of the user. If not provided, lists all sessions for all\n    users.\n\nReturns:\n  A ListSessionsResponse containing the sessions."
  signature: 'def list_sessions(self, *, app_name: str, user_id: typing.Optional[str]=None) -> google.adk.sessions.base_session_service.ListSessionsResponse:'
- rank: 1252
  id: google.adk.sessions.base_session_service.GetSessionConfig
  name: GetSessionConfig
  file_path: google/adk/sessions/base_session_service.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'The configuration of getting a session.


    [Note: Inherited members from pydantic.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, num_recent_events: typing.Optional[int] = None, after_timestamp: typing.Optional[float] = None):'
  properties:
  - signature: 'num_recent_events: typing.Optional[int]'
  - signature: 'after_timestamp: typing.Optional[float]'
  inherited_properties:
    BaseModel:
    - signature: 'model_config: pydantic.ConfigDict'
  omitted_inherited_members_from:
  - pydantic.BaseModel
- rank: 1253
  id: google.adk.sessions.base_session_service.ListSessionsResponse
  name: ListSessionsResponse
  file_path: google/adk/sessions/base_session_service.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'The response of listing sessions.


    The events and states are not set within each Session object.


    [Note: Inherited members from pydantic.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, sessions: list[google.adk.sessions.session.Session] = list()):'
  properties:
  - signature: 'sessions: list[google.adk.sessions.session.Session]'
  inherited_properties:
    BaseModel:
    - signature: 'model_config: pydantic.ConfigDict'
  omitted_inherited_members_from:
  - pydantic.BaseModel
- rank: 1254
  id: google.adk.sessions.database_session_service
  name: database_session_service
  file_path: google/adk/sessions/database_session_service.py
  type: MODULE
  group: Orphan
  usage_score: 0
  methods:
  - signature: 'def set_sqlite_pragma(dbapi_connection, connection_record):'
- rank: 1255
  id: google.adk.sessions.database_session_service.Base
  name: Base
  file_path: google/adk/sessions/database_session_service.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Base class for database tables.


    [Note: Inherited members from DeclarativeBase are omitted.]'
  omitted_inherited_members_from:
  - DeclarativeBase
- rank: 1256
  id: google.adk.sessions.database_session_service.DatabaseSessionService
  name: DatabaseSessionService
  file_path: google/adk/sessions/database_session_service.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'A session service that uses a database for storage.


    [Note: Inherited members from abc.ABC are omitted.]'
  constructor_signature: 'def __init__(self, db_url: str):'
  methods:
  - signature: 'def create_session(self, *, app_name: str, user_id: str, state: typing.Optional[dict[str, typing.Any]]=None, session_id: typing.Optional[str]=None) -> google.adk.sessions.session.Session:'
  - signature: 'def get_session(self, *, app_name: str, user_id: str, session_id: str, config: typing.Optional[google.adk.sessions.base_session_service.GetSessionConfig]=None) -> typing.Optional[google.adk.sessions.session.Session]:'
  - signature: 'def list_sessions(self, *, app_name: str, user_id: typing.Optional[str]=None) -> google.adk.sessions.base_session_service.ListSessionsResponse:'
  - signature: 'def delete_session(self, app_name: str, user_id: str, session_id: str) -> None:'
  - signature: 'def append_event(self, session: google.adk.sessions.session.Session, event: google.adk.events.event.Event) -> google.adk.events.event.Event:'
  inherited_methods:
    BaseSessionService:
    - signature: 'def create_session(self, *, app_name: str, user_id: str, state: typing.Optional[dict[str, typing.Any]]=None, session_id: typing.Optional[str]=None) -> google.adk.sessions.session.Session:'
      docstring: "Creates a new session.\n\nArgs:\n  app_name: the name of the app.\n  user_id: the id of the user.\n  state: the initial state of the session.\n  session_id: the client-provided id of the session. If not provided, a\n    generated ID will be used.\n\nReturns:\n  session: The newly created session instance."
    - signature: 'def get_session(self, *, app_name: str, user_id: str, session_id: str, config: typing.Optional[google.adk.sessions.base_session_service.GetSessionConfig]=None) -> typing.Optional[google.adk.sessions.session.Session]:'
      docstring: Gets a session.
    - signature: 'def list_sessions(self, *, app_name: str, user_id: typing.Optional[str]=None) -> google.adk.sessions.base_session_service.ListSessionsResponse:'
      docstring: "Lists all the sessions for a user.\n\nArgs:\n  app_name: The name of the app.\n  user_id: The ID of the user. If not provided, lists all sessions for all\n    users.\n\nReturns:\n  A ListSessionsResponse containing the sessions."
    - signature: 'def delete_session(self, *, app_name: str, user_id: str, session_id: str) -> None:'
      docstring: Deletes a session.
    - signature: 'def append_event(self, session: google.adk.sessions.session.Session, event: google.adk.events.event.Event) -> google.adk.events.event.Event:'
      docstring: Appends an event to a session object.
  omitted_inherited_members_from:
  - abc.ABC
- rank: 1257
  id: google.adk.sessions.database_session_service.DatabaseSessionService.__init__
  name: __init__
  file_path: google/adk/sessions/database_session_service.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: Initializes the database session service with a database URL.
  signature: 'def __init__(self, db_url: str):'
- rank: 1258
  id: google.adk.sessions.database_session_service.DatabaseSessionService.append_event
  name: append_event
  file_path: google/adk/sessions/database_session_service.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def append_event(self, session: google.adk.sessions.session.Session, event: google.adk.events.event.Event) -> google.adk.events.event.Event:'
- rank: 1259
  id: google.adk.sessions.database_session_service.DatabaseSessionService.create_session
  name: create_session
  file_path: google/adk/sessions/database_session_service.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def create_session(self, *, app_name: str, user_id: str, state: typing.Optional[dict[str, typing.Any]]=None, session_id: typing.Optional[str]=None) -> google.adk.sessions.session.Session:'
- rank: 1260
  id: google.adk.sessions.database_session_service.DatabaseSessionService.delete_session
  name: delete_session
  file_path: google/adk/sessions/database_session_service.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def delete_session(self, app_name: str, user_id: str, session_id: str) -> None:'
- rank: 1261
  id: google.adk.sessions.database_session_service.DatabaseSessionService.get_session
  name: get_session
  file_path: google/adk/sessions/database_session_service.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def get_session(self, *, app_name: str, user_id: str, session_id: str, config: typing.Optional[google.adk.sessions.base_session_service.GetSessionConfig]=None) -> typing.Optional[google.adk.sessions.session.Session]:'
- rank: 1262
  id: google.adk.sessions.database_session_service.DatabaseSessionService.list_sessions
  name: list_sessions
  file_path: google/adk/sessions/database_session_service.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def list_sessions(self, *, app_name: str, user_id: typing.Optional[str]=None) -> google.adk.sessions.base_session_service.ListSessionsResponse:'
- rank: 1263
  id: google.adk.sessions.database_session_service.DynamicJSON
  name: DynamicJSON
  file_path: google/adk/sessions/database_session_service.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'A JSON-like type that uses JSONB on PostgreSQL and TEXT with JSON serialization for other databases.


    [Note: Inherited members from TypeDecorator are omitted.]'
  methods:
  - signature: 'def load_dialect_impl(self, dialect: sqlalchemy.Dialect):'
  - signature: 'def process_bind_param(self, value, dialect: sqlalchemy.Dialect):'
  - signature: 'def process_result_value(self, value, dialect: sqlalchemy.Dialect):'
  properties:
  - signature: 'impl: Any'
  omitted_inherited_members_from:
  - TypeDecorator
- rank: 1264
  id: google.adk.sessions.database_session_service.DynamicJSON.load_dialect_impl
  name: load_dialect_impl
  file_path: google/adk/sessions/database_session_service.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def load_dialect_impl(self, dialect: sqlalchemy.Dialect):'
- rank: 1265
  id: google.adk.sessions.database_session_service.DynamicJSON.process_bind_param
  name: process_bind_param
  file_path: google/adk/sessions/database_session_service.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def process_bind_param(self, value, dialect: sqlalchemy.Dialect):'
- rank: 1266
  id: google.adk.sessions.database_session_service.DynamicJSON.process_result_value
  name: process_result_value
  file_path: google/adk/sessions/database_session_service.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def process_result_value(self, value, dialect: sqlalchemy.Dialect):'
- rank: 1267
  id: google.adk.sessions.database_session_service.DynamicPickleType
  name: DynamicPickleType
  file_path: google/adk/sessions/database_session_service.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Represents a type that can be pickled.


    [Note: Inherited members from TypeDecorator are omitted.]'
  methods:
  - signature: 'def load_dialect_impl(self, dialect):'
  - signature: 'def process_bind_param(self, value, dialect):'
    docstring: Ensures the pickled value is a bytes object before passing it to the database dialect.
  - signature: 'def process_result_value(self, value, dialect):'
    docstring: Ensures the raw bytes from the database are unpickled back into a Python object.
  properties:
  - signature: 'impl: Any'
  omitted_inherited_members_from:
  - TypeDecorator
- rank: 1268
  id: google.adk.sessions.database_session_service.DynamicPickleType.load_dialect_impl
  name: load_dialect_impl
  file_path: google/adk/sessions/database_session_service.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def load_dialect_impl(self, dialect):'
- rank: 1269
  id: google.adk.sessions.database_session_service.DynamicPickleType.process_bind_param
  name: process_bind_param
  file_path: google/adk/sessions/database_session_service.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: Ensures the pickled value is a bytes object before passing it to the database dialect.
  signature: 'def process_bind_param(self, value, dialect):'
- rank: 1270
  id: google.adk.sessions.database_session_service.DynamicPickleType.process_result_value
  name: process_result_value
  file_path: google/adk/sessions/database_session_service.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: Ensures the raw bytes from the database are unpickled back into a Python object.
  signature: 'def process_result_value(self, value, dialect):'
- rank: 1271
  id: google.adk.sessions.database_session_service.PreciseTimestamp
  name: PreciseTimestamp
  file_path: google/adk/sessions/database_session_service.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Represents a timestamp precise to the microsecond.


    [Note: Inherited members from TypeDecorator are omitted.]'
  methods:
  - signature: 'def load_dialect_impl(self, dialect):'
  properties:
  - signature: 'impl: Any'
  - signature: 'cache_ok: bool'
  omitted_inherited_members_from:
  - TypeDecorator
- rank: 1272
  id: google.adk.sessions.database_session_service.PreciseTimestamp.load_dialect_impl
  name: load_dialect_impl
  file_path: google/adk/sessions/database_session_service.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def load_dialect_impl(self, dialect):'
- rank: 1273
  id: google.adk.sessions.database_session_service.StorageAppState
  name: StorageAppState
  file_path: google/adk/sessions/database_session_service.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Represents an app state stored in the database.


    [Note: Inherited members from DeclarativeBase are omitted.]'
  properties:
  - signature: 'app_name: sqlalchemy.orm.Mapped[str]'
  - signature: 'state: sqlalchemy.orm.Mapped[sqlalchemy.ext.mutable.MutableDict[str, typing.Any]]'
  - signature: 'update_time: sqlalchemy.orm.Mapped[datetime.datetime]'
  omitted_inherited_members_from:
  - DeclarativeBase
- rank: 1274
  id: google.adk.sessions.database_session_service.StorageEvent
  name: StorageEvent
  file_path: google/adk/sessions/database_session_service.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Represents an event stored in the database.


    [Note: Inherited members from DeclarativeBase are omitted.]'
  methods:
  - signature: 'def long_running_tool_ids(self, value: set[str]):'
  - signature: 'def long_running_tool_ids(self, value: set[str]):'
  - signature: 'def from_event(cls, session: google.adk.sessions.session.Session, event: google.adk.events.event.Event) -> google.adk.sessions.database_session_service.StorageEvent:'
  - signature: 'def to_event(self) -> google.adk.events.event.Event:'
  properties:
  - signature: 'id: sqlalchemy.orm.Mapped[str]'
  - signature: 'app_name: sqlalchemy.orm.Mapped[str]'
  - signature: 'user_id: sqlalchemy.orm.Mapped[str]'
  - signature: 'session_id: sqlalchemy.orm.Mapped[str]'
  - signature: 'invocation_id: sqlalchemy.orm.Mapped[str]'
  - signature: 'author: sqlalchemy.orm.Mapped[str]'
  - signature: 'actions: sqlalchemy.orm.Mapped[sqlalchemy.ext.mutable.MutableDict[str, typing.Any]]'
  - signature: 'long_running_tool_ids_json: sqlalchemy.orm.Mapped[typing.Optional[str]]'
  - signature: 'branch: sqlalchemy.orm.Mapped[str]'
  - signature: 'timestamp: sqlalchemy.orm.Mapped[google.adk.sessions.database_session_service.PreciseTimestamp]'
  - signature: 'content: sqlalchemy.orm.Mapped[dict[str, typing.Any]]'
  - signature: 'grounding_metadata: sqlalchemy.orm.Mapped[dict[str, typing.Any]]'
  - signature: 'custom_metadata: sqlalchemy.orm.Mapped[dict[str, typing.Any]]'
  - signature: 'usage_metadata: sqlalchemy.orm.Mapped[dict[str, typing.Any]]'
  - signature: 'citation_metadata: sqlalchemy.orm.Mapped[dict[str, typing.Any]]'
  - signature: 'partial: sqlalchemy.orm.Mapped[bool]'
  - signature: 'turn_complete: sqlalchemy.orm.Mapped[bool]'
  - signature: 'error_code: sqlalchemy.orm.Mapped[str]'
  - signature: 'error_message: sqlalchemy.orm.Mapped[str]'
  - signature: 'interrupted: sqlalchemy.orm.Mapped[bool]'
  - signature: 'input_transcription: sqlalchemy.orm.Mapped[dict[str, typing.Any]]'
  - signature: 'output_transcription: sqlalchemy.orm.Mapped[dict[str, typing.Any]]'
  - signature: 'storage_session: sqlalchemy.orm.Mapped[google.adk.sessions.database_session_service.StorageSession]'
  omitted_inherited_members_from:
  - DeclarativeBase
- rank: 1275
  id: google.adk.sessions.database_session_service.StorageEvent.from_event
  name: from_event
  file_path: google/adk/sessions/database_session_service.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def from_event(cls, session: google.adk.sessions.session.Session, event: google.adk.events.event.Event) -> google.adk.sessions.database_session_service.StorageEvent:'
- rank: 1276
  id: google.adk.sessions.database_session_service.StorageEvent.long_running_tool_ids
  name: long_running_tool_ids
  file_path: google/adk/sessions/database_session_service.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def long_running_tool_ids(self, value: set[str]):'
- rank: 1277
  id: google.adk.sessions.database_session_service.StorageEvent.long_running_tool_ids
  name: long_running_tool_ids
  file_path: google/adk/sessions/database_session_service.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def long_running_tool_ids(self, value: set[str]):'
- rank: 1278
  id: google.adk.sessions.database_session_service.StorageEvent.to_event
  name: to_event
  file_path: google/adk/sessions/database_session_service.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def to_event(self) -> google.adk.events.event.Event:'
- rank: 1279
  id: google.adk.sessions.database_session_service.StorageSession
  name: StorageSession
  file_path: google/adk/sessions/database_session_service.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Represents a session stored in the database.


    [Note: Inherited members from DeclarativeBase are omitted.]'
  methods:
  - signature: 'def update_timestamp_tz(self) -> datetime.datetime:'
    docstring: Returns the time zone aware update timestamp.
  - signature: 'def to_session(self, state: dict[str, Any] | None, events: list[Event] | None) -> google.adk.sessions.session.Session:'
    docstring: Converts the storage session to a session object.
  properties:
  - signature: 'app_name: sqlalchemy.orm.Mapped[str]'
  - signature: 'user_id: sqlalchemy.orm.Mapped[str]'
  - signature: 'id: sqlalchemy.orm.Mapped[str]'
  - signature: 'state: sqlalchemy.orm.Mapped[sqlalchemy.ext.mutable.MutableDict[str, typing.Any]]'
  - signature: 'create_time: sqlalchemy.orm.Mapped[datetime.datetime]'
  - signature: 'update_time: sqlalchemy.orm.Mapped[datetime.datetime]'
  - signature: 'storage_events: sqlalchemy.orm.Mapped[list[google.adk.sessions.database_session_service.StorageEvent]]'
  omitted_inherited_members_from:
  - DeclarativeBase
- rank: 1280
  id: google.adk.sessions.database_session_service.StorageSession.to_session
  name: to_session
  file_path: google/adk/sessions/database_session_service.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: Converts the storage session to a session object.
  signature: 'def to_session(self, state: dict[str, Any] | None, events: list[Event] | None) -> google.adk.sessions.session.Session:'
- rank: 1281
  id: google.adk.sessions.database_session_service.StorageSession.update_timestamp_tz
  name: update_timestamp_tz
  file_path: google/adk/sessions/database_session_service.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: Returns the time zone aware update timestamp.
  signature: 'def update_timestamp_tz(self) -> datetime.datetime:'
- rank: 1282
  id: google.adk.sessions.database_session_service.StorageUserState
  name: StorageUserState
  file_path: google/adk/sessions/database_session_service.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Represents a user state stored in the database.


    [Note: Inherited members from DeclarativeBase are omitted.]'
  properties:
  - signature: 'app_name: sqlalchemy.orm.Mapped[str]'
  - signature: 'user_id: sqlalchemy.orm.Mapped[str]'
  - signature: 'state: sqlalchemy.orm.Mapped[sqlalchemy.ext.mutable.MutableDict[str, typing.Any]]'
  - signature: 'update_time: sqlalchemy.orm.Mapped[datetime.datetime]'
  omitted_inherited_members_from:
  - DeclarativeBase
- rank: 1283
  id: google.adk.sessions.database_session_service.set_sqlite_pragma
  name: set_sqlite_pragma
  file_path: google/adk/sessions/database_session_service.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def set_sqlite_pragma(dbapi_connection, connection_record):'
- rank: 1284
  id: google.adk.sessions.in_memory_session_service
  name: in_memory_session_service
  file_path: google/adk/sessions/in_memory_session_service.py
  type: MODULE
  group: Orphan
  usage_score: 0
- rank: 1285
  id: google.adk.sessions.in_memory_session_service.InMemorySessionService.__init__
  name: __init__
  file_path: google/adk/sessions/in_memory_session_service.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def __init__(self):'
- rank: 1286
  id: google.adk.sessions.in_memory_session_service.InMemorySessionService.append_event
  name: append_event
  file_path: google/adk/sessions/in_memory_session_service.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def append_event(self, session: google.adk.sessions.session.Session, event: google.adk.events.event.Event) -> google.adk.events.event.Event:'
- rank: 1287
  id: google.adk.sessions.in_memory_session_service.InMemorySessionService.create_session
  name: create_session
  file_path: google/adk/sessions/in_memory_session_service.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def create_session(self, *, app_name: str, user_id: str, state: typing.Optional[dict[str, typing.Any]]=None, session_id: typing.Optional[str]=None) -> google.adk.sessions.session.Session:'
- rank: 1288
  id: google.adk.sessions.in_memory_session_service.InMemorySessionService.create_session_sync
  name: create_session_sync
  file_path: google/adk/sessions/in_memory_session_service.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def create_session_sync(self, *, app_name: str, user_id: str, state: typing.Optional[dict[str, typing.Any]]=None, session_id: typing.Optional[str]=None) -> google.adk.sessions.session.Session:'
- rank: 1289
  id: google.adk.sessions.in_memory_session_service.InMemorySessionService.delete_session
  name: delete_session
  file_path: google/adk/sessions/in_memory_session_service.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def delete_session(self, *, app_name: str, user_id: str, session_id: str) -> None:'
- rank: 1290
  id: google.adk.sessions.in_memory_session_service.InMemorySessionService.delete_session_sync
  name: delete_session_sync
  file_path: google/adk/sessions/in_memory_session_service.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def delete_session_sync(self, *, app_name: str, user_id: str, session_id: str) -> None:'
- rank: 1291
  id: google.adk.sessions.in_memory_session_service.InMemorySessionService.get_session
  name: get_session
  file_path: google/adk/sessions/in_memory_session_service.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def get_session(self, *, app_name: str, user_id: str, session_id: str, config: typing.Optional[google.adk.sessions.base_session_service.GetSessionConfig]=None) -> typing.Optional[google.adk.sessions.session.Session]:'
- rank: 1292
  id: google.adk.sessions.in_memory_session_service.InMemorySessionService.get_session_sync
  name: get_session_sync
  file_path: google/adk/sessions/in_memory_session_service.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def get_session_sync(self, *, app_name: str, user_id: str, session_id: str, config: typing.Optional[google.adk.sessions.base_session_service.GetSessionConfig]=None) -> typing.Optional[google.adk.sessions.session.Session]:'
- rank: 1293
  id: google.adk.sessions.in_memory_session_service.InMemorySessionService.list_sessions
  name: list_sessions
  file_path: google/adk/sessions/in_memory_session_service.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def list_sessions(self, *, app_name: str, user_id: typing.Optional[str]=None) -> google.adk.sessions.base_session_service.ListSessionsResponse:'
- rank: 1294
  id: google.adk.sessions.in_memory_session_service.InMemorySessionService.list_sessions_sync
  name: list_sessions_sync
  file_path: google/adk/sessions/in_memory_session_service.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def list_sessions_sync(self, *, app_name: str, user_id: typing.Optional[str]=None) -> google.adk.sessions.base_session_service.ListSessionsResponse:'
- rank: 1295
  id: google.adk.sessions.migrate_from_sqlalchemy_sqlite
  name: migrate_from_sqlalchemy_sqlite
  file_path: google/adk/sessions/migrate_from_sqlalchemy_sqlite.py
  type: MODULE
  group: Orphan
  usage_score: 0
  docstring: Migration script from SQLAlchemy SQLite to the new SQLite JSON schema.
  methods:
  - signature: 'def migrate(source_db_url: str, dest_db_path: str):'
    docstring: Migrates data from a SQLAlchemy-based SQLite DB to the new schema.
- rank: 1296
  id: google.adk.sessions.migrate_from_sqlalchemy_sqlite.migrate
  name: migrate
  file_path: google/adk/sessions/migrate_from_sqlalchemy_sqlite.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: Migrates data from a SQLAlchemy-based SQLite DB to the new schema.
  signature: 'def migrate(source_db_url: str, dest_db_path: str):'
- rank: 1297
  id: google.adk.sessions.session
  name: session
  file_path: google/adk/sessions/session.py
  type: MODULE
  group: Orphan
  usage_score: 0
- rank: 1298
  id: google.adk.sessions.session.Session
  name: Session
  file_path: google/adk/sessions/session.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Represents a series of interactions between a user and agents.


    [Note: Inherited members from pydantic.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, id: str, app_name: str, user_id: str, state: dict[str, typing.Any] = dict(), events: list[google.adk.events.event.Event] = list()):'
  aliases:
  - google.adk.sessions.Session
  properties:
  - signature: 'model_config: pydantic.ConfigDict'
    docstring: The pydantic model config.
  - signature: 'id: str'
    docstring: The unique identifier of the session.
  - signature: 'app_name: str'
    docstring: The name of the app.
  - signature: 'user_id: str'
    docstring: The id of the user.
  - signature: 'state: dict[str, typing.Any]'
    docstring: The state of the session.
  - signature: 'events: list[google.adk.events.event.Event]'
    docstring: 'The events of the session, e.g. user input, model response, function

      call/response, etc.'
  - signature: 'last_update_time: float'
    docstring: The last update time of the session.
  inherited_properties:
    BaseModel:
    - signature: 'model_config: pydantic.ConfigDict'
  omitted_inherited_members_from:
  - pydantic.BaseModel
- rank: 1299
  id: google.adk.sessions.sqlite_session_service
  name: sqlite_session_service
  file_path: google/adk/sessions/sqlite_session_service.py
  type: MODULE
  group: Orphan
  usage_score: 0
- rank: 1300
  id: google.adk.sessions.sqlite_session_service.SqliteSessionService
  name: SqliteSessionService
  file_path: google/adk/sessions/sqlite_session_service.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'A session service that uses an SQLite database for storage via aiosqlite.


    Event data is stored as JSON to allow for schema flexibility as event

    fields evolve.


    [Note: Inherited members from abc.ABC are omitted.]'
  constructor_signature: 'def __init__(self, db_path: str):'
  methods:
  - signature: 'def create_session(self, *, app_name: str, user_id: str, state: typing.Optional[dict[str, typing.Any]]=None, session_id: typing.Optional[str]=None) -> google.adk.sessions.session.Session:'
  - signature: 'def get_session(self, *, app_name: str, user_id: str, session_id: str, config: typing.Optional[google.adk.sessions.base_session_service.GetSessionConfig]=None) -> typing.Optional[google.adk.sessions.session.Session]:'
  - signature: 'def list_sessions(self, *, app_name: str, user_id: typing.Optional[str]=None) -> google.adk.sessions.base_session_service.ListSessionsResponse:'
  - signature: 'def delete_session(self, *, app_name: str, user_id: str, session_id: str) -> None:'
  - signature: 'def append_event(self, session: google.adk.sessions.session.Session, event: google.adk.events.event.Event) -> google.adk.events.event.Event:'
  inherited_methods:
    BaseSessionService:
    - signature: 'def create_session(self, *, app_name: str, user_id: str, state: typing.Optional[dict[str, typing.Any]]=None, session_id: typing.Optional[str]=None) -> google.adk.sessions.session.Session:'
      docstring: "Creates a new session.\n\nArgs:\n  app_name: the name of the app.\n  user_id: the id of the user.\n  state: the initial state of the session.\n  session_id: the client-provided id of the session. If not provided, a\n    generated ID will be used.\n\nReturns:\n  session: The newly created session instance."
    - signature: 'def get_session(self, *, app_name: str, user_id: str, session_id: str, config: typing.Optional[google.adk.sessions.base_session_service.GetSessionConfig]=None) -> typing.Optional[google.adk.sessions.session.Session]:'
      docstring: Gets a session.
    - signature: 'def list_sessions(self, *, app_name: str, user_id: typing.Optional[str]=None) -> google.adk.sessions.base_session_service.ListSessionsResponse:'
      docstring: "Lists all the sessions for a user.\n\nArgs:\n  app_name: The name of the app.\n  user_id: The ID of the user. If not provided, lists all sessions for all\n    users.\n\nReturns:\n  A ListSessionsResponse containing the sessions."
    - signature: 'def delete_session(self, *, app_name: str, user_id: str, session_id: str) -> None:'
      docstring: Deletes a session.
    - signature: 'def append_event(self, session: google.adk.sessions.session.Session, event: google.adk.events.event.Event) -> google.adk.events.event.Event:'
      docstring: Appends an event to a session object.
  omitted_inherited_members_from:
  - abc.ABC
- rank: 1301
  id: google.adk.sessions.sqlite_session_service.SqliteSessionService.__init__
  name: __init__
  file_path: google/adk/sessions/sqlite_session_service.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: Initializes the SQLite session service with a database path.
  signature: 'def __init__(self, db_path: str):'
- rank: 1302
  id: google.adk.sessions.sqlite_session_service.SqliteSessionService.append_event
  name: append_event
  file_path: google/adk/sessions/sqlite_session_service.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def append_event(self, session: google.adk.sessions.session.Session, event: google.adk.events.event.Event) -> google.adk.events.event.Event:'
- rank: 1303
  id: google.adk.sessions.sqlite_session_service.SqliteSessionService.create_session
  name: create_session
  file_path: google/adk/sessions/sqlite_session_service.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def create_session(self, *, app_name: str, user_id: str, state: typing.Optional[dict[str, typing.Any]]=None, session_id: typing.Optional[str]=None) -> google.adk.sessions.session.Session:'
- rank: 1304
  id: google.adk.sessions.sqlite_session_service.SqliteSessionService.delete_session
  name: delete_session
  file_path: google/adk/sessions/sqlite_session_service.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def delete_session(self, *, app_name: str, user_id: str, session_id: str) -> None:'
- rank: 1305
  id: google.adk.sessions.sqlite_session_service.SqliteSessionService.get_session
  name: get_session
  file_path: google/adk/sessions/sqlite_session_service.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def get_session(self, *, app_name: str, user_id: str, session_id: str, config: typing.Optional[google.adk.sessions.base_session_service.GetSessionConfig]=None) -> typing.Optional[google.adk.sessions.session.Session]:'
- rank: 1306
  id: google.adk.sessions.sqlite_session_service.SqliteSessionService.list_sessions
  name: list_sessions
  file_path: google/adk/sessions/sqlite_session_service.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def list_sessions(self, *, app_name: str, user_id: typing.Optional[str]=None) -> google.adk.sessions.base_session_service.ListSessionsResponse:'
- rank: 1307
  id: google.adk.sessions.state
  name: state
  file_path: google/adk/sessions/state.py
  type: MODULE
  group: Orphan
  usage_score: 0
- rank: 1308
  id: google.adk.sessions.state.State
  name: State
  file_path: google/adk/sessions/state.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: A state dict that maintains the current value and the pending-commit delta.
  constructor_signature: 'def __init__(self, value: dict[str, typing.Any], delta: dict[str, typing.Any]):'
  methods:
  - signature: 'def setdefault(self, key: str, default: typing.Any) -> typing.Any:'
    docstring: Gets the value of a key, or sets it to a default if the key doesn't exist.
  - signature: 'def has_delta(self) -> bool:'
    docstring: Whether the state has pending delta.
  - signature: 'def get(self, key: str, default: typing.Any) -> typing.Any:'
    docstring: Returns the value of the state dict for the given key.
  - signature: 'def update(self, delta: dict[str, typing.Any]):'
    docstring: Updates the state dict with the given delta.
  - signature: 'def to_dict(self) -> dict[str, typing.Any]:'
    docstring: Returns the state dict.
  properties:
  - signature: 'APP_PREFIX: str'
  - signature: 'USER_PREFIX: str'
  - signature: 'TEMP_PREFIX: str'
- rank: 1309
  id: google.adk.sessions.state.State.__init__
  name: __init__
  file_path: google/adk/sessions/state.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: 'Args:

    value: The current value of the state dict.

    delta: The delta change to the current value that hasn''t been committed.'
  signature: 'def __init__(self, value: dict[str, typing.Any], delta: dict[str, typing.Any]):'
- rank: 1310
  id: google.adk.sessions.state.State.get
  name: get
  file_path: google/adk/sessions/state.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: Returns the value of the state dict for the given key.
  signature: 'def get(self, key: str, default: typing.Any) -> typing.Any:'
- rank: 1311
  id: google.adk.sessions.state.State.setdefault
  name: setdefault
  file_path: google/adk/sessions/state.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: Gets the value of a key, or sets it to a default if the key doesn't exist.
  signature: 'def setdefault(self, key: str, default: typing.Any) -> typing.Any:'
- rank: 1312
  id: google.adk.sessions.state.State.to_dict
  name: to_dict
  file_path: google/adk/sessions/state.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: Returns the state dict.
  signature: 'def to_dict(self) -> dict[str, typing.Any]:'
- rank: 1313
  id: google.adk.sessions.state.State.update
  name: update
  file_path: google/adk/sessions/state.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: Updates the state dict with the given delta.
  signature: 'def update(self, delta: dict[str, typing.Any]):'
- rank: 1314
  id: google.adk.sessions.vertex_ai_session_service
  name: vertex_ai_session_service
  file_path: google/adk/sessions/vertex_ai_session_service.py
  type: MODULE
  group: Orphan
  usage_score: 0
- rank: 1315
  id: google.adk.sessions.vertex_ai_session_service.VertexAiSessionService.__init__
  name: __init__
  file_path: google/adk/sessions/vertex_ai_session_service.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Initializes the VertexAiSessionService.\n\nArgs:\n  project: The project id of the project to use.\n  location: The location of the project to use.\n  agent_engine_id: The resource ID of the agent engine to use.\n  express_mode_api_key: The API key to use for Express Mode. If not\n    provided, the API key from the GOOGLE_API_KEY environment variable will\n    be used. It will only be used if GOOGLE_GENAI_USE_VERTEXAI is true.\n    Do not use Google AI Studio API key for this field. For more details,\n    visit\n    https://cloud.google.com/vertex-ai/generative-ai/docs/start/express-mode/overview"
  signature: 'def __init__(self, project: typing.Optional[str], location: typing.Optional[str], agent_engine_id: typing.Optional[str], *, express_mode_api_key: typing.Optional[str]=None):'
- rank: 1316
  id: google.adk.sessions.vertex_ai_session_service.VertexAiSessionService.append_event
  name: append_event
  file_path: google/adk/sessions/vertex_ai_session_service.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def append_event(self, session: google.adk.sessions.session.Session, event: google.adk.events.event.Event) -> google.adk.events.event.Event:'
- rank: 1317
  id: google.adk.sessions.vertex_ai_session_service.VertexAiSessionService.create_session
  name: create_session
  file_path: google/adk/sessions/vertex_ai_session_service.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Creates a new session.\n\nArgs:\n  app_name: The name of the application.\n  user_id: The ID of the user.\n  state: The initial state of the session.\n  session_id: The ID of the session.\n  **kwargs: Additional arguments to pass to the session creation. E.g. set\n    expire_time='2025-10-01T00:00:00Z' to set the session expiration time.\n    See https://cloud.google.com/vertex-ai/generative-ai/docs/reference/rest/v1beta1/projects.locations.reasoningEngines.sessions\n    for more details.\nReturns:\n  The created session."
  signature: 'def create_session(self, *, app_name: str, user_id: str, state: typing.Optional[dict[str, typing.Any]]=None, session_id: typing.Optional[str]=None) -> google.adk.sessions.session.Session:'
- rank: 1318
  id: google.adk.sessions.vertex_ai_session_service.VertexAiSessionService.delete_session
  name: delete_session
  file_path: google/adk/sessions/vertex_ai_session_service.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def delete_session(self, *, app_name: str, user_id: str, session_id: str) -> None:'
- rank: 1319
  id: google.adk.sessions.vertex_ai_session_service.VertexAiSessionService.get_session
  name: get_session
  file_path: google/adk/sessions/vertex_ai_session_service.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def get_session(self, *, app_name: str, user_id: str, session_id: str, config: typing.Optional[google.adk.sessions.base_session_service.GetSessionConfig]=None) -> typing.Optional[google.adk.sessions.session.Session]:'
- rank: 1320
  id: google.adk.sessions.vertex_ai_session_service.VertexAiSessionService.list_sessions
  name: list_sessions
  file_path: google/adk/sessions/vertex_ai_session_service.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def list_sessions(self, *, app_name: str, user_id: typing.Optional[str]=None) -> google.adk.sessions.base_session_service.ListSessionsResponse:'
- rank: 1321
  id: google.adk.telemetry
  name: telemetry
  file_path: google/adk/telemetry/__init__.py
  type: MODULE
  group: Orphan
  usage_score: 0
- rank: 1322
  id: google.adk.telemetry.google_cloud
  name: google_cloud
  file_path: google/adk/telemetry/google_cloud.py
  type: MODULE
  group: Orphan
  usage_score: 0
  methods:
  - signature: 'def get_gcp_exporters(enable_cloud_tracing: bool, enable_cloud_metrics: bool, enable_cloud_logging: bool, google_auth: typing.Optional[tuple[google.auth.credentials.Credentials, str]]) -> google.adk.telemetry.setup.OTelHooks:'
    docstring: "Returns GCP OTel exporters to be used in the app.\n\nArgs:\n  enable_tracing: whether to enable tracing to Cloud Trace.\n  enable_metrics: whether to enable reporting metrics to Cloud Monitoring.\n  enable_logging: whether to enable sending logs to Cloud Logging.\n  google_auth: optional custom credentials and project_id. google.auth.default() used when this is omitted."
  - signature: 'def get_gcp_resource(project_id: typing.Optional[str]) -> opentelemetry.sdk.resources.Resource:'
    docstring: "Returns OTEL with attributes specified in the following order (attributes specified later, overwrite those specified earlier):\n1. Populates gcp.project_id attribute from the project_id argument if present.\n2. OTELResourceDetector populates resource labels from environment variables like OTEL_SERVICE_NAME and OTEL_RESOURCE_ATTRIBUTES.\n3. GCP detector adds attributes corresponding to a correct monitored resource if ADK runs on one of supported platforms (e.g. GCE, GKE, CloudRun).\n\nArgs:\n  project_id: project id to fill out as `gcp.project_id` on the OTEL resource.\n  This may be overwritten by OTELResourceDetector, if `gcp.project_id` is present in `OTEL_RESOURCE_ATTRIBUTES` env var."
- rank: 1323
  id: google.adk.telemetry.google_cloud.get_gcp_exporters
  name: get_gcp_exporters
  file_path: google/adk/telemetry/google_cloud.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Returns GCP OTel exporters to be used in the app.\n\nArgs:\n  enable_tracing: whether to enable tracing to Cloud Trace.\n  enable_metrics: whether to enable reporting metrics to Cloud Monitoring.\n  enable_logging: whether to enable sending logs to Cloud Logging.\n  google_auth: optional custom credentials and project_id. google.auth.default() used when this is omitted."
  signature: 'def get_gcp_exporters(enable_cloud_tracing: bool, enable_cloud_metrics: bool, enable_cloud_logging: bool, google_auth: typing.Optional[tuple[google.auth.credentials.Credentials, str]]) -> google.adk.telemetry.setup.OTelHooks:'
- rank: 1324
  id: google.adk.telemetry.google_cloud.get_gcp_resource
  name: get_gcp_resource
  file_path: google/adk/telemetry/google_cloud.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Returns OTEL with attributes specified in the following order (attributes specified later, overwrite those specified earlier):\n1. Populates gcp.project_id attribute from the project_id argument if present.\n2. OTELResourceDetector populates resource labels from environment variables like OTEL_SERVICE_NAME and OTEL_RESOURCE_ATTRIBUTES.\n3. GCP detector adds attributes corresponding to a correct monitored resource if ADK runs on one of supported platforms (e.g. GCE, GKE, CloudRun).\n\nArgs:\n  project_id: project id to fill out as `gcp.project_id` on the OTEL resource.\n  This may be overwritten by OTELResourceDetector, if `gcp.project_id` is present in `OTEL_RESOURCE_ATTRIBUTES` env var."
  signature: 'def get_gcp_resource(project_id: typing.Optional[str]) -> opentelemetry.sdk.resources.Resource:'
- rank: 1325
  id: google.adk.telemetry.setup
  name: setup
  file_path: google/adk/telemetry/setup.py
  type: MODULE
  group: Orphan
  usage_score: 0
  methods:
  - signature: 'def maybe_set_otel_providers(otel_hooks_to_setup: list[google.adk.telemetry.setup.OTelHooks], otel_resource: typing.Optional[opentelemetry.sdk.resources.Resource]):'
    docstring: "Sets up OTel providers if hooks for a given telemetry type were\npassed.\n\nAdditionally adds generic OTLP exporters based on following env variables:\nOTEL_EXPORTER_OTLP_ENDPOINT\nOTEL_EXPORTER_OTLP_TRACES_ENDPOINT\nOTEL_EXPORTER_OTLP_METRICS_ENDPOINT\nOTEL_EXPORTER_OTLP_LOGS_ENDPOINT\nSee https://opentelemetry.io/docs/languages/sdk-configuration/otlp-exporter/\nfor how they are used.\n\nIf a provider for a specific telemetry type was already globally set -\nthis function will not override it or register more exporters.\n\nArgs:\n  otel_hooks_to_setup: per-telemetry-type processors and readers to be added\n  to OTel providers. If no hooks for a specific telemetry type are passed -\n  provider will not be set.\n  otel_resource: OTel resource to use in providers.\n  If empty - default OTel resource detection will be used."
- rank: 1326
  id: google.adk.telemetry.setup.OTelHooks
  name: OTelHooks
  file_path: google/adk/telemetry/setup.py
  type: CLASS
  group: Orphan
  usage_score: 0
  constructor_signature: 'def __init__(self, *, span_processors: list[opentelemetry.sdk.trace.SpanProcessor] = list(), metric_readers: list[opentelemetry.sdk.metrics.export.MetricReader] = list(), log_record_processors: list[opentelemetry.sdk._logs.LogRecordProcessor] = list()):'
  properties:
  - signature: 'span_processors: list[opentelemetry.sdk.trace.SpanProcessor]'
  - signature: 'metric_readers: list[opentelemetry.sdk.metrics.export.MetricReader]'
  - signature: 'log_record_processors: list[opentelemetry.sdk._logs.LogRecordProcessor]'
- rank: 1327
  id: google.adk.telemetry.setup.maybe_set_otel_providers
  name: maybe_set_otel_providers
  file_path: google/adk/telemetry/setup.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Sets up OTel providers if hooks for a given telemetry type were\npassed.\n\nAdditionally adds generic OTLP exporters based on following env variables:\nOTEL_EXPORTER_OTLP_ENDPOINT\nOTEL_EXPORTER_OTLP_TRACES_ENDPOINT\nOTEL_EXPORTER_OTLP_METRICS_ENDPOINT\nOTEL_EXPORTER_OTLP_LOGS_ENDPOINT\nSee https://opentelemetry.io/docs/languages/sdk-configuration/otlp-exporter/\nfor how they are used.\n\nIf a provider for a specific telemetry type was already globally set -\nthis function will not override it or register more exporters.\n\nArgs:\n  otel_hooks_to_setup: per-telemetry-type processors and readers to be added\n  to OTel providers. If no hooks for a specific telemetry type are passed -\n  provider will not be set.\n  otel_resource: OTel resource to use in providers.\n  If empty - default OTel resource detection will be used."
  signature: 'def maybe_set_otel_providers(otel_hooks_to_setup: list[google.adk.telemetry.setup.OTelHooks], otel_resource: typing.Optional[opentelemetry.sdk.resources.Resource]):'
- rank: 1328
  id: google.adk.telemetry.tracing
  name: tracing
  file_path: google/adk/telemetry/tracing.py
  type: MODULE
  group: Orphan
  usage_score: 0
  methods:
  - signature: 'def trace_agent_invocation(span: opentelemetry.trace.Span, agent: google.adk.agents.base_agent.BaseAgent, ctx: google.adk.agents.invocation_context.InvocationContext) -> None:'
    docstring: "Sets span attributes immediately available on agent invocation according to OTEL semconv version 1.37.\n\nArgs:\n  span: Span on which attributes are set.\n  agent: Agent from which attributes are gathered.\n  ctx: InvocationContext from which attributes are gathered.\n\nInference related fields are not set, due to their planned removal from invoke_agent span:\nhttps://github.com/open-telemetry/semantic-conventions/issues/2632\n\n`gen_ai.agent.id` is not set because currently it's unclear what attributes this field should have, specifically:\n- In which scope should it be unique (globally, given project, given agentic flow, given deployment).\n- Should it be unchanging between deployments, and how this should this be achieved.\n\n`gen_ai.data_source.id` is not set because it's not available.\nClosest type which could contain this information is types.GroundingMetadata, which does not have an ID.\n\n`server.*` attributes are not set pending confirmation from aabmass."
  - signature: 'def trace_tool_call(tool: google.adk.tools.base_tool.BaseTool, args: dict[str, typing.Any], function_response_event: typing.Optional[google.adk.events.event.Event]):'
    docstring: "Traces tool call.\n\nArgs:\n  tool: The tool that was called.\n  args: The arguments to the tool call.\n  function_response_event: The event with the function response details."
  - signature: 'def trace_merged_tool_calls(response_event_id: str, function_response_event: google.adk.events.event.Event):'
    docstring: "Traces merged tool call events.\n\nCalling this function is not needed for telemetry purposes. This is provided\nfor preventing /debug/trace requests (typically sent by web UI).\n\nArgs:\n  response_event_id: The ID of the response event.\n  function_response_event: The merged response event."
  - signature: 'def trace_call_llm(invocation_context: google.adk.agents.invocation_context.InvocationContext, event_id: str, llm_request: google.adk.models.llm_request.LlmRequest, llm_response: google.adk.models.llm_response.LlmResponse):'
    docstring: "Traces a call to the LLM.\n\nThis function records details about the LLM request and response as\nattributes on the current OpenTelemetry span.\n\nArgs:\n  invocation_context: The invocation context for the current agent run.\n  event_id: The ID of the event.\n  llm_request: The LLM request object.\n  llm_response: The LLM response object."
  - signature: 'def trace_send_data(invocation_context: google.adk.agents.invocation_context.InvocationContext, event_id: str, data: list[google.genai.types.Content]):'
    docstring: "Traces the sending of data to the agent.\n\nThis function records details about the data sent to the agent as\nattributes on the current OpenTelemetry span.\n\nArgs:\n  invocation_context: The invocation context for the current agent run.\n  event_id: The ID of the event.\n  data: A list of content objects."
- rank: 1329
  id: google.adk.telemetry.tracing.trace_agent_invocation
  name: trace_agent_invocation
  file_path: google/adk/telemetry/tracing.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Sets span attributes immediately available on agent invocation according to OTEL semconv version 1.37.\n\nArgs:\n  span: Span on which attributes are set.\n  agent: Agent from which attributes are gathered.\n  ctx: InvocationContext from which attributes are gathered.\n\nInference related fields are not set, due to their planned removal from invoke_agent span:\nhttps://github.com/open-telemetry/semantic-conventions/issues/2632\n\n`gen_ai.agent.id` is not set because currently it's unclear what attributes this field should have, specifically:\n- In which scope should it be unique (globally, given project, given agentic flow, given deployment).\n- Should it be unchanging between deployments, and how this should this be achieved.\n\n`gen_ai.data_source.id` is not set because it's not available.\nClosest type which could contain this information is types.GroundingMetadata, which does not have an ID.\n\n`server.*` attributes are not set pending confirmation from aabmass."
  signature: 'def trace_agent_invocation(span: opentelemetry.trace.Span, agent: google.adk.agents.base_agent.BaseAgent, ctx: google.adk.agents.invocation_context.InvocationContext) -> None:'
- rank: 1330
  id: google.adk.telemetry.tracing.trace_call_llm
  name: trace_call_llm
  file_path: google/adk/telemetry/tracing.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Traces a call to the LLM.\n\nThis function records details about the LLM request and response as\nattributes on the current OpenTelemetry span.\n\nArgs:\n  invocation_context: The invocation context for the current agent run.\n  event_id: The ID of the event.\n  llm_request: The LLM request object.\n  llm_response: The LLM response object."
  signature: 'def trace_call_llm(invocation_context: google.adk.agents.invocation_context.InvocationContext, event_id: str, llm_request: google.adk.models.llm_request.LlmRequest, llm_response: google.adk.models.llm_response.LlmResponse):'
  aliases:
  - google.adk.telemetry.trace_call_llm
- rank: 1331
  id: google.adk.telemetry.tracing.trace_merged_tool_calls
  name: trace_merged_tool_calls
  file_path: google/adk/telemetry/tracing.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Traces merged tool call events.\n\nCalling this function is not needed for telemetry purposes. This is provided\nfor preventing /debug/trace requests (typically sent by web UI).\n\nArgs:\n  response_event_id: The ID of the response event.\n  function_response_event: The merged response event."
  signature: 'def trace_merged_tool_calls(response_event_id: str, function_response_event: google.adk.events.event.Event):'
  aliases:
  - google.adk.telemetry.trace_merged_tool_calls
- rank: 1332
  id: google.adk.telemetry.tracing.trace_send_data
  name: trace_send_data
  file_path: google/adk/telemetry/tracing.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Traces the sending of data to the agent.\n\nThis function records details about the data sent to the agent as\nattributes on the current OpenTelemetry span.\n\nArgs:\n  invocation_context: The invocation context for the current agent run.\n  event_id: The ID of the event.\n  data: A list of content objects."
  signature: 'def trace_send_data(invocation_context: google.adk.agents.invocation_context.InvocationContext, event_id: str, data: list[google.genai.types.Content]):'
  aliases:
  - google.adk.telemetry.trace_send_data
- rank: 1333
  id: google.adk.telemetry.tracing.trace_tool_call
  name: trace_tool_call
  file_path: google/adk/telemetry/tracing.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Traces tool call.\n\nArgs:\n  tool: The tool that was called.\n  args: The arguments to the tool call.\n  function_response_event: The event with the function response details."
  signature: 'def trace_tool_call(tool: google.adk.tools.base_tool.BaseTool, args: dict[str, typing.Any], function_response_event: typing.Optional[google.adk.events.event.Event]):'
  aliases:
  - google.adk.telemetry.trace_tool_call
- rank: 1334
  id: google.adk.tools
  name: tools
  file_path: google/adk/tools/__init__.py
  type: MODULE
  group: Orphan
  usage_score: 0
- rank: 1335
  id: google.adk.tools.agent_tool
  name: agent_tool
  file_path: google/adk/tools/agent_tool.py
  type: MODULE
  group: Orphan
  usage_score: 0
- rank: 1336
  id: google.adk.tools.agent_tool.AgentTool.__init__
  name: __init__
  file_path: google/adk/tools/agent_tool.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def __init__(self, agent: google.adk.agents.base_agent.BaseAgent, skip_summarization: bool, *, include_plugins: bool=True):'
- rank: 1337
  id: google.adk.tools.agent_tool.AgentTool.from_config
  name: from_config
  file_path: google/adk/tools/agent_tool.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def from_config(cls, config: google.adk.tools.tool_configs.ToolArgsConfig, config_abs_path: str) -> google.adk.tools.agent_tool.AgentTool:'
- rank: 1338
  id: google.adk.tools.agent_tool.AgentTool.run_async
  name: run_async
  file_path: google/adk/tools/agent_tool.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def run_async(self, *, args: dict[str, typing.Any], tool_context: google.adk.tools.tool_context.ToolContext) -> typing.Any:'
- rank: 1339
  id: google.adk.tools.agent_tool.AgentToolConfig
  name: AgentToolConfig
  file_path: google/adk/tools/agent_tool.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'The config for the AgentTool.


    [Note: Inherited members from pydantic.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, agent: google.adk.agents.common_configs.AgentRefConfig, skip_summarization: bool = False, include_plugins: bool = True):'
  properties:
  - signature: 'agent: google.adk.agents.common_configs.AgentRefConfig'
    docstring: The reference to the agent instance.
  - signature: 'skip_summarization: bool'
    docstring: Whether to skip summarization of the agent output.
  - signature: 'include_plugins: bool'
    docstring: Whether to include plugins from parent runner context.
  inherited_properties:
    BaseToolConfig:
    - signature: 'model_config: pydantic.ConfigDict'
    BaseModel:
    - signature: 'model_config: pydantic.ConfigDict'
  omitted_inherited_members_from:
  - pydantic.BaseModel
- rank: 1340
  id: google.adk.tools.api_registry
  name: api_registry
  file_path: google/adk/tools/api_registry.py
  type: MODULE
  group: Orphan
  usage_score: 0
- rank: 1341
  id: google.adk.tools.api_registry.ApiRegistry
  name: ApiRegistry
  file_path: google/adk/tools/api_registry.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: Registry that provides McpToolsets for MCP servers registered in API Registry.
  constructor_signature: 'def __init__(self, api_registry_project_id: str, location: str, header_provider: typing.Optional[Callable[[ReadonlyContext], typing.Dict[str, str]]]):'
  methods:
  - signature: 'def get_toolset(self, mcp_server_name: str, tool_filter: typing.Optional[typing.Union[google.adk.tools.base_toolset.ToolPredicate, typing.List[str]]], tool_name_prefix: typing.Optional[str]) -> google.adk.tools.mcp_tool.mcp_toolset.McpToolset:'
    docstring: "Return the MCP Toolset based on the params.\n\nArgs:\n  mcp_server_name: Filter to select the MCP server name to get tools\n    from.\n  tool_filter: Optional filter to select specific tools. Can be a list of\n    tool names or a ToolPredicate function.\n  tool_name_prefix: Optional prefix to prepend to the names of the tools\n    returned by the toolset.\n\nReturns:\n  McpToolset: A toolset for the MCP server specified."
- rank: 1342
  id: google.adk.tools.api_registry.ApiRegistry.__init__
  name: __init__
  file_path: google/adk/tools/api_registry.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Initialize the API Registry.\n\nArgs:\n  api_registry_project_id: The project ID for the Google Cloud API Registry.\n  location: The location of the API Registry resources.\n  header_provider: Optional function to provide additional headers for MCP\n    server calls."
  signature: 'def __init__(self, api_registry_project_id: str, location: str, header_provider: typing.Optional[Callable[[ReadonlyContext], typing.Dict[str, str]]]):'
- rank: 1343
  id: google.adk.tools.api_registry.ApiRegistry.get_toolset
  name: get_toolset
  file_path: google/adk/tools/api_registry.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Return the MCP Toolset based on the params.\n\nArgs:\n  mcp_server_name: Filter to select the MCP server name to get tools\n    from.\n  tool_filter: Optional filter to select specific tools. Can be a list of\n    tool names or a ToolPredicate function.\n  tool_name_prefix: Optional prefix to prepend to the names of the tools\n    returned by the toolset.\n\nReturns:\n  McpToolset: A toolset for the MCP server specified."
  signature: 'def get_toolset(self, mcp_server_name: str, tool_filter: typing.Optional[typing.Union[google.adk.tools.base_toolset.ToolPredicate, typing.List[str]]], tool_name_prefix: typing.Optional[str]) -> google.adk.tools.mcp_tool.mcp_toolset.McpToolset:'
- rank: 1344
  id: google.adk.tools.apihub_tool
  name: apihub_tool
  file_path: google/adk/tools/apihub_tool/__init__.py
  type: MODULE
  group: Orphan
  usage_score: 0
- rank: 1345
  id: google.adk.tools.apihub_tool.apihub_toolset
  name: apihub_toolset
  file_path: google/adk/tools/apihub_tool/apihub_toolset.py
  type: MODULE
  group: Orphan
  usage_score: 0
- rank: 1346
  id: google.adk.tools.apihub_tool.apihub_toolset.APIHubToolset.__init__
  name: __init__
  file_path: google/adk/tools/apihub_tool/apihub_toolset.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Initializes the APIHubTool with the given parameters.\n\nExamples::\n\n  apihub_toolset = APIHubToolset(\n      apihub_resource_name=\"projects/test-project/locations/us-central1/apis/test-api\",\n      service_account_json=\"...\",\n  )\n\n  # Get all available tools\n  agent = LlmAgent(tools=[apihub_toolset])\n\n  apihub_toolset = APIHubToolset(\n      apihub_resource_name=\"projects/test-project/locations/us-central1/apis/test-api\",\n      service_account_json=\"...\",\n      tool_filter = ['my_tool']\n  )\n  # Get a specific tool\n  agent = LlmAgent(tools=[\n      ...,\n      apihub_toolset,\n  ])\n\n**apihub_resource_name** is the resource name from API Hub. It must include\nAPI name, and can optionally include API version and spec name.\n\n- If apihub_resource_name includes a spec resource name, the content of that\n  spec will be used for generating the tools.\n- If apihub_resource_name includes only an api or a version name, the\n  first spec of the first version of\
    \ that API will be used.\n\nExample:\n\n* projects/xxx/locations/us-central1/apis/apiname/...\n* https://console.cloud.google.com/apigee/api-hub/apis/apiname?project=xxx\n\nArgs:\n    apihub_resource_name: The resource name of the API in API Hub.\n      Example: ``projects/test-project/locations/us-central1/apis/test-api``.\n    access_token: Google Access token. Generate with gcloud cli\n      ``gcloud auth print-access-token``. Used for fetching API Specs from API Hub.\n    service_account_json: The service account config as a json string.\n      Required if not using default service credential. It is used for\n      creating the API Hub client and fetching the API Specs from API Hub.\n    apihub_client: Optional custom API Hub client.\n    name: Name of the toolset. Optional.\n    description: Description of the toolset. Optional.\n    auth_scheme: Auth scheme that applies to all the tool in the toolset.\n    auth_credential: Auth credential that applies to all the tool in the\n \
    \     toolset.\n    lazy_load_spec: If True, the spec will be loaded lazily when needed.\n      Otherwise, the spec will be loaded immediately and the tools will be\n      generated during initialization.\n    tool_filter: The filter used to filter the tools in the toolset. It can\n      be either a tool predicate or a list of tool names of the tools to\n      expose."
  signature: 'def __init__(self, *, apihub_resource_name: str, access_token: typing.Optional[str]=None, service_account_json: typing.Optional[str]=None, name: str='''', description: str='''', lazy_load_spec=False, auth_scheme: typing.Optional[google.adk.auth.auth_schemes.AuthScheme]=None, auth_credential: typing.Optional[google.adk.auth.auth_credential.AuthCredential]=None, apihub_client: typing.Optional[google.adk.tools.apihub_tool.clients.apihub_client.APIHubClient]=None, tool_filter: typing.Optional[typing.Union[google.adk.tools.base_toolset.ToolPredicate, typing.List[str]]]=None):'
- rank: 1347
  id: google.adk.tools.apihub_tool.apihub_toolset.APIHubToolset.get_tools
  name: get_tools
  file_path: google/adk/tools/apihub_tool/apihub_toolset.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Retrieves all available tools.\n\nReturns:\n    A list of all available RestApiTool objects."
  signature: 'def get_tools(self, readonly_context: typing.Optional[google.adk.agents.readonly_context.ReadonlyContext]) -> typing.List[google.adk.tools.openapi_tool.openapi_spec_parser.rest_api_tool.RestApiTool]:'
- rank: 1348
  id: google.adk.tools.apihub_tool.clients
  name: clients
  file_path: google/adk/tools/apihub_tool/clients/__init__.py
  type: MODULE
  group: Orphan
  usage_score: 0
- rank: 1349
  id: google.adk.tools.apihub_tool.clients.apihub_client
  name: apihub_client
  file_path: google/adk/tools/apihub_tool/clients/apihub_client.py
  type: MODULE
  group: Orphan
  usage_score: 0
- rank: 1350
  id: google.adk.tools.apihub_tool.clients.apihub_client.APIHubClient
  name: APIHubClient
  file_path: google/adk/tools/apihub_tool/clients/apihub_client.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Client for interacting with the API Hub service.


    [Note: Inherited members from ABC are omitted.]'
  constructor_signature: 'def __init__(self, *, access_token: typing.Optional[str]=None, service_account_json: typing.Optional[str]=None):'
  methods:
  - signature: 'def get_spec_content(self, path: str) -> str:'
    docstring: "From a given path, get the first spec available in the API Hub.\n\n- If path includes /apis/apiname, get the first spec of that API\n- If path includes /apis/apiname/versions/versionname, get the first spec\n  of that API Version\n- If path includes /apis/apiname/versions/versionname/specs/specname, return\n  that spec\n\nPath can be resource name (projects/xxx/locations/us-central1/apis/apiname),\nand URL from the UI\n(https://console.cloud.google.com/apigee/api-hub/apis/apiname?project=xxx)\n\nArgs:\n    path: The path to the API, API Version, or API Spec.\n\nReturns:\n    The content of the first spec available in the API Hub."
  - signature: 'def list_apis(self, project: str, location: str) -> typing.List[typing.Dict[str, typing.Any]]:'
    docstring: "Lists all APIs in the specified project and location.\n\nArgs:\n    project: The Google Cloud project name.\n    location: The location of the API Hub resources (e.g., 'us-central1').\n\nReturns:\n    A list of API dictionaries, or an empty list if an error occurs."
  - signature: 'def get_api(self, api_resource_name: str) -> typing.Dict[str, typing.Any]:'
    docstring: "Get API detail by API name.\n\nArgs:\n    api_resource_name: Resource name of this API, like\n      projects/xxx/locations/us-central1/apis/apiname\n\nReturns:\n    An API and details in a dict."
  - signature: 'def get_api_version(self, api_version_name: str) -> typing.Dict[str, typing.Any]:'
    docstring: "Gets details of a specific API version.\n\nArgs:\n    api_version_name: The resource name of the API version.\n\nReturns:\n    The API version details as a dictionary, or an empty dictionary if an\n    error occurs."
  inherited_methods:
    BaseAPIHubClient:
    - signature: 'def get_spec_content(self, resource_name: str) -> str:'
      docstring: From a given resource name, get the spec in the API Hub.
  omitted_inherited_members_from:
  - ABC
- rank: 1351
  id: google.adk.tools.apihub_tool.clients.apihub_client.APIHubClient.__init__
  name: __init__
  file_path: google/adk/tools/apihub_tool/clients/apihub_client.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Initializes the APIHubClient.\n\nYou must set either access_token or service_account_json. This\ncredential is used for sending request to API Hub API.\n\nArgs:\n    access_token: Google Access token. Generate with gcloud cli `gcloud auth\n      print-access-token`. Useful for local testing.\n    service_account_json: The service account configuration as a dictionary.\n      Required if not using default service credential."
  signature: 'def __init__(self, *, access_token: typing.Optional[str]=None, service_account_json: typing.Optional[str]=None):'
- rank: 1352
  id: google.adk.tools.apihub_tool.clients.apihub_client.APIHubClient.get_api
  name: get_api
  file_path: google/adk/tools/apihub_tool/clients/apihub_client.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Get API detail by API name.\n\nArgs:\n    api_resource_name: Resource name of this API, like\n      projects/xxx/locations/us-central1/apis/apiname\n\nReturns:\n    An API and details in a dict."
  signature: 'def get_api(self, api_resource_name: str) -> typing.Dict[str, typing.Any]:'
- rank: 1353
  id: google.adk.tools.apihub_tool.clients.apihub_client.APIHubClient.get_api_version
  name: get_api_version
  file_path: google/adk/tools/apihub_tool/clients/apihub_client.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Gets details of a specific API version.\n\nArgs:\n    api_version_name: The resource name of the API version.\n\nReturns:\n    The API version details as a dictionary, or an empty dictionary if an\n    error occurs."
  signature: 'def get_api_version(self, api_version_name: str) -> typing.Dict[str, typing.Any]:'
- rank: 1354
  id: google.adk.tools.apihub_tool.clients.apihub_client.APIHubClient.get_spec_content
  name: get_spec_content
  file_path: google/adk/tools/apihub_tool/clients/apihub_client.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "From a given path, get the first spec available in the API Hub.\n\n- If path includes /apis/apiname, get the first spec of that API\n- If path includes /apis/apiname/versions/versionname, get the first spec\n  of that API Version\n- If path includes /apis/apiname/versions/versionname/specs/specname, return\n  that spec\n\nPath can be resource name (projects/xxx/locations/us-central1/apis/apiname),\nand URL from the UI\n(https://console.cloud.google.com/apigee/api-hub/apis/apiname?project=xxx)\n\nArgs:\n    path: The path to the API, API Version, or API Spec.\n\nReturns:\n    The content of the first spec available in the API Hub."
  signature: 'def get_spec_content(self, path: str) -> str:'
- rank: 1355
  id: google.adk.tools.apihub_tool.clients.apihub_client.APIHubClient.list_apis
  name: list_apis
  file_path: google/adk/tools/apihub_tool/clients/apihub_client.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Lists all APIs in the specified project and location.\n\nArgs:\n    project: The Google Cloud project name.\n    location: The location of the API Hub resources (e.g., 'us-central1').\n\nReturns:\n    A list of API dictionaries, or an empty list if an error occurs."
  signature: 'def list_apis(self, project: str, location: str) -> typing.List[typing.Dict[str, typing.Any]]:'
- rank: 1356
  id: google.adk.tools.apihub_tool.clients.apihub_client.BaseAPIHubClient
  name: BaseAPIHubClient
  file_path: google/adk/tools/apihub_tool/clients/apihub_client.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Base class for API Hub clients.


    [Note: Inherited members from ABC are omitted.]'
  methods:
  - signature: 'def get_spec_content(self, resource_name: str) -> str:'
    docstring: From a given resource name, get the spec in the API Hub.
  omitted_inherited_members_from:
  - ABC
- rank: 1357
  id: google.adk.tools.apihub_tool.clients.secret_client
  name: secret_client
  file_path: google/adk/tools/apihub_tool/clients/secret_client.py
  type: MODULE
  group: Orphan
  usage_score: 0
- rank: 1358
  id: google.adk.tools.apihub_tool.clients.secret_client.SecretManagerClient
  name: SecretManagerClient
  file_path: google/adk/tools/apihub_tool/clients/secret_client.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: "A client for interacting with Google Cloud Secret Manager.\n\nThis class provides a simplified interface for retrieving secrets from\nSecret Manager, handling authentication using either a service account\nJSON keyfile (passed as a string) or a preexisting authorization token.\n\nAttributes:\n    _credentials:  Google Cloud credentials object (ServiceAccountCredentials\n      or Credentials).\n    _client: Secret Manager client instance."
  constructor_signature: 'def __init__(self, service_account_json: typing.Optional[str], auth_token: typing.Optional[str]):'
  methods:
  - signature: 'def get_secret(self, resource_name: str) -> str:'
    docstring: "Retrieves a secret from Google Cloud Secret Manager.\n\nArgs:\n    resource_name: The full resource name of the secret, in the format\n      \"projects/*/secrets/*/versions/*\".  Usually you want the \"latest\"\n      version, e.g.,\n      \"projects/my-project/secrets/my-secret/versions/latest\".\n\nReturns:\n    The secret payload as a string.\n\nRaises:\n    google.api_core.exceptions.GoogleAPIError: If the Secret Manager API\n        returns an error (e.g., secret not found, permission denied).\n    Exception: For other unexpected errors."
- rank: 1359
  id: google.adk.tools.apihub_tool.clients.secret_client.SecretManagerClient.__init__
  name: __init__
  file_path: google/adk/tools/apihub_tool/clients/secret_client.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Initializes the SecretManagerClient.\n\nArgs:\n    service_account_json:  The content of a service account JSON keyfile (as\n      a string), not the file path.  Must be valid JSON.\n    auth_token: An existing Google Cloud authorization token.\n\nRaises:\n    ValueError: If neither `service_account_json` nor `auth_token` is\n    provided,\n        or if both are provided.  Also raised if the service_account_json\n        is not valid JSON.\n    google.auth.exceptions.GoogleAuthError: If authentication fails."
  signature: 'def __init__(self, service_account_json: typing.Optional[str], auth_token: typing.Optional[str]):'
- rank: 1360
  id: google.adk.tools.apihub_tool.clients.secret_client.SecretManagerClient.get_secret
  name: get_secret
  file_path: google/adk/tools/apihub_tool/clients/secret_client.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Retrieves a secret from Google Cloud Secret Manager.\n\nArgs:\n    resource_name: The full resource name of the secret, in the format\n      \"projects/*/secrets/*/versions/*\".  Usually you want the \"latest\"\n      version, e.g.,\n      \"projects/my-project/secrets/my-secret/versions/latest\".\n\nReturns:\n    The secret payload as a string.\n\nRaises:\n    google.api_core.exceptions.GoogleAPIError: If the Secret Manager API\n        returns an error (e.g., secret not found, permission denied).\n    Exception: For other unexpected errors."
  signature: 'def get_secret(self, resource_name: str) -> str:'
- rank: 1361
  id: google.adk.tools.application_integration_tool
  name: application_integration_tool
  file_path: google/adk/tools/application_integration_tool/__init__.py
  type: MODULE
  group: Orphan
  usage_score: 0
- rank: 1362
  id: google.adk.tools.application_integration_tool.application_integration_toolset
  name: application_integration_toolset
  file_path: google/adk/tools/application_integration_tool/application_integration_toolset.py
  type: MODULE
  group: Orphan
  usage_score: 0
- rank: 1363
  id: google.adk.tools.application_integration_tool.application_integration_toolset.ApplicationIntegrationToolset.__init__
  name: __init__
  file_path: google/adk/tools/application_integration_tool/application_integration_toolset.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Args:\n\nArgs:\n    project: The GCP project ID.\n    location: The GCP location.\n    integration: The integration name.\n    triggers: The list of trigger names in the integration.\n    connection: The connection name.\n    entity_operations: The entity operations supported by the connection.\n    actions: The actions supported by the connection.\n    tool_name_prefix: The name prefix of the generated tools.\n    tool_instructions: The instructions for the tool.\n    service_account_json: The service account configuration as a dictionary.\n      Required if not using default service credential. Used for fetching\n      the Application Integration or Integration Connector resource.\n    tool_filter: The filter used to filter the tools in the toolset. It can\n      be either a tool predicate or a list of tool names of the tools to\n      expose.\n\nRaises:\n    ValueError: If none of the following conditions are met:\n      - ``integration`` is provided.\n      - ``connection``\
    \ is provided and at least one of ``entity_operations``\n        or ``actions`` is provided.\n    Exception: If there is an error during the initialization of the\n      integration or connection client."
  signature: 'def __init__(self, project: str, location: str, integration: typing.Optional[str], triggers: typing.Optional[typing.List[str]], connection: typing.Optional[str], entity_operations: typing.Optional[str], actions: typing.Optional[list[str]], tool_name_prefix: typing.Optional[str], tool_instructions: typing.Optional[str], service_account_json: typing.Optional[str], auth_scheme: typing.Optional[google.adk.auth.auth_schemes.AuthScheme], auth_credential: typing.Optional[google.adk.auth.auth_credential.AuthCredential], tool_filter: typing.Optional[typing.Union[google.adk.tools.base_toolset.ToolPredicate, typing.List[str]]]):'
- rank: 1364
  id: google.adk.tools.application_integration_tool.application_integration_toolset.ApplicationIntegrationToolset.get_tools
  name: get_tools
  file_path: google/adk/tools/application_integration_tool/application_integration_toolset.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def get_tools(self, readonly_context: typing.Optional[google.adk.agents.readonly_context.ReadonlyContext]) -> typing.List[google.adk.tools.openapi_tool.openapi_spec_parser.rest_api_tool.RestApiTool]:'
- rank: 1365
  id: google.adk.tools.application_integration_tool.clients.connections_client
  name: connections_client
  file_path: google/adk/tools/application_integration_tool/clients/connections_client.py
  type: MODULE
  group: Orphan
  usage_score: 0
- rank: 1366
  id: google.adk.tools.application_integration_tool.clients.connections_client.ConnectionsClient
  name: ConnectionsClient
  file_path: google/adk/tools/application_integration_tool/clients/connections_client.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: Utility class for interacting with Google Cloud Connectors API.
  constructor_signature: 'def __init__(self, project: str, location: str, connection: str, service_account_json: typing.Optional[str]):'
  methods:
  - signature: 'def get_connection_details(self) -> typing.Dict[str, typing.Any]:'
    docstring: "Retrieves service details (service name and host) for a given connection.\n\nAlso returns if auth override is enabled for the connection.\n\nReturns:\n    tuple: A tuple containing (service_name, host).\n\nRaises:\n    PermissionError: If there are credential issues.\n    ValueError: If there's a request error.\n    Exception: For any other unexpected errors."
  - signature: 'def get_entity_schema_and_operations(self, entity: str) -> typing.Tuple[typing.Dict[str, typing.Any], typing.List[str]]:'
    docstring: "Retrieves the JSON schema for a given entity in a connection.\n\nArgs:\n    entity (str): The entity name.\n\nReturns:\n    tuple: A tuple containing (schema, operations).\n\nRaises:\n    PermissionError: If there are credential issues.\n    ValueError: If there's a request or processing error.\n    Exception: For any other unexpected errors."
  - signature: 'def get_action_schema(self, action: str) -> typing.Dict[str, typing.Any]:'
    docstring: "Retrieves the input and output JSON schema for a given action in a connection.\n\nArgs:\n    action (str): The action name.\n\nReturns:\n    tuple: A tuple containing (input_schema, output_schema).\n\nRaises:\n    PermissionError: If there are credential issues.\n    ValueError: If there's a request or processing error.\n    Exception: For any other unexpected errors."
  - signature: 'def get_connector_base_spec() -> typing.Dict[str, typing.Any]:'
  - signature: 'def get_action_operation(action: str, operation: str, action_display_name: str, tool_name: str, tool_instructions: str) -> typing.Dict[str, typing.Any]:'
  - signature: 'def list_operation(entity: str, schema_as_string: str, tool_name: str, tool_instructions: str) -> typing.Dict[str, typing.Any]:'
  - signature: 'def get_operation(entity: str, schema_as_string: str, tool_name: str, tool_instructions: str) -> typing.Dict[str, typing.Any]:'
  - signature: 'def create_operation(entity: str, tool_name: str, tool_instructions: str) -> typing.Dict[str, typing.Any]:'
  - signature: 'def update_operation(entity: str, tool_name: str, tool_instructions: str) -> typing.Dict[str, typing.Any]:'
  - signature: 'def delete_operation(entity: str, tool_name: str, tool_instructions: str) -> typing.Dict[str, typing.Any]:'
  - signature: 'def create_operation_request(entity: str) -> typing.Dict[str, typing.Any]:'
  - signature: 'def update_operation_request(entity: str) -> typing.Dict[str, typing.Any]:'
  - signature: 'def get_operation_request() -> typing.Dict[str, typing.Any]:'
  - signature: 'def delete_operation_request() -> typing.Dict[str, typing.Any]:'
  - signature: 'def list_operation_request() -> typing.Dict[str, typing.Any]:'
  - signature: 'def action_request(action: str) -> typing.Dict[str, typing.Any]:'
  - signature: 'def action_response(action: str) -> typing.Dict[str, typing.Any]:'
  - signature: 'def execute_custom_query_request() -> typing.Dict[str, typing.Any]:'
  - signature: 'def connector_payload(self, json_schema: typing.Dict[str, typing.Any]) -> typing.Dict[str, typing.Any]:'
- rank: 1367
  id: google.adk.tools.application_integration_tool.clients.connections_client.ConnectionsClient.__init__
  name: __init__
  file_path: google/adk/tools/application_integration_tool/clients/connections_client.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Initializes the ConnectionsClient.\n\nArgs:\n  project: The Google Cloud project ID.\n  location: The Google Cloud location (e.g., us-central1).\n  connection: The connection name.\n  service_account_json: The service account configuration as a dictionary.\n    Required if not using default service credential. Used for fetching\n    connection details."
  signature: 'def __init__(self, project: str, location: str, connection: str, service_account_json: typing.Optional[str]):'
- rank: 1368
  id: google.adk.tools.application_integration_tool.clients.connections_client.ConnectionsClient.action_request
  name: action_request
  file_path: google/adk/tools/application_integration_tool/clients/connections_client.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def action_request(action: str) -> typing.Dict[str, typing.Any]:'
- rank: 1369
  id: google.adk.tools.application_integration_tool.clients.connections_client.ConnectionsClient.action_response
  name: action_response
  file_path: google/adk/tools/application_integration_tool/clients/connections_client.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def action_response(action: str) -> typing.Dict[str, typing.Any]:'
- rank: 1370
  id: google.adk.tools.application_integration_tool.clients.connections_client.ConnectionsClient.create_operation
  name: create_operation
  file_path: google/adk/tools/application_integration_tool/clients/connections_client.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def create_operation(entity: str, tool_name: str, tool_instructions: str) -> typing.Dict[str, typing.Any]:'
- rank: 1371
  id: google.adk.tools.application_integration_tool.clients.connections_client.ConnectionsClient.create_operation_request
  name: create_operation_request
  file_path: google/adk/tools/application_integration_tool/clients/connections_client.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def create_operation_request(entity: str) -> typing.Dict[str, typing.Any]:'
- rank: 1372
  id: google.adk.tools.application_integration_tool.clients.connections_client.ConnectionsClient.delete_operation
  name: delete_operation
  file_path: google/adk/tools/application_integration_tool/clients/connections_client.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def delete_operation(entity: str, tool_name: str, tool_instructions: str) -> typing.Dict[str, typing.Any]:'
- rank: 1373
  id: google.adk.tools.application_integration_tool.clients.connections_client.ConnectionsClient.delete_operation_request
  name: delete_operation_request
  file_path: google/adk/tools/application_integration_tool/clients/connections_client.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def delete_operation_request() -> typing.Dict[str, typing.Any]:'
- rank: 1374
  id: google.adk.tools.application_integration_tool.clients.connections_client.ConnectionsClient.execute_custom_query_request
  name: execute_custom_query_request
  file_path: google/adk/tools/application_integration_tool/clients/connections_client.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def execute_custom_query_request() -> typing.Dict[str, typing.Any]:'
- rank: 1375
  id: google.adk.tools.application_integration_tool.clients.connections_client.ConnectionsClient.get_action_operation
  name: get_action_operation
  file_path: google/adk/tools/application_integration_tool/clients/connections_client.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def get_action_operation(action: str, operation: str, action_display_name: str, tool_name: str, tool_instructions: str) -> typing.Dict[str, typing.Any]:'
- rank: 1376
  id: google.adk.tools.application_integration_tool.clients.connections_client.ConnectionsClient.get_action_schema
  name: get_action_schema
  file_path: google/adk/tools/application_integration_tool/clients/connections_client.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Retrieves the input and output JSON schema for a given action in a connection.\n\nArgs:\n    action (str): The action name.\n\nReturns:\n    tuple: A tuple containing (input_schema, output_schema).\n\nRaises:\n    PermissionError: If there are credential issues.\n    ValueError: If there's a request or processing error.\n    Exception: For any other unexpected errors."
  signature: 'def get_action_schema(self, action: str) -> typing.Dict[str, typing.Any]:'
- rank: 1377
  id: google.adk.tools.application_integration_tool.clients.connections_client.ConnectionsClient.get_connection_details
  name: get_connection_details
  file_path: google/adk/tools/application_integration_tool/clients/connections_client.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Retrieves service details (service name and host) for a given connection.\n\nAlso returns if auth override is enabled for the connection.\n\nReturns:\n    tuple: A tuple containing (service_name, host).\n\nRaises:\n    PermissionError: If there are credential issues.\n    ValueError: If there's a request error.\n    Exception: For any other unexpected errors."
  signature: 'def get_connection_details(self) -> typing.Dict[str, typing.Any]:'
- rank: 1378
  id: google.adk.tools.application_integration_tool.clients.connections_client.ConnectionsClient.get_connector_base_spec
  name: get_connector_base_spec
  file_path: google/adk/tools/application_integration_tool/clients/connections_client.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def get_connector_base_spec() -> typing.Dict[str, typing.Any]:'
- rank: 1379
  id: google.adk.tools.application_integration_tool.clients.connections_client.ConnectionsClient.get_entity_schema_and_operations
  name: get_entity_schema_and_operations
  file_path: google/adk/tools/application_integration_tool/clients/connections_client.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Retrieves the JSON schema for a given entity in a connection.\n\nArgs:\n    entity (str): The entity name.\n\nReturns:\n    tuple: A tuple containing (schema, operations).\n\nRaises:\n    PermissionError: If there are credential issues.\n    ValueError: If there's a request or processing error.\n    Exception: For any other unexpected errors."
  signature: 'def get_entity_schema_and_operations(self, entity: str) -> typing.Tuple[typing.Dict[str, typing.Any], typing.List[str]]:'
- rank: 1380
  id: google.adk.tools.application_integration_tool.clients.connections_client.ConnectionsClient.get_operation
  name: get_operation
  file_path: google/adk/tools/application_integration_tool/clients/connections_client.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def get_operation(entity: str, schema_as_string: str, tool_name: str, tool_instructions: str) -> typing.Dict[str, typing.Any]:'
- rank: 1381
  id: google.adk.tools.application_integration_tool.clients.connections_client.ConnectionsClient.get_operation_request
  name: get_operation_request
  file_path: google/adk/tools/application_integration_tool/clients/connections_client.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def get_operation_request() -> typing.Dict[str, typing.Any]:'
- rank: 1382
  id: google.adk.tools.application_integration_tool.clients.connections_client.ConnectionsClient.list_operation
  name: list_operation
  file_path: google/adk/tools/application_integration_tool/clients/connections_client.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def list_operation(entity: str, schema_as_string: str, tool_name: str, tool_instructions: str) -> typing.Dict[str, typing.Any]:'
- rank: 1383
  id: google.adk.tools.application_integration_tool.clients.connections_client.ConnectionsClient.list_operation_request
  name: list_operation_request
  file_path: google/adk/tools/application_integration_tool/clients/connections_client.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def list_operation_request() -> typing.Dict[str, typing.Any]:'
- rank: 1384
  id: google.adk.tools.application_integration_tool.clients.connections_client.ConnectionsClient.update_operation
  name: update_operation
  file_path: google/adk/tools/application_integration_tool/clients/connections_client.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def update_operation(entity: str, tool_name: str, tool_instructions: str) -> typing.Dict[str, typing.Any]:'
- rank: 1385
  id: google.adk.tools.application_integration_tool.clients.connections_client.ConnectionsClient.update_operation_request
  name: update_operation_request
  file_path: google/adk/tools/application_integration_tool/clients/connections_client.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def update_operation_request(entity: str) -> typing.Dict[str, typing.Any]:'
- rank: 1386
  id: google.adk.tools.application_integration_tool.clients.integration_client
  name: integration_client
  file_path: google/adk/tools/application_integration_tool/clients/integration_client.py
  type: MODULE
  group: Orphan
  usage_score: 0
- rank: 1387
  id: google.adk.tools.application_integration_tool.clients.integration_client.IntegrationClient
  name: IntegrationClient
  file_path: google/adk/tools/application_integration_tool/clients/integration_client.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'A client for interacting with Google Cloud Application Integration.


    This class provides methods for retrieving OpenAPI spec for an integration or

    a connection.'
  constructor_signature: 'def __init__(self, project: str, location: str, integration: typing.Optional[str], triggers: typing.Optional[typing.List[str]], connection: typing.Optional[str], entity_operations: typing.Optional[dict[str, list[str]]], actions: typing.Optional[list[str]], service_account_json: typing.Optional[str]):'
  methods:
  - signature: 'def get_openapi_spec_for_integration(self):'
    docstring: "Gets the OpenAPI spec for the integration.\n\nReturns:\n    dict: The OpenAPI spec as a dictionary.\nRaises:\n    PermissionError: If there are credential issues.\n    ValueError: If there's a request error or processing error.\n    Exception: For any other unexpected errors."
  - signature: 'def get_openapi_spec_for_connection(self, tool_name, tool_instructions):'
    docstring: "Gets the OpenAPI spec for the connection.\n\nReturns:\n    dict: The OpenAPI spec as a dictionary.\nRaises:\n    ValueError: If there's an error retrieving the OpenAPI spec.\n    PermissionError: If there are credential issues.\n    Exception: For any other unexpected errors."
- rank: 1388
  id: google.adk.tools.application_integration_tool.clients.integration_client.IntegrationClient.__init__
  name: __init__
  file_path: google/adk/tools/application_integration_tool/clients/integration_client.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Initializes the ApplicationIntegrationClient.\n\nArgs:\n    project: The Google Cloud project ID.\n    location: The Google Cloud location (e.g., us-central1).\n    integration: The integration name.\n    triggers: The list of trigger IDs for the integration.\n    connection: The connection name.\n    entity_operations: A dictionary mapping entity names to a list of\n      operations (e.g., LIST, CREATE, UPDATE, DELETE, GET).\n    actions: List of actions.\n    service_account_json: The service account configuration as a dictionary.\n      Required if not using default service credential. Used for fetching\n      connection details."
  signature: 'def __init__(self, project: str, location: str, integration: typing.Optional[str], triggers: typing.Optional[typing.List[str]], connection: typing.Optional[str], entity_operations: typing.Optional[dict[str, list[str]]], actions: typing.Optional[list[str]], service_account_json: typing.Optional[str]):'
- rank: 1389
  id: google.adk.tools.application_integration_tool.clients.integration_client.IntegrationClient.get_openapi_spec_for_connection
  name: get_openapi_spec_for_connection
  file_path: google/adk/tools/application_integration_tool/clients/integration_client.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Gets the OpenAPI spec for the connection.\n\nReturns:\n    dict: The OpenAPI spec as a dictionary.\nRaises:\n    ValueError: If there's an error retrieving the OpenAPI spec.\n    PermissionError: If there are credential issues.\n    Exception: For any other unexpected errors."
  signature: 'def get_openapi_spec_for_connection(self, tool_name, tool_instructions):'
- rank: 1390
  id: google.adk.tools.application_integration_tool.clients.integration_client.IntegrationClient.get_openapi_spec_for_integration
  name: get_openapi_spec_for_integration
  file_path: google/adk/tools/application_integration_tool/clients/integration_client.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Gets the OpenAPI spec for the integration.\n\nReturns:\n    dict: The OpenAPI spec as a dictionary.\nRaises:\n    PermissionError: If there are credential issues.\n    ValueError: If there's a request error or processing error.\n    Exception: For any other unexpected errors."
  signature: 'def get_openapi_spec_for_integration(self):'
- rank: 1391
  id: google.adk.tools.application_integration_tool.integration_connector_tool
  name: integration_connector_tool
  file_path: google/adk/tools/application_integration_tool/integration_connector_tool.py
  type: MODULE
  group: Orphan
  usage_score: 0
- rank: 1392
  id: google.adk.tools.application_integration_tool.integration_connector_tool.IntegrationConnectorTool
  name: IntegrationConnectorTool
  file_path: google/adk/tools/application_integration_tool/integration_connector_tool.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: "A tool that wraps a RestApiTool to interact with a specific Application Integration endpoint.\n\nThis tool adds Application Integration specific context like connection\ndetails, entity, operation, and action to the underlying REST API call\nhandled by RestApiTool. It prepares the arguments and then delegates the\nactual API call execution to the contained RestApiTool instance.\n\n* Generates request params and body\n* Attaches auth credentials to API call.\n\nExample::\n\n  # Each API operation in the spec will be turned into its own tool\n  # Name of the tool is the operationId of that operation, in snake case\n  operations = OperationGenerator().parse(openapi_spec_dict)\n  tool = [RestApiTool.from_parsed_operation(o) for o in operations]\n\n[Note: Inherited members from ABC are omitted.]"
  constructor_signature: 'def __init__(self, name: str, description: str, connection_name: str, connection_host: str, connection_service_name: str, entity: str, operation: str, action: str, rest_api_tool: google.adk.tools.openapi_tool.openapi_spec_parser.rest_api_tool.RestApiTool, auth_scheme: typing.Optional[typing.Union[google.adk.auth.auth_schemes.AuthScheme, str]], auth_credential: typing.Optional[typing.Union[google.adk.auth.auth_credential.AuthCredential, str]]):'
  methods:
  - signature: 'def run_async(self, *, args: dict[str, typing.Any], tool_context: typing.Optional[google.adk.tools.tool_context.ToolContext]) -> typing.Dict[str, typing.Any]:'
  properties:
  - signature: 'EXCLUDE_FIELDS: Any'
  - signature: 'OPTIONAL_FIELDS: Any'
  inherited_methods:
    BaseTool:
    - signature: 'def run_async(self, *, args: dict[str, typing.Any], tool_context: google.adk.tools.tool_context.ToolContext) -> typing.Any:'
      docstring: "Runs the tool with the given arguments and context.\n\nNOTE:\n  - Required if this tool needs to run at the client side.\n  - Otherwise, can be skipped, e.g. for a built-in GoogleSearch tool for\n    Gemini.\n\nArgs:\n  args: The LLM-filled arguments.\n  tool_context: The context of the tool.\n\nReturns:\n  The result of running the tool."
    - signature: 'def process_llm_request(self, *, tool_context: google.adk.tools.tool_context.ToolContext, llm_request: google.adk.models.llm_request.LlmRequest) -> None:'
      docstring: "Processes the outgoing LLM request for this tool.\n\nUse cases:\n- Most common use case is adding this tool to the LLM request.\n- Some tools may just preprocess the LLM request before it's sent out.\n\nArgs:\n  tool_context: The context of the tool.\n  llm_request: The outgoing LLM request, mutable this method."
    - signature: 'def from_config(cls: typing.Type[google.adk.tools.base_tool.SelfTool], config: google.adk.tools.tool_configs.ToolArgsConfig, config_abs_path: str) -> google.adk.tools.base_tool.SelfTool:'
      docstring: "Creates a tool instance from a config.\n\nThis default implementation uses inspect to automatically map config values\nto constructor arguments based on their type hints. Subclasses should\noverride this method for custom initialization logic.\n\nArgs:\n  config: The config for the tool.\n  config_abs_path: The absolute path to the config file that contains the\n    tool config.\n\nReturns:\n  The tool instance."
  inherited_properties:
    BaseTool:
    - signature: 'name: str'
      docstring: The name of the tool.
    - signature: 'description: str'
      docstring: The description of the tool.
    - signature: 'is_long_running: bool'
      docstring: 'Whether the tool is a long running operation, which typically returns a

        resource id first and finishes the operation later.'
    - signature: 'custom_metadata: typing.Optional[dict[str, typing.Any]]'
      docstring: 'The custom metadata of the BaseTool.


        An optional key-value pair for storing and retrieving tool-specific metadata,

        such as tool manifests, etc.


        NOTE: the entire dict must be JSON serializable.'
  omitted_inherited_members_from:
  - ABC
- rank: 1393
  id: google.adk.tools.application_integration_tool.integration_connector_tool.IntegrationConnectorTool.__init__
  name: __init__
  file_path: google/adk/tools/application_integration_tool/integration_connector_tool.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Initializes the ApplicationIntegrationTool.\n\nArgs:\n    name: The name of the tool, typically derived from the API operation.\n      Should be unique and adhere to Gemini function naming conventions\n      (e.g., less than 64 characters).\n    description: A description of what the tool does, usually based on the\n      API operation's summary or description.\n    connection_name: The name of the Integration Connector connection.\n    connection_host: The hostname or IP address for the connection.\n    connection_service_name: The specific service name within the host.\n    entity: The Integration Connector entity being targeted.\n    operation: The specific operation being performed on the entity.\n    action: The action associated with the operation (e.g., 'execute').\n    rest_api_tool: An initialized RestApiTool instance that handles the\n      underlying REST API communication based on an OpenAPI specification\n      operation. This tool will be called by ApplicationIntegrationTool\
    \ with\n      added connection and context arguments. tool =\n      [RestApiTool.from_parsed_operation(o) for o in operations]"
  signature: 'def __init__(self, name: str, description: str, connection_name: str, connection_host: str, connection_service_name: str, entity: str, operation: str, action: str, rest_api_tool: google.adk.tools.openapi_tool.openapi_spec_parser.rest_api_tool.RestApiTool, auth_scheme: typing.Optional[typing.Union[google.adk.auth.auth_schemes.AuthScheme, str]], auth_credential: typing.Optional[typing.Union[google.adk.auth.auth_credential.AuthCredential, str]]):'
- rank: 1394
  id: google.adk.tools.application_integration_tool.integration_connector_tool.IntegrationConnectorTool.run_async
  name: run_async
  file_path: google/adk/tools/application_integration_tool/integration_connector_tool.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def run_async(self, *, args: dict[str, typing.Any], tool_context: typing.Optional[google.adk.tools.tool_context.ToolContext]) -> typing.Dict[str, typing.Any]:'
- rank: 1395
  id: google.adk.tools.authenticated_function_tool
  name: authenticated_function_tool
  file_path: google/adk/tools/authenticated_function_tool.py
  type: MODULE
  group: Orphan
  usage_score: 0
- rank: 1396
  id: google.adk.tools.authenticated_function_tool.AuthenticatedFunctionTool.__init__
  name: __init__
  file_path: google/adk/tools/authenticated_function_tool.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Initializes the AuthenticatedFunctionTool.\n\nArgs:\n    func: The function to be called.\n    auth_config: The authentication configuration.\n    response_for_auth_required: The response to return when the tool is\n      requesting auth credential from the client. There could be two case,\n      the tool doesn't configure any credentials\n      (auth_config.raw_auth_credential is missing) or the credentials\n      configured is not enough to authenticate the tool (e.g. an OAuth\n      client id and client secret are configured) and needs client input\n      (e.g. client need to involve the end user in an oauth flow and get\n      back the oauth response.)"
  signature: 'def __init__(self, *, func: typing.Callable[Ellipsis, typing.Any], auth_config: google.adk.auth.auth_tool.AuthConfig=None, response_for_auth_required: typing.Optional[typing.Union[dict[str, typing.Any], str]]=None):'
- rank: 1397
  id: google.adk.tools.authenticated_function_tool.AuthenticatedFunctionTool._run_async_impl
  name: _run_async_impl
  file_path: google/adk/tools/authenticated_function_tool.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def _run_async_impl(self, *, args: dict[str, typing.Any], tool_context: google.adk.tools.tool_context.ToolContext, credential: google.adk.auth.auth_credential.AuthCredential) -> typing.Any:'
- rank: 1398
  id: google.adk.tools.authenticated_function_tool.AuthenticatedFunctionTool.run_async
  name: run_async
  file_path: google/adk/tools/authenticated_function_tool.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def run_async(self, *, args: dict[str, typing.Any], tool_context: google.adk.tools.tool_context.ToolContext) -> typing.Any:'
- rank: 1399
  id: google.adk.tools.base_authenticated_tool
  name: base_authenticated_tool
  file_path: google/adk/tools/base_authenticated_tool.py
  type: MODULE
  group: Orphan
  usage_score: 0
- rank: 1400
  id: google.adk.tools.base_authenticated_tool.BaseAuthenticatedTool
  name: BaseAuthenticatedTool
  file_path: google/adk/tools/base_authenticated_tool.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'A base tool class that handles authentication before the actual tool logic

    gets called. Functions can accept a special `credential` argument which is the

    credential ready for use.(Experimental)


    [Note: Inherited members from ABC are omitted.]'
  constructor_signature: 'def __init__(self, *, name, description, auth_config: google.adk.auth.auth_tool.AuthConfig=None, response_for_auth_required: typing.Optional[typing.Union[dict[str, typing.Any], str]]=None):'
  methods:
  - signature: 'def run_async(self, *, args: dict[str, typing.Any], tool_context: google.adk.tools.tool_context.ToolContext) -> typing.Any:'
  - signature: 'def _run_async_impl(self, *, args: dict[str, typing.Any], tool_context: google.adk.tools.tool_context.ToolContext, credential: google.adk.auth.auth_credential.AuthCredential) -> typing.Any:'
  inherited_methods:
    BaseTool:
    - signature: 'def run_async(self, *, args: dict[str, typing.Any], tool_context: google.adk.tools.tool_context.ToolContext) -> typing.Any:'
      docstring: "Runs the tool with the given arguments and context.\n\nNOTE:\n  - Required if this tool needs to run at the client side.\n  - Otherwise, can be skipped, e.g. for a built-in GoogleSearch tool for\n    Gemini.\n\nArgs:\n  args: The LLM-filled arguments.\n  tool_context: The context of the tool.\n\nReturns:\n  The result of running the tool."
    - signature: 'def process_llm_request(self, *, tool_context: google.adk.tools.tool_context.ToolContext, llm_request: google.adk.models.llm_request.LlmRequest) -> None:'
      docstring: "Processes the outgoing LLM request for this tool.\n\nUse cases:\n- Most common use case is adding this tool to the LLM request.\n- Some tools may just preprocess the LLM request before it's sent out.\n\nArgs:\n  tool_context: The context of the tool.\n  llm_request: The outgoing LLM request, mutable this method."
    - signature: 'def from_config(cls: typing.Type[google.adk.tools.base_tool.SelfTool], config: google.adk.tools.tool_configs.ToolArgsConfig, config_abs_path: str) -> google.adk.tools.base_tool.SelfTool:'
      docstring: "Creates a tool instance from a config.\n\nThis default implementation uses inspect to automatically map config values\nto constructor arguments based on their type hints. Subclasses should\noverride this method for custom initialization logic.\n\nArgs:\n  config: The config for the tool.\n  config_abs_path: The absolute path to the config file that contains the\n    tool config.\n\nReturns:\n  The tool instance."
  inherited_properties:
    BaseTool:
    - signature: 'name: str'
      docstring: The name of the tool.
    - signature: 'description: str'
      docstring: The description of the tool.
    - signature: 'is_long_running: bool'
      docstring: 'Whether the tool is a long running operation, which typically returns a

        resource id first and finishes the operation later.'
    - signature: 'custom_metadata: typing.Optional[dict[str, typing.Any]]'
      docstring: 'The custom metadata of the BaseTool.


        An optional key-value pair for storing and retrieving tool-specific metadata,

        such as tool manifests, etc.


        NOTE: the entire dict must be JSON serializable.'
  omitted_inherited_members_from:
  - ABC
- rank: 1401
  id: google.adk.tools.base_authenticated_tool.BaseAuthenticatedTool.__init__
  name: __init__
  file_path: google/adk/tools/base_authenticated_tool.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Args:\nname: The name of the tool.\ndescription: The description of the tool.\nauth_config: The auth configuration of the tool.\nresponse_for_auth_required: The response to return when the tool is\n    requesting auth credential from the client. There could be two case,\n    the tool doesn't configure any credentials\n    (auth_config.raw_auth_credential is missing) or the credentials\n    configured is not enough to authenticate the tool (e.g. an OAuth\n    client id and client secret are configured) and needs client input\n    (e.g. client need to involve the end user in an oauth flow and get\n    back the oauth response.)"
  signature: 'def __init__(self, *, name, description, auth_config: google.adk.auth.auth_tool.AuthConfig=None, response_for_auth_required: typing.Optional[typing.Union[dict[str, typing.Any], str]]=None):'
- rank: 1402
  id: google.adk.tools.base_authenticated_tool.BaseAuthenticatedTool._run_async_impl
  name: _run_async_impl
  file_path: google/adk/tools/base_authenticated_tool.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def _run_async_impl(self, *, args: dict[str, typing.Any], tool_context: google.adk.tools.tool_context.ToolContext, credential: google.adk.auth.auth_credential.AuthCredential) -> typing.Any:'
- rank: 1403
  id: google.adk.tools.base_authenticated_tool.BaseAuthenticatedTool.run_async
  name: run_async
  file_path: google/adk/tools/base_authenticated_tool.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def run_async(self, *, args: dict[str, typing.Any], tool_context: google.adk.tools.tool_context.ToolContext) -> typing.Any:'
- rank: 1404
  id: google.adk.tools.base_tool
  name: base_tool
  file_path: google/adk/tools/base_tool.py
  type: MODULE
  group: Orphan
  usage_score: 0
- rank: 1405
  id: google.adk.tools.base_tool.BaseTool
  name: BaseTool
  file_path: google/adk/tools/base_tool.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'The base class for all tools.


    [Note: Inherited members from ABC are omitted.]'
  constructor_signature: 'def __init__(self, *, name, description, is_long_running: bool=False, custom_metadata: typing.Optional[dict[str, typing.Any]]=None):'
  methods:
  - signature: 'def run_async(self, *, args: dict[str, typing.Any], tool_context: google.adk.tools.tool_context.ToolContext) -> typing.Any:'
    docstring: "Runs the tool with the given arguments and context.\n\nNOTE:\n  - Required if this tool needs to run at the client side.\n  - Otherwise, can be skipped, e.g. for a built-in GoogleSearch tool for\n    Gemini.\n\nArgs:\n  args: The LLM-filled arguments.\n  tool_context: The context of the tool.\n\nReturns:\n  The result of running the tool."
  - signature: 'def process_llm_request(self, *, tool_context: google.adk.tools.tool_context.ToolContext, llm_request: google.adk.models.llm_request.LlmRequest) -> None:'
    docstring: "Processes the outgoing LLM request for this tool.\n\nUse cases:\n- Most common use case is adding this tool to the LLM request.\n- Some tools may just preprocess the LLM request before it's sent out.\n\nArgs:\n  tool_context: The context of the tool.\n  llm_request: The outgoing LLM request, mutable this method."
  - signature: 'def from_config(cls: typing.Type[google.adk.tools.base_tool.SelfTool], config: google.adk.tools.tool_configs.ToolArgsConfig, config_abs_path: str) -> google.adk.tools.base_tool.SelfTool:'
    docstring: "Creates a tool instance from a config.\n\nThis default implementation uses inspect to automatically map config values\nto constructor arguments based on their type hints. Subclasses should\noverride this method for custom initialization logic.\n\nArgs:\n  config: The config for the tool.\n  config_abs_path: The absolute path to the config file that contains the\n    tool config.\n\nReturns:\n  The tool instance."
  properties:
  - signature: 'name: str'
    docstring: The name of the tool.
  - signature: 'description: str'
    docstring: The description of the tool.
  - signature: 'is_long_running: bool'
    docstring: 'Whether the tool is a long running operation, which typically returns a

      resource id first and finishes the operation later.'
  - signature: 'custom_metadata: typing.Optional[dict[str, typing.Any]]'
    docstring: 'The custom metadata of the BaseTool.


      An optional key-value pair for storing and retrieving tool-specific metadata,

      such as tool manifests, etc.


      NOTE: the entire dict must be JSON serializable.'
  omitted_inherited_members_from:
  - ABC
- rank: 1406
  id: google.adk.tools.base_tool.BaseTool.__init__
  name: __init__
  file_path: google/adk/tools/base_tool.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def __init__(self, *, name, description, is_long_running: bool=False, custom_metadata: typing.Optional[dict[str, typing.Any]]=None):'
- rank: 1407
  id: google.adk.tools.base_tool.BaseTool.from_config
  name: from_config
  file_path: google/adk/tools/base_tool.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Creates a tool instance from a config.\n\nThis default implementation uses inspect to automatically map config values\nto constructor arguments based on their type hints. Subclasses should\noverride this method for custom initialization logic.\n\nArgs:\n  config: The config for the tool.\n  config_abs_path: The absolute path to the config file that contains the\n    tool config.\n\nReturns:\n  The tool instance."
  signature: 'def from_config(cls: typing.Type[google.adk.tools.base_tool.SelfTool], config: google.adk.tools.tool_configs.ToolArgsConfig, config_abs_path: str) -> google.adk.tools.base_tool.SelfTool:'
- rank: 1408
  id: google.adk.tools.base_tool.BaseTool.process_llm_request
  name: process_llm_request
  file_path: google/adk/tools/base_tool.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Processes the outgoing LLM request for this tool.\n\nUse cases:\n- Most common use case is adding this tool to the LLM request.\n- Some tools may just preprocess the LLM request before it's sent out.\n\nArgs:\n  tool_context: The context of the tool.\n  llm_request: The outgoing LLM request, mutable this method."
  signature: 'def process_llm_request(self, *, tool_context: google.adk.tools.tool_context.ToolContext, llm_request: google.adk.models.llm_request.LlmRequest) -> None:'
- rank: 1409
  id: google.adk.tools.base_tool.BaseTool.run_async
  name: run_async
  file_path: google/adk/tools/base_tool.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Runs the tool with the given arguments and context.\n\nNOTE:\n  - Required if this tool needs to run at the client side.\n  - Otherwise, can be skipped, e.g. for a built-in GoogleSearch tool for\n    Gemini.\n\nArgs:\n  args: The LLM-filled arguments.\n  tool_context: The context of the tool.\n\nReturns:\n  The result of running the tool."
  signature: 'def run_async(self, *, args: dict[str, typing.Any], tool_context: google.adk.tools.tool_context.ToolContext) -> typing.Any:'
- rank: 1410
  id: google.adk.tools.base_toolset
  name: base_toolset
  file_path: google/adk/tools/base_toolset.py
  type: MODULE
  group: Orphan
  usage_score: 0
- rank: 1411
  id: google.adk.tools.base_toolset.BaseToolset
  name: BaseToolset
  file_path: google/adk/tools/base_toolset.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Base class for toolset.


    A toolset is a collection of tools that can be used by an agent.


    [Note: Inherited members from ABC are omitted.]'
  constructor_signature: 'def __init__(self, *, tool_filter: typing.Optional[typing.Union[google.adk.tools.base_toolset.ToolPredicate, typing.List[str]]]=None, tool_name_prefix: typing.Optional[str]=None):'
  methods:
  - signature: 'def get_tools(self, readonly_context: typing.Optional[google.adk.agents.readonly_context.ReadonlyContext]) -> list[google.adk.tools.base_tool.BaseTool]:'
    docstring: "Return all tools in the toolset based on the provided context.\n\nArgs:\n  readonly_context (ReadonlyContext, optional): Context used to filter tools\n    available to the agent. If None, all tools in the toolset are returned.\n\nReturns:\n  list[BaseTool]: A list of tools available under the specified context."
  - signature: 'def get_tools_with_prefix(self, readonly_context: typing.Optional[google.adk.agents.readonly_context.ReadonlyContext]) -> list[google.adk.tools.base_tool.BaseTool]:'
    docstring: "Return all tools with optional prefix applied to tool names.\n\nThis method calls get_tools() and applies prefixing if tool_name_prefix is provided.\n\nArgs:\n  readonly_context (ReadonlyContext, optional): Context used to filter tools\n    available to the agent. If None, all tools in the toolset are returned.\n\nReturns:\n  list[BaseTool]: A list of tools with prefixed names if tool_name_prefix is provided."
  - signature: 'def close(self) -> None:'
    docstring: "Performs cleanup and releases resources held by the toolset.\n\nNOTE:\n  This method is invoked, for example, at the end of an agent server's\n  lifecycle or when the toolset is no longer needed. Implementations\n  should ensure that any open connections, files, or other managed\n  resources are properly released to prevent leaks."
  - signature: 'def from_config(cls: typing.Type[google.adk.tools.base_toolset.SelfToolset], config: google.adk.tools.tool_configs.ToolArgsConfig, config_abs_path: str) -> google.adk.tools.base_toolset.SelfToolset:'
    docstring: "Creates a toolset instance from a config.\n\nArgs:\n  config: The config for the tool.\n  config_abs_path: The absolute path to the config file that contains the\n    tool config.\n\nReturns:\n  The toolset instance."
  - signature: 'def process_llm_request(self, *, tool_context: google.adk.tools.tool_context.ToolContext, llm_request: google.adk.models.llm_request.LlmRequest) -> None:'
    docstring: "Processes the outgoing LLM request for this toolset. This method will be\ncalled before each tool processes the llm request.\n\nUse cases:\n- Instead of let each tool process the llm request, we can let the toolset\n  process the llm request. e.g. ComputerUseToolset can add computer use\n  tool to the llm request.\n\nArgs:\n  tool_context: The context of the tool.\n  llm_request: The outgoing LLM request, mutable this method."
  omitted_inherited_members_from:
  - ABC
- rank: 1412
  id: google.adk.tools.base_toolset.BaseToolset.__init__
  name: __init__
  file_path: google/adk/tools/base_toolset.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Initialize the toolset.\n\nArgs:\n  tool_filter: Filter to apply to tools.\n  tool_name_prefix: The prefix to prepend to the names of the tools returned by the toolset."
  signature: 'def __init__(self, *, tool_filter: typing.Optional[typing.Union[google.adk.tools.base_toolset.ToolPredicate, typing.List[str]]]=None, tool_name_prefix: typing.Optional[str]=None):'
- rank: 1413
  id: google.adk.tools.base_toolset.BaseToolset.close
  name: close
  file_path: google/adk/tools/base_toolset.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Performs cleanup and releases resources held by the toolset.\n\nNOTE:\n  This method is invoked, for example, at the end of an agent server's\n  lifecycle or when the toolset is no longer needed. Implementations\n  should ensure that any open connections, files, or other managed\n  resources are properly released to prevent leaks."
  signature: 'def close(self) -> None:'
- rank: 1414
  id: google.adk.tools.base_toolset.BaseToolset.from_config
  name: from_config
  file_path: google/adk/tools/base_toolset.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Creates a toolset instance from a config.\n\nArgs:\n  config: The config for the tool.\n  config_abs_path: The absolute path to the config file that contains the\n    tool config.\n\nReturns:\n  The toolset instance."
  signature: 'def from_config(cls: typing.Type[google.adk.tools.base_toolset.SelfToolset], config: google.adk.tools.tool_configs.ToolArgsConfig, config_abs_path: str) -> google.adk.tools.base_toolset.SelfToolset:'
- rank: 1415
  id: google.adk.tools.base_toolset.BaseToolset.get_tools
  name: get_tools
  file_path: google/adk/tools/base_toolset.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Return all tools in the toolset based on the provided context.\n\nArgs:\n  readonly_context (ReadonlyContext, optional): Context used to filter tools\n    available to the agent. If None, all tools in the toolset are returned.\n\nReturns:\n  list[BaseTool]: A list of tools available under the specified context."
  signature: 'def get_tools(self, readonly_context: typing.Optional[google.adk.agents.readonly_context.ReadonlyContext]) -> list[google.adk.tools.base_tool.BaseTool]:'
- rank: 1416
  id: google.adk.tools.base_toolset.BaseToolset.get_tools_with_prefix
  name: get_tools_with_prefix
  file_path: google/adk/tools/base_toolset.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Return all tools with optional prefix applied to tool names.\n\nThis method calls get_tools() and applies prefixing if tool_name_prefix is provided.\n\nArgs:\n  readonly_context (ReadonlyContext, optional): Context used to filter tools\n    available to the agent. If None, all tools in the toolset are returned.\n\nReturns:\n  list[BaseTool]: A list of tools with prefixed names if tool_name_prefix is provided."
  signature: 'def get_tools_with_prefix(self, readonly_context: typing.Optional[google.adk.agents.readonly_context.ReadonlyContext]) -> list[google.adk.tools.base_tool.BaseTool]:'
- rank: 1417
  id: google.adk.tools.base_toolset.BaseToolset.process_llm_request
  name: process_llm_request
  file_path: google/adk/tools/base_toolset.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Processes the outgoing LLM request for this toolset. This method will be\ncalled before each tool processes the llm request.\n\nUse cases:\n- Instead of let each tool process the llm request, we can let the toolset\n  process the llm request. e.g. ComputerUseToolset can add computer use\n  tool to the llm request.\n\nArgs:\n  tool_context: The context of the tool.\n  llm_request: The outgoing LLM request, mutable this method."
  signature: 'def process_llm_request(self, *, tool_context: google.adk.tools.tool_context.ToolContext, llm_request: google.adk.models.llm_request.LlmRequest) -> None:'
- rank: 1418
  id: google.adk.tools.base_toolset.ToolPredicate
  name: ToolPredicate
  file_path: google/adk/tools/base_toolset.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Base class for a predicate that defines the interface to decide whether a


    tool should be exposed to LLM. Toolset implementer could consider whether to

    accept such instance in the toolset''s constructor and apply the predicate in

    get_tools method.


    [Note: Inherited members from Protocol are omitted.]'
  omitted_inherited_members_from:
  - Protocol
- rank: 1419
  id: google.adk.tools.bigquery
  name: bigquery
  file_path: google/adk/tools/bigquery/__init__.py
  type: MODULE
  group: Orphan
  usage_score: 0
  docstring: "BigQuery Tools (Experimental).\n\nBigQuery Tools under this module are hand crafted and customized while the tools\nunder google.adk.tools.google_api_tool are auto generated based on API\ndefinition. The rationales to have customized tool are:\n\n1. BigQuery APIs have functions overlaps and LLM can't tell what tool to use\n2. BigQuery APIs have a lot of parameters with some rarely used, which are not\n   LLM-friendly\n3. We want to provide more high-level tools like forecasting, RAG, segmentation,\n   etc.\n4. We want to provide extra access guardrails in those tools. For example,\n   execute_sql can't arbitrarily mutate existing data."
- rank: 1420
  id: google.adk.tools.bigquery.bigquery_credentials
  name: bigquery_credentials
  file_path: google/adk/tools/bigquery/bigquery_credentials.py
  type: MODULE
  group: Orphan
  usage_score: 0
- rank: 1421
  id: google.adk.tools.bigquery.bigquery_toolset
  name: bigquery_toolset
  file_path: google/adk/tools/bigquery/bigquery_toolset.py
  type: MODULE
  group: Orphan
  usage_score: 0
- rank: 1422
  id: google.adk.tools.bigquery.bigquery_toolset.BigQueryToolset.__init__
  name: __init__
  file_path: google/adk/tools/bigquery/bigquery_toolset.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def __init__(self, *, tool_filter: typing.Optional[typing.Union[google.adk.tools.base_toolset.ToolPredicate, typing.List[str]]]=None, credentials_config: typing.Optional[google.adk.tools.bigquery.bigquery_credentials.BigQueryCredentialsConfig]=None, bigquery_tool_config: typing.Optional[google.adk.tools.bigquery.config.BigQueryToolConfig]=None):'
- rank: 1423
  id: google.adk.tools.bigquery.bigquery_toolset.BigQueryToolset.get_tools
  name: get_tools
  file_path: google/adk/tools/bigquery/bigquery_toolset.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: Get tools from the toolset.
  signature: 'def get_tools(self, readonly_context: typing.Optional[google.adk.agents.readonly_context.ReadonlyContext]) -> typing.List[google.adk.tools.base_tool.BaseTool]:'
- rank: 1424
  id: google.adk.tools.bigquery.client
  name: client
  file_path: google/adk/tools/bigquery/client.py
  type: MODULE
  group: Orphan
  usage_score: 0
  methods:
  - signature: 'def get_bigquery_client(*, project: typing.Optional[str], credentials: google.auth.credentials.Credentials, location: typing.Optional[str]=None, user_agent: typing.Optional[typing.Union[str, typing.List[str]]]=None) -> google.cloud.bigquery.Client:'
    docstring: "Get a BigQuery client.\n\nArgs:\n  project: The GCP project ID.\n  credentials: The credentials to use for the request.\n  location: The location of the BigQuery client.\n  user_agent: The user agent to use for the request.\n\nReturns:\n  A BigQuery client."
- rank: 1425
  id: google.adk.tools.bigquery.config
  name: config
  file_path: google/adk/tools/bigquery/config.py
  type: MODULE
  group: Orphan
  usage_score: 0
- rank: 1426
  id: google.adk.tools.bigquery.config.BigQueryToolConfig.validate_application_name
  name: validate_application_name
  file_path: google/adk/tools/bigquery/config.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: Validate the application name.
  signature: 'def validate_application_name(cls, v):'
- rank: 1427
  id: google.adk.tools.bigquery.config.BigQueryToolConfig.validate_maximum_bytes_billed
  name: validate_maximum_bytes_billed
  file_path: google/adk/tools/bigquery/config.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: Validate the maximum bytes billed.
  signature: 'def validate_maximum_bytes_billed(cls, v):'
- rank: 1428
  id: google.adk.tools.bigquery.config.WriteMode
  name: WriteMode
  file_path: google/adk/tools/bigquery/config.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Write mode indicating what levels of write operations are allowed in BigQuery.


    [Note: Inherited members from Enum are omitted.]'
  properties:
  - signature: 'BLOCKED: str'
    docstring: 'No write operations are allowed.


      This mode implies that only read (i.e. SELECT query) operations are allowed.'
  - signature: 'PROTECTED: str'
    docstring: 'Only protected write operations are allowed in a BigQuery session.


      In this mode write operations in the anonymous dataset of a BigQuery session

      are allowed. For example, a temporary table can be created, manipulated and

      deleted in the anonymous dataset during Agent interaction, while protecting

      permanent tables from being modified or deleted. To learn more about BigQuery

      sessions, see https://cloud.google.com/bigquery/docs/sessions-intro.'
  - signature: 'ALLOWED: str'
    docstring: All write operations are allowed.
  omitted_inherited_members_from:
  - Enum
- rank: 1429
  id: google.adk.tools.bigquery.data_insights_tool
  name: data_insights_tool
  file_path: google/adk/tools/bigquery/data_insights_tool.py
  type: MODULE
  group: Orphan
  usage_score: 0
  methods:
  - signature: 'def ask_data_insights(project_id: str, user_query_with_context: str, table_references: typing.List[typing.Dict[str, str]], credentials: google.auth.credentials.Credentials, settings: google.adk.tools.bigquery.config.BigQueryToolConfig) -> typing.Dict[str, typing.Any]:'
    docstring: "Answers questions about structured data in BigQuery tables using natural language.\n\nThis function takes a user's question (which can include conversational\nhistory for context) and references to specific BigQuery tables, and sends\nthem to a stateless conversational API.\n\nThe API uses a GenAI agent to understand the question, generate and execute\nSQL queries and Python code, and formulate an answer. This function returns a\ndetailed, sequential log of this entire process, which includes any generated\nSQL or Python code, the data retrieved, and the final text answer. The final\nanswer is always in plain text, as the underlying API is instructed not to\ngenerate any charts, graphs, images, or other visualizations.\n\nUse this tool to perform data analysis, get insights, or answer complex\nquestions about the contents of specific BigQuery tables.\n\nArgs:\n    project_id (str): The project that the inquiry is performed in.\n    user_query_with_context (str): The user's\
      \ original request, enriched with\n      relevant context from the conversation history. The user's core intent\n      should be preserved, but context should be added to resolve ambiguities\n      in follow-up questions.\n    table_references (List[Dict[str, str]]): A list of dictionaries, each\n      specifying a BigQuery table to be used as context for the question.\n    credentials (Credentials): The credentials to use for the request.\n    settings (BigQueryToolConfig): The settings for the tool.\n\nReturns:\n    A dictionary with two keys:\n    - 'status': A string indicating the final status (e.g., \"SUCCESS\").\n    - 'response': A list of dictionaries, where each dictionary\n      represents a step in the API's execution process (e.g., SQL\n      generation, data retrieval, final answer).\n\nExample:\n    A query joining multiple tables, showing the full return structure.\n    The original question: \"Which customer from New York spent the most last\n    month?\"\n\n    >>>\
      \ ask_data_insights(\n    ...     project_id=\"some-project-id\",\n    ...     user_query_with_context=(\n    ...         \"Which customer from New York spent the most last month?\"\n    ...         \"Context: The 'customers' table joins with the 'orders' table\"\n    ...         \" on the 'customer_id' column.\"\n    ...         \"\"\n    ...     ),\n    ...     table_references=[\n    ...         {\n    ...             \"projectId\": \"my-gcp-project\",\n    ...             \"datasetId\": \"sales_data\",\n    ...             \"tableId\": \"customers\"\n    ...         },\n    ...         {\n    ...             \"projectId\": \"my-gcp-project\",\n    ...             \"datasetId\": \"sales_data\",\n    ...             \"tableId\": \"orders\"\n    ...         }\n    ...     ]\n    ... )\n    {\n      \"status\": \"SUCCESS\",\n      \"response\": [\n        {\n          \"SQL Generated\": \"SELECT t1.customer_name, SUM(t2.order_total) ... \"\n        },\n        {\n          \"Data Retrieved\"\
      : {\n            \"headers\": [\"customer_name\", \"total_spent\"],\n            \"rows\": [[\"Jane Doe\", 1234.56]],\n            \"summary\": \"Showing all 1 rows.\"\n          }\n        },\n        {\n          \"Answer\": \"The customer who spent the most was Jane Doe.\"\n        }\n      ]\n    }"
- rank: 1430
  id: google.adk.tools.bigquery.data_insights_tool.ask_data_insights
  name: ask_data_insights
  file_path: google/adk/tools/bigquery/data_insights_tool.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Answers questions about structured data in BigQuery tables using natural language.\n\nThis function takes a user's question (which can include conversational\nhistory for context) and references to specific BigQuery tables, and sends\nthem to a stateless conversational API.\n\nThe API uses a GenAI agent to understand the question, generate and execute\nSQL queries and Python code, and formulate an answer. This function returns a\ndetailed, sequential log of this entire process, which includes any generated\nSQL or Python code, the data retrieved, and the final text answer. The final\nanswer is always in plain text, as the underlying API is instructed not to\ngenerate any charts, graphs, images, or other visualizations.\n\nUse this tool to perform data analysis, get insights, or answer complex\nquestions about the contents of specific BigQuery tables.\n\nArgs:\n    project_id (str): The project that the inquiry is performed in.\n    user_query_with_context (str): The user's\
    \ original request, enriched with\n      relevant context from the conversation history. The user's core intent\n      should be preserved, but context should be added to resolve ambiguities\n      in follow-up questions.\n    table_references (List[Dict[str, str]]): A list of dictionaries, each\n      specifying a BigQuery table to be used as context for the question.\n    credentials (Credentials): The credentials to use for the request.\n    settings (BigQueryToolConfig): The settings for the tool.\n\nReturns:\n    A dictionary with two keys:\n    - 'status': A string indicating the final status (e.g., \"SUCCESS\").\n    - 'response': A list of dictionaries, where each dictionary\n      represents a step in the API's execution process (e.g., SQL\n      generation, data retrieval, final answer).\n\nExample:\n    A query joining multiple tables, showing the full return structure.\n    The original question: \"Which customer from New York spent the most last\n    month?\"\n\n    >>>\
    \ ask_data_insights(\n    ...     project_id=\"some-project-id\",\n    ...     user_query_with_context=(\n    ...         \"Which customer from New York spent the most last month?\"\n    ...         \"Context: The 'customers' table joins with the 'orders' table\"\n    ...         \" on the 'customer_id' column.\"\n    ...         \"\"\n    ...     ),\n    ...     table_references=[\n    ...         {\n    ...             \"projectId\": \"my-gcp-project\",\n    ...             \"datasetId\": \"sales_data\",\n    ...             \"tableId\": \"customers\"\n    ...         },\n    ...         {\n    ...             \"projectId\": \"my-gcp-project\",\n    ...             \"datasetId\": \"sales_data\",\n    ...             \"tableId\": \"orders\"\n    ...         }\n    ...     ]\n    ... )\n    {\n      \"status\": \"SUCCESS\",\n      \"response\": [\n        {\n          \"SQL Generated\": \"SELECT t1.customer_name, SUM(t2.order_total) ... \"\n        },\n        {\n          \"Data Retrieved\"\
    : {\n            \"headers\": [\"customer_name\", \"total_spent\"],\n            \"rows\": [[\"Jane Doe\", 1234.56]],\n            \"summary\": \"Showing all 1 rows.\"\n          }\n        },\n        {\n          \"Answer\": \"The customer who spent the most was Jane Doe.\"\n        }\n      ]\n    }"
  signature: 'def ask_data_insights(project_id: str, user_query_with_context: str, table_references: typing.List[typing.Dict[str, str]], credentials: google.auth.credentials.Credentials, settings: google.adk.tools.bigquery.config.BigQueryToolConfig) -> typing.Dict[str, typing.Any]:'
- rank: 1431
  id: google.adk.tools.bigquery.metadata_tool
  name: metadata_tool
  file_path: google/adk/tools/bigquery/metadata_tool.py
  type: MODULE
  group: Orphan
  usage_score: 0
  methods:
  - signature: 'def list_dataset_ids(project_id: str, credentials: google.auth.credentials.Credentials, settings: google.adk.tools.bigquery.config.BigQueryToolConfig) -> list[str]:'
    docstring: "List BigQuery dataset ids in a Google Cloud project.\n\nArgs:\n    project_id (str): The Google Cloud project id.\n    credentials (Credentials): The credentials to use for the request.\n\nReturns:\n    list[str]: List of the BigQuery dataset ids present in the project.\n\nExamples:\n    >>> list_dataset_ids(\"bigquery-public-data\")\n    ['america_health_rankings',\n     'american_community_survey',\n     'aml_ai_input_dataset',\n     'austin_311',\n     'austin_bikeshare',\n     'austin_crime',\n     'austin_incidents',\n     'austin_waste',\n     'baseball',\n     'bbc_news']"
  - signature: 'def get_dataset_info(project_id: str, dataset_id: str, credentials: google.auth.credentials.Credentials, settings: google.adk.tools.bigquery.config.BigQueryToolConfig) -> dict:'
    docstring: "Get metadata information about a BigQuery dataset.\n\nArgs:\n    project_id (str): The Google Cloud project id containing the dataset.\n    dataset_id (str): The BigQuery dataset id.\n    credentials (Credentials): The credentials to use for the request.\n\nReturns:\n    dict: Dictionary representing the properties of the dataset.\n\nExamples:\n    >>> get_dataset_info(\"bigquery-public-data\", \"cdc_places\")\n    {\n      \"kind\": \"bigquery#dataset\",\n      \"etag\": \"fz9BaiXKgbGi53EpI2rJug==\",\n      \"id\": \"bigquery-public-data:cdc_places\",\n      \"selfLink\": \"https://content-bigquery.googleapis.com/bigquery/v2/projects/bigquery-public-data/datasets/cdc_places\",\n      \"datasetReference\": {\n        \"datasetId\": \"cdc_places\",\n        \"projectId\": \"bigquery-public-data\"\n      },\n      \"description\": \"Local Data for Better Health, County Data\",\n      \"access\": [\n        {\n          \"role\": \"WRITER\",\n          \"specialGroup\": \"projectWriters\"\
      \n        },\n        {\n          \"role\": \"OWNER\",\n          \"specialGroup\": \"projectOwners\"\n        },\n        {\n          \"role\": \"OWNER\",\n          \"userByEmail\": \"some-redacted-email@bigquery-public-data.iam.gserviceaccount.com\"\n        },\n        {\n          \"role\": \"READER\",\n          \"specialGroup\": \"projectReaders\"\n        }\n      ],\n      \"creationTime\": \"1640891845643\",\n      \"lastModifiedTime\": \"1640891845643\",\n      \"location\": \"US\",\n      \"type\": \"DEFAULT\",\n      \"maxTimeTravelHours\": \"168\"\n    }"
  - signature: 'def list_table_ids(project_id: str, dataset_id: str, credentials: google.auth.credentials.Credentials, settings: google.adk.tools.bigquery.config.BigQueryToolConfig) -> list[str]:'
    docstring: "List table ids in a BigQuery dataset.\n\nArgs:\n    project_id (str): The Google Cloud project id containing the dataset.\n    dataset_id (str): The BigQuery dataset id.\n    credentials (Credentials): The credentials to use for the request.\n\nReturns:\n    list[str]: List of the tables ids present in the dataset.\n\nExamples:\n    >>> list_table_ids(\"bigquery-public-data\", \"cdc_places\")\n    ['chronic_disease_indicators',\n     'local_data_for_better_health_county_data']"
  - signature: 'def get_table_info(project_id: str, dataset_id: str, table_id: str, credentials: google.auth.credentials.Credentials, settings: google.adk.tools.bigquery.config.BigQueryToolConfig) -> dict:'
    docstring: "Get metadata information about a BigQuery table.\n\nArgs:\n    project_id (str): The Google Cloud project id containing the dataset.\n    dataset_id (str): The BigQuery dataset id containing the table.\n    table_id (str): The BigQuery table id.\n    credentials (Credentials): The credentials to use for the request.\n\nReturns:\n    dict: Dictionary representing the properties of the table.\n\nExamples:\n    >>> get_table_info(\"bigquery-public-data\", \"cdc_places\", \"local_data_for_better_health_county_data\")\n    {\n      \"kind\": \"bigquery#table\",\n      \"etag\": \"wx23aDqmgc39oUSiNuYTAA==\",\n      \"id\": \"bigquery-public-data:cdc_places.local_data_for_better_health_county_data\",\n      \"selfLink\": \"https://content-bigquery.googleapis.com/bigquery/v2/projects/bigquery-public-data/datasets/cdc_places/tables/local_data_for_better_health_county_data\",\n      \"tableReference\": {\n        \"projectId\": \"bigquery-public-data\",\n        \"datasetId\": \"cdc_places\"\
      ,\n        \"tableId\": \"local_data_for_better_health_county_data\"\n      },\n      \"description\": \"Local Data for Better Health, County Data\",\n      \"schema\": {\n        \"fields\": [\n          {\n            \"name\": \"year\",\n            \"type\": \"INTEGER\",\n            \"mode\": \"NULLABLE\"\n          },\n          {\n            \"name\": \"stateabbr\",\n            \"type\": \"STRING\",\n            \"mode\": \"NULLABLE\"\n          },\n          {\n            \"name\": \"statedesc\",\n            \"type\": \"STRING\",\n            \"mode\": \"NULLABLE\"\n          },\n          {\n            \"name\": \"locationname\",\n            \"type\": \"STRING\",\n            \"mode\": \"NULLABLE\"\n          },\n          {\n            \"name\": \"datasource\",\n            \"type\": \"STRING\",\n            \"mode\": \"NULLABLE\"\n          },\n          {\n            \"name\": \"category\",\n            \"type\": \"STRING\",\n            \"mode\": \"NULLABLE\"\n\
      \          },\n          {\n            \"name\": \"measure\",\n            \"type\": \"STRING\",\n            \"mode\": \"NULLABLE\"\n          },\n          {\n            \"name\": \"data_value_unit\",\n            \"type\": \"STRING\",\n            \"mode\": \"NULLABLE\"\n          },\n          {\n            \"name\": \"data_value_type\",\n            \"type\": \"STRING\",\n            \"mode\": \"NULLABLE\"\n          },\n          {\n            \"name\": \"data_value\",\n            \"type\": \"FLOAT\",\n            \"mode\": \"NULLABLE\"\n          }\n        ]\n      },\n      \"numBytes\": \"234849\",\n      \"numLongTermBytes\": \"0\",\n      \"numRows\": \"1000\",\n      \"creationTime\": \"1640891846119\",\n      \"lastModifiedTime\": \"1749427268137\",\n      \"type\": \"TABLE\",\n      \"location\": \"US\",\n      \"numTimeTravelPhysicalBytes\": \"285737\",\n      \"numTotalLogicalBytes\": \"234849\",\n      \"numActiveLogicalBytes\": \"234849\",\n      \"numLongTermLogicalBytes\"\
      : \"0\",\n      \"numTotalPhysicalBytes\": \"326557\",\n      \"numActivePhysicalBytes\": \"326557\",\n      \"numLongTermPhysicalBytes\": \"0\",\n      \"numCurrentPhysicalBytes\": \"40820\"\n    }"
  - signature: 'def get_job_info(project_id: str, job_id: str, credentials: google.auth.credentials.Credentials, settings: google.adk.tools.bigquery.config.BigQueryToolConfig) -> dict:'
    docstring: "Get metadata information about a BigQuery job. Including slot usage,\n   job configuration, job statistics, job status, original query etc.\n\nArgs:\n    project_id (str): The Google Cloud project id containing the job.\n    job_id (str): The BigQuery job id.\n    credentials (Credentials): The credentials to use for the request.\n    settings (BigQueryToolConfig): The BigQuery tool settings.\n\nReturns:\n    dict: Dictionary representing the properties of the job.\n\nExamples:\n    >>> user may give job id in format of: project_id:region.job_id\n    like bigquery-public-data:US.bquxjob_12345678_1234567890\n    >>> get_job_info(\"bigquery-public-data\", \"bquxjob_12345678_1234567890\")\n    {\n      \"get_job_info_response\": {\n        \"configuration\": {\n          \"jobType\": \"QUERY\",\n          \"query\": {\n            \"destinationTable\": {\n              \"datasetId\": \"_fd6de55d5d5c13fcfb0449cbf933bb695b2c3085\",\n              \"projectId\": \"projectid\",\n\
      \              \"tableId\": \"anonfbbe65d6_9782_469b_9f56_1392560314b2\"\n            },\n            \"priority\": \"INTERACTIVE\",\n            \"query\": \"SELECT * FROM `projectid.dataset_id.table_id` WHERE TIMESTAMP_TRUNC(_PARTITIONTIME, DAY) = TIMESTAMP(\"2025-10-29\") LIMIT 1000\",\n            \"useLegacySql\": false,\n            \"writeDisposition\": \"WRITE_TRUNCATE\"\n          }\n        },\n        \"etag\": \"EdeYv9sdcO7tD9HsffvcuQ==\",\n        \"id\": \"projectid:US.job-id\",\n        \"jobCreationReason\": {\n          \"code\": \"REQUESTED\"\n        },\n        \"jobReference\": {\n          \"jobId\": \"job-id\",\n          \"location\": \"US\",\n          \"projectId\": \"projectid\"\n        },\n        \"kind\": \"bigquery#job\",\n        \"principal_subject\": \"user:abc@google.com\",\n        \"selfLink\": \"https://bigquery.googleapis.com/bigquery/v2/projects/projectid/jobs/job-id?location=US\",\n        \"statistics\": {\n          \"creationTime\": 1761760370152,\n\
      \          \"endTime\": 1761760371250,\n          \"finalExecutionDurationMs\": \"489\",\n          \"query\": {\n            \"billingTier\": 1,\n            \"cacheHit\": false,\n            \"estimatedBytesProcessed\": \"5597805\",\n            \"metadataCacheStatistics\": {\n              \"tableMetadataCacheUsage\": [\n                {\n                  \"explanation\": \"Table does not have CMETA.\",\n                  \"tableReference\": {\n                    \"datasetId\": \"datasetId\",\n                    \"projectId\": \"projectid\",\n                    \"tableId\": \"tableId\"\n                  },\n                  \"unusedReason\": \"OTHER_REASON\"\n                }\n              ]\n            },\n            \"queryPlan\": [\n              {\n                \"completedParallelInputs\": \"3\",\n                \"computeMode\": \"BIGQUERY\",\n                \"computeMsAvg\": \"13\",\n                \"computeMsMax\": \"15\",\n                \"computeRatioAvg\"\
      : 0.054852320675105488,\n                \"computeRatioMax\": 0.063291139240506333,\n                \"endMs\": \"1761760370422\",\n                \"id\": \"0\",\n                \"name\": \"S00: Input\",\n                \"parallelInputs\": \"8\",\n                \"readMsAvg\": \"18\",\n                \"readMsMax\": \"21\",\n                \"readRatioAvg\": 0.0759493670886076,\n                \"readRatioMax\": 0.088607594936708861,\n                \"recordsRead\": \"1690\",\n                \"recordsWritten\": \"1690\",\n                \"shuffleOutputBytes\": \"1031149\",\n                \"shuffleOutputBytesSpilled\": \"0\",\n                \"slotMs\": \"157\",\n                \"startMs\": \"1761760370388\",\n                \"status\": \"COMPLETE\",\n                \"steps\": [\n                  {\n                    \"kind\": \"READ\",\n                    \"substeps\": [\n                      \"$2:extendedFields.$is_not_null, $3:extendedFields.traceId, $4:span.$is_not_null,\
      \ $5:span.spanKind, $6:span.endTime, $7:span.startTime, $8:span.parentSpanId, $9:span.spanId, $10:span.name, $11:span.childSpanCount.$is_not_null, $12:span.childSpanCount.value, $13:span.sameProcessAsParentSpan.$is_not_null, $14:span.sameProcessAsParentSpan.value, $15:span.status.$is_not_null, $16:span.status.message, $17:span.status.code\",\n                      \"FROM projectid.dataset_id.table_id\",\n                      \"WHERE equal(timestamp_trunc($1, 3), 1761696000.000000000)\"\n                    ]\n                  },\n                  {\n                    \"kind\": \"LIMIT\",\n                    \"substeps\": [\n                      \"1000\"\n                    ]\n                  },\n                  {\n                    \"kind\": \"WRITE\",\n                    \"substeps\": [\n                      \"$2, $3, $4, $5, $6, $7, $8, $9, $10, $11, $12, $13, $14, $15, $16, $17\",\n                      \"TO __stage00_output\"\n                    ]\n           \
      \       }\n                ],\n                \"waitMsAvg\": \"1\",\n                \"waitMsMax\": \"1\",\n                \"waitRatioAvg\": 0.0042194092827004216,\n                \"waitRatioMax\": 0.0042194092827004216,\n                \"writeMsAvg\": \"2\",\n                \"writeMsMax\": \"2\",\n                \"writeRatioAvg\": 0.0084388185654008432,\n                \"writeRatioMax\": 0.0084388185654008432\n              },\n              {\n                \"completedParallelInputs\": \"1\",\n                \"computeMode\": \"BIGQUERY\",\n                \"computeMsAvg\": \"22\",\n                \"computeMsMax\": \"22\",\n                \"computeRatioAvg\": 0.092827004219409287,\n                \"computeRatioMax\": 0.092827004219409287,\n                \"endMs\": \"1761760370428\",\n                \"id\": \"1\",\n                \"inputStages\": [\n                  \"0\"\n                ],\n                \"name\": \"S01: Compute+\",\n                \"parallelInputs\"\
      : \"1\",\n                \"readMsAvg\": \"0\",\n                \"readMsMax\": \"0\",\n                \"readRatioAvg\": 0,\n                \"readRatioMax\": 0,\n                \"recordsRead\": \"1001\",\n                \"recordsWritten\": \"1000\",\n                \"shuffleOutputBytes\": \"800157\",\n                \"shuffleOutputBytesSpilled\": \"0\",\n                \"slotMs\": \"29\",\n                \"startMs\": \"1761760370398\",\n                \"status\": \"COMPLETE\",\n                \"steps\": [\n                  {\n                    \"kind\": \"READ\",\n                    \"substeps\": [\n                      \"$2, $3, $4, $5, $6, $7, $8, $9, $10, $11, $12, $13, $14, $15, $16, $17\",\n                      \"FROM __stage00_output\"\n                    ]\n                  },\n                  {\n                    \"kind\": \"COMPUTE\",\n                    \"substeps\": [\n                      \"$130 := MAKE_STRUCT($3, $2)\",\n                      \"\
      $131 := MAKE_STRUCT($10, $9, $8, MAKE_STRUCT($29, $28, $27), $7, $6, MAKE_STRUCT(...), MAKE_STRUCT(...), MAKE_STRUCT(...), ...)\"\n                    ]\n                  },\n                  {\n                    \"kind\": \"LIMIT\",\n                    \"substeps\": [\n                      \"1000\"\n                    ]\n                  },\n                  {\n                    \"kind\": \"WRITE\",\n                    \"substeps\": [\n                      \"$130, $131\",\n                      \"TO __stage01_output\"\n                    ]\n                  }\n                ],\n                \"waitMsAvg\": \"7\",\n                \"waitMsMax\": \"7\",\n                \"waitRatioAvg\": 0.029535864978902954,\n                \"waitRatioMax\": 0.029535864978902954,\n                \"writeMsAvg\": \"4\",\n                \"writeMsMax\": \"4\",\n                \"writeRatioAvg\": 0.016877637130801686,\n                \"writeRatioMax\": 0.016877637130801686\n     \
      \         },\n              {\n                \"completedParallelInputs\": \"1\",\n                \"computeMode\": \"BIGQUERY\",\n                \"computeMsAvg\": \"33\",\n                \"computeMsMax\": \"33\",\n                \"computeRatioAvg\": 0.13924050632911392,\n                \"computeRatioMax\": 0.13924050632911392,\n                \"endMs\": \"1761760370745\",\n                \"id\": \"2\",\n                \"inputStages\": [\n                  \"1\"\n                ],\n                \"name\": \"S02: Output\",\n                \"parallelInputs\": \"1\",\n                \"readMsAvg\": \"0\",\n                \"readMsMax\": \"0\",\n                \"readRatioAvg\": 0,\n                \"readRatioMax\": 0,\n                \"recordsRead\": \"1000\",\n                \"recordsWritten\": \"1000\",\n                \"shuffleOutputBytes\": \"459829\",\n                \"shuffleOutputBytesSpilled\": \"0\",\n                \"slotMs\": \"106\",\n                \"startMs\"\
      : \"1761760370667\",\n                \"status\": \"COMPLETE\",\n                \"steps\": [\n                  {\n                    \"kind\": \"READ\",\n                    \"substeps\": [\n                      \"$130, $131\",\n                      \"FROM __stage01_output\"\n                    ]\n                  },\n                  {\n                    \"kind\": \"WRITE\",\n                    \"substeps\": [\n                      \"$130, $131\",\n                      \"TO __stage02_output\"\n                    ]\n                  }\n                ],\n                \"waitMsAvg\": \"237\",\n                \"waitMsMax\": \"237\",\n                \"waitRatioAvg\": 1,\n                \"waitRatioMax\": 1,\n                \"writeMsAvg\": \"55\",\n                \"writeMsMax\": \"55\",\n                \"writeRatioAvg\": 0.2320675105485232,\n                \"writeRatioMax\": 0.2320675105485232\n              }\n            ],\n            \"referencedTables\": [\n\
      \              {\n                \"datasetId\": \"dataset_id\",\n                \"projectId\": \"projectid\",\n                \"tableId\": \"table_id\"\n              }\n            ],\n            \"statementType\": \"SELECT\",\n            \"timeline\": [\n              {\n                \"completedUnits\": \"5\",\n                \"elapsedMs\": \"492\",\n                \"estimatedRunnableUnits\": \"0\",\n                \"pendingUnits\": \"5\",\n                \"totalSlotMs\": \"293\"\n              }\n            ],\n            \"totalBytesBilled\": \"10485760\",\n            \"totalBytesProcessed\": \"5597805\",\n            \"totalPartitionsProcessed\": \"2\",\n            \"totalSlotMs\": \"293\",\n            \"transferredBytes\": \"0\"\n          },\n          \"startTime\": 1761760370268,\n          \"totalBytesProcessed\": \"5597805\",\n          \"totalSlotMs\": \"293\"\n        },\n        \"status\": {\n          \"state\": \"DONE\"\n        },\n        \"user_email\"\
      : \"abc@google.com\"\n      }\n    }"
- rank: 1432
  id: google.adk.tools.bigquery.metadata_tool.get_dataset_info
  name: get_dataset_info
  file_path: google/adk/tools/bigquery/metadata_tool.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Get metadata information about a BigQuery dataset.\n\nArgs:\n    project_id (str): The Google Cloud project id containing the dataset.\n    dataset_id (str): The BigQuery dataset id.\n    credentials (Credentials): The credentials to use for the request.\n\nReturns:\n    dict: Dictionary representing the properties of the dataset.\n\nExamples:\n    >>> get_dataset_info(\"bigquery-public-data\", \"cdc_places\")\n    {\n      \"kind\": \"bigquery#dataset\",\n      \"etag\": \"fz9BaiXKgbGi53EpI2rJug==\",\n      \"id\": \"bigquery-public-data:cdc_places\",\n      \"selfLink\": \"https://content-bigquery.googleapis.com/bigquery/v2/projects/bigquery-public-data/datasets/cdc_places\",\n      \"datasetReference\": {\n        \"datasetId\": \"cdc_places\",\n        \"projectId\": \"bigquery-public-data\"\n      },\n      \"description\": \"Local Data for Better Health, County Data\",\n      \"access\": [\n        {\n          \"role\": \"WRITER\",\n          \"specialGroup\": \"projectWriters\"\
    \n        },\n        {\n          \"role\": \"OWNER\",\n          \"specialGroup\": \"projectOwners\"\n        },\n        {\n          \"role\": \"OWNER\",\n          \"userByEmail\": \"some-redacted-email@bigquery-public-data.iam.gserviceaccount.com\"\n        },\n        {\n          \"role\": \"READER\",\n          \"specialGroup\": \"projectReaders\"\n        }\n      ],\n      \"creationTime\": \"1640891845643\",\n      \"lastModifiedTime\": \"1640891845643\",\n      \"location\": \"US\",\n      \"type\": \"DEFAULT\",\n      \"maxTimeTravelHours\": \"168\"\n    }"
  signature: 'def get_dataset_info(project_id: str, dataset_id: str, credentials: google.auth.credentials.Credentials, settings: google.adk.tools.bigquery.config.BigQueryToolConfig) -> dict:'
- rank: 1433
  id: google.adk.tools.bigquery.metadata_tool.get_job_info
  name: get_job_info
  file_path: google/adk/tools/bigquery/metadata_tool.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Get metadata information about a BigQuery job. Including slot usage,\n   job configuration, job statistics, job status, original query etc.\n\nArgs:\n    project_id (str): The Google Cloud project id containing the job.\n    job_id (str): The BigQuery job id.\n    credentials (Credentials): The credentials to use for the request.\n    settings (BigQueryToolConfig): The BigQuery tool settings.\n\nReturns:\n    dict: Dictionary representing the properties of the job.\n\nExamples:\n    >>> user may give job id in format of: project_id:region.job_id\n    like bigquery-public-data:US.bquxjob_12345678_1234567890\n    >>> get_job_info(\"bigquery-public-data\", \"bquxjob_12345678_1234567890\")\n    {\n      \"get_job_info_response\": {\n        \"configuration\": {\n          \"jobType\": \"QUERY\",\n          \"query\": {\n            \"destinationTable\": {\n              \"datasetId\": \"_fd6de55d5d5c13fcfb0449cbf933bb695b2c3085\",\n              \"projectId\": \"projectid\",\n\
    \              \"tableId\": \"anonfbbe65d6_9782_469b_9f56_1392560314b2\"\n            },\n            \"priority\": \"INTERACTIVE\",\n            \"query\": \"SELECT * FROM `projectid.dataset_id.table_id` WHERE TIMESTAMP_TRUNC(_PARTITIONTIME, DAY) = TIMESTAMP(\"2025-10-29\") LIMIT 1000\",\n            \"useLegacySql\": false,\n            \"writeDisposition\": \"WRITE_TRUNCATE\"\n          }\n        },\n        \"etag\": \"EdeYv9sdcO7tD9HsffvcuQ==\",\n        \"id\": \"projectid:US.job-id\",\n        \"jobCreationReason\": {\n          \"code\": \"REQUESTED\"\n        },\n        \"jobReference\": {\n          \"jobId\": \"job-id\",\n          \"location\": \"US\",\n          \"projectId\": \"projectid\"\n        },\n        \"kind\": \"bigquery#job\",\n        \"principal_subject\": \"user:abc@google.com\",\n        \"selfLink\": \"https://bigquery.googleapis.com/bigquery/v2/projects/projectid/jobs/job-id?location=US\",\n        \"statistics\": {\n          \"creationTime\": 1761760370152,\n\
    \          \"endTime\": 1761760371250,\n          \"finalExecutionDurationMs\": \"489\",\n          \"query\": {\n            \"billingTier\": 1,\n            \"cacheHit\": false,\n            \"estimatedBytesProcessed\": \"5597805\",\n            \"metadataCacheStatistics\": {\n              \"tableMetadataCacheUsage\": [\n                {\n                  \"explanation\": \"Table does not have CMETA.\",\n                  \"tableReference\": {\n                    \"datasetId\": \"datasetId\",\n                    \"projectId\": \"projectid\",\n                    \"tableId\": \"tableId\"\n                  },\n                  \"unusedReason\": \"OTHER_REASON\"\n                }\n              ]\n            },\n            \"queryPlan\": [\n              {\n                \"completedParallelInputs\": \"3\",\n                \"computeMode\": \"BIGQUERY\",\n                \"computeMsAvg\": \"13\",\n                \"computeMsMax\": \"15\",\n                \"computeRatioAvg\"\
    : 0.054852320675105488,\n                \"computeRatioMax\": 0.063291139240506333,\n                \"endMs\": \"1761760370422\",\n                \"id\": \"0\",\n                \"name\": \"S00: Input\",\n                \"parallelInputs\": \"8\",\n                \"readMsAvg\": \"18\",\n                \"readMsMax\": \"21\",\n                \"readRatioAvg\": 0.0759493670886076,\n                \"readRatioMax\": 0.088607594936708861,\n                \"recordsRead\": \"1690\",\n                \"recordsWritten\": \"1690\",\n                \"shuffleOutputBytes\": \"1031149\",\n                \"shuffleOutputBytesSpilled\": \"0\",\n                \"slotMs\": \"157\",\n                \"startMs\": \"1761760370388\",\n                \"status\": \"COMPLETE\",\n                \"steps\": [\n                  {\n                    \"kind\": \"READ\",\n                    \"substeps\": [\n                      \"$2:extendedFields.$is_not_null, $3:extendedFields.traceId, $4:span.$is_not_null,\
    \ $5:span.spanKind, $6:span.endTime, $7:span.startTime, $8:span.parentSpanId, $9:span.spanId, $10:span.name, $11:span.childSpanCount.$is_not_null, $12:span.childSpanCount.value, $13:span.sameProcessAsParentSpan.$is_not_null, $14:span.sameProcessAsParentSpan.value, $15:span.status.$is_not_null, $16:span.status.message, $17:span.status.code\",\n                      \"FROM projectid.dataset_id.table_id\",\n                      \"WHERE equal(timestamp_trunc($1, 3), 1761696000.000000000)\"\n                    ]\n                  },\n                  {\n                    \"kind\": \"LIMIT\",\n                    \"substeps\": [\n                      \"1000\"\n                    ]\n                  },\n                  {\n                    \"kind\": \"WRITE\",\n                    \"substeps\": [\n                      \"$2, $3, $4, $5, $6, $7, $8, $9, $10, $11, $12, $13, $14, $15, $16, $17\",\n                      \"TO __stage00_output\"\n                    ]\n             \
    \     }\n                ],\n                \"waitMsAvg\": \"1\",\n                \"waitMsMax\": \"1\",\n                \"waitRatioAvg\": 0.0042194092827004216,\n                \"waitRatioMax\": 0.0042194092827004216,\n                \"writeMsAvg\": \"2\",\n                \"writeMsMax\": \"2\",\n                \"writeRatioAvg\": 0.0084388185654008432,\n                \"writeRatioMax\": 0.0084388185654008432\n              },\n              {\n                \"completedParallelInputs\": \"1\",\n                \"computeMode\": \"BIGQUERY\",\n                \"computeMsAvg\": \"22\",\n                \"computeMsMax\": \"22\",\n                \"computeRatioAvg\": 0.092827004219409287,\n                \"computeRatioMax\": 0.092827004219409287,\n                \"endMs\": \"1761760370428\",\n                \"id\": \"1\",\n                \"inputStages\": [\n                  \"0\"\n                ],\n                \"name\": \"S01: Compute+\",\n                \"parallelInputs\"\
    : \"1\",\n                \"readMsAvg\": \"0\",\n                \"readMsMax\": \"0\",\n                \"readRatioAvg\": 0,\n                \"readRatioMax\": 0,\n                \"recordsRead\": \"1001\",\n                \"recordsWritten\": \"1000\",\n                \"shuffleOutputBytes\": \"800157\",\n                \"shuffleOutputBytesSpilled\": \"0\",\n                \"slotMs\": \"29\",\n                \"startMs\": \"1761760370398\",\n                \"status\": \"COMPLETE\",\n                \"steps\": [\n                  {\n                    \"kind\": \"READ\",\n                    \"substeps\": [\n                      \"$2, $3, $4, $5, $6, $7, $8, $9, $10, $11, $12, $13, $14, $15, $16, $17\",\n                      \"FROM __stage00_output\"\n                    ]\n                  },\n                  {\n                    \"kind\": \"COMPUTE\",\n                    \"substeps\": [\n                      \"$130 := MAKE_STRUCT($3, $2)\",\n                      \"$131\
    \ := MAKE_STRUCT($10, $9, $8, MAKE_STRUCT($29, $28, $27), $7, $6, MAKE_STRUCT(...), MAKE_STRUCT(...), MAKE_STRUCT(...), ...)\"\n                    ]\n                  },\n                  {\n                    \"kind\": \"LIMIT\",\n                    \"substeps\": [\n                      \"1000\"\n                    ]\n                  },\n                  {\n                    \"kind\": \"WRITE\",\n                    \"substeps\": [\n                      \"$130, $131\",\n                      \"TO __stage01_output\"\n                    ]\n                  }\n                ],\n                \"waitMsAvg\": \"7\",\n                \"waitMsMax\": \"7\",\n                \"waitRatioAvg\": 0.029535864978902954,\n                \"waitRatioMax\": 0.029535864978902954,\n                \"writeMsAvg\": \"4\",\n                \"writeMsMax\": \"4\",\n                \"writeRatioAvg\": 0.016877637130801686,\n                \"writeRatioMax\": 0.016877637130801686\n          \
    \    },\n              {\n                \"completedParallelInputs\": \"1\",\n                \"computeMode\": \"BIGQUERY\",\n                \"computeMsAvg\": \"33\",\n                \"computeMsMax\": \"33\",\n                \"computeRatioAvg\": 0.13924050632911392,\n                \"computeRatioMax\": 0.13924050632911392,\n                \"endMs\": \"1761760370745\",\n                \"id\": \"2\",\n                \"inputStages\": [\n                  \"1\"\n                ],\n                \"name\": \"S02: Output\",\n                \"parallelInputs\": \"1\",\n                \"readMsAvg\": \"0\",\n                \"readMsMax\": \"0\",\n                \"readRatioAvg\": 0,\n                \"readRatioMax\": 0,\n                \"recordsRead\": \"1000\",\n                \"recordsWritten\": \"1000\",\n                \"shuffleOutputBytes\": \"459829\",\n                \"shuffleOutputBytesSpilled\": \"0\",\n                \"slotMs\": \"106\",\n                \"startMs\"\
    : \"1761760370667\",\n                \"status\": \"COMPLETE\",\n                \"steps\": [\n                  {\n                    \"kind\": \"READ\",\n                    \"substeps\": [\n                      \"$130, $131\",\n                      \"FROM __stage01_output\"\n                    ]\n                  },\n                  {\n                    \"kind\": \"WRITE\",\n                    \"substeps\": [\n                      \"$130, $131\",\n                      \"TO __stage02_output\"\n                    ]\n                  }\n                ],\n                \"waitMsAvg\": \"237\",\n                \"waitMsMax\": \"237\",\n                \"waitRatioAvg\": 1,\n                \"waitRatioMax\": 1,\n                \"writeMsAvg\": \"55\",\n                \"writeMsMax\": \"55\",\n                \"writeRatioAvg\": 0.2320675105485232,\n                \"writeRatioMax\": 0.2320675105485232\n              }\n            ],\n            \"referencedTables\": [\n\
    \              {\n                \"datasetId\": \"dataset_id\",\n                \"projectId\": \"projectid\",\n                \"tableId\": \"table_id\"\n              }\n            ],\n            \"statementType\": \"SELECT\",\n            \"timeline\": [\n              {\n                \"completedUnits\": \"5\",\n                \"elapsedMs\": \"492\",\n                \"estimatedRunnableUnits\": \"0\",\n                \"pendingUnits\": \"5\",\n                \"totalSlotMs\": \"293\"\n              }\n            ],\n            \"totalBytesBilled\": \"10485760\",\n            \"totalBytesProcessed\": \"5597805\",\n            \"totalPartitionsProcessed\": \"2\",\n            \"totalSlotMs\": \"293\",\n            \"transferredBytes\": \"0\"\n          },\n          \"startTime\": 1761760370268,\n          \"totalBytesProcessed\": \"5597805\",\n          \"totalSlotMs\": \"293\"\n        },\n        \"status\": {\n          \"state\": \"DONE\"\n        },\n        \"user_email\"\
    : \"abc@google.com\"\n      }\n    }"
  signature: 'def get_job_info(project_id: str, job_id: str, credentials: google.auth.credentials.Credentials, settings: google.adk.tools.bigquery.config.BigQueryToolConfig) -> dict:'
- rank: 1434
  id: google.adk.tools.bigquery.metadata_tool.get_table_info
  name: get_table_info
  file_path: google/adk/tools/bigquery/metadata_tool.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Get metadata information about a BigQuery table.\n\nArgs:\n    project_id (str): The Google Cloud project id containing the dataset.\n    dataset_id (str): The BigQuery dataset id containing the table.\n    table_id (str): The BigQuery table id.\n    credentials (Credentials): The credentials to use for the request.\n\nReturns:\n    dict: Dictionary representing the properties of the table.\n\nExamples:\n    >>> get_table_info(\"bigquery-public-data\", \"cdc_places\", \"local_data_for_better_health_county_data\")\n    {\n      \"kind\": \"bigquery#table\",\n      \"etag\": \"wx23aDqmgc39oUSiNuYTAA==\",\n      \"id\": \"bigquery-public-data:cdc_places.local_data_for_better_health_county_data\",\n      \"selfLink\": \"https://content-bigquery.googleapis.com/bigquery/v2/projects/bigquery-public-data/datasets/cdc_places/tables/local_data_for_better_health_county_data\",\n      \"tableReference\": {\n        \"projectId\": \"bigquery-public-data\",\n        \"datasetId\": \"cdc_places\"\
    ,\n        \"tableId\": \"local_data_for_better_health_county_data\"\n      },\n      \"description\": \"Local Data for Better Health, County Data\",\n      \"schema\": {\n        \"fields\": [\n          {\n            \"name\": \"year\",\n            \"type\": \"INTEGER\",\n            \"mode\": \"NULLABLE\"\n          },\n          {\n            \"name\": \"stateabbr\",\n            \"type\": \"STRING\",\n            \"mode\": \"NULLABLE\"\n          },\n          {\n            \"name\": \"statedesc\",\n            \"type\": \"STRING\",\n            \"mode\": \"NULLABLE\"\n          },\n          {\n            \"name\": \"locationname\",\n            \"type\": \"STRING\",\n            \"mode\": \"NULLABLE\"\n          },\n          {\n            \"name\": \"datasource\",\n            \"type\": \"STRING\",\n            \"mode\": \"NULLABLE\"\n          },\n          {\n            \"name\": \"category\",\n            \"type\": \"STRING\",\n            \"mode\": \"NULLABLE\"\n \
    \         },\n          {\n            \"name\": \"measure\",\n            \"type\": \"STRING\",\n            \"mode\": \"NULLABLE\"\n          },\n          {\n            \"name\": \"data_value_unit\",\n            \"type\": \"STRING\",\n            \"mode\": \"NULLABLE\"\n          },\n          {\n            \"name\": \"data_value_type\",\n            \"type\": \"STRING\",\n            \"mode\": \"NULLABLE\"\n          },\n          {\n            \"name\": \"data_value\",\n            \"type\": \"FLOAT\",\n            \"mode\": \"NULLABLE\"\n          }\n        ]\n      },\n      \"numBytes\": \"234849\",\n      \"numLongTermBytes\": \"0\",\n      \"numRows\": \"1000\",\n      \"creationTime\": \"1640891846119\",\n      \"lastModifiedTime\": \"1749427268137\",\n      \"type\": \"TABLE\",\n      \"location\": \"US\",\n      \"numTimeTravelPhysicalBytes\": \"285737\",\n      \"numTotalLogicalBytes\": \"234849\",\n      \"numActiveLogicalBytes\": \"234849\",\n      \"numLongTermLogicalBytes\"\
    : \"0\",\n      \"numTotalPhysicalBytes\": \"326557\",\n      \"numActivePhysicalBytes\": \"326557\",\n      \"numLongTermPhysicalBytes\": \"0\",\n      \"numCurrentPhysicalBytes\": \"40820\"\n    }"
  signature: 'def get_table_info(project_id: str, dataset_id: str, table_id: str, credentials: google.auth.credentials.Credentials, settings: google.adk.tools.bigquery.config.BigQueryToolConfig) -> dict:'
- rank: 1435
  id: google.adk.tools.bigquery.metadata_tool.list_dataset_ids
  name: list_dataset_ids
  file_path: google/adk/tools/bigquery/metadata_tool.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "List BigQuery dataset ids in a Google Cloud project.\n\nArgs:\n    project_id (str): The Google Cloud project id.\n    credentials (Credentials): The credentials to use for the request.\n\nReturns:\n    list[str]: List of the BigQuery dataset ids present in the project.\n\nExamples:\n    >>> list_dataset_ids(\"bigquery-public-data\")\n    ['america_health_rankings',\n     'american_community_survey',\n     'aml_ai_input_dataset',\n     'austin_311',\n     'austin_bikeshare',\n     'austin_crime',\n     'austin_incidents',\n     'austin_waste',\n     'baseball',\n     'bbc_news']"
  signature: 'def list_dataset_ids(project_id: str, credentials: google.auth.credentials.Credentials, settings: google.adk.tools.bigquery.config.BigQueryToolConfig) -> list[str]:'
- rank: 1436
  id: google.adk.tools.bigquery.metadata_tool.list_table_ids
  name: list_table_ids
  file_path: google/adk/tools/bigquery/metadata_tool.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "List table ids in a BigQuery dataset.\n\nArgs:\n    project_id (str): The Google Cloud project id containing the dataset.\n    dataset_id (str): The BigQuery dataset id.\n    credentials (Credentials): The credentials to use for the request.\n\nReturns:\n    list[str]: List of the tables ids present in the dataset.\n\nExamples:\n    >>> list_table_ids(\"bigquery-public-data\", \"cdc_places\")\n    ['chronic_disease_indicators',\n     'local_data_for_better_health_county_data']"
  signature: 'def list_table_ids(project_id: str, dataset_id: str, credentials: google.auth.credentials.Credentials, settings: google.adk.tools.bigquery.config.BigQueryToolConfig) -> list[str]:'
- rank: 1437
  id: google.adk.tools.bigquery.query_tool
  name: query_tool
  file_path: google/adk/tools/bigquery/query_tool.py
  type: MODULE
  group: Orphan
  usage_score: 0
  methods:
  - signature: 'def execute_sql(project_id: str, query: str, credentials: google.auth.credentials.Credentials, settings: google.adk.tools.bigquery.config.BigQueryToolConfig, tool_context: google.adk.tools.tool_context.ToolContext, dry_run: bool) -> dict:'
    docstring: "Run a BigQuery or BigQuery ML SQL query in the project and return the result.\n\nArgs:\n    project_id (str): The GCP project id in which the query should be\n      executed.\n    query (str): The BigQuery SQL query to be executed.\n    credentials (Credentials): The credentials to use for the request.\n    settings (BigQueryToolConfig): The settings for the tool.\n    tool_context (ToolContext): The context for the tool.\n    dry_run (bool, default False): If True, the query will not be executed.\n      Instead, the query will be validated and information about the query\n      will be returned. Defaults to False.\n\nReturns:\n    dict: If `dry_run` is False, dictionary representing the result of the\n          query. If the result contains the key \"result_is_likely_truncated\"\n          with value True, it means that there may be additional rows matching\n          the query not returned in the result.\n          If `dry_run` is True, dictionary with \"dry_run_info\"\
      \ field\n          containing query information returned by BigQuery.\n\nExamples:\n    Fetch data or insights from a table:\n\n        >>> execute_sql(\"my_project\",\n        ... \"SELECT island, COUNT(*) AS population \"\n        ... \"FROM bigquery-public-data.ml_datasets.penguins GROUP BY island\")\n        {\n          \"status\": \"SUCCESS\",\n          \"rows\": [\n              {\n                  \"island\": \"Dream\",\n                  \"population\": 124\n              },\n              {\n                  \"island\": \"Biscoe\",\n                  \"population\": 168\n              },\n              {\n                  \"island\": \"Torgersen\",\n                  \"population\": 52\n              }\n          ]\n        }\n\n    Validate a query and estimate costs without executing it:\n\n        >>> execute_sql(\n        ...     \"my_project\",\n        ...     \"SELECT island FROM \"\n        ...     \"bigquery-public-data.ml_datasets.penguins\",\n        ...  \
      \   dry_run=True\n        ... )\n        {\n          \"status\": \"SUCCESS\",\n          \"dry_run_info\": {\n            \"configuration\": {\n              \"dryRun\": True,\n              \"jobType\": \"QUERY\",\n              \"query\": {\n                \"destinationTable\": {\n                  \"datasetId\": \"_...\",\n                  \"projectId\": \"my_project\",\n                  \"tableId\": \"anon...\"\n                },\n                \"priority\": \"INTERACTIVE\",\n                \"query\": \"SELECT island FROM bigquery-public-data.ml_datasets.penguins\",\n                \"useLegacySql\": False,\n                \"writeDisposition\": \"WRITE_TRUNCATE\"\n              }\n            },\n            \"jobReference\": {\n              \"location\": \"US\",\n              \"projectId\": \"my_project\"\n            }\n          }\n        }"
  - signature: 'def get_execute_sql(settings: google.adk.tools.bigquery.config.BigQueryToolConfig) -> typing.Callable[Ellipsis, dict]:'
    docstring: "Get the execute_sql tool customized as per the given tool settings.\n\nArgs:\n    settings: BigQuery tool settings indicating the behavior of the\n      execute_sql tool.\n\nReturns:\n    callable[..., dict]: A version of the execute_sql tool respecting the tool\n    settings."
  - signature: 'def forecast(project_id: str, history_data: str, timestamp_col: str, data_col: str, horizon: int, id_cols: typing.Optional[list[str]], *, credentials: google.auth.credentials.Credentials, settings: google.adk.tools.bigquery.config.BigQueryToolConfig, tool_context: google.adk.tools.tool_context.ToolContext) -> dict:'
    docstring: "Run a BigQuery AI time series forecast using AI.FORECAST.\n\nArgs:\n    project_id (str): The GCP project id in which the query should be\n      executed.\n    history_data (str): The table id of the BigQuery table containing the\n      history time series data or a query statement that select the history\n      data.\n    timestamp_col (str): The name of the column containing the timestamp for\n      each data point.\n    data_col (str): The name of the column containing the numerical values to\n      be forecasted.\n    horizon (int, optional): The number of time steps to forecast into the\n      future. Defaults to 10.\n    id_cols (list, optional): The column names of the id columns to indicate\n      each time series when there are multiple time series in the table. All\n      elements must be strings. Defaults to None.\n    credentials (Credentials): The credentials to use for the request.\n    settings (BigQueryToolConfig): The settings for the tool.\n    tool_context\
      \ (ToolContext): The context for the tool.\n\nReturns:\n    dict: Dictionary representing the result of the forecast. The result\n          contains the forecasted values along with prediction intervals.\n\nExamples:\n    Forecast daily sales for the next 7 days based on historical data from\n    a BigQuery table:\n\n        >>> forecast(\n        ...     project_id=\"my-gcp-project\",\n        ...     history_data=\"my-dataset.my-sales-table\",\n        ...     timestamp_col=\"sale_date\",\n        ...     data_col=\"daily_sales\",\n        ...     horizon=7\n        ... )\n        {\n          \"status\": \"SUCCESS\",\n          \"rows\": [\n            {\n              \"forecast_timestamp\": \"2025-01-08T00:00:00\",\n              \"forecast_value\": 12345.67,\n              \"confidence_level\": 0.95,\n              \"prediction_interval_lower_bound\": 11000.0,\n              \"prediction_interval_upper_bound\": 13691.34,\n              \"ai_forecast_status\": \"\"\n         \
      \   },\n            ...\n          ]\n        }\n\n    Forecast multiple time series using a SQL query as input:\n\n        >>> history_query = (\n        ...     \"SELECT unique_id, timestamp, value \"\n        ...     \"FROM `my-project.my-dataset.my-timeseries-table` \"\n        ...     \"WHERE timestamp > '1980-01-01'\"\n        ... )\n        >>> forecast(\n        ...     project_id=\"my-gcp-project\",\n        ...     history_data=history_query,\n        ...     timestamp_col=\"timestamp\",\n        ...     data_col=\"value\",\n        ...     id_cols=[\"unique_id\"],\n        ...     horizon=14\n        ... )\n        {\n          \"status\": \"SUCCESS\",\n          \"rows\": [\n            {\n              \"unique_id\": \"T1\",\n              \"forecast_timestamp\": \"1980-08-28T00:00:00\",\n              \"forecast_value\": 1253218.75,\n              \"confidence_level\": 0.95,\n              \"prediction_interval_lower_bound\": 274252.51,\n              \"prediction_interval_upper_bound\"\
      : 2232184.99,\n              \"ai_forecast_status\": \"\"\n            },\n            ...\n          ]\n        }\n\n    Error Scenarios:\n        When an element in `id_cols` is not a string:\n\n        >>> forecast(\n        ...     project_id=\"my-gcp-project\",\n        ...     history_data=\"my-dataset.my-sales-table\",\n        ...     timestamp_col=\"sale_date\",\n        ...     data_col=\"daily_sales\",\n        ...     id_cols=[\"store_id\", 123]\n        ... )\n        {\n          \"status\": \"ERROR\",\n          \"error_details\": \"All elements in id_cols must be strings.\"\n        }\n\n        When `history_data` refers to a table that does not exist:\n\n        >>> forecast(\n        ...     project_id=\"my-gcp-project\",\n        ...     history_data=\"my-dataset.nonexistent-table\",\n        ...     timestamp_col=\"sale_date\",\n        ...     data_col=\"daily_sales\"\n        ... )\n        {\n          \"status\": \"ERROR\",\n          \"error_details\": \"\
      Not found: Table\n          my-gcp-project:my-dataset.nonexistent-table was not found in\n          location US\"\n        }"
  - signature: 'def analyze_contribution(project_id: str, input_data: str, contribution_metric: str, dimension_id_cols: list[str], is_test_col: str, credentials: google.auth.credentials.Credentials, settings: google.adk.tools.bigquery.config.BigQueryToolConfig, tool_context: google.adk.tools.tool_context.ToolContext, top_k_insights: int, pruning_method: str) -> dict:'
    docstring: "Run a BigQuery ML contribution analysis using ML.CREATE_MODEL and ML.GET_INSIGHTS.\n\nArgs:\n    project_id (str): The GCP project id in which the query should be\n      executed.\n    input_data (str): The data that contain the test and control data to\n      analyze. Can be a fully qualified BigQuery table ID or a SQL query.\n    dimension_id_cols (list[str]): The column names of the dimension columns.\n    contribution_metric (str): The name of the column that contains the metric\n      to analyze. Provides the expression to use to calculate the metric you\n      are analyzing. To calculate a summable metric, the expression must be in\n      the form SUM(metric_column_name), where metric_column_name is a numeric\n      data type.  To calculate a summable ratio metric, the expression must be\n      in the form\n      SUM(numerator_metric_column_name)/SUM(denominator_metric_column_name),\n      where numerator_metric_column_name and denominator_metric_column_name\n     \
      \ are numeric data types.  To calculate a summable by category metric, the\n      expression must be in the form\n      SUM(metric_sum_column_name)/COUNT(DISTINCT categorical_column_name). The\n      summed column must be a numeric data type. The categorical column must\n      have type BOOL, DATE, DATETIME, TIME, TIMESTAMP, STRING, or INT64.\n    is_test_col (str): The name of the column to use to determine whether a\n      given row is test data or control data. The column must have a BOOL data\n      type.\n    credentials: The credentials to use for the request.\n    settings: The settings for the tool.\n    tool_context: The context for the tool.\n    top_k_insights (int, optional): The number of top insights to return,\n      ranked by apriori support. Defaults to 30.\n    pruning_method (str, optional): The method to use for pruning redundant\n      insights. Can be 'NO_PRUNING' or 'PRUNE_REDUNDANT_INSIGHTS'. Defaults to\n      \"PRUNE_REDUNDANT_INSIGHTS\".\n\nReturns:\n   \
      \ dict: Dictionary representing the result of the contribution analysis.\n\nExamples:\n    Analyze the contribution of different dimensions to the total sales:\n\n        >>> analyze_contribution(\n        ...     project_id=\"my-gcp-project\",\n        ...     input_data=\"my-dataset.my-sales-table\",\n        ...     dimension_id_cols=[\"store_id\", \"product_category\"],\n        ...     contribution_metric=\"SUM(total_sales)\",\n        ...     is_test_col=\"is_test\"\n        ... )\n        The return is:\n        {\n          \"status\": \"SUCCESS\",\n          \"rows\": [\n            {\n              \"store_id\": \"S1\",\n              \"product_category\": \"Electronics\",\n              \"contributors\": [\"S1\", \"Electronics\"],\n              \"metric_test\": 120,\n              \"metric_control\": 100,\n              \"difference\": 20,\n              \"relative_difference\": 0.2,\n              \"unexpected_difference\": 5,\n              \"relative_unexpected_difference\"\
      : 0.043,\n              \"apriori_support\": 0.15\n            },\n            ...\n          ]\n        }\n\n    Analyze the contribution of different dimensions to the total sales using\n    a SQL query as input:\n\n        >>> analyze_contribution(\n        ...     project_id=\"my-gcp-project\",\n        ...     input_data=\"SELECT store_id, product_category, total_sales, \"\n        ...     \"is_test FROM `my-project.my-dataset.my-sales-table` \"\n        ...     \"WHERE transaction_date > '2025-01-01'\"\n        ...     dimension_id_cols=[\"store_id\", \"product_category\"],\n        ...     contribution_metric=\"SUM(total_sales)\",\n        ...     is_test_col=\"is_test\"\n        ... )\n        The return is:\n        {\n          \"status\": \"SUCCESS\",\n          \"rows\": [\n            {\n              \"store_id\": \"S2\",\n              \"product_category\": \"Groceries\",\n              \"contributors\": [\"S2\", \"Groceries\"],\n              \"metric_test\": 250,\n\
      \              \"metric_control\": 200,\n              \"difference\": 50,\n              \"relative_difference\": 0.25,\n              \"unexpected_difference\": 10,\n              \"relative_unexpected_difference\": 0.041,\n              \"apriori_support\": 0.22\n            },\n            ...\n          ]\n        }"
  - signature: 'def detect_anomalies(project_id: str, history_data: str, times_series_timestamp_col: str, times_series_data_col: str, horizon: typing.Optional[int], target_data: typing.Optional[str], times_series_id_cols: typing.Optional[list[str]], anomaly_prob_threshold: typing.Optional[float], *, credentials: google.auth.credentials.Credentials, settings: google.adk.tools.bigquery.config.BigQueryToolConfig, tool_context: google.adk.tools.tool_context.ToolContext) -> dict:'
    docstring: "Run a BigQuery time series ARIMA_PLUS model training and anomaly detection using CREATE MODEL and ML.DETECT_ANOMALIES clauses.\n\nArgs:\n    project_id (str): The GCP project id in which the query should be\n      executed.\n    history_data (str): The table id of the BigQuery table containing the\n      history time series data or a query statement that select the history\n      data.\n    times_series_timestamp_col (str): The name of the column containing the\n      timestamp for each data point.\n    times_series_data_col (str): The name of the column containing the\n      numerical values to be forecasted and anomaly detected.\n    horizon (int, optional): The number of time steps to forecast into the\n      future. Defaults to 1000.\n    target_data (str, optional): The table id of the BigQuery table containing\n      the target time series data or a query statement that select the target\n      data.\n    times_series_id_cols (list, optional): The column names of the\
      \ id columns\n      to indicate each time series when there are multiple time series in the\n      table. All elements must be strings. Defaults to None.\n    anomaly_prob_threshold (float, optional): The probability threshold to\n      determine if a data point is an anomaly. Defaults to 0.95.\n    credentials (Credentials): The credentials to use for the request.\n    settings (BigQueryToolConfig): The settings for the tool.\n    tool_context (ToolContext): The context for the tool.\n\nReturns:\n    dict: Dictionary representing the result of the anomaly detection. The\n          result contains the boolean value if the data point is anomaly or\n          not, lower bound, upper bound and anomaly probability for each data\n          point and also the probability of whether the data point is anomaly\n          or not.\n\nExamples:\n    Detect Anomalies daily sales based on historical data from a BigQuery\n    table:\n\n        >>> detect_anomalies(\n        ...     project_id=\"\
      my-gcp-project\",\n        ...     history_data=\"my-dataset.my-sales-table\",\n        ...     times_series_timestamp_col=\"sale_date\",\n        ...     times_series_data_col=\"daily_sales\"\n        ... )\n        {\n          \"status\": \"SUCCESS\",\n          \"rows\": [\n            {\n              \"ts_timestamp\": \"2021-01-01 00:00:01 UTC\",\n              \"ts_data\": 125.3,\n              \"is_anomaly\": TRUE,\n              \"lower_bound\": 129.5,\n              \"upper_bound\": 133.6 ,\n              \"anomaly_probability\": 0.93\n            },\n            ...\n          ]\n        }\n\n    Detect Anomalies on multiple time series using a SQL query as input:\n\n        >>> history_query = (\n        ...     \"SELECT unique_id, timestamp, value \"\n        ...     \"FROM `my-project.my-dataset.my-timeseries-table` \"\n        ...     \"WHERE timestamp > '1980-01-01'\"\n        ... )\n        >>> detect_anomalies(\n        ...     project_id=\"my-gcp-project\",\n   \
      \     ...     history_data=history_query,\n        ...     times_series_timestamp_col=\"timestamp\",\n        ...     times_series_data_col=\"value\",\n        ...     times_series_id_cols=[\"unique_id\"]\n        ... )\n        {\n          \"status\": \"SUCCESS\",\n          \"rows\": [\n            {\n              \"unique_id\": \"T1\",\n              \"ts_timestamp\": \"2021-01-01 00:00:01 UTC\",\n              \"ts_data\": 125.3,\n              \"is_anomaly\": TRUE,\n              \"lower_bound\": 129.5,\n              \"upper_bound\": 133.6 ,\n              \"anomaly_probability\": 0.93\n            },\n            ...\n          ]\n        }\n\n    Error Scenarios:\n        When an element in `times_series_id_cols` is not a string:\n\n        >>> detect_anomalies(\n        ...     project_id=\"my-gcp-project\",\n        ...     history_data=\"my-dataset.my-sales-table\",\n        ...     times_series_timestamp_col=\"sale_date\",\n        ...     times_series_data_col=\"daily_sales\"\
      ,\n        ...     times_series_id_cols=[\"store_id\", 123]\n        ... )\n        {\n          \"status\": \"ERROR\",\n          \"error_details\": \"All elements in times_series_id_cols must be\n          strings.\"\n        }\n\n        When `history_data` refers to a table that does not exist:\n\n        >>> detect_anomalies(\n        ...     project_id=\"my-gcp-project\",\n        ...     history_data=\"my-dataset.nonexistent-table\",\n        ...     times_series_timestamp_col=\"sale_date\",\n        ...     times_series_data_col=\"daily_sales\"\n        ... )\n        {\n          \"status\": \"ERROR\",\n          \"error_details\": \"Not found: Table\n          my-gcp-project:my-dataset.nonexistent-table was not found in\n          location US\"\n        }"
- rank: 1438
  id: google.adk.tools.bigquery.query_tool.analyze_contribution
  name: analyze_contribution
  file_path: google/adk/tools/bigquery/query_tool.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Run a BigQuery ML contribution analysis using ML.CREATE_MODEL and ML.GET_INSIGHTS.\n\nArgs:\n    project_id (str): The GCP project id in which the query should be\n      executed.\n    input_data (str): The data that contain the test and control data to\n      analyze. Can be a fully qualified BigQuery table ID or a SQL query.\n    dimension_id_cols (list[str]): The column names of the dimension columns.\n    contribution_metric (str): The name of the column that contains the metric\n      to analyze. Provides the expression to use to calculate the metric you\n      are analyzing. To calculate a summable metric, the expression must be in\n      the form SUM(metric_column_name), where metric_column_name is a numeric\n      data type.  To calculate a summable ratio metric, the expression must be\n      in the form\n      SUM(numerator_metric_column_name)/SUM(denominator_metric_column_name),\n      where numerator_metric_column_name and denominator_metric_column_name\n      are\
    \ numeric data types.  To calculate a summable by category metric, the\n      expression must be in the form\n      SUM(metric_sum_column_name)/COUNT(DISTINCT categorical_column_name). The\n      summed column must be a numeric data type. The categorical column must\n      have type BOOL, DATE, DATETIME, TIME, TIMESTAMP, STRING, or INT64.\n    is_test_col (str): The name of the column to use to determine whether a\n      given row is test data or control data. The column must have a BOOL data\n      type.\n    credentials: The credentials to use for the request.\n    settings: The settings for the tool.\n    tool_context: The context for the tool.\n    top_k_insights (int, optional): The number of top insights to return,\n      ranked by apriori support. Defaults to 30.\n    pruning_method (str, optional): The method to use for pruning redundant\n      insights. Can be 'NO_PRUNING' or 'PRUNE_REDUNDANT_INSIGHTS'. Defaults to\n      \"PRUNE_REDUNDANT_INSIGHTS\".\n\nReturns:\n    dict:\
    \ Dictionary representing the result of the contribution analysis.\n\nExamples:\n    Analyze the contribution of different dimensions to the total sales:\n\n        >>> analyze_contribution(\n        ...     project_id=\"my-gcp-project\",\n        ...     input_data=\"my-dataset.my-sales-table\",\n        ...     dimension_id_cols=[\"store_id\", \"product_category\"],\n        ...     contribution_metric=\"SUM(total_sales)\",\n        ...     is_test_col=\"is_test\"\n        ... )\n        The return is:\n        {\n          \"status\": \"SUCCESS\",\n          \"rows\": [\n            {\n              \"store_id\": \"S1\",\n              \"product_category\": \"Electronics\",\n              \"contributors\": [\"S1\", \"Electronics\"],\n              \"metric_test\": 120,\n              \"metric_control\": 100,\n              \"difference\": 20,\n              \"relative_difference\": 0.2,\n              \"unexpected_difference\": 5,\n              \"relative_unexpected_difference\"\
    : 0.043,\n              \"apriori_support\": 0.15\n            },\n            ...\n          ]\n        }\n\n    Analyze the contribution of different dimensions to the total sales using\n    a SQL query as input:\n\n        >>> analyze_contribution(\n        ...     project_id=\"my-gcp-project\",\n        ...     input_data=\"SELECT store_id, product_category, total_sales, \"\n        ...     \"is_test FROM `my-project.my-dataset.my-sales-table` \"\n        ...     \"WHERE transaction_date > '2025-01-01'\"\n        ...     dimension_id_cols=[\"store_id\", \"product_category\"],\n        ...     contribution_metric=\"SUM(total_sales)\",\n        ...     is_test_col=\"is_test\"\n        ... )\n        The return is:\n        {\n          \"status\": \"SUCCESS\",\n          \"rows\": [\n            {\n              \"store_id\": \"S2\",\n              \"product_category\": \"Groceries\",\n              \"contributors\": [\"S2\", \"Groceries\"],\n              \"metric_test\": 250,\n \
    \             \"metric_control\": 200,\n              \"difference\": 50,\n              \"relative_difference\": 0.25,\n              \"unexpected_difference\": 10,\n              \"relative_unexpected_difference\": 0.041,\n              \"apriori_support\": 0.22\n            },\n            ...\n          ]\n        }"
  signature: 'def analyze_contribution(project_id: str, input_data: str, contribution_metric: str, dimension_id_cols: list[str], is_test_col: str, credentials: google.auth.credentials.Credentials, settings: google.adk.tools.bigquery.config.BigQueryToolConfig, tool_context: google.adk.tools.tool_context.ToolContext, top_k_insights: int, pruning_method: str) -> dict:'
- rank: 1439
  id: google.adk.tools.bigquery.query_tool.detect_anomalies
  name: detect_anomalies
  file_path: google/adk/tools/bigquery/query_tool.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Run a BigQuery time series ARIMA_PLUS model training and anomaly detection using CREATE MODEL and ML.DETECT_ANOMALIES clauses.\n\nArgs:\n    project_id (str): The GCP project id in which the query should be\n      executed.\n    history_data (str): The table id of the BigQuery table containing the\n      history time series data or a query statement that select the history\n      data.\n    times_series_timestamp_col (str): The name of the column containing the\n      timestamp for each data point.\n    times_series_data_col (str): The name of the column containing the\n      numerical values to be forecasted and anomaly detected.\n    horizon (int, optional): The number of time steps to forecast into the\n      future. Defaults to 1000.\n    target_data (str, optional): The table id of the BigQuery table containing\n      the target time series data or a query statement that select the target\n      data.\n    times_series_id_cols (list, optional): The column names of the\
    \ id columns\n      to indicate each time series when there are multiple time series in the\n      table. All elements must be strings. Defaults to None.\n    anomaly_prob_threshold (float, optional): The probability threshold to\n      determine if a data point is an anomaly. Defaults to 0.95.\n    credentials (Credentials): The credentials to use for the request.\n    settings (BigQueryToolConfig): The settings for the tool.\n    tool_context (ToolContext): The context for the tool.\n\nReturns:\n    dict: Dictionary representing the result of the anomaly detection. The\n          result contains the boolean value if the data point is anomaly or\n          not, lower bound, upper bound and anomaly probability for each data\n          point and also the probability of whether the data point is anomaly\n          or not.\n\nExamples:\n    Detect Anomalies daily sales based on historical data from a BigQuery\n    table:\n\n        >>> detect_anomalies(\n        ...     project_id=\"my-gcp-project\"\
    ,\n        ...     history_data=\"my-dataset.my-sales-table\",\n        ...     times_series_timestamp_col=\"sale_date\",\n        ...     times_series_data_col=\"daily_sales\"\n        ... )\n        {\n          \"status\": \"SUCCESS\",\n          \"rows\": [\n            {\n              \"ts_timestamp\": \"2021-01-01 00:00:01 UTC\",\n              \"ts_data\": 125.3,\n              \"is_anomaly\": TRUE,\n              \"lower_bound\": 129.5,\n              \"upper_bound\": 133.6 ,\n              \"anomaly_probability\": 0.93\n            },\n            ...\n          ]\n        }\n\n    Detect Anomalies on multiple time series using a SQL query as input:\n\n        >>> history_query = (\n        ...     \"SELECT unique_id, timestamp, value \"\n        ...     \"FROM `my-project.my-dataset.my-timeseries-table` \"\n        ...     \"WHERE timestamp > '1980-01-01'\"\n        ... )\n        >>> detect_anomalies(\n        ...     project_id=\"my-gcp-project\",\n        ...     history_data=history_query,\n\
    \        ...     times_series_timestamp_col=\"timestamp\",\n        ...     times_series_data_col=\"value\",\n        ...     times_series_id_cols=[\"unique_id\"]\n        ... )\n        {\n          \"status\": \"SUCCESS\",\n          \"rows\": [\n            {\n              \"unique_id\": \"T1\",\n              \"ts_timestamp\": \"2021-01-01 00:00:01 UTC\",\n              \"ts_data\": 125.3,\n              \"is_anomaly\": TRUE,\n              \"lower_bound\": 129.5,\n              \"upper_bound\": 133.6 ,\n              \"anomaly_probability\": 0.93\n            },\n            ...\n          ]\n        }\n\n    Error Scenarios:\n        When an element in `times_series_id_cols` is not a string:\n\n        >>> detect_anomalies(\n        ...     project_id=\"my-gcp-project\",\n        ...     history_data=\"my-dataset.my-sales-table\",\n        ...     times_series_timestamp_col=\"sale_date\",\n        ...     times_series_data_col=\"daily_sales\",\n        ...     times_series_id_cols=[\"\
    store_id\", 123]\n        ... )\n        {\n          \"status\": \"ERROR\",\n          \"error_details\": \"All elements in times_series_id_cols must be\n          strings.\"\n        }\n\n        When `history_data` refers to a table that does not exist:\n\n        >>> detect_anomalies(\n        ...     project_id=\"my-gcp-project\",\n        ...     history_data=\"my-dataset.nonexistent-table\",\n        ...     times_series_timestamp_col=\"sale_date\",\n        ...     times_series_data_col=\"daily_sales\"\n        ... )\n        {\n          \"status\": \"ERROR\",\n          \"error_details\": \"Not found: Table\n          my-gcp-project:my-dataset.nonexistent-table was not found in\n          location US\"\n        }"
  signature: 'def detect_anomalies(project_id: str, history_data: str, times_series_timestamp_col: str, times_series_data_col: str, horizon: typing.Optional[int], target_data: typing.Optional[str], times_series_id_cols: typing.Optional[list[str]], anomaly_prob_threshold: typing.Optional[float], *, credentials: google.auth.credentials.Credentials, settings: google.adk.tools.bigquery.config.BigQueryToolConfig, tool_context: google.adk.tools.tool_context.ToolContext) -> dict:'
- rank: 1440
  id: google.adk.tools.bigquery.query_tool.execute_sql
  name: execute_sql
  file_path: google/adk/tools/bigquery/query_tool.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Run a BigQuery or BigQuery ML SQL query in the project and return the result.\n\nArgs:\n    project_id (str): The GCP project id in which the query should be\n      executed.\n    query (str): The BigQuery SQL query to be executed.\n    credentials (Credentials): The credentials to use for the request.\n    settings (BigQueryToolConfig): The settings for the tool.\n    tool_context (ToolContext): The context for the tool.\n    dry_run (bool, default False): If True, the query will not be executed.\n      Instead, the query will be validated and information about the query\n      will be returned. Defaults to False.\n\nReturns:\n    dict: If `dry_run` is False, dictionary representing the result of the\n          query. If the result contains the key \"result_is_likely_truncated\"\n          with value True, it means that there may be additional rows matching\n          the query not returned in the result.\n          If `dry_run` is True, dictionary with \"dry_run_info\" field\n\
    \          containing query information returned by BigQuery.\n\nExamples:\n    Fetch data or insights from a table:\n\n        >>> execute_sql(\"my_project\",\n        ... \"SELECT island, COUNT(*) AS population \"\n        ... \"FROM bigquery-public-data.ml_datasets.penguins GROUP BY island\")\n        {\n          \"status\": \"SUCCESS\",\n          \"rows\": [\n              {\n                  \"island\": \"Dream\",\n                  \"population\": 124\n              },\n              {\n                  \"island\": \"Biscoe\",\n                  \"population\": 168\n              },\n              {\n                  \"island\": \"Torgersen\",\n                  \"population\": 52\n              }\n          ]\n        }\n\n    Validate a query and estimate costs without executing it:\n\n        >>> execute_sql(\n        ...     \"my_project\",\n        ...     \"SELECT island FROM \"\n        ...     \"bigquery-public-data.ml_datasets.penguins\",\n        ...     dry_run=True\n\
    \        ... )\n        {\n          \"status\": \"SUCCESS\",\n          \"dry_run_info\": {\n            \"configuration\": {\n              \"dryRun\": True,\n              \"jobType\": \"QUERY\",\n              \"query\": {\n                \"destinationTable\": {\n                  \"datasetId\": \"_...\",\n                  \"projectId\": \"my_project\",\n                  \"tableId\": \"anon...\"\n                },\n                \"priority\": \"INTERACTIVE\",\n                \"query\": \"SELECT island FROM bigquery-public-data.ml_datasets.penguins\",\n                \"useLegacySql\": False,\n                \"writeDisposition\": \"WRITE_TRUNCATE\"\n              }\n            },\n            \"jobReference\": {\n              \"location\": \"US\",\n              \"projectId\": \"my_project\"\n            }\n          }\n        }"
  signature: 'def execute_sql(project_id: str, query: str, credentials: google.auth.credentials.Credentials, settings: google.adk.tools.bigquery.config.BigQueryToolConfig, tool_context: google.adk.tools.tool_context.ToolContext, dry_run: bool) -> dict:'
- rank: 1441
  id: google.adk.tools.bigquery.query_tool.forecast
  name: forecast
  file_path: google/adk/tools/bigquery/query_tool.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Run a BigQuery AI time series forecast using AI.FORECAST.\n\nArgs:\n    project_id (str): The GCP project id in which the query should be\n      executed.\n    history_data (str): The table id of the BigQuery table containing the\n      history time series data or a query statement that select the history\n      data.\n    timestamp_col (str): The name of the column containing the timestamp for\n      each data point.\n    data_col (str): The name of the column containing the numerical values to\n      be forecasted.\n    horizon (int, optional): The number of time steps to forecast into the\n      future. Defaults to 10.\n    id_cols (list, optional): The column names of the id columns to indicate\n      each time series when there are multiple time series in the table. All\n      elements must be strings. Defaults to None.\n    credentials (Credentials): The credentials to use for the request.\n    settings (BigQueryToolConfig): The settings for the tool.\n    tool_context\
    \ (ToolContext): The context for the tool.\n\nReturns:\n    dict: Dictionary representing the result of the forecast. The result\n          contains the forecasted values along with prediction intervals.\n\nExamples:\n    Forecast daily sales for the next 7 days based on historical data from\n    a BigQuery table:\n\n        >>> forecast(\n        ...     project_id=\"my-gcp-project\",\n        ...     history_data=\"my-dataset.my-sales-table\",\n        ...     timestamp_col=\"sale_date\",\n        ...     data_col=\"daily_sales\",\n        ...     horizon=7\n        ... )\n        {\n          \"status\": \"SUCCESS\",\n          \"rows\": [\n            {\n              \"forecast_timestamp\": \"2025-01-08T00:00:00\",\n              \"forecast_value\": 12345.67,\n              \"confidence_level\": 0.95,\n              \"prediction_interval_lower_bound\": 11000.0,\n              \"prediction_interval_upper_bound\": 13691.34,\n              \"ai_forecast_status\": \"\"\n           \
    \ },\n            ...\n          ]\n        }\n\n    Forecast multiple time series using a SQL query as input:\n\n        >>> history_query = (\n        ...     \"SELECT unique_id, timestamp, value \"\n        ...     \"FROM `my-project.my-dataset.my-timeseries-table` \"\n        ...     \"WHERE timestamp > '1980-01-01'\"\n        ... )\n        >>> forecast(\n        ...     project_id=\"my-gcp-project\",\n        ...     history_data=history_query,\n        ...     timestamp_col=\"timestamp\",\n        ...     data_col=\"value\",\n        ...     id_cols=[\"unique_id\"],\n        ...     horizon=14\n        ... )\n        {\n          \"status\": \"SUCCESS\",\n          \"rows\": [\n            {\n              \"unique_id\": \"T1\",\n              \"forecast_timestamp\": \"1980-08-28T00:00:00\",\n              \"forecast_value\": 1253218.75,\n              \"confidence_level\": 0.95,\n              \"prediction_interval_lower_bound\": 274252.51,\n              \"prediction_interval_upper_bound\"\
    : 2232184.99,\n              \"ai_forecast_status\": \"\"\n            },\n            ...\n          ]\n        }\n\n    Error Scenarios:\n        When an element in `id_cols` is not a string:\n\n        >>> forecast(\n        ...     project_id=\"my-gcp-project\",\n        ...     history_data=\"my-dataset.my-sales-table\",\n        ...     timestamp_col=\"sale_date\",\n        ...     data_col=\"daily_sales\",\n        ...     id_cols=[\"store_id\", 123]\n        ... )\n        {\n          \"status\": \"ERROR\",\n          \"error_details\": \"All elements in id_cols must be strings.\"\n        }\n\n        When `history_data` refers to a table that does not exist:\n\n        >>> forecast(\n        ...     project_id=\"my-gcp-project\",\n        ...     history_data=\"my-dataset.nonexistent-table\",\n        ...     timestamp_col=\"sale_date\",\n        ...     data_col=\"daily_sales\"\n        ... )\n        {\n          \"status\": \"ERROR\",\n          \"error_details\": \"Not\
    \ found: Table\n          my-gcp-project:my-dataset.nonexistent-table was not found in\n          location US\"\n        }"
  signature: 'def forecast(project_id: str, history_data: str, timestamp_col: str, data_col: str, horizon: int, id_cols: typing.Optional[list[str]], *, credentials: google.auth.credentials.Credentials, settings: google.adk.tools.bigquery.config.BigQueryToolConfig, tool_context: google.adk.tools.tool_context.ToolContext) -> dict:'
- rank: 1442
  id: google.adk.tools.bigquery.query_tool.get_execute_sql
  name: get_execute_sql
  file_path: google/adk/tools/bigquery/query_tool.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Get the execute_sql tool customized as per the given tool settings.\n\nArgs:\n    settings: BigQuery tool settings indicating the behavior of the\n      execute_sql tool.\n\nReturns:\n    callable[..., dict]: A version of the execute_sql tool respecting the tool\n    settings."
  signature: 'def get_execute_sql(settings: google.adk.tools.bigquery.config.BigQueryToolConfig) -> typing.Callable[Ellipsis, dict]:'
- rank: 1443
  id: google.adk.tools.bigtable
  name: bigtable
  file_path: google/adk/tools/bigtable/__init__.py
  type: MODULE
  group: Orphan
  usage_score: 0
  docstring: 'Bigtable Tools (Experimental).


    Bigtable tools under this module are hand crafted and customized while the tools

    under google.adk.tools.google_api_tool are auto generated based on API

    definition. The rationales to have customized tool are:


    1. A dedicated Bigtable toolset to provide an easier, integrated way to interact

    with Bigtable for building AI Agent applications quickly.

    2. We want to provide extra access guardrails and controls in those tools.

    3. Use Bigtable Toolset for more customization and control to interact with

    Bigtable tables.'
- rank: 1444
  id: google.adk.tools.bigtable.bigtable_credentials
  name: bigtable_credentials
  file_path: google/adk/tools/bigtable/bigtable_credentials.py
  type: MODULE
  group: Orphan
  usage_score: 0
- rank: 1445
  id: google.adk.tools.bigtable.bigtable_toolset
  name: bigtable_toolset
  file_path: google/adk/tools/bigtable/bigtable_toolset.py
  type: MODULE
  group: Orphan
  usage_score: 0
- rank: 1446
  id: google.adk.tools.bigtable.bigtable_toolset.BigtableToolset
  name: BigtableToolset
  file_path: google/adk/tools/bigtable/bigtable_toolset.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: "Bigtable Toolset contains tools for interacting with Bigtable data and metadata.\n\nThe tool names are:\n  - bigtable_list_instances\n  - bigtable_get_instance_info\n  - bigtable_list_tables\n  - bigtable_get_table_info\n  - bigtable_execute_sql\n\n[Note: Inherited members from ABC are omitted.]"
  constructor_signature: 'def __init__(self, *, tool_filter: typing.Optional[typing.Union[google.adk.tools.base_toolset.ToolPredicate, typing.List[str]]]=None, credentials_config: typing.Optional[google.adk.tools.bigtable.bigtable_credentials.BigtableCredentialsConfig]=None, bigtable_tool_settings: typing.Optional[google.adk.tools.bigtable.settings.BigtableToolSettings]=None):'
  methods:
  - signature: 'def get_tools(self, readonly_context: typing.Optional[google.adk.agents.readonly_context.ReadonlyContext]) -> typing.List[google.adk.tools.base_tool.BaseTool]:'
    docstring: Get tools from the toolset.
  inherited_methods:
    BaseToolset:
    - signature: 'def get_tools(self, readonly_context: typing.Optional[google.adk.agents.readonly_context.ReadonlyContext]) -> list[google.adk.tools.base_tool.BaseTool]:'
      docstring: "Return all tools in the toolset based on the provided context.\n\nArgs:\n  readonly_context (ReadonlyContext, optional): Context used to filter tools\n    available to the agent. If None, all tools in the toolset are returned.\n\nReturns:\n  list[BaseTool]: A list of tools available under the specified context."
    - signature: 'def get_tools_with_prefix(self, readonly_context: typing.Optional[google.adk.agents.readonly_context.ReadonlyContext]) -> list[google.adk.tools.base_tool.BaseTool]:'
      docstring: "Return all tools with optional prefix applied to tool names.\n\nThis method calls get_tools() and applies prefixing if tool_name_prefix is provided.\n\nArgs:\n  readonly_context (ReadonlyContext, optional): Context used to filter tools\n    available to the agent. If None, all tools in the toolset are returned.\n\nReturns:\n  list[BaseTool]: A list of tools with prefixed names if tool_name_prefix is provided."
    - signature: 'def close(self) -> None:'
      docstring: "Performs cleanup and releases resources held by the toolset.\n\nNOTE:\n  This method is invoked, for example, at the end of an agent server's\n  lifecycle or when the toolset is no longer needed. Implementations\n  should ensure that any open connections, files, or other managed\n  resources are properly released to prevent leaks."
    - signature: 'def from_config(cls: typing.Type[google.adk.tools.base_toolset.SelfToolset], config: google.adk.tools.tool_configs.ToolArgsConfig, config_abs_path: str) -> google.adk.tools.base_toolset.SelfToolset:'
      docstring: "Creates a toolset instance from a config.\n\nArgs:\n  config: The config for the tool.\n  config_abs_path: The absolute path to the config file that contains the\n    tool config.\n\nReturns:\n  The toolset instance."
    - signature: 'def process_llm_request(self, *, tool_context: google.adk.tools.tool_context.ToolContext, llm_request: google.adk.models.llm_request.LlmRequest) -> None:'
      docstring: "Processes the outgoing LLM request for this toolset. This method will be\ncalled before each tool processes the llm request.\n\nUse cases:\n- Instead of let each tool process the llm request, we can let the toolset\n  process the llm request. e.g. ComputerUseToolset can add computer use\n  tool to the llm request.\n\nArgs:\n  tool_context: The context of the tool.\n  llm_request: The outgoing LLM request, mutable this method."
  omitted_inherited_members_from:
  - ABC
- rank: 1447
  id: google.adk.tools.bigtable.bigtable_toolset.BigtableToolset.__init__
  name: __init__
  file_path: google/adk/tools/bigtable/bigtable_toolset.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def __init__(self, *, tool_filter: typing.Optional[typing.Union[google.adk.tools.base_toolset.ToolPredicate, typing.List[str]]]=None, credentials_config: typing.Optional[google.adk.tools.bigtable.bigtable_credentials.BigtableCredentialsConfig]=None, bigtable_tool_settings: typing.Optional[google.adk.tools.bigtable.settings.BigtableToolSettings]=None):'
- rank: 1448
  id: google.adk.tools.bigtable.bigtable_toolset.BigtableToolset.get_tools
  name: get_tools
  file_path: google/adk/tools/bigtable/bigtable_toolset.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: Get tools from the toolset.
  signature: 'def get_tools(self, readonly_context: typing.Optional[google.adk.agents.readonly_context.ReadonlyContext]) -> typing.List[google.adk.tools.base_tool.BaseTool]:'
- rank: 1449
  id: google.adk.tools.bigtable.client
  name: client
  file_path: google/adk/tools/bigtable/client.py
  type: MODULE
  group: Orphan
  usage_score: 0
  methods:
  - signature: 'def get_bigtable_data_client(*, project: str, credentials: google.auth.credentials.Credentials) -> google.cloud.bigtable.BigtableDataClient:'
    docstring: Get a Bigtable client.
  - signature: 'def get_bigtable_admin_client(*, project: str, credentials: google.auth.credentials.Credentials) -> google.cloud.bigtable.Client:'
    docstring: Get a Bigtable client.
- rank: 1450
  id: google.adk.tools.bigtable.client.get_bigtable_admin_client
  name: get_bigtable_admin_client
  file_path: google/adk/tools/bigtable/client.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: Get a Bigtable client.
  signature: 'def get_bigtable_admin_client(*, project: str, credentials: google.auth.credentials.Credentials) -> google.cloud.bigtable.Client:'
- rank: 1451
  id: google.adk.tools.bigtable.client.get_bigtable_data_client
  name: get_bigtable_data_client
  file_path: google/adk/tools/bigtable/client.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: Get a Bigtable client.
  signature: 'def get_bigtable_data_client(*, project: str, credentials: google.auth.credentials.Credentials) -> google.cloud.bigtable.BigtableDataClient:'
- rank: 1452
  id: google.adk.tools.bigtable.metadata_tool
  name: metadata_tool
  file_path: google/adk/tools/bigtable/metadata_tool.py
  type: MODULE
  group: Orphan
  usage_score: 0
  methods:
  - signature: 'def list_instances(project_id: str, credentials: google.auth.credentials.Credentials) -> dict:'
    docstring: "List Bigtable instance ids in a Google Cloud project.\n\nArgs:\n    project_id (str): The Google Cloud project id.\n    credentials (Credentials): The credentials to use for the request.\n\nReturns:\n    dict: Dictionary with a list of the Bigtable instance ids present in the project."
  - signature: 'def get_instance_info(project_id: str, instance_id: str, credentials: google.auth.credentials.Credentials) -> dict:'
    docstring: "Get metadata information about a Bigtable instance.\n\nArgs:\n    project_id (str): The Google Cloud project id containing the instance.\n    instance_id (str): The Bigtable instance id.\n    credentials (Credentials): The credentials to use for the request.\n\nReturns:\n    dict: Dictionary representing the properties of the instance."
  - signature: 'def list_tables(project_id: str, instance_id: str, credentials: google.auth.credentials.Credentials) -> dict:'
    docstring: "List table ids in a Bigtable instance.\n\nArgs:\n    project_id (str): The Google Cloud project id containing the instance.\n    instance_id (str): The Bigtable instance id.\n    credentials (Credentials): The credentials to use for the request.\n\nReturns:\n    dict: Dictionary with a list of the tables ids present in the instance."
  - signature: 'def get_table_info(project_id: str, instance_id: str, table_id: str, credentials: google.auth.credentials.Credentials) -> dict:'
    docstring: "Get metadata information about a Bigtable table.\n\nArgs:\n    project_id (str): The Google Cloud project id containing the instance.\n    instance_id (str): The Bigtable instance id containing the table.\n    table_id (str): The Bigtable table id.\n    credentials (Credentials): The credentials to use for the request.\n\nReturns:\n    dict: Dictionary representing the properties of the table."
- rank: 1453
  id: google.adk.tools.bigtable.metadata_tool.get_instance_info
  name: get_instance_info
  file_path: google/adk/tools/bigtable/metadata_tool.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Get metadata information about a Bigtable instance.\n\nArgs:\n    project_id (str): The Google Cloud project id containing the instance.\n    instance_id (str): The Bigtable instance id.\n    credentials (Credentials): The credentials to use for the request.\n\nReturns:\n    dict: Dictionary representing the properties of the instance."
  signature: 'def get_instance_info(project_id: str, instance_id: str, credentials: google.auth.credentials.Credentials) -> dict:'
- rank: 1454
  id: google.adk.tools.bigtable.metadata_tool.get_table_info
  name: get_table_info
  file_path: google/adk/tools/bigtable/metadata_tool.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Get metadata information about a Bigtable table.\n\nArgs:\n    project_id (str): The Google Cloud project id containing the instance.\n    instance_id (str): The Bigtable instance id containing the table.\n    table_id (str): The Bigtable table id.\n    credentials (Credentials): The credentials to use for the request.\n\nReturns:\n    dict: Dictionary representing the properties of the table."
  signature: 'def get_table_info(project_id: str, instance_id: str, table_id: str, credentials: google.auth.credentials.Credentials) -> dict:'
- rank: 1455
  id: google.adk.tools.bigtable.metadata_tool.list_instances
  name: list_instances
  file_path: google/adk/tools/bigtable/metadata_tool.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "List Bigtable instance ids in a Google Cloud project.\n\nArgs:\n    project_id (str): The Google Cloud project id.\n    credentials (Credentials): The credentials to use for the request.\n\nReturns:\n    dict: Dictionary with a list of the Bigtable instance ids present in the project."
  signature: 'def list_instances(project_id: str, credentials: google.auth.credentials.Credentials) -> dict:'
- rank: 1456
  id: google.adk.tools.bigtable.metadata_tool.list_tables
  name: list_tables
  file_path: google/adk/tools/bigtable/metadata_tool.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "List table ids in a Bigtable instance.\n\nArgs:\n    project_id (str): The Google Cloud project id containing the instance.\n    instance_id (str): The Bigtable instance id.\n    credentials (Credentials): The credentials to use for the request.\n\nReturns:\n    dict: Dictionary with a list of the tables ids present in the instance."
  signature: 'def list_tables(project_id: str, instance_id: str, credentials: google.auth.credentials.Credentials) -> dict:'
- rank: 1457
  id: google.adk.tools.bigtable.query_tool
  name: query_tool
  file_path: google/adk/tools/bigtable/query_tool.py
  type: MODULE
  group: Orphan
  usage_score: 0
  methods:
  - signature: 'def execute_sql(project_id: str, instance_id: str, query: str, credentials: google.auth.credentials.Credentials, settings: google.adk.tools.bigtable.settings.BigtableToolSettings, tool_context: google.adk.tools.tool_context.ToolContext) -> dict:'
    docstring: "Execute a GoogleSQL query from a Bigtable table.\n\nArgs:\n    project_id (str): The GCP project id in which the query should be\n      executed.\n    instance_id (str): The instance id of the Bigtable database.\n    query (str): The Bigtable SQL query to be executed.\n    credentials (Credentials): The credentials to use for the request.\n    settings (BigtableToolSettings): The configuration for the tool.\n    tool_context (ToolContext): The context for the tool.\nReturns:\n    dict: Dictionary containing the status and the rows read.\n          If the result contains the key \"result_is_likely_truncated\" with\n          value True, it means that there may be additional rows matching the\n          query not returned in the result.\n\nExamples:\n    Fetch data or insights from a table:\n\n        >>> execute_sql(\"my_project\", \"my_instance\",\n        ... \"SELECT * from mytable\", credentials, config, tool_context)\n        {\n          \"status\": \"SUCCESS\",\n  \
      \        \"rows\": [\n              {\n                  \"user_id\": 1,\n                  \"user_name\": \"Alice\"\n              }\n          ]\n        }"
- rank: 1458
  id: google.adk.tools.bigtable.query_tool.execute_sql
  name: execute_sql
  file_path: google/adk/tools/bigtable/query_tool.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Execute a GoogleSQL query from a Bigtable table.\n\nArgs:\n    project_id (str): The GCP project id in which the query should be\n      executed.\n    instance_id (str): The instance id of the Bigtable database.\n    query (str): The Bigtable SQL query to be executed.\n    credentials (Credentials): The credentials to use for the request.\n    settings (BigtableToolSettings): The configuration for the tool.\n    tool_context (ToolContext): The context for the tool.\nReturns:\n    dict: Dictionary containing the status and the rows read.\n          If the result contains the key \"result_is_likely_truncated\" with\n          value True, it means that there may be additional rows matching the\n          query not returned in the result.\n\nExamples:\n    Fetch data or insights from a table:\n\n        >>> execute_sql(\"my_project\", \"my_instance\",\n        ... \"SELECT * from mytable\", credentials, config, tool_context)\n        {\n          \"status\": \"SUCCESS\",\n    \
    \      \"rows\": [\n              {\n                  \"user_id\": 1,\n                  \"user_name\": \"Alice\"\n              }\n          ]\n        }"
  signature: 'def execute_sql(project_id: str, instance_id: str, query: str, credentials: google.auth.credentials.Credentials, settings: google.adk.tools.bigtable.settings.BigtableToolSettings, tool_context: google.adk.tools.tool_context.ToolContext) -> dict:'
- rank: 1459
  id: google.adk.tools.bigtable.settings
  name: settings
  file_path: google/adk/tools/bigtable/settings.py
  type: MODULE
  group: Orphan
  usage_score: 0
- rank: 1460
  id: google.adk.tools.bigtable.settings.BigtableToolSettings
  name: BigtableToolSettings
  file_path: google/adk/tools/bigtable/settings.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Settings for Bigtable tools.


    [Note: Inherited members from pydantic.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, max_query_result_rows: int = 50):'
  properties:
  - signature: 'max_query_result_rows: int'
    docstring: Maximum number of rows to return from a query result.
  inherited_properties:
    BaseModel:
    - signature: 'model_config: pydantic.ConfigDict'
  omitted_inherited_members_from:
  - pydantic.BaseModel
- rank: 1461
  id: google.adk.tools.computer_use
  name: computer_use
  file_path: google/adk/tools/computer_use/__init__.py
  type: MODULE
  group: Orphan
  usage_score: 0
- rank: 1462
  id: google.adk.tools.computer_use.base_computer
  name: base_computer
  file_path: google/adk/tools/computer_use/base_computer.py
  type: MODULE
  group: Orphan
  usage_score: 0
- rank: 1463
  id: google.adk.tools.computer_use.base_computer.BaseComputer
  name: BaseComputer
  file_path: google/adk/tools/computer_use/base_computer.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'async defines an interface for computer environments.


    This abstract base class async defines the standard interface for controlling

    computer environments, including web browsers and other interactive systems.


    [Note: Inherited members from abc.ABC are omitted.]'
  methods:
  - signature: 'def screen_size(self) -> tuple[int, int]:'
    docstring: "Returns the screen size of the environment.\n\nReturns:\n  A tuple of (width, height) in pixels."
  - signature: 'def open_web_browser(self) -> google.adk.tools.computer_use.base_computer.ComputerState:'
    docstring: "Opens the web browser.\n\nReturns:\n  The current state after opening the browser."
  - signature: 'def click_at(self, x: int, y: int) -> google.adk.tools.computer_use.base_computer.ComputerState:'
    docstring: "Clicks at a specific x, y coordinate on the webpage.\n\nThe 'x' and 'y' values are absolute values, scaled to the height and width of the screen.\n\nArgs:\n  x: The x-coordinate to click at.\n  y: The y-coordinate to click at.\n\nReturns:\n  The current state after clicking."
  - signature: 'def hover_at(self, x: int, y: int) -> google.adk.tools.computer_use.base_computer.ComputerState:'
    docstring: "Hovers at a specific x, y coordinate on the webpage.\n\nMay be used to explore sub-menus that appear on hover.\nThe 'x' and 'y' values are absolute values, scaled to the height and width of the screen.\n\nArgs:\n  x: The x-coordinate to hover at.\n  y: The y-coordinate to hover at.\n\nReturns:\n  The current state after hovering."
  - signature: 'def type_text_at(self, x: int, y: int, text: str, press_enter: bool, clear_before_typing: bool) -> google.adk.tools.computer_use.base_computer.ComputerState:'
    docstring: "Types text at a specific x, y coordinate.\n\nThe system automatically presses ENTER after typing. To disable this, set `press_enter` to False.\nThe system automatically clears any existing content before typing the specified `text`. To disable this, set `clear_before_typing` to False.\nThe 'x' and 'y' values are absolute values, scaled to the height and width of the screen.\n\nArgs:\n  x: The x-coordinate to type at.\n  y: The y-coordinate to type at.\n  text: The text to type.\n  press_enter: Whether to press ENTER after typing.\n  clear_before_typing: Whether to clear existing content before typing.\n\nReturns:\n  The current state after typing."
  - signature: 'def scroll_document(self, direction: typing.Literal[up, down, left, right]) -> google.adk.tools.computer_use.base_computer.ComputerState:'
    docstring: "Scrolls the entire webpage \"up\", \"down\", \"left\" or \"right\" based on direction.\n\nArgs:\n  direction: The direction to scroll.\n\nReturns:\n  The current state after scrolling."
  - signature: 'def scroll_at(self, x: int, y: int, direction: typing.Literal[up, down, left, right], magnitude: int) -> google.adk.tools.computer_use.base_computer.ComputerState:'
    docstring: "Scrolls up, down, right, or left at a x, y coordinate by magnitude.\n\nThe 'x' and 'y' values are absolute values, scaled to the height and width of the screen.\n\nArgs:\n  x: The x-coordinate to scroll at.\n  y: The y-coordinate to scroll at.\n  direction: The direction to scroll.\n  magnitude: The amount to scroll.\n\nReturns:\n  The current state after scrolling."
  - signature: 'def wait(self, seconds: int) -> google.adk.tools.computer_use.base_computer.ComputerState:'
    docstring: "Waits for n seconds to allow unfinished webpage processes to complete.\n\nArgs:\n  seconds: The number of seconds to wait.\n\nReturns:\n  The current state after waiting."
  - signature: 'def go_back(self) -> google.adk.tools.computer_use.base_computer.ComputerState:'
    docstring: "Navigates back to the previous webpage in the browser history.\n\nReturns:\n  The current state after navigating back."
  - signature: 'def go_forward(self) -> google.adk.tools.computer_use.base_computer.ComputerState:'
    docstring: "Navigates forward to the next webpage in the browser history.\n\nReturns:\n  The current state after navigating forward."
  - signature: 'def search(self) -> google.adk.tools.computer_use.base_computer.ComputerState:'
    docstring: "Directly jumps to a search engine home page.\n\nUsed when you need to start with a search. For example, this is used when\nthe current website doesn't have the information needed or because a new\ntask is being started.\n\nReturns:\n  The current state after navigating to search."
  - signature: 'def navigate(self, url: str) -> google.adk.tools.computer_use.base_computer.ComputerState:'
    docstring: "Navigates directly to a specified URL.\n\nArgs:\n  url: The URL to navigate to.\n\nReturns:\n  The current state after navigation."
  - signature: 'def key_combination(self, keys: list[str]) -> google.adk.tools.computer_use.base_computer.ComputerState:'
    docstring: "Presses keyboard keys and combinations, such as \"control+c\" or \"enter\".\n\nArgs:\n  keys: List of keys to press in combination.\n\nReturns:\n  The current state after key press."
  - signature: 'def drag_and_drop(self, x: int, y: int, destination_x: int, destination_y: int) -> google.adk.tools.computer_use.base_computer.ComputerState:'
    docstring: "Drag and drop an element from a x, y coordinate to a destination destination_y, destination_x coordinate.\n\nThe 'x', 'y', 'destination_y' and 'destination_x' values are absolute values, scaled to the height and width of the screen.\n\nArgs:\n  x: The x-coordinate to start dragging from.\n  y: The y-coordinate to start dragging from.\n  destination_x: The x-coordinate to drop at.\n  destination_y: The y-coordinate to drop at.\n\nReturns:\n  The current state after drag and drop."
  - signature: 'def current_state(self) -> google.adk.tools.computer_use.base_computer.ComputerState:'
    docstring: "Returns the current state of the current webpage.\n\nReturns:\n  The current environment state."
  - signature: 'def initialize(self) -> None:'
    docstring: Initialize the computer.
  - signature: 'def close(self) -> None:'
    docstring: Cleanup resource of the computer.
  - signature: 'def environment(self) -> google.adk.tools.computer_use.base_computer.ComputerEnvironment:'
    docstring: Returns the environment of the computer.
  omitted_inherited_members_from:
  - abc.ABC
- rank: 1464
  id: google.adk.tools.computer_use.base_computer.BaseComputer.click_at
  name: click_at
  file_path: google/adk/tools/computer_use/base_computer.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Clicks at a specific x, y coordinate on the webpage.\n\nThe 'x' and 'y' values are absolute values, scaled to the height and width of the screen.\n\nArgs:\n  x: The x-coordinate to click at.\n  y: The y-coordinate to click at.\n\nReturns:\n  The current state after clicking."
  signature: 'def click_at(self, x: int, y: int) -> google.adk.tools.computer_use.base_computer.ComputerState:'
- rank: 1465
  id: google.adk.tools.computer_use.base_computer.BaseComputer.current_state
  name: current_state
  file_path: google/adk/tools/computer_use/base_computer.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Returns the current state of the current webpage.\n\nReturns:\n  The current environment state."
  signature: 'def current_state(self) -> google.adk.tools.computer_use.base_computer.ComputerState:'
- rank: 1466
  id: google.adk.tools.computer_use.base_computer.BaseComputer.drag_and_drop
  name: drag_and_drop
  file_path: google/adk/tools/computer_use/base_computer.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Drag and drop an element from a x, y coordinate to a destination destination_y, destination_x coordinate.\n\nThe 'x', 'y', 'destination_y' and 'destination_x' values are absolute values, scaled to the height and width of the screen.\n\nArgs:\n  x: The x-coordinate to start dragging from.\n  y: The y-coordinate to start dragging from.\n  destination_x: The x-coordinate to drop at.\n  destination_y: The y-coordinate to drop at.\n\nReturns:\n  The current state after drag and drop."
  signature: 'def drag_and_drop(self, x: int, y: int, destination_x: int, destination_y: int) -> google.adk.tools.computer_use.base_computer.ComputerState:'
- rank: 1467
  id: google.adk.tools.computer_use.base_computer.BaseComputer.go_back
  name: go_back
  file_path: google/adk/tools/computer_use/base_computer.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Navigates back to the previous webpage in the browser history.\n\nReturns:\n  The current state after navigating back."
  signature: 'def go_back(self) -> google.adk.tools.computer_use.base_computer.ComputerState:'
- rank: 1468
  id: google.adk.tools.computer_use.base_computer.BaseComputer.go_forward
  name: go_forward
  file_path: google/adk/tools/computer_use/base_computer.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Navigates forward to the next webpage in the browser history.\n\nReturns:\n  The current state after navigating forward."
  signature: 'def go_forward(self) -> google.adk.tools.computer_use.base_computer.ComputerState:'
- rank: 1469
  id: google.adk.tools.computer_use.base_computer.BaseComputer.hover_at
  name: hover_at
  file_path: google/adk/tools/computer_use/base_computer.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Hovers at a specific x, y coordinate on the webpage.\n\nMay be used to explore sub-menus that appear on hover.\nThe 'x' and 'y' values are absolute values, scaled to the height and width of the screen.\n\nArgs:\n  x: The x-coordinate to hover at.\n  y: The y-coordinate to hover at.\n\nReturns:\n  The current state after hovering."
  signature: 'def hover_at(self, x: int, y: int) -> google.adk.tools.computer_use.base_computer.ComputerState:'
- rank: 1470
  id: google.adk.tools.computer_use.base_computer.BaseComputer.key_combination
  name: key_combination
  file_path: google/adk/tools/computer_use/base_computer.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Presses keyboard keys and combinations, such as \"control+c\" or \"enter\".\n\nArgs:\n  keys: List of keys to press in combination.\n\nReturns:\n  The current state after key press."
  signature: 'def key_combination(self, keys: list[str]) -> google.adk.tools.computer_use.base_computer.ComputerState:'
- rank: 1471
  id: google.adk.tools.computer_use.base_computer.BaseComputer.navigate
  name: navigate
  file_path: google/adk/tools/computer_use/base_computer.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Navigates directly to a specified URL.\n\nArgs:\n  url: The URL to navigate to.\n\nReturns:\n  The current state after navigation."
  signature: 'def navigate(self, url: str) -> google.adk.tools.computer_use.base_computer.ComputerState:'
- rank: 1472
  id: google.adk.tools.computer_use.base_computer.BaseComputer.open_web_browser
  name: open_web_browser
  file_path: google/adk/tools/computer_use/base_computer.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Opens the web browser.\n\nReturns:\n  The current state after opening the browser."
  signature: 'def open_web_browser(self) -> google.adk.tools.computer_use.base_computer.ComputerState:'
- rank: 1473
  id: google.adk.tools.computer_use.base_computer.BaseComputer.screen_size
  name: screen_size
  file_path: google/adk/tools/computer_use/base_computer.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Returns the screen size of the environment.\n\nReturns:\n  A tuple of (width, height) in pixels."
  signature: 'def screen_size(self) -> tuple[int, int]:'
- rank: 1474
  id: google.adk.tools.computer_use.base_computer.BaseComputer.scroll_at
  name: scroll_at
  file_path: google/adk/tools/computer_use/base_computer.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Scrolls up, down, right, or left at a x, y coordinate by magnitude.\n\nThe 'x' and 'y' values are absolute values, scaled to the height and width of the screen.\n\nArgs:\n  x: The x-coordinate to scroll at.\n  y: The y-coordinate to scroll at.\n  direction: The direction to scroll.\n  magnitude: The amount to scroll.\n\nReturns:\n  The current state after scrolling."
  signature: 'def scroll_at(self, x: int, y: int, direction: typing.Literal[up, down, left, right], magnitude: int) -> google.adk.tools.computer_use.base_computer.ComputerState:'
- rank: 1475
  id: google.adk.tools.computer_use.base_computer.BaseComputer.scroll_document
  name: scroll_document
  file_path: google/adk/tools/computer_use/base_computer.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Scrolls the entire webpage \"up\", \"down\", \"left\" or \"right\" based on direction.\n\nArgs:\n  direction: The direction to scroll.\n\nReturns:\n  The current state after scrolling."
  signature: 'def scroll_document(self, direction: typing.Literal[up, down, left, right]) -> google.adk.tools.computer_use.base_computer.ComputerState:'
- rank: 1476
  id: google.adk.tools.computer_use.base_computer.BaseComputer.search
  name: search
  file_path: google/adk/tools/computer_use/base_computer.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Directly jumps to a search engine home page.\n\nUsed when you need to start with a search. For example, this is used when\nthe current website doesn't have the information needed or because a new\ntask is being started.\n\nReturns:\n  The current state after navigating to search."
  signature: 'def search(self) -> google.adk.tools.computer_use.base_computer.ComputerState:'
- rank: 1477
  id: google.adk.tools.computer_use.base_computer.BaseComputer.type_text_at
  name: type_text_at
  file_path: google/adk/tools/computer_use/base_computer.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Types text at a specific x, y coordinate.\n\nThe system automatically presses ENTER after typing. To disable this, set `press_enter` to False.\nThe system automatically clears any existing content before typing the specified `text`. To disable this, set `clear_before_typing` to False.\nThe 'x' and 'y' values are absolute values, scaled to the height and width of the screen.\n\nArgs:\n  x: The x-coordinate to type at.\n  y: The y-coordinate to type at.\n  text: The text to type.\n  press_enter: Whether to press ENTER after typing.\n  clear_before_typing: Whether to clear existing content before typing.\n\nReturns:\n  The current state after typing."
  signature: 'def type_text_at(self, x: int, y: int, text: str, press_enter: bool, clear_before_typing: bool) -> google.adk.tools.computer_use.base_computer.ComputerState:'
- rank: 1478
  id: google.adk.tools.computer_use.base_computer.BaseComputer.wait
  name: wait
  file_path: google/adk/tools/computer_use/base_computer.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Waits for n seconds to allow unfinished webpage processes to complete.\n\nArgs:\n  seconds: The number of seconds to wait.\n\nReturns:\n  The current state after waiting."
  signature: 'def wait(self, seconds: int) -> google.adk.tools.computer_use.base_computer.ComputerState:'
- rank: 1479
  id: google.adk.tools.computer_use.base_computer.ComputerEnvironment
  name: ComputerEnvironment
  file_path: google/adk/tools/computer_use/base_computer.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Case insensitive enum for computer environments.


    [Note: Inherited members from Enum, str are omitted.]'
  properties:
  - signature: 'ENVIRONMENT_UNSPECIFIED: str'
    docstring: Defaults to browser.
  - signature: 'ENVIRONMENT_BROWSER: str'
    docstring: Operates in a web browser.
  omitted_inherited_members_from:
  - str
  - Enum
- rank: 1480
  id: google.adk.tools.computer_use.base_computer.ComputerState
  name: ComputerState
  file_path: google/adk/tools/computer_use/base_computer.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: "Represents the current state of the computer environment.\n\nAttributes:\n  screenshot: The screenshot in PNG format as bytes.\n  url: The current URL of the webpage being displayed.\n\n[Note: Inherited members from pydantic.BaseModel are omitted.]"
  constructor_signature: 'def __init__(self, *, screenshot: bytes = None, url: typing.Optional[str] = None):'
  properties:
  - signature: 'screenshot: bytes'
  - signature: 'url: typing.Optional[str]'
  omitted_inherited_members_from:
  - pydantic.BaseModel
- rank: 1481
  id: google.adk.tools.computer_use.computer_use_tool
  name: computer_use_tool
  file_path: google/adk/tools/computer_use/computer_use_tool.py
  type: MODULE
  group: Orphan
  usage_score: 0
- rank: 1482
  id: google.adk.tools.computer_use.computer_use_tool.ComputerUseTool
  name: ComputerUseTool
  file_path: google/adk/tools/computer_use/computer_use_tool.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'A tool that wraps computer control functions for use with LLMs.


    This tool automatically normalizes coordinates from a virtual coordinate space

    (by default 1000x1000) to the actual screen size. This allows LLMs to work

    with a consistent coordinate system regardless of the actual screen dimensions,

    making their output more predictable and easier to handle.


    [Note: Inherited members from ABC are omitted.]'
  constructor_signature: 'def __init__(self, *, func: typing.Callable[Ellipsis, typing.Any], screen_size: tuple[int, int], virtual_screen_size: tuple[int, int]=(1000, 1000)):'
  methods:
  - signature: 'def run_async(self, *, args: dict[str, typing.Any], tool_context: google.adk.tools.tool_context.ToolContext) -> typing.Any:'
    docstring: Run the computer control function with normalized coordinates.
  - signature: 'def process_llm_request(self, *, tool_context: google.adk.tools.tool_context.ToolContext, llm_request: google.adk.models.llm_request.LlmRequest) -> None:'
    docstring: 'ComputerUseToolset will add this tool to the LLM request and add computer

      use configuration to the LLM request.'
  inherited_methods:
    FunctionTool:
    - signature: 'def run_async(self, *, args: dict[str, typing.Any], tool_context: google.adk.tools.tool_context.ToolContext) -> typing.Any:'
    BaseTool:
    - signature: 'def run_async(self, *, args: dict[str, typing.Any], tool_context: google.adk.tools.tool_context.ToolContext) -> typing.Any:'
      docstring: "Runs the tool with the given arguments and context.\n\nNOTE:\n  - Required if this tool needs to run at the client side.\n  - Otherwise, can be skipped, e.g. for a built-in GoogleSearch tool for\n    Gemini.\n\nArgs:\n  args: The LLM-filled arguments.\n  tool_context: The context of the tool.\n\nReturns:\n  The result of running the tool."
    - signature: 'def process_llm_request(self, *, tool_context: google.adk.tools.tool_context.ToolContext, llm_request: google.adk.models.llm_request.LlmRequest) -> None:'
      docstring: "Processes the outgoing LLM request for this tool.\n\nUse cases:\n- Most common use case is adding this tool to the LLM request.\n- Some tools may just preprocess the LLM request before it's sent out.\n\nArgs:\n  tool_context: The context of the tool.\n  llm_request: The outgoing LLM request, mutable this method."
    - signature: 'def from_config(cls: typing.Type[google.adk.tools.base_tool.SelfTool], config: google.adk.tools.tool_configs.ToolArgsConfig, config_abs_path: str) -> google.adk.tools.base_tool.SelfTool:'
      docstring: "Creates a tool instance from a config.\n\nThis default implementation uses inspect to automatically map config values\nto constructor arguments based on their type hints. Subclasses should\noverride this method for custom initialization logic.\n\nArgs:\n  config: The config for the tool.\n  config_abs_path: The absolute path to the config file that contains the\n    tool config.\n\nReturns:\n  The tool instance."
  inherited_properties:
    BaseTool:
    - signature: 'name: str'
      docstring: The name of the tool.
    - signature: 'description: str'
      docstring: The description of the tool.
    - signature: 'is_long_running: bool'
      docstring: 'Whether the tool is a long running operation, which typically returns a

        resource id first and finishes the operation later.'
    - signature: 'custom_metadata: typing.Optional[dict[str, typing.Any]]'
      docstring: 'The custom metadata of the BaseTool.


        An optional key-value pair for storing and retrieving tool-specific metadata,

        such as tool manifests, etc.


        NOTE: the entire dict must be JSON serializable.'
  omitted_inherited_members_from:
  - ABC
- rank: 1483
  id: google.adk.tools.computer_use.computer_use_tool.ComputerUseTool.__init__
  name: __init__
  file_path: google/adk/tools/computer_use/computer_use_tool.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Initialize the ComputerUseTool.\n\nArgs:\n  func: The computer control function to wrap.\n  screen_size: The actual screen size as (width, height) in pixels.\n    This represents the real dimensions of the target screen/display.\n  virtual_screen_size: The virtual coordinate space dimensions as (width, height)\n    that the LLM uses to specify coordinates. Coordinates from the LLM are\n    automatically normalized from this virtual space to the actual screen_size.\n    Default is (1000, 1000), meaning the LLM thinks it's working with a\n    1000x1000 pixel screen regardless of the actual screen dimensions.\n\nRaises:\n  ValueError: If screen_size or virtual_screen_size is not a valid tuple\n    of positive integers."
  signature: 'def __init__(self, *, func: typing.Callable[Ellipsis, typing.Any], screen_size: tuple[int, int], virtual_screen_size: tuple[int, int]=(1000, 1000)):'
- rank: 1484
  id: google.adk.tools.computer_use.computer_use_tool.ComputerUseTool.process_llm_request
  name: process_llm_request
  file_path: google/adk/tools/computer_use/computer_use_tool.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: 'ComputerUseToolset will add this tool to the LLM request and add computer

    use configuration to the LLM request.'
  signature: 'def process_llm_request(self, *, tool_context: google.adk.tools.tool_context.ToolContext, llm_request: google.adk.models.llm_request.LlmRequest) -> None:'
- rank: 1485
  id: google.adk.tools.computer_use.computer_use_tool.ComputerUseTool.run_async
  name: run_async
  file_path: google/adk/tools/computer_use/computer_use_tool.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: Run the computer control function with normalized coordinates.
  signature: 'def run_async(self, *, args: dict[str, typing.Any], tool_context: google.adk.tools.tool_context.ToolContext) -> typing.Any:'
- rank: 1486
  id: google.adk.tools.computer_use.computer_use_toolset
  name: computer_use_toolset
  file_path: google/adk/tools/computer_use/computer_use_toolset.py
  type: MODULE
  group: Orphan
  usage_score: 0
- rank: 1487
  id: google.adk.tools.computer_use.computer_use_toolset.ComputerUseToolset
  name: ComputerUseToolset
  file_path: google/adk/tools/computer_use/computer_use_toolset.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: '[Note: Inherited members from ABC are omitted.]'
  constructor_signature: 'def __init__(self, *, computer: google.adk.tools.computer_use.base_computer.BaseComputer):'
  methods:
  - signature: 'def adapt_computer_use_tool(method_name: str, adapter_func: typing.Union[typing.Callable[[Callable[..., Any]], typing.Callable[Ellipsis, typing.Any]], typing.Callable[[Callable[..., Any]], typing.Any]], llm_request: google.adk.models.llm_request.LlmRequest) -> None:'
    docstring: "Adapt a computer use tool by replacing it with a modified version.\n\nArgs:\n  method_name: The name of the method (of BaseComputer class) to adapt (e.g. 'wait').\n  adapter_func: A function that accepts existing computer use async function and returns a new computer use async function.\n    Can be either sync or async function. The name of the returned function will be used as the new tool name.\n  llm_request: The LLM request containing the tools dictionary."
  - signature: 'def get_tools(self, readonly_context: typing.Optional[google.adk.agents.readonly_context.ReadonlyContext]) -> list[google.adk.tools.computer_use.computer_use_tool.ComputerUseTool]:'
  - signature: 'def close(self) -> None:'
  - signature: 'def process_llm_request(self, *, tool_context: google.adk.tools.tool_context.ToolContext, llm_request: google.adk.models.llm_request.LlmRequest) -> None:'
    docstring: 'Add its tools to the LLM request and add computer

      use configuration to the LLM request.'
  inherited_methods:
    BaseToolset:
    - signature: 'def get_tools(self, readonly_context: typing.Optional[google.adk.agents.readonly_context.ReadonlyContext]) -> list[google.adk.tools.base_tool.BaseTool]:'
      docstring: "Return all tools in the toolset based on the provided context.\n\nArgs:\n  readonly_context (ReadonlyContext, optional): Context used to filter tools\n    available to the agent. If None, all tools in the toolset are returned.\n\nReturns:\n  list[BaseTool]: A list of tools available under the specified context."
    - signature: 'def get_tools_with_prefix(self, readonly_context: typing.Optional[google.adk.agents.readonly_context.ReadonlyContext]) -> list[google.adk.tools.base_tool.BaseTool]:'
      docstring: "Return all tools with optional prefix applied to tool names.\n\nThis method calls get_tools() and applies prefixing if tool_name_prefix is provided.\n\nArgs:\n  readonly_context (ReadonlyContext, optional): Context used to filter tools\n    available to the agent. If None, all tools in the toolset are returned.\n\nReturns:\n  list[BaseTool]: A list of tools with prefixed names if tool_name_prefix is provided."
    - signature: 'def close(self) -> None:'
      docstring: "Performs cleanup and releases resources held by the toolset.\n\nNOTE:\n  This method is invoked, for example, at the end of an agent server's\n  lifecycle or when the toolset is no longer needed. Implementations\n  should ensure that any open connections, files, or other managed\n  resources are properly released to prevent leaks."
    - signature: 'def from_config(cls: typing.Type[google.adk.tools.base_toolset.SelfToolset], config: google.adk.tools.tool_configs.ToolArgsConfig, config_abs_path: str) -> google.adk.tools.base_toolset.SelfToolset:'
      docstring: "Creates a toolset instance from a config.\n\nArgs:\n  config: The config for the tool.\n  config_abs_path: The absolute path to the config file that contains the\n    tool config.\n\nReturns:\n  The toolset instance."
    - signature: 'def process_llm_request(self, *, tool_context: google.adk.tools.tool_context.ToolContext, llm_request: google.adk.models.llm_request.LlmRequest) -> None:'
      docstring: "Processes the outgoing LLM request for this toolset. This method will be\ncalled before each tool processes the llm request.\n\nUse cases:\n- Instead of let each tool process the llm request, we can let the toolset\n  process the llm request. e.g. ComputerUseToolset can add computer use\n  tool to the llm request.\n\nArgs:\n  tool_context: The context of the tool.\n  llm_request: The outgoing LLM request, mutable this method."
  omitted_inherited_members_from:
  - ABC
- rank: 1488
  id: google.adk.tools.computer_use.computer_use_toolset.ComputerUseToolset.__init__
  name: __init__
  file_path: google/adk/tools/computer_use/computer_use_toolset.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def __init__(self, *, computer: google.adk.tools.computer_use.base_computer.BaseComputer):'
- rank: 1489
  id: google.adk.tools.computer_use.computer_use_toolset.ComputerUseToolset.adapt_computer_use_tool
  name: adapt_computer_use_tool
  file_path: google/adk/tools/computer_use/computer_use_toolset.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Adapt a computer use tool by replacing it with a modified version.\n\nArgs:\n  method_name: The name of the method (of BaseComputer class) to adapt (e.g. 'wait').\n  adapter_func: A function that accepts existing computer use async function and returns a new computer use async function.\n    Can be either sync or async function. The name of the returned function will be used as the new tool name.\n  llm_request: The LLM request containing the tools dictionary."
  signature: 'def adapt_computer_use_tool(method_name: str, adapter_func: typing.Union[typing.Callable[[Callable[..., Any]], typing.Callable[Ellipsis, typing.Any]], typing.Callable[[Callable[..., Any]], typing.Any]], llm_request: google.adk.models.llm_request.LlmRequest) -> None:'
- rank: 1490
  id: google.adk.tools.computer_use.computer_use_toolset.ComputerUseToolset.get_tools
  name: get_tools
  file_path: google/adk/tools/computer_use/computer_use_toolset.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def get_tools(self, readonly_context: typing.Optional[google.adk.agents.readonly_context.ReadonlyContext]) -> list[google.adk.tools.computer_use.computer_use_tool.ComputerUseTool]:'
- rank: 1491
  id: google.adk.tools.computer_use.computer_use_toolset.ComputerUseToolset.process_llm_request
  name: process_llm_request
  file_path: google/adk/tools/computer_use/computer_use_toolset.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: 'Add its tools to the LLM request and add computer

    use configuration to the LLM request.'
  signature: 'def process_llm_request(self, *, tool_context: google.adk.tools.tool_context.ToolContext, llm_request: google.adk.models.llm_request.LlmRequest) -> None:'
- rank: 1492
  id: google.adk.tools.crewai_tool
  name: crewai_tool
  file_path: google/adk/tools/crewai_tool.py
  type: MODULE
  group: Orphan
  usage_score: 0
- rank: 1493
  id: google.adk.tools.crewai_tool.CrewaiTool
  name: CrewaiTool
  file_path: google/adk/tools/crewai_tool.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Use this class to wrap a CrewAI tool.


    If the original tool name and description are not suitable, you can override

    them in the constructor.


    [Note: Inherited members from ABC are omitted.]'
  constructor_signature: 'def __init__(self, tool: crewai.tools.BaseTool, *, name: str, description: str):'
  methods:
  - signature: 'def run_async(self, *, args: dict[str, typing.Any], tool_context: google.adk.tools.tool_context.ToolContext) -> typing.Any:'
    docstring: 'Override run_async to handle CrewAI-specific parameter filtering.


      CrewAI tools use **kwargs pattern, so we need special parameter filtering

      logic that allows all parameters to pass through while removing only

      reserved parameters like ''self'' and ''tool_context''.


      Note: ''tool_context'' is removed from the initial args dictionary to prevent

      duplicates, but is re-added if the function signature explicitly requires it

      as a parameter.'
  - signature: 'def from_config(cls: type[google.adk.tools.crewai_tool.CrewaiTool], config: google.adk.tools.tool_configs.ToolArgsConfig, config_abs_path: str) -> google.adk.tools.crewai_tool.CrewaiTool:'
  properties:
  - signature: 'tool: crewai.tools.BaseTool'
    docstring: The wrapped CrewAI tool.
  inherited_methods:
    FunctionTool:
    - signature: 'def run_async(self, *, args: dict[str, typing.Any], tool_context: google.adk.tools.tool_context.ToolContext) -> typing.Any:'
    BaseTool:
    - signature: 'def run_async(self, *, args: dict[str, typing.Any], tool_context: google.adk.tools.tool_context.ToolContext) -> typing.Any:'
      docstring: "Runs the tool with the given arguments and context.\n\nNOTE:\n  - Required if this tool needs to run at the client side.\n  - Otherwise, can be skipped, e.g. for a built-in GoogleSearch tool for\n    Gemini.\n\nArgs:\n  args: The LLM-filled arguments.\n  tool_context: The context of the tool.\n\nReturns:\n  The result of running the tool."
    - signature: 'def process_llm_request(self, *, tool_context: google.adk.tools.tool_context.ToolContext, llm_request: google.adk.models.llm_request.LlmRequest) -> None:'
      docstring: "Processes the outgoing LLM request for this tool.\n\nUse cases:\n- Most common use case is adding this tool to the LLM request.\n- Some tools may just preprocess the LLM request before it's sent out.\n\nArgs:\n  tool_context: The context of the tool.\n  llm_request: The outgoing LLM request, mutable this method."
    - signature: 'def from_config(cls: typing.Type[google.adk.tools.base_tool.SelfTool], config: google.adk.tools.tool_configs.ToolArgsConfig, config_abs_path: str) -> google.adk.tools.base_tool.SelfTool:'
      docstring: "Creates a tool instance from a config.\n\nThis default implementation uses inspect to automatically map config values\nto constructor arguments based on their type hints. Subclasses should\noverride this method for custom initialization logic.\n\nArgs:\n  config: The config for the tool.\n  config_abs_path: The absolute path to the config file that contains the\n    tool config.\n\nReturns:\n  The tool instance."
  inherited_properties:
    BaseTool:
    - signature: 'name: str'
      docstring: The name of the tool.
    - signature: 'description: str'
      docstring: The description of the tool.
    - signature: 'is_long_running: bool'
      docstring: 'Whether the tool is a long running operation, which typically returns a

        resource id first and finishes the operation later.'
    - signature: 'custom_metadata: typing.Optional[dict[str, typing.Any]]'
      docstring: 'The custom metadata of the BaseTool.


        An optional key-value pair for storing and retrieving tool-specific metadata,

        such as tool manifests, etc.


        NOTE: the entire dict must be JSON serializable.'
  omitted_inherited_members_from:
  - ABC
- rank: 1494
  id: google.adk.tools.crewai_tool.CrewaiTool.__init__
  name: __init__
  file_path: google/adk/tools/crewai_tool.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def __init__(self, tool: crewai.tools.BaseTool, *, name: str, description: str):'
- rank: 1495
  id: google.adk.tools.crewai_tool.CrewaiTool.from_config
  name: from_config
  file_path: google/adk/tools/crewai_tool.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def from_config(cls: type[google.adk.tools.crewai_tool.CrewaiTool], config: google.adk.tools.tool_configs.ToolArgsConfig, config_abs_path: str) -> google.adk.tools.crewai_tool.CrewaiTool:'
- rank: 1496
  id: google.adk.tools.crewai_tool.CrewaiTool.run_async
  name: run_async
  file_path: google/adk/tools/crewai_tool.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: 'Override run_async to handle CrewAI-specific parameter filtering.


    CrewAI tools use **kwargs pattern, so we need special parameter filtering

    logic that allows all parameters to pass through while removing only

    reserved parameters like ''self'' and ''tool_context''.


    Note: ''tool_context'' is removed from the initial args dictionary to prevent

    duplicates, but is re-added if the function signature explicitly requires it

    as a parameter.'
  signature: 'def run_async(self, *, args: dict[str, typing.Any], tool_context: google.adk.tools.tool_context.ToolContext) -> typing.Any:'
- rank: 1497
  id: google.adk.tools.crewai_tool.CrewaiToolConfig
  name: CrewaiToolConfig
  file_path: google/adk/tools/crewai_tool.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: '[Note: Inherited members from pydantic.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, tool: str, name: str = '''', description: str = ''''):'
  properties:
  - signature: 'tool: str'
    docstring: The fully qualified path of the CrewAI tool instance.
  - signature: 'name: str'
    docstring: The name of the tool.
  - signature: 'description: str'
    docstring: The description of the tool.
  inherited_properties:
    BaseToolConfig:
    - signature: 'model_config: pydantic.ConfigDict'
    BaseModel:
    - signature: 'model_config: pydantic.ConfigDict'
  omitted_inherited_members_from:
  - pydantic.BaseModel
- rank: 1498
  id: google.adk.tools.discovery_engine_search_tool
  name: discovery_engine_search_tool
  file_path: google/adk/tools/discovery_engine_search_tool.py
  type: MODULE
  group: Orphan
  usage_score: 0
- rank: 1499
  id: google.adk.tools.discovery_engine_search_tool.DiscoveryEngineSearchTool
  name: DiscoveryEngineSearchTool
  file_path: google/adk/tools/discovery_engine_search_tool.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Tool for searching the discovery engine.


    [Note: Inherited members from ABC are omitted.]'
  constructor_signature: 'def __init__(self, data_store_id: typing.Optional[str], data_store_specs: typing.Optional[list[google.genai.types.VertexAISearchDataStoreSpec]], search_engine_id: typing.Optional[str], filter: typing.Optional[str], max_results: typing.Optional[int]):'
  methods:
  - signature: 'def discovery_engine_search(self, query: str) -> dict[str, typing.Any]:'
    docstring: "Search through Vertex AI Search's discovery engine search API.\n\nArgs:\n  query: The search query.\n\nReturns:\n  A dictionary containing the status of the request and the list of search\n  results, which contains the title, url and content."
  inherited_methods:
    FunctionTool:
    - signature: 'def run_async(self, *, args: dict[str, typing.Any], tool_context: google.adk.tools.tool_context.ToolContext) -> typing.Any:'
    BaseTool:
    - signature: 'def run_async(self, *, args: dict[str, typing.Any], tool_context: google.adk.tools.tool_context.ToolContext) -> typing.Any:'
      docstring: "Runs the tool with the given arguments and context.\n\nNOTE:\n  - Required if this tool needs to run at the client side.\n  - Otherwise, can be skipped, e.g. for a built-in GoogleSearch tool for\n    Gemini.\n\nArgs:\n  args: The LLM-filled arguments.\n  tool_context: The context of the tool.\n\nReturns:\n  The result of running the tool."
    - signature: 'def process_llm_request(self, *, tool_context: google.adk.tools.tool_context.ToolContext, llm_request: google.adk.models.llm_request.LlmRequest) -> None:'
      docstring: "Processes the outgoing LLM request for this tool.\n\nUse cases:\n- Most common use case is adding this tool to the LLM request.\n- Some tools may just preprocess the LLM request before it's sent out.\n\nArgs:\n  tool_context: The context of the tool.\n  llm_request: The outgoing LLM request, mutable this method."
    - signature: 'def from_config(cls: typing.Type[google.adk.tools.base_tool.SelfTool], config: google.adk.tools.tool_configs.ToolArgsConfig, config_abs_path: str) -> google.adk.tools.base_tool.SelfTool:'
      docstring: "Creates a tool instance from a config.\n\nThis default implementation uses inspect to automatically map config values\nto constructor arguments based on their type hints. Subclasses should\noverride this method for custom initialization logic.\n\nArgs:\n  config: The config for the tool.\n  config_abs_path: The absolute path to the config file that contains the\n    tool config.\n\nReturns:\n  The tool instance."
  inherited_properties:
    BaseTool:
    - signature: 'name: str'
      docstring: The name of the tool.
    - signature: 'description: str'
      docstring: The description of the tool.
    - signature: 'is_long_running: bool'
      docstring: 'Whether the tool is a long running operation, which typically returns a

        resource id first and finishes the operation later.'
    - signature: 'custom_metadata: typing.Optional[dict[str, typing.Any]]'
      docstring: 'The custom metadata of the BaseTool.


        An optional key-value pair for storing and retrieving tool-specific metadata,

        such as tool manifests, etc.


        NOTE: the entire dict must be JSON serializable.'
  omitted_inherited_members_from:
  - ABC
- rank: 1500
  id: google.adk.tools.discovery_engine_search_tool.DiscoveryEngineSearchTool.__init__
  name: __init__
  file_path: google/adk/tools/discovery_engine_search_tool.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Initializes the DiscoveryEngineSearchTool.\n\nArgs:\n  data_store_id: The Vertex AI search data store resource ID in the format\n    of\n    \"projects/{project}/locations/{location}/collections/{collection}/dataStores/{dataStore}\".\n  data_store_specs: Specifications that define the specific DataStores to be\n    searched. It should only be set if engine is used.\n  search_engine_id: The Vertex AI search engine resource ID in the format of\n    \"projects/{project}/locations/{location}/collections/{collection}/engines/{engine}\".\n  filter: The filter to be applied to the search request. Default is None.\n  max_results: The maximum number of results to return. Default is None."
  signature: 'def __init__(self, data_store_id: typing.Optional[str], data_store_specs: typing.Optional[list[google.genai.types.VertexAISearchDataStoreSpec]], search_engine_id: typing.Optional[str], filter: typing.Optional[str], max_results: typing.Optional[int]):'
- rank: 1501
  id: google.adk.tools.discovery_engine_search_tool.DiscoveryEngineSearchTool.discovery_engine_search
  name: discovery_engine_search
  file_path: google/adk/tools/discovery_engine_search_tool.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Search through Vertex AI Search's discovery engine search API.\n\nArgs:\n  query: The search query.\n\nReturns:\n  A dictionary containing the status of the request and the list of search\n  results, which contains the title, url and content."
  signature: 'def discovery_engine_search(self, query: str) -> dict[str, typing.Any]:'
- rank: 1502
  id: google.adk.tools.enterprise_search_tool
  name: enterprise_search_tool
  file_path: google/adk/tools/enterprise_search_tool.py
  type: MODULE
  group: Orphan
  usage_score: 0
- rank: 1503
  id: google.adk.tools.enterprise_search_tool.EnterpriseWebSearchTool
  name: EnterpriseWebSearchTool
  file_path: google/adk/tools/enterprise_search_tool.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'A Gemini 2+ built-in tool using web grounding for Enterprise compliance.


    See the documentation for more details:

    https://cloud.google.com/vertex-ai/generative-ai/docs/grounding/web-grounding-enterprise.


    [Note: Inherited members from ABC are omitted.]'
  constructor_signature: 'def __init__(self):'
  methods:
  - signature: 'def process_llm_request(self, *, tool_context: google.adk.tools.tool_context.ToolContext, llm_request: google.adk.models.LlmRequest) -> None:'
  inherited_methods:
    BaseTool:
    - signature: 'def run_async(self, *, args: dict[str, typing.Any], tool_context: google.adk.tools.tool_context.ToolContext) -> typing.Any:'
      docstring: "Runs the tool with the given arguments and context.\n\nNOTE:\n  - Required if this tool needs to run at the client side.\n  - Otherwise, can be skipped, e.g. for a built-in GoogleSearch tool for\n    Gemini.\n\nArgs:\n  args: The LLM-filled arguments.\n  tool_context: The context of the tool.\n\nReturns:\n  The result of running the tool."
    - signature: 'def process_llm_request(self, *, tool_context: google.adk.tools.tool_context.ToolContext, llm_request: google.adk.models.llm_request.LlmRequest) -> None:'
      docstring: "Processes the outgoing LLM request for this tool.\n\nUse cases:\n- Most common use case is adding this tool to the LLM request.\n- Some tools may just preprocess the LLM request before it's sent out.\n\nArgs:\n  tool_context: The context of the tool.\n  llm_request: The outgoing LLM request, mutable this method."
    - signature: 'def from_config(cls: typing.Type[google.adk.tools.base_tool.SelfTool], config: google.adk.tools.tool_configs.ToolArgsConfig, config_abs_path: str) -> google.adk.tools.base_tool.SelfTool:'
      docstring: "Creates a tool instance from a config.\n\nThis default implementation uses inspect to automatically map config values\nto constructor arguments based on their type hints. Subclasses should\noverride this method for custom initialization logic.\n\nArgs:\n  config: The config for the tool.\n  config_abs_path: The absolute path to the config file that contains the\n    tool config.\n\nReturns:\n  The tool instance."
  inherited_properties:
    BaseTool:
    - signature: 'name: str'
      docstring: The name of the tool.
    - signature: 'description: str'
      docstring: The description of the tool.
    - signature: 'is_long_running: bool'
      docstring: 'Whether the tool is a long running operation, which typically returns a

        resource id first and finishes the operation later.'
    - signature: 'custom_metadata: typing.Optional[dict[str, typing.Any]]'
      docstring: 'The custom metadata of the BaseTool.


        An optional key-value pair for storing and retrieving tool-specific metadata,

        such as tool manifests, etc.


        NOTE: the entire dict must be JSON serializable.'
  omitted_inherited_members_from:
  - ABC
- rank: 1504
  id: google.adk.tools.enterprise_search_tool.EnterpriseWebSearchTool.__init__
  name: __init__
  file_path: google/adk/tools/enterprise_search_tool.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: Initializes the Vertex AI Search tool.
  signature: 'def __init__(self):'
- rank: 1505
  id: google.adk.tools.enterprise_search_tool.EnterpriseWebSearchTool.process_llm_request
  name: process_llm_request
  file_path: google/adk/tools/enterprise_search_tool.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def process_llm_request(self, *, tool_context: google.adk.tools.tool_context.ToolContext, llm_request: google.adk.models.LlmRequest) -> None:'
- rank: 1506
  id: google.adk.tools.example_tool
  name: example_tool
  file_path: google/adk/tools/example_tool.py
  type: MODULE
  group: Orphan
  usage_score: 0
- rank: 1507
  id: google.adk.tools.example_tool.ExampleTool.__init__
  name: __init__
  file_path: google/adk/tools/example_tool.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def __init__(self, examples: typing.Union[list[google.adk.examples.example.Example], google.adk.examples.base_example_provider.BaseExampleProvider]):'
- rank: 1508
  id: google.adk.tools.example_tool.ExampleTool.from_config
  name: from_config
  file_path: google/adk/tools/example_tool.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def from_config(cls: type[google.adk.tools.example_tool.ExampleTool], config: google.adk.tools.tool_configs.ToolArgsConfig, config_abs_path: str) -> google.adk.tools.example_tool.ExampleTool:'
- rank: 1509
  id: google.adk.tools.example_tool.ExampleTool.process_llm_request
  name: process_llm_request
  file_path: google/adk/tools/example_tool.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def process_llm_request(self, *, tool_context: google.adk.tools.tool_context.ToolContext, llm_request: google.adk.models.llm_request.LlmRequest) -> None:'
- rank: 1510
  id: google.adk.tools.example_tool.ExampleToolConfig
  name: ExampleToolConfig
  file_path: google/adk/tools/example_tool.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: '[Note: Inherited members from pydantic.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, examples: typing.Union[list[google.adk.examples.example.Example], str]):'
  properties:
  - signature: 'examples: typing.Union[list[google.adk.examples.example.Example], str]'
    docstring: 'The examples to add to the LLM request. User can either provide a list of

      examples or a fully-qualified name to a BaseExampleProvider object in code.'
  inherited_properties:
    BaseToolConfig:
    - signature: 'model_config: pydantic.ConfigDict'
    BaseModel:
    - signature: 'model_config: pydantic.ConfigDict'
  omitted_inherited_members_from:
  - pydantic.BaseModel
- rank: 1511
  id: google.adk.tools.exit_loop_tool
  name: exit_loop_tool
  file_path: google/adk/tools/exit_loop_tool.py
  type: MODULE
  group: Orphan
  usage_score: 0
  methods:
  - signature: 'def exit_loop(tool_context: google.adk.tools.tool_context.ToolContext):'
    docstring: 'Exits the loop.


      Call this function only when you are instructed to do so.'
- rank: 1512
  id: google.adk.tools.exit_loop_tool.exit_loop
  name: exit_loop
  file_path: google/adk/tools/exit_loop_tool.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: 'Exits the loop.


    Call this function only when you are instructed to do so.'
  signature: 'def exit_loop(tool_context: google.adk.tools.tool_context.ToolContext):'
  aliases:
  - google.adk.tools.exit_loop
- rank: 1513
  id: google.adk.tools.function_tool
  name: function_tool
  file_path: google/adk/tools/function_tool.py
  type: MODULE
  group: Orphan
  usage_score: 0
- rank: 1514
  id: google.adk.tools.function_tool.FunctionTool.__init__
  name: __init__
  file_path: google/adk/tools/function_tool.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Initializes the FunctionTool. Extracts metadata from a callable object.\n\nArgs:\n  func: The function to wrap.\n  require_confirmation: Whether this tool requires confirmation. A boolean or\n    a callable that takes the function's arguments and returns a boolean. If\n    the callable returns True, the tool will require confirmation from the\n    user."
  signature: 'def __init__(self, func: typing.Callable[Ellipsis, typing.Any], *, require_confirmation: typing.Union[bool, typing.Callable[Ellipsis, bool]]=False):'
- rank: 1515
  id: google.adk.tools.function_tool.FunctionTool.run_async
  name: run_async
  file_path: google/adk/tools/function_tool.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def run_async(self, *, args: dict[str, typing.Any], tool_context: google.adk.tools.tool_context.ToolContext) -> typing.Any:'
- rank: 1516
  id: google.adk.tools.get_user_choice_tool
  name: get_user_choice_tool
  file_path: google/adk/tools/get_user_choice_tool.py
  type: MODULE
  group: Orphan
  usage_score: 0
  methods:
  - signature: 'def get_user_choice(options: list[str], tool_context: google.adk.tools.tool_context.ToolContext) -> typing.Optional[str]:'
    docstring: Provides the options to the user and asks them to choose one.
- rank: 1517
  id: google.adk.tools.get_user_choice_tool.get_user_choice
  name: get_user_choice
  file_path: google/adk/tools/get_user_choice_tool.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: Provides the options to the user and asks them to choose one.
  signature: 'def get_user_choice(options: list[str], tool_context: google.adk.tools.tool_context.ToolContext) -> typing.Optional[str]:'
- rank: 1518
  id: google.adk.tools.google_api_tool
  name: google_api_tool
  file_path: google/adk/tools/google_api_tool/__init__.py
  type: MODULE
  group: Orphan
  usage_score: 0
  docstring: 'Auto-generated tools and toolsets for Google APIs.


    These tools and toolsets are auto-generated based on the API specifications

    provided by the Google API Discovery API.'
- rank: 1519
  id: google.adk.tools.google_api_tool.google_api_tool
  name: google_api_tool
  file_path: google/adk/tools/google_api_tool/google_api_tool.py
  type: MODULE
  group: Orphan
  usage_score: 0
- rank: 1520
  id: google.adk.tools.google_api_tool.google_api_tool.GoogleApiTool
  name: GoogleApiTool
  file_path: google/adk/tools/google_api_tool/google_api_tool.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: '[Note: Inherited members from ABC are omitted.]'
  constructor_signature: 'def __init__(self, rest_api_tool: google.adk.tools.openapi_tool.RestApiTool, client_id: typing.Optional[str], client_secret: typing.Optional[str], service_account: typing.Optional[google.adk.auth.auth_credential.ServiceAccount], *, additional_headers: typing.Optional[typing.Dict[str, str]]=None):'
  methods:
  - signature: 'def run_async(self, *, args: typing.Dict[str, typing.Any], tool_context: typing.Optional[google.adk.tools.tool_context.ToolContext]) -> typing.Dict[str, typing.Any]:'
  - signature: 'def configure_auth(self, client_id: str, client_secret: str):'
  - signature: 'def configure_sa_auth(self, service_account: google.adk.auth.auth_credential.ServiceAccount):'
  inherited_methods:
    BaseTool:
    - signature: 'def run_async(self, *, args: dict[str, typing.Any], tool_context: google.adk.tools.tool_context.ToolContext) -> typing.Any:'
      docstring: "Runs the tool with the given arguments and context.\n\nNOTE:\n  - Required if this tool needs to run at the client side.\n  - Otherwise, can be skipped, e.g. for a built-in GoogleSearch tool for\n    Gemini.\n\nArgs:\n  args: The LLM-filled arguments.\n  tool_context: The context of the tool.\n\nReturns:\n  The result of running the tool."
    - signature: 'def process_llm_request(self, *, tool_context: google.adk.tools.tool_context.ToolContext, llm_request: google.adk.models.llm_request.LlmRequest) -> None:'
      docstring: "Processes the outgoing LLM request for this tool.\n\nUse cases:\n- Most common use case is adding this tool to the LLM request.\n- Some tools may just preprocess the LLM request before it's sent out.\n\nArgs:\n  tool_context: The context of the tool.\n  llm_request: The outgoing LLM request, mutable this method."
    - signature: 'def from_config(cls: typing.Type[google.adk.tools.base_tool.SelfTool], config: google.adk.tools.tool_configs.ToolArgsConfig, config_abs_path: str) -> google.adk.tools.base_tool.SelfTool:'
      docstring: "Creates a tool instance from a config.\n\nThis default implementation uses inspect to automatically map config values\nto constructor arguments based on their type hints. Subclasses should\noverride this method for custom initialization logic.\n\nArgs:\n  config: The config for the tool.\n  config_abs_path: The absolute path to the config file that contains the\n    tool config.\n\nReturns:\n  The tool instance."
  inherited_properties:
    BaseTool:
    - signature: 'name: str'
      docstring: The name of the tool.
    - signature: 'description: str'
      docstring: The description of the tool.
    - signature: 'is_long_running: bool'
      docstring: 'Whether the tool is a long running operation, which typically returns a

        resource id first and finishes the operation later.'
    - signature: 'custom_metadata: typing.Optional[dict[str, typing.Any]]'
      docstring: 'The custom metadata of the BaseTool.


        An optional key-value pair for storing and retrieving tool-specific metadata,

        such as tool manifests, etc.


        NOTE: the entire dict must be JSON serializable.'
  omitted_inherited_members_from:
  - ABC
- rank: 1521
  id: google.adk.tools.google_api_tool.google_api_tool.GoogleApiTool.__init__
  name: __init__
  file_path: google/adk/tools/google_api_tool/google_api_tool.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def __init__(self, rest_api_tool: google.adk.tools.openapi_tool.RestApiTool, client_id: typing.Optional[str], client_secret: typing.Optional[str], service_account: typing.Optional[google.adk.auth.auth_credential.ServiceAccount], *, additional_headers: typing.Optional[typing.Dict[str, str]]=None):'
- rank: 1522
  id: google.adk.tools.google_api_tool.google_api_tool.GoogleApiTool.configure_auth
  name: configure_auth
  file_path: google/adk/tools/google_api_tool/google_api_tool.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def configure_auth(self, client_id: str, client_secret: str):'
- rank: 1523
  id: google.adk.tools.google_api_tool.google_api_tool.GoogleApiTool.configure_sa_auth
  name: configure_sa_auth
  file_path: google/adk/tools/google_api_tool/google_api_tool.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def configure_sa_auth(self, service_account: google.adk.auth.auth_credential.ServiceAccount):'
- rank: 1524
  id: google.adk.tools.google_api_tool.google_api_tool.GoogleApiTool.run_async
  name: run_async
  file_path: google/adk/tools/google_api_tool/google_api_tool.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def run_async(self, *, args: typing.Dict[str, typing.Any], tool_context: typing.Optional[google.adk.tools.tool_context.ToolContext]) -> typing.Dict[str, typing.Any]:'
- rank: 1525
  id: google.adk.tools.google_api_tool.google_api_toolset
  name: google_api_toolset
  file_path: google/adk/tools/google_api_tool/google_api_toolset.py
  type: MODULE
  group: Orphan
  usage_score: 0
- rank: 1526
  id: google.adk.tools.google_api_tool.google_api_toolset.GoogleApiToolset
  name: GoogleApiToolset
  file_path: google/adk/tools/google_api_tool/google_api_toolset.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: "Google API Toolset contains tools for interacting with Google APIs.\n\nUsually one toolsets will contain tools only related to one Google API, e.g.\nGoogle Bigquery API toolset will contain tools only related to Google\nBigquery API, like list dataset tool, list table tool etc.\n\nArgs:\n  api_name: The name of the Google API (e.g., \"calendar\", \"gmail\").\n  api_version: The version of the API (e.g., \"v3\", \"v1\").\n  client_id: OAuth2 client ID for authentication.\n  client_secret: OAuth2 client secret for authentication.\n  tool_filter: Optional filter to include only specific tools or use a predicate function.\n  service_account: Optional service account for authentication.\n  tool_name_prefix: Optional prefix to add to all tool names in this toolset.\n  additional_headers: Optional dict of HTTP headers to inject into every request\n    executed by this toolset.\n\n[Note: Inherited members from ABC are omitted.]"
  constructor_signature: 'def __init__(self, api_name: str, api_version: str, client_id: typing.Optional[str], client_secret: typing.Optional[str], tool_filter: typing.Optional[typing.Union[google.adk.tools.base_toolset.ToolPredicate, typing.List[str]]], service_account: typing.Optional[google.adk.auth.auth_credential.ServiceAccount], tool_name_prefix: typing.Optional[str], *, additional_headers: typing.Optional[typing.Dict[str, str]]=None):'
  methods:
  - signature: 'def get_tools(self, readonly_context: typing.Optional[google.adk.agents.readonly_context.ReadonlyContext]) -> typing.List[google.adk.tools.google_api_tool.google_api_tool.GoogleApiTool]:'
    docstring: Get all tools in the toolset.
  - signature: 'def set_tool_filter(self, tool_filter: typing.Union[google.adk.tools.base_toolset.ToolPredicate, typing.List[str]]):'
  - signature: 'def configure_auth(self, client_id: str, client_secret: str):'
  - signature: 'def configure_sa_auth(self, service_account: google.adk.auth.auth_credential.ServiceAccount):'
  - signature: 'def close(self):'
  inherited_methods:
    BaseToolset:
    - signature: 'def get_tools(self, readonly_context: typing.Optional[google.adk.agents.readonly_context.ReadonlyContext]) -> list[google.adk.tools.base_tool.BaseTool]:'
      docstring: "Return all tools in the toolset based on the provided context.\n\nArgs:\n  readonly_context (ReadonlyContext, optional): Context used to filter tools\n    available to the agent. If None, all tools in the toolset are returned.\n\nReturns:\n  list[BaseTool]: A list of tools available under the specified context."
    - signature: 'def get_tools_with_prefix(self, readonly_context: typing.Optional[google.adk.agents.readonly_context.ReadonlyContext]) -> list[google.adk.tools.base_tool.BaseTool]:'
      docstring: "Return all tools with optional prefix applied to tool names.\n\nThis method calls get_tools() and applies prefixing if tool_name_prefix is provided.\n\nArgs:\n  readonly_context (ReadonlyContext, optional): Context used to filter tools\n    available to the agent. If None, all tools in the toolset are returned.\n\nReturns:\n  list[BaseTool]: A list of tools with prefixed names if tool_name_prefix is provided."
    - signature: 'def close(self) -> None:'
      docstring: "Performs cleanup and releases resources held by the toolset.\n\nNOTE:\n  This method is invoked, for example, at the end of an agent server's\n  lifecycle or when the toolset is no longer needed. Implementations\n  should ensure that any open connections, files, or other managed\n  resources are properly released to prevent leaks."
    - signature: 'def from_config(cls: typing.Type[google.adk.tools.base_toolset.SelfToolset], config: google.adk.tools.tool_configs.ToolArgsConfig, config_abs_path: str) -> google.adk.tools.base_toolset.SelfToolset:'
      docstring: "Creates a toolset instance from a config.\n\nArgs:\n  config: The config for the tool.\n  config_abs_path: The absolute path to the config file that contains the\n    tool config.\n\nReturns:\n  The toolset instance."
    - signature: 'def process_llm_request(self, *, tool_context: google.adk.tools.tool_context.ToolContext, llm_request: google.adk.models.llm_request.LlmRequest) -> None:'
      docstring: "Processes the outgoing LLM request for this toolset. This method will be\ncalled before each tool processes the llm request.\n\nUse cases:\n- Instead of let each tool process the llm request, we can let the toolset\n  process the llm request. e.g. ComputerUseToolset can add computer use\n  tool to the llm request.\n\nArgs:\n  tool_context: The context of the tool.\n  llm_request: The outgoing LLM request, mutable this method."
  omitted_inherited_members_from:
  - ABC
- rank: 1527
  id: google.adk.tools.google_api_tool.google_api_toolset.GoogleApiToolset.__init__
  name: __init__
  file_path: google/adk/tools/google_api_tool/google_api_toolset.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def __init__(self, api_name: str, api_version: str, client_id: typing.Optional[str], client_secret: typing.Optional[str], tool_filter: typing.Optional[typing.Union[google.adk.tools.base_toolset.ToolPredicate, typing.List[str]]], service_account: typing.Optional[google.adk.auth.auth_credential.ServiceAccount], tool_name_prefix: typing.Optional[str], *, additional_headers: typing.Optional[typing.Dict[str, str]]=None):'
- rank: 1528
  id: google.adk.tools.google_api_tool.google_api_toolset.GoogleApiToolset.get_tools
  name: get_tools
  file_path: google/adk/tools/google_api_tool/google_api_toolset.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: Get all tools in the toolset.
  signature: 'def get_tools(self, readonly_context: typing.Optional[google.adk.agents.readonly_context.ReadonlyContext]) -> typing.List[google.adk.tools.google_api_tool.google_api_tool.GoogleApiTool]:'
- rank: 1529
  id: google.adk.tools.google_api_tool.google_api_toolsets
  name: google_api_toolsets
  file_path: google/adk/tools/google_api_tool/google_api_toolsets.py
  type: MODULE
  group: Orphan
  usage_score: 0
- rank: 1530
  id: google.adk.tools.google_api_tool.google_api_toolsets.BigQueryToolset
  name: BigQueryToolset
  file_path: google/adk/tools/google_api_tool/google_api_toolsets.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: "Auto-generated BigQuery toolset based on Google BigQuery API v2 spec exposed by Google API discovery API.\n\nArgs:\n  client_id: OAuth2 client ID for authentication.\n  client_secret: OAuth2 client secret for authentication.\n  tool_filter: Optional filter to include only specific tools or use a predicate function.\n  service_account: Optional service account for authentication.\n  tool_name_prefix: Optional prefix to add to all tool names in this toolset.\n\n[Note: Inherited members from ABC are omitted.]"
  constructor_signature: 'def __init__(self, client_id: typing.Optional[str], client_secret: typing.Optional[str], tool_filter: typing.Optional[typing.Union[google.adk.tools.base_toolset.ToolPredicate, typing.List[str]]], service_account: typing.Optional[google.adk.auth.auth_credential.ServiceAccount], tool_name_prefix: typing.Optional[str]):'
  aliases:
  - google.adk.tools.google_api_tool.BigQueryToolset
  inherited_methods:
    GoogleApiToolset:
    - signature: 'def get_tools(self, readonly_context: typing.Optional[google.adk.agents.readonly_context.ReadonlyContext]) -> typing.List[google.adk.tools.google_api_tool.google_api_tool.GoogleApiTool]:'
      docstring: Get all tools in the toolset.
    - signature: 'def set_tool_filter(self, tool_filter: typing.Union[google.adk.tools.base_toolset.ToolPredicate, typing.List[str]]):'
    - signature: 'def configure_auth(self, client_id: str, client_secret: str):'
    - signature: 'def configure_sa_auth(self, service_account: google.adk.auth.auth_credential.ServiceAccount):'
    - signature: 'def close(self):'
    BaseToolset:
    - signature: 'def get_tools(self, readonly_context: typing.Optional[google.adk.agents.readonly_context.ReadonlyContext]) -> list[google.adk.tools.base_tool.BaseTool]:'
      docstring: "Return all tools in the toolset based on the provided context.\n\nArgs:\n  readonly_context (ReadonlyContext, optional): Context used to filter tools\n    available to the agent. If None, all tools in the toolset are returned.\n\nReturns:\n  list[BaseTool]: A list of tools available under the specified context."
    - signature: 'def get_tools_with_prefix(self, readonly_context: typing.Optional[google.adk.agents.readonly_context.ReadonlyContext]) -> list[google.adk.tools.base_tool.BaseTool]:'
      docstring: "Return all tools with optional prefix applied to tool names.\n\nThis method calls get_tools() and applies prefixing if tool_name_prefix is provided.\n\nArgs:\n  readonly_context (ReadonlyContext, optional): Context used to filter tools\n    available to the agent. If None, all tools in the toolset are returned.\n\nReturns:\n  list[BaseTool]: A list of tools with prefixed names if tool_name_prefix is provided."
    - signature: 'def close(self) -> None:'
      docstring: "Performs cleanup and releases resources held by the toolset.\n\nNOTE:\n  This method is invoked, for example, at the end of an agent server's\n  lifecycle or when the toolset is no longer needed. Implementations\n  should ensure that any open connections, files, or other managed\n  resources are properly released to prevent leaks."
    - signature: 'def from_config(cls: typing.Type[google.adk.tools.base_toolset.SelfToolset], config: google.adk.tools.tool_configs.ToolArgsConfig, config_abs_path: str) -> google.adk.tools.base_toolset.SelfToolset:'
      docstring: "Creates a toolset instance from a config.\n\nArgs:\n  config: The config for the tool.\n  config_abs_path: The absolute path to the config file that contains the\n    tool config.\n\nReturns:\n  The toolset instance."
    - signature: 'def process_llm_request(self, *, tool_context: google.adk.tools.tool_context.ToolContext, llm_request: google.adk.models.llm_request.LlmRequest) -> None:'
      docstring: "Processes the outgoing LLM request for this toolset. This method will be\ncalled before each tool processes the llm request.\n\nUse cases:\n- Instead of let each tool process the llm request, we can let the toolset\n  process the llm request. e.g. ComputerUseToolset can add computer use\n  tool to the llm request.\n\nArgs:\n  tool_context: The context of the tool.\n  llm_request: The outgoing LLM request, mutable this method."
  omitted_inherited_members_from:
  - ABC
- rank: 1531
  id: google.adk.tools.google_api_tool.google_api_toolsets.BigQueryToolset.__init__
  name: __init__
  file_path: google/adk/tools/google_api_tool/google_api_toolsets.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def __init__(self, client_id: typing.Optional[str], client_secret: typing.Optional[str], tool_filter: typing.Optional[typing.Union[google.adk.tools.base_toolset.ToolPredicate, typing.List[str]]], service_account: typing.Optional[google.adk.auth.auth_credential.ServiceAccount], tool_name_prefix: typing.Optional[str]):'
- rank: 1532
  id: google.adk.tools.google_api_tool.google_api_toolsets.CalendarToolset
  name: CalendarToolset
  file_path: google/adk/tools/google_api_tool/google_api_toolsets.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: "Auto-generated Calendar toolset based on Google Calendar API v3 spec exposed by Google API discovery API.\n\nArgs:\n  client_id: OAuth2 client ID for authentication.\n  client_secret: OAuth2 client secret for authentication.\n  tool_filter: Optional filter to include only specific tools or use a predicate function.\n  service_account: Optional service account for authentication.\n  tool_name_prefix: Optional prefix to add to all tool names in this toolset.\n\n[Note: Inherited members from ABC are omitted.]"
  constructor_signature: 'def __init__(self, client_id: typing.Optional[str], client_secret: typing.Optional[str], tool_filter: typing.Optional[typing.Union[google.adk.tools.base_toolset.ToolPredicate, typing.List[str]]], service_account: typing.Optional[google.adk.auth.auth_credential.ServiceAccount], tool_name_prefix: typing.Optional[str]):'
  aliases:
  - google.adk.tools.google_api_tool.CalendarToolset
  inherited_methods:
    GoogleApiToolset:
    - signature: 'def get_tools(self, readonly_context: typing.Optional[google.adk.agents.readonly_context.ReadonlyContext]) -> typing.List[google.adk.tools.google_api_tool.google_api_tool.GoogleApiTool]:'
      docstring: Get all tools in the toolset.
    - signature: 'def set_tool_filter(self, tool_filter: typing.Union[google.adk.tools.base_toolset.ToolPredicate, typing.List[str]]):'
    - signature: 'def configure_auth(self, client_id: str, client_secret: str):'
    - signature: 'def configure_sa_auth(self, service_account: google.adk.auth.auth_credential.ServiceAccount):'
    - signature: 'def close(self):'
    BaseToolset:
    - signature: 'def get_tools(self, readonly_context: typing.Optional[google.adk.agents.readonly_context.ReadonlyContext]) -> list[google.adk.tools.base_tool.BaseTool]:'
      docstring: "Return all tools in the toolset based on the provided context.\n\nArgs:\n  readonly_context (ReadonlyContext, optional): Context used to filter tools\n    available to the agent. If None, all tools in the toolset are returned.\n\nReturns:\n  list[BaseTool]: A list of tools available under the specified context."
    - signature: 'def get_tools_with_prefix(self, readonly_context: typing.Optional[google.adk.agents.readonly_context.ReadonlyContext]) -> list[google.adk.tools.base_tool.BaseTool]:'
      docstring: "Return all tools with optional prefix applied to tool names.\n\nThis method calls get_tools() and applies prefixing if tool_name_prefix is provided.\n\nArgs:\n  readonly_context (ReadonlyContext, optional): Context used to filter tools\n    available to the agent. If None, all tools in the toolset are returned.\n\nReturns:\n  list[BaseTool]: A list of tools with prefixed names if tool_name_prefix is provided."
    - signature: 'def close(self) -> None:'
      docstring: "Performs cleanup and releases resources held by the toolset.\n\nNOTE:\n  This method is invoked, for example, at the end of an agent server's\n  lifecycle or when the toolset is no longer needed. Implementations\n  should ensure that any open connections, files, or other managed\n  resources are properly released to prevent leaks."
    - signature: 'def from_config(cls: typing.Type[google.adk.tools.base_toolset.SelfToolset], config: google.adk.tools.tool_configs.ToolArgsConfig, config_abs_path: str) -> google.adk.tools.base_toolset.SelfToolset:'
      docstring: "Creates a toolset instance from a config.\n\nArgs:\n  config: The config for the tool.\n  config_abs_path: The absolute path to the config file that contains the\n    tool config.\n\nReturns:\n  The toolset instance."
    - signature: 'def process_llm_request(self, *, tool_context: google.adk.tools.tool_context.ToolContext, llm_request: google.adk.models.llm_request.LlmRequest) -> None:'
      docstring: "Processes the outgoing LLM request for this toolset. This method will be\ncalled before each tool processes the llm request.\n\nUse cases:\n- Instead of let each tool process the llm request, we can let the toolset\n  process the llm request. e.g. ComputerUseToolset can add computer use\n  tool to the llm request.\n\nArgs:\n  tool_context: The context of the tool.\n  llm_request: The outgoing LLM request, mutable this method."
  omitted_inherited_members_from:
  - ABC
- rank: 1533
  id: google.adk.tools.google_api_tool.google_api_toolsets.CalendarToolset.__init__
  name: __init__
  file_path: google/adk/tools/google_api_tool/google_api_toolsets.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def __init__(self, client_id: typing.Optional[str], client_secret: typing.Optional[str], tool_filter: typing.Optional[typing.Union[google.adk.tools.base_toolset.ToolPredicate, typing.List[str]]], service_account: typing.Optional[google.adk.auth.auth_credential.ServiceAccount], tool_name_prefix: typing.Optional[str]):'
- rank: 1534
  id: google.adk.tools.google_api_tool.google_api_toolsets.DocsToolset
  name: DocsToolset
  file_path: google/adk/tools/google_api_tool/google_api_toolsets.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: "Auto-generated Docs toolset based on Google Docs API v1 spec exposed by Google API discovery API.\n\nArgs:\n  client_id: OAuth2 client ID for authentication.\n  client_secret: OAuth2 client secret for authentication.\n  tool_filter: Optional filter to include only specific tools or use a predicate function.\n  service_account: Optional service account for authentication.\n  tool_name_prefix: Optional prefix to add to all tool names in this toolset.\n\n[Note: Inherited members from ABC are omitted.]"
  constructor_signature: 'def __init__(self, client_id: typing.Optional[str], client_secret: typing.Optional[str], tool_filter: typing.Optional[typing.Union[google.adk.tools.base_toolset.ToolPredicate, typing.List[str]]], service_account: typing.Optional[google.adk.auth.auth_credential.ServiceAccount], tool_name_prefix: typing.Optional[str]):'
  aliases:
  - google.adk.tools.google_api_tool.DocsToolset
  inherited_methods:
    GoogleApiToolset:
    - signature: 'def get_tools(self, readonly_context: typing.Optional[google.adk.agents.readonly_context.ReadonlyContext]) -> typing.List[google.adk.tools.google_api_tool.google_api_tool.GoogleApiTool]:'
      docstring: Get all tools in the toolset.
    - signature: 'def set_tool_filter(self, tool_filter: typing.Union[google.adk.tools.base_toolset.ToolPredicate, typing.List[str]]):'
    - signature: 'def configure_auth(self, client_id: str, client_secret: str):'
    - signature: 'def configure_sa_auth(self, service_account: google.adk.auth.auth_credential.ServiceAccount):'
    - signature: 'def close(self):'
    BaseToolset:
    - signature: 'def get_tools(self, readonly_context: typing.Optional[google.adk.agents.readonly_context.ReadonlyContext]) -> list[google.adk.tools.base_tool.BaseTool]:'
      docstring: "Return all tools in the toolset based on the provided context.\n\nArgs:\n  readonly_context (ReadonlyContext, optional): Context used to filter tools\n    available to the agent. If None, all tools in the toolset are returned.\n\nReturns:\n  list[BaseTool]: A list of tools available under the specified context."
    - signature: 'def get_tools_with_prefix(self, readonly_context: typing.Optional[google.adk.agents.readonly_context.ReadonlyContext]) -> list[google.adk.tools.base_tool.BaseTool]:'
      docstring: "Return all tools with optional prefix applied to tool names.\n\nThis method calls get_tools() and applies prefixing if tool_name_prefix is provided.\n\nArgs:\n  readonly_context (ReadonlyContext, optional): Context used to filter tools\n    available to the agent. If None, all tools in the toolset are returned.\n\nReturns:\n  list[BaseTool]: A list of tools with prefixed names if tool_name_prefix is provided."
    - signature: 'def close(self) -> None:'
      docstring: "Performs cleanup and releases resources held by the toolset.\n\nNOTE:\n  This method is invoked, for example, at the end of an agent server's\n  lifecycle or when the toolset is no longer needed. Implementations\n  should ensure that any open connections, files, or other managed\n  resources are properly released to prevent leaks."
    - signature: 'def from_config(cls: typing.Type[google.adk.tools.base_toolset.SelfToolset], config: google.adk.tools.tool_configs.ToolArgsConfig, config_abs_path: str) -> google.adk.tools.base_toolset.SelfToolset:'
      docstring: "Creates a toolset instance from a config.\n\nArgs:\n  config: The config for the tool.\n  config_abs_path: The absolute path to the config file that contains the\n    tool config.\n\nReturns:\n  The toolset instance."
    - signature: 'def process_llm_request(self, *, tool_context: google.adk.tools.tool_context.ToolContext, llm_request: google.adk.models.llm_request.LlmRequest) -> None:'
      docstring: "Processes the outgoing LLM request for this toolset. This method will be\ncalled before each tool processes the llm request.\n\nUse cases:\n- Instead of let each tool process the llm request, we can let the toolset\n  process the llm request. e.g. ComputerUseToolset can add computer use\n  tool to the llm request.\n\nArgs:\n  tool_context: The context of the tool.\n  llm_request: The outgoing LLM request, mutable this method."
  omitted_inherited_members_from:
  - ABC
- rank: 1535
  id: google.adk.tools.google_api_tool.google_api_toolsets.DocsToolset.__init__
  name: __init__
  file_path: google/adk/tools/google_api_tool/google_api_toolsets.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def __init__(self, client_id: typing.Optional[str], client_secret: typing.Optional[str], tool_filter: typing.Optional[typing.Union[google.adk.tools.base_toolset.ToolPredicate, typing.List[str]]], service_account: typing.Optional[google.adk.auth.auth_credential.ServiceAccount], tool_name_prefix: typing.Optional[str]):'
- rank: 1536
  id: google.adk.tools.google_api_tool.google_api_toolsets.GmailToolset
  name: GmailToolset
  file_path: google/adk/tools/google_api_tool/google_api_toolsets.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: "Auto-generated Gmail toolset based on Google Gmail API v1 spec exposed by Google API discovery API.\n\nArgs:\n  client_id: OAuth2 client ID for authentication.\n  client_secret: OAuth2 client secret for authentication.\n  tool_filter: Optional filter to include only specific tools or use a predicate function.\n  service_account: Optional service account for authentication.\n  tool_name_prefix: Optional prefix to add to all tool names in this toolset.\n\n[Note: Inherited members from ABC are omitted.]"
  constructor_signature: 'def __init__(self, client_id: typing.Optional[str], client_secret: typing.Optional[str], tool_filter: typing.Optional[typing.Union[google.adk.tools.base_toolset.ToolPredicate, typing.List[str]]], service_account: typing.Optional[google.adk.auth.auth_credential.ServiceAccount], tool_name_prefix: typing.Optional[str]):'
  aliases:
  - google.adk.tools.google_api_tool.GmailToolset
  inherited_methods:
    GoogleApiToolset:
    - signature: 'def get_tools(self, readonly_context: typing.Optional[google.adk.agents.readonly_context.ReadonlyContext]) -> typing.List[google.adk.tools.google_api_tool.google_api_tool.GoogleApiTool]:'
      docstring: Get all tools in the toolset.
    - signature: 'def set_tool_filter(self, tool_filter: typing.Union[google.adk.tools.base_toolset.ToolPredicate, typing.List[str]]):'
    - signature: 'def configure_auth(self, client_id: str, client_secret: str):'
    - signature: 'def configure_sa_auth(self, service_account: google.adk.auth.auth_credential.ServiceAccount):'
    - signature: 'def close(self):'
    BaseToolset:
    - signature: 'def get_tools(self, readonly_context: typing.Optional[google.adk.agents.readonly_context.ReadonlyContext]) -> list[google.adk.tools.base_tool.BaseTool]:'
      docstring: "Return all tools in the toolset based on the provided context.\n\nArgs:\n  readonly_context (ReadonlyContext, optional): Context used to filter tools\n    available to the agent. If None, all tools in the toolset are returned.\n\nReturns:\n  list[BaseTool]: A list of tools available under the specified context."
    - signature: 'def get_tools_with_prefix(self, readonly_context: typing.Optional[google.adk.agents.readonly_context.ReadonlyContext]) -> list[google.adk.tools.base_tool.BaseTool]:'
      docstring: "Return all tools with optional prefix applied to tool names.\n\nThis method calls get_tools() and applies prefixing if tool_name_prefix is provided.\n\nArgs:\n  readonly_context (ReadonlyContext, optional): Context used to filter tools\n    available to the agent. If None, all tools in the toolset are returned.\n\nReturns:\n  list[BaseTool]: A list of tools with prefixed names if tool_name_prefix is provided."
    - signature: 'def close(self) -> None:'
      docstring: "Performs cleanup and releases resources held by the toolset.\n\nNOTE:\n  This method is invoked, for example, at the end of an agent server's\n  lifecycle or when the toolset is no longer needed. Implementations\n  should ensure that any open connections, files, or other managed\n  resources are properly released to prevent leaks."
    - signature: 'def from_config(cls: typing.Type[google.adk.tools.base_toolset.SelfToolset], config: google.adk.tools.tool_configs.ToolArgsConfig, config_abs_path: str) -> google.adk.tools.base_toolset.SelfToolset:'
      docstring: "Creates a toolset instance from a config.\n\nArgs:\n  config: The config for the tool.\n  config_abs_path: The absolute path to the config file that contains the\n    tool config.\n\nReturns:\n  The toolset instance."
    - signature: 'def process_llm_request(self, *, tool_context: google.adk.tools.tool_context.ToolContext, llm_request: google.adk.models.llm_request.LlmRequest) -> None:'
      docstring: "Processes the outgoing LLM request for this toolset. This method will be\ncalled before each tool processes the llm request.\n\nUse cases:\n- Instead of let each tool process the llm request, we can let the toolset\n  process the llm request. e.g. ComputerUseToolset can add computer use\n  tool to the llm request.\n\nArgs:\n  tool_context: The context of the tool.\n  llm_request: The outgoing LLM request, mutable this method."
  omitted_inherited_members_from:
  - ABC
- rank: 1537
  id: google.adk.tools.google_api_tool.google_api_toolsets.GmailToolset.__init__
  name: __init__
  file_path: google/adk/tools/google_api_tool/google_api_toolsets.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def __init__(self, client_id: typing.Optional[str], client_secret: typing.Optional[str], tool_filter: typing.Optional[typing.Union[google.adk.tools.base_toolset.ToolPredicate, typing.List[str]]], service_account: typing.Optional[google.adk.auth.auth_credential.ServiceAccount], tool_name_prefix: typing.Optional[str]):'
- rank: 1538
  id: google.adk.tools.google_api_tool.google_api_toolsets.SheetsToolset
  name: SheetsToolset
  file_path: google/adk/tools/google_api_tool/google_api_toolsets.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: "Auto-generated Sheets toolset based on Google Sheets API v4 spec exposed by Google API discovery API.\n\nArgs:\n  client_id: OAuth2 client ID for authentication.\n  client_secret: OAuth2 client secret for authentication.\n  tool_filter: Optional filter to include only specific tools or use a predicate function.\n  service_account: Optional service account for authentication.\n  tool_name_prefix: Optional prefix to add to all tool names in this toolset.\n\n[Note: Inherited members from ABC are omitted.]"
  constructor_signature: 'def __init__(self, client_id: typing.Optional[str], client_secret: typing.Optional[str], tool_filter: typing.Optional[typing.Union[google.adk.tools.base_toolset.ToolPredicate, typing.List[str]]], service_account: typing.Optional[google.adk.auth.auth_credential.ServiceAccount], tool_name_prefix: typing.Optional[str]):'
  aliases:
  - google.adk.tools.google_api_tool.SheetsToolset
  inherited_methods:
    GoogleApiToolset:
    - signature: 'def get_tools(self, readonly_context: typing.Optional[google.adk.agents.readonly_context.ReadonlyContext]) -> typing.List[google.adk.tools.google_api_tool.google_api_tool.GoogleApiTool]:'
      docstring: Get all tools in the toolset.
    - signature: 'def set_tool_filter(self, tool_filter: typing.Union[google.adk.tools.base_toolset.ToolPredicate, typing.List[str]]):'
    - signature: 'def configure_auth(self, client_id: str, client_secret: str):'
    - signature: 'def configure_sa_auth(self, service_account: google.adk.auth.auth_credential.ServiceAccount):'
    - signature: 'def close(self):'
    BaseToolset:
    - signature: 'def get_tools(self, readonly_context: typing.Optional[google.adk.agents.readonly_context.ReadonlyContext]) -> list[google.adk.tools.base_tool.BaseTool]:'
      docstring: "Return all tools in the toolset based on the provided context.\n\nArgs:\n  readonly_context (ReadonlyContext, optional): Context used to filter tools\n    available to the agent. If None, all tools in the toolset are returned.\n\nReturns:\n  list[BaseTool]: A list of tools available under the specified context."
    - signature: 'def get_tools_with_prefix(self, readonly_context: typing.Optional[google.adk.agents.readonly_context.ReadonlyContext]) -> list[google.adk.tools.base_tool.BaseTool]:'
      docstring: "Return all tools with optional prefix applied to tool names.\n\nThis method calls get_tools() and applies prefixing if tool_name_prefix is provided.\n\nArgs:\n  readonly_context (ReadonlyContext, optional): Context used to filter tools\n    available to the agent. If None, all tools in the toolset are returned.\n\nReturns:\n  list[BaseTool]: A list of tools with prefixed names if tool_name_prefix is provided."
    - signature: 'def close(self) -> None:'
      docstring: "Performs cleanup and releases resources held by the toolset.\n\nNOTE:\n  This method is invoked, for example, at the end of an agent server's\n  lifecycle or when the toolset is no longer needed. Implementations\n  should ensure that any open connections, files, or other managed\n  resources are properly released to prevent leaks."
    - signature: 'def from_config(cls: typing.Type[google.adk.tools.base_toolset.SelfToolset], config: google.adk.tools.tool_configs.ToolArgsConfig, config_abs_path: str) -> google.adk.tools.base_toolset.SelfToolset:'
      docstring: "Creates a toolset instance from a config.\n\nArgs:\n  config: The config for the tool.\n  config_abs_path: The absolute path to the config file that contains the\n    tool config.\n\nReturns:\n  The toolset instance."
    - signature: 'def process_llm_request(self, *, tool_context: google.adk.tools.tool_context.ToolContext, llm_request: google.adk.models.llm_request.LlmRequest) -> None:'
      docstring: "Processes the outgoing LLM request for this toolset. This method will be\ncalled before each tool processes the llm request.\n\nUse cases:\n- Instead of let each tool process the llm request, we can let the toolset\n  process the llm request. e.g. ComputerUseToolset can add computer use\n  tool to the llm request.\n\nArgs:\n  tool_context: The context of the tool.\n  llm_request: The outgoing LLM request, mutable this method."
  omitted_inherited_members_from:
  - ABC
- rank: 1539
  id: google.adk.tools.google_api_tool.google_api_toolsets.SheetsToolset.__init__
  name: __init__
  file_path: google/adk/tools/google_api_tool/google_api_toolsets.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def __init__(self, client_id: typing.Optional[str], client_secret: typing.Optional[str], tool_filter: typing.Optional[typing.Union[google.adk.tools.base_toolset.ToolPredicate, typing.List[str]]], service_account: typing.Optional[google.adk.auth.auth_credential.ServiceAccount], tool_name_prefix: typing.Optional[str]):'
- rank: 1540
  id: google.adk.tools.google_api_tool.google_api_toolsets.SlidesToolset
  name: SlidesToolset
  file_path: google/adk/tools/google_api_tool/google_api_toolsets.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: "Auto-generated Slides toolset based on Google Slides API v1 spec exposed by Google API discovery API.\n\nArgs:\n  client_id: OAuth2 client ID for authentication.\n  client_secret: OAuth2 client secret for authentication.\n  tool_filter: Optional filter to include only specific tools or use a predicate function.\n  service_account: Optional service account for authentication.\n  tool_name_prefix: Optional prefix to add to all tool names in this toolset.\n\n[Note: Inherited members from ABC are omitted.]"
  constructor_signature: 'def __init__(self, client_id: typing.Optional[str], client_secret: typing.Optional[str], tool_filter: typing.Optional[typing.Union[google.adk.tools.base_toolset.ToolPredicate, typing.List[str]]], service_account: typing.Optional[google.adk.auth.auth_credential.ServiceAccount], tool_name_prefix: typing.Optional[str]):'
  aliases:
  - google.adk.tools.google_api_tool.SlidesToolset
  inherited_methods:
    GoogleApiToolset:
    - signature: 'def get_tools(self, readonly_context: typing.Optional[google.adk.agents.readonly_context.ReadonlyContext]) -> typing.List[google.adk.tools.google_api_tool.google_api_tool.GoogleApiTool]:'
      docstring: Get all tools in the toolset.
    - signature: 'def set_tool_filter(self, tool_filter: typing.Union[google.adk.tools.base_toolset.ToolPredicate, typing.List[str]]):'
    - signature: 'def configure_auth(self, client_id: str, client_secret: str):'
    - signature: 'def configure_sa_auth(self, service_account: google.adk.auth.auth_credential.ServiceAccount):'
    - signature: 'def close(self):'
    BaseToolset:
    - signature: 'def get_tools(self, readonly_context: typing.Optional[google.adk.agents.readonly_context.ReadonlyContext]) -> list[google.adk.tools.base_tool.BaseTool]:'
      docstring: "Return all tools in the toolset based on the provided context.\n\nArgs:\n  readonly_context (ReadonlyContext, optional): Context used to filter tools\n    available to the agent. If None, all tools in the toolset are returned.\n\nReturns:\n  list[BaseTool]: A list of tools available under the specified context."
    - signature: 'def get_tools_with_prefix(self, readonly_context: typing.Optional[google.adk.agents.readonly_context.ReadonlyContext]) -> list[google.adk.tools.base_tool.BaseTool]:'
      docstring: "Return all tools with optional prefix applied to tool names.\n\nThis method calls get_tools() and applies prefixing if tool_name_prefix is provided.\n\nArgs:\n  readonly_context (ReadonlyContext, optional): Context used to filter tools\n    available to the agent. If None, all tools in the toolset are returned.\n\nReturns:\n  list[BaseTool]: A list of tools with prefixed names if tool_name_prefix is provided."
    - signature: 'def close(self) -> None:'
      docstring: "Performs cleanup and releases resources held by the toolset.\n\nNOTE:\n  This method is invoked, for example, at the end of an agent server's\n  lifecycle or when the toolset is no longer needed. Implementations\n  should ensure that any open connections, files, or other managed\n  resources are properly released to prevent leaks."
    - signature: 'def from_config(cls: typing.Type[google.adk.tools.base_toolset.SelfToolset], config: google.adk.tools.tool_configs.ToolArgsConfig, config_abs_path: str) -> google.adk.tools.base_toolset.SelfToolset:'
      docstring: "Creates a toolset instance from a config.\n\nArgs:\n  config: The config for the tool.\n  config_abs_path: The absolute path to the config file that contains the\n    tool config.\n\nReturns:\n  The toolset instance."
    - signature: 'def process_llm_request(self, *, tool_context: google.adk.tools.tool_context.ToolContext, llm_request: google.adk.models.llm_request.LlmRequest) -> None:'
      docstring: "Processes the outgoing LLM request for this toolset. This method will be\ncalled before each tool processes the llm request.\n\nUse cases:\n- Instead of let each tool process the llm request, we can let the toolset\n  process the llm request. e.g. ComputerUseToolset can add computer use\n  tool to the llm request.\n\nArgs:\n  tool_context: The context of the tool.\n  llm_request: The outgoing LLM request, mutable this method."
  omitted_inherited_members_from:
  - ABC
- rank: 1541
  id: google.adk.tools.google_api_tool.google_api_toolsets.SlidesToolset.__init__
  name: __init__
  file_path: google/adk/tools/google_api_tool/google_api_toolsets.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def __init__(self, client_id: typing.Optional[str], client_secret: typing.Optional[str], tool_filter: typing.Optional[typing.Union[google.adk.tools.base_toolset.ToolPredicate, typing.List[str]]], service_account: typing.Optional[google.adk.auth.auth_credential.ServiceAccount], tool_name_prefix: typing.Optional[str]):'
- rank: 1542
  id: google.adk.tools.google_api_tool.google_api_toolsets.YoutubeToolset
  name: YoutubeToolset
  file_path: google/adk/tools/google_api_tool/google_api_toolsets.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: "Auto-generated YouTube toolset based on YouTube API v3 spec exposed by Google API discovery API.\n\nArgs:\n  client_id: OAuth2 client ID for authentication.\n  client_secret: OAuth2 client secret for authentication.\n  tool_filter: Optional filter to include only specific tools or use a predicate function.\n  service_account: Optional service account for authentication.\n  tool_name_prefix: Optional prefix to add to all tool names in this toolset.\n\n[Note: Inherited members from ABC are omitted.]"
  constructor_signature: 'def __init__(self, client_id: typing.Optional[str], client_secret: typing.Optional[str], tool_filter: typing.Optional[typing.Union[google.adk.tools.base_toolset.ToolPredicate, typing.List[str]]], service_account: typing.Optional[google.adk.auth.auth_credential.ServiceAccount], tool_name_prefix: typing.Optional[str]):'
  aliases:
  - google.adk.tools.google_api_tool.YoutubeToolset
  inherited_methods:
    GoogleApiToolset:
    - signature: 'def get_tools(self, readonly_context: typing.Optional[google.adk.agents.readonly_context.ReadonlyContext]) -> typing.List[google.adk.tools.google_api_tool.google_api_tool.GoogleApiTool]:'
      docstring: Get all tools in the toolset.
    - signature: 'def set_tool_filter(self, tool_filter: typing.Union[google.adk.tools.base_toolset.ToolPredicate, typing.List[str]]):'
    - signature: 'def configure_auth(self, client_id: str, client_secret: str):'
    - signature: 'def configure_sa_auth(self, service_account: google.adk.auth.auth_credential.ServiceAccount):'
    - signature: 'def close(self):'
    BaseToolset:
    - signature: 'def get_tools(self, readonly_context: typing.Optional[google.adk.agents.readonly_context.ReadonlyContext]) -> list[google.adk.tools.base_tool.BaseTool]:'
      docstring: "Return all tools in the toolset based on the provided context.\n\nArgs:\n  readonly_context (ReadonlyContext, optional): Context used to filter tools\n    available to the agent. If None, all tools in the toolset are returned.\n\nReturns:\n  list[BaseTool]: A list of tools available under the specified context."
    - signature: 'def get_tools_with_prefix(self, readonly_context: typing.Optional[google.adk.agents.readonly_context.ReadonlyContext]) -> list[google.adk.tools.base_tool.BaseTool]:'
      docstring: "Return all tools with optional prefix applied to tool names.\n\nThis method calls get_tools() and applies prefixing if tool_name_prefix is provided.\n\nArgs:\n  readonly_context (ReadonlyContext, optional): Context used to filter tools\n    available to the agent. If None, all tools in the toolset are returned.\n\nReturns:\n  list[BaseTool]: A list of tools with prefixed names if tool_name_prefix is provided."
    - signature: 'def close(self) -> None:'
      docstring: "Performs cleanup and releases resources held by the toolset.\n\nNOTE:\n  This method is invoked, for example, at the end of an agent server's\n  lifecycle or when the toolset is no longer needed. Implementations\n  should ensure that any open connections, files, or other managed\n  resources are properly released to prevent leaks."
    - signature: 'def from_config(cls: typing.Type[google.adk.tools.base_toolset.SelfToolset], config: google.adk.tools.tool_configs.ToolArgsConfig, config_abs_path: str) -> google.adk.tools.base_toolset.SelfToolset:'
      docstring: "Creates a toolset instance from a config.\n\nArgs:\n  config: The config for the tool.\n  config_abs_path: The absolute path to the config file that contains the\n    tool config.\n\nReturns:\n  The toolset instance."
    - signature: 'def process_llm_request(self, *, tool_context: google.adk.tools.tool_context.ToolContext, llm_request: google.adk.models.llm_request.LlmRequest) -> None:'
      docstring: "Processes the outgoing LLM request for this toolset. This method will be\ncalled before each tool processes the llm request.\n\nUse cases:\n- Instead of let each tool process the llm request, we can let the toolset\n  process the llm request. e.g. ComputerUseToolset can add computer use\n  tool to the llm request.\n\nArgs:\n  tool_context: The context of the tool.\n  llm_request: The outgoing LLM request, mutable this method."
  omitted_inherited_members_from:
  - ABC
- rank: 1543
  id: google.adk.tools.google_api_tool.google_api_toolsets.YoutubeToolset.__init__
  name: __init__
  file_path: google/adk/tools/google_api_tool/google_api_toolsets.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def __init__(self, client_id: typing.Optional[str], client_secret: typing.Optional[str], tool_filter: typing.Optional[typing.Union[google.adk.tools.base_toolset.ToolPredicate, typing.List[str]]], service_account: typing.Optional[google.adk.auth.auth_credential.ServiceAccount], tool_name_prefix: typing.Optional[str]):'
- rank: 1544
  id: google.adk.tools.google_api_tool.googleapi_to_openapi_converter
  name: googleapi_to_openapi_converter
  file_path: google/adk/tools/google_api_tool/googleapi_to_openapi_converter.py
  type: MODULE
  group: Orphan
  usage_score: 0
  methods:
  - signature: 'def main():'
    docstring: Command line interface for the converter.
- rank: 1545
  id: google.adk.tools.google_api_tool.googleapi_to_openapi_converter.GoogleApiToOpenApiConverter
  name: GoogleApiToOpenApiConverter
  file_path: google/adk/tools/google_api_tool/googleapi_to_openapi_converter.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: Converts Google API Discovery documents to OpenAPI v3 format.
  constructor_signature: 'def __init__(self, api_name: str, api_version: str):'
  methods:
  - signature: 'def fetch_google_api_spec(self) -> None:'
    docstring: Fetches the Google API specification using discovery service.
  - signature: 'def convert(self) -> typing.Dict[str, typing.Any]:'
    docstring: "Convert the Google API spec to OpenAPI v3 format.\n\nReturns:\n    Dict containing the converted OpenAPI v3 specification"
  - signature: 'def save_openapi_spec(self, output_path: str) -> None:'
    docstring: "Save the OpenAPI specification to a file.\n\nArgs:\n    output_path: Path where the OpenAPI spec should be saved"
- rank: 1546
  id: google.adk.tools.google_api_tool.googleapi_to_openapi_converter.GoogleApiToOpenApiConverter.__init__
  name: __init__
  file_path: google/adk/tools/google_api_tool/googleapi_to_openapi_converter.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Initialize the converter with the API name and version.\n\nArgs:\n    api_name: The name of the Google API (e.g., \"calendar\")\n    api_version: The version of the API (e.g., \"v3\")"
  signature: 'def __init__(self, api_name: str, api_version: str):'
- rank: 1547
  id: google.adk.tools.google_api_tool.googleapi_to_openapi_converter.GoogleApiToOpenApiConverter.convert
  name: convert
  file_path: google/adk/tools/google_api_tool/googleapi_to_openapi_converter.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Convert the Google API spec to OpenAPI v3 format.\n\nReturns:\n    Dict containing the converted OpenAPI v3 specification"
  signature: 'def convert(self) -> typing.Dict[str, typing.Any]:'
- rank: 1548
  id: google.adk.tools.google_api_tool.googleapi_to_openapi_converter.GoogleApiToOpenApiConverter.fetch_google_api_spec
  name: fetch_google_api_spec
  file_path: google/adk/tools/google_api_tool/googleapi_to_openapi_converter.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: Fetches the Google API specification using discovery service.
  signature: 'def fetch_google_api_spec(self) -> None:'
- rank: 1549
  id: google.adk.tools.google_api_tool.googleapi_to_openapi_converter.GoogleApiToOpenApiConverter.save_openapi_spec
  name: save_openapi_spec
  file_path: google/adk/tools/google_api_tool/googleapi_to_openapi_converter.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Save the OpenAPI specification to a file.\n\nArgs:\n    output_path: Path where the OpenAPI spec should be saved"
  signature: 'def save_openapi_spec(self, output_path: str) -> None:'
- rank: 1550
  id: google.adk.tools.google_api_tool.googleapi_to_openapi_converter.main
  name: main
  file_path: google/adk/tools/google_api_tool/googleapi_to_openapi_converter.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: Command line interface for the converter.
  signature: 'def main():'
- rank: 1551
  id: google.adk.tools.google_maps_grounding_tool
  name: google_maps_grounding_tool
  file_path: google/adk/tools/google_maps_grounding_tool.py
  type: MODULE
  group: Orphan
  usage_score: 0
- rank: 1552
  id: google.adk.tools.google_maps_grounding_tool.GoogleMapsGroundingTool
  name: GoogleMapsGroundingTool
  file_path: google/adk/tools/google_maps_grounding_tool.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'A built-in tool that is automatically invoked by Gemini 2 models to ground query results with Google Maps.


    This tool operates internally within the model and does not require or perform

    local code execution.


    Only available for use with the VertexAI Gemini API (e.g.

    GOOGLE_GENAI_USE_VERTEXAI=TRUE)


    [Note: Inherited members from ABC are omitted.]'
  constructor_signature: 'def __init__(self):'
  methods:
  - signature: 'def process_llm_request(self, *, tool_context: google.adk.tools.tool_context.ToolContext, llm_request: google.adk.models.LlmRequest) -> None:'
  inherited_methods:
    BaseTool:
    - signature: 'def run_async(self, *, args: dict[str, typing.Any], tool_context: google.adk.tools.tool_context.ToolContext) -> typing.Any:'
      docstring: "Runs the tool with the given arguments and context.\n\nNOTE:\n  - Required if this tool needs to run at the client side.\n  - Otherwise, can be skipped, e.g. for a built-in GoogleSearch tool for\n    Gemini.\n\nArgs:\n  args: The LLM-filled arguments.\n  tool_context: The context of the tool.\n\nReturns:\n  The result of running the tool."
    - signature: 'def process_llm_request(self, *, tool_context: google.adk.tools.tool_context.ToolContext, llm_request: google.adk.models.llm_request.LlmRequest) -> None:'
      docstring: "Processes the outgoing LLM request for this tool.\n\nUse cases:\n- Most common use case is adding this tool to the LLM request.\n- Some tools may just preprocess the LLM request before it's sent out.\n\nArgs:\n  tool_context: The context of the tool.\n  llm_request: The outgoing LLM request, mutable this method."
    - signature: 'def from_config(cls: typing.Type[google.adk.tools.base_tool.SelfTool], config: google.adk.tools.tool_configs.ToolArgsConfig, config_abs_path: str) -> google.adk.tools.base_tool.SelfTool:'
      docstring: "Creates a tool instance from a config.\n\nThis default implementation uses inspect to automatically map config values\nto constructor arguments based on their type hints. Subclasses should\noverride this method for custom initialization logic.\n\nArgs:\n  config: The config for the tool.\n  config_abs_path: The absolute path to the config file that contains the\n    tool config.\n\nReturns:\n  The tool instance."
  inherited_properties:
    BaseTool:
    - signature: 'name: str'
      docstring: The name of the tool.
    - signature: 'description: str'
      docstring: The description of the tool.
    - signature: 'is_long_running: bool'
      docstring: 'Whether the tool is a long running operation, which typically returns a

        resource id first and finishes the operation later.'
    - signature: 'custom_metadata: typing.Optional[dict[str, typing.Any]]'
      docstring: 'The custom metadata of the BaseTool.


        An optional key-value pair for storing and retrieving tool-specific metadata,

        such as tool manifests, etc.


        NOTE: the entire dict must be JSON serializable.'
  omitted_inherited_members_from:
  - ABC
- rank: 1553
  id: google.adk.tools.google_maps_grounding_tool.GoogleMapsGroundingTool.process_llm_request
  name: process_llm_request
  file_path: google/adk/tools/google_maps_grounding_tool.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def process_llm_request(self, *, tool_context: google.adk.tools.tool_context.ToolContext, llm_request: google.adk.models.LlmRequest) -> None:'
- rank: 1554
  id: google.adk.tools.google_search_agent_tool
  name: google_search_agent_tool
  file_path: google/adk/tools/google_search_agent_tool.py
  type: MODULE
  group: Orphan
  usage_score: 0
  methods:
  - signature: 'def create_google_search_agent(model: typing.Union[str, google.adk.models.base_llm.BaseLlm]) -> google.adk.agents.llm_agent.LlmAgent:'
    docstring: Create a sub-agent that only uses google_search tool.
- rank: 1555
  id: google.adk.tools.google_search_agent_tool.GoogleSearchAgentTool
  name: GoogleSearchAgentTool
  file_path: google/adk/tools/google_search_agent_tool.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: "A tool that wraps a sub-agent that only uses google_search tool.\n\nThis is a workaround to support using google_search tool with other tools.\nTODO(b/448114567): Remove once the workaround is no longer needed.\n\nAttributes:\n  model: The model to use for the sub-agent.\n\n[Note: Inherited members from ABC are omitted.]"
  constructor_signature: 'def __init__(self, agent: google.adk.agents.llm_agent.LlmAgent):'
  methods:
  - signature: 'def run_async(self, *, args: dict[str, typing.Any], tool_context: google.adk.tools.tool_context.ToolContext) -> typing.Any:'
  inherited_methods:
    AgentTool:
    - signature: 'def populate_name(cls, data: typing.Any) -> typing.Any:'
    - signature: 'def run_async(self, *, args: dict[str, typing.Any], tool_context: google.adk.tools.tool_context.ToolContext) -> typing.Any:'
    - signature: 'def from_config(cls, config: google.adk.tools.tool_configs.ToolArgsConfig, config_abs_path: str) -> google.adk.tools.agent_tool.AgentTool:'
    BaseTool:
    - signature: 'def run_async(self, *, args: dict[str, typing.Any], tool_context: google.adk.tools.tool_context.ToolContext) -> typing.Any:'
      docstring: "Runs the tool with the given arguments and context.\n\nNOTE:\n  - Required if this tool needs to run at the client side.\n  - Otherwise, can be skipped, e.g. for a built-in GoogleSearch tool for\n    Gemini.\n\nArgs:\n  args: The LLM-filled arguments.\n  tool_context: The context of the tool.\n\nReturns:\n  The result of running the tool."
    - signature: 'def process_llm_request(self, *, tool_context: google.adk.tools.tool_context.ToolContext, llm_request: google.adk.models.llm_request.LlmRequest) -> None:'
      docstring: "Processes the outgoing LLM request for this tool.\n\nUse cases:\n- Most common use case is adding this tool to the LLM request.\n- Some tools may just preprocess the LLM request before it's sent out.\n\nArgs:\n  tool_context: The context of the tool.\n  llm_request: The outgoing LLM request, mutable this method."
    - signature: 'def from_config(cls: typing.Type[google.adk.tools.base_tool.SelfTool], config: google.adk.tools.tool_configs.ToolArgsConfig, config_abs_path: str) -> google.adk.tools.base_tool.SelfTool:'
      docstring: "Creates a tool instance from a config.\n\nThis default implementation uses inspect to automatically map config values\nto constructor arguments based on their type hints. Subclasses should\noverride this method for custom initialization logic.\n\nArgs:\n  config: The config for the tool.\n  config_abs_path: The absolute path to the config file that contains the\n    tool config.\n\nReturns:\n  The tool instance."
  inherited_properties:
    BaseTool:
    - signature: 'name: str'
      docstring: The name of the tool.
    - signature: 'description: str'
      docstring: The description of the tool.
    - signature: 'is_long_running: bool'
      docstring: 'Whether the tool is a long running operation, which typically returns a

        resource id first and finishes the operation later.'
    - signature: 'custom_metadata: typing.Optional[dict[str, typing.Any]]'
      docstring: 'The custom metadata of the BaseTool.


        An optional key-value pair for storing and retrieving tool-specific metadata,

        such as tool manifests, etc.


        NOTE: the entire dict must be JSON serializable.'
  omitted_inherited_members_from:
  - ABC
- rank: 1556
  id: google.adk.tools.google_search_agent_tool.GoogleSearchAgentTool.run_async
  name: run_async
  file_path: google/adk/tools/google_search_agent_tool.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def run_async(self, *, args: dict[str, typing.Any], tool_context: google.adk.tools.tool_context.ToolContext) -> typing.Any:'
- rank: 1557
  id: google.adk.tools.google_search_agent_tool.create_google_search_agent
  name: create_google_search_agent
  file_path: google/adk/tools/google_search_agent_tool.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: Create a sub-agent that only uses google_search tool.
  signature: 'def create_google_search_agent(model: typing.Union[str, google.adk.models.base_llm.BaseLlm]) -> google.adk.agents.llm_agent.LlmAgent:'
- rank: 1558
  id: google.adk.tools.google_search_tool
  name: google_search_tool
  file_path: google/adk/tools/google_search_tool.py
  type: MODULE
  group: Orphan
  usage_score: 0
- rank: 1559
  id: google.adk.tools.google_search_tool.GoogleSearchTool.__init__
  name: __init__
  file_path: google/adk/tools/google_search_tool.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Initializes the Google search tool.\n\nArgs:\n  bypass_multi_tools_limit: Whether to bypass the multi tools limitation,\n    so that the tool can be used with other tools in the same agent."
  signature: 'def __init__(self, *, bypass_multi_tools_limit: bool=False):'
- rank: 1560
  id: google.adk.tools.google_search_tool.GoogleSearchTool.process_llm_request
  name: process_llm_request
  file_path: google/adk/tools/google_search_tool.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def process_llm_request(self, *, tool_context: google.adk.tools.tool_context.ToolContext, llm_request: google.adk.models.LlmRequest) -> None:'
- rank: 1561
  id: google.adk.tools.google_tool
  name: google_tool
  file_path: google/adk/tools/google_tool.py
  type: MODULE
  group: Orphan
  usage_score: 0
- rank: 1562
  id: google.adk.tools.google_tool.GoogleTool
  name: GoogleTool
  file_path: google/adk/tools/google_tool.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'GoogleTool class for tools that call Google APIs.


    This class is for developers to handcraft customized Google API tools rather

    than auto generate Google API tools based on API specs.


    This class handles all the OAuth complexity, credential management,

    and common Google API patterns so subclasses can focus on their

    specific functionality.


    [Note: Inherited members from ABC are omitted.]'
  constructor_signature: 'def __init__(self, func: typing.Callable[Ellipsis, typing.Any], *, credentials_config: typing.Optional[google.adk.tools._google_credentials.BaseGoogleCredentialsConfig]=None, tool_settings: typing.Optional[pydantic.BaseModel]=None):'
  methods:
  - signature: 'def run_async(self, *, args: dict[str, typing.Any], tool_context: google.adk.tools.tool_context.ToolContext) -> typing.Any:'
    docstring: 'Main entry point for tool execution with credential handling.


      This method handles all the OAuth complexity and then delegates

      to the subclass''s run_async_with_credential method.'
  inherited_methods:
    FunctionTool:
    - signature: 'def run_async(self, *, args: dict[str, typing.Any], tool_context: google.adk.tools.tool_context.ToolContext) -> typing.Any:'
    BaseTool:
    - signature: 'def run_async(self, *, args: dict[str, typing.Any], tool_context: google.adk.tools.tool_context.ToolContext) -> typing.Any:'
      docstring: "Runs the tool with the given arguments and context.\n\nNOTE:\n  - Required if this tool needs to run at the client side.\n  - Otherwise, can be skipped, e.g. for a built-in GoogleSearch tool for\n    Gemini.\n\nArgs:\n  args: The LLM-filled arguments.\n  tool_context: The context of the tool.\n\nReturns:\n  The result of running the tool."
    - signature: 'def process_llm_request(self, *, tool_context: google.adk.tools.tool_context.ToolContext, llm_request: google.adk.models.llm_request.LlmRequest) -> None:'
      docstring: "Processes the outgoing LLM request for this tool.\n\nUse cases:\n- Most common use case is adding this tool to the LLM request.\n- Some tools may just preprocess the LLM request before it's sent out.\n\nArgs:\n  tool_context: The context of the tool.\n  llm_request: The outgoing LLM request, mutable this method."
    - signature: 'def from_config(cls: typing.Type[google.adk.tools.base_tool.SelfTool], config: google.adk.tools.tool_configs.ToolArgsConfig, config_abs_path: str) -> google.adk.tools.base_tool.SelfTool:'
      docstring: "Creates a tool instance from a config.\n\nThis default implementation uses inspect to automatically map config values\nto constructor arguments based on their type hints. Subclasses should\noverride this method for custom initialization logic.\n\nArgs:\n  config: The config for the tool.\n  config_abs_path: The absolute path to the config file that contains the\n    tool config.\n\nReturns:\n  The tool instance."
  inherited_properties:
    BaseTool:
    - signature: 'name: str'
      docstring: The name of the tool.
    - signature: 'description: str'
      docstring: The description of the tool.
    - signature: 'is_long_running: bool'
      docstring: 'Whether the tool is a long running operation, which typically returns a

        resource id first and finishes the operation later.'
    - signature: 'custom_metadata: typing.Optional[dict[str, typing.Any]]'
      docstring: 'The custom metadata of the BaseTool.


        An optional key-value pair for storing and retrieving tool-specific metadata,

        such as tool manifests, etc.


        NOTE: the entire dict must be JSON serializable.'
  omitted_inherited_members_from:
  - ABC
- rank: 1563
  id: google.adk.tools.google_tool.GoogleTool.__init__
  name: __init__
  file_path: google/adk/tools/google_tool.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Initialize the Google API tool.\n\nArgs:\n    func: callable that implements the tool's logic, can accept one\n      'credential\" parameter\n    credentials_config: credentials config used to call Google API. If None,\n      then we don't handle the auth logic\n    tool_settings: Tool-specific settings. This settings should be provided\n      by each toolset that uses this class to create customized tools."
  signature: 'def __init__(self, func: typing.Callable[Ellipsis, typing.Any], *, credentials_config: typing.Optional[google.adk.tools._google_credentials.BaseGoogleCredentialsConfig]=None, tool_settings: typing.Optional[pydantic.BaseModel]=None):'
- rank: 1564
  id: google.adk.tools.google_tool.GoogleTool.run_async
  name: run_async
  file_path: google/adk/tools/google_tool.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: 'Main entry point for tool execution with credential handling.


    This method handles all the OAuth complexity and then delegates

    to the subclass''s run_async_with_credential method.'
  signature: 'def run_async(self, *, args: dict[str, typing.Any], tool_context: google.adk.tools.tool_context.ToolContext) -> typing.Any:'
- rank: 1565
  id: google.adk.tools.langchain_tool
  name: langchain_tool
  file_path: google/adk/tools/langchain_tool.py
  type: MODULE
  group: Orphan
  usage_score: 0
- rank: 1566
  id: google.adk.tools.langchain_tool.LangchainTool.__init__
  name: __init__
  file_path: google/adk/tools/langchain_tool.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def __init__(self, tool: typing.Union[langchain_core.tools.BaseTool, object], name: typing.Optional[str], description: typing.Optional[str]):'
- rank: 1567
  id: google.adk.tools.langchain_tool.LangchainTool.from_config
  name: from_config
  file_path: google/adk/tools/langchain_tool.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def from_config(cls: type[google.adk.tools.langchain_tool.LangchainTool], config: google.adk.tools.tool_configs.ToolArgsConfig, config_abs_path: str) -> google.adk.tools.langchain_tool.LangchainTool:'
- rank: 1568
  id: google.adk.tools.langchain_tool.LangchainToolConfig
  name: LangchainToolConfig
  file_path: google/adk/tools/langchain_tool.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: '[Note: Inherited members from pydantic.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, tool: str, name: str = '''', description: str = ''''):'
  properties:
  - signature: 'tool: str'
    docstring: The fully qualified path of the Langchain tool instance.
  - signature: 'name: str'
    docstring: The name of the tool.
  - signature: 'description: str'
    docstring: The description of the tool.
  inherited_properties:
    BaseToolConfig:
    - signature: 'model_config: pydantic.ConfigDict'
    BaseModel:
    - signature: 'model_config: pydantic.ConfigDict'
  omitted_inherited_members_from:
  - pydantic.BaseModel
- rank: 1569
  id: google.adk.tools.load_artifacts_tool
  name: load_artifacts_tool
  file_path: google/adk/tools/load_artifacts_tool.py
  type: MODULE
  group: Orphan
  usage_score: 0
- rank: 1570
  id: google.adk.tools.load_artifacts_tool.LoadArtifactsTool
  name: LoadArtifactsTool
  file_path: google/adk/tools/load_artifacts_tool.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'A tool that loads the artifacts and adds them to the session.


    [Note: Inherited members from ABC are omitted.]'
  constructor_signature: 'def __init__(self):'
  methods:
  - signature: 'def run_async(self, *, args: dict[str, typing.Any], tool_context: google.adk.tools.tool_context.ToolContext) -> typing.Any:'
  - signature: 'def process_llm_request(self, *, tool_context: google.adk.tools.tool_context.ToolContext, llm_request: google.adk.models.llm_request.LlmRequest) -> None:'
  inherited_methods:
    BaseTool:
    - signature: 'def run_async(self, *, args: dict[str, typing.Any], tool_context: google.adk.tools.tool_context.ToolContext) -> typing.Any:'
      docstring: "Runs the tool with the given arguments and context.\n\nNOTE:\n  - Required if this tool needs to run at the client side.\n  - Otherwise, can be skipped, e.g. for a built-in GoogleSearch tool for\n    Gemini.\n\nArgs:\n  args: The LLM-filled arguments.\n  tool_context: The context of the tool.\n\nReturns:\n  The result of running the tool."
    - signature: 'def process_llm_request(self, *, tool_context: google.adk.tools.tool_context.ToolContext, llm_request: google.adk.models.llm_request.LlmRequest) -> None:'
      docstring: "Processes the outgoing LLM request for this tool.\n\nUse cases:\n- Most common use case is adding this tool to the LLM request.\n- Some tools may just preprocess the LLM request before it's sent out.\n\nArgs:\n  tool_context: The context of the tool.\n  llm_request: The outgoing LLM request, mutable this method."
    - signature: 'def from_config(cls: typing.Type[google.adk.tools.base_tool.SelfTool], config: google.adk.tools.tool_configs.ToolArgsConfig, config_abs_path: str) -> google.adk.tools.base_tool.SelfTool:'
      docstring: "Creates a tool instance from a config.\n\nThis default implementation uses inspect to automatically map config values\nto constructor arguments based on their type hints. Subclasses should\noverride this method for custom initialization logic.\n\nArgs:\n  config: The config for the tool.\n  config_abs_path: The absolute path to the config file that contains the\n    tool config.\n\nReturns:\n  The tool instance."
  inherited_properties:
    BaseTool:
    - signature: 'name: str'
      docstring: The name of the tool.
    - signature: 'description: str'
      docstring: The description of the tool.
    - signature: 'is_long_running: bool'
      docstring: 'Whether the tool is a long running operation, which typically returns a

        resource id first and finishes the operation later.'
    - signature: 'custom_metadata: typing.Optional[dict[str, typing.Any]]'
      docstring: 'The custom metadata of the BaseTool.


        An optional key-value pair for storing and retrieving tool-specific metadata,

        such as tool manifests, etc.


        NOTE: the entire dict must be JSON serializable.'
  omitted_inherited_members_from:
  - ABC
- rank: 1571
  id: google.adk.tools.load_artifacts_tool.LoadArtifactsTool.__init__
  name: __init__
  file_path: google/adk/tools/load_artifacts_tool.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def __init__(self):'
- rank: 1572
  id: google.adk.tools.load_artifacts_tool.LoadArtifactsTool.process_llm_request
  name: process_llm_request
  file_path: google/adk/tools/load_artifacts_tool.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def process_llm_request(self, *, tool_context: google.adk.tools.tool_context.ToolContext, llm_request: google.adk.models.llm_request.LlmRequest) -> None:'
- rank: 1573
  id: google.adk.tools.load_artifacts_tool.LoadArtifactsTool.run_async
  name: run_async
  file_path: google/adk/tools/load_artifacts_tool.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def run_async(self, *, args: dict[str, typing.Any], tool_context: google.adk.tools.tool_context.ToolContext) -> typing.Any:'
- rank: 1574
  id: google.adk.tools.load_memory_tool
  name: load_memory_tool
  file_path: google/adk/tools/load_memory_tool.py
  type: MODULE
  group: Orphan
  usage_score: 0
  methods:
  - signature: 'def load_memory(query: str, tool_context: google.adk.tools.tool_context.ToolContext) -> google.adk.tools.load_memory_tool.LoadMemoryResponse:'
    docstring: "Loads the memory for the current user.\n\nArgs:\n  query: The query to load the memory for.\n\nReturns:\n  A list of memory results."
- rank: 1575
  id: google.adk.tools.load_memory_tool.LoadMemoryResponse
  name: LoadMemoryResponse
  file_path: google/adk/tools/load_memory_tool.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: '[Note: Inherited members from pydantic.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, memories: list[google.adk.memory.memory_entry.MemoryEntry] = list()):'
  properties:
  - signature: 'memories: list[google.adk.memory.memory_entry.MemoryEntry]'
  inherited_properties:
    BaseModel:
    - signature: 'model_config: pydantic.ConfigDict'
  omitted_inherited_members_from:
  - pydantic.BaseModel
- rank: 1576
  id: google.adk.tools.load_memory_tool.LoadMemoryTool
  name: LoadMemoryTool
  file_path: google/adk/tools/load_memory_tool.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'A tool that loads the memory for the current user.


    NOTE: Currently this tool only uses text part from the memory.


    [Note: Inherited members from ABC are omitted.]'
  constructor_signature: 'def __init__(self):'
  methods:
  - signature: 'def process_llm_request(self, *, tool_context: google.adk.tools.tool_context.ToolContext, llm_request: google.adk.models.LlmRequest) -> None:'
  inherited_methods:
    FunctionTool:
    - signature: 'def run_async(self, *, args: dict[str, typing.Any], tool_context: google.adk.tools.tool_context.ToolContext) -> typing.Any:'
    BaseTool:
    - signature: 'def run_async(self, *, args: dict[str, typing.Any], tool_context: google.adk.tools.tool_context.ToolContext) -> typing.Any:'
      docstring: "Runs the tool with the given arguments and context.\n\nNOTE:\n  - Required if this tool needs to run at the client side.\n  - Otherwise, can be skipped, e.g. for a built-in GoogleSearch tool for\n    Gemini.\n\nArgs:\n  args: The LLM-filled arguments.\n  tool_context: The context of the tool.\n\nReturns:\n  The result of running the tool."
    - signature: 'def process_llm_request(self, *, tool_context: google.adk.tools.tool_context.ToolContext, llm_request: google.adk.models.llm_request.LlmRequest) -> None:'
      docstring: "Processes the outgoing LLM request for this tool.\n\nUse cases:\n- Most common use case is adding this tool to the LLM request.\n- Some tools may just preprocess the LLM request before it's sent out.\n\nArgs:\n  tool_context: The context of the tool.\n  llm_request: The outgoing LLM request, mutable this method."
    - signature: 'def from_config(cls: typing.Type[google.adk.tools.base_tool.SelfTool], config: google.adk.tools.tool_configs.ToolArgsConfig, config_abs_path: str) -> google.adk.tools.base_tool.SelfTool:'
      docstring: "Creates a tool instance from a config.\n\nThis default implementation uses inspect to automatically map config values\nto constructor arguments based on their type hints. Subclasses should\noverride this method for custom initialization logic.\n\nArgs:\n  config: The config for the tool.\n  config_abs_path: The absolute path to the config file that contains the\n    tool config.\n\nReturns:\n  The tool instance."
  inherited_properties:
    BaseTool:
    - signature: 'name: str'
      docstring: The name of the tool.
    - signature: 'description: str'
      docstring: The description of the tool.
    - signature: 'is_long_running: bool'
      docstring: 'Whether the tool is a long running operation, which typically returns a

        resource id first and finishes the operation later.'
    - signature: 'custom_metadata: typing.Optional[dict[str, typing.Any]]'
      docstring: 'The custom metadata of the BaseTool.


        An optional key-value pair for storing and retrieving tool-specific metadata,

        such as tool manifests, etc.


        NOTE: the entire dict must be JSON serializable.'
  omitted_inherited_members_from:
  - ABC
- rank: 1577
  id: google.adk.tools.load_memory_tool.LoadMemoryTool.process_llm_request
  name: process_llm_request
  file_path: google/adk/tools/load_memory_tool.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def process_llm_request(self, *, tool_context: google.adk.tools.tool_context.ToolContext, llm_request: google.adk.models.LlmRequest) -> None:'
- rank: 1578
  id: google.adk.tools.load_memory_tool.load_memory
  name: load_memory
  file_path: google/adk/tools/load_memory_tool.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Loads the memory for the current user.\n\nArgs:\n  query: The query to load the memory for.\n\nReturns:\n  A list of memory results."
  signature: 'def load_memory(query: str, tool_context: google.adk.tools.tool_context.ToolContext) -> google.adk.tools.load_memory_tool.LoadMemoryResponse:'
- rank: 1579
  id: google.adk.tools.load_web_page
  name: load_web_page
  file_path: google/adk/tools/load_web_page.py
  type: MODULE
  group: Orphan
  usage_score: 0
  docstring: Tool for web browse.
  methods:
  - signature: 'def load_web_page(url: str) -> str:'
    docstring: "Fetches the content in the url and returns the text in it.\n\nArgs:\n    url (str): The url to browse.\n\nReturns:\n    str: The text content of the url."
- rank: 1580
  id: google.adk.tools.load_web_page.load_web_page
  name: load_web_page
  file_path: google/adk/tools/load_web_page.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Fetches the content in the url and returns the text in it.\n\nArgs:\n    url (str): The url to browse.\n\nReturns:\n    str: The text content of the url."
  signature: 'def load_web_page(url: str) -> str:'
- rank: 1581
  id: google.adk.tools.long_running_tool
  name: long_running_tool
  file_path: google/adk/tools/long_running_tool.py
  type: MODULE
  group: Orphan
  usage_score: 0
- rank: 1582
  id: google.adk.tools.mcp_tool
  name: mcp_tool
  file_path: google/adk/tools/mcp_tool/__init__.py
  type: MODULE
  group: Orphan
  usage_score: 0
- rank: 1583
  id: google.adk.tools.mcp_tool.conversion_utils
  name: conversion_utils
  file_path: google/adk/tools/mcp_tool/conversion_utils.py
  type: MODULE
  group: Orphan
  usage_score: 0
  methods:
  - signature: 'def adk_to_mcp_tool_type(tool: google.adk.tools.base_tool.BaseTool) -> mcp.types.Tool:'
    docstring: "Convert a Tool in ADK into MCP tool type.\n\nThis function transforms an ADK tool definition into its equivalent\nrepresentation in the MCP (Model Context Protocol) system.\n\nArgs:\n    tool: The ADK tool to convert. It should be an instance of a class derived\n      from `BaseTool`.\n\nReturns:\n    An object of MCP Tool type, representing the converted tool.\n\nExamples:\n    # Assuming 'my_tool' is an instance of a BaseTool derived class\n    mcp_tool = adk_to_mcp_tool_type(my_tool)\n    print(mcp_tool)"
  - signature: 'def gemini_to_json_schema(gemini_schema: google.genai.types.Schema) -> typing.Dict[str, typing.Any]:'
    docstring: "Converts a Gemini Schema object into a JSON Schema dictionary.\n\nArgs:\n    gemini_schema: An instance of the Gemini Schema class.\n\nReturns:\n    A dictionary representing the equivalent JSON Schema.\n\nRaises:\n    TypeError: If the input is not an instance of the expected Schema class.\n    ValueError: If an invalid Gemini Type enum value is encountered."
- rank: 1584
  id: google.adk.tools.mcp_tool.conversion_utils.adk_to_mcp_tool_type
  name: adk_to_mcp_tool_type
  file_path: google/adk/tools/mcp_tool/conversion_utils.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Convert a Tool in ADK into MCP tool type.\n\nThis function transforms an ADK tool definition into its equivalent\nrepresentation in the MCP (Model Context Protocol) system.\n\nArgs:\n    tool: The ADK tool to convert. It should be an instance of a class derived\n      from `BaseTool`.\n\nReturns:\n    An object of MCP Tool type, representing the converted tool.\n\nExamples:\n    # Assuming 'my_tool' is an instance of a BaseTool derived class\n    mcp_tool = adk_to_mcp_tool_type(my_tool)\n    print(mcp_tool)"
  signature: 'def adk_to_mcp_tool_type(tool: google.adk.tools.base_tool.BaseTool) -> mcp.types.Tool:'
- rank: 1585
  id: google.adk.tools.mcp_tool.conversion_utils.gemini_to_json_schema
  name: gemini_to_json_schema
  file_path: google/adk/tools/mcp_tool/conversion_utils.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Converts a Gemini Schema object into a JSON Schema dictionary.\n\nArgs:\n    gemini_schema: An instance of the Gemini Schema class.\n\nReturns:\n    A dictionary representing the equivalent JSON Schema.\n\nRaises:\n    TypeError: If the input is not an instance of the expected Schema class.\n    ValueError: If an invalid Gemini Type enum value is encountered."
  signature: 'def gemini_to_json_schema(gemini_schema: google.genai.types.Schema) -> typing.Dict[str, typing.Any]:'
- rank: 1586
  id: google.adk.tools.mcp_tool.mcp_session_manager
  name: mcp_session_manager
  file_path: google/adk/tools/mcp_tool/mcp_session_manager.py
  type: MODULE
  group: Orphan
  usage_score: 0
  methods:
  - signature: 'def retry_on_errors(func):'
    docstring: "Decorator to automatically retry action when MCP session errors occur.\n\nWhen MCP session errors occur, the decorator will automatically retry the\naction once. The create_session method will handle creating a new session\nif the old one was disconnected.\n\nArgs:\n    func: The function to decorate.\n\nReturns:\n    The decorated function."
  - signature: 'def wrapper(self):'
- rank: 1587
  id: google.adk.tools.mcp_tool.mcp_session_manager.MCPSessionManager
  name: MCPSessionManager
  file_path: google/adk/tools/mcp_tool/mcp_session_manager.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Manages MCP client sessions.


    This class provides methods for creating and initializing MCP client sessions,

    handling different connection parameters (Stdio and SSE) and supporting

    session pooling based on authentication headers.'
  constructor_signature: 'def __init__(self, connection_params: typing.Union[mcp.StdioServerParameters, google.adk.tools.mcp_tool.mcp_session_manager.StdioConnectionParams, google.adk.tools.mcp_tool.mcp_session_manager.SseConnectionParams, google.adk.tools.mcp_tool.mcp_session_manager.StreamableHTTPConnectionParams], errlog: typing.TextIO):'
  methods:
  - signature: 'def create_session(self, headers: typing.Optional[typing.Dict[str, str]]) -> mcp.ClientSession:'
    docstring: "Creates and initializes an MCP client session.\n\nThis method will check if an existing session for the given headers\nis still connected. If it's disconnected, it will be cleaned up and\na new session will be created.\n\nArgs:\n    headers: Optional headers to include in the session. These will be\n            merged with any existing connection headers. Only applicable\n            for SSE and StreamableHTTP connections.\n\nReturns:\n    ClientSession: The initialized MCP client session."
  - signature: 'def close(self):'
    docstring: Closes all sessions and cleans up resources.
- rank: 1588
  id: google.adk.tools.mcp_tool.mcp_session_manager.MCPSessionManager.__init__
  name: __init__
  file_path: google/adk/tools/mcp_tool/mcp_session_manager.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Initializes the MCP session manager.\n\nArgs:\n    connection_params: Parameters for the MCP connection (Stdio, SSE or\n      Streamable HTTP). Stdio by default also has a 5s read timeout as other\n      parameters but it's not configurable for now.\n    errlog: (Optional) TextIO stream for error logging. Use only for\n      initializing a local stdio MCP session."
  signature: 'def __init__(self, connection_params: typing.Union[mcp.StdioServerParameters, google.adk.tools.mcp_tool.mcp_session_manager.StdioConnectionParams, google.adk.tools.mcp_tool.mcp_session_manager.SseConnectionParams, google.adk.tools.mcp_tool.mcp_session_manager.StreamableHTTPConnectionParams], errlog: typing.TextIO):'
- rank: 1589
  id: google.adk.tools.mcp_tool.mcp_session_manager.MCPSessionManager.close
  name: close
  file_path: google/adk/tools/mcp_tool/mcp_session_manager.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: Closes all sessions and cleans up resources.
  signature: 'def close(self):'
- rank: 1590
  id: google.adk.tools.mcp_tool.mcp_session_manager.MCPSessionManager.create_session
  name: create_session
  file_path: google/adk/tools/mcp_tool/mcp_session_manager.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Creates and initializes an MCP client session.\n\nThis method will check if an existing session for the given headers\nis still connected. If it's disconnected, it will be cleaned up and\na new session will be created.\n\nArgs:\n    headers: Optional headers to include in the session. These will be\n            merged with any existing connection headers. Only applicable\n            for SSE and StreamableHTTP connections.\n\nReturns:\n    ClientSession: The initialized MCP client session."
  signature: 'def create_session(self, headers: typing.Optional[typing.Dict[str, str]]) -> mcp.ClientSession:'
- rank: 1591
  id: google.adk.tools.mcp_tool.mcp_session_manager.retry_on_errors
  name: retry_on_errors
  file_path: google/adk/tools/mcp_tool/mcp_session_manager.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Decorator to automatically retry action when MCP session errors occur.\n\nWhen MCP session errors occur, the decorator will automatically retry the\naction once. The create_session method will handle creating a new session\nif the old one was disconnected.\n\nArgs:\n    func: The function to decorate.\n\nReturns:\n    The decorated function."
  signature: 'def retry_on_errors(func):'
- rank: 1592
  id: google.adk.tools.mcp_tool.mcp_session_manager.wrapper
  name: wrapper
  file_path: google/adk/tools/mcp_tool/mcp_session_manager.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def wrapper(self):'
- rank: 1593
  id: google.adk.tools.mcp_tool.mcp_tool
  name: mcp_tool
  file_path: google/adk/tools/mcp_tool/mcp_tool.py
  type: MODULE
  group: Orphan
  usage_score: 0
- rank: 1594
  id: google.adk.tools.mcp_tool.mcp_tool.MCPTool
  name: MCPTool
  file_path: google/adk/tools/mcp_tool/mcp_tool.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Deprecated name, use `McpTool` instead.


    [Note: Inherited members from ABC are omitted.]'
  constructor_signature: 'def __init__(self):'
  inherited_methods:
    McpTool:
    - signature: 'def raw_mcp_tool(self) -> mcp.types.Tool:'
      docstring: Returns the raw MCP tool.
    - signature: 'def run_async(self, *, args: dict[str, typing.Any], tool_context: google.adk.tools.tool_context.ToolContext) -> typing.Any:'
    - signature: 'def _run_async_impl(self, *, args, tool_context: google.adk.tools.tool_context.ToolContext, credential: google.adk.auth.auth_credential.AuthCredential) -> typing.Dict[str, typing.Any]:'
      docstring: "Runs the tool asynchronously.\n\nArgs:\n    args: The arguments as a dict to pass to the tool.\n    tool_context: The tool context of the current invocation.\n\nReturns:\n    Any: The response from the tool."
    BaseAuthenticatedTool:
    - signature: 'def run_async(self, *, args: dict[str, typing.Any], tool_context: google.adk.tools.tool_context.ToolContext) -> typing.Any:'
    - signature: 'def _run_async_impl(self, *, args: dict[str, typing.Any], tool_context: google.adk.tools.tool_context.ToolContext, credential: google.adk.auth.auth_credential.AuthCredential) -> typing.Any:'
    BaseTool:
    - signature: 'def run_async(self, *, args: dict[str, typing.Any], tool_context: google.adk.tools.tool_context.ToolContext) -> typing.Any:'
      docstring: "Runs the tool with the given arguments and context.\n\nNOTE:\n  - Required if this tool needs to run at the client side.\n  - Otherwise, can be skipped, e.g. for a built-in GoogleSearch tool for\n    Gemini.\n\nArgs:\n  args: The LLM-filled arguments.\n  tool_context: The context of the tool.\n\nReturns:\n  The result of running the tool."
    - signature: 'def process_llm_request(self, *, tool_context: google.adk.tools.tool_context.ToolContext, llm_request: google.adk.models.llm_request.LlmRequest) -> None:'
      docstring: "Processes the outgoing LLM request for this tool.\n\nUse cases:\n- Most common use case is adding this tool to the LLM request.\n- Some tools may just preprocess the LLM request before it's sent out.\n\nArgs:\n  tool_context: The context of the tool.\n  llm_request: The outgoing LLM request, mutable this method."
    - signature: 'def from_config(cls: typing.Type[google.adk.tools.base_tool.SelfTool], config: google.adk.tools.tool_configs.ToolArgsConfig, config_abs_path: str) -> google.adk.tools.base_tool.SelfTool:'
      docstring: "Creates a tool instance from a config.\n\nThis default implementation uses inspect to automatically map config values\nto constructor arguments based on their type hints. Subclasses should\noverride this method for custom initialization logic.\n\nArgs:\n  config: The config for the tool.\n  config_abs_path: The absolute path to the config file that contains the\n    tool config.\n\nReturns:\n  The tool instance."
  inherited_properties:
    BaseTool:
    - signature: 'name: str'
      docstring: The name of the tool.
    - signature: 'description: str'
      docstring: The description of the tool.
    - signature: 'is_long_running: bool'
      docstring: 'Whether the tool is a long running operation, which typically returns a

        resource id first and finishes the operation later.'
    - signature: 'custom_metadata: typing.Optional[dict[str, typing.Any]]'
      docstring: 'The custom metadata of the BaseTool.


        An optional key-value pair for storing and retrieving tool-specific metadata,

        such as tool manifests, etc.


        NOTE: the entire dict must be JSON serializable.'
  omitted_inherited_members_from:
  - ABC
- rank: 1595
  id: google.adk.tools.mcp_tool.mcp_tool.MCPTool.__init__
  name: __init__
  file_path: google/adk/tools/mcp_tool/mcp_tool.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def __init__(self):'
- rank: 1596
  id: google.adk.tools.mcp_tool.mcp_tool.McpTool
  name: McpTool
  file_path: google/adk/tools/mcp_tool/mcp_tool.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Turns an MCP Tool into an ADK Tool.


    Internally, the tool initializes from a MCP Tool, and uses the MCP Session to

    call the tool.


    Note: For API key authentication, only header-based API keys are supported.

    Query and cookie-based API keys will result in authentication errors.


    [Note: Inherited members from ABC are omitted.]'
  constructor_signature: 'def __init__(self, *, mcp_tool: mcp.types.Tool, mcp_session_manager: google.adk.tools.mcp_tool.mcp_session_manager.MCPSessionManager, auth_scheme: typing.Optional[google.adk.auth.auth_schemes.AuthScheme]=None, auth_credential: typing.Optional[google.adk.auth.auth_credential.AuthCredential]=None, require_confirmation: typing.Union[bool, typing.Callable[Ellipsis, bool]]=False, header_provider: typing.Optional[typing.Callable[[ReadonlyContext], typing.Dict[str, str]]]=None):'
  methods:
  - signature: 'def raw_mcp_tool(self) -> mcp.types.Tool:'
    docstring: Returns the raw MCP tool.
  - signature: 'def run_async(self, *, args: dict[str, typing.Any], tool_context: google.adk.tools.tool_context.ToolContext) -> typing.Any:'
  - signature: 'def _run_async_impl(self, *, args, tool_context: google.adk.tools.tool_context.ToolContext, credential: google.adk.auth.auth_credential.AuthCredential) -> typing.Dict[str, typing.Any]:'
    docstring: "Runs the tool asynchronously.\n\nArgs:\n    args: The arguments as a dict to pass to the tool.\n    tool_context: The tool context of the current invocation.\n\nReturns:\n    Any: The response from the tool."
  inherited_methods:
    BaseAuthenticatedTool:
    - signature: 'def run_async(self, *, args: dict[str, typing.Any], tool_context: google.adk.tools.tool_context.ToolContext) -> typing.Any:'
    - signature: 'def _run_async_impl(self, *, args: dict[str, typing.Any], tool_context: google.adk.tools.tool_context.ToolContext, credential: google.adk.auth.auth_credential.AuthCredential) -> typing.Any:'
    BaseTool:
    - signature: 'def run_async(self, *, args: dict[str, typing.Any], tool_context: google.adk.tools.tool_context.ToolContext) -> typing.Any:'
      docstring: "Runs the tool with the given arguments and context.\n\nNOTE:\n  - Required if this tool needs to run at the client side.\n  - Otherwise, can be skipped, e.g. for a built-in GoogleSearch tool for\n    Gemini.\n\nArgs:\n  args: The LLM-filled arguments.\n  tool_context: The context of the tool.\n\nReturns:\n  The result of running the tool."
    - signature: 'def process_llm_request(self, *, tool_context: google.adk.tools.tool_context.ToolContext, llm_request: google.adk.models.llm_request.LlmRequest) -> None:'
      docstring: "Processes the outgoing LLM request for this tool.\n\nUse cases:\n- Most common use case is adding this tool to the LLM request.\n- Some tools may just preprocess the LLM request before it's sent out.\n\nArgs:\n  tool_context: The context of the tool.\n  llm_request: The outgoing LLM request, mutable this method."
    - signature: 'def from_config(cls: typing.Type[google.adk.tools.base_tool.SelfTool], config: google.adk.tools.tool_configs.ToolArgsConfig, config_abs_path: str) -> google.adk.tools.base_tool.SelfTool:'
      docstring: "Creates a tool instance from a config.\n\nThis default implementation uses inspect to automatically map config values\nto constructor arguments based on their type hints. Subclasses should\noverride this method for custom initialization logic.\n\nArgs:\n  config: The config for the tool.\n  config_abs_path: The absolute path to the config file that contains the\n    tool config.\n\nReturns:\n  The tool instance."
  inherited_properties:
    BaseTool:
    - signature: 'name: str'
      docstring: The name of the tool.
    - signature: 'description: str'
      docstring: The description of the tool.
    - signature: 'is_long_running: bool'
      docstring: 'Whether the tool is a long running operation, which typically returns a

        resource id first and finishes the operation later.'
    - signature: 'custom_metadata: typing.Optional[dict[str, typing.Any]]'
      docstring: 'The custom metadata of the BaseTool.


        An optional key-value pair for storing and retrieving tool-specific metadata,

        such as tool manifests, etc.


        NOTE: the entire dict must be JSON serializable.'
  omitted_inherited_members_from:
  - ABC
- rank: 1597
  id: google.adk.tools.mcp_tool.mcp_tool.McpTool.__init__
  name: __init__
  file_path: google/adk/tools/mcp_tool/mcp_tool.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Initializes an McpTool.\n\nThis tool wraps an MCP Tool interface and uses a session manager to\ncommunicate with the MCP server.\n\nArgs:\n    mcp_tool: The MCP tool to wrap.\n    mcp_session_manager: The MCP session manager to use for communication.\n    auth_scheme: The authentication scheme to use.\n    auth_credential: The authentication credential to use.\n    require_confirmation: Whether this tool requires confirmation. A boolean\n      or a callable that takes the function's arguments and returns a\n      boolean. If the callable returns True, the tool will require\n      confirmation from the user.\n\nRaises:\n    ValueError: If mcp_tool or mcp_session_manager is None."
  signature: 'def __init__(self, *, mcp_tool: mcp.types.Tool, mcp_session_manager: google.adk.tools.mcp_tool.mcp_session_manager.MCPSessionManager, auth_scheme: typing.Optional[google.adk.auth.auth_schemes.AuthScheme]=None, auth_credential: typing.Optional[google.adk.auth.auth_credential.AuthCredential]=None, require_confirmation: typing.Union[bool, typing.Callable[Ellipsis, bool]]=False, header_provider: typing.Optional[typing.Callable[[ReadonlyContext], typing.Dict[str, str]]]=None):'
- rank: 1598
  id: google.adk.tools.mcp_tool.mcp_tool.McpTool._run_async_impl
  name: _run_async_impl
  file_path: google/adk/tools/mcp_tool/mcp_tool.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Runs the tool asynchronously.\n\nArgs:\n    args: The arguments as a dict to pass to the tool.\n    tool_context: The tool context of the current invocation.\n\nReturns:\n    Any: The response from the tool."
  signature: 'def _run_async_impl(self, *, args, tool_context: google.adk.tools.tool_context.ToolContext, credential: google.adk.auth.auth_credential.AuthCredential) -> typing.Dict[str, typing.Any]:'
- rank: 1599
  id: google.adk.tools.mcp_tool.mcp_tool.McpTool.run_async
  name: run_async
  file_path: google/adk/tools/mcp_tool/mcp_tool.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def run_async(self, *, args: dict[str, typing.Any], tool_context: google.adk.tools.tool_context.ToolContext) -> typing.Any:'
- rank: 1600
  id: google.adk.tools.mcp_tool.mcp_toolset
  name: mcp_toolset
  file_path: google/adk/tools/mcp_tool/mcp_toolset.py
  type: MODULE
  group: Orphan
  usage_score: 0
- rank: 1601
  id: google.adk.tools.mcp_tool.mcp_toolset.MCPToolset.__init__
  name: __init__
  file_path: google/adk/tools/mcp_tool/mcp_toolset.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def __init__(self):'
- rank: 1602
  id: google.adk.tools.mcp_tool.mcp_toolset.McpToolset.__init__
  name: __init__
  file_path: google/adk/tools/mcp_tool/mcp_toolset.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Initializes the McpToolset.\n\nArgs:\n  connection_params: The connection parameters to the MCP server. Can be:\n    ``StdioConnectionParams`` for using local mcp server (e.g. using ``npx`` or\n    ``python3``); or ``SseConnectionParams`` for a local/remote SSE server; or\n    ``StreamableHTTPConnectionParams`` for local/remote Streamable http\n    server. Note, ``StdioServerParameters`` is also supported for using local\n    mcp server (e.g. using ``npx`` or ``python3`` ), but it does not support\n    timeout, and we recommend to use ``StdioConnectionParams`` instead when\n    timeout is needed.\n  tool_filter: Optional filter to select specific tools. Can be either: - A\n    list of tool names to include - A ToolPredicate function for custom\n    filtering logic\n  tool_name_prefix: A prefix to be added to the name of each tool in this\n    toolset.\n  errlog: TextIO stream for error logging.\n  auth_scheme: The auth scheme of the tool for tool calling\n  auth_credential:\
    \ The auth credential of the tool for tool calling\n  require_confirmation: Whether tools in this toolset require\n    confirmation. Can be a single boolean or a callable to apply to all\n    tools.\n  header_provider: A callable that takes a ReadonlyContext and returns a\n    dictionary of headers to be used for the MCP session."
  signature: 'def __init__(self, *, connection_params: typing.Union[mcp.StdioServerParameters, google.adk.tools.mcp_tool.mcp_session_manager.StdioConnectionParams, google.adk.tools.mcp_tool.mcp_session_manager.SseConnectionParams, google.adk.tools.mcp_tool.mcp_session_manager.StreamableHTTPConnectionParams], tool_filter: typing.Optional[typing.Union[google.adk.tools.base_toolset.ToolPredicate, typing.List[str]]]=None, tool_name_prefix: typing.Optional[str]=None, errlog: typing.TextIO=sys.stderr, auth_scheme: typing.Optional[google.adk.auth.auth_schemes.AuthScheme]=None, auth_credential: typing.Optional[google.adk.auth.auth_credential.AuthCredential]=None, require_confirmation: typing.Union[bool, typing.Callable[Ellipsis, bool]]=False, header_provider: typing.Optional[typing.Callable[[ReadonlyContext], typing.Dict[str, str]]]=None):'
- rank: 1603
  id: google.adk.tools.mcp_tool.mcp_toolset.McpToolset.close
  name: close
  file_path: google/adk/tools/mcp_tool/mcp_toolset.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: 'Performs cleanup and releases resources held by the toolset.


    This method closes the MCP session and cleans up all associated resources.

    It''s designed to be safe to call multiple times and handles cleanup errors

    gracefully to avoid blocking application shutdown.'
  signature: 'def close(self) -> None:'
- rank: 1604
  id: google.adk.tools.mcp_tool.mcp_toolset.McpToolset.from_config
  name: from_config
  file_path: google/adk/tools/mcp_tool/mcp_toolset.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: Creates an McpToolset from a configuration object.
  signature: 'def from_config(cls: type[google.adk.tools.mcp_tool.mcp_toolset.McpToolset], config: google.adk.tools.tool_configs.ToolArgsConfig, config_abs_path: str) -> google.adk.tools.mcp_tool.mcp_toolset.McpToolset:'
- rank: 1605
  id: google.adk.tools.mcp_tool.mcp_toolset.McpToolset.get_tools
  name: get_tools
  file_path: google/adk/tools/mcp_tool/mcp_toolset.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Return all tools in the toolset based on the provided context.\n\nArgs:\n    readonly_context: Context used to filter tools available to the agent.\n        If None, all tools in the toolset are returned.\n\nReturns:\n    List[BaseTool]: A list of tools available under the specified context."
  signature: 'def get_tools(self, readonly_context: typing.Optional[google.adk.agents.readonly_context.ReadonlyContext]) -> typing.List[google.adk.tools.base_tool.BaseTool]:'
- rank: 1606
  id: google.adk.tools.mcp_tool.mcp_toolset.McpToolsetConfig
  name: McpToolsetConfig
  file_path: google/adk/tools/mcp_tool/mcp_toolset.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'The config for McpToolset.


    [Note: Inherited members from pydantic.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, stdio_server_params: typing.Optional[mcp.StdioServerParameters] = None, stdio_connection_params: typing.Optional[google.adk.tools.mcp_tool.mcp_session_manager.StdioConnectionParams] = None, sse_connection_params: typing.Optional[google.adk.tools.mcp_tool.mcp_session_manager.SseConnectionParams] = None, streamable_http_connection_params: typing.Optional[google.adk.tools.mcp_tool.mcp_session_manager.StreamableHTTPConnectionParams] = None, tool_filter: typing.Optional[typing.List[str]] = None, tool_name_prefix: typing.Optional[str] = None, auth_scheme: typing.Optional[google.adk.auth.auth_schemes.AuthScheme] = None, auth_credential: typing.Optional[google.adk.auth.auth_credential.AuthCredential] = None):'
  properties:
  - signature: 'stdio_server_params: typing.Optional[mcp.StdioServerParameters]'
  - signature: 'stdio_connection_params: typing.Optional[google.adk.tools.mcp_tool.mcp_session_manager.StdioConnectionParams]'
  - signature: 'sse_connection_params: typing.Optional[google.adk.tools.mcp_tool.mcp_session_manager.SseConnectionParams]'
  - signature: 'streamable_http_connection_params: typing.Optional[google.adk.tools.mcp_tool.mcp_session_manager.StreamableHTTPConnectionParams]'
  - signature: 'tool_filter: typing.Optional[typing.List[str]]'
  - signature: 'tool_name_prefix: typing.Optional[str]'
  - signature: 'auth_scheme: typing.Optional[google.adk.auth.auth_schemes.AuthScheme]'
  - signature: 'auth_credential: typing.Optional[google.adk.auth.auth_credential.AuthCredential]'
  inherited_properties:
    BaseToolConfig:
    - signature: 'model_config: pydantic.ConfigDict'
    BaseModel:
    - signature: 'model_config: pydantic.ConfigDict'
  omitted_inherited_members_from:
  - pydantic.BaseModel
- rank: 1607
  id: google.adk.tools.openapi_tool
  name: openapi_tool
  file_path: google/adk/tools/openapi_tool/__init__.py
  type: MODULE
  group: Orphan
  usage_score: 0
- rank: 1608
  id: google.adk.tools.openapi_tool.auth
  name: auth
  file_path: google/adk/tools/openapi_tool/auth/__init__.py
  type: MODULE
  group: Orphan
  usage_score: 0
- rank: 1609
  id: google.adk.tools.openapi_tool.auth.auth_helpers
  name: auth_helpers
  file_path: google/adk/tools/openapi_tool/auth/auth_helpers.py
  type: MODULE
  group: Orphan
  usage_score: 0
  methods:
  - signature: 'def token_to_scheme_credential(token_type: typing.Literal[apikey, oauth2Token], location: typing.Optional[typing.Literal[header, query, cookie]], name: typing.Optional[str], credential_value: typing.Optional[str]) -> typing.Tuple[google.adk.auth.auth_schemes.AuthScheme, google.adk.auth.auth_credential.AuthCredential]:'
    docstring: "Creates a AuthScheme and AuthCredential for API key or bearer token.\n\nExamples:\n```\n# API Key in header\nauth_scheme, auth_credential = token_to_scheme_credential(\"apikey\", \"header\",\n\"X-API-Key\", \"your_api_key_value\")\n\n# API Key in query parameter\nauth_scheme, auth_credential = token_to_scheme_credential(\"apikey\", \"query\",\n\"api_key\", \"your_api_key_value\")\n\n# OAuth2 Bearer Token in Authorization header\nauth_scheme, auth_credential = token_to_scheme_credential(\"oauth2Token\",\n\"header\", \"Authorization\", \"your_bearer_token_value\")\n```\n\nArgs:\n    type: 'apikey' or 'oauth2Token'.\n    location: 'header', 'query', or 'cookie' (only 'header' for oauth2Token).\n    name: The name of the header, query parameter, or cookie.\n    credential_value:  The value of the API Key/ Token.\n\nReturns:\n    Tuple: (AuthScheme, AuthCredential)\n\nRaises:\n    ValueError: For invalid type or location."
  - signature: 'def service_account_dict_to_scheme_credential(config: typing.Dict[str, typing.Any], scopes: typing.List[str]) -> typing.Tuple[google.adk.auth.auth_schemes.AuthScheme, google.adk.auth.auth_credential.AuthCredential]:'
    docstring: "Creates AuthScheme and AuthCredential for Google Service Account.\n\nReturns a bearer token scheme, and a service account credential.\n\nArgs:\n    config: A ServiceAccount object containing the Google Service Account\n      configuration.\n    scopes: A list of scopes to be used.\n\nReturns:\n    Tuple: (AuthScheme, AuthCredential)"
  - signature: 'def service_account_scheme_credential(config: google.adk.auth.auth_credential.ServiceAccount) -> typing.Tuple[google.adk.auth.auth_schemes.AuthScheme, google.adk.auth.auth_credential.AuthCredential]:'
    docstring: "Creates AuthScheme and AuthCredential for Google Service Account.\n\nReturns a bearer token scheme, and a service account credential.\n\nArgs:\n    config: A ServiceAccount object containing the Google Service Account\n      configuration.\n\nReturns:\n    Tuple: (AuthScheme, AuthCredential)"
  - signature: 'def openid_dict_to_scheme_credential(config_dict: typing.Dict[str, typing.Any], scopes: typing.List[str], credential_dict: typing.Dict[str, typing.Any]) -> typing.Tuple[google.adk.auth.auth_schemes.OpenIdConnectWithConfig, google.adk.auth.auth_credential.AuthCredential]:'
    docstring: "Constructs OpenID scheme and credential from configuration and credential dictionaries.\n\nArgs:\n    config_dict: Dictionary containing OpenID Connect configuration,  must\n      include at least 'authorization_endpoint' and 'token_endpoint'.\n    scopes: List of scopes to be used.\n    credential_dict: Dictionary containing credential information, must\n      include 'client_id', 'client_secret', and 'scopes'.  May optionally\n      include 'redirect_uri'.\n\nReturns:\n    Tuple: (OpenIdConnectWithConfig, AuthCredential)\n\nRaises:\n    ValueError: If required fields are missing in the input dictionaries."
  - signature: 'def openid_url_to_scheme_credential(openid_url: str, scopes: typing.List[str], credential_dict: typing.Dict[str, typing.Any]) -> typing.Tuple[google.adk.auth.auth_schemes.OpenIdConnectWithConfig, google.adk.auth.auth_credential.AuthCredential]:'
    docstring: "Constructs OpenID scheme and credential from OpenID URL, scopes, and credential dictionary.\n\nFetches OpenID configuration from the provided URL.\n\nArgs:\n    openid_url: The OpenID Connect discovery URL.\n    scopes: List of scopes to be used.\n    credential_dict: Dictionary containing credential information, must\n      include at least \"client_id\" and \"client_secret\", may optionally include\n      \"redirect_uri\" and \"scope\"\n\nReturns:\n    Tuple: (AuthScheme, AuthCredential)\n\nRaises:\n    ValueError: If the OpenID URL is invalid, fetching fails, or required\n      fields are missing.\n    requests.exceptions.RequestException:  If there's an error during the\n        HTTP request."
  - signature: 'def credential_to_param(auth_scheme: google.adk.auth.auth_schemes.AuthScheme, auth_credential: google.adk.auth.auth_credential.AuthCredential) -> typing.Tuple[typing.Optional[google.adk.tools.openapi_tool.common.common.ApiParameter], typing.Optional[typing.Dict[str, typing.Any]]]:'
    docstring: "Converts AuthCredential and AuthScheme to a Parameter and a dictionary for additional kwargs.\n\nThis function now supports all credential types returned by the exchangers:\n- API Key\n- HTTP Bearer (for Bearer tokens, OAuth2, Service Account, OpenID Connect)\n- OAuth2 and OpenID Connect (returns None, None, as the token is now a Bearer\ntoken)\n- Service Account (returns None, None, as the token is now a Bearer token)\n\nArgs:\n    auth_scheme: The AuthScheme object.\n    auth_credential: The AuthCredential object.\n\nReturns:\n    Tuple: (ApiParameter, Dict[str, Any])"
  - signature: 'def dict_to_auth_scheme(data: typing.Dict[str, typing.Any]) -> google.adk.auth.auth_schemes.AuthScheme:'
    docstring: "Converts a dictionary to a FastAPI AuthScheme object.\n\nArgs:\n    data: The dictionary representing the security scheme.\n\nReturns:\n    A AuthScheme object (APIKey, HTTPBase, OAuth2, OpenIdConnect, or\n    HTTPBearer).\n\nRaises:\n    ValueError: If the 'type' field is missing or invalid, or if the\n        dictionary cannot be converted to the corresponding Pydantic model.\n\nExample:\n```python\napi_key_data = {\n    \"type\": \"apiKey\",\n    \"in\": \"header\",\n    \"name\": \"X-API-Key\",\n}\napi_key_scheme = dict_to_auth_scheme(api_key_data)\n\nbearer_data = {\n    \"type\": \"http\",\n    \"scheme\": \"bearer\",\n    \"bearerFormat\": \"JWT\",\n}\nbearer_scheme = dict_to_auth_scheme(bearer_data)\n\noauth2_data = {\n    \"type\": \"oauth2\",\n    \"flows\": {\n        \"authorizationCode\": {\n            \"authorizationUrl\": \"https://example.com/auth\",\n            \"tokenUrl\": \"https://example.com/token\",\n        }\n    }\n}\noauth2_scheme = dict_to_auth_scheme(oauth2_data)\n\
      \nopenid_data = {\n    \"type\": \"openIdConnect\",\n    \"openIdConnectUrl\": \"https://example.com/.well-known/openid-configuration\"\n}\nopenid_scheme = dict_to_auth_scheme(openid_data)\n\n```"
- rank: 1610
  id: google.adk.tools.openapi_tool.auth.auth_helpers.OpenIdConfig
  name: OpenIdConfig
  file_path: google/adk/tools/openapi_tool/auth/auth_helpers.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: "Represents OpenID Connect configuration.\n\nAttributes:\n    client_id: The client ID.\n    auth_uri: The authorization URI.\n    token_uri: The token URI.\n    client_secret: The client secret.\n\nExample:\n    config = OpenIdConfig(\n        client_id=\"your_client_id\",\n        auth_uri=\"https://accounts.google.com/o/oauth2/auth\",\n        token_uri=\"https://oauth2.googleapis.com/token\",\n        client_secret=\"your_client_secret\",\n        redirect\n    )\n\n[Note: Inherited members from pydantic.BaseModel are omitted.]"
  constructor_signature: 'def __init__(self, *, client_id: str, auth_uri: str, token_uri: str, client_secret: str, redirect_uri: typing.Optional[str]):'
  properties:
  - signature: 'client_id: str'
  - signature: 'auth_uri: str'
  - signature: 'token_uri: str'
  - signature: 'client_secret: str'
  - signature: 'redirect_uri: typing.Optional[str]'
  inherited_properties:
    BaseModel:
    - signature: 'model_config: pydantic.ConfigDict'
  omitted_inherited_members_from:
  - pydantic.BaseModel
- rank: 1611
  id: google.adk.tools.openapi_tool.auth.auth_helpers.credential_to_param
  name: credential_to_param
  file_path: google/adk/tools/openapi_tool/auth/auth_helpers.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Converts AuthCredential and AuthScheme to a Parameter and a dictionary for additional kwargs.\n\nThis function now supports all credential types returned by the exchangers:\n- API Key\n- HTTP Bearer (for Bearer tokens, OAuth2, Service Account, OpenID Connect)\n- OAuth2 and OpenID Connect (returns None, None, as the token is now a Bearer\ntoken)\n- Service Account (returns None, None, as the token is now a Bearer token)\n\nArgs:\n    auth_scheme: The AuthScheme object.\n    auth_credential: The AuthCredential object.\n\nReturns:\n    Tuple: (ApiParameter, Dict[str, Any])"
  signature: 'def credential_to_param(auth_scheme: google.adk.auth.auth_schemes.AuthScheme, auth_credential: google.adk.auth.auth_credential.AuthCredential) -> typing.Tuple[typing.Optional[google.adk.tools.openapi_tool.common.common.ApiParameter], typing.Optional[typing.Dict[str, typing.Any]]]:'
- rank: 1612
  id: google.adk.tools.openapi_tool.auth.auth_helpers.dict_to_auth_scheme
  name: dict_to_auth_scheme
  file_path: google/adk/tools/openapi_tool/auth/auth_helpers.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Converts a dictionary to a FastAPI AuthScheme object.\n\nArgs:\n    data: The dictionary representing the security scheme.\n\nReturns:\n    A AuthScheme object (APIKey, HTTPBase, OAuth2, OpenIdConnect, or\n    HTTPBearer).\n\nRaises:\n    ValueError: If the 'type' field is missing or invalid, or if the\n        dictionary cannot be converted to the corresponding Pydantic model.\n\nExample:\n```python\napi_key_data = {\n    \"type\": \"apiKey\",\n    \"in\": \"header\",\n    \"name\": \"X-API-Key\",\n}\napi_key_scheme = dict_to_auth_scheme(api_key_data)\n\nbearer_data = {\n    \"type\": \"http\",\n    \"scheme\": \"bearer\",\n    \"bearerFormat\": \"JWT\",\n}\nbearer_scheme = dict_to_auth_scheme(bearer_data)\n\noauth2_data = {\n    \"type\": \"oauth2\",\n    \"flows\": {\n        \"authorizationCode\": {\n            \"authorizationUrl\": \"https://example.com/auth\",\n            \"tokenUrl\": \"https://example.com/token\",\n        }\n    }\n}\noauth2_scheme = dict_to_auth_scheme(oauth2_data)\n\
    \nopenid_data = {\n    \"type\": \"openIdConnect\",\n    \"openIdConnectUrl\": \"https://example.com/.well-known/openid-configuration\"\n}\nopenid_scheme = dict_to_auth_scheme(openid_data)\n\n```"
  signature: 'def dict_to_auth_scheme(data: typing.Dict[str, typing.Any]) -> google.adk.auth.auth_schemes.AuthScheme:'
- rank: 1613
  id: google.adk.tools.openapi_tool.auth.auth_helpers.openid_dict_to_scheme_credential
  name: openid_dict_to_scheme_credential
  file_path: google/adk/tools/openapi_tool/auth/auth_helpers.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Constructs OpenID scheme and credential from configuration and credential dictionaries.\n\nArgs:\n    config_dict: Dictionary containing OpenID Connect configuration,  must\n      include at least 'authorization_endpoint' and 'token_endpoint'.\n    scopes: List of scopes to be used.\n    credential_dict: Dictionary containing credential information, must\n      include 'client_id', 'client_secret', and 'scopes'.  May optionally\n      include 'redirect_uri'.\n\nReturns:\n    Tuple: (OpenIdConnectWithConfig, AuthCredential)\n\nRaises:\n    ValueError: If required fields are missing in the input dictionaries."
  signature: 'def openid_dict_to_scheme_credential(config_dict: typing.Dict[str, typing.Any], scopes: typing.List[str], credential_dict: typing.Dict[str, typing.Any]) -> typing.Tuple[google.adk.auth.auth_schemes.OpenIdConnectWithConfig, google.adk.auth.auth_credential.AuthCredential]:'
- rank: 1614
  id: google.adk.tools.openapi_tool.auth.auth_helpers.openid_url_to_scheme_credential
  name: openid_url_to_scheme_credential
  file_path: google/adk/tools/openapi_tool/auth/auth_helpers.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Constructs OpenID scheme and credential from OpenID URL, scopes, and credential dictionary.\n\nFetches OpenID configuration from the provided URL.\n\nArgs:\n    openid_url: The OpenID Connect discovery URL.\n    scopes: List of scopes to be used.\n    credential_dict: Dictionary containing credential information, must\n      include at least \"client_id\" and \"client_secret\", may optionally include\n      \"redirect_uri\" and \"scope\"\n\nReturns:\n    Tuple: (AuthScheme, AuthCredential)\n\nRaises:\n    ValueError: If the OpenID URL is invalid, fetching fails, or required\n      fields are missing.\n    requests.exceptions.RequestException:  If there's an error during the\n        HTTP request."
  signature: 'def openid_url_to_scheme_credential(openid_url: str, scopes: typing.List[str], credential_dict: typing.Dict[str, typing.Any]) -> typing.Tuple[google.adk.auth.auth_schemes.OpenIdConnectWithConfig, google.adk.auth.auth_credential.AuthCredential]:'
- rank: 1615
  id: google.adk.tools.openapi_tool.auth.auth_helpers.service_account_dict_to_scheme_credential
  name: service_account_dict_to_scheme_credential
  file_path: google/adk/tools/openapi_tool/auth/auth_helpers.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Creates AuthScheme and AuthCredential for Google Service Account.\n\nReturns a bearer token scheme, and a service account credential.\n\nArgs:\n    config: A ServiceAccount object containing the Google Service Account\n      configuration.\n    scopes: A list of scopes to be used.\n\nReturns:\n    Tuple: (AuthScheme, AuthCredential)"
  signature: 'def service_account_dict_to_scheme_credential(config: typing.Dict[str, typing.Any], scopes: typing.List[str]) -> typing.Tuple[google.adk.auth.auth_schemes.AuthScheme, google.adk.auth.auth_credential.AuthCredential]:'
- rank: 1616
  id: google.adk.tools.openapi_tool.auth.auth_helpers.service_account_scheme_credential
  name: service_account_scheme_credential
  file_path: google/adk/tools/openapi_tool/auth/auth_helpers.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Creates AuthScheme and AuthCredential for Google Service Account.\n\nReturns a bearer token scheme, and a service account credential.\n\nArgs:\n    config: A ServiceAccount object containing the Google Service Account\n      configuration.\n\nReturns:\n    Tuple: (AuthScheme, AuthCredential)"
  signature: 'def service_account_scheme_credential(config: google.adk.auth.auth_credential.ServiceAccount) -> typing.Tuple[google.adk.auth.auth_schemes.AuthScheme, google.adk.auth.auth_credential.AuthCredential]:'
- rank: 1617
  id: google.adk.tools.openapi_tool.auth.auth_helpers.token_to_scheme_credential
  name: token_to_scheme_credential
  file_path: google/adk/tools/openapi_tool/auth/auth_helpers.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Creates a AuthScheme and AuthCredential for API key or bearer token.\n\nExamples:\n```\n# API Key in header\nauth_scheme, auth_credential = token_to_scheme_credential(\"apikey\", \"header\",\n\"X-API-Key\", \"your_api_key_value\")\n\n# API Key in query parameter\nauth_scheme, auth_credential = token_to_scheme_credential(\"apikey\", \"query\",\n\"api_key\", \"your_api_key_value\")\n\n# OAuth2 Bearer Token in Authorization header\nauth_scheme, auth_credential = token_to_scheme_credential(\"oauth2Token\",\n\"header\", \"Authorization\", \"your_bearer_token_value\")\n```\n\nArgs:\n    type: 'apikey' or 'oauth2Token'.\n    location: 'header', 'query', or 'cookie' (only 'header' for oauth2Token).\n    name: The name of the header, query parameter, or cookie.\n    credential_value:  The value of the API Key/ Token.\n\nReturns:\n    Tuple: (AuthScheme, AuthCredential)\n\nRaises:\n    ValueError: For invalid type or location."
  signature: 'def token_to_scheme_credential(token_type: typing.Literal[apikey, oauth2Token], location: typing.Optional[typing.Literal[header, query, cookie]], name: typing.Optional[str], credential_value: typing.Optional[str]) -> typing.Tuple[google.adk.auth.auth_schemes.AuthScheme, google.adk.auth.auth_credential.AuthCredential]:'
- rank: 1618
  id: google.adk.tools.openapi_tool.auth.credential_exchangers
  name: credential_exchangers
  file_path: google/adk/tools/openapi_tool/auth/credential_exchangers/__init__.py
  type: MODULE
  group: Orphan
  usage_score: 0
- rank: 1619
  id: google.adk.tools.openapi_tool.auth.credential_exchangers.auto_auth_credential_exchanger
  name: auto_auth_credential_exchanger
  file_path: google/adk/tools/openapi_tool/auth/credential_exchangers/auto_auth_credential_exchanger.py
  type: MODULE
  group: Orphan
  usage_score: 0
- rank: 1620
  id: google.adk.tools.openapi_tool.auth.credential_exchangers.auto_auth_credential_exchanger.AutoAuthCredentialExchanger
  name: AutoAuthCredentialExchanger
  file_path: google/adk/tools/openapi_tool/auth/credential_exchangers/auto_auth_credential_exchanger.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: "Automatically selects the appropriate credential exchanger based on the auth scheme.\n\nOptionally, an override can be provided to use a specific exchanger for a\ngiven auth scheme.\n\nExample (common case):\n```\nexchanger = AutoAuthCredentialExchanger()\nauth_credential = exchanger.exchange_credential(\n    auth_scheme=service_account_scheme,\n    auth_credential=service_account_credential,\n)\n# Returns an oauth token in the form of a bearer token.\n```\n\nExample (use CustomAuthExchanger for OAuth2):\n```\nexchanger = AutoAuthCredentialExchanger(\n    custom_exchangers={\n        AuthScheme.OAUTH2: CustomAuthExchanger,\n    }\n)\n```\n\nAttributes:\n  exchangers: A dictionary mapping auth scheme to credential exchanger class."
  constructor_signature: 'def __init__(self, custom_exchangers: typing.Optional[typing.Dict[str, typing.Type[google.adk.tools.openapi_tool.auth.credential_exchangers.base_credential_exchanger.BaseAuthCredentialExchanger]]]):'
  methods:
  - signature: 'def exchange_credential(self, auth_scheme: google.adk.auth.auth_schemes.AuthScheme, auth_credential: typing.Optional[google.adk.auth.auth_credential.AuthCredential]) -> typing.Optional[google.adk.auth.auth_credential.AuthCredential]:'
    docstring: "Automatically exchanges for the credential uses the appropriate credential exchanger.\n\nArgs:\n    auth_scheme (AuthScheme): The security scheme.\n    auth_credential (AuthCredential): Optional. The authentication\n      credential.\n\nReturns: (AuthCredential)\n    A new AuthCredential object containing the exchanged credential."
  inherited_methods:
    BaseAuthCredentialExchanger:
    - signature: 'def exchange_credential(self, auth_scheme: google.adk.auth.auth_schemes.AuthScheme, auth_credential: typing.Optional[google.adk.auth.auth_credential.AuthCredential]) -> google.adk.auth.auth_credential.AuthCredential:'
      docstring: "Exchanges the provided authentication credential for a usable token/credential.\n\nArgs:\n    auth_scheme: The security scheme.\n    auth_credential: The authentication credential.\n\nReturns:\n    An updated AuthCredential object containing the fetched credential.\n    For simple schemes like API key, it may return the original credential\n    if no exchange is needed.\n\nRaises:\n    NotImplementedError: If the method is not implemented by a subclass."
- rank: 1621
  id: google.adk.tools.openapi_tool.auth.credential_exchangers.auto_auth_credential_exchanger.AutoAuthCredentialExchanger.__init__
  name: __init__
  file_path: google/adk/tools/openapi_tool/auth/credential_exchangers/auto_auth_credential_exchanger.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Initializes the AutoAuthCredentialExchanger.\n\nArgs:\n  custom_exchangers: Optional dictionary for adding or overriding auth\n    exchangers. The key is the auth scheme, and the value is the credential\n    exchanger class."
  signature: 'def __init__(self, custom_exchangers: typing.Optional[typing.Dict[str, typing.Type[google.adk.tools.openapi_tool.auth.credential_exchangers.base_credential_exchanger.BaseAuthCredentialExchanger]]]):'
- rank: 1622
  id: google.adk.tools.openapi_tool.auth.credential_exchangers.auto_auth_credential_exchanger.AutoAuthCredentialExchanger.exchange_credential
  name: exchange_credential
  file_path: google/adk/tools/openapi_tool/auth/credential_exchangers/auto_auth_credential_exchanger.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Automatically exchanges for the credential uses the appropriate credential exchanger.\n\nArgs:\n    auth_scheme (AuthScheme): The security scheme.\n    auth_credential (AuthCredential): Optional. The authentication\n      credential.\n\nReturns: (AuthCredential)\n    A new AuthCredential object containing the exchanged credential."
  signature: 'def exchange_credential(self, auth_scheme: google.adk.auth.auth_schemes.AuthScheme, auth_credential: typing.Optional[google.adk.auth.auth_credential.AuthCredential]) -> typing.Optional[google.adk.auth.auth_credential.AuthCredential]:'
- rank: 1623
  id: google.adk.tools.openapi_tool.auth.credential_exchangers.base_credential_exchanger
  name: base_credential_exchanger
  file_path: google/adk/tools/openapi_tool/auth/credential_exchangers/base_credential_exchanger.py
  type: MODULE
  group: Orphan
  usage_score: 0
- rank: 1624
  id: google.adk.tools.openapi_tool.auth.credential_exchangers.base_credential_exchanger.AuthCredentialMissingError
  name: AuthCredentialMissingError
  file_path: google/adk/tools/openapi_tool/auth/credential_exchangers/base_credential_exchanger.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Exception raised when required authentication credentials are missing.


    [Note: Inherited members from Exception are omitted.]'
  constructor_signature: 'def __init__(self, message: str):'
  omitted_inherited_members_from:
  - Exception
- rank: 1625
  id: google.adk.tools.openapi_tool.auth.credential_exchangers.base_credential_exchanger.BaseAuthCredentialExchanger
  name: BaseAuthCredentialExchanger
  file_path: google/adk/tools/openapi_tool/auth/credential_exchangers/base_credential_exchanger.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: Base class for authentication credential exchangers.
  aliases:
  - google.adk.tools.openapi_tool.auth.credential_exchangers.BaseAuthCredentialExchanger
  methods:
  - signature: 'def exchange_credential(self, auth_scheme: google.adk.auth.auth_schemes.AuthScheme, auth_credential: typing.Optional[google.adk.auth.auth_credential.AuthCredential]) -> google.adk.auth.auth_credential.AuthCredential:'
    docstring: "Exchanges the provided authentication credential for a usable token/credential.\n\nArgs:\n    auth_scheme: The security scheme.\n    auth_credential: The authentication credential.\n\nReturns:\n    An updated AuthCredential object containing the fetched credential.\n    For simple schemes like API key, it may return the original credential\n    if no exchange is needed.\n\nRaises:\n    NotImplementedError: If the method is not implemented by a subclass."
- rank: 1626
  id: google.adk.tools.openapi_tool.auth.credential_exchangers.base_credential_exchanger.BaseAuthCredentialExchanger.exchange_credential
  name: exchange_credential
  file_path: google/adk/tools/openapi_tool/auth/credential_exchangers/base_credential_exchanger.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Exchanges the provided authentication credential for a usable token/credential.\n\nArgs:\n    auth_scheme: The security scheme.\n    auth_credential: The authentication credential.\n\nReturns:\n    An updated AuthCredential object containing the fetched credential.\n    For simple schemes like API key, it may return the original credential\n    if no exchange is needed.\n\nRaises:\n    NotImplementedError: If the method is not implemented by a subclass."
  signature: 'def exchange_credential(self, auth_scheme: google.adk.auth.auth_schemes.AuthScheme, auth_credential: typing.Optional[google.adk.auth.auth_credential.AuthCredential]) -> google.adk.auth.auth_credential.AuthCredential:'
- rank: 1627
  id: google.adk.tools.openapi_tool.auth.credential_exchangers.oauth2_exchanger
  name: oauth2_exchanger
  file_path: google/adk/tools/openapi_tool/auth/credential_exchangers/oauth2_exchanger.py
  type: MODULE
  group: Orphan
  usage_score: 0
  docstring: Credential fetcher for OpenID Connect.
- rank: 1628
  id: google.adk.tools.openapi_tool.auth.credential_exchangers.oauth2_exchanger.OAuth2CredentialExchanger
  name: OAuth2CredentialExchanger
  file_path: google/adk/tools/openapi_tool/auth/credential_exchangers/oauth2_exchanger.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: Fetches credentials for OAuth2 and OpenID Connect.
  aliases:
  - google.adk.tools.openapi_tool.auth.credential_exchangers.OAuth2CredentialExchanger
  methods:
  - signature: 'def generate_auth_token(self, auth_credential: typing.Optional[google.adk.auth.auth_credential.AuthCredential]) -> google.adk.auth.auth_credential.AuthCredential:'
    docstring: "Generates an auth token from the authorization response.\n\nArgs:\n    auth_scheme: The OpenID Connect or OAuth2 auth scheme.\n    auth_credential: The auth credential.\n\nReturns:\n    An AuthCredential object containing the HTTP bearer access token. If the\n    HTTP bearer token cannot be generated, return the original credential."
  - signature: 'def exchange_credential(self, auth_scheme: google.adk.auth.auth_schemes.AuthScheme, auth_credential: typing.Optional[google.adk.auth.auth_credential.AuthCredential]) -> google.adk.auth.auth_credential.AuthCredential:'
    docstring: "Exchanges the OpenID Connect auth credential for an access token or an auth URI.\n\nArgs:\n    auth_scheme: The auth scheme.\n    auth_credential: The auth credential.\n\nReturns:\n    An AuthCredential object containing the HTTP Bearer access token.\n\nRaises:\n    ValueError: If the auth scheme or auth credential is invalid."
  inherited_methods:
    BaseAuthCredentialExchanger:
    - signature: 'def exchange_credential(self, auth_scheme: google.adk.auth.auth_schemes.AuthScheme, auth_credential: typing.Optional[google.adk.auth.auth_credential.AuthCredential]) -> google.adk.auth.auth_credential.AuthCredential:'
      docstring: "Exchanges the provided authentication credential for a usable token/credential.\n\nArgs:\n    auth_scheme: The security scheme.\n    auth_credential: The authentication credential.\n\nReturns:\n    An updated AuthCredential object containing the fetched credential.\n    For simple schemes like API key, it may return the original credential\n    if no exchange is needed.\n\nRaises:\n    NotImplementedError: If the method is not implemented by a subclass."
- rank: 1629
  id: google.adk.tools.openapi_tool.auth.credential_exchangers.oauth2_exchanger.OAuth2CredentialExchanger.exchange_credential
  name: exchange_credential
  file_path: google/adk/tools/openapi_tool/auth/credential_exchangers/oauth2_exchanger.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Exchanges the OpenID Connect auth credential for an access token or an auth URI.\n\nArgs:\n    auth_scheme: The auth scheme.\n    auth_credential: The auth credential.\n\nReturns:\n    An AuthCredential object containing the HTTP Bearer access token.\n\nRaises:\n    ValueError: If the auth scheme or auth credential is invalid."
  signature: 'def exchange_credential(self, auth_scheme: google.adk.auth.auth_schemes.AuthScheme, auth_credential: typing.Optional[google.adk.auth.auth_credential.AuthCredential]) -> google.adk.auth.auth_credential.AuthCredential:'
- rank: 1630
  id: google.adk.tools.openapi_tool.auth.credential_exchangers.oauth2_exchanger.OAuth2CredentialExchanger.generate_auth_token
  name: generate_auth_token
  file_path: google/adk/tools/openapi_tool/auth/credential_exchangers/oauth2_exchanger.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Generates an auth token from the authorization response.\n\nArgs:\n    auth_scheme: The OpenID Connect or OAuth2 auth scheme.\n    auth_credential: The auth credential.\n\nReturns:\n    An AuthCredential object containing the HTTP bearer access token. If the\n    HTTP bearer token cannot be generated, return the original credential."
  signature: 'def generate_auth_token(self, auth_credential: typing.Optional[google.adk.auth.auth_credential.AuthCredential]) -> google.adk.auth.auth_credential.AuthCredential:'
- rank: 1631
  id: google.adk.tools.openapi_tool.auth.credential_exchangers.service_account_exchanger
  name: service_account_exchanger
  file_path: google/adk/tools/openapi_tool/auth/credential_exchangers/service_account_exchanger.py
  type: MODULE
  group: Orphan
  usage_score: 0
  docstring: Credential fetcher for Google Service Account.
- rank: 1632
  id: google.adk.tools.openapi_tool.auth.credential_exchangers.service_account_exchanger.ServiceAccountCredentialExchanger
  name: ServiceAccountCredentialExchanger
  file_path: google/adk/tools/openapi_tool/auth/credential_exchangers/service_account_exchanger.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Fetches credentials for Google Service Account.


    Uses the default service credential if `use_default_credential = True`.

    Otherwise, uses the service account credential provided in the auth

    credential.'
  aliases:
  - google.adk.tools.openapi_tool.auth.credential_exchangers.ServiceAccountCredentialExchanger
  methods:
  - signature: 'def exchange_credential(self, auth_scheme: google.adk.auth.auth_schemes.AuthScheme, auth_credential: typing.Optional[google.adk.auth.auth_credential.AuthCredential]) -> google.adk.auth.auth_credential.AuthCredential:'
    docstring: "Exchanges the service account auth credential for an access token.\n\nIf auth_credential contains a service account credential, it will be used\nto fetch an access token. Otherwise, the default service credential will be\nused for fetching an access token.\n\nArgs:\n    auth_scheme: The auth scheme.\n    auth_credential: The auth credential.\n\nReturns:\n    An AuthCredential in HTTPBearer format, containing the access token."
  inherited_methods:
    BaseAuthCredentialExchanger:
    - signature: 'def exchange_credential(self, auth_scheme: google.adk.auth.auth_schemes.AuthScheme, auth_credential: typing.Optional[google.adk.auth.auth_credential.AuthCredential]) -> google.adk.auth.auth_credential.AuthCredential:'
      docstring: "Exchanges the provided authentication credential for a usable token/credential.\n\nArgs:\n    auth_scheme: The security scheme.\n    auth_credential: The authentication credential.\n\nReturns:\n    An updated AuthCredential object containing the fetched credential.\n    For simple schemes like API key, it may return the original credential\n    if no exchange is needed.\n\nRaises:\n    NotImplementedError: If the method is not implemented by a subclass."
- rank: 1633
  id: google.adk.tools.openapi_tool.auth.credential_exchangers.service_account_exchanger.ServiceAccountCredentialExchanger.exchange_credential
  name: exchange_credential
  file_path: google/adk/tools/openapi_tool/auth/credential_exchangers/service_account_exchanger.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Exchanges the service account auth credential for an access token.\n\nIf auth_credential contains a service account credential, it will be used\nto fetch an access token. Otherwise, the default service credential will be\nused for fetching an access token.\n\nArgs:\n    auth_scheme: The auth scheme.\n    auth_credential: The auth credential.\n\nReturns:\n    An AuthCredential in HTTPBearer format, containing the access token."
  signature: 'def exchange_credential(self, auth_scheme: google.adk.auth.auth_schemes.AuthScheme, auth_credential: typing.Optional[google.adk.auth.auth_credential.AuthCredential]) -> google.adk.auth.auth_credential.AuthCredential:'
- rank: 1634
  id: google.adk.tools.openapi_tool.common
  name: common
  file_path: google/adk/tools/openapi_tool/common/__init__.py
  type: MODULE
  group: Orphan
  usage_score: 0
- rank: 1635
  id: google.adk.tools.openapi_tool.common.common
  name: common
  file_path: google/adk/tools/openapi_tool/common/common.py
  type: MODULE
  group: Orphan
  usage_score: 0
  methods:
  - signature: 'def rename_python_keywords(s: str, prefix: str) -> str:'
    docstring: "Renames Python keywords by adding a prefix.\n\nExample:\n```\nrename_python_keywords('if') -> 'param_if'\nrename_python_keywords('for') -> 'param_for'\n```\n\nArgs:\n    s: The input string.\n    prefix: The prefix to add to the keyword.\n\nReturns:\n    The renamed string."
- rank: 1636
  id: google.adk.tools.openapi_tool.common.common.ApiParameter
  name: ApiParameter
  file_path: google/adk/tools/openapi_tool/common/common.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Data class representing a function parameter.


    [Note: Inherited members from pydantic.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, original_name: str, param_location: str, param_schema: typing.Union[str, fastapi.openapi.models.Schema], description: typing.Optional[str] = '''', py_name: typing.Optional[str] = '''', type_value: type[typing.Any] = None, type_hint: str = None, required: bool = False):'
  methods:
  - signature: 'def model_post_init(self, _: typing.Any):'
  - signature: 'def to_arg_string(self):'
    docstring: Converts the parameter to an argument string for function call.
  - signature: 'def to_dict_property(self):'
    docstring: Converts the parameter to a key:value string for dict property.
  - signature: 'def to_pydoc_string(self):'
    docstring: Converts the parameter to a PyDoc parameter docstr.
  properties:
  - signature: 'original_name: str'
  - signature: 'param_location: str'
  - signature: 'param_schema: typing.Union[str, fastapi.openapi.models.Schema]'
  - signature: 'description: typing.Optional[str]'
  - signature: 'py_name: typing.Optional[str]'
  - signature: 'type_value: type[typing.Any]'
  - signature: 'type_hint: str'
  - signature: 'required: bool'
  inherited_properties:
    BaseModel:
    - signature: 'model_config: pydantic.ConfigDict'
  omitted_inherited_members_from:
  - pydantic.BaseModel
- rank: 1637
  id: google.adk.tools.openapi_tool.common.common.ApiParameter.model_post_init
  name: model_post_init
  file_path: google/adk/tools/openapi_tool/common/common.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def model_post_init(self, _: typing.Any):'
- rank: 1638
  id: google.adk.tools.openapi_tool.common.common.PydocHelper
  name: PydocHelper
  file_path: google/adk/tools/openapi_tool/common/common.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: Helper class for generating PyDoc strings.
  methods:
  - signature: 'def generate_param_doc(param: google.adk.tools.openapi_tool.common.common.ApiParameter) -> str:'
    docstring: "Generates a parameter documentation string.\n\nArgs:\n  param: ApiParameter - The parameter to generate the documentation for.\n\nReturns:\n  str: The generated parameter Python documentation string."
  - signature: 'def generate_return_doc(responses: typing.Dict[str, fastapi.openapi.models.Response]) -> str:'
    docstring: "Generates a return value documentation string.\n\nArgs:\n  responses: Dict[str, TypedDict[Response]] - Response in an OpenAPI\n    Operation\n\nReturns:\n  str: The generated return value Python documentation string."
- rank: 1639
  id: google.adk.tools.openapi_tool.common.common.PydocHelper.generate_param_doc
  name: generate_param_doc
  file_path: google/adk/tools/openapi_tool/common/common.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Generates a parameter documentation string.\n\nArgs:\n  param: ApiParameter - The parameter to generate the documentation for.\n\nReturns:\n  str: The generated parameter Python documentation string."
  signature: 'def generate_param_doc(param: google.adk.tools.openapi_tool.common.common.ApiParameter) -> str:'
- rank: 1640
  id: google.adk.tools.openapi_tool.common.common.PydocHelper.generate_return_doc
  name: generate_return_doc
  file_path: google/adk/tools/openapi_tool/common/common.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Generates a return value documentation string.\n\nArgs:\n  responses: Dict[str, TypedDict[Response]] - Response in an OpenAPI\n    Operation\n\nReturns:\n  str: The generated return value Python documentation string."
  signature: 'def generate_return_doc(responses: typing.Dict[str, fastapi.openapi.models.Response]) -> str:'
- rank: 1641
  id: google.adk.tools.openapi_tool.common.common.TypeHintHelper
  name: TypeHintHelper
  file_path: google/adk/tools/openapi_tool/common/common.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: Helper class for generating type hints.
  methods:
  - signature: 'def get_type_value(schema: fastapi.openapi.models.Schema) -> typing.Any:'
    docstring: Generates the Python type value for a given parameter.
  - signature: 'def get_type_hint(schema: fastapi.openapi.models.Schema) -> str:'
    docstring: Generates the Python type in string for a given parameter.
- rank: 1642
  id: google.adk.tools.openapi_tool.common.common.TypeHintHelper.get_type_hint
  name: get_type_hint
  file_path: google/adk/tools/openapi_tool/common/common.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: Generates the Python type in string for a given parameter.
  signature: 'def get_type_hint(schema: fastapi.openapi.models.Schema) -> str:'
- rank: 1643
  id: google.adk.tools.openapi_tool.common.common.TypeHintHelper.get_type_value
  name: get_type_value
  file_path: google/adk/tools/openapi_tool/common/common.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: Generates the Python type value for a given parameter.
  signature: 'def get_type_value(schema: fastapi.openapi.models.Schema) -> typing.Any:'
- rank: 1644
  id: google.adk.tools.openapi_tool.common.common.rename_python_keywords
  name: rename_python_keywords
  file_path: google/adk/tools/openapi_tool/common/common.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Renames Python keywords by adding a prefix.\n\nExample:\n```\nrename_python_keywords('if') -> 'param_if'\nrename_python_keywords('for') -> 'param_for'\n```\n\nArgs:\n    s: The input string.\n    prefix: The prefix to add to the keyword.\n\nReturns:\n    The renamed string."
  signature: 'def rename_python_keywords(s: str, prefix: str) -> str:'
- rank: 1645
  id: google.adk.tools.openapi_tool.openapi_spec_parser
  name: openapi_spec_parser
  file_path: google/adk/tools/openapi_tool/openapi_spec_parser/__init__.py
  type: MODULE
  group: Orphan
  usage_score: 0
- rank: 1646
  id: google.adk.tools.openapi_tool.openapi_spec_parser.openapi_spec_parser
  name: openapi_spec_parser
  file_path: google/adk/tools/openapi_tool/openapi_spec_parser/openapi_spec_parser.py
  type: MODULE
  group: Orphan
  usage_score: 0
- rank: 1647
  id: google.adk.tools.openapi_tool.openapi_spec_parser.openapi_spec_parser.OpenApiSpecParser
  name: OpenApiSpecParser
  file_path: google/adk/tools/openapi_tool/openapi_spec_parser/openapi_spec_parser.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Generates Python code, JSON schema, and callables for an OpenAPI operation.


    This class takes an OpenApiOperation object and provides methods to generate:

    1. A string representation of a Python function that handles the operation.

    2. A JSON schema representing the input parameters of the operation.

    3. A callable Python object (a function) that can execute the operation.'
  methods:
  - signature: 'def parse(self, openapi_spec_dict: typing.Dict[str, typing.Any]) -> typing.List[google.adk.tools.openapi_tool.openapi_spec_parser.openapi_spec_parser.ParsedOperation]:'
    docstring: "Extracts an OpenAPI spec dict into a list of ParsedOperation objects.\n\nParsedOperation objects are further used for generating RestApiTool.\n\nArgs:\n    openapi_spec_dict: A dictionary representing the OpenAPI specification.\n\nReturns:\n    A list of ParsedOperation objects."
  - signature: 'def resolve_ref(ref_string, current_doc):'
    docstring: Resolves a single $ref string.
  - signature: 'def recursive_resolve(obj, current_doc, seen_refs):'
    docstring: "Recursively resolves references, handling circularity.\n\nArgs:\n    obj: The object to traverse.\n    current_doc:  Document to search for refs.\n    seen_refs: A set to track already-visited references (for circularity\n      detection).\n\nReturns:\n    The resolved object."
- rank: 1648
  id: google.adk.tools.openapi_tool.openapi_spec_parser.openapi_spec_parser.OpenApiSpecParser.parse
  name: parse
  file_path: google/adk/tools/openapi_tool/openapi_spec_parser/openapi_spec_parser.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Extracts an OpenAPI spec dict into a list of ParsedOperation objects.\n\nParsedOperation objects are further used for generating RestApiTool.\n\nArgs:\n    openapi_spec_dict: A dictionary representing the OpenAPI specification.\n\nReturns:\n    A list of ParsedOperation objects."
  signature: 'def parse(self, openapi_spec_dict: typing.Dict[str, typing.Any]) -> typing.List[google.adk.tools.openapi_tool.openapi_spec_parser.openapi_spec_parser.ParsedOperation]:'
- rank: 1649
  id: google.adk.tools.openapi_tool.openapi_spec_parser.openapi_spec_parser.OpenApiSpecParser.recursive_resolve
  name: recursive_resolve
  file_path: google/adk/tools/openapi_tool/openapi_spec_parser/openapi_spec_parser.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Recursively resolves references, handling circularity.\n\nArgs:\n    obj: The object to traverse.\n    current_doc:  Document to search for refs.\n    seen_refs: A set to track already-visited references (for circularity\n      detection).\n\nReturns:\n    The resolved object."
  signature: 'def recursive_resolve(obj, current_doc, seen_refs):'
- rank: 1650
  id: google.adk.tools.openapi_tool.openapi_spec_parser.openapi_spec_parser.OpenApiSpecParser.resolve_ref
  name: resolve_ref
  file_path: google/adk/tools/openapi_tool/openapi_spec_parser/openapi_spec_parser.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: Resolves a single $ref string.
  signature: 'def resolve_ref(ref_string, current_doc):'
- rank: 1651
  id: google.adk.tools.openapi_tool.openapi_spec_parser.openapi_spec_parser.OperationEndpoint
  name: OperationEndpoint
  file_path: google/adk/tools/openapi_tool/openapi_spec_parser/openapi_spec_parser.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: '[Note: Inherited members from pydantic.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, base_url: str, path: str, method: str):'
  properties:
  - signature: 'base_url: str'
  - signature: 'path: str'
  - signature: 'method: str'
  inherited_properties:
    BaseModel:
    - signature: 'model_config: pydantic.ConfigDict'
  omitted_inherited_members_from:
  - pydantic.BaseModel
- rank: 1652
  id: google.adk.tools.openapi_tool.openapi_spec_parser.openapi_spec_parser.ParsedOperation
  name: ParsedOperation
  file_path: google/adk/tools/openapi_tool/openapi_spec_parser/openapi_spec_parser.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: '[Note: Inherited members from pydantic.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, name: str, description: str, endpoint: google.adk.tools.openapi_tool.openapi_spec_parser.openapi_spec_parser.OperationEndpoint, operation: fastapi.openapi.models.Operation, parameters: typing.List[google.adk.tools.openapi_tool.common.common.ApiParameter], return_value: google.adk.tools.openapi_tool.common.common.ApiParameter, auth_scheme: typing.Optional[google.adk.auth.auth_schemes.AuthScheme] = None, auth_credential: typing.Optional[google.adk.auth.auth_credential.AuthCredential] = None, additional_context: typing.Optional[typing.Any] = None):'
  properties:
  - signature: 'name: str'
  - signature: 'description: str'
  - signature: 'endpoint: google.adk.tools.openapi_tool.openapi_spec_parser.openapi_spec_parser.OperationEndpoint'
  - signature: 'operation: fastapi.openapi.models.Operation'
  - signature: 'parameters: typing.List[google.adk.tools.openapi_tool.common.common.ApiParameter]'
  - signature: 'return_value: google.adk.tools.openapi_tool.common.common.ApiParameter'
  - signature: 'auth_scheme: typing.Optional[google.adk.auth.auth_schemes.AuthScheme]'
  - signature: 'auth_credential: typing.Optional[google.adk.auth.auth_credential.AuthCredential]'
  - signature: 'additional_context: typing.Optional[typing.Any]'
  inherited_properties:
    BaseModel:
    - signature: 'model_config: pydantic.ConfigDict'
  omitted_inherited_members_from:
  - pydantic.BaseModel
- rank: 1653
  id: google.adk.tools.openapi_tool.openapi_spec_parser.openapi_toolset
  name: openapi_toolset
  file_path: google/adk/tools/openapi_tool/openapi_spec_parser/openapi_toolset.py
  type: MODULE
  group: Orphan
  usage_score: 0
- rank: 1654
  id: google.adk.tools.openapi_tool.openapi_spec_parser.openapi_toolset.OpenAPIToolset
  name: OpenAPIToolset
  file_path: google/adk/tools/openapi_tool/openapi_spec_parser/openapi_toolset.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: "Class for parsing OpenAPI spec into a list of RestApiTool.\n\nUsage::\n\n  # Initialize OpenAPI toolset from a spec string.\n  openapi_toolset = OpenAPIToolset(spec_str=openapi_spec_str,\n    spec_str_type=\"json\")\n  # Or, initialize OpenAPI toolset from a spec dictionary.\n  openapi_toolset = OpenAPIToolset(spec_dict=openapi_spec_dict)\n\n  # Add all tools to an agent.\n  agent = Agent(\n    tools=[*openapi_toolset.get_tools()]\n  )\n  # Or, add a single tool to an agent.\n  agent = Agent(\n    tools=[openapi_toolset.get_tool('tool_name')]\n  )\n\n[Note: Inherited members from ABC are omitted.]"
  constructor_signature: 'def __init__(self, *, spec_dict: typing.Optional[typing.Dict[str, typing.Any]]=None, spec_str: typing.Optional[str]=None, spec_str_type: typing.Literal[json, yaml]=''json'', auth_scheme: typing.Optional[google.adk.auth.auth_schemes.AuthScheme]=None, auth_credential: typing.Optional[google.adk.auth.auth_credential.AuthCredential]=None, tool_filter: typing.Optional[typing.Union[google.adk.tools.base_toolset.ToolPredicate, typing.List[str]]]=None):'
  methods:
  - signature: 'def get_tools(self, readonly_context: typing.Optional[google.adk.agents.readonly_context.ReadonlyContext]) -> typing.List[google.adk.tools.openapi_tool.openapi_spec_parser.rest_api_tool.RestApiTool]:'
    docstring: Get all tools in the toolset.
  - signature: 'def get_tool(self, tool_name: str) -> typing.Optional[google.adk.tools.openapi_tool.openapi_spec_parser.rest_api_tool.RestApiTool]:'
    docstring: Get a tool by name.
  - signature: 'def close(self):'
  inherited_methods:
    BaseToolset:
    - signature: 'def get_tools(self, readonly_context: typing.Optional[google.adk.agents.readonly_context.ReadonlyContext]) -> list[google.adk.tools.base_tool.BaseTool]:'
      docstring: "Return all tools in the toolset based on the provided context.\n\nArgs:\n  readonly_context (ReadonlyContext, optional): Context used to filter tools\n    available to the agent. If None, all tools in the toolset are returned.\n\nReturns:\n  list[BaseTool]: A list of tools available under the specified context."
    - signature: 'def get_tools_with_prefix(self, readonly_context: typing.Optional[google.adk.agents.readonly_context.ReadonlyContext]) -> list[google.adk.tools.base_tool.BaseTool]:'
      docstring: "Return all tools with optional prefix applied to tool names.\n\nThis method calls get_tools() and applies prefixing if tool_name_prefix is provided.\n\nArgs:\n  readonly_context (ReadonlyContext, optional): Context used to filter tools\n    available to the agent. If None, all tools in the toolset are returned.\n\nReturns:\n  list[BaseTool]: A list of tools with prefixed names if tool_name_prefix is provided."
    - signature: 'def close(self) -> None:'
      docstring: "Performs cleanup and releases resources held by the toolset.\n\nNOTE:\n  This method is invoked, for example, at the end of an agent server's\n  lifecycle or when the toolset is no longer needed. Implementations\n  should ensure that any open connections, files, or other managed\n  resources are properly released to prevent leaks."
    - signature: 'def from_config(cls: typing.Type[google.adk.tools.base_toolset.SelfToolset], config: google.adk.tools.tool_configs.ToolArgsConfig, config_abs_path: str) -> google.adk.tools.base_toolset.SelfToolset:'
      docstring: "Creates a toolset instance from a config.\n\nArgs:\n  config: The config for the tool.\n  config_abs_path: The absolute path to the config file that contains the\n    tool config.\n\nReturns:\n  The toolset instance."
    - signature: 'def process_llm_request(self, *, tool_context: google.adk.tools.tool_context.ToolContext, llm_request: google.adk.models.llm_request.LlmRequest) -> None:'
      docstring: "Processes the outgoing LLM request for this toolset. This method will be\ncalled before each tool processes the llm request.\n\nUse cases:\n- Instead of let each tool process the llm request, we can let the toolset\n  process the llm request. e.g. ComputerUseToolset can add computer use\n  tool to the llm request.\n\nArgs:\n  tool_context: The context of the tool.\n  llm_request: The outgoing LLM request, mutable this method."
  omitted_inherited_members_from:
  - ABC
- rank: 1655
  id: google.adk.tools.openapi_tool.openapi_spec_parser.openapi_toolset.OpenAPIToolset.__init__
  name: __init__
  file_path: google/adk/tools/openapi_tool/openapi_spec_parser/openapi_toolset.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Initializes the OpenAPIToolset.\n\nUsage::\n\n  # Initialize OpenAPI toolset from a spec string.\n  openapi_toolset = OpenAPIToolset(spec_str=openapi_spec_str,\n    spec_str_type=\"json\")\n  # Or, initialize OpenAPI toolset from a spec dictionary.\n  openapi_toolset = OpenAPIToolset(spec_dict=openapi_spec_dict)\n\n  # Add all tools to an agent.\n  agent = Agent(\n    tools=[*openapi_toolset.get_tools()]\n  )\n  # Or, add a single tool to an agent.\n  agent = Agent(\n    tools=[openapi_toolset.get_tool('tool_name')]\n  )\n\nArgs:\n  spec_dict: The OpenAPI spec dictionary. If provided, it will be used\n    instead of loading the spec from a string.\n  spec_str: The OpenAPI spec string in JSON or YAML format. It will be used\n    when spec_dict is not provided.\n  spec_str_type: The type of the OpenAPI spec string. Can be \"json\" or\n    \"yaml\".\n  auth_scheme: The auth scheme to use for all tools. Use AuthScheme or use\n    helpers in ``google.adk.tools.openapi_tool.auth.auth_helpers``\n\
    \  auth_credential: The auth credential to use for all tools. Use\n    AuthCredential or use helpers in\n    ``google.adk.tools.openapi_tool.auth.auth_helpers``\n  tool_filter: The filter used to filter the tools in the toolset. It can be\n    either a tool predicate or a list of tool names of the tools to expose."
  signature: 'def __init__(self, *, spec_dict: typing.Optional[typing.Dict[str, typing.Any]]=None, spec_str: typing.Optional[str]=None, spec_str_type: typing.Literal[json, yaml]=''json'', auth_scheme: typing.Optional[google.adk.auth.auth_schemes.AuthScheme]=None, auth_credential: typing.Optional[google.adk.auth.auth_credential.AuthCredential]=None, tool_filter: typing.Optional[typing.Union[google.adk.tools.base_toolset.ToolPredicate, typing.List[str]]]=None):'
- rank: 1656
  id: google.adk.tools.openapi_tool.openapi_spec_parser.openapi_toolset.OpenAPIToolset.get_tool
  name: get_tool
  file_path: google/adk/tools/openapi_tool/openapi_spec_parser/openapi_toolset.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: Get a tool by name.
  signature: 'def get_tool(self, tool_name: str) -> typing.Optional[google.adk.tools.openapi_tool.openapi_spec_parser.rest_api_tool.RestApiTool]:'
- rank: 1657
  id: google.adk.tools.openapi_tool.openapi_spec_parser.openapi_toolset.OpenAPIToolset.get_tools
  name: get_tools
  file_path: google/adk/tools/openapi_tool/openapi_spec_parser/openapi_toolset.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: Get all tools in the toolset.
  signature: 'def get_tools(self, readonly_context: typing.Optional[google.adk.agents.readonly_context.ReadonlyContext]) -> typing.List[google.adk.tools.openapi_tool.openapi_spec_parser.rest_api_tool.RestApiTool]:'
- rank: 1658
  id: google.adk.tools.openapi_tool.openapi_spec_parser.operation_parser
  name: operation_parser
  file_path: google/adk/tools/openapi_tool/openapi_spec_parser/operation_parser.py
  type: MODULE
  group: Orphan
  usage_score: 0
- rank: 1659
  id: google.adk.tools.openapi_tool.openapi_spec_parser.operation_parser.OperationParser
  name: OperationParser
  file_path: google/adk/tools/openapi_tool/openapi_spec_parser/operation_parser.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Generates parameters for Python functions from an OpenAPI operation.


    This class processes an OpenApiOperation object and provides helper methods

    to extract information needed to generate Python function declarations,

    docstrings, signatures, and JSON schemas.  It handles parameter processing,

    name deduplication, and type hint generation.'
  constructor_signature: 'def __init__(self, operation: typing.Union[fastapi.openapi.models.Operation, typing.Dict[str, typing.Any], str], should_parse):'
  aliases:
  - google.adk.tools.openapi_tool.openapi_spec_parser.OperationParser
  methods:
  - signature: 'def load(cls, operation: typing.Union[fastapi.openapi.models.Operation, typing.Dict[str, typing.Any]], params: typing.List[google.adk.tools.openapi_tool.common.common.ApiParameter], return_value: typing.Optional[google.adk.tools.openapi_tool.common.common.ApiParameter]) -> google.adk.tools.openapi_tool.openapi_spec_parser.operation_parser.OperationParser:'
  - signature: 'def get_function_name(self) -> str:'
    docstring: Returns the generated function name.
  - signature: 'def get_return_type_hint(self) -> str:'
    docstring: Returns the return type hint string (like 'str', 'int', etc.).
  - signature: 'def get_return_type_value(self) -> typing.Any:'
    docstring: Returns the return type value (like str, int, List[str], etc.).
  - signature: 'def get_parameters(self) -> typing.List[google.adk.tools.openapi_tool.common.common.ApiParameter]:'
    docstring: Returns the list of Parameter objects.
  - signature: 'def get_return_value(self) -> google.adk.tools.openapi_tool.common.common.ApiParameter:'
    docstring: Returns the list of Parameter objects.
  - signature: 'def get_auth_scheme_name(self) -> str:'
    docstring: Returns the name of the auth scheme for this operation from the spec.
  - signature: 'def get_pydoc_string(self) -> str:'
    docstring: Returns the generated PyDoc string.
  - signature: 'def get_json_schema(self) -> typing.Dict[str, typing.Any]:'
    docstring: Returns the JSON schema for the function arguments.
  - signature: 'def get_signature_parameters(self) -> typing.List[inspect.Parameter]:'
    docstring: Returns a list of inspect.Parameter objects for the function.
  - signature: 'def get_annotations(self) -> typing.Dict[str, typing.Any]:'
    docstring: Returns a dictionary of parameter annotations for the function.
- rank: 1660
  id: google.adk.tools.openapi_tool.openapi_spec_parser.operation_parser.OperationParser.__init__
  name: __init__
  file_path: google/adk/tools/openapi_tool/openapi_spec_parser/operation_parser.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Initializes the OperationParser with an OpenApiOperation.\n\nArgs:\n    operation: The OpenApiOperation object or a dictionary to process.\n    should_parse: Whether to parse the operation during initialization."
  signature: 'def __init__(self, operation: typing.Union[fastapi.openapi.models.Operation, typing.Dict[str, typing.Any], str], should_parse):'
- rank: 1661
  id: google.adk.tools.openapi_tool.openapi_spec_parser.operation_parser.OperationParser.get_annotations
  name: get_annotations
  file_path: google/adk/tools/openapi_tool/openapi_spec_parser/operation_parser.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: Returns a dictionary of parameter annotations for the function.
  signature: 'def get_annotations(self) -> typing.Dict[str, typing.Any]:'
- rank: 1662
  id: google.adk.tools.openapi_tool.openapi_spec_parser.operation_parser.OperationParser.get_auth_scheme_name
  name: get_auth_scheme_name
  file_path: google/adk/tools/openapi_tool/openapi_spec_parser/operation_parser.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: Returns the name of the auth scheme for this operation from the spec.
  signature: 'def get_auth_scheme_name(self) -> str:'
- rank: 1663
  id: google.adk.tools.openapi_tool.openapi_spec_parser.operation_parser.OperationParser.get_function_name
  name: get_function_name
  file_path: google/adk/tools/openapi_tool/openapi_spec_parser/operation_parser.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: Returns the generated function name.
  signature: 'def get_function_name(self) -> str:'
- rank: 1664
  id: google.adk.tools.openapi_tool.openapi_spec_parser.operation_parser.OperationParser.get_json_schema
  name: get_json_schema
  file_path: google/adk/tools/openapi_tool/openapi_spec_parser/operation_parser.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: Returns the JSON schema for the function arguments.
  signature: 'def get_json_schema(self) -> typing.Dict[str, typing.Any]:'
- rank: 1665
  id: google.adk.tools.openapi_tool.openapi_spec_parser.operation_parser.OperationParser.get_pydoc_string
  name: get_pydoc_string
  file_path: google/adk/tools/openapi_tool/openapi_spec_parser/operation_parser.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: Returns the generated PyDoc string.
  signature: 'def get_pydoc_string(self) -> str:'
- rank: 1666
  id: google.adk.tools.openapi_tool.openapi_spec_parser.operation_parser.OperationParser.get_signature_parameters
  name: get_signature_parameters
  file_path: google/adk/tools/openapi_tool/openapi_spec_parser/operation_parser.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: Returns a list of inspect.Parameter objects for the function.
  signature: 'def get_signature_parameters(self) -> typing.List[inspect.Parameter]:'
- rank: 1667
  id: google.adk.tools.openapi_tool.openapi_spec_parser.operation_parser.OperationParser.load
  name: load
  file_path: google/adk/tools/openapi_tool/openapi_spec_parser/operation_parser.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def load(cls, operation: typing.Union[fastapi.openapi.models.Operation, typing.Dict[str, typing.Any]], params: typing.List[google.adk.tools.openapi_tool.common.common.ApiParameter], return_value: typing.Optional[google.adk.tools.openapi_tool.common.common.ApiParameter]) -> google.adk.tools.openapi_tool.openapi_spec_parser.operation_parser.OperationParser:'
- rank: 1668
  id: google.adk.tools.openapi_tool.openapi_spec_parser.rest_api_tool
  name: rest_api_tool
  file_path: google/adk/tools/openapi_tool/openapi_spec_parser/rest_api_tool.py
  type: MODULE
  group: Orphan
  usage_score: 0
  methods:
  - signature: 'def snake_to_lower_camel(snake_case_string: str):'
    docstring: "Converts a snake_case string to a lower_camel_case string.\n\nArgs:\n    snake_case_string: The input snake_case string.\n\nReturns:\n    The lower_camel_case string."
- rank: 1669
  id: google.adk.tools.openapi_tool.openapi_spec_parser.rest_api_tool.RestApiTool
  name: RestApiTool
  file_path: google/adk/tools/openapi_tool/openapi_spec_parser/rest_api_tool.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: "A generic tool that interacts with a REST API.\n\n* Generates request params and body\n* Attaches auth credentials to API call.\n\nExample::\n\n  # Each API operation in the spec will be turned into its own tool\n  # Name of the tool is the operationId of that operation, in snake case\n  operations = OperationGenerator().parse(openapi_spec_dict)\n  tool = [RestApiTool.from_parsed_operation(o) for o in operations]\n\n[Note: Inherited members from ABC are omitted.]"
  constructor_signature: 'def __init__(self, name: str, description: str, endpoint: typing.Union[google.adk.tools.openapi_tool.openapi_spec_parser.openapi_spec_parser.OperationEndpoint, str], operation: typing.Union[fastapi.openapi.models.Operation, str], auth_scheme: typing.Optional[typing.Union[google.adk.auth.auth_schemes.AuthScheme, str]], auth_credential: typing.Optional[typing.Union[google.adk.auth.auth_credential.AuthCredential, str]], should_parse_operation):'
  aliases:
  - google.adk.tools.openapi_tool.openapi_spec_parser.RestApiTool
  methods:
  - signature: 'def from_parsed_operation(cls, parsed: google.adk.tools.openapi_tool.openapi_spec_parser.openapi_spec_parser.ParsedOperation) -> google.adk.tools.openapi_tool.openapi_spec_parser.rest_api_tool.RestApiTool:'
    docstring: "Initializes the RestApiTool from a ParsedOperation object.\n\nArgs:\n    parsed: A ParsedOperation object.\n\nReturns:\n    A RestApiTool object."
  - signature: 'def from_parsed_operation_str(cls, parsed_operation_str: str) -> google.adk.tools.openapi_tool.openapi_spec_parser.rest_api_tool.RestApiTool:'
    docstring: "Initializes the RestApiTool from a dict.\n\nArgs:\n    parsed: A dict representation of a ParsedOperation object.\n\nReturns:\n    A RestApiTool object."
  - signature: 'def configure_auth_scheme(self, auth_scheme: typing.Union[google.adk.auth.auth_schemes.AuthScheme, typing.Dict[str, typing.Any]]):'
    docstring: "Configures the authentication scheme for the API call.\n\nArgs:\n    auth_scheme: AuthScheme|dict -: The authentication scheme. The dict is\n      converted to a AuthScheme object."
  - signature: 'def configure_auth_credential(self, auth_credential: typing.Optional[typing.Union[google.adk.auth.auth_credential.AuthCredential, str]]):'
    docstring: "Configures the authentication credential for the API call.\n\nArgs:\n    auth_credential: AuthCredential|dict - The authentication credential.\n      The dict is converted to an AuthCredential object."
  - signature: 'def set_default_headers(self, headers: typing.Dict[str, str]):'
    docstring: Sets default headers that are merged into every request.
  - signature: 'def run_async(self, *, args: dict[str, typing.Any], tool_context: typing.Optional[google.adk.tools.tool_context.ToolContext]) -> typing.Dict[str, typing.Any]:'
  - signature: 'def call(self, *, args: dict[str, typing.Any], tool_context: typing.Optional[google.adk.tools.tool_context.ToolContext]) -> typing.Dict[str, typing.Any]:'
    docstring: "Executes the REST API call.\n\nArgs:\n    args: Keyword arguments representing the operation parameters.\n    tool_context: The tool context (not used here, but required by the\n      interface).\n\nReturns:\n    The API response as a dictionary."
  inherited_methods:
    BaseTool:
    - signature: 'def run_async(self, *, args: dict[str, typing.Any], tool_context: google.adk.tools.tool_context.ToolContext) -> typing.Any:'
      docstring: "Runs the tool with the given arguments and context.\n\nNOTE:\n  - Required if this tool needs to run at the client side.\n  - Otherwise, can be skipped, e.g. for a built-in GoogleSearch tool for\n    Gemini.\n\nArgs:\n  args: The LLM-filled arguments.\n  tool_context: The context of the tool.\n\nReturns:\n  The result of running the tool."
    - signature: 'def process_llm_request(self, *, tool_context: google.adk.tools.tool_context.ToolContext, llm_request: google.adk.models.llm_request.LlmRequest) -> None:'
      docstring: "Processes the outgoing LLM request for this tool.\n\nUse cases:\n- Most common use case is adding this tool to the LLM request.\n- Some tools may just preprocess the LLM request before it's sent out.\n\nArgs:\n  tool_context: The context of the tool.\n  llm_request: The outgoing LLM request, mutable this method."
    - signature: 'def from_config(cls: typing.Type[google.adk.tools.base_tool.SelfTool], config: google.adk.tools.tool_configs.ToolArgsConfig, config_abs_path: str) -> google.adk.tools.base_tool.SelfTool:'
      docstring: "Creates a tool instance from a config.\n\nThis default implementation uses inspect to automatically map config values\nto constructor arguments based on their type hints. Subclasses should\noverride this method for custom initialization logic.\n\nArgs:\n  config: The config for the tool.\n  config_abs_path: The absolute path to the config file that contains the\n    tool config.\n\nReturns:\n  The tool instance."
  inherited_properties:
    BaseTool:
    - signature: 'name: str'
      docstring: The name of the tool.
    - signature: 'description: str'
      docstring: The description of the tool.
    - signature: 'is_long_running: bool'
      docstring: 'Whether the tool is a long running operation, which typically returns a

        resource id first and finishes the operation later.'
    - signature: 'custom_metadata: typing.Optional[dict[str, typing.Any]]'
      docstring: 'The custom metadata of the BaseTool.


        An optional key-value pair for storing and retrieving tool-specific metadata,

        such as tool manifests, etc.


        NOTE: the entire dict must be JSON serializable.'
  omitted_inherited_members_from:
  - ABC
- rank: 1670
  id: google.adk.tools.openapi_tool.openapi_spec_parser.rest_api_tool.RestApiTool.__init__
  name: __init__
  file_path: google/adk/tools/openapi_tool/openapi_spec_parser/rest_api_tool.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Initializes the RestApiTool with the given parameters.\n\nTo generate RestApiTool from OpenAPI Specs, use OperationGenerator.\nExample::\n\n  # Each API operation in the spec will be turned into its own tool\n  # Name of the tool is the operationId of that operation, in snake case\n  operations = OperationGenerator().parse(openapi_spec_dict)\n  tool = [RestApiTool.from_parsed_operation(o) for o in operations]\n\nHint: Use google.adk.tools.openapi_tool.auth.auth_helpers to construct\nauth_scheme and auth_credential.\n\nArgs:\n    name: The name of the tool.\n    description: The description of the tool.\n    endpoint: Include the base_url, path, and method of the tool.\n    operation: Pydantic object or a dict. Representing the OpenAPI Operation\n      object\n      (https://github.com/OAI/OpenAPI-Specification/blob/main/versions/3.1.0.md#operation-object)\n    auth_scheme: The auth scheme of the tool. Representing the OpenAPI\n      SecurityScheme object\n      (https://github.com/OAI/OpenAPI-Specification/blob/main/versions/3.1.0.md#security-scheme-object)\n\
    \    auth_credential: The authentication credential of the tool.\n    should_parse_operation: Whether to parse the operation."
  signature: 'def __init__(self, name: str, description: str, endpoint: typing.Union[google.adk.tools.openapi_tool.openapi_spec_parser.openapi_spec_parser.OperationEndpoint, str], operation: typing.Union[fastapi.openapi.models.Operation, str], auth_scheme: typing.Optional[typing.Union[google.adk.auth.auth_schemes.AuthScheme, str]], auth_credential: typing.Optional[typing.Union[google.adk.auth.auth_credential.AuthCredential, str]], should_parse_operation):'
- rank: 1671
  id: google.adk.tools.openapi_tool.openapi_spec_parser.rest_api_tool.RestApiTool.call
  name: call
  file_path: google/adk/tools/openapi_tool/openapi_spec_parser/rest_api_tool.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Executes the REST API call.\n\nArgs:\n    args: Keyword arguments representing the operation parameters.\n    tool_context: The tool context (not used here, but required by the\n      interface).\n\nReturns:\n    The API response as a dictionary."
  signature: 'def call(self, *, args: dict[str, typing.Any], tool_context: typing.Optional[google.adk.tools.tool_context.ToolContext]) -> typing.Dict[str, typing.Any]:'
- rank: 1672
  id: google.adk.tools.openapi_tool.openapi_spec_parser.rest_api_tool.RestApiTool.configure_auth_credential
  name: configure_auth_credential
  file_path: google/adk/tools/openapi_tool/openapi_spec_parser/rest_api_tool.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Configures the authentication credential for the API call.\n\nArgs:\n    auth_credential: AuthCredential|dict - The authentication credential.\n      The dict is converted to an AuthCredential object."
  signature: 'def configure_auth_credential(self, auth_credential: typing.Optional[typing.Union[google.adk.auth.auth_credential.AuthCredential, str]]):'
- rank: 1673
  id: google.adk.tools.openapi_tool.openapi_spec_parser.rest_api_tool.RestApiTool.configure_auth_scheme
  name: configure_auth_scheme
  file_path: google/adk/tools/openapi_tool/openapi_spec_parser/rest_api_tool.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Configures the authentication scheme for the API call.\n\nArgs:\n    auth_scheme: AuthScheme|dict -: The authentication scheme. The dict is\n      converted to a AuthScheme object."
  signature: 'def configure_auth_scheme(self, auth_scheme: typing.Union[google.adk.auth.auth_schemes.AuthScheme, typing.Dict[str, typing.Any]]):'
- rank: 1674
  id: google.adk.tools.openapi_tool.openapi_spec_parser.rest_api_tool.RestApiTool.from_parsed_operation
  name: from_parsed_operation
  file_path: google/adk/tools/openapi_tool/openapi_spec_parser/rest_api_tool.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Initializes the RestApiTool from a ParsedOperation object.\n\nArgs:\n    parsed: A ParsedOperation object.\n\nReturns:\n    A RestApiTool object."
  signature: 'def from_parsed_operation(cls, parsed: google.adk.tools.openapi_tool.openapi_spec_parser.openapi_spec_parser.ParsedOperation) -> google.adk.tools.openapi_tool.openapi_spec_parser.rest_api_tool.RestApiTool:'
- rank: 1675
  id: google.adk.tools.openapi_tool.openapi_spec_parser.rest_api_tool.RestApiTool.from_parsed_operation_str
  name: from_parsed_operation_str
  file_path: google/adk/tools/openapi_tool/openapi_spec_parser/rest_api_tool.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Initializes the RestApiTool from a dict.\n\nArgs:\n    parsed: A dict representation of a ParsedOperation object.\n\nReturns:\n    A RestApiTool object."
  signature: 'def from_parsed_operation_str(cls, parsed_operation_str: str) -> google.adk.tools.openapi_tool.openapi_spec_parser.rest_api_tool.RestApiTool:'
- rank: 1676
  id: google.adk.tools.openapi_tool.openapi_spec_parser.rest_api_tool.RestApiTool.run_async
  name: run_async
  file_path: google/adk/tools/openapi_tool/openapi_spec_parser/rest_api_tool.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def run_async(self, *, args: dict[str, typing.Any], tool_context: typing.Optional[google.adk.tools.tool_context.ToolContext]) -> typing.Dict[str, typing.Any]:'
- rank: 1677
  id: google.adk.tools.openapi_tool.openapi_spec_parser.rest_api_tool.snake_to_lower_camel
  name: snake_to_lower_camel
  file_path: google/adk/tools/openapi_tool/openapi_spec_parser/rest_api_tool.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Converts a snake_case string to a lower_camel_case string.\n\nArgs:\n    snake_case_string: The input snake_case string.\n\nReturns:\n    The lower_camel_case string."
  signature: 'def snake_to_lower_camel(snake_case_string: str):'
  aliases:
  - google.adk.tools.openapi_tool.openapi_spec_parser.snake_to_lower_camel
- rank: 1678
  id: google.adk.tools.openapi_tool.openapi_spec_parser.tool_auth_handler
  name: tool_auth_handler
  file_path: google/adk/tools/openapi_tool/openapi_spec_parser/tool_auth_handler.py
  type: MODULE
  group: Orphan
  usage_score: 0
- rank: 1679
  id: google.adk.tools.openapi_tool.openapi_spec_parser.tool_auth_handler.AuthPreparationResult
  name: AuthPreparationResult
  file_path: google/adk/tools/openapi_tool/openapi_spec_parser/tool_auth_handler.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Result of the credential preparation process.


    [Note: Inherited members from pydantic.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, state: google.adk.tools.openapi_tool.openapi_spec_parser.tool_auth_handler.AuthPreparationState, auth_scheme: typing.Optional[google.adk.auth.auth_schemes.AuthScheme] = None, auth_credential: typing.Optional[google.adk.auth.auth_credential.AuthCredential] = None):'
  properties:
  - signature: 'state: google.adk.tools.openapi_tool.openapi_spec_parser.tool_auth_handler.AuthPreparationState'
  - signature: 'auth_scheme: typing.Optional[google.adk.auth.auth_schemes.AuthScheme]'
  - signature: 'auth_credential: typing.Optional[google.adk.auth.auth_credential.AuthCredential]'
  inherited_properties:
    BaseModel:
    - signature: 'model_config: pydantic.ConfigDict'
  omitted_inherited_members_from:
  - pydantic.BaseModel
- rank: 1680
  id: google.adk.tools.openapi_tool.openapi_spec_parser.tool_auth_handler.ToolAuthHandler
  name: ToolAuthHandler
  file_path: google/adk/tools/openapi_tool/openapi_spec_parser/tool_auth_handler.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: Handles the preparation and exchange of authentication credentials for tools.
  constructor_signature: 'def __init__(self, tool_context: google.adk.tools.tool_context.ToolContext, auth_scheme: typing.Optional[google.adk.auth.auth_schemes.AuthScheme], auth_credential: typing.Optional[google.adk.auth.auth_credential.AuthCredential], credential_exchanger: typing.Optional[google.adk.tools.openapi_tool.auth.credential_exchangers.base_credential_exchanger.BaseAuthCredentialExchanger], credential_store: typing.Optional[google.adk.tools.openapi_tool.openapi_spec_parser.tool_auth_handler.ToolContextCredentialStore]):'
  methods:
  - signature: 'def from_tool_context(cls, tool_context: google.adk.tools.tool_context.ToolContext, auth_scheme: typing.Optional[google.adk.auth.auth_schemes.AuthScheme], auth_credential: typing.Optional[google.adk.auth.auth_credential.AuthCredential], credential_exchanger: typing.Optional[google.adk.tools.openapi_tool.auth.credential_exchangers.base_credential_exchanger.BaseAuthCredentialExchanger]) -> google.adk.tools.openapi_tool.openapi_spec_parser.tool_auth_handler.ToolAuthHandler:'
    docstring: Creates a ToolAuthHandler instance from a ToolContext.
  - signature: 'def prepare_auth_credentials(self) -> google.adk.tools.openapi_tool.openapi_spec_parser.tool_auth_handler.AuthPreparationResult:'
    docstring: Prepares authentication credentials, handling exchange and user interaction.
- rank: 1681
  id: google.adk.tools.openapi_tool.openapi_spec_parser.tool_auth_handler.ToolAuthHandler.__init__
  name: __init__
  file_path: google/adk/tools/openapi_tool/openapi_spec_parser/tool_auth_handler.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def __init__(self, tool_context: google.adk.tools.tool_context.ToolContext, auth_scheme: typing.Optional[google.adk.auth.auth_schemes.AuthScheme], auth_credential: typing.Optional[google.adk.auth.auth_credential.AuthCredential], credential_exchanger: typing.Optional[google.adk.tools.openapi_tool.auth.credential_exchangers.base_credential_exchanger.BaseAuthCredentialExchanger], credential_store: typing.Optional[google.adk.tools.openapi_tool.openapi_spec_parser.tool_auth_handler.ToolContextCredentialStore]):'
- rank: 1682
  id: google.adk.tools.openapi_tool.openapi_spec_parser.tool_auth_handler.ToolAuthHandler.from_tool_context
  name: from_tool_context
  file_path: google/adk/tools/openapi_tool/openapi_spec_parser/tool_auth_handler.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: Creates a ToolAuthHandler instance from a ToolContext.
  signature: 'def from_tool_context(cls, tool_context: google.adk.tools.tool_context.ToolContext, auth_scheme: typing.Optional[google.adk.auth.auth_schemes.AuthScheme], auth_credential: typing.Optional[google.adk.auth.auth_credential.AuthCredential], credential_exchanger: typing.Optional[google.adk.tools.openapi_tool.auth.credential_exchangers.base_credential_exchanger.BaseAuthCredentialExchanger]) -> google.adk.tools.openapi_tool.openapi_spec_parser.tool_auth_handler.ToolAuthHandler:'
- rank: 1683
  id: google.adk.tools.openapi_tool.openapi_spec_parser.tool_auth_handler.ToolAuthHandler.prepare_auth_credentials
  name: prepare_auth_credentials
  file_path: google/adk/tools/openapi_tool/openapi_spec_parser/tool_auth_handler.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: Prepares authentication credentials, handling exchange and user interaction.
  signature: 'def prepare_auth_credentials(self) -> google.adk.tools.openapi_tool.openapi_spec_parser.tool_auth_handler.AuthPreparationResult:'
- rank: 1684
  id: google.adk.tools.openapi_tool.openapi_spec_parser.tool_auth_handler.ToolContextCredentialStore
  name: ToolContextCredentialStore
  file_path: google/adk/tools/openapi_tool/openapi_spec_parser/tool_auth_handler.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: Handles storage and retrieval of credentials within a ToolContext.
  constructor_signature: 'def __init__(self, tool_context: google.adk.tools.tool_context.ToolContext):'
  methods:
  - signature: 'def get_credential_key(self, auth_scheme: typing.Optional[google.adk.auth.auth_schemes.AuthScheme], auth_credential: typing.Optional[google.adk.auth.auth_credential.AuthCredential]) -> str:'
    docstring: Generates a unique key for the given auth scheme and credential.
  - signature: 'def get_credential(self, auth_scheme: typing.Optional[google.adk.auth.auth_schemes.AuthScheme], auth_credential: typing.Optional[google.adk.auth.auth_credential.AuthCredential]) -> typing.Optional[google.adk.auth.auth_credential.AuthCredential]:'
  - signature: 'def store_credential(self, key: str, auth_credential: typing.Optional[google.adk.auth.auth_credential.AuthCredential]):'
  - signature: 'def remove_credential(self, key: str):'
- rank: 1685
  id: google.adk.tools.openapi_tool.openapi_spec_parser.tool_auth_handler.ToolContextCredentialStore.get_credential
  name: get_credential
  file_path: google/adk/tools/openapi_tool/openapi_spec_parser/tool_auth_handler.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def get_credential(self, auth_scheme: typing.Optional[google.adk.auth.auth_schemes.AuthScheme], auth_credential: typing.Optional[google.adk.auth.auth_credential.AuthCredential]) -> typing.Optional[google.adk.auth.auth_credential.AuthCredential]:'
- rank: 1686
  id: google.adk.tools.openapi_tool.openapi_spec_parser.tool_auth_handler.ToolContextCredentialStore.get_credential_key
  name: get_credential_key
  file_path: google/adk/tools/openapi_tool/openapi_spec_parser/tool_auth_handler.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: Generates a unique key for the given auth scheme and credential.
  signature: 'def get_credential_key(self, auth_scheme: typing.Optional[google.adk.auth.auth_schemes.AuthScheme], auth_credential: typing.Optional[google.adk.auth.auth_credential.AuthCredential]) -> str:'
- rank: 1687
  id: google.adk.tools.openapi_tool.openapi_spec_parser.tool_auth_handler.ToolContextCredentialStore.store_credential
  name: store_credential
  file_path: google/adk/tools/openapi_tool/openapi_spec_parser/tool_auth_handler.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def store_credential(self, key: str, auth_credential: typing.Optional[google.adk.auth.auth_credential.AuthCredential]):'
- rank: 1688
  id: google.adk.tools.preload_memory_tool
  name: preload_memory_tool
  file_path: google/adk/tools/preload_memory_tool.py
  type: MODULE
  group: Orphan
  usage_score: 0
- rank: 1689
  id: google.adk.tools.preload_memory_tool.PreloadMemoryTool
  name: PreloadMemoryTool
  file_path: google/adk/tools/preload_memory_tool.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'A tool that preloads the memory for the current user.


    This tool will be automatically executed for each llm_request, and it won''t be

    called by the model.


    NOTE: Currently this tool only uses text part from the memory.


    [Note: Inherited members from ABC are omitted.]'
  constructor_signature: 'def __init__(self):'
  methods:
  - signature: 'def process_llm_request(self, *, tool_context: google.adk.tools.tool_context.ToolContext, llm_request: google.adk.models.LlmRequest) -> None:'
  inherited_methods:
    BaseTool:
    - signature: 'def run_async(self, *, args: dict[str, typing.Any], tool_context: google.adk.tools.tool_context.ToolContext) -> typing.Any:'
      docstring: "Runs the tool with the given arguments and context.\n\nNOTE:\n  - Required if this tool needs to run at the client side.\n  - Otherwise, can be skipped, e.g. for a built-in GoogleSearch tool for\n    Gemini.\n\nArgs:\n  args: The LLM-filled arguments.\n  tool_context: The context of the tool.\n\nReturns:\n  The result of running the tool."
    - signature: 'def process_llm_request(self, *, tool_context: google.adk.tools.tool_context.ToolContext, llm_request: google.adk.models.llm_request.LlmRequest) -> None:'
      docstring: "Processes the outgoing LLM request for this tool.\n\nUse cases:\n- Most common use case is adding this tool to the LLM request.\n- Some tools may just preprocess the LLM request before it's sent out.\n\nArgs:\n  tool_context: The context of the tool.\n  llm_request: The outgoing LLM request, mutable this method."
    - signature: 'def from_config(cls: typing.Type[google.adk.tools.base_tool.SelfTool], config: google.adk.tools.tool_configs.ToolArgsConfig, config_abs_path: str) -> google.adk.tools.base_tool.SelfTool:'
      docstring: "Creates a tool instance from a config.\n\nThis default implementation uses inspect to automatically map config values\nto constructor arguments based on their type hints. Subclasses should\noverride this method for custom initialization logic.\n\nArgs:\n  config: The config for the tool.\n  config_abs_path: The absolute path to the config file that contains the\n    tool config.\n\nReturns:\n  The tool instance."
  inherited_properties:
    BaseTool:
    - signature: 'name: str'
      docstring: The name of the tool.
    - signature: 'description: str'
      docstring: The description of the tool.
    - signature: 'is_long_running: bool'
      docstring: 'Whether the tool is a long running operation, which typically returns a

        resource id first and finishes the operation later.'
    - signature: 'custom_metadata: typing.Optional[dict[str, typing.Any]]'
      docstring: 'The custom metadata of the BaseTool.


        An optional key-value pair for storing and retrieving tool-specific metadata,

        such as tool manifests, etc.


        NOTE: the entire dict must be JSON serializable.'
  omitted_inherited_members_from:
  - ABC
- rank: 1690
  id: google.adk.tools.preload_memory_tool.PreloadMemoryTool.__init__
  name: __init__
  file_path: google/adk/tools/preload_memory_tool.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def __init__(self):'
- rank: 1691
  id: google.adk.tools.preload_memory_tool.PreloadMemoryTool.process_llm_request
  name: process_llm_request
  file_path: google/adk/tools/preload_memory_tool.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def process_llm_request(self, *, tool_context: google.adk.tools.tool_context.ToolContext, llm_request: google.adk.models.LlmRequest) -> None:'
- rank: 1692
  id: google.adk.tools.retrieval
  name: retrieval
  file_path: google/adk/tools/retrieval/__init__.py
  type: MODULE
  group: Orphan
  usage_score: 0
- rank: 1693
  id: google.adk.tools.retrieval.base_retrieval_tool
  name: base_retrieval_tool
  file_path: google/adk/tools/retrieval/base_retrieval_tool.py
  type: MODULE
  group: Orphan
  usage_score: 0
- rank: 1694
  id: google.adk.tools.retrieval.base_retrieval_tool.BaseRetrievalTool
  name: BaseRetrievalTool
  file_path: google/adk/tools/retrieval/base_retrieval_tool.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: '[Note: Inherited members from ABC are omitted.]'
  constructor_signature: 'def __init__(self, *, name, description, is_long_running: bool=False, custom_metadata: typing.Optional[dict[str, typing.Any]]=None):'
  inherited_methods:
    BaseTool:
    - signature: 'def run_async(self, *, args: dict[str, typing.Any], tool_context: google.adk.tools.tool_context.ToolContext) -> typing.Any:'
      docstring: "Runs the tool with the given arguments and context.\n\nNOTE:\n  - Required if this tool needs to run at the client side.\n  - Otherwise, can be skipped, e.g. for a built-in GoogleSearch tool for\n    Gemini.\n\nArgs:\n  args: The LLM-filled arguments.\n  tool_context: The context of the tool.\n\nReturns:\n  The result of running the tool."
    - signature: 'def process_llm_request(self, *, tool_context: google.adk.tools.tool_context.ToolContext, llm_request: google.adk.models.llm_request.LlmRequest) -> None:'
      docstring: "Processes the outgoing LLM request for this tool.\n\nUse cases:\n- Most common use case is adding this tool to the LLM request.\n- Some tools may just preprocess the LLM request before it's sent out.\n\nArgs:\n  tool_context: The context of the tool.\n  llm_request: The outgoing LLM request, mutable this method."
    - signature: 'def from_config(cls: typing.Type[google.adk.tools.base_tool.SelfTool], config: google.adk.tools.tool_configs.ToolArgsConfig, config_abs_path: str) -> google.adk.tools.base_tool.SelfTool:'
      docstring: "Creates a tool instance from a config.\n\nThis default implementation uses inspect to automatically map config values\nto constructor arguments based on their type hints. Subclasses should\noverride this method for custom initialization logic.\n\nArgs:\n  config: The config for the tool.\n  config_abs_path: The absolute path to the config file that contains the\n    tool config.\n\nReturns:\n  The tool instance."
  inherited_properties:
    BaseTool:
    - signature: 'name: str'
      docstring: The name of the tool.
    - signature: 'description: str'
      docstring: The description of the tool.
    - signature: 'is_long_running: bool'
      docstring: 'Whether the tool is a long running operation, which typically returns a

        resource id first and finishes the operation later.'
    - signature: 'custom_metadata: typing.Optional[dict[str, typing.Any]]'
      docstring: 'The custom metadata of the BaseTool.


        An optional key-value pair for storing and retrieving tool-specific metadata,

        such as tool manifests, etc.


        NOTE: the entire dict must be JSON serializable.'
  omitted_inherited_members_from:
  - ABC
- rank: 1695
  id: google.adk.tools.retrieval.files_retrieval
  name: files_retrieval
  file_path: google/adk/tools/retrieval/files_retrieval.py
  type: MODULE
  group: Orphan
  usage_score: 0
  docstring: Provides data for the agent.
- rank: 1696
  id: google.adk.tools.retrieval.files_retrieval.FilesRetrieval
  name: FilesRetrieval
  file_path: google/adk/tools/retrieval/files_retrieval.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: '[Note: Inherited members from ABC are omitted.]'
  constructor_signature: 'def __init__(self, *, name: str, description: str, input_dir: str, embedding_model: typing.Optional[llama_index.core.base.embeddings.base.BaseEmbedding]=None):'
  aliases:
  - google.adk.tools.retrieval.FilesRetrieval
  inherited_methods:
    LlamaIndexRetrieval:
    - signature: 'def run_async(self, *, args: dict[str, typing.Any], tool_context: google.adk.tools.tool_context.ToolContext) -> typing.Any:'
    BaseTool:
    - signature: 'def run_async(self, *, args: dict[str, typing.Any], tool_context: google.adk.tools.tool_context.ToolContext) -> typing.Any:'
      docstring: "Runs the tool with the given arguments and context.\n\nNOTE:\n  - Required if this tool needs to run at the client side.\n  - Otherwise, can be skipped, e.g. for a built-in GoogleSearch tool for\n    Gemini.\n\nArgs:\n  args: The LLM-filled arguments.\n  tool_context: The context of the tool.\n\nReturns:\n  The result of running the tool."
    - signature: 'def process_llm_request(self, *, tool_context: google.adk.tools.tool_context.ToolContext, llm_request: google.adk.models.llm_request.LlmRequest) -> None:'
      docstring: "Processes the outgoing LLM request for this tool.\n\nUse cases:\n- Most common use case is adding this tool to the LLM request.\n- Some tools may just preprocess the LLM request before it's sent out.\n\nArgs:\n  tool_context: The context of the tool.\n  llm_request: The outgoing LLM request, mutable this method."
    - signature: 'def from_config(cls: typing.Type[google.adk.tools.base_tool.SelfTool], config: google.adk.tools.tool_configs.ToolArgsConfig, config_abs_path: str) -> google.adk.tools.base_tool.SelfTool:'
      docstring: "Creates a tool instance from a config.\n\nThis default implementation uses inspect to automatically map config values\nto constructor arguments based on their type hints. Subclasses should\noverride this method for custom initialization logic.\n\nArgs:\n  config: The config for the tool.\n  config_abs_path: The absolute path to the config file that contains the\n    tool config.\n\nReturns:\n  The tool instance."
  inherited_properties:
    BaseTool:
    - signature: 'name: str'
      docstring: The name of the tool.
    - signature: 'description: str'
      docstring: The description of the tool.
    - signature: 'is_long_running: bool'
      docstring: 'Whether the tool is a long running operation, which typically returns a

        resource id first and finishes the operation later.'
    - signature: 'custom_metadata: typing.Optional[dict[str, typing.Any]]'
      docstring: 'The custom metadata of the BaseTool.


        An optional key-value pair for storing and retrieving tool-specific metadata,

        such as tool manifests, etc.


        NOTE: the entire dict must be JSON serializable.'
  omitted_inherited_members_from:
  - ABC
- rank: 1697
  id: google.adk.tools.retrieval.files_retrieval.FilesRetrieval.__init__
  name: __init__
  file_path: google/adk/tools/retrieval/files_retrieval.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Initialize FilesRetrieval with optional embedding model.\n\nArgs:\n  name: Name of the tool.\n  description: Description of the tool.\n  input_dir: Directory path containing files to index.\n  embedding_model: Optional custom embedding model. If None, defaults to\n    Google's text-embedding-004 model."
  signature: 'def __init__(self, *, name: str, description: str, input_dir: str, embedding_model: typing.Optional[llama_index.core.base.embeddings.base.BaseEmbedding]=None):'
- rank: 1698
  id: google.adk.tools.retrieval.llama_index_retrieval
  name: llama_index_retrieval
  file_path: google/adk/tools/retrieval/llama_index_retrieval.py
  type: MODULE
  group: Orphan
  usage_score: 0
  docstring: Provides data for the agent.
- rank: 1699
  id: google.adk.tools.retrieval.llama_index_retrieval.LlamaIndexRetrieval
  name: LlamaIndexRetrieval
  file_path: google/adk/tools/retrieval/llama_index_retrieval.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: '[Note: Inherited members from ABC are omitted.]'
  constructor_signature: 'def __init__(self, *, name: str, description: str, retriever: llama_index.core.base.base_retriever.BaseRetriever):'
  aliases:
  - google.adk.tools.retrieval.LlamaIndexRetrieval
  methods:
  - signature: 'def run_async(self, *, args: dict[str, typing.Any], tool_context: google.adk.tools.tool_context.ToolContext) -> typing.Any:'
  inherited_methods:
    BaseTool:
    - signature: 'def run_async(self, *, args: dict[str, typing.Any], tool_context: google.adk.tools.tool_context.ToolContext) -> typing.Any:'
      docstring: "Runs the tool with the given arguments and context.\n\nNOTE:\n  - Required if this tool needs to run at the client side.\n  - Otherwise, can be skipped, e.g. for a built-in GoogleSearch tool for\n    Gemini.\n\nArgs:\n  args: The LLM-filled arguments.\n  tool_context: The context of the tool.\n\nReturns:\n  The result of running the tool."
    - signature: 'def process_llm_request(self, *, tool_context: google.adk.tools.tool_context.ToolContext, llm_request: google.adk.models.llm_request.LlmRequest) -> None:'
      docstring: "Processes the outgoing LLM request for this tool.\n\nUse cases:\n- Most common use case is adding this tool to the LLM request.\n- Some tools may just preprocess the LLM request before it's sent out.\n\nArgs:\n  tool_context: The context of the tool.\n  llm_request: The outgoing LLM request, mutable this method."
    - signature: 'def from_config(cls: typing.Type[google.adk.tools.base_tool.SelfTool], config: google.adk.tools.tool_configs.ToolArgsConfig, config_abs_path: str) -> google.adk.tools.base_tool.SelfTool:'
      docstring: "Creates a tool instance from a config.\n\nThis default implementation uses inspect to automatically map config values\nto constructor arguments based on their type hints. Subclasses should\noverride this method for custom initialization logic.\n\nArgs:\n  config: The config for the tool.\n  config_abs_path: The absolute path to the config file that contains the\n    tool config.\n\nReturns:\n  The tool instance."
  inherited_properties:
    BaseTool:
    - signature: 'name: str'
      docstring: The name of the tool.
    - signature: 'description: str'
      docstring: The description of the tool.
    - signature: 'is_long_running: bool'
      docstring: 'Whether the tool is a long running operation, which typically returns a

        resource id first and finishes the operation later.'
    - signature: 'custom_metadata: typing.Optional[dict[str, typing.Any]]'
      docstring: 'The custom metadata of the BaseTool.


        An optional key-value pair for storing and retrieving tool-specific metadata,

        such as tool manifests, etc.


        NOTE: the entire dict must be JSON serializable.'
  omitted_inherited_members_from:
  - ABC
- rank: 1700
  id: google.adk.tools.retrieval.llama_index_retrieval.LlamaIndexRetrieval.run_async
  name: run_async
  file_path: google/adk/tools/retrieval/llama_index_retrieval.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def run_async(self, *, args: dict[str, typing.Any], tool_context: google.adk.tools.tool_context.ToolContext) -> typing.Any:'
- rank: 1701
  id: google.adk.tools.retrieval.vertex_ai_rag_retrieval
  name: vertex_ai_rag_retrieval
  file_path: google/adk/tools/retrieval/vertex_ai_rag_retrieval.py
  type: MODULE
  group: Orphan
  usage_score: 0
  docstring: A retrieval tool that uses Vertex AI RAG to retrieve data.
- rank: 1702
  id: google.adk.tools.retrieval.vertex_ai_rag_retrieval.VertexAiRagRetrieval.__init__
  name: __init__
  file_path: google/adk/tools/retrieval/vertex_ai_rag_retrieval.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def __init__(self, *, name: str, description: str, rag_corpora: list[str]=None, rag_resources: list[google.adk.dependencies.vertexai.rag.RagResource]=None, similarity_top_k: int=None, vector_distance_threshold: float=None):'
- rank: 1703
  id: google.adk.tools.retrieval.vertex_ai_rag_retrieval.VertexAiRagRetrieval.process_llm_request
  name: process_llm_request
  file_path: google/adk/tools/retrieval/vertex_ai_rag_retrieval.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def process_llm_request(self, *, tool_context: google.adk.tools.tool_context.ToolContext, llm_request: google.adk.models.LlmRequest) -> None:'
- rank: 1704
  id: google.adk.tools.retrieval.vertex_ai_rag_retrieval.VertexAiRagRetrieval.run_async
  name: run_async
  file_path: google/adk/tools/retrieval/vertex_ai_rag_retrieval.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def run_async(self, *, args: dict[str, typing.Any], tool_context: google.adk.tools.tool_context.ToolContext) -> typing.Any:'
- rank: 1705
  id: google.adk.tools.set_model_response_tool
  name: set_model_response_tool
  file_path: google/adk/tools/set_model_response_tool.py
  type: MODULE
  group: Orphan
  usage_score: 0
  docstring: Tool for setting model response when using output_schema with other tools.
- rank: 1706
  id: google.adk.tools.set_model_response_tool.SetModelResponseTool
  name: SetModelResponseTool
  file_path: google/adk/tools/set_model_response_tool.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Internal tool used for output schema workaround.


    This tool allows the model to set its final response when output_schema

    is configured alongside other tools. The model should use this tool to

    provide its final structured response instead of outputting text directly.


    [Note: Inherited members from ABC are omitted.]'
  constructor_signature: 'def __init__(self, output_schema: type[pydantic.BaseModel]):'
  methods:
  - signature: 'def set_model_response() -> str:'
    docstring: 'Set your final response using the required output schema.


      Use this tool to provide your final structured answer instead

      of outputting text directly.'
  - signature: 'def run_async(self, *, args: dict[str, typing.Any], tool_context: google.adk.tools.tool_context.ToolContext) -> dict[str, typing.Any]:'
    docstring: "Process the model's response and return the validated dict.\n\nArgs:\n  args: The structured response data matching the output schema.\n  tool_context: Tool execution context.\n\nReturns:\n  The validated response as dict."
  inherited_methods:
    BaseTool:
    - signature: 'def run_async(self, *, args: dict[str, typing.Any], tool_context: google.adk.tools.tool_context.ToolContext) -> typing.Any:'
      docstring: "Runs the tool with the given arguments and context.\n\nNOTE:\n  - Required if this tool needs to run at the client side.\n  - Otherwise, can be skipped, e.g. for a built-in GoogleSearch tool for\n    Gemini.\n\nArgs:\n  args: The LLM-filled arguments.\n  tool_context: The context of the tool.\n\nReturns:\n  The result of running the tool."
    - signature: 'def process_llm_request(self, *, tool_context: google.adk.tools.tool_context.ToolContext, llm_request: google.adk.models.llm_request.LlmRequest) -> None:'
      docstring: "Processes the outgoing LLM request for this tool.\n\nUse cases:\n- Most common use case is adding this tool to the LLM request.\n- Some tools may just preprocess the LLM request before it's sent out.\n\nArgs:\n  tool_context: The context of the tool.\n  llm_request: The outgoing LLM request, mutable this method."
    - signature: 'def from_config(cls: typing.Type[google.adk.tools.base_tool.SelfTool], config: google.adk.tools.tool_configs.ToolArgsConfig, config_abs_path: str) -> google.adk.tools.base_tool.SelfTool:'
      docstring: "Creates a tool instance from a config.\n\nThis default implementation uses inspect to automatically map config values\nto constructor arguments based on their type hints. Subclasses should\noverride this method for custom initialization logic.\n\nArgs:\n  config: The config for the tool.\n  config_abs_path: The absolute path to the config file that contains the\n    tool config.\n\nReturns:\n  The tool instance."
  inherited_properties:
    BaseTool:
    - signature: 'name: str'
      docstring: The name of the tool.
    - signature: 'description: str'
      docstring: The description of the tool.
    - signature: 'is_long_running: bool'
      docstring: 'Whether the tool is a long running operation, which typically returns a

        resource id first and finishes the operation later.'
    - signature: 'custom_metadata: typing.Optional[dict[str, typing.Any]]'
      docstring: 'The custom metadata of the BaseTool.


        An optional key-value pair for storing and retrieving tool-specific metadata,

        such as tool manifests, etc.


        NOTE: the entire dict must be JSON serializable.'
  omitted_inherited_members_from:
  - ABC
- rank: 1707
  id: google.adk.tools.set_model_response_tool.SetModelResponseTool.__init__
  name: __init__
  file_path: google/adk/tools/set_model_response_tool.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Initialize the tool with the expected output schema.\n\nArgs:\n  output_schema: The pydantic model class defining the expected output\n    structure."
  signature: 'def __init__(self, output_schema: type[pydantic.BaseModel]):'
- rank: 1708
  id: google.adk.tools.set_model_response_tool.SetModelResponseTool.run_async
  name: run_async
  file_path: google/adk/tools/set_model_response_tool.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Process the model's response and return the validated dict.\n\nArgs:\n  args: The structured response data matching the output schema.\n  tool_context: Tool execution context.\n\nReturns:\n  The validated response as dict."
  signature: 'def run_async(self, *, args: dict[str, typing.Any], tool_context: google.adk.tools.tool_context.ToolContext) -> dict[str, typing.Any]:'
- rank: 1709
  id: google.adk.tools.set_model_response_tool.SetModelResponseTool.set_model_response
  name: set_model_response
  file_path: google/adk/tools/set_model_response_tool.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: 'Set your final response using the required output schema.


    Use this tool to provide your final structured answer instead

    of outputting text directly.'
  signature: 'def set_model_response() -> str:'
- rank: 1710
  id: google.adk.tools.tool_configs
  name: tool_configs
  file_path: google/adk/tools/tool_configs.py
  type: MODULE
  group: Orphan
  usage_score: 0
- rank: 1711
  id: google.adk.tools.tool_configs.BaseToolConfig
  name: BaseToolConfig
  file_path: google/adk/tools/tool_configs.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'The base class for all tool configs.


    [Note: Inherited members from pydantic.BaseModel are omitted.]'
  properties:
  - signature: 'model_config: pydantic.ConfigDict'
  inherited_properties:
    BaseModel:
    - signature: 'model_config: pydantic.ConfigDict'
  omitted_inherited_members_from:
  - pydantic.BaseModel
- rank: 1712
  id: google.adk.tools.tool_configs.ToolArgsConfig
  name: ToolArgsConfig
  file_path: google/adk/tools/tool_configs.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Config to host free key-value pairs for the args in ToolConfig.


    [Note: Inherited members from pydantic.BaseModel are omitted.]'
  properties:
  - signature: 'model_config: pydantic.ConfigDict'
  inherited_properties:
    BaseModel:
    - signature: 'model_config: pydantic.ConfigDict'
  omitted_inherited_members_from:
  - pydantic.BaseModel
- rank: 1713
  id: google.adk.tools.tool_configs.ToolConfig
  name: ToolConfig
  file_path: google/adk/tools/tool_configs.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: "The configuration for a tool.\n\nThe config supports these types of tools:\n1. ADK built-in tools\n2. User-defined tool instances\n3. User-defined tool classes\n4. User-defined functions that generate tool instances\n5. User-defined function tools\n\nFor examples:\n\n  1. For ADK built-in tool instances or classes in `google.adk.tools` package,\n  they can be referenced directly with the `name` and optionally with\n  `args`.\n\n  ```\n  tools:\n    - name: google_search\n    - name: AgentTool\n      args:\n        agent: ./another_agent.yaml\n        skip_summarization: true\n  ```\n\n  2. For user-defined tool instances, the `name` is the fully qualified path\n  to the tool instance.\n\n  ```\n  tools:\n    - name: my_package.my_module.my_tool\n  ```\n\n  3. For user-defined tool classes (custom tools), the `name` is the fully\n  qualified path to the tool class and `args` is the arguments for the tool.\n\n  ```\n  tools:\n    - name: my_package.my_module.my_tool_class\n \
    \     args:\n        my_tool_arg1: value1\n        my_tool_arg2: value2\n  ```\n\n  4. For user-defined functions that generate tool instances, the `name` is\n  the fully qualified path to the function and `args` is passed to the\n  function as arguments.\n\n  ```\n  tools:\n    - name: my_package.my_module.my_tool_function\n      args:\n        my_function_arg1: value1\n        my_function_arg2: value2\n  ```\n\n  The function must have the following signature:\n  ```\n  def my_function(args: ToolArgsConfig) -> BaseTool:\n    ...\n  ```\n\n  5. For user-defined function tools, the `name` is the fully qualified path\n  to the function.\n\n  ```\n  tools:\n    - name: my_package.my_module.my_function_tool\n  ```\n\n  If the above use cases don't suffice, users can define a custom tool config\n  by extending BaseToolConfig and override from_config() in the custom tool.\n\n[Note: Inherited members from pydantic.BaseModel are omitted.]"
  constructor_signature: 'def __init__(self, *, name: str, args: typing.Optional[google.adk.tools.tool_configs.ToolArgsConfig] = None):'
  properties:
  - signature: 'model_config: pydantic.ConfigDict'
  - signature: 'name: str'
  - signature: 'args: typing.Optional[google.adk.tools.tool_configs.ToolArgsConfig]'
  inherited_properties:
    BaseModel:
    - signature: 'model_config: pydantic.ConfigDict'
  omitted_inherited_members_from:
  - pydantic.BaseModel
- rank: 1714
  id: google.adk.tools.tool_confirmation
  name: tool_confirmation
  file_path: google/adk/tools/tool_confirmation.py
  type: MODULE
  group: Orphan
  usage_score: 0
- rank: 1715
  id: google.adk.tools.tool_confirmation.ToolConfirmation
  name: ToolConfirmation
  file_path: google/adk/tools/tool_confirmation.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Represents a tool confirmation configuration.


    [Note: Inherited members from pydantic.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, hint: str = '''', confirmed: bool = False, payload: typing.Optional[typing.Any] = None):'
  properties:
  - signature: 'model_config: pydantic.ConfigDict'
    docstring: The pydantic model config.
  - signature: 'hint: str'
    docstring: The hint text for why the input is needed.
  - signature: 'confirmed: bool'
    docstring: Whether the tool execution is confirmed.
  - signature: 'payload: typing.Optional[typing.Any]'
    docstring: 'The custom data payload needed from the user to continue the flow.

      It should be JSON serializable.'
  inherited_properties:
    BaseModel:
    - signature: 'model_config: pydantic.ConfigDict'
  omitted_inherited_members_from:
  - pydantic.BaseModel
- rank: 1716
  id: google.adk.tools.tool_context
  name: tool_context
  file_path: google/adk/tools/tool_context.py
  type: MODULE
  group: Orphan
  usage_score: 0
- rank: 1717
  id: google.adk.tools.tool_context.ToolContext
  name: ToolContext
  file_path: google/adk/tools/tool_context.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: "The context of the tool.\n\nThis class provides the context for a tool invocation, including access to\nthe invocation context, function call ID, event actions, and authentication\nresponse. It also provides methods for requesting credentials, retrieving\nauthentication responses, listing artifacts, and searching memory.\n\nAttributes:\n  invocation_context: The invocation context of the tool.\n  function_call_id: The function call id of the current tool call. This id was\n    returned in the function call event from LLM to identify a function call.\n    If LLM didn't return this id, ADK will assign one to it. This id is used\n    to map function call response to the original function call.\n  event_actions: The event actions of the current tool call.\n  tool_confirmation: The tool confirmation of the current tool call."
  constructor_signature: 'def __init__(self, invocation_context: google.adk.agents.invocation_context.InvocationContext, *, function_call_id: typing.Optional[str]=None, event_actions: typing.Optional[google.adk.events.event_actions.EventActions]=None, tool_confirmation: typing.Optional[google.adk.tools.tool_confirmation.ToolConfirmation]=None):'
  aliases:
  - google.adk.tools.ToolContext
  methods:
  - signature: 'def actions(self) -> google.adk.events.event_actions.EventActions:'
  - signature: 'def request_credential(self, auth_config: google.adk.auth.auth_tool.AuthConfig) -> None:'
  - signature: 'def get_auth_response(self, auth_config: google.adk.auth.auth_tool.AuthConfig) -> google.adk.auth.auth_credential.AuthCredential:'
  - signature: 'def request_confirmation(self, *, hint: typing.Optional[str]=None, payload: typing.Optional[typing.Any]=None) -> None:'
    docstring: "Requests confirmation for the given function call.\n\nArgs:\n  hint: A hint to the user on how to confirm the tool call.\n  payload: The payload used to confirm the tool call."
  - signature: 'def search_memory(self, query: str) -> google.adk.memory.base_memory_service.SearchMemoryResponse:'
    docstring: Searches the memory of the current user.
  inherited_methods:
    CallbackContext:
    - signature: 'def state(self) -> google.adk.sessions.state.State:'
      docstring: 'The delta-aware state of the current session.


        For any state change, you can mutate this object directly,

        e.g. `ctx.state[''foo''] = ''bar''`'
    - signature: 'def load_artifact(self, filename: str, version: typing.Optional[int]) -> typing.Optional[google.genai.types.Part]:'
      docstring: "Loads an artifact attached to the current session.\n\nArgs:\n  filename: The filename of the artifact.\n  version: The version of the artifact. If None, the latest version will be\n    returned.\n\nReturns:\n  The artifact."
    - signature: 'def save_artifact(self, filename: str, artifact: google.genai.types.Part, custom_metadata: typing.Optional[dict[str, typing.Any]]) -> int:'
      docstring: "Saves an artifact and records it as delta for the current session.\n\nArgs:\n  filename: The filename of the artifact.\n  artifact: The artifact to save.\n  custom_metadata: Custom metadata to associate with the artifact.\n\nReturns:\n The version of the artifact."
    - signature: 'def get_artifact_version(self, filename: str, version: typing.Optional[int]) -> typing.Optional[google.adk.artifacts.base_artifact_service.ArtifactVersion]:'
      docstring: "Gets artifact version info.\n\nArgs:\n  filename: The filename of the artifact.\n  version: The version of the artifact. If None, the latest version will be\n    returned.\n\nReturns:\n  The artifact version info."
    - signature: 'def list_artifacts(self) -> list[str]:'
      docstring: Lists the filenames of the artifacts attached to the current session.
    - signature: 'def save_credential(self, auth_config: google.adk.auth.auth_tool.AuthConfig) -> None:'
      docstring: "Saves a credential to the credential service.\n\nArgs:\n  auth_config: The authentication configuration containing the credential."
    - signature: 'def load_credential(self, auth_config: google.adk.auth.auth_tool.AuthConfig) -> typing.Optional[google.adk.auth.auth_credential.AuthCredential]:'
      docstring: "Loads a credential from the credential service.\n\nArgs:\n  auth_config: The authentication configuration for the credential.\n\nReturns:\n  The loaded credential, or None if not found."
    ReadonlyContext:
    - signature: 'def user_content(self) -> typing.Optional[google.genai.types.Content]:'
      docstring: The user content that started this invocation. READONLY field.
    - signature: 'def invocation_id(self) -> str:'
      docstring: The current invocation id.
    - signature: 'def agent_name(self) -> str:'
      docstring: The name of the agent that is currently running.
    - signature: 'def state(self) -> types.MappingProxyType[str, typing.Any]:'
      docstring: The state of the current session. READONLY field.
    - signature: 'def session(self) -> google.adk.sessions.session.Session:'
      docstring: The current session for this invocation.
    - signature: 'def user_id(self) -> str:'
      docstring: The id of the user. READONLY field.
    - signature: 'def run_config(self) -> typing.Optional[google.adk.agents.run_config.RunConfig]:'
      docstring: The run config of the current invocation. READONLY field.
- rank: 1718
  id: google.adk.tools.tool_context.ToolContext.__init__
  name: __init__
  file_path: google/adk/tools/tool_context.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def __init__(self, invocation_context: google.adk.agents.invocation_context.InvocationContext, *, function_call_id: typing.Optional[str]=None, event_actions: typing.Optional[google.adk.events.event_actions.EventActions]=None, tool_confirmation: typing.Optional[google.adk.tools.tool_confirmation.ToolConfirmation]=None):'
- rank: 1719
  id: google.adk.tools.tool_context.ToolContext.request_confirmation
  name: request_confirmation
  file_path: google/adk/tools/tool_context.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Requests confirmation for the given function call.\n\nArgs:\n  hint: A hint to the user on how to confirm the tool call.\n  payload: The payload used to confirm the tool call."
  signature: 'def request_confirmation(self, *, hint: typing.Optional[str]=None, payload: typing.Optional[typing.Any]=None) -> None:'
- rank: 1720
  id: google.adk.tools.tool_context.ToolContext.request_credential
  name: request_credential
  file_path: google/adk/tools/tool_context.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def request_credential(self, auth_config: google.adk.auth.auth_tool.AuthConfig) -> None:'
- rank: 1721
  id: google.adk.tools.tool_context.ToolContext.search_memory
  name: search_memory
  file_path: google/adk/tools/tool_context.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: Searches the memory of the current user.
  signature: 'def search_memory(self, query: str) -> google.adk.memory.base_memory_service.SearchMemoryResponse:'
- rank: 1722
  id: google.adk.tools.toolbox_toolset
  name: toolbox_toolset
  file_path: google/adk/tools/toolbox_toolset.py
  type: MODULE
  group: Orphan
  usage_score: 0
- rank: 1723
  id: google.adk.tools.toolbox_toolset.ToolboxToolset
  name: ToolboxToolset
  file_path: google/adk/tools/toolbox_toolset.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'A class that provides access to toolbox toolsets.


    Example:

    ```python

    toolbox_toolset = ToolboxToolset("http://127.0.0.1:5000",

    toolset_name="my-toolset")

    )

    ```


    [Note: Inherited members from ABC are omitted.]'
  constructor_signature: 'def __init__(self, server_url: str, toolset_name: typing.Optional[str], tool_names: typing.Optional[typing.List[str]], auth_token_getters: typing.Optional[dict[str, typing.Callable[[], str]]], bound_params: typing.Optional[typing.Mapping[str, typing.Union[typing.Callable[[], typing.Any], typing.Any]]]):'
  methods:
  - signature: 'def get_tools(self, readonly_context: typing.Optional[google.adk.agents.readonly_context.ReadonlyContext]) -> list[google.adk.tools.base_tool.BaseTool]:'
  - signature: 'def close(self):'
  inherited_methods:
    BaseToolset:
    - signature: 'def get_tools(self, readonly_context: typing.Optional[google.adk.agents.readonly_context.ReadonlyContext]) -> list[google.adk.tools.base_tool.BaseTool]:'
      docstring: "Return all tools in the toolset based on the provided context.\n\nArgs:\n  readonly_context (ReadonlyContext, optional): Context used to filter tools\n    available to the agent. If None, all tools in the toolset are returned.\n\nReturns:\n  list[BaseTool]: A list of tools available under the specified context."
    - signature: 'def get_tools_with_prefix(self, readonly_context: typing.Optional[google.adk.agents.readonly_context.ReadonlyContext]) -> list[google.adk.tools.base_tool.BaseTool]:'
      docstring: "Return all tools with optional prefix applied to tool names.\n\nThis method calls get_tools() and applies prefixing if tool_name_prefix is provided.\n\nArgs:\n  readonly_context (ReadonlyContext, optional): Context used to filter tools\n    available to the agent. If None, all tools in the toolset are returned.\n\nReturns:\n  list[BaseTool]: A list of tools with prefixed names if tool_name_prefix is provided."
    - signature: 'def close(self) -> None:'
      docstring: "Performs cleanup and releases resources held by the toolset.\n\nNOTE:\n  This method is invoked, for example, at the end of an agent server's\n  lifecycle or when the toolset is no longer needed. Implementations\n  should ensure that any open connections, files, or other managed\n  resources are properly released to prevent leaks."
    - signature: 'def from_config(cls: typing.Type[google.adk.tools.base_toolset.SelfToolset], config: google.adk.tools.tool_configs.ToolArgsConfig, config_abs_path: str) -> google.adk.tools.base_toolset.SelfToolset:'
      docstring: "Creates a toolset instance from a config.\n\nArgs:\n  config: The config for the tool.\n  config_abs_path: The absolute path to the config file that contains the\n    tool config.\n\nReturns:\n  The toolset instance."
    - signature: 'def process_llm_request(self, *, tool_context: google.adk.tools.tool_context.ToolContext, llm_request: google.adk.models.llm_request.LlmRequest) -> None:'
      docstring: "Processes the outgoing LLM request for this toolset. This method will be\ncalled before each tool processes the llm request.\n\nUse cases:\n- Instead of let each tool process the llm request, we can let the toolset\n  process the llm request. e.g. ComputerUseToolset can add computer use\n  tool to the llm request.\n\nArgs:\n  tool_context: The context of the tool.\n  llm_request: The outgoing LLM request, mutable this method."
  omitted_inherited_members_from:
  - ABC
- rank: 1724
  id: google.adk.tools.toolbox_toolset.ToolboxToolset.__init__
  name: __init__
  file_path: google/adk/tools/toolbox_toolset.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Args:\n\n  server_url: The URL of the toolbox server.\n  toolset_name: The name of the toolbox toolset to load.\n  tool_names: The names of the tools to load.\n  auth_token_getters: A mapping of authentication service names to\n    callables that return the corresponding authentication token. see:\n    https://github.com/googleapis/mcp-toolbox-sdk-python/tree/main/packages/toolbox-core#authenticating-tools\n    for details.\n  bound_params: A mapping of parameter names to bind to specific values or\n    callables that are called to produce values as needed. see:\n    https://github.com/googleapis/mcp-toolbox-sdk-python/tree/main/packages/toolbox-core#binding-parameter-values\n    for details.\nThe resulting ToolboxToolset will contain both tools loaded by tool_names\nand toolset_name."
  signature: 'def __init__(self, server_url: str, toolset_name: typing.Optional[str], tool_names: typing.Optional[typing.List[str]], auth_token_getters: typing.Optional[dict[str, typing.Callable[[], str]]], bound_params: typing.Optional[typing.Mapping[str, typing.Union[typing.Callable[[], typing.Any], typing.Any]]]):'
- rank: 1725
  id: google.adk.tools.toolbox_toolset.ToolboxToolset.get_tools
  name: get_tools
  file_path: google/adk/tools/toolbox_toolset.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def get_tools(self, readonly_context: typing.Optional[google.adk.agents.readonly_context.ReadonlyContext]) -> list[google.adk.tools.base_tool.BaseTool]:'
- rank: 1726
  id: google.adk.tools.transfer_to_agent_tool
  name: transfer_to_agent_tool
  file_path: google/adk/tools/transfer_to_agent_tool.py
  type: MODULE
  group: Orphan
  usage_score: 0
  methods:
  - signature: 'def transfer_to_agent(agent_name: str, tool_context: google.adk.tools.tool_context.ToolContext) -> None:'
    docstring: "Transfer the question to another agent.\n\nThis tool hands off control to another agent when it's more suitable to\nanswer the user's question according to the agent's description.\n\nNote:\n  For most use cases, you should use TransferToAgentTool instead of this\n  function directly. TransferToAgentTool provides additional enum constraints\n  that prevent LLMs from hallucinating invalid agent names.\n\nArgs:\n  agent_name: the agent name to transfer to."
- rank: 1727
  id: google.adk.tools.transfer_to_agent_tool.TransferToAgentTool
  name: TransferToAgentTool
  file_path: google/adk/tools/transfer_to_agent_tool.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: "A specialized FunctionTool for agent transfer with enum constraints.\n\nThis tool enhances the base transfer_to_agent function by adding JSON Schema\nenum constraints to the agent_name parameter. This prevents LLMs from\nhallucinating invalid agent names by restricting choices to only valid agents.\n\nAttributes:\n  agent_names: List of valid agent names that can be transferred to.\n\n[Note: Inherited members from ABC are omitted.]"
  constructor_signature: 'def __init__(self, agent_names: list[str]):'
  aliases:
  - google.adk.tools.TransferToAgentTool
  inherited_methods:
    FunctionTool:
    - signature: 'def run_async(self, *, args: dict[str, typing.Any], tool_context: google.adk.tools.tool_context.ToolContext) -> typing.Any:'
    BaseTool:
    - signature: 'def run_async(self, *, args: dict[str, typing.Any], tool_context: google.adk.tools.tool_context.ToolContext) -> typing.Any:'
      docstring: "Runs the tool with the given arguments and context.\n\nNOTE:\n  - Required if this tool needs to run at the client side.\n  - Otherwise, can be skipped, e.g. for a built-in GoogleSearch tool for\n    Gemini.\n\nArgs:\n  args: The LLM-filled arguments.\n  tool_context: The context of the tool.\n\nReturns:\n  The result of running the tool."
    - signature: 'def process_llm_request(self, *, tool_context: google.adk.tools.tool_context.ToolContext, llm_request: google.adk.models.llm_request.LlmRequest) -> None:'
      docstring: "Processes the outgoing LLM request for this tool.\n\nUse cases:\n- Most common use case is adding this tool to the LLM request.\n- Some tools may just preprocess the LLM request before it's sent out.\n\nArgs:\n  tool_context: The context of the tool.\n  llm_request: The outgoing LLM request, mutable this method."
    - signature: 'def from_config(cls: typing.Type[google.adk.tools.base_tool.SelfTool], config: google.adk.tools.tool_configs.ToolArgsConfig, config_abs_path: str) -> google.adk.tools.base_tool.SelfTool:'
      docstring: "Creates a tool instance from a config.\n\nThis default implementation uses inspect to automatically map config values\nto constructor arguments based on their type hints. Subclasses should\noverride this method for custom initialization logic.\n\nArgs:\n  config: The config for the tool.\n  config_abs_path: The absolute path to the config file that contains the\n    tool config.\n\nReturns:\n  The tool instance."
  inherited_properties:
    BaseTool:
    - signature: 'name: str'
      docstring: The name of the tool.
    - signature: 'description: str'
      docstring: The description of the tool.
    - signature: 'is_long_running: bool'
      docstring: 'Whether the tool is a long running operation, which typically returns a

        resource id first and finishes the operation later.'
    - signature: 'custom_metadata: typing.Optional[dict[str, typing.Any]]'
      docstring: 'The custom metadata of the BaseTool.


        An optional key-value pair for storing and retrieving tool-specific metadata,

        such as tool manifests, etc.


        NOTE: the entire dict must be JSON serializable.'
  omitted_inherited_members_from:
  - ABC
- rank: 1728
  id: google.adk.tools.transfer_to_agent_tool.TransferToAgentTool.__init__
  name: __init__
  file_path: google/adk/tools/transfer_to_agent_tool.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Initialize the TransferToAgentTool.\n\nArgs:\n  agent_names: List of valid agent names that can be transferred to."
  signature: 'def __init__(self, agent_names: list[str]):'
- rank: 1729
  id: google.adk.tools.transfer_to_agent_tool.transfer_to_agent
  name: transfer_to_agent
  file_path: google/adk/tools/transfer_to_agent_tool.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Transfer the question to another agent.\n\nThis tool hands off control to another agent when it's more suitable to\nanswer the user's question according to the agent's description.\n\nNote:\n  For most use cases, you should use TransferToAgentTool instead of this\n  function directly. TransferToAgentTool provides additional enum constraints\n  that prevent LLMs from hallucinating invalid agent names.\n\nArgs:\n  agent_name: the agent name to transfer to."
  signature: 'def transfer_to_agent(agent_name: str, tool_context: google.adk.tools.tool_context.ToolContext) -> None:'
  aliases:
  - google.adk.tools.transfer_to_agent
- rank: 1730
  id: google.adk.tools.url_context_tool
  name: url_context_tool
  file_path: google/adk/tools/url_context_tool.py
  type: MODULE
  group: Orphan
  usage_score: 0
- rank: 1731
  id: google.adk.tools.url_context_tool.UrlContextTool
  name: UrlContextTool
  file_path: google/adk/tools/url_context_tool.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'A built-in tool that is automatically invoked by Gemini 2 models to retrieve content from the URLs and use that content to inform and shape its response.


    This tool operates internally within the model and does not require or perform

    local code execution.


    [Note: Inherited members from ABC are omitted.]'
  constructor_signature: 'def __init__(self):'
  methods:
  - signature: 'def process_llm_request(self, *, tool_context: google.adk.tools.tool_context.ToolContext, llm_request: google.adk.models.LlmRequest) -> None:'
  inherited_methods:
    BaseTool:
    - signature: 'def run_async(self, *, args: dict[str, typing.Any], tool_context: google.adk.tools.tool_context.ToolContext) -> typing.Any:'
      docstring: "Runs the tool with the given arguments and context.\n\nNOTE:\n  - Required if this tool needs to run at the client side.\n  - Otherwise, can be skipped, e.g. for a built-in GoogleSearch tool for\n    Gemini.\n\nArgs:\n  args: The LLM-filled arguments.\n  tool_context: The context of the tool.\n\nReturns:\n  The result of running the tool."
    - signature: 'def process_llm_request(self, *, tool_context: google.adk.tools.tool_context.ToolContext, llm_request: google.adk.models.llm_request.LlmRequest) -> None:'
      docstring: "Processes the outgoing LLM request for this tool.\n\nUse cases:\n- Most common use case is adding this tool to the LLM request.\n- Some tools may just preprocess the LLM request before it's sent out.\n\nArgs:\n  tool_context: The context of the tool.\n  llm_request: The outgoing LLM request, mutable this method."
    - signature: 'def from_config(cls: typing.Type[google.adk.tools.base_tool.SelfTool], config: google.adk.tools.tool_configs.ToolArgsConfig, config_abs_path: str) -> google.adk.tools.base_tool.SelfTool:'
      docstring: "Creates a tool instance from a config.\n\nThis default implementation uses inspect to automatically map config values\nto constructor arguments based on their type hints. Subclasses should\noverride this method for custom initialization logic.\n\nArgs:\n  config: The config for the tool.\n  config_abs_path: The absolute path to the config file that contains the\n    tool config.\n\nReturns:\n  The tool instance."
  inherited_properties:
    BaseTool:
    - signature: 'name: str'
      docstring: The name of the tool.
    - signature: 'description: str'
      docstring: The description of the tool.
    - signature: 'is_long_running: bool'
      docstring: 'Whether the tool is a long running operation, which typically returns a

        resource id first and finishes the operation later.'
    - signature: 'custom_metadata: typing.Optional[dict[str, typing.Any]]'
      docstring: 'The custom metadata of the BaseTool.


        An optional key-value pair for storing and retrieving tool-specific metadata,

        such as tool manifests, etc.


        NOTE: the entire dict must be JSON serializable.'
  omitted_inherited_members_from:
  - ABC
- rank: 1732
  id: google.adk.tools.url_context_tool.UrlContextTool.process_llm_request
  name: process_llm_request
  file_path: google/adk/tools/url_context_tool.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def process_llm_request(self, *, tool_context: google.adk.tools.tool_context.ToolContext, llm_request: google.adk.models.LlmRequest) -> None:'
- rank: 1733
  id: google.adk.tools.vertex_ai_search_tool
  name: vertex_ai_search_tool
  file_path: google/adk/tools/vertex_ai_search_tool.py
  type: MODULE
  group: Orphan
  usage_score: 0
- rank: 1734
  id: google.adk.tools.vertex_ai_search_tool.VertexAiSearchTool.__init__
  name: __init__
  file_path: google/adk/tools/vertex_ai_search_tool.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Initializes the Vertex AI Search tool.\n\nArgs:\n  data_store_id: The Vertex AI search data store resource ID in the format\n    of\n    \"projects/{project}/locations/{location}/collections/{collection}/dataStores/{dataStore}\".\n  data_store_specs: Specifications that define the specific DataStores to be\n    searched. It should only be set if engine is used.\n  search_engine_id: The Vertex AI search engine resource ID in the format of\n    \"projects/{project}/locations/{location}/collections/{collection}/engines/{engine}\".\n  filter: The filter to apply to the search results.\n  max_results: The maximum number of results to return.\n  bypass_multi_tools_limit: Whether to bypass the multi tools limitation,\n    so that the tool can be used with other tools in the same agent.\n\nRaises:\n  ValueError: If both data_store_id and search_engine_id are not specified\n  or both are specified."
  signature: 'def __init__(self, *, data_store_id: typing.Optional[str]=None, data_store_specs: typing.Optional[list[google.genai.types.VertexAISearchDataStoreSpec]]=None, search_engine_id: typing.Optional[str]=None, filter: typing.Optional[str]=None, max_results: typing.Optional[int]=None, bypass_multi_tools_limit: bool=False):'
- rank: 1735
  id: google.adk.tools.vertex_ai_search_tool.VertexAiSearchTool.process_llm_request
  name: process_llm_request
  file_path: google/adk/tools/vertex_ai_search_tool.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def process_llm_request(self, *, tool_context: google.adk.tools.tool_context.ToolContext, llm_request: google.adk.models.LlmRequest) -> None:'
- rank: 1736
  id: google.adk.utils
  name: utils
  file_path: google/adk/utils/__init__.py
  type: MODULE
  group: Orphan
  usage_score: 0
- rank: 1737
  id: google.adk.utils.cache_performance_analyzer
  name: cache_performance_analyzer
  file_path: google/adk/utils/cache_performance_analyzer.py
  type: MODULE
  group: Orphan
  usage_score: 0
  docstring: 'Cache performance analysis utilities for ADK context caching system.


    This module provides tools to analyze cache performance metrics from event

    history, including hit ratios, cost savings, and cache refresh patterns.'
- rank: 1738
  id: google.adk.utils.cache_performance_analyzer.CachePerformanceAnalyzer.analyze_agent_cache_performance
  name: analyze_agent_cache_performance
  file_path: google/adk/utils/cache_performance_analyzer.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Analyze cache performance for agent.\n\nArgs:\n    session_id: Session to analyze\n    user_id: User ID for session lookup\n    app_name: App name for session lookup\n    agent_name: Agent to analyze\n\nReturns:\n    Performance analysis dictionary containing:\n    - status: \"active\" if cache data found, \"no_cache_data\" if none\n    - requests_with_cache: Number of requests that used caching\n    - avg_invocations_used: Average number of invocations each cache was used\n    - latest_cache: Resource name of most recent cache used\n    - cache_refreshes: Number of unique cache instances created\n    - total_invocations: Total number of invocations across all caches\n    - total_prompt_tokens: Total prompt tokens across all requests\n    - total_cached_tokens: Total cached content tokens across all requests\n    - cache_hit_ratio_percent: Percentage of tokens served from cache\n    - cache_utilization_ratio_percent: Percentage of requests with cache hits\n    - avg_cached_tokens_per_request:\
    \ Average cached tokens per request\n    - total_requests: Total number of requests processed\n    - requests_with_cache_hits: Number of requests that had cache hits"
  signature: 'def analyze_agent_cache_performance(self, session_id: str, user_id: str, app_name: str, agent_name: str) -> typing.Dict[str, typing.Any]:'
- rank: 1739
  id: google.adk.utils.context_utils
  name: context_utils
  file_path: google/adk/utils/context_utils.py
  type: MODULE
  group: Orphan
  usage_score: 0
  docstring: 'Utilities for ADK context management.


    This module is for ADK internal use only.

    Please do not rely on the implementation details.'
- rank: 1740
  id: google.adk.utils.context_utils.Aclosing
  name: Aclosing
  file_path: google/adk/utils/context_utils.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Async context manager for safely finalizing an asynchronously cleaned-up

    resource such as an async generator, calling its ``aclose()`` method.

    Needed to correctly close contexts for OTel spans.

    See https://github.com/google/adk-python/issues/1670#issuecomment-3115891100.


    Based on

    https://docs.python.org/3/library/contextlib.html#contextlib.aclosing

    which is available in Python 3.10+.


    TODO: replace all occurrences with contextlib.aclosing once Python 3.9 is no

    longer supported.


    [Note: Inherited members from AbstractAsyncContextManager are omitted.]'
  constructor_signature: 'def __init__(self, async_generator: typing.AsyncGenerator[typing.Any, None]):'
  omitted_inherited_members_from:
  - AbstractAsyncContextManager
- rank: 1741
  id: google.adk.utils.env_utils
  name: env_utils
  file_path: google/adk/utils/env_utils.py
  type: MODULE
  group: Orphan
  usage_score: 0
  docstring: 'Utilities for environment variable handling.


    This module is for ADK internal use only.

    Please do not rely on the implementation details.'
  methods:
  - signature: 'def is_env_enabled(env_var_name: str, default: str) -> bool:'
    docstring: "Check if an environment variable is enabled.\n\nAn environment variable is considered enabled if its value (case-insensitive)\nis 'true' or '1'.\n\nArgs:\n  env_var_name: The name of the environment variable to check.\n  default: The default value to use if the environment variable is not set.\n    Defaults to '0'.\n\nReturns:\n  True if the environment variable is enabled, False otherwise.\n\nExamples:\n  >>> os.environ['MY_FLAG'] = 'true'\n  >>> is_env_enabled('MY_FLAG')\n  True\n\n  >>> os.environ['MY_FLAG'] = '1'\n  >>> is_env_enabled('MY_FLAG')\n  True\n\n  >>> os.environ['MY_FLAG'] = 'false'\n  >>> is_env_enabled('MY_FLAG')\n  False\n\n  >>> is_env_enabled('NONEXISTENT_FLAG')\n  False\n\n  >>> is_env_enabled('NONEXISTENT_FLAG', default='1')\n  True"
- rank: 1742
  id: google.adk.utils.env_utils.is_env_enabled
  name: is_env_enabled
  file_path: google/adk/utils/env_utils.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Check if an environment variable is enabled.\n\nAn environment variable is considered enabled if its value (case-insensitive)\nis 'true' or '1'.\n\nArgs:\n  env_var_name: The name of the environment variable to check.\n  default: The default value to use if the environment variable is not set.\n    Defaults to '0'.\n\nReturns:\n  True if the environment variable is enabled, False otherwise.\n\nExamples:\n  >>> os.environ['MY_FLAG'] = 'true'\n  >>> is_env_enabled('MY_FLAG')\n  True\n\n  >>> os.environ['MY_FLAG'] = '1'\n  >>> is_env_enabled('MY_FLAG')\n  True\n\n  >>> os.environ['MY_FLAG'] = 'false'\n  >>> is_env_enabled('MY_FLAG')\n  False\n\n  >>> is_env_enabled('NONEXISTENT_FLAG')\n  False\n\n  >>> is_env_enabled('NONEXISTENT_FLAG', default='1')\n  True"
  signature: 'def is_env_enabled(env_var_name: str, default: str) -> bool:'
- rank: 1743
  id: google.adk.utils.feature_decorator
  name: feature_decorator
  file_path: google/adk/utils/feature_decorator.py
  type: MODULE
  group: Orphan
  usage_score: 0
  methods:
  - signature: 'def decorator_factory(message_or_obj):'
  - signature: 'def decorator(obj: google.adk.utils.feature_decorator.T) -> google.adk.utils.feature_decorator.T:'
  - signature: 'def new_init(self):'
  - signature: 'def wrapper():'
- rank: 1744
  id: google.adk.utils.feature_decorator.decorator
  name: decorator
  file_path: google/adk/utils/feature_decorator.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def decorator(obj: google.adk.utils.feature_decorator.T) -> google.adk.utils.feature_decorator.T:'
- rank: 1745
  id: google.adk.utils.feature_decorator.decorator_factory
  name: decorator_factory
  file_path: google/adk/utils/feature_decorator.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def decorator_factory(message_or_obj):'
- rank: 1746
  id: google.adk.utils.feature_decorator.new_init
  name: new_init
  file_path: google/adk/utils/feature_decorator.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def new_init(self):'
- rank: 1747
  id: google.adk.utils.feature_decorator.wrapper
  name: wrapper
  file_path: google/adk/utils/feature_decorator.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def wrapper():'
- rank: 1748
  id: google.adk.utils.instructions_utils
  name: instructions_utils
  file_path: google/adk/utils/instructions_utils.py
  type: MODULE
  group: Orphan
  usage_score: 0
  methods:
  - signature: 'def inject_session_state(template: str, readonly_context: google.adk.agents.readonly_context.ReadonlyContext) -> str:'
    docstring: "Populates values in the instruction template, e.g. state, artifact, etc.\n\nThis method is intended to be used in InstructionProvider based instruction\nand global_instruction which are called with readonly_context.\n\ne.g.\n```\n...\nfrom google.adk.utils.instructions_utils import inject_session_state\n\nasync def build_instruction(\n    readonly_context: ReadonlyContext,\n) -> str:\n  return await inject_session_state(\n      'You can inject a state variable like {var_name} or an artifact '\n      '{artifact.file_name} into the instruction template.',\n      readonly_context,\n  )\n\nagent = Agent(\n    model=\"gemini-2.0-flash\",\n    name=\"agent\",\n    instruction=build_instruction,\n)\n```\n\nArgs:\n  template: The instruction template.\n  readonly_context: The read-only context\n\nReturns:\n  The instruction template with values populated."
- rank: 1749
  id: google.adk.utils.instructions_utils.inject_session_state
  name: inject_session_state
  file_path: google/adk/utils/instructions_utils.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Populates values in the instruction template, e.g. state, artifact, etc.\n\nThis method is intended to be used in InstructionProvider based instruction\nand global_instruction which are called with readonly_context.\n\ne.g.\n```\n...\nfrom google.adk.utils.instructions_utils import inject_session_state\n\nasync def build_instruction(\n    readonly_context: ReadonlyContext,\n) -> str:\n  return await inject_session_state(\n      'You can inject a state variable like {var_name} or an artifact '\n      '{artifact.file_name} into the instruction template.',\n      readonly_context,\n  )\n\nagent = Agent(\n    model=\"gemini-2.0-flash\",\n    name=\"agent\",\n    instruction=build_instruction,\n)\n```\n\nArgs:\n  template: The instruction template.\n  readonly_context: The read-only context\n\nReturns:\n  The instruction template with values populated."
  signature: 'def inject_session_state(template: str, readonly_context: google.adk.agents.readonly_context.ReadonlyContext) -> str:'
- rank: 1750
  id: google.adk.utils.model_name_utils
  name: model_name_utils
  file_path: google/adk/utils/model_name_utils.py
  type: MODULE
  group: Orphan
  usage_score: 0
  docstring: Utilities for model name validation and parsing.
  methods:
  - signature: 'def extract_model_name(model_string: str) -> str:'
    docstring: "Extract the actual model name from either simple or path-based format.\n\nArgs:\n  model_string: Either a simple model name like \"gemini-2.5-pro\" or a\n    path-based model name like \"projects/.../models/gemini-2.0-flash-001\"\n\nReturns:\n  The extracted model name (e.g., \"gemini-2.5-pro\")"
  - signature: 'def is_gemini_model(model_string: typing.Optional[str]) -> bool:'
    docstring: "Check if the model is a Gemini model using regex patterns.\n\nArgs:\n  model_string: Either a simple model name or path-based model name\n\nReturns:\n  True if it's a Gemini model, False otherwise"
  - signature: 'def is_gemini_1_model(model_string: typing.Optional[str]) -> bool:'
    docstring: "Check if the model is a Gemini 1.x model using regex patterns.\n\nArgs:\n  model_string: Either a simple model name or path-based model name\n\nReturns:\n  True if it's a Gemini 1.x model, False otherwise"
  - signature: 'def is_gemini_2_or_above(model_string: typing.Optional[str]) -> bool:'
    docstring: "Check if the model is a Gemini 2.0 or newer model using semantic versions.\n\nArgs:\n  model_string: Either a simple model name or path-based model name\n\nReturns:\n  True if it's a Gemini 2.0+ model, False otherwise"
- rank: 1751
  id: google.adk.utils.model_name_utils.extract_model_name
  name: extract_model_name
  file_path: google/adk/utils/model_name_utils.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Extract the actual model name from either simple or path-based format.\n\nArgs:\n  model_string: Either a simple model name like \"gemini-2.5-pro\" or a\n    path-based model name like \"projects/.../models/gemini-2.0-flash-001\"\n\nReturns:\n  The extracted model name (e.g., \"gemini-2.5-pro\")"
  signature: 'def extract_model_name(model_string: str) -> str:'
- rank: 1752
  id: google.adk.utils.model_name_utils.is_gemini_1_model
  name: is_gemini_1_model
  file_path: google/adk/utils/model_name_utils.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Check if the model is a Gemini 1.x model using regex patterns.\n\nArgs:\n  model_string: Either a simple model name or path-based model name\n\nReturns:\n  True if it's a Gemini 1.x model, False otherwise"
  signature: 'def is_gemini_1_model(model_string: typing.Optional[str]) -> bool:'
- rank: 1753
  id: google.adk.utils.model_name_utils.is_gemini_2_or_above
  name: is_gemini_2_or_above
  file_path: google/adk/utils/model_name_utils.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Check if the model is a Gemini 2.0 or newer model using semantic versions.\n\nArgs:\n  model_string: Either a simple model name or path-based model name\n\nReturns:\n  True if it's a Gemini 2.0+ model, False otherwise"
  signature: 'def is_gemini_2_or_above(model_string: typing.Optional[str]) -> bool:'
- rank: 1754
  id: google.adk.utils.model_name_utils.is_gemini_model
  name: is_gemini_model
  file_path: google/adk/utils/model_name_utils.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Check if the model is a Gemini model using regex patterns.\n\nArgs:\n  model_string: Either a simple model name or path-based model name\n\nReturns:\n  True if it's a Gemini model, False otherwise"
  signature: 'def is_gemini_model(model_string: typing.Optional[str]) -> bool:'
- rank: 1755
  id: google.adk.utils.output_schema_utils
  name: output_schema_utils
  file_path: google/adk/utils/output_schema_utils.py
  type: MODULE
  group: Orphan
  usage_score: 0
  docstring: 'Utilities for Output Schema.


    This module is for ADK internal use only.

    Please do not rely on the implementation details.'
  methods:
  - signature: 'def can_use_output_schema_with_tools(model: typing.Union[str, google.adk.models.base_llm.BaseLlm]):'
    docstring: Returns True if output schema with tools is supported.
- rank: 1756
  id: google.adk.utils.output_schema_utils.can_use_output_schema_with_tools
  name: can_use_output_schema_with_tools
  file_path: google/adk/utils/output_schema_utils.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: Returns True if output schema with tools is supported.
  signature: 'def can_use_output_schema_with_tools(model: typing.Union[str, google.adk.models.base_llm.BaseLlm]):'
- rank: 1757
  id: google.adk.utils.streaming_utils
  name: streaming_utils
  file_path: google/adk/utils/streaming_utils.py
  type: MODULE
  group: Orphan
  usage_score: 0
- rank: 1758
  id: google.adk.utils.streaming_utils.StreamingResponseAggregator
  name: StreamingResponseAggregator
  file_path: google/adk/utils/streaming_utils.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Aggregates partial streaming responses.


    It aggregates content from partial responses, and generates LlmResponses for

    individual (partial) model responses, as well as for aggregated content.'
  constructor_signature: 'def __init__(self):'
  methods:
  - signature: 'def process_response(self, response: google.genai.types.GenerateContentResponse) -> typing.AsyncGenerator[google.adk.models.llm_response.LlmResponse, None]:'
    docstring: "Processes a single model response.\n\nArgs:\n  response: The response to process.\n\nYields:\n  The generated LlmResponse(s), for the partial response, and the aggregated\n  response if needed."
  - signature: 'def close(self) -> typing.Optional[google.adk.models.llm_response.LlmResponse]:'
    docstring: "Generate an aggregated response at the end, if needed.\n\nThis should be called after all the model responses are processed.\n\nReturns:\n  The aggregated LlmResponse."
- rank: 1759
  id: google.adk.utils.streaming_utils.StreamingResponseAggregator.__init__
  name: __init__
  file_path: google/adk/utils/streaming_utils.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def __init__(self):'
- rank: 1760
  id: google.adk.utils.streaming_utils.StreamingResponseAggregator.close
  name: close
  file_path: google/adk/utils/streaming_utils.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Generate an aggregated response at the end, if needed.\n\nThis should be called after all the model responses are processed.\n\nReturns:\n  The aggregated LlmResponse."
  signature: 'def close(self) -> typing.Optional[google.adk.models.llm_response.LlmResponse]:'
- rank: 1761
  id: google.adk.utils.streaming_utils.StreamingResponseAggregator.process_response
  name: process_response
  file_path: google/adk/utils/streaming_utils.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Processes a single model response.\n\nArgs:\n  response: The response to process.\n\nYields:\n  The generated LlmResponse(s), for the partial response, and the aggregated\n  response if needed."
  signature: 'def process_response(self, response: google.genai.types.GenerateContentResponse) -> typing.AsyncGenerator[google.adk.models.llm_response.LlmResponse, None]:'
- rank: 1762
  id: google.adk.utils.variant_utils
  name: variant_utils
  file_path: google/adk/utils/variant_utils.py
  type: MODULE
  group: Orphan
  usage_score: 0
  docstring: 'Utilities for Google LLM variants.


    This module is for ADK internal use only.

    Please do not rely on the implementation details.'
  methods:
  - signature: 'def get_google_llm_variant() -> google.adk.utils.variant_utils.GoogleLLMVariant:'
- rank: 1763
  id: google.adk.utils.variant_utils.GoogleLLMVariant
  name: GoogleLLMVariant
  file_path: google/adk/utils/variant_utils.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'The Google LLM variant to use.

    see https://google.github.io/adk-docs/get-started/quickstart/#set-up-the-model


    [Note: Inherited members from Enum are omitted.]'
  properties:
  - signature: 'VERTEX_AI: Any'
    docstring: For using credentials from Google Vertex AI
  - signature: 'GEMINI_API: Any'
    docstring: For using API Key from Google AI Studio
  omitted_inherited_members_from:
  - Enum
- rank: 1764
  id: google.adk.utils.vertex_ai_utils
  name: vertex_ai_utils
  file_path: google/adk/utils/vertex_ai_utils.py
  type: MODULE
  group: Orphan
  usage_score: 0
  docstring: 'Utilities for Vertex AI. Includes helper functions for Express Mode.


    This module is for ADK internal use only.

    Please do not rely on the implementation details.'
  methods:
  - signature: 'def get_express_mode_api_key(project: typing.Optional[str], location: typing.Optional[str], express_mode_api_key: typing.Optional[str]) -> typing.Optional[str]:'
    docstring: Validates and returns the API key for Express Mode.
- rank: 1765
  id: google.adk.utils.vertex_ai_utils.get_express_mode_api_key
  name: get_express_mode_api_key
  file_path: google/adk/utils/vertex_ai_utils.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: Validates and returns the API key for Express Mode.
  signature: 'def get_express_mode_api_key(project: typing.Optional[str], location: typing.Optional[str], express_mode_api_key: typing.Optional[str]) -> typing.Optional[str]:'
- rank: 1766
  id: google.adk.utils.yaml_utils
  name: yaml_utils
  file_path: google/adk/utils/yaml_utils.py
  type: MODULE
  group: Orphan
  usage_score: 0
  methods:
  - signature: 'def load_yaml_file(file_path: typing.Union[str, pathlib.Path]) -> typing.Any:'
    docstring: "Loads a YAML file and returns its content.\n\nArgs:\n  file_path: Path to the YAML file.\n\nReturns:\n  The content of the YAML file.\n\nRaises:\n  FileNotFoundError: If the file_path does not exist."
  - signature: 'def dump_pydantic_to_yaml(model: pydantic.BaseModel, file_path: typing.Union[str, pathlib.Path], *, indent: int=2, sort_keys: bool=True, exclude_none: bool=True, exclude_defaults: bool=True, exclude: typing.Optional[pydantic.main.IncEx]=None) -> None:'
    docstring: "Dump a Pydantic model to a YAML file with multiline strings using | style.\n\nArgs:\n  model: The Pydantic model instance to dump.\n  file_path: Path to the output YAML file.\n  indent: Number of spaces for indentation (default: 2).\n  sort_keys: Whether to sort dictionary keys (default: True).\n  exclude_none: Exclude fields with None values (default: True).\n  exclude_defaults: Exclude fields with default values (default: True).\n  exclude: Fields to exclude from the output. Can be a set of field names or\n    a nested dict for fine-grained exclusion (default: None)."
  - signature: 'def multiline_str_representer(dumper, data):'
- rank: 1767
  id: google.adk.utils.yaml_utils.dump_pydantic_to_yaml
  name: dump_pydantic_to_yaml
  file_path: google/adk/utils/yaml_utils.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Dump a Pydantic model to a YAML file with multiline strings using | style.\n\nArgs:\n  model: The Pydantic model instance to dump.\n  file_path: Path to the output YAML file.\n  indent: Number of spaces for indentation (default: 2).\n  sort_keys: Whether to sort dictionary keys (default: True).\n  exclude_none: Exclude fields with None values (default: True).\n  exclude_defaults: Exclude fields with default values (default: True).\n  exclude: Fields to exclude from the output. Can be a set of field names or\n    a nested dict for fine-grained exclusion (default: None)."
  signature: 'def dump_pydantic_to_yaml(model: pydantic.BaseModel, file_path: typing.Union[str, pathlib.Path], *, indent: int=2, sort_keys: bool=True, exclude_none: bool=True, exclude_defaults: bool=True, exclude: typing.Optional[pydantic.main.IncEx]=None) -> None:'
- rank: 1768
  id: google.adk.utils.yaml_utils.load_yaml_file
  name: load_yaml_file
  file_path: google/adk/utils/yaml_utils.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Loads a YAML file and returns its content.\n\nArgs:\n  file_path: Path to the YAML file.\n\nReturns:\n  The content of the YAML file.\n\nRaises:\n  FileNotFoundError: If the file_path does not exist."
  signature: 'def load_yaml_file(file_path: typing.Union[str, pathlib.Path]) -> typing.Any:'
- rank: 1769
  id: google.adk.utils.yaml_utils.multiline_str_representer
  name: multiline_str_representer
  file_path: google/adk/utils/yaml_utils.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def multiline_str_representer(dumper, data):'
- rank: 1770
  id: google.adk.version
  name: version
  file_path: google/adk/version.py
  type: MODULE
  group: Orphan
  usage_score: 0
- rank: 1771
  id: google.genai
  name: root
  file_path: env/lib/python3.13/site-packages/google/genai/__init__.py
  type: MODULE
  group: Orphan
  usage_score: 0
  docstring: Google Gen AI SDK
- rank: 1772
  id: google.genai.batches
  name: batches
  file_path: env/lib/python3.13/site-packages/google/genai/batches.py
  type: MODULE
  group: Orphan
  usage_score: 0
- rank: 1773
  id: google.genai.batches.AsyncBatches
  name: AsyncBatches
  file_path: env/lib/python3.13/site-packages/google/genai/batches.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: '[Note: Inherited members from _api_module.BaseModule are omitted.]'
  methods:
  - signature: 'def get(self, *, name: str, config: typing.Optional[google.genai.types.GetBatchJobConfigOrDict]=None) -> google.genai.types.BatchJob:'
    docstring: "Gets a batch job.\n\nArgs:\n  name (str): A fully-qualified BatchJob resource name or ID.\n    Example: \"projects/.../locations/.../batchPredictionJobs/456\" or \"456\"\n      when project and location are initialized in the Vertex AI client. Or\n      \"batches/abc\" using the Gemini Developer AI client.\n\nReturns:\n  A BatchJob object that contains details about the batch job.\n\nUsage:\n\n.. code-block:: python\n\n  batch_job = await client.aio.batches.get(name='123456789')\n  print(f\"Batch job: {batch_job.name}, state {batch_job.state}\")"
  - signature: 'def cancel(self, *, name: str, config: typing.Optional[google.genai.types.CancelBatchJobConfigOrDict]=None) -> None:'
    docstring: "Cancels a batch job.\n\nOnly available for batch jobs that are running or pending.\n\nArgs:\n  name (str): A fully-qualified BatchJob resource name or ID.\n    Example: \"projects/.../locations/.../batchPredictionJobs/456\" or \"456\"\n      when project and location are initialized in the Vertex AI client. Or\n      \"batches/abc\" using the Gemini Developer AI client.\n\nUsage:\n\n.. code-block:: python\n\n  await client.aio.batches.cancel(name='123456789')"
  - signature: 'def delete(self, *, name: str, config: typing.Optional[google.genai.types.DeleteBatchJobConfigOrDict]=None) -> google.genai.types.DeleteResourceJob:'
    docstring: "Deletes a batch job.\n\nArgs:\n  name (str): A fully-qualified BatchJob resource name or ID.\n    Example: \"projects/.../locations/.../batchPredictionJobs/456\" or \"456\"\n      when project and location are initialized in the client.\n\nReturns:\n  A DeleteResourceJob object that shows the status of the deletion.\n\nUsage:\n\n.. code-block:: python\n\n  await client.aio.batches.delete(name='123456789')"
  - signature: 'def list(self, *, config: typing.Optional[google.genai.types.ListBatchJobsConfigOrDict]=None) -> google.genai.pagers.AsyncPager[google.genai.types.BatchJob]:'
    docstring: "Lists batch jobs asynchronously.\n\nArgs:\n  config (ListBatchJobsConfig): Optional configuration for the list request.\n\nReturns:\n  A Pager object that contains one page of batch jobs. When iterating over\n  the pager, it automatically fetches the next page if there are more.\n\nUsage:\n\n.. code-block:: python\n  async for batch_job in await client.aio.batches.list():\n    print(batch_job.name)"
  - signature: 'def create(self, *, model: str, src: google.genai.types.BatchJobSourceUnionDict, config: typing.Optional[google.genai.types.CreateBatchJobConfigOrDict]=None) -> google.genai.types.BatchJob:'
    docstring: "Creates a batch job asynchronously.\n\nArgs:\n  model (str): The model to use for the batch job.\n  src: The source of the batch job. Currently Vertex AI supports GCS URI(-s)\n    or BigQuery URI. Example: \"gs://path/to/input/data\" or\n    \"bq://projectId.bqDatasetId.bqTableId\". Gemini Develop API supports List\n    of inlined_request, or file name. Example: \"files/file_name\".\n  config (CreateBatchJobConfig): Optional configuration for the batch job.\n\nReturns:\n  A BatchJob object that contains details about the batch job.\n\nUsage:\n\n.. code-block:: python\n\n  batch_job = await client.aio.batches.create(\n      model=\"gemini-2.0-flash-001\",\n      src=\"gs://path/to/input/data\",\n  )"
  - signature: 'def create_embeddings(self, *, model: str, src: google.genai.types.EmbeddingsBatchJobSourceOrDict, config: typing.Optional[google.genai.types.CreateEmbeddingsBatchJobConfigOrDict]=None) -> google.genai.types.BatchJob:'
    docstring: "**Experimental** Creates an asynchronously embedding batch job.\n\nArgs:\n  model (str): The model to use for the batch job.\n  src: Gemini Developer API supports inlined_requests, or file name.\n    Example: \"files/file_name\".\n  config (CreateBatchJobConfig): Optional configuration for the batch job.\n\nReturns:\n  A BatchJob object that contains details about the batch job.\n\nUsage:\n\n.. code-block:: python\n\n  batch_job = await client.aio.batches.create_embeddings(\n      model=\"text-embedding-004\",\n      src=\"files/my_embedding_input\",\n  )\n  print(batch_job.state)"
  omitted_inherited_members_from:
  - _api_module.BaseModule
- rank: 1774
  id: google.genai.batches.AsyncBatches.cancel
  name: cancel
  file_path: env/lib/python3.13/site-packages/google/genai/batches.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Cancels a batch job.\n\nOnly available for batch jobs that are running or pending.\n\nArgs:\n  name (str): A fully-qualified BatchJob resource name or ID.\n    Example: \"projects/.../locations/.../batchPredictionJobs/456\" or \"456\"\n      when project and location are initialized in the Vertex AI client. Or\n      \"batches/abc\" using the Gemini Developer AI client.\n\nUsage:\n\n.. code-block:: python\n\n  await client.aio.batches.cancel(name='123456789')"
  signature: 'def cancel(self, *, name: str, config: typing.Optional[google.genai.types.CancelBatchJobConfigOrDict]=None) -> None:'
- rank: 1775
  id: google.genai.batches.AsyncBatches.create
  name: create
  file_path: env/lib/python3.13/site-packages/google/genai/batches.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Creates a batch job asynchronously.\n\nArgs:\n  model (str): The model to use for the batch job.\n  src: The source of the batch job. Currently Vertex AI supports GCS URI(-s)\n    or BigQuery URI. Example: \"gs://path/to/input/data\" or\n    \"bq://projectId.bqDatasetId.bqTableId\". Gemini Develop API supports List\n    of inlined_request, or file name. Example: \"files/file_name\".\n  config (CreateBatchJobConfig): Optional configuration for the batch job.\n\nReturns:\n  A BatchJob object that contains details about the batch job.\n\nUsage:\n\n.. code-block:: python\n\n  batch_job = await client.aio.batches.create(\n      model=\"gemini-2.0-flash-001\",\n      src=\"gs://path/to/input/data\",\n  )"
  signature: 'def create(self, *, model: str, src: google.genai.types.BatchJobSourceUnionDict, config: typing.Optional[google.genai.types.CreateBatchJobConfigOrDict]=None) -> google.genai.types.BatchJob:'
- rank: 1776
  id: google.genai.batches.AsyncBatches.create_embeddings
  name: create_embeddings
  file_path: env/lib/python3.13/site-packages/google/genai/batches.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "**Experimental** Creates an asynchronously embedding batch job.\n\nArgs:\n  model (str): The model to use for the batch job.\n  src: Gemini Developer API supports inlined_requests, or file name.\n    Example: \"files/file_name\".\n  config (CreateBatchJobConfig): Optional configuration for the batch job.\n\nReturns:\n  A BatchJob object that contains details about the batch job.\n\nUsage:\n\n.. code-block:: python\n\n  batch_job = await client.aio.batches.create_embeddings(\n      model=\"text-embedding-004\",\n      src=\"files/my_embedding_input\",\n  )\n  print(batch_job.state)"
  signature: 'def create_embeddings(self, *, model: str, src: google.genai.types.EmbeddingsBatchJobSourceOrDict, config: typing.Optional[google.genai.types.CreateEmbeddingsBatchJobConfigOrDict]=None) -> google.genai.types.BatchJob:'
- rank: 1777
  id: google.genai.batches.AsyncBatches.delete
  name: delete
  file_path: env/lib/python3.13/site-packages/google/genai/batches.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Deletes a batch job.\n\nArgs:\n  name (str): A fully-qualified BatchJob resource name or ID.\n    Example: \"projects/.../locations/.../batchPredictionJobs/456\" or \"456\"\n      when project and location are initialized in the client.\n\nReturns:\n  A DeleteResourceJob object that shows the status of the deletion.\n\nUsage:\n\n.. code-block:: python\n\n  await client.aio.batches.delete(name='123456789')"
  signature: 'def delete(self, *, name: str, config: typing.Optional[google.genai.types.DeleteBatchJobConfigOrDict]=None) -> google.genai.types.DeleteResourceJob:'
- rank: 1778
  id: google.genai.batches.AsyncBatches.get
  name: get
  file_path: env/lib/python3.13/site-packages/google/genai/batches.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Gets a batch job.\n\nArgs:\n  name (str): A fully-qualified BatchJob resource name or ID.\n    Example: \"projects/.../locations/.../batchPredictionJobs/456\" or \"456\"\n      when project and location are initialized in the Vertex AI client. Or\n      \"batches/abc\" using the Gemini Developer AI client.\n\nReturns:\n  A BatchJob object that contains details about the batch job.\n\nUsage:\n\n.. code-block:: python\n\n  batch_job = await client.aio.batches.get(name='123456789')\n  print(f\"Batch job: {batch_job.name}, state {batch_job.state}\")"
  signature: 'def get(self, *, name: str, config: typing.Optional[google.genai.types.GetBatchJobConfigOrDict]=None) -> google.genai.types.BatchJob:'
- rank: 1779
  id: google.genai.batches.AsyncBatches.list
  name: list
  file_path: env/lib/python3.13/site-packages/google/genai/batches.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Lists batch jobs asynchronously.\n\nArgs:\n  config (ListBatchJobsConfig): Optional configuration for the list request.\n\nReturns:\n  A Pager object that contains one page of batch jobs. When iterating over\n  the pager, it automatically fetches the next page if there are more.\n\nUsage:\n\n.. code-block:: python\n  async for batch_job in await client.aio.batches.list():\n    print(batch_job.name)"
  signature: 'def list(self, *, config: typing.Optional[google.genai.types.ListBatchJobsConfigOrDict]=None) -> google.genai.pagers.AsyncPager[google.genai.types.BatchJob]:'
- rank: 1780
  id: google.genai.batches.Batches
  name: Batches
  file_path: env/lib/python3.13/site-packages/google/genai/batches.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: '[Note: Inherited members from _api_module.BaseModule are omitted.]'
  methods:
  - signature: 'def get(self, *, name: str, config: typing.Optional[google.genai.types.GetBatchJobConfigOrDict]=None) -> google.genai.types.BatchJob:'
    docstring: "Gets a batch job.\n\nArgs:\n  name (str): A fully-qualified BatchJob resource name or ID.\n    Example: \"projects/.../locations/.../batchPredictionJobs/456\" or \"456\"\n      when project and location are initialized in the Vertex AI client. Or\n      \"batches/abc\" using the Gemini Developer AI client.\n\nReturns:\n  A BatchJob object that contains details about the batch job.\n\nUsage:\n\n.. code-block:: python\n\n  batch_job = client.batches.get(name='123456789')\n  print(f\"Batch job: {batch_job.name}, state {batch_job.state}\")"
  - signature: 'def cancel(self, *, name: str, config: typing.Optional[google.genai.types.CancelBatchJobConfigOrDict]=None) -> None:'
    docstring: "Cancels a batch job.\n\nOnly available for batch jobs that are running or pending.\n\nArgs:\n  name (str): A fully-qualified BatchJob resource name or ID.\n    Example: \"projects/.../locations/.../batchPredictionJobs/456\" or \"456\"\n      when project and location are initialized in the Vertex AI client. Or\n      \"batches/abc\" using the Gemini Developer AI client.\n\nUsage:\n\n.. code-block:: python\n\n  client.batches.cancel(name='123456789')"
  - signature: 'def delete(self, *, name: str, config: typing.Optional[google.genai.types.DeleteBatchJobConfigOrDict]=None) -> google.genai.types.DeleteResourceJob:'
    docstring: "Deletes a batch job.\n\nArgs:\n  name (str): A fully-qualified BatchJob resource name or ID.\n    Example: \"projects/.../locations/.../batchPredictionJobs/456\" or \"456\"\n      when project and location are initialized in the client.\n\nReturns:\n  A DeleteResourceJob object that shows the status of the deletion.\n\nUsage:\n\n.. code-block:: python\n\n  client.batches.delete(name='123456789')"
  - signature: 'def list(self, *, config: typing.Optional[google.genai.types.ListBatchJobsConfigOrDict]=None) -> google.genai.pagers.Pager[google.genai.types.BatchJob]:'
    docstring: "Lists batch jobs.\n\nArgs:\n  config (ListBatchJobsConfig): Optional configuration for the list request.\n\nReturns:\n  A Pager object that contains one page of batch jobs. When iterating over\n  the pager, it automatically fetches the next page if there are more.\n\nUsage:\n\n.. code-block:: python\n  config = {'page_size': 10}\n  for batch_job in client.batches.list(config):\n    print(batch_job.name)"
  - signature: 'def create(self, *, model: str, src: google.genai.types.BatchJobSourceUnionDict, config: typing.Optional[google.genai.types.CreateBatchJobConfigOrDict]=None) -> google.genai.types.BatchJob:'
    docstring: "Creates a batch job.\n\nArgs:\n  model (str): The model to use for the batch job.\n  src: The source of the batch job. Currently Vertex AI supports GCS URI(-s)\n    or BigQuery URI. Example: \"gs://path/to/input/data\" or\n    \"bq://projectId.bqDatasetId.bqTableId\". Gemini Developer API supports\n    List of inlined_request, or file name. Example: \"files/file_name\".\n  config (CreateBatchJobConfig): Optional configuration for the batch job.\n\nReturns:\n  A BatchJob object that contains details about the batch job.\n\nUsage:\n\n.. code-block:: python\n\n  batch_job = client.batches.create(\n      model=\"gemini-2.0-flash-001\",\n      src=\"gs://path/to/input/data\",\n  )\n  print(batch_job.state)"
  - signature: 'def create_embeddings(self, *, model: str, src: google.genai.types.EmbeddingsBatchJobSourceOrDict, config: typing.Optional[google.genai.types.CreateEmbeddingsBatchJobConfigOrDict]=None) -> google.genai.types.BatchJob:'
    docstring: "**Experimental** Creates an embedding batch job.\n\nArgs:\n  model (str): The model to use for the batch job.\n  src: Gemini Developer API supports List of inlined_request, or file name.\n    Example: \"files/file_name\".\n  config (CreateBatchJobConfig): Optional configuration for the batch job.\n\nReturns:\n  A BatchJob object that contains details about the batch job.\n\nUsage:\n\n.. code-block:: python\n\n  batch_job = client.batches.create_embeddings(\n      model=\"text-embedding-004\",\n      src=\"files/my_embedding_input\",\n  )\n  print(batch_job.state)"
  omitted_inherited_members_from:
  - _api_module.BaseModule
- rank: 1781
  id: google.genai.batches.Batches.cancel
  name: cancel
  file_path: env/lib/python3.13/site-packages/google/genai/batches.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Cancels a batch job.\n\nOnly available for batch jobs that are running or pending.\n\nArgs:\n  name (str): A fully-qualified BatchJob resource name or ID.\n    Example: \"projects/.../locations/.../batchPredictionJobs/456\" or \"456\"\n      when project and location are initialized in the Vertex AI client. Or\n      \"batches/abc\" using the Gemini Developer AI client.\n\nUsage:\n\n.. code-block:: python\n\n  client.batches.cancel(name='123456789')"
  signature: 'def cancel(self, *, name: str, config: typing.Optional[google.genai.types.CancelBatchJobConfigOrDict]=None) -> None:'
- rank: 1782
  id: google.genai.batches.Batches.create
  name: create
  file_path: env/lib/python3.13/site-packages/google/genai/batches.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Creates a batch job.\n\nArgs:\n  model (str): The model to use for the batch job.\n  src: The source of the batch job. Currently Vertex AI supports GCS URI(-s)\n    or BigQuery URI. Example: \"gs://path/to/input/data\" or\n    \"bq://projectId.bqDatasetId.bqTableId\". Gemini Developer API supports\n    List of inlined_request, or file name. Example: \"files/file_name\".\n  config (CreateBatchJobConfig): Optional configuration for the batch job.\n\nReturns:\n  A BatchJob object that contains details about the batch job.\n\nUsage:\n\n.. code-block:: python\n\n  batch_job = client.batches.create(\n      model=\"gemini-2.0-flash-001\",\n      src=\"gs://path/to/input/data\",\n  )\n  print(batch_job.state)"
  signature: 'def create(self, *, model: str, src: google.genai.types.BatchJobSourceUnionDict, config: typing.Optional[google.genai.types.CreateBatchJobConfigOrDict]=None) -> google.genai.types.BatchJob:'
- rank: 1783
  id: google.genai.batches.Batches.create_embeddings
  name: create_embeddings
  file_path: env/lib/python3.13/site-packages/google/genai/batches.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "**Experimental** Creates an embedding batch job.\n\nArgs:\n  model (str): The model to use for the batch job.\n  src: Gemini Developer API supports List of inlined_request, or file name.\n    Example: \"files/file_name\".\n  config (CreateBatchJobConfig): Optional configuration for the batch job.\n\nReturns:\n  A BatchJob object that contains details about the batch job.\n\nUsage:\n\n.. code-block:: python\n\n  batch_job = client.batches.create_embeddings(\n      model=\"text-embedding-004\",\n      src=\"files/my_embedding_input\",\n  )\n  print(batch_job.state)"
  signature: 'def create_embeddings(self, *, model: str, src: google.genai.types.EmbeddingsBatchJobSourceOrDict, config: typing.Optional[google.genai.types.CreateEmbeddingsBatchJobConfigOrDict]=None) -> google.genai.types.BatchJob:'
- rank: 1784
  id: google.genai.batches.Batches.delete
  name: delete
  file_path: env/lib/python3.13/site-packages/google/genai/batches.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Deletes a batch job.\n\nArgs:\n  name (str): A fully-qualified BatchJob resource name or ID.\n    Example: \"projects/.../locations/.../batchPredictionJobs/456\" or \"456\"\n      when project and location are initialized in the client.\n\nReturns:\n  A DeleteResourceJob object that shows the status of the deletion.\n\nUsage:\n\n.. code-block:: python\n\n  client.batches.delete(name='123456789')"
  signature: 'def delete(self, *, name: str, config: typing.Optional[google.genai.types.DeleteBatchJobConfigOrDict]=None) -> google.genai.types.DeleteResourceJob:'
- rank: 1785
  id: google.genai.batches.Batches.get
  name: get
  file_path: env/lib/python3.13/site-packages/google/genai/batches.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Gets a batch job.\n\nArgs:\n  name (str): A fully-qualified BatchJob resource name or ID.\n    Example: \"projects/.../locations/.../batchPredictionJobs/456\" or \"456\"\n      when project and location are initialized in the Vertex AI client. Or\n      \"batches/abc\" using the Gemini Developer AI client.\n\nReturns:\n  A BatchJob object that contains details about the batch job.\n\nUsage:\n\n.. code-block:: python\n\n  batch_job = client.batches.get(name='123456789')\n  print(f\"Batch job: {batch_job.name}, state {batch_job.state}\")"
  signature: 'def get(self, *, name: str, config: typing.Optional[google.genai.types.GetBatchJobConfigOrDict]=None) -> google.genai.types.BatchJob:'
- rank: 1786
  id: google.genai.batches.Batches.list
  name: list
  file_path: env/lib/python3.13/site-packages/google/genai/batches.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Lists batch jobs.\n\nArgs:\n  config (ListBatchJobsConfig): Optional configuration for the list request.\n\nReturns:\n  A Pager object that contains one page of batch jobs. When iterating over\n  the pager, it automatically fetches the next page if there are more.\n\nUsage:\n\n.. code-block:: python\n  config = {'page_size': 10}\n  for batch_job in client.batches.list(config):\n    print(batch_job.name)"
  signature: 'def list(self, *, config: typing.Optional[google.genai.types.ListBatchJobsConfigOrDict]=None) -> google.genai.pagers.Pager[google.genai.types.BatchJob]:'
- rank: 1787
  id: google.genai.caches
  name: caches
  file_path: env/lib/python3.13/site-packages/google/genai/caches.py
  type: MODULE
  group: Orphan
  usage_score: 0
- rank: 1788
  id: google.genai.caches.AsyncCaches
  name: AsyncCaches
  file_path: env/lib/python3.13/site-packages/google/genai/caches.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: '[Note: Inherited members from _api_module.BaseModule are omitted.]'
  methods:
  - signature: 'def create(self, *, model: str, config: typing.Optional[google.genai.types.CreateCachedContentConfigOrDict]=None) -> google.genai.types.CachedContent:'
    docstring: "Creates a cached contents resource.\n\nUsage:\n\n.. code-block:: python\n\n  contents = ... // Initialize the content to cache.\n  response = await client.aio.caches.create(\n      model= ... // The publisher model id\n      contents=contents,\n      config={\n          'display_name': 'test cache',\n          'system_instruction': 'What is the sum of the two pdfs?',\n          'ttl': '86400s',\n      },\n  )"
  - signature: 'def get(self, *, name: str, config: typing.Optional[google.genai.types.GetCachedContentConfigOrDict]=None) -> google.genai.types.CachedContent:'
    docstring: "Gets cached content configurations.\n\n.. code-block:: python\n\n  await client.aio.caches.get(name= ... ) // The server-generated resource\n  name."
  - signature: 'def delete(self, *, name: str, config: typing.Optional[google.genai.types.DeleteCachedContentConfigOrDict]=None) -> google.genai.types.DeleteCachedContentResponse:'
    docstring: "Deletes cached content.\n\nUsage:\n\n.. code-block:: python\n\n  await client.aio.caches.delete(name= ... ) // The server-generated\n  resource name."
  - signature: 'def update(self, *, name: str, config: typing.Optional[google.genai.types.UpdateCachedContentConfigOrDict]=None) -> google.genai.types.CachedContent:'
    docstring: "Updates cached content configurations.\n\n.. code-block:: python\n\n  response = await client.aio.caches.update(\n      name= ... // The server-generated resource name.\n      config={\n          'ttl': '7600s',\n      },\n  )"
  - signature: 'def list(self, *, config: typing.Optional[google.genai.types.ListCachedContentsConfigOrDict]=None) -> google.genai.pagers.AsyncPager[google.genai.types.CachedContent]:'
    docstring: "Lists cached contents asynchronously.\n\nArgs:\n  config (ListCachedContentsConfig): Optional configuration for the list\n    request.\n\nReturns:\n  A Pager object that contains one page of cached contents. When iterating\n  over\n  the pager, it automatically fetches the next page if there are more.\n\nUsage:\n\n.. code-block:: python\n  async for cached_content in await client.aio.caches.list():\n    print(cached_content.name)"
  omitted_inherited_members_from:
  - _api_module.BaseModule
- rank: 1789
  id: google.genai.caches.AsyncCaches.create
  name: create
  file_path: env/lib/python3.13/site-packages/google/genai/caches.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Creates a cached contents resource.\n\nUsage:\n\n.. code-block:: python\n\n  contents = ... // Initialize the content to cache.\n  response = await client.aio.caches.create(\n      model= ... // The publisher model id\n      contents=contents,\n      config={\n          'display_name': 'test cache',\n          'system_instruction': 'What is the sum of the two pdfs?',\n          'ttl': '86400s',\n      },\n  )"
  signature: 'def create(self, *, model: str, config: typing.Optional[google.genai.types.CreateCachedContentConfigOrDict]=None) -> google.genai.types.CachedContent:'
- rank: 1790
  id: google.genai.caches.AsyncCaches.delete
  name: delete
  file_path: env/lib/python3.13/site-packages/google/genai/caches.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Deletes cached content.\n\nUsage:\n\n.. code-block:: python\n\n  await client.aio.caches.delete(name= ... ) // The server-generated\n  resource name."
  signature: 'def delete(self, *, name: str, config: typing.Optional[google.genai.types.DeleteCachedContentConfigOrDict]=None) -> google.genai.types.DeleteCachedContentResponse:'
- rank: 1791
  id: google.genai.caches.AsyncCaches.get
  name: get
  file_path: env/lib/python3.13/site-packages/google/genai/caches.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Gets cached content configurations.\n\n.. code-block:: python\n\n  await client.aio.caches.get(name= ... ) // The server-generated resource\n  name."
  signature: 'def get(self, *, name: str, config: typing.Optional[google.genai.types.GetCachedContentConfigOrDict]=None) -> google.genai.types.CachedContent:'
- rank: 1792
  id: google.genai.caches.AsyncCaches.list
  name: list
  file_path: env/lib/python3.13/site-packages/google/genai/caches.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Lists cached contents asynchronously.\n\nArgs:\n  config (ListCachedContentsConfig): Optional configuration for the list\n    request.\n\nReturns:\n  A Pager object that contains one page of cached contents. When iterating\n  over\n  the pager, it automatically fetches the next page if there are more.\n\nUsage:\n\n.. code-block:: python\n  async for cached_content in await client.aio.caches.list():\n    print(cached_content.name)"
  signature: 'def list(self, *, config: typing.Optional[google.genai.types.ListCachedContentsConfigOrDict]=None) -> google.genai.pagers.AsyncPager[google.genai.types.CachedContent]:'
- rank: 1793
  id: google.genai.caches.AsyncCaches.update
  name: update
  file_path: env/lib/python3.13/site-packages/google/genai/caches.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Updates cached content configurations.\n\n.. code-block:: python\n\n  response = await client.aio.caches.update(\n      name= ... // The server-generated resource name.\n      config={\n          'ttl': '7600s',\n      },\n  )"
  signature: 'def update(self, *, name: str, config: typing.Optional[google.genai.types.UpdateCachedContentConfigOrDict]=None) -> google.genai.types.CachedContent:'
- rank: 1794
  id: google.genai.caches.Caches
  name: Caches
  file_path: env/lib/python3.13/site-packages/google/genai/caches.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: '[Note: Inherited members from _api_module.BaseModule are omitted.]'
  methods:
  - signature: 'def create(self, *, model: str, config: typing.Optional[google.genai.types.CreateCachedContentConfigOrDict]=None) -> google.genai.types.CachedContent:'
    docstring: "Creates a cached contents resource.\n\nUsage:\n\n.. code-block:: python\n\n  contents = ... // Initialize the content to cache.\n  response = client.caches.create(\n      model= ... // The publisher model id\n      contents=contents,\n      config={\n          'display_name': 'test cache',\n          'system_instruction': 'What is the sum of the two pdfs?',\n          'ttl': '86400s',\n      },\n  )"
  - signature: 'def get(self, *, name: str, config: typing.Optional[google.genai.types.GetCachedContentConfigOrDict]=None) -> google.genai.types.CachedContent:'
    docstring: "Gets cached content configurations.\n\n.. code-block:: python\n\n  client.caches.get(name= ... ) // The server-generated resource name."
  - signature: 'def delete(self, *, name: str, config: typing.Optional[google.genai.types.DeleteCachedContentConfigOrDict]=None) -> google.genai.types.DeleteCachedContentResponse:'
    docstring: "Deletes cached content.\n\nUsage:\n\n.. code-block:: python\n\n  client.caches.delete(name= ... ) // The server-generated resource name."
  - signature: 'def update(self, *, name: str, config: typing.Optional[google.genai.types.UpdateCachedContentConfigOrDict]=None) -> google.genai.types.CachedContent:'
    docstring: "Updates cached content configurations.\n\n.. code-block:: python\n\n  response = client.caches.update(\n      name= ... // The server-generated resource name.\n      config={\n          'ttl': '7600s',\n      },\n  )"
  - signature: 'def list(self, *, config: typing.Optional[google.genai.types.ListCachedContentsConfigOrDict]=None) -> google.genai.pagers.Pager[google.genai.types.CachedContent]:'
    docstring: "Lists cached contents.\n\nArgs:\n  config (ListCachedContentsConfig): Optional configuration for the list\n    request.\n\nReturns:\n  A Pager object that contains one page of cached contents. When iterating\n  over\n  the pager, it automatically fetches the next page if there are more.\n\nUsage:\n\n.. code-block:: python\n  for cached_content in client.caches.list():\n    print(cached_content.name)"
  omitted_inherited_members_from:
  - _api_module.BaseModule
- rank: 1795
  id: google.genai.caches.Caches.create
  name: create
  file_path: env/lib/python3.13/site-packages/google/genai/caches.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Creates a cached contents resource.\n\nUsage:\n\n.. code-block:: python\n\n  contents = ... // Initialize the content to cache.\n  response = client.caches.create(\n      model= ... // The publisher model id\n      contents=contents,\n      config={\n          'display_name': 'test cache',\n          'system_instruction': 'What is the sum of the two pdfs?',\n          'ttl': '86400s',\n      },\n  )"
  signature: 'def create(self, *, model: str, config: typing.Optional[google.genai.types.CreateCachedContentConfigOrDict]=None) -> google.genai.types.CachedContent:'
- rank: 1796
  id: google.genai.caches.Caches.delete
  name: delete
  file_path: env/lib/python3.13/site-packages/google/genai/caches.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Deletes cached content.\n\nUsage:\n\n.. code-block:: python\n\n  client.caches.delete(name= ... ) // The server-generated resource name."
  signature: 'def delete(self, *, name: str, config: typing.Optional[google.genai.types.DeleteCachedContentConfigOrDict]=None) -> google.genai.types.DeleteCachedContentResponse:'
- rank: 1797
  id: google.genai.caches.Caches.get
  name: get
  file_path: env/lib/python3.13/site-packages/google/genai/caches.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Gets cached content configurations.\n\n.. code-block:: python\n\n  client.caches.get(name= ... ) // The server-generated resource name."
  signature: 'def get(self, *, name: str, config: typing.Optional[google.genai.types.GetCachedContentConfigOrDict]=None) -> google.genai.types.CachedContent:'
- rank: 1798
  id: google.genai.caches.Caches.list
  name: list
  file_path: env/lib/python3.13/site-packages/google/genai/caches.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Lists cached contents.\n\nArgs:\n  config (ListCachedContentsConfig): Optional configuration for the list\n    request.\n\nReturns:\n  A Pager object that contains one page of cached contents. When iterating\n  over\n  the pager, it automatically fetches the next page if there are more.\n\nUsage:\n\n.. code-block:: python\n  for cached_content in client.caches.list():\n    print(cached_content.name)"
  signature: 'def list(self, *, config: typing.Optional[google.genai.types.ListCachedContentsConfigOrDict]=None) -> google.genai.pagers.Pager[google.genai.types.CachedContent]:'
- rank: 1799
  id: google.genai.caches.Caches.update
  name: update
  file_path: env/lib/python3.13/site-packages/google/genai/caches.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Updates cached content configurations.\n\n.. code-block:: python\n\n  response = client.caches.update(\n      name= ... // The server-generated resource name.\n      config={\n          'ttl': '7600s',\n      },\n  )"
  signature: 'def update(self, *, name: str, config: typing.Optional[google.genai.types.UpdateCachedContentConfigOrDict]=None) -> google.genai.types.CachedContent:'
- rank: 1800
  id: google.genai.chats
  name: chats
  file_path: env/lib/python3.13/site-packages/google/genai/chats.py
  type: MODULE
  group: Orphan
  usage_score: 0
- rank: 1801
  id: google.genai.chats.AsyncChat
  name: AsyncChat
  file_path: env/lib/python3.13/site-packages/google/genai/chats.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Async chat session.


    [Note: Inherited members from _BaseChat are omitted.]'
  constructor_signature: 'def __init__(self, *, modules: google.genai.models.AsyncModels, model: str, config: typing.Optional[google.genai.types.GenerateContentConfigOrDict]=None, history: list[google.genai.types.ContentOrDict]):'
  methods:
  - signature: 'def send_message(self, message: typing.Union[list[google.genai.types.PartUnionDict], google.genai.types.PartUnionDict], config: typing.Optional[google.genai.types.GenerateContentConfigOrDict]) -> google.genai.types.GenerateContentResponse:'
    docstring: "Sends the conversation history with the additional message and returns model's response.\n\nArgs:\n  message: The message to send to the model.\n  config: Optional config to override the default Chat config for this\n    request.\n\nReturns:\n  The model's response.\n\nUsage:\n\n.. code-block:: python\n\n  chat = client.aio.chats.create(model='gemini-2.0-flash')\n  response = await chat.send_message('tell me a story')"
  - signature: 'def send_message_stream(self, message: typing.Union[list[google.genai.types.PartUnionDict], google.genai.types.PartUnionDict], config: typing.Optional[google.genai.types.GenerateContentConfigOrDict]) -> typing.AsyncIterator[google.genai.types.GenerateContentResponse]:'
    docstring: "Sends the conversation history with the additional message and yields the model's response in chunks.\n\nArgs:\n  message: The message to send to the model.\n  config: Optional config to override the default Chat config for this\n    request.\n\nYields:\n  The model's response in chunks.\n\nUsage:\n\n.. code-block:: python\n\n  chat = client.aio.chats.create(model='gemini-2.0-flash')\n  async for chunk in await chat.send_message_stream('tell me a story'):\n    print(chunk.text)"
  - signature: 'def async_generator():'
  omitted_inherited_members_from:
  - _BaseChat
- rank: 1802
  id: google.genai.chats.AsyncChat.__init__
  name: __init__
  file_path: env/lib/python3.13/site-packages/google/genai/chats.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def __init__(self, *, modules: google.genai.models.AsyncModels, model: str, config: typing.Optional[google.genai.types.GenerateContentConfigOrDict]=None, history: list[google.genai.types.ContentOrDict]):'
- rank: 1803
  id: google.genai.chats.AsyncChat.async_generator
  name: async_generator
  file_path: env/lib/python3.13/site-packages/google/genai/chats.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def async_generator():'
- rank: 1804
  id: google.genai.chats.AsyncChat.send_message
  name: send_message
  file_path: env/lib/python3.13/site-packages/google/genai/chats.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Sends the conversation history with the additional message and returns model's response.\n\nArgs:\n  message: The message to send to the model.\n  config: Optional config to override the default Chat config for this\n    request.\n\nReturns:\n  The model's response.\n\nUsage:\n\n.. code-block:: python\n\n  chat = client.aio.chats.create(model='gemini-2.0-flash')\n  response = await chat.send_message('tell me a story')"
  signature: 'def send_message(self, message: typing.Union[list[google.genai.types.PartUnionDict], google.genai.types.PartUnionDict], config: typing.Optional[google.genai.types.GenerateContentConfigOrDict]) -> google.genai.types.GenerateContentResponse:'
- rank: 1805
  id: google.genai.chats.AsyncChat.send_message_stream
  name: send_message_stream
  file_path: env/lib/python3.13/site-packages/google/genai/chats.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Sends the conversation history with the additional message and yields the model's response in chunks.\n\nArgs:\n  message: The message to send to the model.\n  config: Optional config to override the default Chat config for this\n    request.\n\nYields:\n  The model's response in chunks.\n\nUsage:\n\n.. code-block:: python\n\n  chat = client.aio.chats.create(model='gemini-2.0-flash')\n  async for chunk in await chat.send_message_stream('tell me a story'):\n    print(chunk.text)"
  signature: 'def send_message_stream(self, message: typing.Union[list[google.genai.types.PartUnionDict], google.genai.types.PartUnionDict], config: typing.Optional[google.genai.types.GenerateContentConfigOrDict]) -> typing.AsyncIterator[google.genai.types.GenerateContentResponse]:'
- rank: 1806
  id: google.genai.chats.AsyncChats
  name: AsyncChats
  file_path: env/lib/python3.13/site-packages/google/genai/chats.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: A util class to create async chat sessions.
  constructor_signature: 'def __init__(self, modules: google.genai.models.AsyncModels):'
  methods:
  - signature: 'def create(self, *, model: str, config: typing.Optional[google.genai.types.GenerateContentConfigOrDict]=None, history: typing.Optional[list[google.genai.types.ContentOrDict]]=None) -> google.genai.chats.AsyncChat:'
    docstring: "Creates a new chat session.\n\nArgs:\n  model: The model to use for the chat.\n  config: The configuration to use for the generate content request.\n  history: The history to use for the chat.\n\nReturns:\n  A new chat session."
- rank: 1807
  id: google.genai.chats.AsyncChats.create
  name: create
  file_path: env/lib/python3.13/site-packages/google/genai/chats.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Creates a new chat session.\n\nArgs:\n  model: The model to use for the chat.\n  config: The configuration to use for the generate content request.\n  history: The history to use for the chat.\n\nReturns:\n  A new chat session."
  signature: 'def create(self, *, model: str, config: typing.Optional[google.genai.types.GenerateContentConfigOrDict]=None, history: typing.Optional[list[google.genai.types.ContentOrDict]]=None) -> google.genai.chats.AsyncChat:'
- rank: 1808
  id: google.genai.chats.Chat
  name: Chat
  file_path: env/lib/python3.13/site-packages/google/genai/chats.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Chat session.


    [Note: Inherited members from _BaseChat are omitted.]'
  constructor_signature: 'def __init__(self, *, modules: google.genai.models.Models, model: str, config: typing.Optional[google.genai.types.GenerateContentConfigOrDict]=None, history: list[google.genai.types.ContentOrDict]):'
  methods:
  - signature: 'def send_message(self, message: typing.Union[list[google.genai.types.PartUnionDict], google.genai.types.PartUnionDict], config: typing.Optional[google.genai.types.GenerateContentConfigOrDict]) -> google.genai.types.GenerateContentResponse:'
    docstring: "Sends the conversation history with the additional message and returns the model's response.\n\nArgs:\n  message: The message to send to the model.\n  config:  Optional config to override the default Chat config for this\n    request.\n\nReturns:\n  The model's response.\n\nUsage:\n\n.. code-block:: python\n\n  chat = client.chats.create(model='gemini-2.0-flash')\n  response = chat.send_message('tell me a story')"
  - signature: 'def send_message_stream(self, message: typing.Union[list[google.genai.types.PartUnionDict], google.genai.types.PartUnionDict], config: typing.Optional[google.genai.types.GenerateContentConfigOrDict]) -> collections.abc.Iterator[google.genai.types.GenerateContentResponse]:'
    docstring: "Sends the conversation history with the additional message and yields the model's response in chunks.\n\nArgs:\n  message: The message to send to the model.\n  config: Optional config to override the default Chat config for this\n    request.\n\nYields:\n  The model's response in chunks.\n\nUsage:\n\n.. code-block:: python\n\n  chat = client.chats.create(model='gemini-2.0-flash')\n  for chunk in chat.send_message_stream('tell me a story'):\n    print(chunk.text)"
  omitted_inherited_members_from:
  - _BaseChat
- rank: 1809
  id: google.genai.chats.Chat.__init__
  name: __init__
  file_path: env/lib/python3.13/site-packages/google/genai/chats.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def __init__(self, *, modules: google.genai.models.Models, model: str, config: typing.Optional[google.genai.types.GenerateContentConfigOrDict]=None, history: list[google.genai.types.ContentOrDict]):'
- rank: 1810
  id: google.genai.chats.Chat.send_message
  name: send_message
  file_path: env/lib/python3.13/site-packages/google/genai/chats.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Sends the conversation history with the additional message and returns the model's response.\n\nArgs:\n  message: The message to send to the model.\n  config:  Optional config to override the default Chat config for this\n    request.\n\nReturns:\n  The model's response.\n\nUsage:\n\n.. code-block:: python\n\n  chat = client.chats.create(model='gemini-2.0-flash')\n  response = chat.send_message('tell me a story')"
  signature: 'def send_message(self, message: typing.Union[list[google.genai.types.PartUnionDict], google.genai.types.PartUnionDict], config: typing.Optional[google.genai.types.GenerateContentConfigOrDict]) -> google.genai.types.GenerateContentResponse:'
- rank: 1811
  id: google.genai.chats.Chat.send_message_stream
  name: send_message_stream
  file_path: env/lib/python3.13/site-packages/google/genai/chats.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Sends the conversation history with the additional message and yields the model's response in chunks.\n\nArgs:\n  message: The message to send to the model.\n  config: Optional config to override the default Chat config for this\n    request.\n\nYields:\n  The model's response in chunks.\n\nUsage:\n\n.. code-block:: python\n\n  chat = client.chats.create(model='gemini-2.0-flash')\n  for chunk in chat.send_message_stream('tell me a story'):\n    print(chunk.text)"
  signature: 'def send_message_stream(self, message: typing.Union[list[google.genai.types.PartUnionDict], google.genai.types.PartUnionDict], config: typing.Optional[google.genai.types.GenerateContentConfigOrDict]) -> collections.abc.Iterator[google.genai.types.GenerateContentResponse]:'
- rank: 1812
  id: google.genai.chats.Chats
  name: Chats
  file_path: env/lib/python3.13/site-packages/google/genai/chats.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: A util class to create chat sessions.
  constructor_signature: 'def __init__(self, modules: google.genai.models.Models):'
  methods:
  - signature: 'def create(self, *, model: str, config: typing.Optional[google.genai.types.GenerateContentConfigOrDict]=None, history: typing.Optional[list[google.genai.types.ContentOrDict]]=None) -> google.genai.chats.Chat:'
    docstring: "Creates a new chat session.\n\nArgs:\n  model: The model to use for the chat.\n  config: The configuration to use for the generate content request.\n  history: The history to use for the chat.\n\nReturns:\n  A new chat session."
- rank: 1813
  id: google.genai.chats.Chats.create
  name: create
  file_path: env/lib/python3.13/site-packages/google/genai/chats.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Creates a new chat session.\n\nArgs:\n  model: The model to use for the chat.\n  config: The configuration to use for the generate content request.\n  history: The history to use for the chat.\n\nReturns:\n  A new chat session."
  signature: 'def create(self, *, model: str, config: typing.Optional[google.genai.types.GenerateContentConfigOrDict]=None, history: typing.Optional[list[google.genai.types.ContentOrDict]]=None) -> google.genai.chats.Chat:'
- rank: 1814
  id: google.genai.client
  name: client
  file_path: env/lib/python3.13/site-packages/google/genai/client.py
  type: MODULE
  group: Orphan
  usage_score: 0
- rank: 1815
  id: google.genai.client.AsyncClient
  name: AsyncClient
  file_path: env/lib/python3.13/site-packages/google/genai/client.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: Client for making asynchronous (non-blocking) requests.
  constructor_signature: 'def __init__(self, api_client: google.genai._api_client.BaseApiClient):'
  methods:
  - signature: 'def models(self) -> google.genai.models.AsyncModels:'
  - signature: 'def tunings(self) -> google.genai.tunings.AsyncTunings:'
  - signature: 'def caches(self) -> google.genai.caches.AsyncCaches:'
  - signature: 'def file_search_stores(self) -> google.genai.file_search_stores.AsyncFileSearchStores:'
  - signature: 'def batches(self) -> google.genai.batches.AsyncBatches:'
  - signature: 'def chats(self) -> google.genai.chats.AsyncChats:'
  - signature: 'def files(self) -> google.genai.files.AsyncFiles:'
  - signature: 'def live(self) -> google.genai.live.AsyncLive:'
  - signature: 'def auth_tokens(self) -> google.genai.tokens.AsyncTokens:'
  - signature: 'def operations(self) -> google.genai.operations.AsyncOperations:'
  - signature: 'def aclose(self) -> None:'
    docstring: "Closes the async client explicitly.\n\nHowever, it doesn't close the sync client, which can be closed using the\nClient.close() method or using the context manager.\n\nUsage:\n.. code-block:: python\n\n  from google.genai import Client\n\n  async_client = Client(\n      vertexai=True, project='my-project-id', location='us-central1'\n  ).aio\n  response_1 = await async_client.models.generate_content(\n      model='gemini-2.0-flash',\n      contents='Hello World',\n  )\n  response_2 = await async_client.models.generate_content(\n      model='gemini-2.0-flash',\n      contents='Hello World',\n  )\n  # Close the client to release resources.\n  await async_client.aclose()"
- rank: 1816
  id: google.genai.client.AsyncClient.__init__
  name: __init__
  file_path: env/lib/python3.13/site-packages/google/genai/client.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def __init__(self, api_client: google.genai._api_client.BaseApiClient):'
- rank: 1817
  id: google.genai.client.AsyncClient.aclose
  name: aclose
  file_path: env/lib/python3.13/site-packages/google/genai/client.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Closes the async client explicitly.\n\nHowever, it doesn't close the sync client, which can be closed using the\nClient.close() method or using the context manager.\n\nUsage:\n.. code-block:: python\n\n  from google.genai import Client\n\n  async_client = Client(\n      vertexai=True, project='my-project-id', location='us-central1'\n  ).aio\n  response_1 = await async_client.models.generate_content(\n      model='gemini-2.0-flash',\n      contents='Hello World',\n  )\n  response_2 = await async_client.models.generate_content(\n      model='gemini-2.0-flash',\n      contents='Hello World',\n  )\n  # Close the client to release resources.\n  await async_client.aclose()"
  signature: 'def aclose(self) -> None:'
- rank: 1818
  id: google.genai.client.Client
  name: Client
  file_path: env/lib/python3.13/site-packages/google/genai/client.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: "Client for making synchronous requests.\n\nUse this client to make a request to the Gemini Developer API or Vertex AI\nAPI and then wait for the response.\n\nTo initialize the client, provide the required arguments either directly\nor by using environment variables. Gemini API users and Vertex AI users in\nexpress mode can provide API key by providing input argument\n`api_key=\"your-api-key\"` or by defining `GOOGLE_API_KEY=\"your-api-key\"` as an\nenvironment variable\n\nVertex AI API users can provide inputs argument as `vertexai=True,\nproject=\"your-project-id\", location=\"us-central1\"` or by defining\n`GOOGLE_GENAI_USE_VERTEXAI=true`, `GOOGLE_CLOUD_PROJECT` and\n`GOOGLE_CLOUD_LOCATION` environment variables.\n\nAttributes:\n  api_key: The `API key <https://ai.google.dev/gemini-api/docs/api-key>`_ to\n    use for authentication. Applies to the Gemini Developer API only.\n  vertexai: Indicates whether the client should use the Vertex AI API\n    endpoints. Defaults to\
    \ False (uses Gemini Developer API endpoints).\n    Applies to the Vertex AI API only.\n  credentials: The credentials to use for authentication when calling the\n    Vertex AI APIs. Credentials can be obtained from environment variables and\n    default credentials. For more information, see `Set up Application Default\n    Credentials\n    <https://cloud.google.com/docs/authentication/provide-credentials-adc>`_.\n    Applies to the Vertex AI API only.\n  project: The `Google Cloud project ID\n    <https://cloud.google.com/vertex-ai/docs/start/cloud-environment>`_ to use\n    for quota. Can be obtained from environment variables (for example,\n    ``GOOGLE_CLOUD_PROJECT``). Applies to the Vertex AI API only.\n    Find your `Google Cloud project ID <https://cloud.google.com/resource-manager/docs/creating-managing-projects#identifying_projects>`_.\n  location: The `location\n    <https://cloud.google.com/vertex-ai/generative-ai/docs/learn/locations>`_\n    to send API requests to (for\
    \ example, ``us-central1``). Can be obtained\n    from environment variables. Applies to the Vertex AI API only.\n  debug_config: Config settings that control network behavior of the client.\n    This is typically used when running test code.\n  http_options: Http options to use for the client. These options will be\n    applied to all requests made by the client. Example usage: `client =\n    genai.Client(http_options=types.HttpOptions(api_version='v1'))`.\n\nUsage for the Gemini Developer API:\n\n.. code-block:: python\n\n  from google import genai\n\n  client = genai.Client(api_key='my-api-key')\n\nUsage for the Vertex AI API:\n\n.. code-block:: python\n\n  from google import genai\n\n  client = genai.Client(\n      vertexai=True, project='my-project-id', location='us-central1'\n  )"
  constructor_signature: 'def __init__(self, *, vertexai: typing.Optional[bool]=None, api_key: typing.Optional[str]=None, credentials: typing.Optional[google.auth.credentials.Credentials]=None, project: typing.Optional[str]=None, location: typing.Optional[str]=None, debug_config: typing.Optional[google.genai.client.DebugConfig]=None, http_options: typing.Optional[typing.Union[google.genai.types.HttpOptions, google.genai.types.HttpOptionsDict]]=None):'
  aliases:
  - google.genai.Client
  methods:
  - signature: 'def chats(self) -> google.genai.chats.Chats:'
  - signature: 'def aio(self) -> google.genai.client.AsyncClient:'
  - signature: 'def models(self) -> google.genai.models.Models:'
  - signature: 'def tunings(self) -> google.genai.tunings.Tunings:'
  - signature: 'def caches(self) -> google.genai.caches.Caches:'
  - signature: 'def file_search_stores(self) -> google.genai.file_search_stores.FileSearchStores:'
  - signature: 'def batches(self) -> google.genai.batches.Batches:'
  - signature: 'def files(self) -> google.genai.files.Files:'
  - signature: 'def auth_tokens(self) -> google.genai.tokens.Tokens:'
  - signature: 'def operations(self) -> google.genai.operations.Operations:'
  - signature: 'def vertexai(self) -> bool:'
    docstring: Returns whether the client is using the Vertex AI API.
  - signature: 'def close(self) -> None:'
    docstring: "Closes the synchronous client explicitly.\n\nHowever, it doesn't close the async client, which can be closed using the\nClient.aio.aclose() method or using the async context manager.\n\nUsage:\n.. code-block:: python\n\n  from google.genai import Client\n\n  client = Client(\n      vertexai=True, project='my-project-id', location='us-central1'\n  )\n  response_1 = client.models.generate_content(\n      model='gemini-2.0-flash',\n      contents='Hello World',\n  )\n  response_2 = client.models.generate_content(\n      model='gemini-2.0-flash',\n      contents='Hello World',\n  )\n  # Close the client to release resources.\n  client.close()"
- rank: 1819
  id: google.genai.client.Client.__init__
  name: __init__
  file_path: env/lib/python3.13/site-packages/google/genai/client.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Initializes the client.\n\nArgs:\n   vertexai (bool): Indicates whether the client should use the Vertex AI\n     API endpoints. Defaults to False (uses Gemini Developer API endpoints).\n     Applies to the Vertex AI API only.\n   api_key (str): The `API key\n     <https://ai.google.dev/gemini-api/docs/api-key>`_ to use for\n     authentication. Applies to the Gemini Developer API only.\n   credentials (google.auth.credentials.Credentials): The credentials to use\n     for authentication when calling the Vertex AI APIs. Credentials can be\n     obtained from environment variables and default credentials. For more\n     information, see `Set up Application Default Credentials\n     <https://cloud.google.com/docs/authentication/provide-credentials-adc>`_.\n     Applies to the Vertex AI API only.\n   project (str): The `Google Cloud project ID\n     <https://cloud.google.com/vertex-ai/docs/start/cloud-environment>`_ to\n     use for quota. Can be obtained from environment variables\
    \ (for example,\n     ``GOOGLE_CLOUD_PROJECT``). Applies to the Vertex AI API only.\n   location (str): The `location\n     <https://cloud.google.com/vertex-ai/generative-ai/docs/learn/locations>`_\n     to send API requests to (for example, ``us-central1``). Can be obtained\n     from environment variables. Applies to the Vertex AI API only.\n   debug_config (DebugConfig): Config settings that control network behavior\n     of the client. This is typically used when running test code.\n   http_options (Union[HttpOptions, HttpOptionsDict]): Http options to use\n     for the client."
  signature: 'def __init__(self, *, vertexai: typing.Optional[bool]=None, api_key: typing.Optional[str]=None, credentials: typing.Optional[google.auth.credentials.Credentials]=None, project: typing.Optional[str]=None, location: typing.Optional[str]=None, debug_config: typing.Optional[google.genai.client.DebugConfig]=None, http_options: typing.Optional[typing.Union[google.genai.types.HttpOptions, google.genai.types.HttpOptionsDict]]=None):'
- rank: 1820
  id: google.genai.client.Client.close
  name: close
  file_path: env/lib/python3.13/site-packages/google/genai/client.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Closes the synchronous client explicitly.\n\nHowever, it doesn't close the async client, which can be closed using the\nClient.aio.aclose() method or using the async context manager.\n\nUsage:\n.. code-block:: python\n\n  from google.genai import Client\n\n  client = Client(\n      vertexai=True, project='my-project-id', location='us-central1'\n  )\n  response_1 = client.models.generate_content(\n      model='gemini-2.0-flash',\n      contents='Hello World',\n  )\n  response_2 = client.models.generate_content(\n      model='gemini-2.0-flash',\n      contents='Hello World',\n  )\n  # Close the client to release resources.\n  client.close()"
  signature: 'def close(self) -> None:'
- rank: 1821
  id: google.genai.client.DebugConfig
  name: DebugConfig
  file_path: env/lib/python3.13/site-packages/google/genai/client.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Configuration options that change client network behavior when testing.


    [Note: Inherited members from pydantic.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, client_mode: typing.Optional[str] = Factory(lambda: os.getenv(''GOOGLE_GENAI_CLIENT_MODE'', None)), replays_directory: typing.Optional[str] = Factory(lambda: os.getenv(''GOOGLE_GENAI_REPLAYS_DIRECTORY'', None)), replay_id: typing.Optional[str] = Factory(lambda: os.getenv(''GOOGLE_GENAI_REPLAY_ID'', None))):'
  properties:
  - signature: 'client_mode: typing.Optional[str]'
  - signature: 'replays_directory: typing.Optional[str]'
  - signature: 'replay_id: typing.Optional[str]'
  omitted_inherited_members_from:
  - pydantic.BaseModel
- rank: 1822
  id: google.genai.documents
  name: documents
  file_path: env/lib/python3.13/site-packages/google/genai/documents.py
  type: MODULE
  group: Orphan
  usage_score: 0
- rank: 1823
  id: google.genai.documents.AsyncDocuments
  name: AsyncDocuments
  file_path: env/lib/python3.13/site-packages/google/genai/documents.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: '[Note: Inherited members from _api_module.BaseModule are omitted.]'
  methods:
  - signature: 'def get(self, *, name: str, config: typing.Optional[google.genai.types.GetDocumentConfigOrDict]=None) -> google.genai.types.Document:'
    docstring: "Gets metadata about a Document.\n\nArgs:\n  name (str): The resource name of the Document.\n    Example: ragStores/rag-store-foo/documents/documents-bar\n  config (GetDocumentConfig | None): Optional parameters for the request.\n\nReturns:\n  The Document."
  - signature: 'def delete(self, *, name: str, config: typing.Optional[google.genai.types.DeleteDocumentConfigOrDict]=None) -> None:'
    docstring: "Deletes a Document.\n\nArgs:\n  name (str): The resource name of the Document.\n    Example: ragStores/rag-store-foo/documents/documents-bar\n  config (DeleteDocumentConfig | None): Optional parameters for the request.\n\nReturns:\n  None"
  - signature: 'def list(self, *, parent: str, config: typing.Optional[google.genai.types.ListDocumentsConfigOrDict]=None) -> google.genai.pagers.AsyncPager[google.genai.types.Document]:'
    docstring: "Lists documents asynchronously.\n\nArgs:\n  parent (str): The name of the RagStore containing the Documents.\n  config (ListDocumentsConfig): Optional configuration for the list request.\n\nReturns:\n  A Pager object that contains one page of documents. When iterating over\n  the pager, it automatically fetches the next page if there are more.\nUsage:\n.. code-block:: python\n  async for document in await\n  client.aio.documents.list(parent='rag_store_name'):\n    print(f\"document: {document.name} - {document.display_name}\")"
  omitted_inherited_members_from:
  - _api_module.BaseModule
- rank: 1824
  id: google.genai.documents.AsyncDocuments.delete
  name: delete
  file_path: env/lib/python3.13/site-packages/google/genai/documents.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Deletes a Document.\n\nArgs:\n  name (str): The resource name of the Document.\n    Example: ragStores/rag-store-foo/documents/documents-bar\n  config (DeleteDocumentConfig | None): Optional parameters for the request.\n\nReturns:\n  None"
  signature: 'def delete(self, *, name: str, config: typing.Optional[google.genai.types.DeleteDocumentConfigOrDict]=None) -> None:'
- rank: 1825
  id: google.genai.documents.AsyncDocuments.get
  name: get
  file_path: env/lib/python3.13/site-packages/google/genai/documents.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Gets metadata about a Document.\n\nArgs:\n  name (str): The resource name of the Document.\n    Example: ragStores/rag-store-foo/documents/documents-bar\n  config (GetDocumentConfig | None): Optional parameters for the request.\n\nReturns:\n  The Document."
  signature: 'def get(self, *, name: str, config: typing.Optional[google.genai.types.GetDocumentConfigOrDict]=None) -> google.genai.types.Document:'
- rank: 1826
  id: google.genai.documents.AsyncDocuments.list
  name: list
  file_path: env/lib/python3.13/site-packages/google/genai/documents.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Lists documents asynchronously.\n\nArgs:\n  parent (str): The name of the RagStore containing the Documents.\n  config (ListDocumentsConfig): Optional configuration for the list request.\n\nReturns:\n  A Pager object that contains one page of documents. When iterating over\n  the pager, it automatically fetches the next page if there are more.\nUsage:\n.. code-block:: python\n  async for document in await\n  client.aio.documents.list(parent='rag_store_name'):\n    print(f\"document: {document.name} - {document.display_name}\")"
  signature: 'def list(self, *, parent: str, config: typing.Optional[google.genai.types.ListDocumentsConfigOrDict]=None) -> google.genai.pagers.AsyncPager[google.genai.types.Document]:'
- rank: 1827
  id: google.genai.documents.Documents
  name: Documents
  file_path: env/lib/python3.13/site-packages/google/genai/documents.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: '[Note: Inherited members from _api_module.BaseModule are omitted.]'
  methods:
  - signature: 'def get(self, *, name: str, config: typing.Optional[google.genai.types.GetDocumentConfigOrDict]=None) -> google.genai.types.Document:'
    docstring: "Gets metadata about a Document.\n\nArgs:\n  name (str): The resource name of the Document.\n    Example: ragStores/rag-store-foo/documents/documents-bar\n  config (GetDocumentConfig | None): Optional parameters for the request.\n\nReturns:\n  The Document."
  - signature: 'def delete(self, *, name: str, config: typing.Optional[google.genai.types.DeleteDocumentConfigOrDict]=None) -> None:'
    docstring: "Deletes a Document.\n\nArgs:\n  name (str): The resource name of the Document.\n    Example: ragStores/rag-store-foo/documents/documents-bar\n  config (DeleteDocumentConfig | None): Optional parameters for the request.\n\nReturns:\n  None"
  - signature: 'def list(self, *, parent: str, config: typing.Optional[google.genai.types.ListDocumentsConfigOrDict]=None) -> google.genai.pagers.Pager[google.genai.types.Document]:'
    docstring: "Lists documents.\n\nArgs:\n  parent (str): The name of the RagStore containing the Documents.\n  config (ListDocumentsConfig): Optional configuration for the list request.\n\nReturns:\n  A Pager object that contains one page of documents. When iterating over\n  the pager, it automatically fetches the next page if there are more.\nUsage:\n.. code-block:: python\n  for document in client.documents.list(parent='rag_store_name'):\n    print(f\"document: {document.name} - {document.display_name}\")"
  omitted_inherited_members_from:
  - _api_module.BaseModule
- rank: 1828
  id: google.genai.documents.Documents.delete
  name: delete
  file_path: env/lib/python3.13/site-packages/google/genai/documents.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Deletes a Document.\n\nArgs:\n  name (str): The resource name of the Document.\n    Example: ragStores/rag-store-foo/documents/documents-bar\n  config (DeleteDocumentConfig | None): Optional parameters for the request.\n\nReturns:\n  None"
  signature: 'def delete(self, *, name: str, config: typing.Optional[google.genai.types.DeleteDocumentConfigOrDict]=None) -> None:'
- rank: 1829
  id: google.genai.documents.Documents.get
  name: get
  file_path: env/lib/python3.13/site-packages/google/genai/documents.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Gets metadata about a Document.\n\nArgs:\n  name (str): The resource name of the Document.\n    Example: ragStores/rag-store-foo/documents/documents-bar\n  config (GetDocumentConfig | None): Optional parameters for the request.\n\nReturns:\n  The Document."
  signature: 'def get(self, *, name: str, config: typing.Optional[google.genai.types.GetDocumentConfigOrDict]=None) -> google.genai.types.Document:'
- rank: 1830
  id: google.genai.documents.Documents.list
  name: list
  file_path: env/lib/python3.13/site-packages/google/genai/documents.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Lists documents.\n\nArgs:\n  parent (str): The name of the RagStore containing the Documents.\n  config (ListDocumentsConfig): Optional configuration for the list request.\n\nReturns:\n  A Pager object that contains one page of documents. When iterating over\n  the pager, it automatically fetches the next page if there are more.\nUsage:\n.. code-block:: python\n  for document in client.documents.list(parent='rag_store_name'):\n    print(f\"document: {document.name} - {document.display_name}\")"
  signature: 'def list(self, *, parent: str, config: typing.Optional[google.genai.types.ListDocumentsConfigOrDict]=None) -> google.genai.pagers.Pager[google.genai.types.Document]:'
- rank: 1831
  id: google.genai.errors
  name: errors
  file_path: env/lib/python3.13/site-packages/google/genai/errors.py
  type: MODULE
  group: Orphan
  usage_score: 0
  docstring: Error classes for the GenAI SDK.
- rank: 1832
  id: google.genai.errors.APIError
  name: APIError
  file_path: env/lib/python3.13/site-packages/google/genai/errors.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'General errors raised by the GenAI API.


    [Note: Inherited members from Exception are omitted.]'
  constructor_signature: 'def __init__(self, code: int, response_json: typing.Any, response: typing.Optional[typing.Union[google.genai.replay_api_client.ReplayResponse, httpx.Response, aiohttp.ClientResponse]]):'
  methods:
  - signature: 'def raise_for_response(cls, response: typing.Union[google.genai.replay_api_client.ReplayResponse, httpx.Response]) -> None:'
    docstring: Raises an error with detailed error message if the response has an error status.
  - signature: 'def raise_error(cls, status_code: int, response_json: typing.Any, response: typing.Optional[typing.Union[google.genai.replay_api_client.ReplayResponse, httpx.Response, aiohttp.ClientResponse]]) -> None:'
    docstring: "Raises an appropriate APIError subclass based on the status code.\n\nArgs:\n  status_code: The HTTP status code of the response.\n  response_json: The JSON body of the response, or a dict containing error\n    details.\n  response: The original response object.\n\nRaises:\n  ClientError: If the status code is in the 4xx range.\n  ServerError: If the status code is in the 5xx range.\n  APIError: For other error status codes."
  - signature: 'def raise_for_async_response(cls, response: typing.Union[google.genai.replay_api_client.ReplayResponse, httpx.Response, aiohttp.ClientResponse]) -> None:'
    docstring: Raises an error with detailed error message if the response has an error status.
  - signature: 'def raise_error_async(cls, status_code: int, response_json: typing.Any, response: typing.Optional[typing.Union[google.genai.replay_api_client.ReplayResponse, httpx.Response, aiohttp.ClientResponse]]) -> None:'
    docstring: "Raises an appropriate APIError subclass based on the status code.\n\nArgs:\n  status_code: The HTTP status code of the response.\n  response_json: The JSON body of the response, or a dict containing error\n    details.\n  response: The original response object.\n\nRaises:\n  ClientError: If the status code is in the 4xx range.\n  ServerError: If the status code is in the 5xx range.\n  APIError: For other error status codes."
  properties:
  - signature: 'code: int'
  - signature: 'response: typing.Union[google.genai.replay_api_client.ReplayResponse, httpx.Response, aiohttp.ClientResponse]'
  - signature: 'status: typing.Optional[str]'
  - signature: 'message: typing.Optional[str]'
  omitted_inherited_members_from:
  - Exception
- rank: 1833
  id: google.genai.errors.APIError.__init__
  name: __init__
  file_path: env/lib/python3.13/site-packages/google/genai/errors.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def __init__(self, code: int, response_json: typing.Any, response: typing.Optional[typing.Union[google.genai.replay_api_client.ReplayResponse, httpx.Response, aiohttp.ClientResponse]]):'
- rank: 1834
  id: google.genai.errors.APIError.raise_error
  name: raise_error
  file_path: env/lib/python3.13/site-packages/google/genai/errors.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Raises an appropriate APIError subclass based on the status code.\n\nArgs:\n  status_code: The HTTP status code of the response.\n  response_json: The JSON body of the response, or a dict containing error\n    details.\n  response: The original response object.\n\nRaises:\n  ClientError: If the status code is in the 4xx range.\n  ServerError: If the status code is in the 5xx range.\n  APIError: For other error status codes."
  signature: 'def raise_error(cls, status_code: int, response_json: typing.Any, response: typing.Optional[typing.Union[google.genai.replay_api_client.ReplayResponse, httpx.Response, aiohttp.ClientResponse]]) -> None:'
- rank: 1835
  id: google.genai.errors.APIError.raise_error_async
  name: raise_error_async
  file_path: env/lib/python3.13/site-packages/google/genai/errors.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Raises an appropriate APIError subclass based on the status code.\n\nArgs:\n  status_code: The HTTP status code of the response.\n  response_json: The JSON body of the response, or a dict containing error\n    details.\n  response: The original response object.\n\nRaises:\n  ClientError: If the status code is in the 4xx range.\n  ServerError: If the status code is in the 5xx range.\n  APIError: For other error status codes."
  signature: 'def raise_error_async(cls, status_code: int, response_json: typing.Any, response: typing.Optional[typing.Union[google.genai.replay_api_client.ReplayResponse, httpx.Response, aiohttp.ClientResponse]]) -> None:'
- rank: 1836
  id: google.genai.errors.APIError.raise_for_async_response
  name: raise_for_async_response
  file_path: env/lib/python3.13/site-packages/google/genai/errors.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: Raises an error with detailed error message if the response has an error status.
  signature: 'def raise_for_async_response(cls, response: typing.Union[google.genai.replay_api_client.ReplayResponse, httpx.Response, aiohttp.ClientResponse]) -> None:'
- rank: 1837
  id: google.genai.errors.APIError.raise_for_response
  name: raise_for_response
  file_path: env/lib/python3.13/site-packages/google/genai/errors.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: Raises an error with detailed error message if the response has an error status.
  signature: 'def raise_for_response(cls, response: typing.Union[google.genai.replay_api_client.ReplayResponse, httpx.Response]) -> None:'
- rank: 1838
  id: google.genai.errors.ClientError
  name: ClientError
  file_path: env/lib/python3.13/site-packages/google/genai/errors.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Client error raised by the GenAI API.


    [Note: Inherited members from Exception are omitted.]'
  constructor_signature: 'def __init__(self, code: int, response_json: typing.Any, response: typing.Optional[typing.Union[google.genai.replay_api_client.ReplayResponse, httpx.Response, aiohttp.ClientResponse]]):'
  inherited_methods:
    APIError:
    - signature: 'def raise_for_response(cls, response: typing.Union[google.genai.replay_api_client.ReplayResponse, httpx.Response]) -> None:'
      docstring: Raises an error with detailed error message if the response has an error status.
    - signature: 'def raise_error(cls, status_code: int, response_json: typing.Any, response: typing.Optional[typing.Union[google.genai.replay_api_client.ReplayResponse, httpx.Response, aiohttp.ClientResponse]]) -> None:'
      docstring: "Raises an appropriate APIError subclass based on the status code.\n\nArgs:\n  status_code: The HTTP status code of the response.\n  response_json: The JSON body of the response, or a dict containing error\n    details.\n  response: The original response object.\n\nRaises:\n  ClientError: If the status code is in the 4xx range.\n  ServerError: If the status code is in the 5xx range.\n  APIError: For other error status codes."
    - signature: 'def raise_for_async_response(cls, response: typing.Union[google.genai.replay_api_client.ReplayResponse, httpx.Response, aiohttp.ClientResponse]) -> None:'
      docstring: Raises an error with detailed error message if the response has an error status.
    - signature: 'def raise_error_async(cls, status_code: int, response_json: typing.Any, response: typing.Optional[typing.Union[google.genai.replay_api_client.ReplayResponse, httpx.Response, aiohttp.ClientResponse]]) -> None:'
      docstring: "Raises an appropriate APIError subclass based on the status code.\n\nArgs:\n  status_code: The HTTP status code of the response.\n  response_json: The JSON body of the response, or a dict containing error\n    details.\n  response: The original response object.\n\nRaises:\n  ClientError: If the status code is in the 4xx range.\n  ServerError: If the status code is in the 5xx range.\n  APIError: For other error status codes."
  inherited_properties:
    APIError:
    - signature: 'code: int'
    - signature: 'response: typing.Union[google.genai.replay_api_client.ReplayResponse, httpx.Response, aiohttp.ClientResponse]'
    - signature: 'status: typing.Optional[str]'
    - signature: 'message: typing.Optional[str]'
  omitted_inherited_members_from:
  - Exception
- rank: 1839
  id: google.genai.errors.FunctionInvocationError
  name: FunctionInvocationError
  file_path: env/lib/python3.13/site-packages/google/genai/errors.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Raised when the function cannot be invoked with the given arguments.


    [Note: Inherited members from ValueError are omitted.]'
  omitted_inherited_members_from:
  - ValueError
- rank: 1840
  id: google.genai.errors.ServerError
  name: ServerError
  file_path: env/lib/python3.13/site-packages/google/genai/errors.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Server error raised by the GenAI API.


    [Note: Inherited members from Exception are omitted.]'
  constructor_signature: 'def __init__(self, code: int, response_json: typing.Any, response: typing.Optional[typing.Union[google.genai.replay_api_client.ReplayResponse, httpx.Response, aiohttp.ClientResponse]]):'
  inherited_methods:
    APIError:
    - signature: 'def raise_for_response(cls, response: typing.Union[google.genai.replay_api_client.ReplayResponse, httpx.Response]) -> None:'
      docstring: Raises an error with detailed error message if the response has an error status.
    - signature: 'def raise_error(cls, status_code: int, response_json: typing.Any, response: typing.Optional[typing.Union[google.genai.replay_api_client.ReplayResponse, httpx.Response, aiohttp.ClientResponse]]) -> None:'
      docstring: "Raises an appropriate APIError subclass based on the status code.\n\nArgs:\n  status_code: The HTTP status code of the response.\n  response_json: The JSON body of the response, or a dict containing error\n    details.\n  response: The original response object.\n\nRaises:\n  ClientError: If the status code is in the 4xx range.\n  ServerError: If the status code is in the 5xx range.\n  APIError: For other error status codes."
    - signature: 'def raise_for_async_response(cls, response: typing.Union[google.genai.replay_api_client.ReplayResponse, httpx.Response, aiohttp.ClientResponse]) -> None:'
      docstring: Raises an error with detailed error message if the response has an error status.
    - signature: 'def raise_error_async(cls, status_code: int, response_json: typing.Any, response: typing.Optional[typing.Union[google.genai.replay_api_client.ReplayResponse, httpx.Response, aiohttp.ClientResponse]]) -> None:'
      docstring: "Raises an appropriate APIError subclass based on the status code.\n\nArgs:\n  status_code: The HTTP status code of the response.\n  response_json: The JSON body of the response, or a dict containing error\n    details.\n  response: The original response object.\n\nRaises:\n  ClientError: If the status code is in the 4xx range.\n  ServerError: If the status code is in the 5xx range.\n  APIError: For other error status codes."
  inherited_properties:
    APIError:
    - signature: 'code: int'
    - signature: 'response: typing.Union[google.genai.replay_api_client.ReplayResponse, httpx.Response, aiohttp.ClientResponse]'
    - signature: 'status: typing.Optional[str]'
    - signature: 'message: typing.Optional[str]'
  omitted_inherited_members_from:
  - Exception
- rank: 1841
  id: google.genai.errors.UnknownApiResponseError
  name: UnknownApiResponseError
  file_path: env/lib/python3.13/site-packages/google/genai/errors.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Raised when the response from the API cannot be parsed as JSON.


    [Note: Inherited members from ValueError are omitted.]'
  omitted_inherited_members_from:
  - ValueError
- rank: 1842
  id: google.genai.errors.UnknownFunctionCallArgumentError
  name: UnknownFunctionCallArgumentError
  file_path: env/lib/python3.13/site-packages/google/genai/errors.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Raised when the function call argument cannot be converted to the parameter annotation.


    [Note: Inherited members from ValueError are omitted.]'
  omitted_inherited_members_from:
  - ValueError
- rank: 1843
  id: google.genai.errors.UnsupportedFunctionError
  name: UnsupportedFunctionError
  file_path: env/lib/python3.13/site-packages/google/genai/errors.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Raised when the function is not supported.


    [Note: Inherited members from ValueError are omitted.]'
  omitted_inherited_members_from:
  - ValueError
- rank: 1844
  id: google.genai.file_search_stores
  name: file_search_stores
  file_path: env/lib/python3.13/site-packages/google/genai/file_search_stores.py
  type: MODULE
  group: Orphan
  usage_score: 0
- rank: 1845
  id: google.genai.file_search_stores.AsyncFileSearchStores
  name: AsyncFileSearchStores
  file_path: env/lib/python3.13/site-packages/google/genai/file_search_stores.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: '[Note: Inherited members from _api_module.BaseModule are omitted.]'
  methods:
  - signature: 'def documents(self) -> google.genai.documents.AsyncDocuments:'
  - signature: 'def create(self, *, config: typing.Optional[google.genai.types.CreateFileSearchStoreConfigOrDict]=None) -> google.genai.types.FileSearchStore:'
    docstring: "Creates a File Search Store.\n\nArgs:\n  config (CreateFileSearchStoreConfig | None): Optional parameters for the\n    request.\n\nReturns:\n  FileSearchStore"
  - signature: 'def get(self, *, name: str, config: typing.Optional[google.genai.types.GetFileSearchStoreConfigOrDict]=None) -> google.genai.types.FileSearchStore:'
    docstring: "Gets metadata about a FileSearchStore.\n\nArgs:\n  name (str): The resource name of the FileSearchStore. Example:\n    `FileSearchStores/my-file-search-store-123`\n  config (GetFileSearchStoreConfig | None): Optional parameters for the\n    request.\n\nReturns:\n  A FileSearchStore object containing the metadata."
  - signature: 'def delete(self, *, name: str, config: typing.Optional[google.genai.types.DeleteFileSearchStoreConfigOrDict]=None) -> None:'
    docstring: "Deletes a FileSearchStore.\n\nArgs:\n  name (str): The resource name of the FileSearchStore. Example:\n    `FileSearchStores/my-file-search-store-123`\n  config (DeleteFileSearchStoreConfig | None): Optional parameters for the\n    request.\n\nReturns:\n  None"
  - signature: 'def import_file(self, *, file_search_store_name: str, file_name: str, config: typing.Optional[google.genai.types.ImportFileConfigOrDict]=None) -> google.genai.types.ImportFileOperation:'
    docstring: "Imports a File from File Service to a FileSearchStore.\n\nThis is a long-running operation, see aip.dev/151\n\nArgs:\n  file_search_store_name (str): The resource name of the FileSearchStore.\n    Example: `fileSearchStores/my-file-search-store-123`\n  file_name (str): The resource name of the File to import. Example:\n    `files/abc-123`\n  config (ImportFileConfig | None): Optional parameters for the request.\n\nReturns:\n  ImportFileOperation."
  - signature: 'def list(self, *, config: typing.Optional[google.genai.types.ListFileSearchStoresConfigOrDict]=None) -> google.genai.pagers.AsyncPager[google.genai.types.FileSearchStore]:'
    docstring: "Lists FileSearchStores asynchronously.\n\nArgs:\n  config (ListFileSearchStoresConfig): Optional parameters for the request,\n    such as page_size.\n\nReturns:\n  A Pager object that contains one page of FileSearchStores. When iterating\n  over\n  the pager, it automatically fetches the next page if there are more.\n\nUsage:\n\n.. code-block:: python\n  async for file_search_store in await client.aio.file_search_stores.list():\n    print(f\"file search store: {file_search_store.name} -\n    {file_search_store.display_name}\")"
  - signature: 'def upload_to_file_search_store(self, *, file_search_store_name: str, file: typing.Union[str, os.PathLike[str], io.IOBase], config: typing.Optional[google.genai.types.UploadToFileSearchStoreConfigOrDict]=None) -> google.genai.types.UploadToFileSearchStoreOperation:'
    docstring: "Calls the API to upload a file to the given file search store.\n\nArgs:\n  file_search_store_name: The resource name of the FileSearchStore. Example:\n    `fileSearchStores/file-search-store-123`\n  file: A path to the file or an `IOBase` object to be uploaded. If it's an\n    IOBase object, it must be opened in blocking (the default) mode and\n    binary mode. In other words, do not use non-blocking mode or text mode.\n    The given stream must be seekable, that is, it must be able to call\n    `seek()` on 'path'.\n  config: Optional parameters to set `diplay_name`, `mime_type` and others."
  omitted_inherited_members_from:
  - _api_module.BaseModule
- rank: 1846
  id: google.genai.file_search_stores.AsyncFileSearchStores.create
  name: create
  file_path: env/lib/python3.13/site-packages/google/genai/file_search_stores.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Creates a File Search Store.\n\nArgs:\n  config (CreateFileSearchStoreConfig | None): Optional parameters for the\n    request.\n\nReturns:\n  FileSearchStore"
  signature: 'def create(self, *, config: typing.Optional[google.genai.types.CreateFileSearchStoreConfigOrDict]=None) -> google.genai.types.FileSearchStore:'
- rank: 1847
  id: google.genai.file_search_stores.AsyncFileSearchStores.delete
  name: delete
  file_path: env/lib/python3.13/site-packages/google/genai/file_search_stores.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Deletes a FileSearchStore.\n\nArgs:\n  name (str): The resource name of the FileSearchStore. Example:\n    `FileSearchStores/my-file-search-store-123`\n  config (DeleteFileSearchStoreConfig | None): Optional parameters for the\n    request.\n\nReturns:\n  None"
  signature: 'def delete(self, *, name: str, config: typing.Optional[google.genai.types.DeleteFileSearchStoreConfigOrDict]=None) -> None:'
- rank: 1848
  id: google.genai.file_search_stores.AsyncFileSearchStores.get
  name: get
  file_path: env/lib/python3.13/site-packages/google/genai/file_search_stores.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Gets metadata about a FileSearchStore.\n\nArgs:\n  name (str): The resource name of the FileSearchStore. Example:\n    `FileSearchStores/my-file-search-store-123`\n  config (GetFileSearchStoreConfig | None): Optional parameters for the\n    request.\n\nReturns:\n  A FileSearchStore object containing the metadata."
  signature: 'def get(self, *, name: str, config: typing.Optional[google.genai.types.GetFileSearchStoreConfigOrDict]=None) -> google.genai.types.FileSearchStore:'
- rank: 1849
  id: google.genai.file_search_stores.AsyncFileSearchStores.import_file
  name: import_file
  file_path: env/lib/python3.13/site-packages/google/genai/file_search_stores.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Imports a File from File Service to a FileSearchStore.\n\nThis is a long-running operation, see aip.dev/151\n\nArgs:\n  file_search_store_name (str): The resource name of the FileSearchStore.\n    Example: `fileSearchStores/my-file-search-store-123`\n  file_name (str): The resource name of the File to import. Example:\n    `files/abc-123`\n  config (ImportFileConfig | None): Optional parameters for the request.\n\nReturns:\n  ImportFileOperation."
  signature: 'def import_file(self, *, file_search_store_name: str, file_name: str, config: typing.Optional[google.genai.types.ImportFileConfigOrDict]=None) -> google.genai.types.ImportFileOperation:'
- rank: 1850
  id: google.genai.file_search_stores.AsyncFileSearchStores.list
  name: list
  file_path: env/lib/python3.13/site-packages/google/genai/file_search_stores.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Lists FileSearchStores asynchronously.\n\nArgs:\n  config (ListFileSearchStoresConfig): Optional parameters for the request,\n    such as page_size.\n\nReturns:\n  A Pager object that contains one page of FileSearchStores. When iterating\n  over\n  the pager, it automatically fetches the next page if there are more.\n\nUsage:\n\n.. code-block:: python\n  async for file_search_store in await client.aio.file_search_stores.list():\n    print(f\"file search store: {file_search_store.name} -\n    {file_search_store.display_name}\")"
  signature: 'def list(self, *, config: typing.Optional[google.genai.types.ListFileSearchStoresConfigOrDict]=None) -> google.genai.pagers.AsyncPager[google.genai.types.FileSearchStore]:'
- rank: 1851
  id: google.genai.file_search_stores.AsyncFileSearchStores.upload_to_file_search_store
  name: upload_to_file_search_store
  file_path: env/lib/python3.13/site-packages/google/genai/file_search_stores.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Calls the API to upload a file to the given file search store.\n\nArgs:\n  file_search_store_name: The resource name of the FileSearchStore. Example:\n    `fileSearchStores/file-search-store-123`\n  file: A path to the file or an `IOBase` object to be uploaded. If it's an\n    IOBase object, it must be opened in blocking (the default) mode and\n    binary mode. In other words, do not use non-blocking mode or text mode.\n    The given stream must be seekable, that is, it must be able to call\n    `seek()` on 'path'.\n  config: Optional parameters to set `diplay_name`, `mime_type` and others."
  signature: 'def upload_to_file_search_store(self, *, file_search_store_name: str, file: typing.Union[str, os.PathLike[str], io.IOBase], config: typing.Optional[google.genai.types.UploadToFileSearchStoreConfigOrDict]=None) -> google.genai.types.UploadToFileSearchStoreOperation:'
- rank: 1852
  id: google.genai.file_search_stores.FileSearchStores
  name: FileSearchStores
  file_path: env/lib/python3.13/site-packages/google/genai/file_search_stores.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: '[Note: Inherited members from _api_module.BaseModule are omitted.]'
  methods:
  - signature: 'def documents(self) -> google.genai.documents.Documents:'
  - signature: 'def create(self, *, config: typing.Optional[google.genai.types.CreateFileSearchStoreConfigOrDict]=None) -> google.genai.types.FileSearchStore:'
    docstring: "Creates a File Search Store.\n\nArgs:\n  config (CreateFileSearchStoreConfig | None): Optional parameters for the\n    request.\n\nReturns:\n  FileSearchStore"
  - signature: 'def get(self, *, name: str, config: typing.Optional[google.genai.types.GetFileSearchStoreConfigOrDict]=None) -> google.genai.types.FileSearchStore:'
    docstring: "Gets metadata about a FileSearchStore.\n\nArgs:\n  name (str): The resource name of the FileSearchStore. Example:\n    `FileSearchStores/my-file-search-store-123`\n  config (GetFileSearchStoreConfig | None): Optional parameters for the\n    request.\n\nReturns:\n  A FileSearchStore object containing the metadata."
  - signature: 'def delete(self, *, name: str, config: typing.Optional[google.genai.types.DeleteFileSearchStoreConfigOrDict]=None) -> None:'
    docstring: "Deletes a FileSearchStore.\n\nArgs:\n  name (str): The resource name of the FileSearchStore. Example:\n    `FileSearchStores/my-file-search-store-123`\n  config (DeleteFileSearchStoreConfig | None): Optional parameters for the\n    request.\n\nReturns:\n  None"
  - signature: 'def import_file(self, *, file_search_store_name: str, file_name: str, config: typing.Optional[google.genai.types.ImportFileConfigOrDict]=None) -> google.genai.types.ImportFileOperation:'
    docstring: "Imports a File from File Service to a FileSearchStore.\n\nThis is a long-running operation, see aip.dev/151\n\nArgs:\n  file_search_store_name (str): The resource name of the FileSearchStore.\n    Example: `fileSearchStores/my-file-search-store-123`\n  file_name (str): The resource name of the File to import. Example:\n    `files/abc-123`\n  config (ImportFileConfig | None): Optional parameters for the request.\n\nReturns:\n  ImportFileOperation."
  - signature: 'def list(self, *, config: typing.Optional[google.genai.types.ListFileSearchStoresConfigOrDict]=None) -> google.genai.pagers.Pager[google.genai.types.FileSearchStore]:'
    docstring: "Lists FileSearchStores.\n\nArgs:\n  config (ListFileSearchStoresConfig): Optional configuration for the list\n    request.\n\nReturns:\n  A Pager object that contains one page of file search stores. When\n  iterating over\n  the pager, it automatically fetches the next page if there are more.\n\nUsage:\n\n.. code-block:: python\n  for file_search_store in client.file_search_stores.list():\n    print(f\"file search store: {file_search_store.name} -\n    {file_search_store.display_name}\")"
  - signature: 'def upload_to_file_search_store(self, *, file_search_store_name: str, file: typing.Union[str, os.PathLike[str], io.IOBase], config: typing.Optional[google.genai.types.UploadToFileSearchStoreConfigOrDict]=None) -> google.genai.types.UploadToFileSearchStoreOperation:'
    docstring: "Calls the API to upload a file to the given file search store.\n\nArgs:\n  file_search_store_name: The resource name of the FileSearchStore. Example:\n    `fileSearchStores/file-search-store-123`\n  file: A path to the file or an `IOBase` object to be uploaded. If it's an\n    IOBase object, it must be opened in blocking (the default) mode and\n    binary mode. In other words, do not use non-blocking mode or text mode.\n    The given stream must be seekable, that is, it must be able to call\n    `seek()` on 'path'.\n  config: Optional parameters to set `diplay_name`, `mime_type`, and others."
  omitted_inherited_members_from:
  - _api_module.BaseModule
- rank: 1853
  id: google.genai.file_search_stores.FileSearchStores.create
  name: create
  file_path: env/lib/python3.13/site-packages/google/genai/file_search_stores.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Creates a File Search Store.\n\nArgs:\n  config (CreateFileSearchStoreConfig | None): Optional parameters for the\n    request.\n\nReturns:\n  FileSearchStore"
  signature: 'def create(self, *, config: typing.Optional[google.genai.types.CreateFileSearchStoreConfigOrDict]=None) -> google.genai.types.FileSearchStore:'
- rank: 1854
  id: google.genai.file_search_stores.FileSearchStores.delete
  name: delete
  file_path: env/lib/python3.13/site-packages/google/genai/file_search_stores.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Deletes a FileSearchStore.\n\nArgs:\n  name (str): The resource name of the FileSearchStore. Example:\n    `FileSearchStores/my-file-search-store-123`\n  config (DeleteFileSearchStoreConfig | None): Optional parameters for the\n    request.\n\nReturns:\n  None"
  signature: 'def delete(self, *, name: str, config: typing.Optional[google.genai.types.DeleteFileSearchStoreConfigOrDict]=None) -> None:'
- rank: 1855
  id: google.genai.file_search_stores.FileSearchStores.get
  name: get
  file_path: env/lib/python3.13/site-packages/google/genai/file_search_stores.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Gets metadata about a FileSearchStore.\n\nArgs:\n  name (str): The resource name of the FileSearchStore. Example:\n    `FileSearchStores/my-file-search-store-123`\n  config (GetFileSearchStoreConfig | None): Optional parameters for the\n    request.\n\nReturns:\n  A FileSearchStore object containing the metadata."
  signature: 'def get(self, *, name: str, config: typing.Optional[google.genai.types.GetFileSearchStoreConfigOrDict]=None) -> google.genai.types.FileSearchStore:'
- rank: 1856
  id: google.genai.file_search_stores.FileSearchStores.import_file
  name: import_file
  file_path: env/lib/python3.13/site-packages/google/genai/file_search_stores.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Imports a File from File Service to a FileSearchStore.\n\nThis is a long-running operation, see aip.dev/151\n\nArgs:\n  file_search_store_name (str): The resource name of the FileSearchStore.\n    Example: `fileSearchStores/my-file-search-store-123`\n  file_name (str): The resource name of the File to import. Example:\n    `files/abc-123`\n  config (ImportFileConfig | None): Optional parameters for the request.\n\nReturns:\n  ImportFileOperation."
  signature: 'def import_file(self, *, file_search_store_name: str, file_name: str, config: typing.Optional[google.genai.types.ImportFileConfigOrDict]=None) -> google.genai.types.ImportFileOperation:'
- rank: 1857
  id: google.genai.file_search_stores.FileSearchStores.list
  name: list
  file_path: env/lib/python3.13/site-packages/google/genai/file_search_stores.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Lists FileSearchStores.\n\nArgs:\n  config (ListFileSearchStoresConfig): Optional configuration for the list\n    request.\n\nReturns:\n  A Pager object that contains one page of file search stores. When\n  iterating over\n  the pager, it automatically fetches the next page if there are more.\n\nUsage:\n\n.. code-block:: python\n  for file_search_store in client.file_search_stores.list():\n    print(f\"file search store: {file_search_store.name} -\n    {file_search_store.display_name}\")"
  signature: 'def list(self, *, config: typing.Optional[google.genai.types.ListFileSearchStoresConfigOrDict]=None) -> google.genai.pagers.Pager[google.genai.types.FileSearchStore]:'
- rank: 1858
  id: google.genai.file_search_stores.FileSearchStores.upload_to_file_search_store
  name: upload_to_file_search_store
  file_path: env/lib/python3.13/site-packages/google/genai/file_search_stores.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Calls the API to upload a file to the given file search store.\n\nArgs:\n  file_search_store_name: The resource name of the FileSearchStore. Example:\n    `fileSearchStores/file-search-store-123`\n  file: A path to the file or an `IOBase` object to be uploaded. If it's an\n    IOBase object, it must be opened in blocking (the default) mode and\n    binary mode. In other words, do not use non-blocking mode or text mode.\n    The given stream must be seekable, that is, it must be able to call\n    `seek()` on 'path'.\n  config: Optional parameters to set `diplay_name`, `mime_type`, and others."
  signature: 'def upload_to_file_search_store(self, *, file_search_store_name: str, file: typing.Union[str, os.PathLike[str], io.IOBase], config: typing.Optional[google.genai.types.UploadToFileSearchStoreConfigOrDict]=None) -> google.genai.types.UploadToFileSearchStoreOperation:'
- rank: 1859
  id: google.genai.files
  name: files
  file_path: env/lib/python3.13/site-packages/google/genai/files.py
  type: MODULE
  group: Orphan
  usage_score: 0
- rank: 1860
  id: google.genai.files.AsyncFiles
  name: AsyncFiles
  file_path: env/lib/python3.13/site-packages/google/genai/files.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: '[Note: Inherited members from _api_module.BaseModule are omitted.]'
  methods:
  - signature: 'def get(self, *, name: str, config: typing.Optional[google.genai.types.GetFileConfigOrDict]=None) -> google.genai.types.File:'
    docstring: "Retrieves the file information from the service.\n\nArgs:\n  name (str): The name identifier for the file to retrieve.\n  config (GetFileConfig): Optional, configuration for the get method.\n\nReturns:\n  File: The file information.\n\nUsage:\n\n.. code-block:: python\n\n  file = await client.aio.files.get(name='files/...')\n  print(file.uri)"
  - signature: 'def delete(self, *, name: str, config: typing.Optional[google.genai.types.DeleteFileConfigOrDict]=None) -> google.genai.types.DeleteFileResponse:'
    docstring: "Deletes a remotely stored file.\n\nArgs:\n  name (str): The name identifier for the file to delete.\n  config (DeleteFileConfig): Optional, configuration for the delete method.\n\nReturns:\n  DeleteFileResponse: The response for the delete method\n\nUsage:\n\n.. code-block:: python\n\n  await client.aio.files.delete(name='files/...')"
  - signature: 'def list(self, *, config: typing.Optional[google.genai.types.ListFilesConfigOrDict]=None) -> google.genai.pagers.AsyncPager[google.genai.types.File]:'
    docstring: "Lists all files from the service asynchronously.\n\nArgs:\n  config (ListFilesConfig): Optional, configuration for the list method.\n\nReturns:\n  A Pager object that contains one page of files. When iterating over\n  the pager, it automatically fetches the next page if there are more.\n\nUsage:\n\n.. code-block:: python\n\n  async for file in await client.aio.files.list(config={'page_size': 10}):\n    print(file.name)"
  - signature: 'def upload(self, *, file: typing.Union[str, os.PathLike[str], io.IOBase], config: typing.Optional[google.genai.types.UploadFileConfigOrDict]=None) -> google.genai.types.File:'
    docstring: "Calls the API to upload a file asynchronously using a supported file service.\n\nArgs:\n  file: A path to the file or an `IOBase` object to be uploaded. If it's an\n    IOBase object, it must be opened in blocking (the default) mode and\n    binary mode. In other words, do not use non-blocking mode or text mode.\n    The given stream must be seekable, that is, it must be able to call\n    `seek()` on 'path'.\n  config: Optional parameters to set `diplay_name`, `mime_type`, and `name`."
  - signature: 'def download(self, *, file: typing.Union[str, google.genai.types.File], config: typing.Optional[google.genai.types.DownloadFileConfigOrDict]=None) -> bytes:'
    docstring: "Downloads a file's data from the file service.\n\nThe Vertex-AI implementation of the API foes not include the file service.\n\nFiles created by `upload` can't be downloaded. You can tell which files are\ndownloadable by checking the `download_uri` property.\n\nArgs:\n  File (str): A file name, uri, or file object. Identifying which file to\n    download.\n  config (DownloadFileConfigOrDict): Optional, configuration for the get\n    method.\n\nReturns:\n  File: The file data as bytes.\n\nUsage:\n\n.. code-block:: python\n\n  for file client.files.list():\n    if file.download_uri is not None:\n      break\n  else:\n    raise ValueError('No files found with a `download_uri`.')\n  data = client.files.download(file=file)\n  # data = client.files.download(file=file.name)\n  # data = client.files.download(file=file.uri)"
  omitted_inherited_members_from:
  - _api_module.BaseModule
- rank: 1861
  id: google.genai.files.AsyncFiles.delete
  name: delete
  file_path: env/lib/python3.13/site-packages/google/genai/files.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Deletes a remotely stored file.\n\nArgs:\n  name (str): The name identifier for the file to delete.\n  config (DeleteFileConfig): Optional, configuration for the delete method.\n\nReturns:\n  DeleteFileResponse: The response for the delete method\n\nUsage:\n\n.. code-block:: python\n\n  await client.aio.files.delete(name='files/...')"
  signature: 'def delete(self, *, name: str, config: typing.Optional[google.genai.types.DeleteFileConfigOrDict]=None) -> google.genai.types.DeleteFileResponse:'
- rank: 1862
  id: google.genai.files.AsyncFiles.download
  name: download
  file_path: env/lib/python3.13/site-packages/google/genai/files.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Downloads a file's data from the file service.\n\nThe Vertex-AI implementation of the API foes not include the file service.\n\nFiles created by `upload` can't be downloaded. You can tell which files are\ndownloadable by checking the `download_uri` property.\n\nArgs:\n  File (str): A file name, uri, or file object. Identifying which file to\n    download.\n  config (DownloadFileConfigOrDict): Optional, configuration for the get\n    method.\n\nReturns:\n  File: The file data as bytes.\n\nUsage:\n\n.. code-block:: python\n\n  for file client.files.list():\n    if file.download_uri is not None:\n      break\n  else:\n    raise ValueError('No files found with a `download_uri`.')\n  data = client.files.download(file=file)\n  # data = client.files.download(file=file.name)\n  # data = client.files.download(file=file.uri)"
  signature: 'def download(self, *, file: typing.Union[str, google.genai.types.File], config: typing.Optional[google.genai.types.DownloadFileConfigOrDict]=None) -> bytes:'
- rank: 1863
  id: google.genai.files.AsyncFiles.get
  name: get
  file_path: env/lib/python3.13/site-packages/google/genai/files.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Retrieves the file information from the service.\n\nArgs:\n  name (str): The name identifier for the file to retrieve.\n  config (GetFileConfig): Optional, configuration for the get method.\n\nReturns:\n  File: The file information.\n\nUsage:\n\n.. code-block:: python\n\n  file = await client.aio.files.get(name='files/...')\n  print(file.uri)"
  signature: 'def get(self, *, name: str, config: typing.Optional[google.genai.types.GetFileConfigOrDict]=None) -> google.genai.types.File:'
- rank: 1864
  id: google.genai.files.AsyncFiles.list
  name: list
  file_path: env/lib/python3.13/site-packages/google/genai/files.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Lists all files from the service asynchronously.\n\nArgs:\n  config (ListFilesConfig): Optional, configuration for the list method.\n\nReturns:\n  A Pager object that contains one page of files. When iterating over\n  the pager, it automatically fetches the next page if there are more.\n\nUsage:\n\n.. code-block:: python\n\n  async for file in await client.aio.files.list(config={'page_size': 10}):\n    print(file.name)"
  signature: 'def list(self, *, config: typing.Optional[google.genai.types.ListFilesConfigOrDict]=None) -> google.genai.pagers.AsyncPager[google.genai.types.File]:'
- rank: 1865
  id: google.genai.files.AsyncFiles.upload
  name: upload
  file_path: env/lib/python3.13/site-packages/google/genai/files.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Calls the API to upload a file asynchronously using a supported file service.\n\nArgs:\n  file: A path to the file or an `IOBase` object to be uploaded. If it's an\n    IOBase object, it must be opened in blocking (the default) mode and\n    binary mode. In other words, do not use non-blocking mode or text mode.\n    The given stream must be seekable, that is, it must be able to call\n    `seek()` on 'path'.\n  config: Optional parameters to set `diplay_name`, `mime_type`, and `name`."
  signature: 'def upload(self, *, file: typing.Union[str, os.PathLike[str], io.IOBase], config: typing.Optional[google.genai.types.UploadFileConfigOrDict]=None) -> google.genai.types.File:'
- rank: 1866
  id: google.genai.files.Files
  name: Files
  file_path: env/lib/python3.13/site-packages/google/genai/files.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: '[Note: Inherited members from _api_module.BaseModule are omitted.]'
  methods:
  - signature: 'def get(self, *, name: str, config: typing.Optional[google.genai.types.GetFileConfigOrDict]=None) -> google.genai.types.File:'
    docstring: "Retrieves the file information from the service.\n\nArgs:\n  name (str): The name identifier for the file to retrieve.\n  config (GetFileConfig): Optional, configuration for the get method.\n\nReturns:\n  File: The file information.\n\nUsage:\n\n.. code-block:: python\n\n  file = client.files.get(name='files/...')\n  print(file.uri)"
  - signature: 'def delete(self, *, name: str, config: typing.Optional[google.genai.types.DeleteFileConfigOrDict]=None) -> google.genai.types.DeleteFileResponse:'
    docstring: "Deletes a remotely stored file.\n\nArgs:\n  name (str): The name identifier for the file to delete.\n  config (DeleteFileConfig): Optional, configuration for the delete method.\n\nReturns:\n  DeleteFileResponse: The response for the delete method\n\nUsage:\n\n.. code-block:: python\n\n  client.files.delete(name='files/...')"
  - signature: 'def list(self, *, config: typing.Optional[google.genai.types.ListFilesConfigOrDict]=None) -> google.genai.pagers.Pager[google.genai.types.File]:'
    docstring: "Lists all files from the service.\n\nArgs:\n  config (ListFilesConfig): Optional, configuration for the list method.\n\nReturns:\n  A Pager object that contains one page of files. When iterating over\n  the pager, it automatically fetches the next page if there are more.\n\nUsage:\n\n.. code-block:: python\n\n  for file in client.files.list(config={'page_size': 10}):\n    print(file.name)"
  - signature: 'def upload(self, *, file: typing.Union[str, os.PathLike[str], io.IOBase], config: typing.Optional[google.genai.types.UploadFileConfigOrDict]=None) -> google.genai.types.File:'
    docstring: "Calls the API to upload a file using a supported file service.\n\nArgs:\n  file: A path to the file or an `IOBase` object to be uploaded. If it's an\n    IOBase object, it must be opened in blocking (the default) mode and\n    binary mode. In other words, do not use non-blocking mode or text mode.\n    The given stream must be seekable, that is, it must be able to call\n    `seek()` on 'path'.\n  config: Optional parameters to set `diplay_name`, `mime_type`, and `name`."
  - signature: 'def download(self, *, file: typing.Union[str, google.genai.types.File, google.genai.types.Video, google.genai.types.GeneratedVideo], config: typing.Optional[google.genai.types.DownloadFileConfigOrDict]=None) -> bytes:'
    docstring: "Downloads a file's data from storage.\n\nFiles created by `upload` can't be downloaded. You can tell which files are\ndownloadable by checking the `source` or `download_uri` property.\n\nNote: This method returns the data as bytes. For `Video` and\n`GeneratedVideo` objects there is an additional side effect, that it also\nsets the `video_bytes` property on the `Video` object.\n\nArgs:\n  file (str): A file name, uri, or file object. Identifying which file to\n    download.\n  config (DownloadFileConfigOrDict): Optional, configuration for the get\n    method.\n\nReturns:\n  File: The file data as bytes.\n\nUsage:\n\n.. code-block:: python\n\n  for file client.files.list():\n    if file.download_uri is not None:\n      break\n  else:\n    raise ValueError('No files found with a `download_uri`.')\n  data = client.files.download(file=file)\n  # data = client.files.download(file=file.name)\n  # data = client.files.download(file=file.download_uri)\n\n  video = types.Video(uri=file.uri)\n\
      \  video_bytes = client.files.download(file=video)\n  video.video_bytes"
  omitted_inherited_members_from:
  - _api_module.BaseModule
- rank: 1867
  id: google.genai.files.Files.delete
  name: delete
  file_path: env/lib/python3.13/site-packages/google/genai/files.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Deletes a remotely stored file.\n\nArgs:\n  name (str): The name identifier for the file to delete.\n  config (DeleteFileConfig): Optional, configuration for the delete method.\n\nReturns:\n  DeleteFileResponse: The response for the delete method\n\nUsage:\n\n.. code-block:: python\n\n  client.files.delete(name='files/...')"
  signature: 'def delete(self, *, name: str, config: typing.Optional[google.genai.types.DeleteFileConfigOrDict]=None) -> google.genai.types.DeleteFileResponse:'
- rank: 1868
  id: google.genai.files.Files.download
  name: download
  file_path: env/lib/python3.13/site-packages/google/genai/files.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Downloads a file's data from storage.\n\nFiles created by `upload` can't be downloaded. You can tell which files are\ndownloadable by checking the `source` or `download_uri` property.\n\nNote: This method returns the data as bytes. For `Video` and\n`GeneratedVideo` objects there is an additional side effect, that it also\nsets the `video_bytes` property on the `Video` object.\n\nArgs:\n  file (str): A file name, uri, or file object. Identifying which file to\n    download.\n  config (DownloadFileConfigOrDict): Optional, configuration for the get\n    method.\n\nReturns:\n  File: The file data as bytes.\n\nUsage:\n\n.. code-block:: python\n\n  for file client.files.list():\n    if file.download_uri is not None:\n      break\n  else:\n    raise ValueError('No files found with a `download_uri`.')\n  data = client.files.download(file=file)\n  # data = client.files.download(file=file.name)\n  # data = client.files.download(file=file.download_uri)\n\n  video = types.Video(uri=file.uri)\n\
    \  video_bytes = client.files.download(file=video)\n  video.video_bytes"
  signature: 'def download(self, *, file: typing.Union[str, google.genai.types.File, google.genai.types.Video, google.genai.types.GeneratedVideo], config: typing.Optional[google.genai.types.DownloadFileConfigOrDict]=None) -> bytes:'
- rank: 1869
  id: google.genai.files.Files.get
  name: get
  file_path: env/lib/python3.13/site-packages/google/genai/files.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Retrieves the file information from the service.\n\nArgs:\n  name (str): The name identifier for the file to retrieve.\n  config (GetFileConfig): Optional, configuration for the get method.\n\nReturns:\n  File: The file information.\n\nUsage:\n\n.. code-block:: python\n\n  file = client.files.get(name='files/...')\n  print(file.uri)"
  signature: 'def get(self, *, name: str, config: typing.Optional[google.genai.types.GetFileConfigOrDict]=None) -> google.genai.types.File:'
- rank: 1870
  id: google.genai.files.Files.list
  name: list
  file_path: env/lib/python3.13/site-packages/google/genai/files.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Lists all files from the service.\n\nArgs:\n  config (ListFilesConfig): Optional, configuration for the list method.\n\nReturns:\n  A Pager object that contains one page of files. When iterating over\n  the pager, it automatically fetches the next page if there are more.\n\nUsage:\n\n.. code-block:: python\n\n  for file in client.files.list(config={'page_size': 10}):\n    print(file.name)"
  signature: 'def list(self, *, config: typing.Optional[google.genai.types.ListFilesConfigOrDict]=None) -> google.genai.pagers.Pager[google.genai.types.File]:'
- rank: 1871
  id: google.genai.files.Files.upload
  name: upload
  file_path: env/lib/python3.13/site-packages/google/genai/files.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Calls the API to upload a file using a supported file service.\n\nArgs:\n  file: A path to the file or an `IOBase` object to be uploaded. If it's an\n    IOBase object, it must be opened in blocking (the default) mode and\n    binary mode. In other words, do not use non-blocking mode or text mode.\n    The given stream must be seekable, that is, it must be able to call\n    `seek()` on 'path'.\n  config: Optional parameters to set `diplay_name`, `mime_type`, and `name`."
  signature: 'def upload(self, *, file: typing.Union[str, os.PathLike[str], io.IOBase], config: typing.Optional[google.genai.types.UploadFileConfigOrDict]=None) -> google.genai.types.File:'
- rank: 1872
  id: google.genai.live
  name: live
  file_path: env/lib/python3.13/site-packages/google/genai/live.py
  type: MODULE
  group: Orphan
  usage_score: 0
  docstring: '[Preview] Live API client.'
- rank: 1873
  id: google.genai.live.AsyncLive
  name: AsyncLive
  file_path: env/lib/python3.13/site-packages/google/genai/live.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: '[Preview] AsyncLive.


    [Note: Inherited members from _api_module.BaseModule are omitted.]'
  constructor_signature: 'def __init__(self, api_client: google.genai._api_client.BaseApiClient):'
  methods:
  - signature: 'def music(self) -> google.genai.live_music.AsyncLiveMusic:'
  - signature: 'def connect(self, *, model: str, config: typing.Optional[google.genai.types.LiveConnectConfigOrDict]=None) -> typing.AsyncIterator[google.genai.live.AsyncSession]:'
    docstring: "[Preview] Connect to the live server.\n\nNote: the live API is currently in preview.\n\nUsage:\n\n.. code-block:: python\n\n  client = genai.Client(api_key=API_KEY)\n  config = {}\n  async with client.aio.live.connect(model='...', config=config) as session:\n    await session.send_client_content(\n      turns=types.Content(\n        role='user',\n        parts=[types.Part(text='hello!')]\n      ),\n      turn_complete=True\n    )\n    async for message in session.receive():\n      print(message)\n\nArgs:\n  model: The model to use for the live session.\n  config: The configuration for the live session.\n  **kwargs: additional keyword arguments.\n\nYields:\n  An AsyncSession object."
  omitted_inherited_members_from:
  - _api_module.BaseModule
- rank: 1874
  id: google.genai.live.AsyncLive.connect
  name: connect
  file_path: env/lib/python3.13/site-packages/google/genai/live.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "[Preview] Connect to the live server.\n\nNote: the live API is currently in preview.\n\nUsage:\n\n.. code-block:: python\n\n  client = genai.Client(api_key=API_KEY)\n  config = {}\n  async with client.aio.live.connect(model='...', config=config) as session:\n    await session.send_client_content(\n      turns=types.Content(\n        role='user',\n        parts=[types.Part(text='hello!')]\n      ),\n      turn_complete=True\n    )\n    async for message in session.receive():\n      print(message)\n\nArgs:\n  model: The model to use for the live session.\n  config: The configuration for the live session.\n  **kwargs: additional keyword arguments.\n\nYields:\n  An AsyncSession object."
  signature: 'def connect(self, *, model: str, config: typing.Optional[google.genai.types.LiveConnectConfigOrDict]=None) -> typing.AsyncIterator[google.genai.live.AsyncSession]:'
- rank: 1875
  id: google.genai.live.AsyncSession
  name: AsyncSession
  file_path: env/lib/python3.13/site-packages/google/genai/live.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: '[Preview] AsyncSession.'
  constructor_signature: 'def __init__(self, api_client: google.genai._api_client.BaseApiClient, websocket: websockets.client.ClientConnection, session_id: typing.Optional[str]):'
  methods:
  - signature: 'def send(self, *, input: typing.Optional[typing.Union[google.genai.types.ContentListUnion, google.genai.types.ContentListUnionDict, google.genai.types.LiveClientContentOrDict, google.genai.types.LiveClientRealtimeInputOrDict, google.genai.types.LiveClientToolResponseOrDict, google.genai.types.FunctionResponseOrDict, typing.Sequence[google.genai.types.FunctionResponseOrDict]]]=None, end_of_turn: typing.Optional[bool]=False) -> None:'
    docstring: "[Deprecated] Send input to the model.\n\n> **Warning**: This method is deprecated and will be removed in a future\nversion (not before Q3 2025). Please use one of the more specific methods:\n`send_client_content`, `send_realtime_input`, or `send_tool_response`\ninstead.\n\nThe method will send the input request to the server.\n\nArgs:\n  input: The input request to the model.\n  end_of_turn: Whether the input is the last message in a turn.\n\nExample usage:\n\n.. code-block:: python\n\n  client = genai.Client(api_key=API_KEY)\n\n  async with client.aio.live.connect(model='...') as session:\n    await session.send(input='Hello world!', end_of_turn=True)\n    async for message in session.receive():\n      print(message)"
  - signature: 'def send_client_content(self, *, turns: typing.Optional[typing.Union[google.genai.types.Content, google.genai.types.ContentDict, list[typing.Union[google.genai.types.Content, google.genai.types.ContentDict]]]]=None, turn_complete: bool=True) -> None:'
    docstring: "Send non-realtime, turn based content to the model.\n\nThere are two ways to send messages to the live API:\n`send_client_content` and `send_realtime_input`.\n\n`send_client_content` messages are added to the model context **in order**.\nHaving a conversation using `send_client_content` messages is roughly\nequivalent to using the `Chat.send_message_stream` method, except that the\nstate of the `chat` history is stored on the API server.\n\nBecause of `send_client_content`'s order guarantee, the model cannot\nrespond as quickly to `send_client_content` messages as to\n`send_realtime_input` messages. This makes the biggest difference when\nsending objects that have significant preprocessing time (typically images).\n\nThe `send_client_content` message sends a list of `Content` objects,\nwhich has more options than the `media:Blob` sent by `send_realtime_input`.\n\nThe main use-cases for `send_client_content` over `send_realtime_input` are:\n\n- Prefilling a conversation context\
      \ (including sending anything that can't\n  be represented as a realtime message), before starting a realtime\n  conversation.\n- Conducting a non-realtime conversation, similar to `client.chat`, using\n  the live api.\n\nCaution: Interleaving `send_client_content` and `send_realtime_input`\n  in the same conversation is not recommended and can lead to unexpected\n  results.\n\nArgs:\n  turns: A `Content` object or list of `Content` objects (or equivalent\n    dicts).\n  turn_complete: if true (the default) the model will reply immediately. If\n    false, the model will wait for you to send additional client_content,\n    and will not return until you send `turn_complete=True`.\n\nExample:\n\n.. code-block:: python\n\n  import google.genai\n  from google.genai import types\n  import os\n\n  if os.environ.get('GOOGLE_GENAI_USE_VERTEXAI'):\n    MODEL_NAME = 'gemini-2.0-flash-live-preview-04-09'\n  else:\n    MODEL_NAME = 'gemini-live-2.5-flash-preview';\n\n  client = genai.Client()\n\
      \  async with client.aio.live.connect(\n      model=MODEL_NAME,\n      config={\"response_modalities\": [\"TEXT\"]}\n  ) as session:\n    await session.send_client_content(\n        turns=types.Content(\n            role='user',\n            parts=[types.Part(text=\"Hello world!\")]))\n    async for msg in session.receive():\n      if msg.text:\n        print(msg.text)"
  - signature: 'def send_realtime_input(self, *, media: typing.Optional[google.genai.types.BlobImageUnionDict]=None, audio: typing.Optional[google.genai.types.BlobOrDict]=None, audio_stream_end: typing.Optional[bool]=None, video: typing.Optional[google.genai.types.BlobImageUnionDict]=None, text: typing.Optional[str]=None, activity_start: typing.Optional[google.genai.types.ActivityStartOrDict]=None, activity_end: typing.Optional[google.genai.types.ActivityEndOrDict]=None) -> None:'
    docstring: "Send realtime input to the model, only send one argument per call.\n\nUse `send_realtime_input` for realtime audio chunks and video\nframes(images).\n\nWith `send_realtime_input` the api will respond to audio automatically\nbased on voice activity detection (VAD).\n\n`send_realtime_input` is optimized for responsivness at the expense of\ndeterministic ordering. Audio and video tokens are added to the\ncontext when they become available.\n\nArgs:\n  media: A `Blob`-like object, the realtime media to send.\n\nExample:\n\n.. code-block:: python\n\n  from pathlib import Path\n\n  from google import genai\n  from google.genai import types\n\n  import PIL.Image\n\n  import os\n\n  if os.environ.get('GOOGLE_GENAI_USE_VERTEXAI'):\n    MODEL_NAME = 'gemini-2.0-flash-live-preview-04-09'\n  else:\n    MODEL_NAME = 'gemini-live-2.5-flash-preview';\n\n  client = genai.Client()\n\n  async with client.aio.live.connect(\n      model=MODEL_NAME,\n      config={\"response_modalities\": [\"\
      TEXT\"]},\n  ) as session:\n    await session.send_realtime_input(\n        media=PIL.Image.open('image.jpg'))\n\n    audio_bytes = Path('audio.pcm').read_bytes()\n    await session.send_realtime_input(\n        media=types.Blob(data=audio_bytes, mime_type='audio/pcm;rate=16000'))\n\n    async for msg in session.receive():\n      if msg.text is not None:\n        print(f'{msg.text}')"
  - signature: 'def send_tool_response(self, *, function_responses: typing.Union[google.genai.types.FunctionResponseOrDict, typing.Sequence[google.genai.types.FunctionResponseOrDict]]) -> None:'
    docstring: "Send a tool response to the session.\n\nUse `send_tool_response` to reply to `LiveServerToolCall` messages\nfrom the server.\n\nTo set the available tools, use the `config.tools` argument\nwhen you connect to the session (`client.live.connect`).\n\nArgs:\n  function_responses: A `FunctionResponse`-like object or list of\n    `FunctionResponse`-like objects.\n\nExample:\n\n.. code-block:: python\n\n  from google import genai\n  from google.genai import types\n\n  import os\n\n  if os.environ.get('GOOGLE_GENAI_USE_VERTEXAI'):\n    MODEL_NAME = 'gemini-2.0-flash-live-preview-04-09'\n  else:\n    MODEL_NAME = 'gemini-live-2.5-flash-preview';\n\n  client = genai.Client()\n\n  tools = [{'function_declarations': [{'name': 'turn_on_the_lights'}]}]\n  config = {\n      \"tools\": tools,\n      \"response_modalities\": ['TEXT']\n  }\n\n  async with client.aio.live.connect(\n      model='models/gemini-live-2.5-flash-preview',\n      config=config\n  ) as session:\n    prompt = \"Turn\
      \ on the lights please\"\n    await session.send_client_content(\n        turns={\"parts\": [{'text': prompt}]}\n    )\n\n    async for chunk in session.receive():\n        if chunk.server_content:\n          if chunk.text is not None:\n            print(chunk.text)\n        elif chunk.tool_call:\n          print(chunk.tool_call)\n          print('_'*80)\n          function_response=types.FunctionResponse(\n                  name='turn_on_the_lights',\n                  response={'result': 'ok'},\n                  id=chunk.tool_call.function_calls[0].id,\n              )\n          print(function_response)\n          await session.send_tool_response(\n              function_responses=function_response\n          )\n\n          print('_'*80)"
  - signature: 'def receive(self) -> typing.AsyncIterator[google.genai.types.LiveServerMessage]:'
    docstring: "Receive model responses from the server.\n\nThe method will yield the model responses from the server. The returned\nresponses will represent a complete model turn. When the returned message\nis function call, user must call `send` with the function response to\ncontinue the turn.\n\nYields:\n  The model responses from the server.\n\nExample usage:\n\n.. code-block:: python\n\n  client = genai.Client(api_key=API_KEY)\n\n  async with client.aio.live.connect(model='...') as session:\n    await session.send(input='Hello world!', end_of_turn=True)\n    async for message in session.receive():\n      print(message)"
  - signature: 'def start_stream(self, *, stream: typing.AsyncIterator[bytes], mime_type: str) -> typing.AsyncIterator[google.genai.types.LiveServerMessage]:'
    docstring: "[Deprecated] Start a live session from a data stream.\n\n> **Warning**: This method is deprecated and will be removed in a future\nversion (not before Q2 2025). Please use one of the more specific methods:\n`send_client_content`, `send_realtime_input`, or `send_tool_response`\ninstead.\n\nThe interaction terminates when the input stream is complete.\nThis method will start two async tasks. One task will be used to send the\ninput stream to the model and the other task will be used to receive the\nresponses from the model.\n\nArgs:\n  stream: An iterator that yields the model response.\n  mime_type: The MIME type of the data in the stream.\n\nYields:\n  The audio bytes received from the model and server response messages.\n\nExample usage:\n\n.. code-block:: python\n\n  client = genai.Client(api_key=API_KEY)\n  config = {'response_modalities': ['AUDIO']}\n  async def audio_stream():\n    stream = read_audio()\n    for data in stream:\n      yield data\n  async with client.aio.live.connect(model='...',\
      \ config=config) as session:\n    for audio in session.start_stream(stream = audio_stream(),\n    mime_type = 'audio/pcm'):\n      play_audio_chunk(audio.data)"
  - signature: 'def close(self) -> None:'
- rank: 1876
  id: google.genai.live.AsyncSession.__init__
  name: __init__
  file_path: env/lib/python3.13/site-packages/google/genai/live.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def __init__(self, api_client: google.genai._api_client.BaseApiClient, websocket: websockets.client.ClientConnection, session_id: typing.Optional[str]):'
- rank: 1877
  id: google.genai.live.AsyncSession.receive
  name: receive
  file_path: env/lib/python3.13/site-packages/google/genai/live.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Receive model responses from the server.\n\nThe method will yield the model responses from the server. The returned\nresponses will represent a complete model turn. When the returned message\nis function call, user must call `send` with the function response to\ncontinue the turn.\n\nYields:\n  The model responses from the server.\n\nExample usage:\n\n.. code-block:: python\n\n  client = genai.Client(api_key=API_KEY)\n\n  async with client.aio.live.connect(model='...') as session:\n    await session.send(input='Hello world!', end_of_turn=True)\n    async for message in session.receive():\n      print(message)"
  signature: 'def receive(self) -> typing.AsyncIterator[google.genai.types.LiveServerMessage]:'
- rank: 1878
  id: google.genai.live.AsyncSession.send
  name: send
  file_path: env/lib/python3.13/site-packages/google/genai/live.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "[Deprecated] Send input to the model.\n\n> **Warning**: This method is deprecated and will be removed in a future\nversion (not before Q3 2025). Please use one of the more specific methods:\n`send_client_content`, `send_realtime_input`, or `send_tool_response`\ninstead.\n\nThe method will send the input request to the server.\n\nArgs:\n  input: The input request to the model.\n  end_of_turn: Whether the input is the last message in a turn.\n\nExample usage:\n\n.. code-block:: python\n\n  client = genai.Client(api_key=API_KEY)\n\n  async with client.aio.live.connect(model='...') as session:\n    await session.send(input='Hello world!', end_of_turn=True)\n    async for message in session.receive():\n      print(message)"
  signature: 'def send(self, *, input: typing.Optional[typing.Union[google.genai.types.ContentListUnion, google.genai.types.ContentListUnionDict, google.genai.types.LiveClientContentOrDict, google.genai.types.LiveClientRealtimeInputOrDict, google.genai.types.LiveClientToolResponseOrDict, google.genai.types.FunctionResponseOrDict, typing.Sequence[google.genai.types.FunctionResponseOrDict]]]=None, end_of_turn: typing.Optional[bool]=False) -> None:'
- rank: 1879
  id: google.genai.live.AsyncSession.send_client_content
  name: send_client_content
  file_path: env/lib/python3.13/site-packages/google/genai/live.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Send non-realtime, turn based content to the model.\n\nThere are two ways to send messages to the live API:\n`send_client_content` and `send_realtime_input`.\n\n`send_client_content` messages are added to the model context **in order**.\nHaving a conversation using `send_client_content` messages is roughly\nequivalent to using the `Chat.send_message_stream` method, except that the\nstate of the `chat` history is stored on the API server.\n\nBecause of `send_client_content`'s order guarantee, the model cannot\nrespond as quickly to `send_client_content` messages as to\n`send_realtime_input` messages. This makes the biggest difference when\nsending objects that have significant preprocessing time (typically images).\n\nThe `send_client_content` message sends a list of `Content` objects,\nwhich has more options than the `media:Blob` sent by `send_realtime_input`.\n\nThe main use-cases for `send_client_content` over `send_realtime_input` are:\n\n- Prefilling a conversation context\
    \ (including sending anything that can't\n  be represented as a realtime message), before starting a realtime\n  conversation.\n- Conducting a non-realtime conversation, similar to `client.chat`, using\n  the live api.\n\nCaution: Interleaving `send_client_content` and `send_realtime_input`\n  in the same conversation is not recommended and can lead to unexpected\n  results.\n\nArgs:\n  turns: A `Content` object or list of `Content` objects (or equivalent\n    dicts).\n  turn_complete: if true (the default) the model will reply immediately. If\n    false, the model will wait for you to send additional client_content,\n    and will not return until you send `turn_complete=True`.\n\nExample:\n\n.. code-block:: python\n\n  import google.genai\n  from google.genai import types\n  import os\n\n  if os.environ.get('GOOGLE_GENAI_USE_VERTEXAI'):\n    MODEL_NAME = 'gemini-2.0-flash-live-preview-04-09'\n  else:\n    MODEL_NAME = 'gemini-live-2.5-flash-preview';\n\n  client = genai.Client()\n \
    \ async with client.aio.live.connect(\n      model=MODEL_NAME,\n      config={\"response_modalities\": [\"TEXT\"]}\n  ) as session:\n    await session.send_client_content(\n        turns=types.Content(\n            role='user',\n            parts=[types.Part(text=\"Hello world!\")]))\n    async for msg in session.receive():\n      if msg.text:\n        print(msg.text)"
  signature: 'def send_client_content(self, *, turns: typing.Optional[typing.Union[google.genai.types.Content, google.genai.types.ContentDict, list[typing.Union[google.genai.types.Content, google.genai.types.ContentDict]]]]=None, turn_complete: bool=True) -> None:'
- rank: 1880
  id: google.genai.live.AsyncSession.send_realtime_input
  name: send_realtime_input
  file_path: env/lib/python3.13/site-packages/google/genai/live.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Send realtime input to the model, only send one argument per call.\n\nUse `send_realtime_input` for realtime audio chunks and video\nframes(images).\n\nWith `send_realtime_input` the api will respond to audio automatically\nbased on voice activity detection (VAD).\n\n`send_realtime_input` is optimized for responsivness at the expense of\ndeterministic ordering. Audio and video tokens are added to the\ncontext when they become available.\n\nArgs:\n  media: A `Blob`-like object, the realtime media to send.\n\nExample:\n\n.. code-block:: python\n\n  from pathlib import Path\n\n  from google import genai\n  from google.genai import types\n\n  import PIL.Image\n\n  import os\n\n  if os.environ.get('GOOGLE_GENAI_USE_VERTEXAI'):\n    MODEL_NAME = 'gemini-2.0-flash-live-preview-04-09'\n  else:\n    MODEL_NAME = 'gemini-live-2.5-flash-preview';\n\n  client = genai.Client()\n\n  async with client.aio.live.connect(\n      model=MODEL_NAME,\n      config={\"response_modalities\": [\"TEXT\"\
    ]},\n  ) as session:\n    await session.send_realtime_input(\n        media=PIL.Image.open('image.jpg'))\n\n    audio_bytes = Path('audio.pcm').read_bytes()\n    await session.send_realtime_input(\n        media=types.Blob(data=audio_bytes, mime_type='audio/pcm;rate=16000'))\n\n    async for msg in session.receive():\n      if msg.text is not None:\n        print(f'{msg.text}')"
  signature: 'def send_realtime_input(self, *, media: typing.Optional[google.genai.types.BlobImageUnionDict]=None, audio: typing.Optional[google.genai.types.BlobOrDict]=None, audio_stream_end: typing.Optional[bool]=None, video: typing.Optional[google.genai.types.BlobImageUnionDict]=None, text: typing.Optional[str]=None, activity_start: typing.Optional[google.genai.types.ActivityStartOrDict]=None, activity_end: typing.Optional[google.genai.types.ActivityEndOrDict]=None) -> None:'
- rank: 1881
  id: google.genai.live.AsyncSession.send_tool_response
  name: send_tool_response
  file_path: env/lib/python3.13/site-packages/google/genai/live.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Send a tool response to the session.\n\nUse `send_tool_response` to reply to `LiveServerToolCall` messages\nfrom the server.\n\nTo set the available tools, use the `config.tools` argument\nwhen you connect to the session (`client.live.connect`).\n\nArgs:\n  function_responses: A `FunctionResponse`-like object or list of\n    `FunctionResponse`-like objects.\n\nExample:\n\n.. code-block:: python\n\n  from google import genai\n  from google.genai import types\n\n  import os\n\n  if os.environ.get('GOOGLE_GENAI_USE_VERTEXAI'):\n    MODEL_NAME = 'gemini-2.0-flash-live-preview-04-09'\n  else:\n    MODEL_NAME = 'gemini-live-2.5-flash-preview';\n\n  client = genai.Client()\n\n  tools = [{'function_declarations': [{'name': 'turn_on_the_lights'}]}]\n  config = {\n      \"tools\": tools,\n      \"response_modalities\": ['TEXT']\n  }\n\n  async with client.aio.live.connect(\n      model='models/gemini-live-2.5-flash-preview',\n      config=config\n  ) as session:\n    prompt = \"Turn\
    \ on the lights please\"\n    await session.send_client_content(\n        turns={\"parts\": [{'text': prompt}]}\n    )\n\n    async for chunk in session.receive():\n        if chunk.server_content:\n          if chunk.text is not None:\n            print(chunk.text)\n        elif chunk.tool_call:\n          print(chunk.tool_call)\n          print('_'*80)\n          function_response=types.FunctionResponse(\n                  name='turn_on_the_lights',\n                  response={'result': 'ok'},\n                  id=chunk.tool_call.function_calls[0].id,\n              )\n          print(function_response)\n          await session.send_tool_response(\n              function_responses=function_response\n          )\n\n          print('_'*80)"
  signature: 'def send_tool_response(self, *, function_responses: typing.Union[google.genai.types.FunctionResponseOrDict, typing.Sequence[google.genai.types.FunctionResponseOrDict]]) -> None:'
- rank: 1882
  id: google.genai.live.AsyncSession.start_stream
  name: start_stream
  file_path: env/lib/python3.13/site-packages/google/genai/live.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "[Deprecated] Start a live session from a data stream.\n\n> **Warning**: This method is deprecated and will be removed in a future\nversion (not before Q2 2025). Please use one of the more specific methods:\n`send_client_content`, `send_realtime_input`, or `send_tool_response`\ninstead.\n\nThe interaction terminates when the input stream is complete.\nThis method will start two async tasks. One task will be used to send the\ninput stream to the model and the other task will be used to receive the\nresponses from the model.\n\nArgs:\n  stream: An iterator that yields the model response.\n  mime_type: The MIME type of the data in the stream.\n\nYields:\n  The audio bytes received from the model and server response messages.\n\nExample usage:\n\n.. code-block:: python\n\n  client = genai.Client(api_key=API_KEY)\n  config = {'response_modalities': ['AUDIO']}\n  async def audio_stream():\n    stream = read_audio()\n    for data in stream:\n      yield data\n  async with client.aio.live.connect(model='...',\
    \ config=config) as session:\n    for audio in session.start_stream(stream = audio_stream(),\n    mime_type = 'audio/pcm'):\n      play_audio_chunk(audio.data)"
  signature: 'def start_stream(self, *, stream: typing.AsyncIterator[bytes], mime_type: str) -> typing.AsyncIterator[google.genai.types.LiveServerMessage]:'
- rank: 1883
  id: google.genai.live_music
  name: live_music
  file_path: env/lib/python3.13/site-packages/google/genai/live_music.py
  type: MODULE
  group: Orphan
  usage_score: 0
  docstring: '[Experimental] Live Music API client.'
- rank: 1884
  id: google.genai.live_music.AsyncLiveMusic
  name: AsyncLiveMusic
  file_path: env/lib/python3.13/site-packages/google/genai/live_music.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: '[Experimental] Live music module.


    Live music can be accessed via `client.aio.live.music`.


    [Note: Inherited members from _api_module.BaseModule are omitted.]'
  methods:
  - signature: 'def connect(self, *, model: str) -> typing.AsyncIterator[google.genai.live_music.AsyncMusicSession]:'
    docstring: '[Experimental] Connect to the live music server.'
  omitted_inherited_members_from:
  - _api_module.BaseModule
- rank: 1885
  id: google.genai.live_music.AsyncLiveMusic.connect
  name: connect
  file_path: env/lib/python3.13/site-packages/google/genai/live_music.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: '[Experimental] Connect to the live music server.'
  signature: 'def connect(self, *, model: str) -> typing.AsyncIterator[google.genai.live_music.AsyncMusicSession]:'
- rank: 1886
  id: google.genai.live_music.AsyncMusicSession
  name: AsyncMusicSession
  file_path: env/lib/python3.13/site-packages/google/genai/live_music.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: '[Experimental] AsyncMusicSession.'
  constructor_signature: 'def __init__(self, api_client: google.genai._api_client.BaseApiClient, websocket: websockets.client.ClientConnection):'
  methods:
  - signature: 'def set_weighted_prompts(self, prompts: list[google.genai.types.WeightedPrompt]) -> None:'
  - signature: 'def set_music_generation_config(self, config: google.genai.types.LiveMusicGenerationConfig) -> None:'
  - signature: 'def play(self) -> None:'
    docstring: Sends playback signal to start the music stream.
  - signature: 'def pause(self) -> None:'
    docstring: Sends a playback signal to pause the music stream.
  - signature: 'def stop(self) -> None:'
    docstring: 'Sends a playback signal to stop the music stream.


      Resets the music generation context while retaining the current config.'
  - signature: 'def reset_context(self) -> None:'
    docstring: Reset the context (prompts retained) without stopping the music generation.
  - signature: 'def receive(self) -> typing.AsyncIterator[google.genai.types.LiveMusicServerMessage]:'
    docstring: "Receive model responses from the server.\n\nYields:\n  The audio chunks from the server."
  - signature: 'def close(self) -> None:'
    docstring: Closes the bi-directional stream and terminates the session.
- rank: 1887
  id: google.genai.live_music.AsyncMusicSession.receive
  name: receive
  file_path: env/lib/python3.13/site-packages/google/genai/live_music.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Receive model responses from the server.\n\nYields:\n  The audio chunks from the server."
  signature: 'def receive(self) -> typing.AsyncIterator[google.genai.types.LiveMusicServerMessage]:'
- rank: 1888
  id: google.genai.live_music.AsyncMusicSession.reset_context
  name: reset_context
  file_path: env/lib/python3.13/site-packages/google/genai/live_music.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: Reset the context (prompts retained) without stopping the music generation.
  signature: 'def reset_context(self) -> None:'
- rank: 1889
  id: google.genai.live_music.AsyncMusicSession.set_music_generation_config
  name: set_music_generation_config
  file_path: env/lib/python3.13/site-packages/google/genai/live_music.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def set_music_generation_config(self, config: google.genai.types.LiveMusicGenerationConfig) -> None:'
- rank: 1890
  id: google.genai.live_music.AsyncMusicSession.set_weighted_prompts
  name: set_weighted_prompts
  file_path: env/lib/python3.13/site-packages/google/genai/live_music.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def set_weighted_prompts(self, prompts: list[google.genai.types.WeightedPrompt]) -> None:'
- rank: 1891
  id: google.genai.live_music.AsyncMusicSession.stop
  name: stop
  file_path: env/lib/python3.13/site-packages/google/genai/live_music.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: 'Sends a playback signal to stop the music stream.


    Resets the music generation context while retaining the current config.'
  signature: 'def stop(self) -> None:'
- rank: 1892
  id: google.genai.local_tokenizer
  name: local_tokenizer
  file_path: env/lib/python3.13/site-packages/google/genai/local_tokenizer.py
  type: MODULE
  group: Orphan
  usage_score: 0
  docstring: '[Experimental] Text Only Local Tokenizer.'
- rank: 1893
  id: google.genai.local_tokenizer.LocalTokenizer
  name: LocalTokenizer
  file_path: env/lib/python3.13/site-packages/google/genai/local_tokenizer.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: '[Experimental] Text Only Local Tokenizer.


    This class provides a local tokenizer for text only token counting.


    LIMITATIONS:

    - Only supports text based tokenization and no multimodal tokenization.

    - Forward compatibility depends on the open-source tokenizer models for future

    Gemini versions.

    - For token counting of tools and response schemas, the `LocalTokenizer` only

    supports `types.Tool` and `types.Schema` objects. Python functions or Pydantic

    models cannot be passed directly.'
  constructor_signature: 'def __init__(self, model_name: str):'
  methods:
  - signature: 'def count_tokens(self, contents: typing.Union[google.genai.types.ContentListUnion, google.genai.types.ContentListUnionDict], *, config: typing.Optional[google.genai.types.CountTokensConfigOrDict]=None) -> google.genai.types.CountTokensResult:'
    docstring: "Counts the number of tokens in a given text.\n\nArgs:\n  contents: The contents to tokenize.\n  config: The configuration for counting tokens.\n\nReturns:\n  A `CountTokensResult` containing the total number of tokens.\n\nUsage:\n\n.. code-block:: python\n\n  from google import genai\n  tokenizer = genai.LocalTokenizer(model_name='gemini-2.0-flash-001')\n  result = tokenizer.count_tokens(\"What is your name?\")\n  print(result)\n  # total_tokens=5"
  - signature: 'def compute_tokens(self, contents: typing.Union[google.genai.types.ContentListUnion, google.genai.types.ContentListUnionDict]) -> google.genai.types.ComputeTokensResult:'
    docstring: "Computes the tokens ids and string pieces in the input.\n\nArgs:\n  contents: The contents to tokenize.\n\nReturns:\n  A `ComputeTokensResult` containing the token information.\n\nUsage:\n\n.. code-block:: python\n\n  from google import genai\n  tokenizer = genai.LocalTokenizer(model_name='gemini-2.0-flash-001')\n  result = tokenizer.compute_tokens(\"What is your name?\")\n  print(result)\n  # tokens_info=[TokensInfo(token_ids=[279, 329, 1313, 2508, 13], tokens=[b' What', b' is', b' your', b' name', b'?'], role='user')]"
- rank: 1894
  id: google.genai.local_tokenizer.LocalTokenizer.__init__
  name: __init__
  file_path: env/lib/python3.13/site-packages/google/genai/local_tokenizer.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def __init__(self, model_name: str):'
- rank: 1895
  id: google.genai.local_tokenizer.LocalTokenizer.compute_tokens
  name: compute_tokens
  file_path: env/lib/python3.13/site-packages/google/genai/local_tokenizer.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Computes the tokens ids and string pieces in the input.\n\nArgs:\n  contents: The contents to tokenize.\n\nReturns:\n  A `ComputeTokensResult` containing the token information.\n\nUsage:\n\n.. code-block:: python\n\n  from google import genai\n  tokenizer = genai.LocalTokenizer(model_name='gemini-2.0-flash-001')\n  result = tokenizer.compute_tokens(\"What is your name?\")\n  print(result)\n  # tokens_info=[TokensInfo(token_ids=[279, 329, 1313, 2508, 13], tokens=[b' What', b' is', b' your', b' name', b'?'], role='user')]"
  signature: 'def compute_tokens(self, contents: typing.Union[google.genai.types.ContentListUnion, google.genai.types.ContentListUnionDict]) -> google.genai.types.ComputeTokensResult:'
- rank: 1896
  id: google.genai.local_tokenizer.LocalTokenizer.count_tokens
  name: count_tokens
  file_path: env/lib/python3.13/site-packages/google/genai/local_tokenizer.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Counts the number of tokens in a given text.\n\nArgs:\n  contents: The contents to tokenize.\n  config: The configuration for counting tokens.\n\nReturns:\n  A `CountTokensResult` containing the total number of tokens.\n\nUsage:\n\n.. code-block:: python\n\n  from google import genai\n  tokenizer = genai.LocalTokenizer(model_name='gemini-2.0-flash-001')\n  result = tokenizer.count_tokens(\"What is your name?\")\n  print(result)\n  # total_tokens=5"
  signature: 'def count_tokens(self, contents: typing.Union[google.genai.types.ContentListUnion, google.genai.types.ContentListUnionDict], *, config: typing.Optional[google.genai.types.CountTokensConfigOrDict]=None) -> google.genai.types.CountTokensResult:'
- rank: 1897
  id: google.genai.models
  name: models
  file_path: env/lib/python3.13/site-packages/google/genai/models.py
  type: MODULE
  group: Orphan
  usage_score: 0
- rank: 1898
  id: google.genai.models.AsyncModels
  name: AsyncModels
  file_path: env/lib/python3.13/site-packages/google/genai/models.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: '[Note: Inherited members from _api_module.BaseModule are omitted.]'
  methods:
  - signature: 'def async_generator(model, contents, config):'
  - signature: 'def embed_content(self, *, model: str, contents: typing.Union[google.genai.types.ContentListUnion, google.genai.types.ContentListUnionDict], config: typing.Optional[google.genai.types.EmbedContentConfigOrDict]=None) -> google.genai.types.EmbedContentResponse:'
    docstring: "Calculates embeddings for the given contents. Only text is supported.\n\nArgs:\n  model (str): The model to use.\n  contents (list[Content]): The contents to embed.\n  config (EmbedContentConfig): Optional configuration for embeddings.\n\nUsage:\n\n.. code-block:: python\n\n  embeddings = await client.aio.models.embed_content(\n      model= 'text-embedding-004',\n      contents=[\n          'What is your name?',\n          'What is your favorite color?',\n      ],\n      config={\n          'output_dimensionality': 64\n      },\n  )"
  - signature: 'def recontext_image(self, *, model: str, source: google.genai.types.RecontextImageSourceOrDict, config: typing.Optional[google.genai.types.RecontextImageConfigOrDict]=None) -> google.genai.types.RecontextImageResponse:'
    docstring: "Recontextualizes an image.\n\nThere are two types of recontextualization currently supported:\n1) Imagen Product Recontext - Generate images of products in new scenes\n   and contexts.\n2) Virtual Try-On: Generate images of persons modeling fashion products.\n\nArgs:\n  model (str): The model to use.\n  source (RecontextImageSource): An object containing the source inputs\n    (prompt, person_image, product_images) for image recontext. prompt is\n    optional for product recontext and disallowed for virtual try-on.\n    person_image is required for virtual try-on, disallowed for product\n    recontext. product_images is required for both product recontext and\n    virtual try-on. Only one product image is supported for virtual try-on,\n    and up to 3 product images (different angles of the same product) are\n    supported for product recontext.\n  config (RecontextImageConfig): Configuration for recontextualization.\n\nUsage:\n\n  ```\n  product_recontext_response = client.models.recontext_image(\n\
      \      model=\"imagen-product-recontext-preview-06-30\",\n      source=types.RecontextImageSource(\n          prompt=\"In a modern kitchen setting.\",\n          product_images=[types.ProductImage.from_file(IMAGE_FILE_PATH)],\n      ),\n      config=types.RecontextImageConfig(\n          number_of_images=1,\n      ),\n  )\n  image = product_recontext_response.generated_images[0].image\n\n  virtual_try_on_response = client.models.recontext_image(\n      model=\"virtual-try-on-preview-08-04\",\n      source=types.RecontextImageSource(\n          person_image=types.Image.from_file(IMAGE1_FILE_PATH),\n          product_images=[types.ProductImage.from_file(IMAGE2_FILE_PATH)],\n      ),\n      config=types.RecontextImageConfig(\n          number_of_images=1,\n      ),\n  )\n  image = virtual_try_on_response.generated_images[0].image\n  ```"
  - signature: 'def segment_image(self, *, model: str, source: google.genai.types.SegmentImageSourceOrDict, config: typing.Optional[google.genai.types.SegmentImageConfigOrDict]=None) -> google.genai.types.SegmentImageResponse:'
    docstring: "Segments an image, creating a mask of a specified area.\n\nArgs:\n  model (str): The model to use.\n  source (SegmentImageSource): An object containing the source inputs\n    (prompt, image, scribble_image) for image segmentation. The prompt is\n    required for prompt mode and semantic mode, disallowed for other modes.\n    scribble_image is required for the interactive mode, disallowed for\n    other modes.\n  config (SegmentImageConfig): Configuration for segmentation.\n\nUsage:\n\n  ```\n  response = client.models.segment_image(\n      model=\"image-segmentation-001\",\n      source=types.SegmentImageSource(\n          image=types.Image.from_file(IMAGE_FILE_PATH),\n      ),\n      config=types.SegmentImageConfig(\n          mode=types.SegmentMode.foreground,\n      ),\n  )\n\n  mask_image = response.generated_masks[0].mask\n  ```"
  - signature: 'def get(self, *, model: str, config: typing.Optional[google.genai.types.GetModelConfigOrDict]=None) -> google.genai.types.Model:'
  - signature: 'def update(self, *, model: str, config: typing.Optional[google.genai.types.UpdateModelConfigOrDict]=None) -> google.genai.types.Model:'
  - signature: 'def delete(self, *, model: str, config: typing.Optional[google.genai.types.DeleteModelConfigOrDict]=None) -> google.genai.types.DeleteModelResponse:'
  - signature: 'def count_tokens(self, *, model: str, contents: typing.Union[google.genai.types.ContentListUnion, google.genai.types.ContentListUnionDict], config: typing.Optional[google.genai.types.CountTokensConfigOrDict]=None) -> google.genai.types.CountTokensResponse:'
    docstring: "Counts the number of tokens in the given content.\n\nMultimodal input is supported for Gemini models.\n\nArgs:\n  model (str): The model to use for counting tokens.\n  contents (list[types.Content]): The content to count tokens for.\n  config (CountTokensConfig): The configuration for counting tokens.\n\nUsage:\n\n.. code-block:: python\n\n  response = await client.aio.models.count_tokens(\n      model='gemini-2.0-flash',\n      contents='What is your name?',\n  )\n  print(response)\n  # total_tokens=5 cached_content_token_count=None"
  - signature: 'def compute_tokens(self, *, model: str, contents: typing.Union[google.genai.types.ContentListUnion, google.genai.types.ContentListUnionDict], config: typing.Optional[google.genai.types.ComputeTokensConfigOrDict]=None) -> google.genai.types.ComputeTokensResponse:'
    docstring: "Given a list of contents, returns a corresponding TokensInfo containing the\n\nlist of tokens and list of token ids.\n\nArgs:\n  model (str): The model to use.\n  contents (list[shared.Content]): The content to compute tokens for.\n\nUsage:\n\n.. code-block:: python\n\n  response = await client.aio.models.compute_tokens(\n      model='gemini-2.0-flash',\n      contents='What is your name?',\n  )\n  print(response)\n  # tokens_info=[TokensInfo(role='user', token_ids=['1841', ...],\n  # tokens=[b'What', b' is', b' your', b' name', b'?'])]"
  - signature: 'def generate_content(self, *, model: str, contents: typing.Union[google.genai.types.ContentListUnion, google.genai.types.ContentListUnionDict], config: typing.Optional[google.genai.types.GenerateContentConfigOrDict]=None) -> google.genai.types.GenerateContentResponse:'
    docstring: "Makes an API request to generate content using a model.\n\nSome models support multimodal input and output.\n\nBuilt-in MCP support is an experimental feature.\n\nUsage:\n\n.. code-block:: python\n\n  from google.genai import types\n  from google import genai\n\n  client = genai.Client(\n      vertexai=True, project='my-project-id', location='us-central1'\n  )\n\n  response = await client.aio.models.generate_content(\n      model='gemini-2.0-flash',\n      contents='User input: I like bagels. Answer:',\n      config=types.GenerateContentConfig(\n          system_instruction=\n            [\n              'You are a helpful language translator.',\n              'Your mission is to translate text in English to French.'\n            ]\n      ),\n  )\n  print(response.text)\n  # J'aime les bagels."
  - signature: 'def generate_content_stream(self, *, model: str, contents: typing.Union[google.genai.types.ContentListUnion, google.genai.types.ContentListUnionDict], config: typing.Optional[google.genai.types.GenerateContentConfigOrDict]=None) -> typing.AsyncIterator[google.genai.types.GenerateContentResponse]:'
    docstring: "Makes an API request to generate content using a model and yields the model's response in chunks.\n\nFor the `model` parameter, supported formats for Vertex AI API include:\n- The Gemini model ID, for example: 'gemini-2.0-flash'\n- The full resource name starts with 'projects/', for example:\n  'projects/my-project-id/locations/us-central1/publishers/google/models/gemini-2.0-flash'\n- The partial resource name with 'publishers/', for example:\n  'publishers/google/models/gemini-2.0-flash' or\n- `/` separated publisher and model name, for example:\n  'google/gemini-2.0-flash'\n\nFor the `model` parameter, supported formats for Gemini API include:\n- The Gemini model ID, for example: 'gemini-2.0-flash'\n- The model name starts with 'models/', for example:\n  'models/gemini-2.0-flash'\n- For tuned models, the model name starts with 'tunedModels/',\n  for example:\n  'tunedModels/1234567890123456789'\n\nSome models support multimodal input and output.\n\nBuilt-in MCP support\
      \ is an experimental feature.\n\nUsage:\n\n.. code-block:: python\n\n  from google.genai import types\n  from google import genai\n\n  client = genai.Client(\n      vertexai=True, project='my-project-id', location='us-central1'\n  )\n\n  async for chunk in await client.aio.models.generate_content_stream(\n    model='gemini-2.0-flash',\n    contents='''What is a good name for a flower shop that specializes in\n      selling bouquets of dried flowers?'''\n  ):\n    print(chunk.text)\n  # **Elegant & Classic:**\n  # * The Dried Bloom\n  # * Everlasting Florals\n  # * Timeless Petals\n\n  async for chunk in await client.aio.models.generate_content_stream(\n    model='gemini-2.0-flash',\n    contents=[\n      types.Part.from_text('What is shown in this image?'),\n      types.Part.from_uri('gs://generativeai-downloads/images/scones.jpg',\n      'image/jpeg')\n    ]\n  ):\n    print(chunk.text)\n  # The image shows a flat lay arrangement of freshly baked blueberry\n  # scones."
  - signature: 'def base_async_generator(model, contents, config):'
  - signature: 'def base_async_generator(model, contents, config):'
  - signature: 'def async_generator(model, contents, config):'
  - signature: 'def edit_image(self, *, model: str, prompt: str, reference_images: list[google.genai.types._ReferenceImageAPIOrDict], config: typing.Optional[google.genai.types.EditImageConfigOrDict]=None) -> google.genai.types.EditImageResponse:'
    docstring: "Edits an image based on a text description and configuration.\n\nArgs:\n  model (str): The model to use.\n  prompt (str): A text description of the edit to apply to the image.\n    reference_images (list[Union[RawReferenceImage, MaskReferenceImage,\n    ControlReferenceImage, StyleReferenceImage, SubjectReferenceImage]): The\n    reference images for editing.\n  config (EditImageConfig): Configuration for editing.\n\nUsage:\n\n.. code-block:: python\n\n  from google.genai.types import RawReferenceImage, MaskReferenceImage\n\n  raw_ref_image = RawReferenceImage(\n    reference_id=1,\n    reference_image=types.Image.from_file(IMAGE_FILE_PATH),\n  )\n\n  mask_ref_image = MaskReferenceImage(\n    reference_id=2,\n    config=types.MaskReferenceConfig(\n        mask_mode='MASK_MODE_FOREGROUND',\n        mask_dilation=0.06,\n    ),\n  )\n  response = await client.aio.models.edit_image(\n    model='imagen-3.0-capability-001',\n    prompt='man with dog',\n    reference_images=[raw_ref_image,\
      \ mask_ref_image],\n    config=types.EditImageConfig(\n        edit_mode= \"EDIT_MODE_INPAINT_INSERTION\",\n        number_of_images= 1,\n        include_rai_reason= True,\n    )\n  )\n  response.generated_images[0].image.show()\n  # Shows a man with a dog instead of a cat."
  - signature: 'def list(self, *, config: typing.Optional[google.genai.types.ListModelsConfigOrDict]=None) -> google.genai.pagers.AsyncPager[google.genai.types.Model]:'
    docstring: "Makes an API request to list the available models.\n\nIf `query_base` is set to True in the config or not set (default), the\nAPI will return all available base models. If set to False, it will return\nall tuned models.\n\nArgs:\n  config (ListModelsConfigOrDict): Configuration for retrieving models.\n\nUsage:\n\n.. code-block:: python\n\n  response = await client.aio.models.list(config={'page_size': 5})\n  print(response.page)\n  # [Model(name='projects/./locations/./models/123', display_name='my_model'\n\n  response = await client.aio.models.list(\n      config={'page_size': 5, 'query_base': True}\n    )\n  print(response.page)\n  # [Model(name='publishers/google/models/gemini-2.0-flash-exp' ..."
  - signature: 'def generate_images(self, *, model: str, prompt: str, config: typing.Optional[google.genai.types.GenerateImagesConfigOrDict]=None) -> google.genai.types.GenerateImagesResponse:'
    docstring: "Generates images based on a text description and configuration.\n\nArgs:\n  model (str): The model to use.\n  prompt (str): A text description of the images to generate.\n  config (GenerateImagesConfig): Configuration for generation.\n\nUsage:\n\n.. code-block:: python\n\n  response = await client.aio.models.generate_images(\n    model='imagen-3.0-generate-002',\n    prompt='Man with a dog',\n    config=types.GenerateImagesConfig(\n        number_of_images= 1,\n        include_rai_reason= True,\n    )\n  )\n  response.generated_images[0].image.show()\n  # Shows a man with a dog."
  - signature: 'def upscale_image(self, *, model: str, image: google.genai.types.ImageOrDict, upscale_factor: str, config: typing.Optional[google.genai.types.UpscaleImageConfigOrDict]=None) -> google.genai.types.UpscaleImageResponse:'
    docstring: "Makes an API request to upscale a provided image.\n\nArgs:\n  model (str): The model to use.\n  image (Image): The input image for upscaling.\n  upscale_factor (str): The factor to upscale the image (x2 or x4).\n  config (UpscaleImageConfig): Configuration for upscaling.\n\nUsage:\n\n.. code-block:: python\n\n  from google.genai.types import Image\n\n  IMAGE_FILE_PATH=\"my-image.png\"\n  response = await client.aio.models.upscale_image(\n      model='imagen-3.0-generate-001',\n      image=types.Image.from_file(IMAGE_FILE_PATH),\n      upscale_factor='x2',\n  )\n  response.generated_images[0].image.show()\n  # Opens my-image.png which is upscaled by a factor of 2."
  - signature: 'def generate_videos(self, *, model: str, prompt: typing.Optional[str]=None, image: typing.Optional[google.genai.types.ImageOrDict]=None, video: typing.Optional[google.genai.types.VideoOrDict]=None, source: typing.Optional[google.genai.types.GenerateVideosSourceOrDict]=None, config: typing.Optional[google.genai.types.GenerateVideosConfigOrDict]=None) -> google.genai.types.GenerateVideosOperation:'
    docstring: "Generates videos based on an input (text, image, or video) and configuration.\n\nThe following use cases are supported:\n1. Text to video generation.\n2a. Image to video generation (additional text prompt is optional).\n2b. Image to video generation with frame interpolation (specify last_frame\nin config).\n3. Video extension (additional text prompt is optional)\n\nArgs:\n  model: The model to use.\n  prompt: The text prompt for generating the videos. Optional for image to\n    video and video extension use cases. This argument is deprecated, please\n    use source instead.\n  image: The input image for generating the videos. Optional if prompt is\n    provided. This argument is deprecated, please use source instead.\n  video: The input video for video extension use cases. Optional if prompt\n    or image is provided. This argument is deprecated, please use source\n    instead.\n  source: The input source for generating the videos (prompt, image, and/or\n    video)\n  config:\
      \ Configuration for generation.\n\nUsage:\n\n  ```\n  operation = client.models.generate_videos(\n      model=\"veo-2.0-generate-001\",\n      source=types.GenerateVideosSource(\n          prompt=\"A neon hologram of a cat driving at top speed\",\n      ),\n  )\n  while not operation.done:\n      time.sleep(10)\n      operation = client.operations.get(operation)\n\n  operation.result.generated_videos[0].video.uri\n  ```"
  omitted_inherited_members_from:
  - _api_module.BaseModule
- rank: 1899
  id: google.genai.models.AsyncModels.async_generator
  name: async_generator
  file_path: env/lib/python3.13/site-packages/google/genai/models.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def async_generator(model, contents, config):'
- rank: 1900
  id: google.genai.models.AsyncModels.async_generator
  name: async_generator
  file_path: env/lib/python3.13/site-packages/google/genai/models.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def async_generator(model, contents, config):'
- rank: 1901
  id: google.genai.models.AsyncModels.compute_tokens
  name: compute_tokens
  file_path: env/lib/python3.13/site-packages/google/genai/models.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Given a list of contents, returns a corresponding TokensInfo containing the\n\nlist of tokens and list of token ids.\n\nArgs:\n  model (str): The model to use.\n  contents (list[shared.Content]): The content to compute tokens for.\n\nUsage:\n\n.. code-block:: python\n\n  response = await client.aio.models.compute_tokens(\n      model='gemini-2.0-flash',\n      contents='What is your name?',\n  )\n  print(response)\n  # tokens_info=[TokensInfo(role='user', token_ids=['1841', ...],\n  # tokens=[b'What', b' is', b' your', b' name', b'?'])]"
  signature: 'def compute_tokens(self, *, model: str, contents: typing.Union[google.genai.types.ContentListUnion, google.genai.types.ContentListUnionDict], config: typing.Optional[google.genai.types.ComputeTokensConfigOrDict]=None) -> google.genai.types.ComputeTokensResponse:'
- rank: 1902
  id: google.genai.models.AsyncModels.count_tokens
  name: count_tokens
  file_path: env/lib/python3.13/site-packages/google/genai/models.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Counts the number of tokens in the given content.\n\nMultimodal input is supported for Gemini models.\n\nArgs:\n  model (str): The model to use for counting tokens.\n  contents (list[types.Content]): The content to count tokens for.\n  config (CountTokensConfig): The configuration for counting tokens.\n\nUsage:\n\n.. code-block:: python\n\n  response = await client.aio.models.count_tokens(\n      model='gemini-2.0-flash',\n      contents='What is your name?',\n  )\n  print(response)\n  # total_tokens=5 cached_content_token_count=None"
  signature: 'def count_tokens(self, *, model: str, contents: typing.Union[google.genai.types.ContentListUnion, google.genai.types.ContentListUnionDict], config: typing.Optional[google.genai.types.CountTokensConfigOrDict]=None) -> google.genai.types.CountTokensResponse:'
- rank: 1903
  id: google.genai.models.AsyncModels.delete
  name: delete
  file_path: env/lib/python3.13/site-packages/google/genai/models.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def delete(self, *, model: str, config: typing.Optional[google.genai.types.DeleteModelConfigOrDict]=None) -> google.genai.types.DeleteModelResponse:'
- rank: 1904
  id: google.genai.models.AsyncModels.edit_image
  name: edit_image
  file_path: env/lib/python3.13/site-packages/google/genai/models.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Edits an image based on a text description and configuration.\n\nArgs:\n  model (str): The model to use.\n  prompt (str): A text description of the edit to apply to the image.\n    reference_images (list[Union[RawReferenceImage, MaskReferenceImage,\n    ControlReferenceImage, StyleReferenceImage, SubjectReferenceImage]): The\n    reference images for editing.\n  config (EditImageConfig): Configuration for editing.\n\nUsage:\n\n.. code-block:: python\n\n  from google.genai.types import RawReferenceImage, MaskReferenceImage\n\n  raw_ref_image = RawReferenceImage(\n    reference_id=1,\n    reference_image=types.Image.from_file(IMAGE_FILE_PATH),\n  )\n\n  mask_ref_image = MaskReferenceImage(\n    reference_id=2,\n    config=types.MaskReferenceConfig(\n        mask_mode='MASK_MODE_FOREGROUND',\n        mask_dilation=0.06,\n    ),\n  )\n  response = await client.aio.models.edit_image(\n    model='imagen-3.0-capability-001',\n    prompt='man with dog',\n    reference_images=[raw_ref_image,\
    \ mask_ref_image],\n    config=types.EditImageConfig(\n        edit_mode= \"EDIT_MODE_INPAINT_INSERTION\",\n        number_of_images= 1,\n        include_rai_reason= True,\n    )\n  )\n  response.generated_images[0].image.show()\n  # Shows a man with a dog instead of a cat."
  signature: 'def edit_image(self, *, model: str, prompt: str, reference_images: list[google.genai.types._ReferenceImageAPIOrDict], config: typing.Optional[google.genai.types.EditImageConfigOrDict]=None) -> google.genai.types.EditImageResponse:'
- rank: 1905
  id: google.genai.models.AsyncModels.embed_content
  name: embed_content
  file_path: env/lib/python3.13/site-packages/google/genai/models.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Calculates embeddings for the given contents. Only text is supported.\n\nArgs:\n  model (str): The model to use.\n  contents (list[Content]): The contents to embed.\n  config (EmbedContentConfig): Optional configuration for embeddings.\n\nUsage:\n\n.. code-block:: python\n\n  embeddings = await client.aio.models.embed_content(\n      model= 'text-embedding-004',\n      contents=[\n          'What is your name?',\n          'What is your favorite color?',\n      ],\n      config={\n          'output_dimensionality': 64\n      },\n  )"
  signature: 'def embed_content(self, *, model: str, contents: typing.Union[google.genai.types.ContentListUnion, google.genai.types.ContentListUnionDict], config: typing.Optional[google.genai.types.EmbedContentConfigOrDict]=None) -> google.genai.types.EmbedContentResponse:'
- rank: 1906
  id: google.genai.models.AsyncModels.generate_content
  name: generate_content
  file_path: env/lib/python3.13/site-packages/google/genai/models.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Makes an API request to generate content using a model.\n\nSome models support multimodal input and output.\n\nBuilt-in MCP support is an experimental feature.\n\nUsage:\n\n.. code-block:: python\n\n  from google.genai import types\n  from google import genai\n\n  client = genai.Client(\n      vertexai=True, project='my-project-id', location='us-central1'\n  )\n\n  response = await client.aio.models.generate_content(\n      model='gemini-2.0-flash',\n      contents='User input: I like bagels. Answer:',\n      config=types.GenerateContentConfig(\n          system_instruction=\n            [\n              'You are a helpful language translator.',\n              'Your mission is to translate text in English to French.'\n            ]\n      ),\n  )\n  print(response.text)\n  # J'aime les bagels."
  signature: 'def generate_content(self, *, model: str, contents: typing.Union[google.genai.types.ContentListUnion, google.genai.types.ContentListUnionDict], config: typing.Optional[google.genai.types.GenerateContentConfigOrDict]=None) -> google.genai.types.GenerateContentResponse:'
- rank: 1907
  id: google.genai.models.AsyncModels.generate_content_stream
  name: generate_content_stream
  file_path: env/lib/python3.13/site-packages/google/genai/models.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Makes an API request to generate content using a model and yields the model's response in chunks.\n\nFor the `model` parameter, supported formats for Vertex AI API include:\n- The Gemini model ID, for example: 'gemini-2.0-flash'\n- The full resource name starts with 'projects/', for example:\n  'projects/my-project-id/locations/us-central1/publishers/google/models/gemini-2.0-flash'\n- The partial resource name with 'publishers/', for example:\n  'publishers/google/models/gemini-2.0-flash' or\n- `/` separated publisher and model name, for example:\n  'google/gemini-2.0-flash'\n\nFor the `model` parameter, supported formats for Gemini API include:\n- The Gemini model ID, for example: 'gemini-2.0-flash'\n- The model name starts with 'models/', for example:\n  'models/gemini-2.0-flash'\n- For tuned models, the model name starts with 'tunedModels/',\n  for example:\n  'tunedModels/1234567890123456789'\n\nSome models support multimodal input and output.\n\nBuilt-in MCP support is\
    \ an experimental feature.\n\nUsage:\n\n.. code-block:: python\n\n  from google.genai import types\n  from google import genai\n\n  client = genai.Client(\n      vertexai=True, project='my-project-id', location='us-central1'\n  )\n\n  async for chunk in await client.aio.models.generate_content_stream(\n    model='gemini-2.0-flash',\n    contents='''What is a good name for a flower shop that specializes in\n      selling bouquets of dried flowers?'''\n  ):\n    print(chunk.text)\n  # **Elegant & Classic:**\n  # * The Dried Bloom\n  # * Everlasting Florals\n  # * Timeless Petals\n\n  async for chunk in await client.aio.models.generate_content_stream(\n    model='gemini-2.0-flash',\n    contents=[\n      types.Part.from_text('What is shown in this image?'),\n      types.Part.from_uri('gs://generativeai-downloads/images/scones.jpg',\n      'image/jpeg')\n    ]\n  ):\n    print(chunk.text)\n  # The image shows a flat lay arrangement of freshly baked blueberry\n  # scones."
  signature: 'def generate_content_stream(self, *, model: str, contents: typing.Union[google.genai.types.ContentListUnion, google.genai.types.ContentListUnionDict], config: typing.Optional[google.genai.types.GenerateContentConfigOrDict]=None) -> typing.AsyncIterator[google.genai.types.GenerateContentResponse]:'
- rank: 1908
  id: google.genai.models.AsyncModels.generate_images
  name: generate_images
  file_path: env/lib/python3.13/site-packages/google/genai/models.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Generates images based on a text description and configuration.\n\nArgs:\n  model (str): The model to use.\n  prompt (str): A text description of the images to generate.\n  config (GenerateImagesConfig): Configuration for generation.\n\nUsage:\n\n.. code-block:: python\n\n  response = await client.aio.models.generate_images(\n    model='imagen-3.0-generate-002',\n    prompt='Man with a dog',\n    config=types.GenerateImagesConfig(\n        number_of_images= 1,\n        include_rai_reason= True,\n    )\n  )\n  response.generated_images[0].image.show()\n  # Shows a man with a dog."
  signature: 'def generate_images(self, *, model: str, prompt: str, config: typing.Optional[google.genai.types.GenerateImagesConfigOrDict]=None) -> google.genai.types.GenerateImagesResponse:'
- rank: 1909
  id: google.genai.models.AsyncModels.generate_videos
  name: generate_videos
  file_path: env/lib/python3.13/site-packages/google/genai/models.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Generates videos based on an input (text, image, or video) and configuration.\n\nThe following use cases are supported:\n1. Text to video generation.\n2a. Image to video generation (additional text prompt is optional).\n2b. Image to video generation with frame interpolation (specify last_frame\nin config).\n3. Video extension (additional text prompt is optional)\n\nArgs:\n  model: The model to use.\n  prompt: The text prompt for generating the videos. Optional for image to\n    video and video extension use cases. This argument is deprecated, please\n    use source instead.\n  image: The input image for generating the videos. Optional if prompt is\n    provided. This argument is deprecated, please use source instead.\n  video: The input video for video extension use cases. Optional if prompt\n    or image is provided. This argument is deprecated, please use source\n    instead.\n  source: The input source for generating the videos (prompt, image, and/or\n    video)\n  config:\
    \ Configuration for generation.\n\nUsage:\n\n  ```\n  operation = client.models.generate_videos(\n      model=\"veo-2.0-generate-001\",\n      source=types.GenerateVideosSource(\n          prompt=\"A neon hologram of a cat driving at top speed\",\n      ),\n  )\n  while not operation.done:\n      time.sleep(10)\n      operation = client.operations.get(operation)\n\n  operation.result.generated_videos[0].video.uri\n  ```"
  signature: 'def generate_videos(self, *, model: str, prompt: typing.Optional[str]=None, image: typing.Optional[google.genai.types.ImageOrDict]=None, video: typing.Optional[google.genai.types.VideoOrDict]=None, source: typing.Optional[google.genai.types.GenerateVideosSourceOrDict]=None, config: typing.Optional[google.genai.types.GenerateVideosConfigOrDict]=None) -> google.genai.types.GenerateVideosOperation:'
- rank: 1910
  id: google.genai.models.AsyncModels.get
  name: get
  file_path: env/lib/python3.13/site-packages/google/genai/models.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def get(self, *, model: str, config: typing.Optional[google.genai.types.GetModelConfigOrDict]=None) -> google.genai.types.Model:'
- rank: 1911
  id: google.genai.models.AsyncModels.list
  name: list
  file_path: env/lib/python3.13/site-packages/google/genai/models.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Makes an API request to list the available models.\n\nIf `query_base` is set to True in the config or not set (default), the\nAPI will return all available base models. If set to False, it will return\nall tuned models.\n\nArgs:\n  config (ListModelsConfigOrDict): Configuration for retrieving models.\n\nUsage:\n\n.. code-block:: python\n\n  response = await client.aio.models.list(config={'page_size': 5})\n  print(response.page)\n  # [Model(name='projects/./locations/./models/123', display_name='my_model'\n\n  response = await client.aio.models.list(\n      config={'page_size': 5, 'query_base': True}\n    )\n  print(response.page)\n  # [Model(name='publishers/google/models/gemini-2.0-flash-exp' ..."
  signature: 'def list(self, *, config: typing.Optional[google.genai.types.ListModelsConfigOrDict]=None) -> google.genai.pagers.AsyncPager[google.genai.types.Model]:'
- rank: 1912
  id: google.genai.models.AsyncModels.recontext_image
  name: recontext_image
  file_path: env/lib/python3.13/site-packages/google/genai/models.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Recontextualizes an image.\n\nThere are two types of recontextualization currently supported:\n1) Imagen Product Recontext - Generate images of products in new scenes\n   and contexts.\n2) Virtual Try-On: Generate images of persons modeling fashion products.\n\nArgs:\n  model (str): The model to use.\n  source (RecontextImageSource): An object containing the source inputs\n    (prompt, person_image, product_images) for image recontext. prompt is\n    optional for product recontext and disallowed for virtual try-on.\n    person_image is required for virtual try-on, disallowed for product\n    recontext. product_images is required for both product recontext and\n    virtual try-on. Only one product image is supported for virtual try-on,\n    and up to 3 product images (different angles of the same product) are\n    supported for product recontext.\n  config (RecontextImageConfig): Configuration for recontextualization.\n\nUsage:\n\n  ```\n  product_recontext_response = client.models.recontext_image(\n\
    \      model=\"imagen-product-recontext-preview-06-30\",\n      source=types.RecontextImageSource(\n          prompt=\"In a modern kitchen setting.\",\n          product_images=[types.ProductImage.from_file(IMAGE_FILE_PATH)],\n      ),\n      config=types.RecontextImageConfig(\n          number_of_images=1,\n      ),\n  )\n  image = product_recontext_response.generated_images[0].image\n\n  virtual_try_on_response = client.models.recontext_image(\n      model=\"virtual-try-on-preview-08-04\",\n      source=types.RecontextImageSource(\n          person_image=types.Image.from_file(IMAGE1_FILE_PATH),\n          product_images=[types.ProductImage.from_file(IMAGE2_FILE_PATH)],\n      ),\n      config=types.RecontextImageConfig(\n          number_of_images=1,\n      ),\n  )\n  image = virtual_try_on_response.generated_images[0].image\n  ```"
  signature: 'def recontext_image(self, *, model: str, source: google.genai.types.RecontextImageSourceOrDict, config: typing.Optional[google.genai.types.RecontextImageConfigOrDict]=None) -> google.genai.types.RecontextImageResponse:'
- rank: 1913
  id: google.genai.models.AsyncModels.segment_image
  name: segment_image
  file_path: env/lib/python3.13/site-packages/google/genai/models.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Segments an image, creating a mask of a specified area.\n\nArgs:\n  model (str): The model to use.\n  source (SegmentImageSource): An object containing the source inputs\n    (prompt, image, scribble_image) for image segmentation. The prompt is\n    required for prompt mode and semantic mode, disallowed for other modes.\n    scribble_image is required for the interactive mode, disallowed for\n    other modes.\n  config (SegmentImageConfig): Configuration for segmentation.\n\nUsage:\n\n  ```\n  response = client.models.segment_image(\n      model=\"image-segmentation-001\",\n      source=types.SegmentImageSource(\n          image=types.Image.from_file(IMAGE_FILE_PATH),\n      ),\n      config=types.SegmentImageConfig(\n          mode=types.SegmentMode.foreground,\n      ),\n  )\n\n  mask_image = response.generated_masks[0].mask\n  ```"
  signature: 'def segment_image(self, *, model: str, source: google.genai.types.SegmentImageSourceOrDict, config: typing.Optional[google.genai.types.SegmentImageConfigOrDict]=None) -> google.genai.types.SegmentImageResponse:'
- rank: 1914
  id: google.genai.models.AsyncModels.update
  name: update
  file_path: env/lib/python3.13/site-packages/google/genai/models.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def update(self, *, model: str, config: typing.Optional[google.genai.types.UpdateModelConfigOrDict]=None) -> google.genai.types.Model:'
- rank: 1915
  id: google.genai.models.AsyncModels.upscale_image
  name: upscale_image
  file_path: env/lib/python3.13/site-packages/google/genai/models.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Makes an API request to upscale a provided image.\n\nArgs:\n  model (str): The model to use.\n  image (Image): The input image for upscaling.\n  upscale_factor (str): The factor to upscale the image (x2 or x4).\n  config (UpscaleImageConfig): Configuration for upscaling.\n\nUsage:\n\n.. code-block:: python\n\n  from google.genai.types import Image\n\n  IMAGE_FILE_PATH=\"my-image.png\"\n  response = await client.aio.models.upscale_image(\n      model='imagen-3.0-generate-001',\n      image=types.Image.from_file(IMAGE_FILE_PATH),\n      upscale_factor='x2',\n  )\n  response.generated_images[0].image.show()\n  # Opens my-image.png which is upscaled by a factor of 2."
  signature: 'def upscale_image(self, *, model: str, image: google.genai.types.ImageOrDict, upscale_factor: str, config: typing.Optional[google.genai.types.UpscaleImageConfigOrDict]=None) -> google.genai.types.UpscaleImageResponse:'
- rank: 1916
  id: google.genai.models.Models
  name: Models
  file_path: env/lib/python3.13/site-packages/google/genai/models.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: '[Note: Inherited members from _api_module.BaseModule are omitted.]'
  methods:
  - signature: 'def embed_content(self, *, model: str, contents: typing.Union[google.genai.types.ContentListUnion, google.genai.types.ContentListUnionDict], config: typing.Optional[google.genai.types.EmbedContentConfigOrDict]=None) -> google.genai.types.EmbedContentResponse:'
    docstring: "Calculates embeddings for the given contents. Only text is supported.\n\nArgs:\n  model (str): The model to use.\n  contents (list[Content]): The contents to embed.\n  config (EmbedContentConfig): Optional configuration for embeddings.\n\nUsage:\n\n.. code-block:: python\n\n  embeddings = client.models.embed_content(\n      model= 'text-embedding-004',\n      contents=[\n          'What is your name?',\n          'What is your favorite color?',\n      ],\n      config={\n          'output_dimensionality': 64\n      },\n  )"
  - signature: 'def recontext_image(self, *, model: str, source: google.genai.types.RecontextImageSourceOrDict, config: typing.Optional[google.genai.types.RecontextImageConfigOrDict]=None) -> google.genai.types.RecontextImageResponse:'
    docstring: "Recontextualizes an image.\n\nThere are two types of recontextualization currently supported:\n1) Imagen Product Recontext - Generate images of products in new scenes\n   and contexts.\n2) Virtual Try-On: Generate images of persons modeling fashion products.\n\nArgs:\n  model (str): The model to use.\n  source (RecontextImageSource): An object containing the source inputs\n    (prompt, person_image, product_images) for image recontext. prompt is\n    optional for product recontext and disallowed for virtual try-on.\n    person_image is required for virtual try-on, disallowed for product\n    recontext. product_images is required for both product recontext and\n    virtual try-on. Only one product image is supported for virtual try-on,\n    and up to 3 product images (different angles of the same product) are\n    supported for product recontext.\n  config (RecontextImageConfig): Configuration for recontextualization.\n\nUsage:\n\n  ```\n  product_recontext_response = client.models.recontext_image(\n\
      \      model=\"imagen-product-recontext-preview-06-30\",\n      source=types.RecontextImageSource(\n          prompt=\"In a modern kitchen setting.\",\n          product_images=[types.ProductImage.from_file(IMAGE_FILE_PATH)],\n      ),\n      config=types.RecontextImageConfig(\n          number_of_images=1,\n      ),\n  )\n  image = product_recontext_response.generated_images[0].image\n\n  virtual_try_on_response = client.models.recontext_image(\n      model=\"virtual-try-on-preview-08-04\",\n      source=types.RecontextImageSource(\n          person_image=types.Image.from_file(IMAGE1_FILE_PATH),\n          product_images=[types.ProductImage.from_file(IMAGE2_FILE_PATH)],\n      ),\n      config=types.RecontextImageConfig(\n          number_of_images=1,\n      ),\n  )\n  image = virtual_try_on_response.generated_images[0].image\n  ```"
  - signature: 'def segment_image(self, *, model: str, source: google.genai.types.SegmentImageSourceOrDict, config: typing.Optional[google.genai.types.SegmentImageConfigOrDict]=None) -> google.genai.types.SegmentImageResponse:'
    docstring: "Segments an image, creating a mask of a specified area.\n\nArgs:\n  model (str): The model to use.\n  source (SegmentImageSource): An object containing the source inputs\n    (prompt, image, scribble_image) for image segmentation. The prompt is\n    required for prompt mode and semantic mode, disallowed for other modes.\n    scribble_image is required for the interactive mode, disallowed for\n    other modes.\n  config (SegmentImageConfig): Configuration for segmentation.\n\nUsage:\n\n  ```\n  response = client.models.segment_image(\n      model=\"image-segmentation-001\",\n      source=types.SegmentImageSource(\n          image=types.Image.from_file(IMAGE_FILE_PATH),\n      ),\n  )\n\n  mask_image = response.generated_masks[0].mask\n  ```"
  - signature: 'def get(self, *, model: str, config: typing.Optional[google.genai.types.GetModelConfigOrDict]=None) -> google.genai.types.Model:'
  - signature: 'def update(self, *, model: str, config: typing.Optional[google.genai.types.UpdateModelConfigOrDict]=None) -> google.genai.types.Model:'
  - signature: 'def delete(self, *, model: str, config: typing.Optional[google.genai.types.DeleteModelConfigOrDict]=None) -> google.genai.types.DeleteModelResponse:'
  - signature: 'def count_tokens(self, *, model: str, contents: typing.Union[google.genai.types.ContentListUnion, google.genai.types.ContentListUnionDict], config: typing.Optional[google.genai.types.CountTokensConfigOrDict]=None) -> google.genai.types.CountTokensResponse:'
    docstring: "Counts the number of tokens in the given content.\n\nMultimodal input is supported for Gemini models.\n\nArgs:\n  model (str): The model to use for counting tokens.\n  contents (list[types.Content]): The content to count tokens for.\n  config (CountTokensConfig): The configuration for counting tokens.\n\nUsage:\n\n.. code-block:: python\n\n  response = client.models.count_tokens(\n      model='gemini-2.0-flash',\n      contents='What is your name?',\n  )\n  print(response)\n  # total_tokens=5 cached_content_token_count=None"
  - signature: 'def compute_tokens(self, *, model: str, contents: typing.Union[google.genai.types.ContentListUnion, google.genai.types.ContentListUnionDict], config: typing.Optional[google.genai.types.ComputeTokensConfigOrDict]=None) -> google.genai.types.ComputeTokensResponse:'
    docstring: "Given a list of contents, returns a corresponding TokensInfo containing the\n\nlist of tokens and list of token ids.\n\nThis method is not supported by the Gemini Developer API.\n\nArgs:\n  model (str): The model to use.\n  contents (list[shared.Content]): The content to compute tokens for.\n\nUsage:\n\n.. code-block:: python\n\n  response = client.models.compute_tokens(\n      model='gemini-2.0-flash',\n      contents='What is your name?',\n  )\n  print(response)\n  # tokens_info=[TokensInfo(role='user', token_ids=['1841', ...],\n  # tokens=[b'What', b' is', b' your', b' name', b'?'])]"
  - signature: 'def generate_content(self, *, model: str, contents: google.genai.types.ContentListUnionDict, config: typing.Optional[google.genai.types.GenerateContentConfigOrDict]=None) -> google.genai.types.GenerateContentResponse:'
    docstring: "Makes an API request to generate content using a model.\n\nFor the `model` parameter, supported formats for Vertex AI API include:\n- The Gemini model ID, for example: 'gemini-2.0-flash'\n- The full resource name starts with 'projects/', for example:\n  'projects/my-project-id/locations/us-central1/publishers/google/models/gemini-2.0-flash'\n- The partial resource name with 'publishers/', for example:\n  'publishers/google/models/gemini-2.0-flash' or\n- `/` separated publisher and model name, for example:\n  'google/gemini-2.0-flash'\n\nFor the `model` parameter, supported formats for Gemini API include:\n- The Gemini model ID, for example: 'gemini-2.0-flash'\n- The model name starts with 'models/', for example:\n  'models/gemini-2.0-flash'\n- For tuned models, the model name starts with 'tunedModels/',\n  for example:\n  'tunedModels/1234567890123456789'\n\nSome models support multimodal input and output.\n\nBuilt-in MCP support is an experimental feature.\n\nUsage:\n\n\
      .. code-block:: python\n\n  from google.genai import types\n  from google import genai\n\n  client = genai.Client(\n      vertexai=True, project='my-project-id', location='us-central1'\n  )\n\n  response = client.models.generate_content(\n    model='gemini-2.0-flash',\n    contents='''What is a good name for a flower shop that specializes in\n      selling bouquets of dried flowers?'''\n  )\n  print(response.text)\n  # **Elegant & Classic:**\n  # * The Dried Bloom\n  # * Everlasting Florals\n  # * Timeless Petals\n\n  response = client.models.generate_content(\n    model='gemini-2.0-flash',\n    contents=[\n      types.Part.from_text(text='What is shown in this image?'),\n      types.Part.from_uri(file_uri='gs://generativeai-downloads/images/scones.jpg',\n      mime_type='image/jpeg')\n    ]\n  )\n  print(response.text)\n  # The image shows a flat lay arrangement of freshly baked blueberry\n  # scones."
  - signature: 'def generate_content_stream(self, *, model: str, contents: google.genai.types.ContentListUnionDict, config: typing.Optional[google.genai.types.GenerateContentConfigOrDict]=None) -> typing.Iterator[google.genai.types.GenerateContentResponse]:'
    docstring: "Makes an API request to generate content using a model and yields the model's response in chunks.\n\nFor the `model` parameter, supported formats for Vertex AI API include:\n- The Gemini model ID, for example: 'gemini-2.0-flash'\n- The full resource name starts with 'projects/', for example:\n  'projects/my-project-id/locations/us-central1/publishers/google/models/gemini-2.0-flash'\n- The partial resource name with 'publishers/', for example:\n  'publishers/google/models/gemini-2.0-flash' or\n- `/` separated publisher and model name, for example:\n  'google/gemini-2.0-flash'\n\nFor the `model` parameter, supported formats for Gemini API include:\n- The Gemini model ID, for example: 'gemini-2.0-flash'\n- The model name starts with 'models/', for example:\n  'models/gemini-2.0-flash'\n- For tuned models, the model name starts with 'tunedModels/',\n  for example:\n  'tunedModels/1234567890123456789'\n\nSome models support multimodal input and output.\n\nBuilt-in MCP support\
      \ is an experimental feature.\n\nUsage:\n\n.. code-block:: python\n\n  from google.genai import types\n  from google import genai\n\n  client = genai.Client(\n      vertexai=True, project='my-project-id', location='us-central1'\n  )\n\n  for chunk in client.models.generate_content_stream(\n    model='gemini-2.0-flash',\n    contents='''What is a good name for a flower shop that specializes in\n      selling bouquets of dried flowers?'''\n  ):\n    print(chunk.text)\n  # **Elegant & Classic:**\n  # * The Dried Bloom\n  # * Everlasting Florals\n  # * Timeless Petals\n\n  for chunk in client.models.generate_content_stream(\n    model='gemini-2.0-flash',\n    contents=[\n      types.Part.from_text('What is shown in this image?'),\n      types.Part.from_uri('gs://generativeai-downloads/images/scones.jpg',\n      'image/jpeg')\n    ]\n  ):\n    print(chunk.text)\n  # The image shows a flat lay arrangement of freshly baked blueberry\n  # scones."
  - signature: 'def generate_images(self, *, model: str, prompt: str, config: typing.Optional[google.genai.types.GenerateImagesConfigOrDict]=None) -> google.genai.types.GenerateImagesResponse:'
    docstring: "Generates images based on a text description and configuration.\n\nArgs:\n  model (str): The model to use.\n  prompt (str): A text description of the images to generate.\n  config (GenerateImagesConfig): Configuration for generation.\n\nUsage:\n\n.. code-block:: python\n\n  response = client.models.generate_images(\n    model='imagen-3.0-generate-002',\n    prompt='Man with a dog',\n    config=types.GenerateImagesConfig(\n        number_of_images= 1,\n        include_rai_reason= True,\n    )\n  )\n  response.generated_images[0].image.show()\n  # Shows a man with a dog."
  - signature: 'def edit_image(self, *, model: str, prompt: str, reference_images: list[google.genai.types._ReferenceImageAPIOrDict], config: typing.Optional[google.genai.types.EditImageConfigOrDict]=None) -> google.genai.types.EditImageResponse:'
    docstring: "Edits an image based on a text description and configuration.\n\nArgs:\n  model (str): The model to use.\n  prompt (str): A text description of the edit to apply to the image.\n    reference_images (list[Union[RawReferenceImage, MaskReferenceImage,\n    ControlReferenceImage, StyleReferenceImage, SubjectReferenceImage]): The\n    reference images for editing.\n  config (EditImageConfig): Configuration for editing.\n\nUsage:\n\n.. code-block:: python\n\n  from google.genai.types import RawReferenceImage, MaskReferenceImage\n\n  raw_ref_image = RawReferenceImage(\n    reference_id=1,\n    reference_image=types.Image.from_file(IMAGE_FILE_PATH),\n  )\n\n  mask_ref_image = MaskReferenceImage(\n    reference_id=2,\n    config=types.MaskReferenceConfig(\n        mask_mode='MASK_MODE_FOREGROUND',\n        mask_dilation=0.06,\n    ),\n  )\n  response = client.models.edit_image(\n    model='imagen-3.0-capability-001',\n    prompt='man with dog',\n    reference_images=[raw_ref_image,\
      \ mask_ref_image],\n    config=types.EditImageConfig(\n        edit_mode= \"EDIT_MODE_INPAINT_INSERTION\",\n        number_of_images= 1,\n        include_rai_reason= True,\n    )\n  )\n  response.generated_images[0].image.show()\n  # Shows a man with a dog instead of a cat."
  - signature: 'def upscale_image(self, *, model: str, image: google.genai.types.ImageOrDict, upscale_factor: str, config: typing.Optional[google.genai.types.UpscaleImageConfigOrDict]=None) -> google.genai.types.UpscaleImageResponse:'
    docstring: "Makes an API request to upscale a provided image.\n\nArgs:\n  model (str): The model to use.\n  image (Image): The input image for upscaling.\n  upscale_factor (str): The factor to upscale the image (x2 or x4).\n  config (UpscaleImageConfig): Configuration for upscaling.\n\nUsage:\n\n.. code-block:: python\n\n  from google.genai.types import Image\n\n  IMAGE_FILE_PATH=\"my-image.png\"\n  response=client.models.upscale_image(\n      model='imagen-3.0-generate-001',\n      image=types.Image.from_file(IMAGE_FILE_PATH),\n      upscale_factor='x2',\n  )\n  response.generated_images[0].image.show()\n  # Opens my-image.png which is upscaled by a factor of 2."
  - signature: 'def generate_videos(self, *, model: str, prompt: typing.Optional[str]=None, image: typing.Optional[google.genai.types.ImageOrDict]=None, video: typing.Optional[google.genai.types.VideoOrDict]=None, source: typing.Optional[google.genai.types.GenerateVideosSourceOrDict]=None, config: typing.Optional[google.genai.types.GenerateVideosConfigOrDict]=None) -> google.genai.types.GenerateVideosOperation:'
    docstring: "Generates videos based on an input (text, image, or video) and configuration.\n\nThe following use cases are supported:\n1. Text to video generation.\n2a. Image to video generation (additional text prompt is optional).\n2b. Image to video generation with frame interpolation (specify last_frame\nin config).\n3. Video extension (additional text prompt is optional)\n\nArgs:\n  model: The model to use.\n  prompt: The text prompt for generating the videos. Optional for image to\n    video and video extension use cases. This argument is deprecated, please\n    use source instead.\n  image: The input image for generating the videos. Optional if prompt is\n    provided. This argument is deprecated, please use source instead.\n  video: The input video for video extension use cases. Optional if prompt\n    or image is provided. This argument is deprecated, please use source\n    instead.\n  source: The input source for generating the videos (prompt, image, and/or\n    video)\n  config:\
      \ Configuration for generation.\n\nUsage:\n\n  ```\n  operation = client.models.generate_videos(\n      model=\"veo-2.0-generate-001\",\n      source=types.GenerateVideosSource(\n          prompt=\"A neon hologram of a cat driving at top speed\",\n      ),\n  )\n  while not operation.done:\n      time.sleep(10)\n      operation = client.operations.get(operation)\n\n  operation.result.generated_videos[0].video.uri\n  ```"
  - signature: 'def list(self, *, config: typing.Optional[google.genai.types.ListModelsConfigOrDict]=None) -> google.genai.pagers.Pager[google.genai.types.Model]:'
    docstring: "Makes an API request to list the available models.\n\nIf `query_base` is set to True in the config or not set (default), the\nAPI will return all available base models. If set to False, it will return\nall tuned models.\n\nArgs:\n  config (ListModelsConfigOrDict): Configuration for retrieving models.\n\nUsage:\n\n.. code-block:: python\n\n  response=client.models.list(config={'page_size': 5})\n  print(response.page)\n  # [Model(name='projects/./locations/./models/123', display_name='my_model'\n\n  response=client.models.list(config={'page_size': 5, 'query_base': True})\n  print(response.page)\n  # [Model(name='publishers/google/models/gemini-2.0-flash-exp' ..."
  omitted_inherited_members_from:
  - _api_module.BaseModule
- rank: 1917
  id: google.genai.models.Models.compute_tokens
  name: compute_tokens
  file_path: env/lib/python3.13/site-packages/google/genai/models.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Given a list of contents, returns a corresponding TokensInfo containing the\n\nlist of tokens and list of token ids.\n\nThis method is not supported by the Gemini Developer API.\n\nArgs:\n  model (str): The model to use.\n  contents (list[shared.Content]): The content to compute tokens for.\n\nUsage:\n\n.. code-block:: python\n\n  response = client.models.compute_tokens(\n      model='gemini-2.0-flash',\n      contents='What is your name?',\n  )\n  print(response)\n  # tokens_info=[TokensInfo(role='user', token_ids=['1841', ...],\n  # tokens=[b'What', b' is', b' your', b' name', b'?'])]"
  signature: 'def compute_tokens(self, *, model: str, contents: typing.Union[google.genai.types.ContentListUnion, google.genai.types.ContentListUnionDict], config: typing.Optional[google.genai.types.ComputeTokensConfigOrDict]=None) -> google.genai.types.ComputeTokensResponse:'
- rank: 1918
  id: google.genai.models.Models.count_tokens
  name: count_tokens
  file_path: env/lib/python3.13/site-packages/google/genai/models.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Counts the number of tokens in the given content.\n\nMultimodal input is supported for Gemini models.\n\nArgs:\n  model (str): The model to use for counting tokens.\n  contents (list[types.Content]): The content to count tokens for.\n  config (CountTokensConfig): The configuration for counting tokens.\n\nUsage:\n\n.. code-block:: python\n\n  response = client.models.count_tokens(\n      model='gemini-2.0-flash',\n      contents='What is your name?',\n  )\n  print(response)\n  # total_tokens=5 cached_content_token_count=None"
  signature: 'def count_tokens(self, *, model: str, contents: typing.Union[google.genai.types.ContentListUnion, google.genai.types.ContentListUnionDict], config: typing.Optional[google.genai.types.CountTokensConfigOrDict]=None) -> google.genai.types.CountTokensResponse:'
- rank: 1919
  id: google.genai.models.Models.delete
  name: delete
  file_path: env/lib/python3.13/site-packages/google/genai/models.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def delete(self, *, model: str, config: typing.Optional[google.genai.types.DeleteModelConfigOrDict]=None) -> google.genai.types.DeleteModelResponse:'
- rank: 1920
  id: google.genai.models.Models.edit_image
  name: edit_image
  file_path: env/lib/python3.13/site-packages/google/genai/models.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Edits an image based on a text description and configuration.\n\nArgs:\n  model (str): The model to use.\n  prompt (str): A text description of the edit to apply to the image.\n    reference_images (list[Union[RawReferenceImage, MaskReferenceImage,\n    ControlReferenceImage, StyleReferenceImage, SubjectReferenceImage]): The\n    reference images for editing.\n  config (EditImageConfig): Configuration for editing.\n\nUsage:\n\n.. code-block:: python\n\n  from google.genai.types import RawReferenceImage, MaskReferenceImage\n\n  raw_ref_image = RawReferenceImage(\n    reference_id=1,\n    reference_image=types.Image.from_file(IMAGE_FILE_PATH),\n  )\n\n  mask_ref_image = MaskReferenceImage(\n    reference_id=2,\n    config=types.MaskReferenceConfig(\n        mask_mode='MASK_MODE_FOREGROUND',\n        mask_dilation=0.06,\n    ),\n  )\n  response = client.models.edit_image(\n    model='imagen-3.0-capability-001',\n    prompt='man with dog',\n    reference_images=[raw_ref_image,\
    \ mask_ref_image],\n    config=types.EditImageConfig(\n        edit_mode= \"EDIT_MODE_INPAINT_INSERTION\",\n        number_of_images= 1,\n        include_rai_reason= True,\n    )\n  )\n  response.generated_images[0].image.show()\n  # Shows a man with a dog instead of a cat."
  signature: 'def edit_image(self, *, model: str, prompt: str, reference_images: list[google.genai.types._ReferenceImageAPIOrDict], config: typing.Optional[google.genai.types.EditImageConfigOrDict]=None) -> google.genai.types.EditImageResponse:'
- rank: 1921
  id: google.genai.models.Models.embed_content
  name: embed_content
  file_path: env/lib/python3.13/site-packages/google/genai/models.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Calculates embeddings for the given contents. Only text is supported.\n\nArgs:\n  model (str): The model to use.\n  contents (list[Content]): The contents to embed.\n  config (EmbedContentConfig): Optional configuration for embeddings.\n\nUsage:\n\n.. code-block:: python\n\n  embeddings = client.models.embed_content(\n      model= 'text-embedding-004',\n      contents=[\n          'What is your name?',\n          'What is your favorite color?',\n      ],\n      config={\n          'output_dimensionality': 64\n      },\n  )"
  signature: 'def embed_content(self, *, model: str, contents: typing.Union[google.genai.types.ContentListUnion, google.genai.types.ContentListUnionDict], config: typing.Optional[google.genai.types.EmbedContentConfigOrDict]=None) -> google.genai.types.EmbedContentResponse:'
- rank: 1922
  id: google.genai.models.Models.generate_content
  name: generate_content
  file_path: env/lib/python3.13/site-packages/google/genai/models.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Makes an API request to generate content using a model.\n\nFor the `model` parameter, supported formats for Vertex AI API include:\n- The Gemini model ID, for example: 'gemini-2.0-flash'\n- The full resource name starts with 'projects/', for example:\n  'projects/my-project-id/locations/us-central1/publishers/google/models/gemini-2.0-flash'\n- The partial resource name with 'publishers/', for example:\n  'publishers/google/models/gemini-2.0-flash' or\n- `/` separated publisher and model name, for example:\n  'google/gemini-2.0-flash'\n\nFor the `model` parameter, supported formats for Gemini API include:\n- The Gemini model ID, for example: 'gemini-2.0-flash'\n- The model name starts with 'models/', for example:\n  'models/gemini-2.0-flash'\n- For tuned models, the model name starts with 'tunedModels/',\n  for example:\n  'tunedModels/1234567890123456789'\n\nSome models support multimodal input and output.\n\nBuilt-in MCP support is an experimental feature.\n\nUsage:\n\n..\
    \ code-block:: python\n\n  from google.genai import types\n  from google import genai\n\n  client = genai.Client(\n      vertexai=True, project='my-project-id', location='us-central1'\n  )\n\n  response = client.models.generate_content(\n    model='gemini-2.0-flash',\n    contents='''What is a good name for a flower shop that specializes in\n      selling bouquets of dried flowers?'''\n  )\n  print(response.text)\n  # **Elegant & Classic:**\n  # * The Dried Bloom\n  # * Everlasting Florals\n  # * Timeless Petals\n\n  response = client.models.generate_content(\n    model='gemini-2.0-flash',\n    contents=[\n      types.Part.from_text(text='What is shown in this image?'),\n      types.Part.from_uri(file_uri='gs://generativeai-downloads/images/scones.jpg',\n      mime_type='image/jpeg')\n    ]\n  )\n  print(response.text)\n  # The image shows a flat lay arrangement of freshly baked blueberry\n  # scones."
  signature: 'def generate_content(self, *, model: str, contents: google.genai.types.ContentListUnionDict, config: typing.Optional[google.genai.types.GenerateContentConfigOrDict]=None) -> google.genai.types.GenerateContentResponse:'
- rank: 1923
  id: google.genai.models.Models.generate_content_stream
  name: generate_content_stream
  file_path: env/lib/python3.13/site-packages/google/genai/models.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Makes an API request to generate content using a model and yields the model's response in chunks.\n\nFor the `model` parameter, supported formats for Vertex AI API include:\n- The Gemini model ID, for example: 'gemini-2.0-flash'\n- The full resource name starts with 'projects/', for example:\n  'projects/my-project-id/locations/us-central1/publishers/google/models/gemini-2.0-flash'\n- The partial resource name with 'publishers/', for example:\n  'publishers/google/models/gemini-2.0-flash' or\n- `/` separated publisher and model name, for example:\n  'google/gemini-2.0-flash'\n\nFor the `model` parameter, supported formats for Gemini API include:\n- The Gemini model ID, for example: 'gemini-2.0-flash'\n- The model name starts with 'models/', for example:\n  'models/gemini-2.0-flash'\n- For tuned models, the model name starts with 'tunedModels/',\n  for example:\n  'tunedModels/1234567890123456789'\n\nSome models support multimodal input and output.\n\nBuilt-in MCP support is\
    \ an experimental feature.\n\nUsage:\n\n.. code-block:: python\n\n  from google.genai import types\n  from google import genai\n\n  client = genai.Client(\n      vertexai=True, project='my-project-id', location='us-central1'\n  )\n\n  for chunk in client.models.generate_content_stream(\n    model='gemini-2.0-flash',\n    contents='''What is a good name for a flower shop that specializes in\n      selling bouquets of dried flowers?'''\n  ):\n    print(chunk.text)\n  # **Elegant & Classic:**\n  # * The Dried Bloom\n  # * Everlasting Florals\n  # * Timeless Petals\n\n  for chunk in client.models.generate_content_stream(\n    model='gemini-2.0-flash',\n    contents=[\n      types.Part.from_text('What is shown in this image?'),\n      types.Part.from_uri('gs://generativeai-downloads/images/scones.jpg',\n      'image/jpeg')\n    ]\n  ):\n    print(chunk.text)\n  # The image shows a flat lay arrangement of freshly baked blueberry\n  # scones."
  signature: 'def generate_content_stream(self, *, model: str, contents: google.genai.types.ContentListUnionDict, config: typing.Optional[google.genai.types.GenerateContentConfigOrDict]=None) -> typing.Iterator[google.genai.types.GenerateContentResponse]:'
- rank: 1924
  id: google.genai.models.Models.generate_images
  name: generate_images
  file_path: env/lib/python3.13/site-packages/google/genai/models.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Generates images based on a text description and configuration.\n\nArgs:\n  model (str): The model to use.\n  prompt (str): A text description of the images to generate.\n  config (GenerateImagesConfig): Configuration for generation.\n\nUsage:\n\n.. code-block:: python\n\n  response = client.models.generate_images(\n    model='imagen-3.0-generate-002',\n    prompt='Man with a dog',\n    config=types.GenerateImagesConfig(\n        number_of_images= 1,\n        include_rai_reason= True,\n    )\n  )\n  response.generated_images[0].image.show()\n  # Shows a man with a dog."
  signature: 'def generate_images(self, *, model: str, prompt: str, config: typing.Optional[google.genai.types.GenerateImagesConfigOrDict]=None) -> google.genai.types.GenerateImagesResponse:'
- rank: 1925
  id: google.genai.models.Models.generate_videos
  name: generate_videos
  file_path: env/lib/python3.13/site-packages/google/genai/models.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Generates videos based on an input (text, image, or video) and configuration.\n\nThe following use cases are supported:\n1. Text to video generation.\n2a. Image to video generation (additional text prompt is optional).\n2b. Image to video generation with frame interpolation (specify last_frame\nin config).\n3. Video extension (additional text prompt is optional)\n\nArgs:\n  model: The model to use.\n  prompt: The text prompt for generating the videos. Optional for image to\n    video and video extension use cases. This argument is deprecated, please\n    use source instead.\n  image: The input image for generating the videos. Optional if prompt is\n    provided. This argument is deprecated, please use source instead.\n  video: The input video for video extension use cases. Optional if prompt\n    or image is provided. This argument is deprecated, please use source\n    instead.\n  source: The input source for generating the videos (prompt, image, and/or\n    video)\n  config:\
    \ Configuration for generation.\n\nUsage:\n\n  ```\n  operation = client.models.generate_videos(\n      model=\"veo-2.0-generate-001\",\n      source=types.GenerateVideosSource(\n          prompt=\"A neon hologram of a cat driving at top speed\",\n      ),\n  )\n  while not operation.done:\n      time.sleep(10)\n      operation = client.operations.get(operation)\n\n  operation.result.generated_videos[0].video.uri\n  ```"
  signature: 'def generate_videos(self, *, model: str, prompt: typing.Optional[str]=None, image: typing.Optional[google.genai.types.ImageOrDict]=None, video: typing.Optional[google.genai.types.VideoOrDict]=None, source: typing.Optional[google.genai.types.GenerateVideosSourceOrDict]=None, config: typing.Optional[google.genai.types.GenerateVideosConfigOrDict]=None) -> google.genai.types.GenerateVideosOperation:'
- rank: 1926
  id: google.genai.models.Models.get
  name: get
  file_path: env/lib/python3.13/site-packages/google/genai/models.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def get(self, *, model: str, config: typing.Optional[google.genai.types.GetModelConfigOrDict]=None) -> google.genai.types.Model:'
- rank: 1927
  id: google.genai.models.Models.list
  name: list
  file_path: env/lib/python3.13/site-packages/google/genai/models.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Makes an API request to list the available models.\n\nIf `query_base` is set to True in the config or not set (default), the\nAPI will return all available base models. If set to False, it will return\nall tuned models.\n\nArgs:\n  config (ListModelsConfigOrDict): Configuration for retrieving models.\n\nUsage:\n\n.. code-block:: python\n\n  response=client.models.list(config={'page_size': 5})\n  print(response.page)\n  # [Model(name='projects/./locations/./models/123', display_name='my_model'\n\n  response=client.models.list(config={'page_size': 5, 'query_base': True})\n  print(response.page)\n  # [Model(name='publishers/google/models/gemini-2.0-flash-exp' ..."
  signature: 'def list(self, *, config: typing.Optional[google.genai.types.ListModelsConfigOrDict]=None) -> google.genai.pagers.Pager[google.genai.types.Model]:'
- rank: 1928
  id: google.genai.models.Models.recontext_image
  name: recontext_image
  file_path: env/lib/python3.13/site-packages/google/genai/models.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Recontextualizes an image.\n\nThere are two types of recontextualization currently supported:\n1) Imagen Product Recontext - Generate images of products in new scenes\n   and contexts.\n2) Virtual Try-On: Generate images of persons modeling fashion products.\n\nArgs:\n  model (str): The model to use.\n  source (RecontextImageSource): An object containing the source inputs\n    (prompt, person_image, product_images) for image recontext. prompt is\n    optional for product recontext and disallowed for virtual try-on.\n    person_image is required for virtual try-on, disallowed for product\n    recontext. product_images is required for both product recontext and\n    virtual try-on. Only one product image is supported for virtual try-on,\n    and up to 3 product images (different angles of the same product) are\n    supported for product recontext.\n  config (RecontextImageConfig): Configuration for recontextualization.\n\nUsage:\n\n  ```\n  product_recontext_response = client.models.recontext_image(\n\
    \      model=\"imagen-product-recontext-preview-06-30\",\n      source=types.RecontextImageSource(\n          prompt=\"In a modern kitchen setting.\",\n          product_images=[types.ProductImage.from_file(IMAGE_FILE_PATH)],\n      ),\n      config=types.RecontextImageConfig(\n          number_of_images=1,\n      ),\n  )\n  image = product_recontext_response.generated_images[0].image\n\n  virtual_try_on_response = client.models.recontext_image(\n      model=\"virtual-try-on-preview-08-04\",\n      source=types.RecontextImageSource(\n          person_image=types.Image.from_file(IMAGE1_FILE_PATH),\n          product_images=[types.ProductImage.from_file(IMAGE2_FILE_PATH)],\n      ),\n      config=types.RecontextImageConfig(\n          number_of_images=1,\n      ),\n  )\n  image = virtual_try_on_response.generated_images[0].image\n  ```"
  signature: 'def recontext_image(self, *, model: str, source: google.genai.types.RecontextImageSourceOrDict, config: typing.Optional[google.genai.types.RecontextImageConfigOrDict]=None) -> google.genai.types.RecontextImageResponse:'
- rank: 1929
  id: google.genai.models.Models.segment_image
  name: segment_image
  file_path: env/lib/python3.13/site-packages/google/genai/models.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Segments an image, creating a mask of a specified area.\n\nArgs:\n  model (str): The model to use.\n  source (SegmentImageSource): An object containing the source inputs\n    (prompt, image, scribble_image) for image segmentation. The prompt is\n    required for prompt mode and semantic mode, disallowed for other modes.\n    scribble_image is required for the interactive mode, disallowed for\n    other modes.\n  config (SegmentImageConfig): Configuration for segmentation.\n\nUsage:\n\n  ```\n  response = client.models.segment_image(\n      model=\"image-segmentation-001\",\n      source=types.SegmentImageSource(\n          image=types.Image.from_file(IMAGE_FILE_PATH),\n      ),\n  )\n\n  mask_image = response.generated_masks[0].mask\n  ```"
  signature: 'def segment_image(self, *, model: str, source: google.genai.types.SegmentImageSourceOrDict, config: typing.Optional[google.genai.types.SegmentImageConfigOrDict]=None) -> google.genai.types.SegmentImageResponse:'
- rank: 1930
  id: google.genai.models.Models.update
  name: update
  file_path: env/lib/python3.13/site-packages/google/genai/models.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def update(self, *, model: str, config: typing.Optional[google.genai.types.UpdateModelConfigOrDict]=None) -> google.genai.types.Model:'
- rank: 1931
  id: google.genai.models.Models.upscale_image
  name: upscale_image
  file_path: env/lib/python3.13/site-packages/google/genai/models.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Makes an API request to upscale a provided image.\n\nArgs:\n  model (str): The model to use.\n  image (Image): The input image for upscaling.\n  upscale_factor (str): The factor to upscale the image (x2 or x4).\n  config (UpscaleImageConfig): Configuration for upscaling.\n\nUsage:\n\n.. code-block:: python\n\n  from google.genai.types import Image\n\n  IMAGE_FILE_PATH=\"my-image.png\"\n  response=client.models.upscale_image(\n      model='imagen-3.0-generate-001',\n      image=types.Image.from_file(IMAGE_FILE_PATH),\n      upscale_factor='x2',\n  )\n  response.generated_images[0].image.show()\n  # Opens my-image.png which is upscaled by a factor of 2."
  signature: 'def upscale_image(self, *, model: str, image: google.genai.types.ImageOrDict, upscale_factor: str, config: typing.Optional[google.genai.types.UpscaleImageConfigOrDict]=None) -> google.genai.types.UpscaleImageResponse:'
- rank: 1932
  id: google.genai.operations
  name: operations
  file_path: env/lib/python3.13/site-packages/google/genai/operations.py
  type: MODULE
  group: Orphan
  usage_score: 0
- rank: 1933
  id: google.genai.operations.AsyncOperations
  name: AsyncOperations
  file_path: env/lib/python3.13/site-packages/google/genai/operations.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: '[Note: Inherited members from _api_module.BaseModule are omitted.]'
  methods:
  - signature: 'def get(self, operation: T, *, config: typing.Optional[google.genai.types.GetOperationConfigOrDict]=None) -> T:'
    docstring: Gets the status of an operation.
  properties:
  - signature: 'T: typing.TypeVar'
  omitted_inherited_members_from:
  - _api_module.BaseModule
- rank: 1934
  id: google.genai.operations.AsyncOperations.get
  name: get
  file_path: env/lib/python3.13/site-packages/google/genai/operations.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: Gets the status of an operation.
  signature: 'def get(self, operation: T, *, config: typing.Optional[google.genai.types.GetOperationConfigOrDict]=None) -> T:'
- rank: 1935
  id: google.genai.operations.Operations
  name: Operations
  file_path: env/lib/python3.13/site-packages/google/genai/operations.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: '[Note: Inherited members from _api_module.BaseModule are omitted.]'
  methods:
  - signature: 'def get(self, operation: T, *, config: typing.Optional[google.genai.types.GetOperationConfigOrDict]=None) -> T:'
    docstring: Gets the status of an operation.
  properties:
  - signature: 'T: typing.TypeVar'
  omitted_inherited_members_from:
  - _api_module.BaseModule
- rank: 1936
  id: google.genai.operations.Operations.get
  name: get
  file_path: env/lib/python3.13/site-packages/google/genai/operations.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: Gets the status of an operation.
  signature: 'def get(self, operation: T, *, config: typing.Optional[google.genai.types.GetOperationConfigOrDict]=None) -> T:'
- rank: 1937
  id: google.genai.pagers
  name: pagers
  file_path: env/lib/python3.13/site-packages/google/genai/pagers.py
  type: MODULE
  group: Orphan
  usage_score: 0
  docstring: Pagers for the GenAI List APIs.
- rank: 1938
  id: google.genai.pagers.AsyncPager
  name: AsyncPager
  file_path: env/lib/python3.13/site-packages/google/genai/pagers.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: AsyncPager class for iterating through paginated results.
  constructor_signature: 'def __init__(self, name: google.genai.pagers.PagedItem, request: typing.Callable[Ellipsis, typing.Awaitable[typing.Any]], response: typing.Any, config: typing.Any):'
  methods:
  - signature: 'def next_page(self) -> list[google.genai.pagers.T]:'
    docstring: "Fetches the next page of items asynchronously.\n\nThis makes a new API request.\n\nReturns:\n  The next page of items.\n\nRaises:\n  IndexError: No more pages to fetch.\n\nUsage:\n\n.. code-block:: python\n\n  batch_jobs_pager = await client.aio.batches.list(config={'page_size': 5})\n  print(f\"current page: {batch_jobs_pager.page}\")\n  await batch_jobs_pager.next_page()\n  print(f\"next page: {batch_jobs_pager.page}\")\n  # current page: [BatchJob(name='projects/.../batchPredictionJobs/1\n  # next page: [BatchJob(name='projects/.../batchPredictionJobs/6"
- rank: 1939
  id: google.genai.pagers.AsyncPager.__init__
  name: __init__
  file_path: env/lib/python3.13/site-packages/google/genai/pagers.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def __init__(self, name: google.genai.pagers.PagedItem, request: typing.Callable[Ellipsis, typing.Awaitable[typing.Any]], response: typing.Any, config: typing.Any):'
- rank: 1940
  id: google.genai.pagers.AsyncPager.next_page
  name: next_page
  file_path: env/lib/python3.13/site-packages/google/genai/pagers.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Fetches the next page of items asynchronously.\n\nThis makes a new API request.\n\nReturns:\n  The next page of items.\n\nRaises:\n  IndexError: No more pages to fetch.\n\nUsage:\n\n.. code-block:: python\n\n  batch_jobs_pager = await client.aio.batches.list(config={'page_size': 5})\n  print(f\"current page: {batch_jobs_pager.page}\")\n  await batch_jobs_pager.next_page()\n  print(f\"next page: {batch_jobs_pager.page}\")\n  # current page: [BatchJob(name='projects/.../batchPredictionJobs/1\n  # next page: [BatchJob(name='projects/.../batchPredictionJobs/6"
  signature: 'def next_page(self) -> list[google.genai.pagers.T]:'
- rank: 1941
  id: google.genai.pagers.Pager
  name: Pager
  file_path: env/lib/python3.13/site-packages/google/genai/pagers.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: Pager class for iterating through paginated results.
  methods:
  - signature: 'def next_page(self) -> list[google.genai.pagers.T]:'
    docstring: "Fetches the next page of items. This makes a new API request.\n\nUsage:\n\n.. code-block:: python\n\n  batch_jobs_pager = client.batches.list(config={'page_size': 5})\n  print(f\"current page: {batch_jobs_pager.page}\")\n  batch_jobs_pager.next_page()\n  print(f\"next page: {batch_jobs_pager.page}\")\n  # current page: [BatchJob(name='projects/.../batchPredictionJobs/1\n  # next page: [BatchJob(name='projects/.../batchPredictionJobs/6"
- rank: 1942
  id: google.genai.pagers.Pager.next_page
  name: next_page
  file_path: env/lib/python3.13/site-packages/google/genai/pagers.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Fetches the next page of items. This makes a new API request.\n\nUsage:\n\n.. code-block:: python\n\n  batch_jobs_pager = client.batches.list(config={'page_size': 5})\n  print(f\"current page: {batch_jobs_pager.page}\")\n  batch_jobs_pager.next_page()\n  print(f\"next page: {batch_jobs_pager.page}\")\n  # current page: [BatchJob(name='projects/.../batchPredictionJobs/1\n  # next page: [BatchJob(name='projects/.../batchPredictionJobs/6"
  signature: 'def next_page(self) -> list[google.genai.pagers.T]:'
- rank: 1943
  id: google.genai.tokens
  name: tokens
  file_path: env/lib/python3.13/site-packages/google/genai/tokens.py
  type: MODULE
  group: Orphan
  usage_score: 0
  docstring: '[Experimental] Auth Tokens API client.'
- rank: 1944
  id: google.genai.tokens.AsyncTokens
  name: AsyncTokens
  file_path: env/lib/python3.13/site-packages/google/genai/tokens.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: '[Experimental] Async Auth Tokens API client.


    This class provides asynchronous methods for creating auth tokens.


    [Note: Inherited members from _api_module.BaseModule are omitted.]'
  methods:
  - signature: 'def create(self, *, config: typing.Optional[google.genai.types.CreateAuthTokenConfigOrDict]=None) -> google.genai.types.AuthToken:'
    docstring: "Creates an auth token asynchronously. Support in v1alpha only.\n\nArgs:\n  config (CreateAuthTokenConfig): Optional configuration for the request.\n\nUsage:\n\n.. code-block:: python\n\n  client = genai.Client(\n      api_key=API_KEY,\n      http_options=types.HttpOptions(api_version='v1alpha'),\n  )\n\n  auth_token = await client.aio.tokens.create(\n      config=types.CreateAuthTokenConfig(\n          uses=10,\n          live_constrained_parameters=types.LiveEphemeralParameters(\n              model='gemini-live-2.5-flash-preview',\n              config=types.LiveConnectConfig(\n                  system_instruction='You are an LLM called Gemini.'\n              ),\n          ),\n      )\n  )"
  omitted_inherited_members_from:
  - _api_module.BaseModule
- rank: 1945
  id: google.genai.tokens.AsyncTokens.create
  name: create
  file_path: env/lib/python3.13/site-packages/google/genai/tokens.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Creates an auth token asynchronously. Support in v1alpha only.\n\nArgs:\n  config (CreateAuthTokenConfig): Optional configuration for the request.\n\nUsage:\n\n.. code-block:: python\n\n  client = genai.Client(\n      api_key=API_KEY,\n      http_options=types.HttpOptions(api_version='v1alpha'),\n  )\n\n  auth_token = await client.aio.tokens.create(\n      config=types.CreateAuthTokenConfig(\n          uses=10,\n          live_constrained_parameters=types.LiveEphemeralParameters(\n              model='gemini-live-2.5-flash-preview',\n              config=types.LiveConnectConfig(\n                  system_instruction='You are an LLM called Gemini.'\n              ),\n          ),\n      )\n  )"
  signature: 'def create(self, *, config: typing.Optional[google.genai.types.CreateAuthTokenConfigOrDict]=None) -> google.genai.types.AuthToken:'
- rank: 1946
  id: google.genai.tokens.Tokens
  name: Tokens
  file_path: env/lib/python3.13/site-packages/google/genai/tokens.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: '[Experimental] Auth Tokens API client.


    This class provides methods for creating auth tokens.


    [Note: Inherited members from _api_module.BaseModule are omitted.]'
  methods:
  - signature: 'def create(self, *, config: typing.Optional[google.genai.types.CreateAuthTokenConfigOrDict]=None) -> google.genai.types.AuthToken:'
    docstring: "[Experimental] Creates an auth token.\n\nArgs:\n  config (CreateAuthTokenConfig): Optional configuration for the request.\n\nThe CreateAuthTokenConfig's `live_constrained_parameters` attrubite\nCan be used to lock the parameters of the live session so they\ncan't be changed client side. This behavior has two basic modes depending on\nwhether `lock_additional_fields` is set:\n\nIf you do not pass `lock_additional_fields` the entire\n`live_constrained_parameters` is locked and can't be changed\nby the token's user.\n\nIf you set `lock_additional_fields`, then the non-null fields of\n`live_constrained_parameters` are locked, and any additional fields\nspecified in `lock_additional_fields`.\n\nUsage:\n\n.. code-block:: python\n\n  # Case 1: If LiveEphemeralParameters is unset, unlock LiveConnectConfig\n  # when using the token in Live API sessions. Each session connection can\n  # use a different configuration.\n\n  config = types.CreateAuthTokenConfig(\n      uses=10,\n    \
      \  expire_time='2025-05-01T00:00:00Z',\n  )\n  auth_token = client.tokens.create(config=config)\n\n.. code-block:: python\n\n  # Case 2: If LiveEphemeralParameters is set, lock all fields in\n  # LiveConnectConfig when using the token in Live API sessions. For\n  # example, changing `output_audio_transcription` in the Live API\n  # connection will be ignored by the API.\n\n  auth_token = client.tokens.create(\n      config=types.CreateAuthTokenConfig(\n          uses=10,\n          live_constrained_parameters=types.LiveEphemeralParameters(\n              model='gemini-live-2.5-flash-preview',\n              config=types.LiveConnectConfig(\n                  system_instruction='You are an LLM called Gemini.'\n              ),\n          ),\n      )\n  )\n\n.. code-block:: python\n\n  # Case 3: If LiveEphemeralParameters is set and lockAdditionalFields is\n  # empty, lock LiveConnectConfig with set fields (e.g.\n  # system_instruction in this example) when using the token in Live API\n\
      \  # sessions.\n  auth_token = client.tokens.create(\n      config=types.CreateAuthTokenConfig(\n          uses=10,\n          live_constrained_parameters=types.LiveEphemeralParameters(\n              config=types.LiveConnectConfig(\n                  system_instruction='You are an LLM called Gemini.'\n              ),\n          ),\n          lock_additional_fields=[],\n      )\n  )\n\n.. code-block:: python\n\n  # Case 4: If LiveEphemeralParameters is set and lockAdditionalFields is\n  # set, lock LiveConnectConfig with set and additional fields (e.g.\n  # system_instruction, temperature in this example) when using the token\n  # in Live API sessions.\n  auth_token = client.tokens.create(\n      config=types.CreateAuthTokenConfig(\n          uses=10,\n          live_constrained_parameters=types.LiveEphemeralParameters(\n              model='gemini-live-2.5-flash-preview',\n              config=types.LiveConnectConfig(\n                  system_instruction='You are an LLM called Gemini.'\n\
      \              ),\n          ),\n          lock_additional_fields=['temperature'],\n      )\n  )"
  omitted_inherited_members_from:
  - _api_module.BaseModule
- rank: 1947
  id: google.genai.tokens.Tokens.create
  name: create
  file_path: env/lib/python3.13/site-packages/google/genai/tokens.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "[Experimental] Creates an auth token.\n\nArgs:\n  config (CreateAuthTokenConfig): Optional configuration for the request.\n\nThe CreateAuthTokenConfig's `live_constrained_parameters` attrubite\nCan be used to lock the parameters of the live session so they\ncan't be changed client side. This behavior has two basic modes depending on\nwhether `lock_additional_fields` is set:\n\nIf you do not pass `lock_additional_fields` the entire\n`live_constrained_parameters` is locked and can't be changed\nby the token's user.\n\nIf you set `lock_additional_fields`, then the non-null fields of\n`live_constrained_parameters` are locked, and any additional fields\nspecified in `lock_additional_fields`.\n\nUsage:\n\n.. code-block:: python\n\n  # Case 1: If LiveEphemeralParameters is unset, unlock LiveConnectConfig\n  # when using the token in Live API sessions. Each session connection can\n  # use a different configuration.\n\n  config = types.CreateAuthTokenConfig(\n      uses=10,\n      expire_time='2025-05-01T00:00:00Z',\n\
    \  )\n  auth_token = client.tokens.create(config=config)\n\n.. code-block:: python\n\n  # Case 2: If LiveEphemeralParameters is set, lock all fields in\n  # LiveConnectConfig when using the token in Live API sessions. For\n  # example, changing `output_audio_transcription` in the Live API\n  # connection will be ignored by the API.\n\n  auth_token = client.tokens.create(\n      config=types.CreateAuthTokenConfig(\n          uses=10,\n          live_constrained_parameters=types.LiveEphemeralParameters(\n              model='gemini-live-2.5-flash-preview',\n              config=types.LiveConnectConfig(\n                  system_instruction='You are an LLM called Gemini.'\n              ),\n          ),\n      )\n  )\n\n.. code-block:: python\n\n  # Case 3: If LiveEphemeralParameters is set and lockAdditionalFields is\n  # empty, lock LiveConnectConfig with set fields (e.g.\n  # system_instruction in this example) when using the token in Live API\n  # sessions.\n  auth_token = client.tokens.create(\n\
    \      config=types.CreateAuthTokenConfig(\n          uses=10,\n          live_constrained_parameters=types.LiveEphemeralParameters(\n              config=types.LiveConnectConfig(\n                  system_instruction='You are an LLM called Gemini.'\n              ),\n          ),\n          lock_additional_fields=[],\n      )\n  )\n\n.. code-block:: python\n\n  # Case 4: If LiveEphemeralParameters is set and lockAdditionalFields is\n  # set, lock LiveConnectConfig with set and additional fields (e.g.\n  # system_instruction, temperature in this example) when using the token\n  # in Live API sessions.\n  auth_token = client.tokens.create(\n      config=types.CreateAuthTokenConfig(\n          uses=10,\n          live_constrained_parameters=types.LiveEphemeralParameters(\n              model='gemini-live-2.5-flash-preview',\n              config=types.LiveConnectConfig(\n                  system_instruction='You are an LLM called Gemini.'\n              ),\n          ),\n          lock_additional_fields=['temperature'],\n\
    \      )\n  )"
  signature: 'def create(self, *, config: typing.Optional[google.genai.types.CreateAuthTokenConfigOrDict]=None) -> google.genai.types.AuthToken:'
- rank: 1948
  id: google.genai.tunings
  name: tunings
  file_path: env/lib/python3.13/site-packages/google/genai/tunings.py
  type: MODULE
  group: Orphan
  usage_score: 0
- rank: 1949
  id: google.genai.tunings.AsyncTunings
  name: AsyncTunings
  file_path: env/lib/python3.13/site-packages/google/genai/tunings.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: '[Note: Inherited members from _api_module.BaseModule are omitted.]'
  methods:
  - signature: 'def cancel(self, *, name: str, config: typing.Optional[google.genai.types.CancelTuningJobConfigOrDict]=None) -> google.genai.types.CancelTuningJobResponse:'
    docstring: "Cancels a tuning job asynchronously.\n\nArgs:\n  name (str): A TuningJob resource name."
  - signature: 'def list(self, *, config: typing.Optional[google.genai.types.ListTuningJobsConfigOrDict]=None) -> google.genai.pagers.AsyncPager[google.genai.types.TuningJob]:'
    docstring: "Lists `TuningJob` objects asynchronously.\n\nArgs:\n  config: The configuration for the list request.\n\nReturns:\n  A Pager object that contains one page of tuning jobs. When iterating over\n  the pager, it automatically fetches the next page if there are more.\n\nUsage:\n\n.. code-block:: python\n    async for tuning_job in await client.aio.tunings.list():\n        print(tuning_job.name)"
  - signature: 'def get(self, *, name: str, config: typing.Optional[google.genai.types.GetTuningJobConfigOrDict]=None) -> google.genai.types.TuningJob:'
  - signature: 'def tune(self, *, base_model: str, training_dataset: google.genai.types.TuningDatasetOrDict, config: typing.Optional[google.genai.types.CreateTuningJobConfigOrDict]=None) -> google.genai.types.TuningJob:'
  omitted_inherited_members_from:
  - _api_module.BaseModule
- rank: 1950
  id: google.genai.tunings.AsyncTunings.cancel
  name: cancel
  file_path: env/lib/python3.13/site-packages/google/genai/tunings.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Cancels a tuning job asynchronously.\n\nArgs:\n  name (str): A TuningJob resource name."
  signature: 'def cancel(self, *, name: str, config: typing.Optional[google.genai.types.CancelTuningJobConfigOrDict]=None) -> google.genai.types.CancelTuningJobResponse:'
- rank: 1951
  id: google.genai.tunings.AsyncTunings.get
  name: get
  file_path: env/lib/python3.13/site-packages/google/genai/tunings.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def get(self, *, name: str, config: typing.Optional[google.genai.types.GetTuningJobConfigOrDict]=None) -> google.genai.types.TuningJob:'
- rank: 1952
  id: google.genai.tunings.AsyncTunings.list
  name: list
  file_path: env/lib/python3.13/site-packages/google/genai/tunings.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Lists `TuningJob` objects asynchronously.\n\nArgs:\n  config: The configuration for the list request.\n\nReturns:\n  A Pager object that contains one page of tuning jobs. When iterating over\n  the pager, it automatically fetches the next page if there are more.\n\nUsage:\n\n.. code-block:: python\n    async for tuning_job in await client.aio.tunings.list():\n        print(tuning_job.name)"
  signature: 'def list(self, *, config: typing.Optional[google.genai.types.ListTuningJobsConfigOrDict]=None) -> google.genai.pagers.AsyncPager[google.genai.types.TuningJob]:'
- rank: 1953
  id: google.genai.tunings.AsyncTunings.tune
  name: tune
  file_path: env/lib/python3.13/site-packages/google/genai/tunings.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def tune(self, *, base_model: str, training_dataset: google.genai.types.TuningDatasetOrDict, config: typing.Optional[google.genai.types.CreateTuningJobConfigOrDict]=None) -> google.genai.types.TuningJob:'
- rank: 1954
  id: google.genai.tunings.Tunings
  name: Tunings
  file_path: env/lib/python3.13/site-packages/google/genai/tunings.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: '[Note: Inherited members from _api_module.BaseModule are omitted.]'
  methods:
  - signature: 'def cancel(self, *, name: str, config: typing.Optional[google.genai.types.CancelTuningJobConfigOrDict]=None) -> google.genai.types.CancelTuningJobResponse:'
    docstring: "Cancels a tuning job.\n\nArgs:\n  name (str): TuningJob resource name."
  - signature: 'def list(self, *, config: typing.Optional[google.genai.types.ListTuningJobsConfigOrDict]=None) -> google.genai.pagers.Pager[google.genai.types.TuningJob]:'
    docstring: "Lists `TuningJob` objects.\n\nArgs:\n  config: The configuration for the list request.\n\nReturns:\n  A Pager object that contains one page of tuning jobs. When iterating over\n  the pager, it automatically fetches the next page if there are more.\n\nUsage:\n\n.. code-block:: python\n    for tuning_job in client.tunings.list():\n        print(tuning_job.name)"
  - signature: 'def get(self, *, name: str, config: typing.Optional[google.genai.types.GetTuningJobConfigOrDict]=None) -> google.genai.types.TuningJob:'
  - signature: 'def tune(self, *, base_model: str, training_dataset: google.genai.types.TuningDatasetOrDict, config: typing.Optional[google.genai.types.CreateTuningJobConfigOrDict]=None) -> google.genai.types.TuningJob:'
  omitted_inherited_members_from:
  - _api_module.BaseModule
- rank: 1955
  id: google.genai.tunings.Tunings.cancel
  name: cancel
  file_path: env/lib/python3.13/site-packages/google/genai/tunings.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Cancels a tuning job.\n\nArgs:\n  name (str): TuningJob resource name."
  signature: 'def cancel(self, *, name: str, config: typing.Optional[google.genai.types.CancelTuningJobConfigOrDict]=None) -> google.genai.types.CancelTuningJobResponse:'
- rank: 1956
  id: google.genai.tunings.Tunings.get
  name: get
  file_path: env/lib/python3.13/site-packages/google/genai/tunings.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def get(self, *, name: str, config: typing.Optional[google.genai.types.GetTuningJobConfigOrDict]=None) -> google.genai.types.TuningJob:'
- rank: 1957
  id: google.genai.tunings.Tunings.list
  name: list
  file_path: env/lib/python3.13/site-packages/google/genai/tunings.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Lists `TuningJob` objects.\n\nArgs:\n  config: The configuration for the list request.\n\nReturns:\n  A Pager object that contains one page of tuning jobs. When iterating over\n  the pager, it automatically fetches the next page if there are more.\n\nUsage:\n\n.. code-block:: python\n    for tuning_job in client.tunings.list():\n        print(tuning_job.name)"
  signature: 'def list(self, *, config: typing.Optional[google.genai.types.ListTuningJobsConfigOrDict]=None) -> google.genai.pagers.Pager[google.genai.types.TuningJob]:'
- rank: 1958
  id: google.genai.tunings.Tunings.tune
  name: tune
  file_path: env/lib/python3.13/site-packages/google/genai/tunings.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def tune(self, *, base_model: str, training_dataset: google.genai.types.TuningDatasetOrDict, config: typing.Optional[google.genai.types.CreateTuningJobConfigOrDict]=None) -> google.genai.types.TuningJob:'
- rank: 1959
  id: google.genai.types
  name: types
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: MODULE
  group: Orphan
  usage_score: 0
- rank: 1960
  id: google.genai.types.ActivityEnd
  name: ActivityEnd
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Marks the end of user activity.


    This can only be sent if automatic (i.e. server-side) activity detection is

    disabled.


    [Note: Inherited members from _common.BaseModel are omitted.]'
  omitted_inherited_members_from:
  - _common.BaseModel
- rank: 1961
  id: google.genai.types.ActivityEndDict
  name: ActivityEndDict
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Marks the end of user activity.


    This can only be sent if automatic (i.e. server-side) activity detection is

    disabled.


    [Note: Inherited members from TypedDict are omitted.]'
  omitted_inherited_members_from:
  - TypedDict
- rank: 1962
  id: google.genai.types.ActivityHandling
  name: ActivityHandling
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'The different ways of handling user activity.


    [Note: Inherited members from _common.CaseInSensitiveEnum are omitted.]'
  properties:
  - signature: 'ACTIVITY_HANDLING_UNSPECIFIED: str'
    docstring: If unspecified, the default behavior is `START_OF_ACTIVITY_INTERRUPTS`.
  - signature: 'START_OF_ACTIVITY_INTERRUPTS: str'
    docstring: If true, start of activity will interrupt the model's response (also called "barge in"). The model's current response will be cut-off in the moment of the interruption. This is the default behavior.
  - signature: 'NO_INTERRUPTION: str'
    docstring: The model's response will not be interrupted.
  omitted_inherited_members_from:
  - _common.CaseInSensitiveEnum
- rank: 1963
  id: google.genai.types.ActivityStart
  name: ActivityStart
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Marks the start of user activity.


    This can only be sent if automatic (i.e. server-side) activity detection is

    disabled.


    [Note: Inherited members from _common.BaseModel are omitted.]'
  omitted_inherited_members_from:
  - _common.BaseModel
- rank: 1964
  id: google.genai.types.ActivityStartDict
  name: ActivityStartDict
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Marks the start of user activity.


    This can only be sent if automatic (i.e. server-side) activity detection is

    disabled.


    [Note: Inherited members from TypedDict are omitted.]'
  omitted_inherited_members_from:
  - TypedDict
- rank: 1965
  id: google.genai.types.AdapterSize
  name: AdapterSize
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Adapter size for tuning. This enum is not supported in Gemini API.


    [Note: Inherited members from _common.CaseInSensitiveEnum are omitted.]'
  properties:
  - signature: 'ADAPTER_SIZE_UNSPECIFIED: str'
    docstring: Adapter size is unspecified.
  - signature: 'ADAPTER_SIZE_ONE: str'
    docstring: Adapter size 1.
  - signature: 'ADAPTER_SIZE_TWO: str'
    docstring: Adapter size 2.
  - signature: 'ADAPTER_SIZE_FOUR: str'
    docstring: Adapter size 4.
  - signature: 'ADAPTER_SIZE_EIGHT: str'
    docstring: Adapter size 8.
  - signature: 'ADAPTER_SIZE_SIXTEEN: str'
    docstring: Adapter size 16.
  - signature: 'ADAPTER_SIZE_THIRTY_TWO: str'
    docstring: Adapter size 32.
  omitted_inherited_members_from:
  - _common.CaseInSensitiveEnum
- rank: 1966
  id: google.genai.types.ApiAuth
  name: ApiAuth
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'The generic reusable api auth config.


    Deprecated. Please use AuthConfig (google/cloud/aiplatform/master/auth.proto)

    instead. This data type is not supported in Gemini API.


    [Note: Inherited members from _common.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, api_key_config: typing.Optional[google.genai.types.ApiAuthApiKeyConfig] = None):'
  properties:
  - signature: 'api_key_config: typing.Optional[google.genai.types.ApiAuthApiKeyConfig]'
  omitted_inherited_members_from:
  - _common.BaseModel
- rank: 1967
  id: google.genai.types.ApiAuthApiKeyConfig
  name: ApiAuthApiKeyConfig
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'The API secret. This data type is not supported in Gemini API.


    [Note: Inherited members from _common.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, api_key_secret_version: typing.Optional[str] = None, api_key_string: typing.Optional[str] = None):'
  properties:
  - signature: 'api_key_secret_version: typing.Optional[str]'
  - signature: 'api_key_string: typing.Optional[str]'
  omitted_inherited_members_from:
  - _common.BaseModel
- rank: 1968
  id: google.genai.types.ApiAuthApiKeyConfigDict
  name: ApiAuthApiKeyConfigDict
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'The API secret. This data type is not supported in Gemini API.


    [Note: Inherited members from TypedDict are omitted.]'
  properties:
  - signature: 'api_key_secret_version: typing.Optional[str]'
    docstring: Required. The SecretManager secret version resource name storing API key. e.g. projects/{project}/secrets/{secret}/versions/{version}
  - signature: 'api_key_string: typing.Optional[str]'
    docstring: The API key string. Either this or `api_key_secret_version` must be set.
  omitted_inherited_members_from:
  - TypedDict
- rank: 1969
  id: google.genai.types.ApiAuthDict
  name: ApiAuthDict
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'The generic reusable api auth config.


    Deprecated. Please use AuthConfig (google/cloud/aiplatform/master/auth.proto)

    instead. This data type is not supported in Gemini API.


    [Note: Inherited members from TypedDict are omitted.]'
  properties:
  - signature: 'api_key_config: typing.Optional[google.genai.types.ApiAuthApiKeyConfigDict]'
    docstring: The API secret.
  omitted_inherited_members_from:
  - TypedDict
- rank: 1970
  id: google.genai.types.ApiKeyConfig
  name: ApiKeyConfig
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Config for authentication with API key.


    This data type is not supported in Gemini API.


    [Note: Inherited members from _common.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, api_key_secret: typing.Optional[str] = None, api_key_string: typing.Optional[str] = None, http_element_location: typing.Optional[google.genai.types.HttpElementLocation] = None, name: typing.Optional[str] = None):'
  properties:
  - signature: 'api_key_secret: typing.Optional[str]'
  - signature: 'api_key_string: typing.Optional[str]'
  - signature: 'http_element_location: typing.Optional[google.genai.types.HttpElementLocation]'
  - signature: 'name: typing.Optional[str]'
  omitted_inherited_members_from:
  - _common.BaseModel
- rank: 1971
  id: google.genai.types.ApiKeyConfigDict
  name: ApiKeyConfigDict
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Config for authentication with API key.


    This data type is not supported in Gemini API.


    [Note: Inherited members from TypedDict are omitted.]'
  properties:
  - signature: 'api_key_secret: typing.Optional[str]'
    docstring: 'Optional. The name of the SecretManager secret version resource storing the API key. Format: `projects/{project}/secrets/{secrete}/versions/{version}` - If both `api_key_secret` and `api_key_string` are specified, this field takes precedence over `api_key_string`. - If specified, the `secretmanager.versions.access` permission should be granted to Vertex AI Extension Service Agent (https://cloud.google.com/vertex-ai/docs/general/access-control#service-agents) on the specified resource.'
  - signature: 'api_key_string: typing.Optional[str]'
    docstring: Optional. The API key to be used in the request directly.
  - signature: 'http_element_location: typing.Optional[google.genai.types.HttpElementLocation]'
    docstring: Optional. The location of the API key.
  - signature: 'name: typing.Optional[str]'
    docstring: Optional. The parameter name of the API key. E.g. If the API request is "https://example.com/act?api_key=", "api_key" would be the parameter name.
  omitted_inherited_members_from:
  - TypedDict
- rank: 1972
  id: google.genai.types.ApiSpec
  name: ApiSpec
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'The API spec that the external API implements.


    This enum is not supported in Gemini API.


    [Note: Inherited members from _common.CaseInSensitiveEnum are omitted.]'
  properties:
  - signature: 'API_SPEC_UNSPECIFIED: str'
    docstring: Unspecified API spec. This value should not be used.
  - signature: 'SIMPLE_SEARCH: str'
    docstring: Simple search API spec.
  - signature: 'ELASTIC_SEARCH: str'
    docstring: Elastic search API spec.
  omitted_inherited_members_from:
  - _common.CaseInSensitiveEnum
- rank: 1973
  id: google.genai.types.AudioChunk
  name: AudioChunk
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Representation of an audio chunk.


    [Note: Inherited members from _common.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, data: typing.Optional[bytes] = None, mime_type: typing.Optional[str] = None, source_metadata: typing.Optional[google.genai.types.LiveMusicSourceMetadata] = None):'
  properties:
  - signature: 'data: typing.Optional[bytes]'
  - signature: 'mime_type: typing.Optional[str]'
  - signature: 'source_metadata: typing.Optional[google.genai.types.LiveMusicSourceMetadata]'
  omitted_inherited_members_from:
  - _common.BaseModel
- rank: 1974
  id: google.genai.types.AudioChunkDict
  name: AudioChunkDict
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Representation of an audio chunk.


    [Note: Inherited members from TypedDict are omitted.]'
  properties:
  - signature: 'data: typing.Optional[bytes]'
    docstring: Raw bytes of audio data.
  - signature: 'mime_type: typing.Optional[str]'
    docstring: MIME type of the audio chunk.
  - signature: 'source_metadata: typing.Optional[google.genai.types.LiveMusicSourceMetadataDict]'
    docstring: Prompts and config used for generating this audio chunk.
  omitted_inherited_members_from:
  - TypedDict
- rank: 1975
  id: google.genai.types.AudioTranscriptionConfig
  name: AudioTranscriptionConfig
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'The audio transcription configuration in Setup.


    [Note: Inherited members from _common.BaseModel are omitted.]'
  omitted_inherited_members_from:
  - _common.BaseModel
- rank: 1976
  id: google.genai.types.AudioTranscriptionConfigDict
  name: AudioTranscriptionConfigDict
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'The audio transcription configuration in Setup.


    [Note: Inherited members from TypedDict are omitted.]'
  omitted_inherited_members_from:
  - TypedDict
- rank: 1977
  id: google.genai.types.AuthConfig
  name: AuthConfig
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Auth configuration to run the extension.


    This data type is not supported in Gemini API.


    [Note: Inherited members from _common.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, api_key_config: typing.Optional[google.genai.types.ApiKeyConfig] = None, auth_type: typing.Optional[google.genai.types.AuthType] = None, google_service_account_config: typing.Optional[google.genai.types.AuthConfigGoogleServiceAccountConfig] = None, http_basic_auth_config: typing.Optional[google.genai.types.AuthConfigHttpBasicAuthConfig] = None, oauth_config: typing.Optional[google.genai.types.AuthConfigOauthConfig] = None, oidc_config: typing.Optional[google.genai.types.AuthConfigOidcConfig] = None):'
  properties:
  - signature: 'api_key_config: typing.Optional[google.genai.types.ApiKeyConfig]'
  - signature: 'auth_type: typing.Optional[google.genai.types.AuthType]'
  - signature: 'google_service_account_config: typing.Optional[google.genai.types.AuthConfigGoogleServiceAccountConfig]'
  - signature: 'http_basic_auth_config: typing.Optional[google.genai.types.AuthConfigHttpBasicAuthConfig]'
  - signature: 'oauth_config: typing.Optional[google.genai.types.AuthConfigOauthConfig]'
  - signature: 'oidc_config: typing.Optional[google.genai.types.AuthConfigOidcConfig]'
  omitted_inherited_members_from:
  - _common.BaseModel
- rank: 1978
  id: google.genai.types.AuthConfigDict
  name: AuthConfigDict
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Auth configuration to run the extension.


    This data type is not supported in Gemini API.


    [Note: Inherited members from TypedDict are omitted.]'
  properties:
  - signature: 'api_key_config: typing.Optional[google.genai.types.ApiKeyConfigDict]'
    docstring: Config for API key auth.
  - signature: 'auth_type: typing.Optional[google.genai.types.AuthType]'
    docstring: Type of auth scheme.
  - signature: 'google_service_account_config: typing.Optional[google.genai.types.AuthConfigGoogleServiceAccountConfigDict]'
    docstring: Config for Google Service Account auth.
  - signature: 'http_basic_auth_config: typing.Optional[google.genai.types.AuthConfigHttpBasicAuthConfigDict]'
    docstring: Config for HTTP Basic auth.
  - signature: 'oauth_config: typing.Optional[google.genai.types.AuthConfigOauthConfigDict]'
    docstring: Config for user oauth.
  - signature: 'oidc_config: typing.Optional[google.genai.types.AuthConfigOidcConfigDict]'
    docstring: Config for user OIDC auth.
  omitted_inherited_members_from:
  - TypedDict
- rank: 1979
  id: google.genai.types.AuthConfigGoogleServiceAccountConfig
  name: AuthConfigGoogleServiceAccountConfig
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Config for Google Service Account Authentication.


    This data type is not supported in Gemini API.


    [Note: Inherited members from _common.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, service_account: typing.Optional[str] = None):'
  properties:
  - signature: 'service_account: typing.Optional[str]'
  omitted_inherited_members_from:
  - _common.BaseModel
- rank: 1980
  id: google.genai.types.AuthConfigGoogleServiceAccountConfigDict
  name: AuthConfigGoogleServiceAccountConfigDict
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Config for Google Service Account Authentication.


    This data type is not supported in Gemini API.


    [Note: Inherited members from TypedDict are omitted.]'
  properties:
  - signature: 'service_account: typing.Optional[str]'
    docstring: Optional. The service account that the extension execution service runs as. - If the service account is specified, the `iam.serviceAccounts.getAccessToken` permission should be granted to Vertex AI Extension Service Agent (https://cloud.google.com/vertex-ai/docs/general/access-control#service-agents) on the specified service account. - If not specified, the Vertex AI Extension Service Agent will be used to execute the Extension.
  omitted_inherited_members_from:
  - TypedDict
- rank: 1981
  id: google.genai.types.AuthConfigHttpBasicAuthConfig
  name: AuthConfigHttpBasicAuthConfig
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Config for HTTP Basic Authentication.


    This data type is not supported in Gemini API.


    [Note: Inherited members from _common.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, credential_secret: typing.Optional[str] = None):'
  properties:
  - signature: 'credential_secret: typing.Optional[str]'
  omitted_inherited_members_from:
  - _common.BaseModel
- rank: 1982
  id: google.genai.types.AuthConfigHttpBasicAuthConfigDict
  name: AuthConfigHttpBasicAuthConfigDict
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Config for HTTP Basic Authentication.


    This data type is not supported in Gemini API.


    [Note: Inherited members from TypedDict are omitted.]'
  properties:
  - signature: 'credential_secret: typing.Optional[str]'
    docstring: 'Required. The name of the SecretManager secret version resource storing the base64 encoded credentials. Format: `projects/{project}/secrets/{secrete}/versions/{version}` - If specified, the `secretmanager.versions.access` permission should be granted to Vertex AI Extension Service Agent (https://cloud.google.com/vertex-ai/docs/general/access-control#service-agents) on the specified resource.'
  omitted_inherited_members_from:
  - TypedDict
- rank: 1983
  id: google.genai.types.AuthConfigOauthConfig
  name: AuthConfigOauthConfig
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Config for user oauth. This data type is not supported in Gemini API.


    [Note: Inherited members from _common.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, access_token: typing.Optional[str] = None, service_account: typing.Optional[str] = None):'
  properties:
  - signature: 'access_token: typing.Optional[str]'
  - signature: 'service_account: typing.Optional[str]'
  omitted_inherited_members_from:
  - _common.BaseModel
- rank: 1984
  id: google.genai.types.AuthConfigOauthConfigDict
  name: AuthConfigOauthConfigDict
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Config for user oauth. This data type is not supported in Gemini API.


    [Note: Inherited members from TypedDict are omitted.]'
  properties:
  - signature: 'access_token: typing.Optional[str]'
    docstring: Access token for extension endpoint. Only used to propagate token from [[ExecuteExtensionRequest.runtime_auth_config]] at request time.
  - signature: 'service_account: typing.Optional[str]'
    docstring: The service account used to generate access tokens for executing the Extension. - If the service account is specified, the `iam.serviceAccounts.getAccessToken` permission should be granted to Vertex AI Extension Service Agent (https://cloud.google.com/vertex-ai/docs/general/access-control#service-agents) on the provided service account.
  omitted_inherited_members_from:
  - TypedDict
- rank: 1985
  id: google.genai.types.AuthConfigOidcConfig
  name: AuthConfigOidcConfig
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Config for user OIDC auth.


    This data type is not supported in Gemini API.


    [Note: Inherited members from _common.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, id_token: typing.Optional[str] = None, service_account: typing.Optional[str] = None):'
  properties:
  - signature: 'id_token: typing.Optional[str]'
  - signature: 'service_account: typing.Optional[str]'
  omitted_inherited_members_from:
  - _common.BaseModel
- rank: 1986
  id: google.genai.types.AuthConfigOidcConfigDict
  name: AuthConfigOidcConfigDict
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Config for user OIDC auth.


    This data type is not supported in Gemini API.


    [Note: Inherited members from TypedDict are omitted.]'
  properties:
  - signature: 'id_token: typing.Optional[str]'
    docstring: OpenID Connect formatted ID token for extension endpoint. Only used to propagate token from [[ExecuteExtensionRequest.runtime_auth_config]] at request time.
  - signature: 'service_account: typing.Optional[str]'
    docstring: The service account used to generate an OpenID Connect (OIDC)-compatible JWT token signed by the Google OIDC Provider (accounts.google.com) for extension endpoint (https://cloud.google.com/iam/docs/create-short-lived-credentials-direct#sa-credentials-oidc). - The audience for the token will be set to the URL in the server url defined in the OpenApi spec. - If the service account is provided, the service account should grant `iam.serviceAccounts.getOpenIdToken` permission to Vertex AI Extension Service Agent (https://cloud.google.com/vertex-ai/docs/general/access-control#service-agents).
  omitted_inherited_members_from:
  - TypedDict
- rank: 1987
  id: google.genai.types.AuthToken
  name: AuthToken
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Config for auth_tokens.create parameters.


    [Note: Inherited members from _common.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, name: typing.Optional[str] = None):'
  properties:
  - signature: 'name: typing.Optional[str]'
  omitted_inherited_members_from:
  - _common.BaseModel
- rank: 1988
  id: google.genai.types.AuthTokenDict
  name: AuthTokenDict
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Config for auth_tokens.create parameters.


    [Note: Inherited members from TypedDict are omitted.]'
  properties:
  - signature: 'name: typing.Optional[str]'
    docstring: The name of the auth token.
  omitted_inherited_members_from:
  - TypedDict
- rank: 1989
  id: google.genai.types.AuthType
  name: AuthType
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Type of auth scheme. This enum is not supported in Gemini API.


    [Note: Inherited members from _common.CaseInSensitiveEnum are omitted.]'
  properties:
  - signature: 'AUTH_TYPE_UNSPECIFIED: str'
  - signature: 'NO_AUTH: str'
    docstring: No Auth.
  - signature: 'API_KEY_AUTH: str'
    docstring: API Key Auth.
  - signature: 'HTTP_BASIC_AUTH: str'
    docstring: HTTP Basic Auth.
  - signature: 'GOOGLE_SERVICE_ACCOUNT_AUTH: str'
    docstring: Google Service Account Auth.
  - signature: 'OAUTH: str'
    docstring: OAuth auth.
  - signature: 'OIDC_AUTH: str'
    docstring: OpenID Connect (OIDC) Auth.
  omitted_inherited_members_from:
  - _common.CaseInSensitiveEnum
- rank: 1990
  id: google.genai.types.AutomaticActivityDetection
  name: AutomaticActivityDetection
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Configures automatic detection of activity.


    [Note: Inherited members from _common.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, disabled: typing.Optional[bool] = None, start_of_speech_sensitivity: typing.Optional[google.genai.types.StartSensitivity] = None, end_of_speech_sensitivity: typing.Optional[google.genai.types.EndSensitivity] = None, prefix_padding_ms: typing.Optional[int] = None, silence_duration_ms: typing.Optional[int] = None):'
  properties:
  - signature: 'disabled: typing.Optional[bool]'
  - signature: 'start_of_speech_sensitivity: typing.Optional[google.genai.types.StartSensitivity]'
  - signature: 'end_of_speech_sensitivity: typing.Optional[google.genai.types.EndSensitivity]'
  - signature: 'prefix_padding_ms: typing.Optional[int]'
  - signature: 'silence_duration_ms: typing.Optional[int]'
  omitted_inherited_members_from:
  - _common.BaseModel
- rank: 1991
  id: google.genai.types.AutomaticActivityDetectionDict
  name: AutomaticActivityDetectionDict
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Configures automatic detection of activity.


    [Note: Inherited members from TypedDict are omitted.]'
  properties:
  - signature: 'disabled: typing.Optional[bool]'
    docstring: If enabled, detected voice and text input count as activity. If disabled, the client must send activity signals.
  - signature: 'start_of_speech_sensitivity: typing.Optional[google.genai.types.StartSensitivity]'
    docstring: Determines how likely speech is to be detected.
  - signature: 'end_of_speech_sensitivity: typing.Optional[google.genai.types.EndSensitivity]'
    docstring: Determines how likely detected speech is ended.
  - signature: 'prefix_padding_ms: typing.Optional[int]'
    docstring: The required duration of detected speech before start-of-speech is committed. The lower this value the more sensitive the start-of-speech detection is and the shorter speech can be recognized. However, this also increases the probability of false positives.
  - signature: 'silence_duration_ms: typing.Optional[int]'
    docstring: The required duration of detected non-speech (e.g. silence) before end-of-speech is committed. The larger this value, the longer speech gaps can be without interrupting the user's activity but this will increase the model's latency.
  omitted_inherited_members_from:
  - TypedDict
- rank: 1992
  id: google.genai.types.AutomaticFunctionCallingConfig
  name: AutomaticFunctionCallingConfig
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'The configuration for automatic function calling.


    [Note: Inherited members from _common.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, disable: typing.Optional[bool] = None, maximum_remote_calls: typing.Optional[int] = 10, ignore_call_history: typing.Optional[bool] = None):'
  properties:
  - signature: 'disable: typing.Optional[bool]'
  - signature: 'maximum_remote_calls: typing.Optional[int]'
  - signature: 'ignore_call_history: typing.Optional[bool]'
  omitted_inherited_members_from:
  - _common.BaseModel
- rank: 1993
  id: google.genai.types.AutomaticFunctionCallingConfigDict
  name: AutomaticFunctionCallingConfigDict
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'The configuration for automatic function calling.


    [Note: Inherited members from TypedDict are omitted.]'
  properties:
  - signature: 'disable: typing.Optional[bool]'
    docstring: 'Whether to disable automatic function calling.

      If not set or set to False, will enable automatic function calling.

      If set to True, will disable automatic function calling.'
  - signature: 'maximum_remote_calls: typing.Optional[int]'
    docstring: 'If automatic function calling is enabled,

      maximum number of remote calls for automatic function calling.

      This number should be a positive integer.

      If not set, SDK will set maximum number of remote calls to 10.'
  - signature: 'ignore_call_history: typing.Optional[bool]'
    docstring: 'If automatic function calling is enabled,

      whether to ignore call history to the response.

      If not set, SDK will set ignore_call_history to false,

      and will append the call history to

      GenerateContentResponse.automatic_function_calling_history.'
  omitted_inherited_members_from:
  - TypedDict
- rank: 1994
  id: google.genai.types.AutoraterConfig
  name: AutoraterConfig
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Autorater config used for evaluation.


    [Note: Inherited members from _common.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, sampling_count: typing.Optional[int] = None, flip_enabled: typing.Optional[bool] = None, autorater_model: typing.Optional[str] = None, generation_config: typing.Optional[google.genai.types.GenerationConfig] = None):'
  properties:
  - signature: 'sampling_count: typing.Optional[int]'
  - signature: 'flip_enabled: typing.Optional[bool]'
  - signature: 'autorater_model: typing.Optional[str]'
  - signature: 'generation_config: typing.Optional[google.genai.types.GenerationConfig]'
  omitted_inherited_members_from:
  - _common.BaseModel
- rank: 1995
  id: google.genai.types.AutoraterConfigDict
  name: AutoraterConfigDict
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Autorater config used for evaluation.


    [Note: Inherited members from TypedDict are omitted.]'
  properties:
  - signature: 'sampling_count: typing.Optional[int]'
    docstring: 'Number of samples for each instance in the dataset.

      If not specified, the default is 4. Minimum value is 1, maximum value

      is 32.'
  - signature: 'flip_enabled: typing.Optional[bool]'
    docstring: 'Optional. Default is true. Whether to flip the candidate and baseline

      responses. This is only applicable to the pairwise metric. If enabled, also

      provide PairwiseMetricSpec.candidate_response_field_name and

      PairwiseMetricSpec.baseline_response_field_name. When rendering

      PairwiseMetricSpec.metric_prompt_template, the candidate and baseline

      fields will be flipped for half of the samples to reduce bias.'
  - signature: 'autorater_model: typing.Optional[str]'
    docstring: 'The fully qualified name of the publisher model or tuned autorater

      endpoint to use.


      Publisher model format:

      `projects/{project}/locations/{location}/publishers/{publisher}/models/{model}`


      Tuned model endpoint format:

      `projects/{project}/locations/{location}/endpoints/{endpoint}`'
  - signature: 'generation_config: typing.Optional[google.genai.types.GenerationConfigDict]'
    docstring: Configuration options for model generation and outputs.
  omitted_inherited_members_from:
  - TypedDict
- rank: 1996
  id: google.genai.types.BatchJob
  name: BatchJob
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Config for batches.create return value.


    [Note: Inherited members from _common.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, name: typing.Optional[str] = None, display_name: typing.Optional[str] = None, state: typing.Optional[google.genai.types.JobState] = None, error: typing.Optional[google.genai.types.JobError] = None, create_time: typing.Optional[datetime.datetime] = None, start_time: typing.Optional[datetime.datetime] = None, end_time: typing.Optional[datetime.datetime] = None, update_time: typing.Optional[datetime.datetime] = None, model: typing.Optional[str] = None, src: typing.Optional[google.genai.types.BatchJobSource] = None, dest: typing.Optional[google.genai.types.BatchJobDestination] = None, completion_stats: typing.Optional[google.genai.types.CompletionStats] = None):'
  methods:
  - signature: 'def done(self) -> bool:'
    docstring: Returns True if the batch job has ended.
  properties:
  - signature: 'name: typing.Optional[str]'
  - signature: 'display_name: typing.Optional[str]'
  - signature: 'state: typing.Optional[google.genai.types.JobState]'
  - signature: 'error: typing.Optional[google.genai.types.JobError]'
  - signature: 'create_time: typing.Optional[datetime.datetime]'
  - signature: 'start_time: typing.Optional[datetime.datetime]'
  - signature: 'end_time: typing.Optional[datetime.datetime]'
  - signature: 'update_time: typing.Optional[datetime.datetime]'
  - signature: 'model: typing.Optional[str]'
  - signature: 'src: typing.Optional[google.genai.types.BatchJobSource]'
  - signature: 'dest: typing.Optional[google.genai.types.BatchJobDestination]'
  - signature: 'completion_stats: typing.Optional[google.genai.types.CompletionStats]'
  omitted_inherited_members_from:
  - _common.BaseModel
- rank: 1997
  id: google.genai.types.BatchJob.done
  name: done
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: Returns True if the batch job has ended.
  signature: 'def done(self) -> bool:'
- rank: 1998
  id: google.genai.types.BatchJobDestination
  name: BatchJobDestination
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Config for `des` parameter.


    [Note: Inherited members from _common.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, format: typing.Optional[str] = None, gcs_uri: typing.Optional[str] = None, bigquery_uri: typing.Optional[str] = None, file_name: typing.Optional[str] = None, inlined_responses: typing.Optional[list[google.genai.types.InlinedResponse]] = None, inlined_embed_content_responses: typing.Optional[list[google.genai.types.InlinedEmbedContentResponse]] = None):'
  properties:
  - signature: 'format: typing.Optional[str]'
  - signature: 'gcs_uri: typing.Optional[str]'
  - signature: 'bigquery_uri: typing.Optional[str]'
  - signature: 'file_name: typing.Optional[str]'
  - signature: 'inlined_responses: typing.Optional[list[google.genai.types.InlinedResponse]]'
  - signature: 'inlined_embed_content_responses: typing.Optional[list[google.genai.types.InlinedEmbedContentResponse]]'
  omitted_inherited_members_from:
  - _common.BaseModel
- rank: 1999
  id: google.genai.types.BatchJobDestinationDict
  name: BatchJobDestinationDict
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Config for `des` parameter.


    [Note: Inherited members from TypedDict are omitted.]'
  properties:
  - signature: 'format: typing.Optional[str]'
    docstring: 'Storage format of the output files. Must be one of:

      ''jsonl'', ''bigquery''.'
  - signature: 'gcs_uri: typing.Optional[str]'
    docstring: "The Google Cloud Storage URI to the output file.\n      "
  - signature: 'bigquery_uri: typing.Optional[str]'
    docstring: "The BigQuery URI to the output table.\n      "
  - signature: 'file_name: typing.Optional[str]'
    docstring: 'The Gemini Developer API''s file resource name of the output data

      (e.g. "files/12345"). The file will be a JSONL file with a single response

      per line. The responses will be GenerateContentResponse messages formatted

      as JSON. The responses will be written in the same order as the input

      requests.'
  - signature: 'inlined_responses: typing.Optional[list[google.genai.types.InlinedResponseDict]]'
    docstring: 'The responses to the requests in the batch. Returned when the batch was

      built using inlined requests. The responses will be in the same order as

      the input requests.'
  - signature: 'inlined_embed_content_responses: typing.Optional[list[google.genai.types.InlinedEmbedContentResponseDict]]'
    docstring: 'The responses to the requests in the batch. Returned when the batch was

      built using inlined requests. The responses will be in the same order as

      the input requests.'
  omitted_inherited_members_from:
  - TypedDict
- rank: 2000
  id: google.genai.types.BatchJobDict
  name: BatchJobDict
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Config for batches.create return value.


    [Note: Inherited members from TypedDict are omitted.]'
  properties:
  - signature: 'name: typing.Optional[str]'
    docstring: "The resource name of the BatchJob. Output only.\".\n      "
  - signature: 'display_name: typing.Optional[str]'
    docstring: "The display name of the BatchJob.\n      "
  - signature: 'state: typing.Optional[google.genai.types.JobState]'
    docstring: "The state of the BatchJob.\n      "
  - signature: 'error: typing.Optional[google.genai.types.JobErrorDict]'
    docstring: Output only. Only populated when the job's state is JOB_STATE_FAILED or JOB_STATE_CANCELLED.
  - signature: 'create_time: typing.Optional[datetime.datetime]'
    docstring: "The time when the BatchJob was created.\n      "
  - signature: 'start_time: typing.Optional[datetime.datetime]'
    docstring: Output only. Time when the Job for the first time entered the `JOB_STATE_RUNNING` state.
  - signature: 'end_time: typing.Optional[datetime.datetime]'
    docstring: "The time when the BatchJob was completed. This field is for Vertex AI only.\n      "
  - signature: 'update_time: typing.Optional[datetime.datetime]'
    docstring: "The time when the BatchJob was last updated.\n      "
  - signature: 'model: typing.Optional[str]'
    docstring: "The name of the model that produces the predictions via the BatchJob.\n      "
  - signature: 'src: typing.Optional[google.genai.types.BatchJobSourceDict]'
    docstring: "Configuration for the input data. This field is for Vertex AI only.\n      "
  - signature: 'dest: typing.Optional[google.genai.types.BatchJobDestinationDict]'
    docstring: "Configuration for the output data.\n      "
  - signature: 'completion_stats: typing.Optional[google.genai.types.CompletionStatsDict]'
    docstring: "Statistics on completed and failed prediction instances. This field is for Vertex AI only.\n      "
  omitted_inherited_members_from:
  - TypedDict
- rank: 2001
  id: google.genai.types.BatchJobSource
  name: BatchJobSource
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Config for `src` parameter.


    [Note: Inherited members from _common.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, format: typing.Optional[str] = None, gcs_uri: typing.Optional[list[str]] = None, bigquery_uri: typing.Optional[str] = None, file_name: typing.Optional[str] = None, inlined_requests: typing.Optional[list[google.genai.types.InlinedRequest]] = None):'
  properties:
  - signature: 'format: typing.Optional[str]'
  - signature: 'gcs_uri: typing.Optional[list[str]]'
  - signature: 'bigquery_uri: typing.Optional[str]'
  - signature: 'file_name: typing.Optional[str]'
  - signature: 'inlined_requests: typing.Optional[list[google.genai.types.InlinedRequest]]'
  omitted_inherited_members_from:
  - _common.BaseModel
- rank: 2002
  id: google.genai.types.BatchJobSourceDict
  name: BatchJobSourceDict
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Config for `src` parameter.


    [Note: Inherited members from TypedDict are omitted.]'
  properties:
  - signature: 'format: typing.Optional[str]'
    docstring: 'Storage format of the input files. Must be one of:

      ''jsonl'', ''bigquery''.'
  - signature: 'gcs_uri: typing.Optional[list[str]]'
    docstring: "The Google Cloud Storage URIs to input files.\n      "
  - signature: 'bigquery_uri: typing.Optional[str]'
    docstring: "The BigQuery URI to input table.\n      "
  - signature: 'file_name: typing.Optional[str]'
    docstring: 'The Gemini Developer API''s file resource name of the input data

      (e.g. "files/12345").'
  - signature: 'inlined_requests: typing.Optional[list[google.genai.types.InlinedRequestDict]]'
    docstring: "The Gemini Developer API's inlined input data to run batch job.\n      "
  omitted_inherited_members_from:
  - TypedDict
- rank: 2003
  id: google.genai.types.Behavior
  name: Behavior
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Defines the function behavior. Defaults to `BLOCKING`.


    [Note: Inherited members from _common.CaseInSensitiveEnum are omitted.]'
  properties:
  - signature: 'UNSPECIFIED: str'
    docstring: This value is unused.
  - signature: 'BLOCKING: str'
    docstring: If set, the system will wait to receive the function response before continuing the conversation.
  - signature: 'NON_BLOCKING: str'
    docstring: If set, the system will not wait to receive the function response. Instead, it will attempt to handle function responses as they become available while maintaining the conversation between the user and the model.
  omitted_inherited_members_from:
  - _common.CaseInSensitiveEnum
- rank: 2004
  id: google.genai.types.BleuSpec
  name: BleuSpec
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Spec for bleu metric.


    [Note: Inherited members from _common.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, use_effective_order: typing.Optional[bool] = None):'
  properties:
  - signature: 'use_effective_order: typing.Optional[bool]'
  omitted_inherited_members_from:
  - _common.BaseModel
- rank: 2005
  id: google.genai.types.BleuSpecDict
  name: BleuSpecDict
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Spec for bleu metric.


    [Note: Inherited members from TypedDict are omitted.]'
  properties:
  - signature: 'use_effective_order: typing.Optional[bool]'
    docstring: Optional. Whether to use_effective_order to compute bleu score.
  omitted_inherited_members_from:
  - TypedDict
- rank: 2006
  id: google.genai.types.Blob
  name: Blob
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Content blob.


    [Note: Inherited members from _common.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, data: typing.Optional[bytes] = None, display_name: typing.Optional[str] = None, mime_type: typing.Optional[str] = None):'
  methods:
  - signature: 'def as_image(self) -> typing.Optional[google.genai.types.Image]:'
    docstring: Returns the Blob as a Image, or None if the Blob is not an image.
  properties:
  - signature: 'data: typing.Optional[bytes]'
  - signature: 'display_name: typing.Optional[str]'
  - signature: 'mime_type: typing.Optional[str]'
  omitted_inherited_members_from:
  - _common.BaseModel
- rank: 2007
  id: google.genai.types.Blob.as_image
  name: as_image
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: Returns the Blob as a Image, or None if the Blob is not an image.
  signature: 'def as_image(self) -> typing.Optional[google.genai.types.Image]:'
- rank: 2008
  id: google.genai.types.BlobDict
  name: BlobDict
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Content blob.


    [Note: Inherited members from TypedDict are omitted.]'
  properties:
  - signature: 'data: typing.Optional[bytes]'
    docstring: Required. Raw bytes.
  - signature: 'display_name: typing.Optional[str]'
    docstring: Optional. Display name of the blob. Used to provide a label or filename to distinguish blobs. This field is only returned in PromptMessage for prompt management. It is currently used in the Gemini GenerateContent calls only when server side tools (code_execution, google_search, and url_context) are enabled. This field is not supported in Gemini API.
  - signature: 'mime_type: typing.Optional[str]'
    docstring: Required. The IANA standard MIME type of the source data.
  omitted_inherited_members_from:
  - TypedDict
- rank: 2009
  id: google.genai.types.BlockedReason
  name: BlockedReason
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Output only. The reason why the prompt was blocked.


    [Note: Inherited members from _common.CaseInSensitiveEnum are omitted.]'
  properties:
  - signature: 'BLOCKED_REASON_UNSPECIFIED: str'
    docstring: The blocked reason is unspecified.
  - signature: 'SAFETY: str'
    docstring: The prompt was blocked for safety reasons.
  - signature: 'OTHER: str'
    docstring: The prompt was blocked for other reasons. For example, it may be due to the prompt's language, or because it contains other harmful content.
  - signature: 'BLOCKLIST: str'
    docstring: The prompt was blocked because it contains a term from the terminology blocklist.
  - signature: 'PROHIBITED_CONTENT: str'
    docstring: The prompt was blocked because it contains prohibited content.
  - signature: 'IMAGE_SAFETY: str'
    docstring: The prompt was blocked because it contains content that is unsafe for image generation.
  - signature: 'MODEL_ARMOR: str'
    docstring: The prompt was blocked by Model Armor. This enum value is not supported in Gemini API.
  - signature: 'JAILBREAK: str'
    docstring: The prompt was blocked as a jailbreak attempt. This enum value is not supported in Gemini API.
  omitted_inherited_members_from:
  - _common.CaseInSensitiveEnum
- rank: 2010
  id: google.genai.types.CachedContent
  name: CachedContent
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'A resource used in LLM queries for users to explicitly specify what to cache.


    [Note: Inherited members from _common.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, name: typing.Optional[str] = None, display_name: typing.Optional[str] = None, model: typing.Optional[str] = None, create_time: typing.Optional[datetime.datetime] = None, update_time: typing.Optional[datetime.datetime] = None, expire_time: typing.Optional[datetime.datetime] = None, usage_metadata: typing.Optional[google.genai.types.CachedContentUsageMetadata] = None):'
  properties:
  - signature: 'name: typing.Optional[str]'
  - signature: 'display_name: typing.Optional[str]'
  - signature: 'model: typing.Optional[str]'
  - signature: 'create_time: typing.Optional[datetime.datetime]'
  - signature: 'update_time: typing.Optional[datetime.datetime]'
  - signature: 'expire_time: typing.Optional[datetime.datetime]'
  - signature: 'usage_metadata: typing.Optional[google.genai.types.CachedContentUsageMetadata]'
  omitted_inherited_members_from:
  - _common.BaseModel
- rank: 2011
  id: google.genai.types.CachedContentDict
  name: CachedContentDict
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'A resource used in LLM queries for users to explicitly specify what to cache.


    [Note: Inherited members from TypedDict are omitted.]'
  properties:
  - signature: 'name: typing.Optional[str]'
    docstring: The server-generated resource name of the cached content.
  - signature: 'display_name: typing.Optional[str]'
    docstring: The user-generated meaningful display name of the cached content.
  - signature: 'model: typing.Optional[str]'
    docstring: The name of the publisher model to use for cached content.
  - signature: 'create_time: typing.Optional[datetime.datetime]'
    docstring: Creation time of the cache entry.
  - signature: 'update_time: typing.Optional[datetime.datetime]'
    docstring: When the cache entry was last updated in UTC time.
  - signature: 'expire_time: typing.Optional[datetime.datetime]'
    docstring: Expiration time of the cached content.
  - signature: 'usage_metadata: typing.Optional[google.genai.types.CachedContentUsageMetadataDict]'
    docstring: Metadata on the usage of the cached content.
  omitted_inherited_members_from:
  - TypedDict
- rank: 2012
  id: google.genai.types.CachedContentUsageMetadata
  name: CachedContentUsageMetadata
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Metadata on the usage of the cached content.


    [Note: Inherited members from _common.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, audio_duration_seconds: typing.Optional[int] = None, image_count: typing.Optional[int] = None, text_count: typing.Optional[int] = None, total_token_count: typing.Optional[int] = None, video_duration_seconds: typing.Optional[int] = None):'
  properties:
  - signature: 'audio_duration_seconds: typing.Optional[int]'
  - signature: 'image_count: typing.Optional[int]'
  - signature: 'text_count: typing.Optional[int]'
  - signature: 'total_token_count: typing.Optional[int]'
  - signature: 'video_duration_seconds: typing.Optional[int]'
  omitted_inherited_members_from:
  - _common.BaseModel
- rank: 2013
  id: google.genai.types.CachedContentUsageMetadataDict
  name: CachedContentUsageMetadataDict
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Metadata on the usage of the cached content.


    [Note: Inherited members from TypedDict are omitted.]'
  properties:
  - signature: 'audio_duration_seconds: typing.Optional[int]'
    docstring: Duration of audio in seconds. This field is not supported in Gemini API.
  - signature: 'image_count: typing.Optional[int]'
    docstring: Number of images. This field is not supported in Gemini API.
  - signature: 'text_count: typing.Optional[int]'
    docstring: Number of text characters. This field is not supported in Gemini API.
  - signature: 'total_token_count: typing.Optional[int]'
    docstring: Total number of tokens that the cached content consumes.
  - signature: 'video_duration_seconds: typing.Optional[int]'
    docstring: Duration of video in seconds. This field is not supported in Gemini API.
  omitted_inherited_members_from:
  - TypedDict
- rank: 2014
  id: google.genai.types.CancelBatchJobConfig
  name: CancelBatchJobConfig
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Optional parameters.


    [Note: Inherited members from _common.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, http_options: typing.Optional[google.genai.types.HttpOptions] = None):'
  properties:
  - signature: 'http_options: typing.Optional[google.genai.types.HttpOptions]'
  omitted_inherited_members_from:
  - _common.BaseModel
- rank: 2015
  id: google.genai.types.CancelBatchJobConfigDict
  name: CancelBatchJobConfigDict
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Optional parameters.


    [Note: Inherited members from TypedDict are omitted.]'
  properties:
  - signature: 'http_options: typing.Optional[google.genai.types.HttpOptionsDict]'
    docstring: Used to override HTTP request options.
  omitted_inherited_members_from:
  - TypedDict
- rank: 2016
  id: google.genai.types.CancelTuningJobConfig
  name: CancelTuningJobConfig
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Optional parameters for tunings.cancel method.


    [Note: Inherited members from _common.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, http_options: typing.Optional[google.genai.types.HttpOptions] = None):'
  properties:
  - signature: 'http_options: typing.Optional[google.genai.types.HttpOptions]'
  omitted_inherited_members_from:
  - _common.BaseModel
- rank: 2017
  id: google.genai.types.CancelTuningJobConfigDict
  name: CancelTuningJobConfigDict
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Optional parameters for tunings.cancel method.


    [Note: Inherited members from TypedDict are omitted.]'
  properties:
  - signature: 'http_options: typing.Optional[google.genai.types.HttpOptionsDict]'
    docstring: Used to override HTTP request options.
  omitted_inherited_members_from:
  - TypedDict
- rank: 2018
  id: google.genai.types.CancelTuningJobResponse
  name: CancelTuningJobResponse
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Empty response for tunings.cancel method.


    [Note: Inherited members from _common.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, sdk_http_response: typing.Optional[google.genai.types.HttpResponse] = None):'
  properties:
  - signature: 'sdk_http_response: typing.Optional[google.genai.types.HttpResponse]'
  omitted_inherited_members_from:
  - _common.BaseModel
- rank: 2019
  id: google.genai.types.CancelTuningJobResponseDict
  name: CancelTuningJobResponseDict
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Empty response for tunings.cancel method.


    [Note: Inherited members from TypedDict are omitted.]'
  properties:
  - signature: 'sdk_http_response: typing.Optional[google.genai.types.HttpResponseDict]'
    docstring: Used to retain the full HTTP response.
  omitted_inherited_members_from:
  - TypedDict
- rank: 2020
  id: google.genai.types.Candidate
  name: Candidate
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'A response candidate generated from the model.


    [Note: Inherited members from _common.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, content: typing.Optional[google.genai.types.Content] = None, citation_metadata: typing.Optional[google.genai.types.CitationMetadata] = None, finish_message: typing.Optional[str] = None, token_count: typing.Optional[int] = None, finish_reason: typing.Optional[google.genai.types.FinishReason] = None, avg_logprobs: typing.Optional[float] = None, grounding_metadata: typing.Optional[google.genai.types.GroundingMetadata] = None, index: typing.Optional[int] = None, logprobs_result: typing.Optional[google.genai.types.LogprobsResult] = None, safety_ratings: typing.Optional[list[google.genai.types.SafetyRating]] = None, url_context_metadata: typing.Optional[google.genai.types.UrlContextMetadata] = None):'
  properties:
  - signature: 'content: typing.Optional[google.genai.types.Content]'
  - signature: 'citation_metadata: typing.Optional[google.genai.types.CitationMetadata]'
  - signature: 'finish_message: typing.Optional[str]'
  - signature: 'token_count: typing.Optional[int]'
  - signature: 'finish_reason: typing.Optional[google.genai.types.FinishReason]'
  - signature: 'avg_logprobs: typing.Optional[float]'
  - signature: 'grounding_metadata: typing.Optional[google.genai.types.GroundingMetadata]'
  - signature: 'index: typing.Optional[int]'
  - signature: 'logprobs_result: typing.Optional[google.genai.types.LogprobsResult]'
  - signature: 'safety_ratings: typing.Optional[list[google.genai.types.SafetyRating]]'
  - signature: 'url_context_metadata: typing.Optional[google.genai.types.UrlContextMetadata]'
  omitted_inherited_members_from:
  - _common.BaseModel
- rank: 2021
  id: google.genai.types.CandidateDict
  name: CandidateDict
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'A response candidate generated from the model.


    [Note: Inherited members from TypedDict are omitted.]'
  properties:
  - signature: 'content: typing.Optional[google.genai.types.ContentDict]'
    docstring: "Contains the multi-part content of the response.\n      "
  - signature: 'citation_metadata: typing.Optional[google.genai.types.CitationMetadataDict]'
    docstring: "Source attribution of the generated content.\n      "
  - signature: 'finish_message: typing.Optional[str]'
    docstring: "Describes the reason the model stopped generating tokens.\n      "
  - signature: 'token_count: typing.Optional[int]'
    docstring: "Number of tokens for this candidate.\n      "
  - signature: 'finish_reason: typing.Optional[google.genai.types.FinishReason]'
    docstring: 'The reason why the model stopped generating tokens.

      If empty, the model has not stopped generating the tokens.'
  - signature: 'avg_logprobs: typing.Optional[float]'
    docstring: Output only. Average log probability score of the candidate.
  - signature: 'grounding_metadata: typing.Optional[google.genai.types.GroundingMetadataDict]'
    docstring: Output only. Metadata specifies sources used to ground generated content.
  - signature: 'index: typing.Optional[int]'
    docstring: Output only. Index of the candidate.
  - signature: 'logprobs_result: typing.Optional[google.genai.types.LogprobsResultDict]'
    docstring: Output only. Log-likelihood scores for the response tokens and top tokens
  - signature: 'safety_ratings: typing.Optional[list[google.genai.types.SafetyRatingDict]]'
    docstring: Output only. List of ratings for the safety of a response candidate. There is at most one rating per category.
  - signature: 'url_context_metadata: typing.Optional[google.genai.types.UrlContextMetadataDict]'
    docstring: Output only. Metadata related to url context retrieval tool.
  omitted_inherited_members_from:
  - TypedDict
- rank: 2022
  id: google.genai.types.Checkpoint
  name: Checkpoint
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Describes the machine learning model version checkpoint.


    [Note: Inherited members from _common.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, checkpoint_id: typing.Optional[str] = None, epoch: typing.Optional[int] = None, step: typing.Optional[int] = None):'
  properties:
  - signature: 'checkpoint_id: typing.Optional[str]'
  - signature: 'epoch: typing.Optional[int]'
  - signature: 'step: typing.Optional[int]'
  omitted_inherited_members_from:
  - _common.BaseModel
- rank: 2023
  id: google.genai.types.CheckpointDict
  name: CheckpointDict
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Describes the machine learning model version checkpoint.


    [Note: Inherited members from TypedDict are omitted.]'
  properties:
  - signature: 'checkpoint_id: typing.Optional[str]'
    docstring: "The ID of the checkpoint.\n      "
  - signature: 'epoch: typing.Optional[int]'
    docstring: "The epoch of the checkpoint.\n      "
  - signature: 'step: typing.Optional[int]'
    docstring: "The step of the checkpoint.\n      "
  omitted_inherited_members_from:
  - TypedDict
- rank: 2024
  id: google.genai.types.ChunkingConfig
  name: ChunkingConfig
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Config for telling the service how to chunk the file.


    [Note: Inherited members from _common.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, white_space_config: typing.Optional[google.genai.types.WhiteSpaceConfig] = None):'
  properties:
  - signature: 'white_space_config: typing.Optional[google.genai.types.WhiteSpaceConfig]'
  omitted_inherited_members_from:
  - _common.BaseModel
- rank: 2025
  id: google.genai.types.ChunkingConfigDict
  name: ChunkingConfigDict
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Config for telling the service how to chunk the file.


    [Note: Inherited members from TypedDict are omitted.]'
  properties:
  - signature: 'white_space_config: typing.Optional[google.genai.types.WhiteSpaceConfigDict]'
    docstring: White space chunking configuration.
  omitted_inherited_members_from:
  - TypedDict
- rank: 2026
  id: google.genai.types.Citation
  name: Citation
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Source attributions for content.


    This data type is not supported in Gemini API.


    [Note: Inherited members from _common.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, end_index: typing.Optional[int] = None, license: typing.Optional[str] = None, publication_date: typing.Optional[google.genai.types.GoogleTypeDate] = None, start_index: typing.Optional[int] = None, title: typing.Optional[str] = None, uri: typing.Optional[str] = None):'
  properties:
  - signature: 'end_index: typing.Optional[int]'
  - signature: 'license: typing.Optional[str]'
  - signature: 'publication_date: typing.Optional[google.genai.types.GoogleTypeDate]'
  - signature: 'start_index: typing.Optional[int]'
  - signature: 'title: typing.Optional[str]'
  - signature: 'uri: typing.Optional[str]'
  omitted_inherited_members_from:
  - _common.BaseModel
- rank: 2027
  id: google.genai.types.CitationDict
  name: CitationDict
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Source attributions for content.


    This data type is not supported in Gemini API.


    [Note: Inherited members from TypedDict are omitted.]'
  properties:
  - signature: 'end_index: typing.Optional[int]'
    docstring: Output only. End index into the content.
  - signature: 'license: typing.Optional[str]'
    docstring: Output only. License of the attribution.
  - signature: 'publication_date: typing.Optional[google.genai.types.GoogleTypeDateDict]'
    docstring: Output only. Publication date of the attribution.
  - signature: 'start_index: typing.Optional[int]'
    docstring: Output only. Start index into the content.
  - signature: 'title: typing.Optional[str]'
    docstring: Output only. Title of the attribution.
  - signature: 'uri: typing.Optional[str]'
    docstring: Output only. Url reference of the attribution.
  omitted_inherited_members_from:
  - TypedDict
- rank: 2028
  id: google.genai.types.CitationMetadata
  name: CitationMetadata
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Citation information when the model quotes another source.


    [Note: Inherited members from _common.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, citations: typing.Optional[list[google.genai.types.Citation]] = None):'
  properties:
  - signature: 'citations: typing.Optional[list[google.genai.types.Citation]]'
  omitted_inherited_members_from:
  - _common.BaseModel
- rank: 2029
  id: google.genai.types.CitationMetadataDict
  name: CitationMetadataDict
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Citation information when the model quotes another source.


    [Note: Inherited members from TypedDict are omitted.]'
  properties:
  - signature: 'citations: typing.Optional[list[google.genai.types.CitationDict]]'
    docstring: 'Contains citation information when the model directly quotes, at

      length, from another source. Can include traditional websites and code

      repositories.'
  omitted_inherited_members_from:
  - TypedDict
- rank: 2030
  id: google.genai.types.CodeExecutionResult
  name: CodeExecutionResult
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Result of executing the [ExecutableCode].


    Only generated when using the [CodeExecution] tool, and always follows a

    `part` containing the [ExecutableCode].


    [Note: Inherited members from _common.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, outcome: typing.Optional[google.genai.types.Outcome] = None, output: typing.Optional[str] = None):'
  properties:
  - signature: 'outcome: typing.Optional[google.genai.types.Outcome]'
  - signature: 'output: typing.Optional[str]'
  omitted_inherited_members_from:
  - _common.BaseModel
- rank: 2031
  id: google.genai.types.CodeExecutionResultDict
  name: CodeExecutionResultDict
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Result of executing the [ExecutableCode].


    Only generated when using the [CodeExecution] tool, and always follows a

    `part` containing the [ExecutableCode].


    [Note: Inherited members from TypedDict are omitted.]'
  properties:
  - signature: 'outcome: typing.Optional[google.genai.types.Outcome]'
    docstring: Required. Outcome of the code execution.
  - signature: 'output: typing.Optional[str]'
    docstring: Optional. Contains stdout when code execution is successful, stderr or other description otherwise.
  omitted_inherited_members_from:
  - TypedDict
- rank: 2032
  id: google.genai.types.CompletionStats
  name: CompletionStats
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Success and error statistics of processing multiple entities (for example, DataItems or structured data rows) in batch.


    This data type is not supported in Gemini API.


    [Note: Inherited members from _common.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, failed_count: typing.Optional[int] = None, incomplete_count: typing.Optional[int] = None, successful_count: typing.Optional[int] = None, successful_forecast_point_count: typing.Optional[int] = None):'
  properties:
  - signature: 'failed_count: typing.Optional[int]'
  - signature: 'incomplete_count: typing.Optional[int]'
  - signature: 'successful_count: typing.Optional[int]'
  - signature: 'successful_forecast_point_count: typing.Optional[int]'
  omitted_inherited_members_from:
  - _common.BaseModel
- rank: 2033
  id: google.genai.types.CompletionStatsDict
  name: CompletionStatsDict
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Success and error statistics of processing multiple entities (for example, DataItems or structured data rows) in batch.


    This data type is not supported in Gemini API.


    [Note: Inherited members from TypedDict are omitted.]'
  properties:
  - signature: 'failed_count: typing.Optional[int]'
    docstring: Output only. The number of entities for which any error was encountered.
  - signature: 'incomplete_count: typing.Optional[int]'
    docstring: Output only. In cases when enough errors are encountered a job, pipeline, or operation may be failed as a whole. Below is the number of entities for which the processing had not been finished (either in successful or failed state). Set to -1 if the number is unknown (for example, the operation failed before the total entity number could be collected).
  - signature: 'successful_count: typing.Optional[int]'
    docstring: Output only. The number of entities that had been processed successfully.
  - signature: 'successful_forecast_point_count: typing.Optional[int]'
    docstring: Output only. The number of the successful forecast points that are generated by the forecasting model. This is ONLY used by the forecasting batch prediction.
  omitted_inherited_members_from:
  - TypedDict
- rank: 2034
  id: google.genai.types.ComputeTokensConfig
  name: ComputeTokensConfig
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Optional parameters for computing tokens.


    [Note: Inherited members from _common.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, http_options: typing.Optional[google.genai.types.HttpOptions] = None):'
  properties:
  - signature: 'http_options: typing.Optional[google.genai.types.HttpOptions]'
  omitted_inherited_members_from:
  - _common.BaseModel
- rank: 2035
  id: google.genai.types.ComputeTokensConfigDict
  name: ComputeTokensConfigDict
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Optional parameters for computing tokens.


    [Note: Inherited members from TypedDict are omitted.]'
  properties:
  - signature: 'http_options: typing.Optional[google.genai.types.HttpOptionsDict]'
    docstring: Used to override HTTP request options.
  omitted_inherited_members_from:
  - TypedDict
- rank: 2036
  id: google.genai.types.ComputeTokensResponse
  name: ComputeTokensResponse
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Response for computing tokens.


    [Note: Inherited members from _common.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, sdk_http_response: typing.Optional[google.genai.types.HttpResponse] = None, tokens_info: typing.Optional[list[google.genai.types.TokensInfo]] = None):'
  properties:
  - signature: 'sdk_http_response: typing.Optional[google.genai.types.HttpResponse]'
  - signature: 'tokens_info: typing.Optional[list[google.genai.types.TokensInfo]]'
  omitted_inherited_members_from:
  - _common.BaseModel
- rank: 2037
  id: google.genai.types.ComputeTokensResponseDict
  name: ComputeTokensResponseDict
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Response for computing tokens.


    [Note: Inherited members from TypedDict are omitted.]'
  properties:
  - signature: 'sdk_http_response: typing.Optional[google.genai.types.HttpResponseDict]'
    docstring: Used to retain the full HTTP response.
  - signature: 'tokens_info: typing.Optional[list[google.genai.types.TokensInfoDict]]'
    docstring: Lists of tokens info from the input. A ComputeTokensRequest could have multiple instances with a prompt in each instance. We also need to return lists of tokens info for the request with multiple instances.
  omitted_inherited_members_from:
  - TypedDict
- rank: 2038
  id: google.genai.types.ComputeTokensResult
  name: ComputeTokensResult
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Local tokenizer compute tokens result.


    [Note: Inherited members from _common.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, tokens_info: typing.Optional[list[google.genai.types.TokensInfo]] = None):'
  properties:
  - signature: 'tokens_info: typing.Optional[list[google.genai.types.TokensInfo]]'
  omitted_inherited_members_from:
  - _common.BaseModel
- rank: 2039
  id: google.genai.types.ComputeTokensResultDict
  name: ComputeTokensResultDict
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Local tokenizer compute tokens result.


    [Note: Inherited members from TypedDict are omitted.]'
  properties:
  - signature: 'tokens_info: typing.Optional[list[google.genai.types.TokensInfoDict]]'
    docstring: Lists of tokens info from the input.
  omitted_inherited_members_from:
  - TypedDict
- rank: 2040
  id: google.genai.types.ComputerUse
  name: ComputerUse
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Tool to support computer use.


    [Note: Inherited members from _common.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, environment: typing.Optional[google.genai.types.Environment] = None, excluded_predefined_functions: typing.Optional[list[str]] = None):'
  properties:
  - signature: 'environment: typing.Optional[google.genai.types.Environment]'
  - signature: 'excluded_predefined_functions: typing.Optional[list[str]]'
  omitted_inherited_members_from:
  - _common.BaseModel
- rank: 2041
  id: google.genai.types.ComputerUseDict
  name: ComputerUseDict
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Tool to support computer use.


    [Note: Inherited members from TypedDict are omitted.]'
  properties:
  - signature: 'environment: typing.Optional[google.genai.types.Environment]'
    docstring: Required. The environment being operated.
  - signature: 'excluded_predefined_functions: typing.Optional[list[str]]'
    docstring: "By default, predefined functions are included in the final model call.\nSome of them can be explicitly excluded from being automatically included.\nThis can serve two purposes:\n  1. Using a more restricted / different action space.\n  2. Improving the definitions / instructions of predefined functions."
  omitted_inherited_members_from:
  - TypedDict
- rank: 2042
  id: google.genai.types.Content
  name: Content
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Contains the multi-part content of a message.


    [Note: Inherited members from _common.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, parts: typing.Optional[list[google.genai.types.Part]] = None, role: typing.Optional[str] = None):'
  properties:
  - signature: 'parts: typing.Optional[list[google.genai.types.Part]]'
  - signature: 'role: typing.Optional[str]'
  omitted_inherited_members_from:
  - _common.BaseModel
- rank: 2043
  id: google.genai.types.ContentDict
  name: ContentDict
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Contains the multi-part content of a message.


    [Note: Inherited members from TypedDict are omitted.]'
  properties:
  - signature: 'parts: typing.Optional[list[google.genai.types.PartDict]]'
    docstring: 'List of parts that constitute a single message. Each part may have

      a different IANA MIME type.'
  - signature: 'role: typing.Optional[str]'
    docstring: Optional. The producer of the content. Must be either 'user' or 'model'. Useful to set for multi-turn conversations, otherwise can be left blank or unset.
  omitted_inherited_members_from:
  - TypedDict
- rank: 2044
  id: google.genai.types.ContentEmbedding
  name: ContentEmbedding
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'The embedding generated from an input content.


    [Note: Inherited members from _common.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, values: typing.Optional[list[float]] = None, statistics: typing.Optional[google.genai.types.ContentEmbeddingStatistics] = None):'
  properties:
  - signature: 'values: typing.Optional[list[float]]'
  - signature: 'statistics: typing.Optional[google.genai.types.ContentEmbeddingStatistics]'
  omitted_inherited_members_from:
  - _common.BaseModel
- rank: 2045
  id: google.genai.types.ContentEmbeddingDict
  name: ContentEmbeddingDict
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'The embedding generated from an input content.


    [Note: Inherited members from TypedDict are omitted.]'
  properties:
  - signature: 'values: typing.Optional[list[float]]'
    docstring: "A list of floats representing an embedding.\n      "
  - signature: 'statistics: typing.Optional[google.genai.types.ContentEmbeddingStatisticsDict]'
    docstring: 'Vertex API only. Statistics of the input text associated with this

      embedding.'
  omitted_inherited_members_from:
  - TypedDict
- rank: 2046
  id: google.genai.types.ContentEmbeddingStatistics
  name: ContentEmbeddingStatistics
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Statistics of the input text associated with the result of content embedding.


    [Note: Inherited members from _common.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, truncated: typing.Optional[bool] = None, token_count: typing.Optional[float] = None):'
  properties:
  - signature: 'truncated: typing.Optional[bool]'
  - signature: 'token_count: typing.Optional[float]'
  omitted_inherited_members_from:
  - _common.BaseModel
- rank: 2047
  id: google.genai.types.ContentEmbeddingStatisticsDict
  name: ContentEmbeddingStatisticsDict
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Statistics of the input text associated with the result of content embedding.


    [Note: Inherited members from TypedDict are omitted.]'
  properties:
  - signature: 'truncated: typing.Optional[bool]'
    docstring: 'Vertex API only. If the input text was truncated due to having

      a length longer than the allowed maximum input.'
  - signature: 'token_count: typing.Optional[float]'
    docstring: "Vertex API only. Number of tokens of the input text.\n      "
  omitted_inherited_members_from:
  - TypedDict
- rank: 2048
  id: google.genai.types.ContentReferenceImage
  name: ContentReferenceImage
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'A content reference image.


    A content reference image represents a subject to reference (ex. person,

    product, animal) provided by the user. It can optionally be provided in

    addition to a style reference image (ex. background, style reference).


    [Note: Inherited members from _common.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, reference_image: typing.Optional[google.genai.types.Image] = None, reference_id: typing.Optional[int] = None, reference_type: typing.Optional[str] = None):'
  properties:
  - signature: 'reference_image: typing.Optional[google.genai.types.Image]'
  - signature: 'reference_id: typing.Optional[int]'
  - signature: 'reference_type: typing.Optional[str]'
  omitted_inherited_members_from:
  - _common.BaseModel
- rank: 2049
  id: google.genai.types.ContentReferenceImageDict
  name: ContentReferenceImageDict
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'A content reference image.


    A content reference image represents a subject to reference (ex. person,

    product, animal) provided by the user. It can optionally be provided in

    addition to a style reference image (ex. background, style reference).


    [Note: Inherited members from TypedDict are omitted.]'
  properties:
  - signature: 'reference_image: typing.Optional[google.genai.types.ImageDict]'
    docstring: The reference image for the editing operation.
  - signature: 'reference_id: typing.Optional[int]'
    docstring: The id of the reference image.
  - signature: 'reference_type: typing.Optional[str]'
    docstring: The type of the reference image. Only set by the SDK.
  omitted_inherited_members_from:
  - TypedDict
- rank: 2050
  id: google.genai.types.ContextWindowCompressionConfig
  name: ContextWindowCompressionConfig
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Enables context window compression -- mechanism managing model context window so it does not exceed given length.


    [Note: Inherited members from _common.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, trigger_tokens: typing.Optional[int] = None, sliding_window: typing.Optional[google.genai.types.SlidingWindow] = None):'
  properties:
  - signature: 'trigger_tokens: typing.Optional[int]'
  - signature: 'sliding_window: typing.Optional[google.genai.types.SlidingWindow]'
  omitted_inherited_members_from:
  - _common.BaseModel
- rank: 2051
  id: google.genai.types.ContextWindowCompressionConfigDict
  name: ContextWindowCompressionConfigDict
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Enables context window compression -- mechanism managing model context window so it does not exceed given length.


    [Note: Inherited members from TypedDict are omitted.]'
  properties:
  - signature: 'trigger_tokens: typing.Optional[int]'
    docstring: Number of tokens (before running turn) that triggers context window compression mechanism.
  - signature: 'sliding_window: typing.Optional[google.genai.types.SlidingWindowDict]'
    docstring: Sliding window compression mechanism.
  omitted_inherited_members_from:
  - TypedDict
- rank: 2052
  id: google.genai.types.ControlReferenceConfig
  name: ControlReferenceConfig
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Configuration for a Control reference image.


    [Note: Inherited members from _common.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, control_type: typing.Optional[google.genai.types.ControlReferenceType] = None, enable_control_image_computation: typing.Optional[bool] = None):'
  properties:
  - signature: 'control_type: typing.Optional[google.genai.types.ControlReferenceType]'
  - signature: 'enable_control_image_computation: typing.Optional[bool]'
  omitted_inherited_members_from:
  - _common.BaseModel
- rank: 2053
  id: google.genai.types.ControlReferenceConfigDict
  name: ControlReferenceConfigDict
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Configuration for a Control reference image.


    [Note: Inherited members from TypedDict are omitted.]'
  properties:
  - signature: 'control_type: typing.Optional[google.genai.types.ControlReferenceType]'
    docstring: The type of control reference image to use.
  - signature: 'enable_control_image_computation: typing.Optional[bool]'
    docstring: 'Defaults to False. When set to True, the control image will be

      computed by the model based on the control type. When set to False,

      the control image must be provided by the user.'
  omitted_inherited_members_from:
  - TypedDict
- rank: 2054
  id: google.genai.types.ControlReferenceImage
  name: ControlReferenceImage
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'A control reference image.


    The image of the control reference image is either a control image provided

    by the user, or a regular image which the backend will use to generate a

    control image of. In the case of the latter, the

    enable_control_image_computation field in the config should be set to True.


    A control image is an image that represents a sketch image of areas for the

    model to fill in based on the prompt.


    [Note: Inherited members from _common.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, reference_image: typing.Optional[google.genai.types.Image] = None, reference_id: typing.Optional[int] = None, reference_type: typing.Optional[str] = None, config: typing.Optional[google.genai.types.ControlReferenceConfig] = None, control_image_config: typing.Optional[google.genai.types.ControlReferenceConfig] = None):'
  properties:
  - signature: 'reference_image: typing.Optional[google.genai.types.Image]'
  - signature: 'reference_id: typing.Optional[int]'
  - signature: 'reference_type: typing.Optional[str]'
  - signature: 'config: typing.Optional[google.genai.types.ControlReferenceConfig]'
    docstring: Re-map config to control_reference_config to send to API.
  - signature: 'control_image_config: typing.Optional[google.genai.types.ControlReferenceConfig]'
  omitted_inherited_members_from:
  - _common.BaseModel
- rank: 2055
  id: google.genai.types.ControlReferenceImageDict
  name: ControlReferenceImageDict
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'A control reference image.


    The image of the control reference image is either a control image provided

    by the user, or a regular image which the backend will use to generate a

    control image of. In the case of the latter, the

    enable_control_image_computation field in the config should be set to True.


    A control image is an image that represents a sketch image of areas for the

    model to fill in based on the prompt.


    [Note: Inherited members from TypedDict are omitted.]'
  properties:
  - signature: 'reference_image: typing.Optional[google.genai.types.ImageDict]'
    docstring: The reference image for the editing operation.
  - signature: 'reference_id: typing.Optional[int]'
    docstring: The id of the reference image.
  - signature: 'reference_type: typing.Optional[str]'
    docstring: The type of the reference image. Only set by the SDK.
  - signature: 'config: typing.Optional[google.genai.types.ControlReferenceConfigDict]'
    docstring: Configuration for the control reference image.
  omitted_inherited_members_from:
  - TypedDict
- rank: 2056
  id: google.genai.types.ControlReferenceType
  name: ControlReferenceType
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Enum representing the control type of a control reference image.


    [Note: Inherited members from _common.CaseInSensitiveEnum are omitted.]'
  properties:
  - signature: 'CONTROL_TYPE_DEFAULT: str'
  - signature: 'CONTROL_TYPE_CANNY: str'
  - signature: 'CONTROL_TYPE_SCRIBBLE: str'
  - signature: 'CONTROL_TYPE_FACE_MESH: str'
  omitted_inherited_members_from:
  - _common.CaseInSensitiveEnum
- rank: 2057
  id: google.genai.types.CountTokensConfig
  name: CountTokensConfig
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Config for the count_tokens method.


    [Note: Inherited members from _common.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, http_options: typing.Optional[google.genai.types.HttpOptions] = None, system_instruction: typing.Optional[google.genai.types.ContentUnion] = None, tools: typing.Optional[list[google.genai.types.Tool]] = None, generation_config: typing.Optional[google.genai.types.GenerationConfig] = None):'
  properties:
  - signature: 'http_options: typing.Optional[google.genai.types.HttpOptions]'
  - signature: 'system_instruction: typing.Optional[google.genai.types.ContentUnion]'
  - signature: 'tools: typing.Optional[list[google.genai.types.Tool]]'
  - signature: 'generation_config: typing.Optional[google.genai.types.GenerationConfig]'
  omitted_inherited_members_from:
  - _common.BaseModel
- rank: 2058
  id: google.genai.types.CountTokensConfigDict
  name: CountTokensConfigDict
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Config for the count_tokens method.


    [Note: Inherited members from TypedDict are omitted.]'
  properties:
  - signature: 'http_options: typing.Optional[google.genai.types.HttpOptionsDict]'
    docstring: Used to override HTTP request options.
  - signature: 'system_instruction: typing.Optional[google.genai.types.ContentUnionDict]'
    docstring: "Instructions for the model to steer it toward better performance.\n      "
  - signature: 'tools: typing.Optional[list[google.genai.types.ToolDict]]'
    docstring: 'Code that enables the system to interact with external systems to

      perform an action outside of the knowledge and scope of the model.'
  - signature: 'generation_config: typing.Optional[google.genai.types.GenerationConfigDict]'
    docstring: 'Configuration that the model uses to generate the response. Not

      supported by the Gemini Developer API.'
  omitted_inherited_members_from:
  - TypedDict
- rank: 2059
  id: google.genai.types.CountTokensResponse
  name: CountTokensResponse
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Response for counting tokens.


    [Note: Inherited members from _common.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, sdk_http_response: typing.Optional[google.genai.types.HttpResponse] = None, total_tokens: typing.Optional[int] = None, cached_content_token_count: typing.Optional[int] = None):'
  properties:
  - signature: 'sdk_http_response: typing.Optional[google.genai.types.HttpResponse]'
  - signature: 'total_tokens: typing.Optional[int]'
  - signature: 'cached_content_token_count: typing.Optional[int]'
  omitted_inherited_members_from:
  - _common.BaseModel
- rank: 2060
  id: google.genai.types.CountTokensResponseDict
  name: CountTokensResponseDict
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Response for counting tokens.


    [Note: Inherited members from TypedDict are omitted.]'
  properties:
  - signature: 'sdk_http_response: typing.Optional[google.genai.types.HttpResponseDict]'
    docstring: Used to retain the full HTTP response.
  - signature: 'total_tokens: typing.Optional[int]'
    docstring: Total number of tokens.
  - signature: 'cached_content_token_count: typing.Optional[int]'
    docstring: Number of tokens in the cached part of the prompt (the cached content).
  omitted_inherited_members_from:
  - TypedDict
- rank: 2061
  id: google.genai.types.CountTokensResult
  name: CountTokensResult
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Local tokenizer count tokens result.


    [Note: Inherited members from _common.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, total_tokens: typing.Optional[int] = None):'
  properties:
  - signature: 'total_tokens: typing.Optional[int]'
  omitted_inherited_members_from:
  - _common.BaseModel
- rank: 2062
  id: google.genai.types.CountTokensResultDict
  name: CountTokensResultDict
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Local tokenizer count tokens result.


    [Note: Inherited members from TypedDict are omitted.]'
  properties:
  - signature: 'total_tokens: typing.Optional[int]'
    docstring: The total number of tokens.
  omitted_inherited_members_from:
  - TypedDict
- rank: 2063
  id: google.genai.types.CreateAuthTokenConfig
  name: CreateAuthTokenConfig
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Optional parameters.


    [Note: Inherited members from _common.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, http_options: typing.Optional[google.genai.types.HttpOptions] = None, expire_time: typing.Optional[datetime.datetime] = None, new_session_expire_time: typing.Optional[datetime.datetime] = None, uses: typing.Optional[int] = None, live_connect_constraints: typing.Optional[google.genai.types.LiveConnectConstraints] = None, lock_additional_fields: typing.Optional[list[str]] = None):'
  properties:
  - signature: 'http_options: typing.Optional[google.genai.types.HttpOptions]'
  - signature: 'expire_time: typing.Optional[datetime.datetime]'
  - signature: 'new_session_expire_time: typing.Optional[datetime.datetime]'
  - signature: 'uses: typing.Optional[int]'
  - signature: 'live_connect_constraints: typing.Optional[google.genai.types.LiveConnectConstraints]'
  - signature: 'lock_additional_fields: typing.Optional[list[str]]'
  omitted_inherited_members_from:
  - _common.BaseModel
- rank: 2064
  id: google.genai.types.CreateAuthTokenConfigDict
  name: CreateAuthTokenConfigDict
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Optional parameters.


    [Note: Inherited members from TypedDict are omitted.]'
  properties:
  - signature: 'http_options: typing.Optional[google.genai.types.HttpOptionsDict]'
    docstring: Used to override HTTP request options.
  - signature: 'expire_time: typing.Optional[datetime.datetime]'
    docstring: 'An optional time after which, when using the resulting token,

      messages in Live API sessions will be rejected. (Gemini may

      preemptively close the session after this time.)


      If not set then this defaults to 30 minutes in the future. If set, this

      value must be less than 20 hours in the future.'
  - signature: 'new_session_expire_time: typing.Optional[datetime.datetime]'
    docstring: 'The time after which new Live API sessions using the token

      resulting from this request will be rejected.


      If not set this defaults to 60 seconds in the future. If set, this value

      must be less than 20 hours in the future.'
  - signature: 'uses: typing.Optional[int]'
    docstring: 'The number of times the token can be used. If this value is zero

      then no limit is applied. Default is 1. Resuming a Live API session does

      not count as a use.'
  - signature: 'live_connect_constraints: typing.Optional[google.genai.types.LiveConnectConstraintsDict]'
    docstring: Configuration specific to Live API connections created using this token.
  - signature: 'lock_additional_fields: typing.Optional[list[str]]'
    docstring: Additional fields to lock in the effective LiveConnectParameters.
  omitted_inherited_members_from:
  - TypedDict
- rank: 2065
  id: google.genai.types.CreateAuthTokenParameters
  name: CreateAuthTokenParameters
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Config for auth_tokens.create parameters.


    [Note: Inherited members from _common.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, config: typing.Optional[google.genai.types.CreateAuthTokenConfig] = None):'
  properties:
  - signature: 'config: typing.Optional[google.genai.types.CreateAuthTokenConfig]'
  omitted_inherited_members_from:
  - _common.BaseModel
- rank: 2066
  id: google.genai.types.CreateAuthTokenParametersDict
  name: CreateAuthTokenParametersDict
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Config for auth_tokens.create parameters.


    [Note: Inherited members from TypedDict are omitted.]'
  properties:
  - signature: 'config: typing.Optional[google.genai.types.CreateAuthTokenConfigDict]'
    docstring: Optional parameters for the request.
  omitted_inherited_members_from:
  - TypedDict
- rank: 2067
  id: google.genai.types.CreateBatchJobConfig
  name: CreateBatchJobConfig
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Config for optional parameters.


    [Note: Inherited members from _common.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, http_options: typing.Optional[google.genai.types.HttpOptions] = None, display_name: typing.Optional[str] = None, dest: typing.Optional[google.genai.types.BatchJobDestinationUnion] = None):'
  properties:
  - signature: 'http_options: typing.Optional[google.genai.types.HttpOptions]'
  - signature: 'display_name: typing.Optional[str]'
  - signature: 'dest: typing.Optional[google.genai.types.BatchJobDestinationUnion]'
  omitted_inherited_members_from:
  - _common.BaseModel
- rank: 2068
  id: google.genai.types.CreateBatchJobConfigDict
  name: CreateBatchJobConfigDict
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Config for optional parameters.


    [Note: Inherited members from TypedDict are omitted.]'
  properties:
  - signature: 'http_options: typing.Optional[google.genai.types.HttpOptionsDict]'
    docstring: Used to override HTTP request options.
  - signature: 'display_name: typing.Optional[str]'
    docstring: "The user-defined name of this BatchJob.\n      "
  - signature: 'dest: typing.Optional[google.genai.types.BatchJobDestinationUnionDict]'
    docstring: 'GCS or BigQuery URI prefix for the output predictions. Example:

      "gs://path/to/output/data" or "bq://projectId.bqDatasetId.bqTableId".'
  omitted_inherited_members_from:
  - TypedDict
- rank: 2069
  id: google.genai.types.CreateCachedContentConfig
  name: CreateCachedContentConfig
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Optional configuration for cached content creation.


    [Note: Inherited members from _common.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, http_options: typing.Optional[google.genai.types.HttpOptions] = None, ttl: typing.Optional[str] = None, expire_time: typing.Optional[datetime.datetime] = None, display_name: typing.Optional[str] = None, contents: typing.Optional[google.genai.types.ContentListUnion] = None, system_instruction: typing.Optional[google.genai.types.ContentUnion] = None, tools: typing.Optional[list[google.genai.types.Tool]] = None, tool_config: typing.Optional[google.genai.types.ToolConfig] = None, kms_key_name: typing.Optional[str] = None):'
  properties:
  - signature: 'http_options: typing.Optional[google.genai.types.HttpOptions]'
  - signature: 'ttl: typing.Optional[str]'
  - signature: 'expire_time: typing.Optional[datetime.datetime]'
  - signature: 'display_name: typing.Optional[str]'
  - signature: 'contents: typing.Optional[google.genai.types.ContentListUnion]'
  - signature: 'system_instruction: typing.Optional[google.genai.types.ContentUnion]'
  - signature: 'tools: typing.Optional[list[google.genai.types.Tool]]'
  - signature: 'tool_config: typing.Optional[google.genai.types.ToolConfig]'
  - signature: 'kms_key_name: typing.Optional[str]'
  omitted_inherited_members_from:
  - _common.BaseModel
- rank: 2070
  id: google.genai.types.CreateCachedContentConfigDict
  name: CreateCachedContentConfigDict
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Optional configuration for cached content creation.


    [Note: Inherited members from TypedDict are omitted.]'
  properties:
  - signature: 'http_options: typing.Optional[google.genai.types.HttpOptionsDict]'
    docstring: Used to override HTTP request options.
  - signature: 'ttl: typing.Optional[str]'
    docstring: 'The TTL for this resource. The expiration time is computed: now + TTL. It is a duration string, with up to nine fractional digits, terminated by ''s''. Example: "3.5s".'
  - signature: 'expire_time: typing.Optional[datetime.datetime]'
    docstring: 'Timestamp of when this resource is considered expired. Uses RFC 3339 format, Example: 2014-10-02T15:01:23Z.'
  - signature: 'display_name: typing.Optional[str]'
    docstring: "The user-generated meaningful display name of the cached content.\n      "
  - signature: 'contents: typing.Optional[google.genai.types.ContentListUnionDict]'
    docstring: "The content to cache.\n      "
  - signature: 'system_instruction: typing.Optional[google.genai.types.ContentUnionDict]'
    docstring: "Developer set system instruction.\n      "
  - signature: 'tools: typing.Optional[list[google.genai.types.ToolDict]]'
    docstring: "A list of `Tools` the model may use to generate the next response.\n      "
  - signature: 'tool_config: typing.Optional[google.genai.types.ToolConfigDict]'
    docstring: "Configuration for the tools to use. This config is shared for all tools.\n      "
  - signature: 'kms_key_name: typing.Optional[str]'
    docstring: 'The Cloud KMS resource identifier of the customer managed

      encryption key used to protect a resource.

      The key needs to be in the same region as where the compute resource is

      created. See

      https://cloud.google.com/vertex-ai/docs/general/cmek for more

      details. If this is set, then all created CachedContent objects

      will be encrypted with the provided encryption key.

      Allowed formats: projects/{project}/locations/{location}/keyRings/{key_ring}/cryptoKeys/{crypto_key}'
  omitted_inherited_members_from:
  - TypedDict
- rank: 2071
  id: google.genai.types.CreateEmbeddingsBatchJobConfig
  name: CreateEmbeddingsBatchJobConfig
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Config for optional parameters.


    [Note: Inherited members from _common.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, http_options: typing.Optional[google.genai.types.HttpOptions] = None, display_name: typing.Optional[str] = None):'
  properties:
  - signature: 'http_options: typing.Optional[google.genai.types.HttpOptions]'
  - signature: 'display_name: typing.Optional[str]'
  omitted_inherited_members_from:
  - _common.BaseModel
- rank: 2072
  id: google.genai.types.CreateEmbeddingsBatchJobConfigDict
  name: CreateEmbeddingsBatchJobConfigDict
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Config for optional parameters.


    [Note: Inherited members from TypedDict are omitted.]'
  properties:
  - signature: 'http_options: typing.Optional[google.genai.types.HttpOptionsDict]'
    docstring: Used to override HTTP request options.
  - signature: 'display_name: typing.Optional[str]'
    docstring: "The user-defined name of this BatchJob.\n      "
  omitted_inherited_members_from:
  - TypedDict
- rank: 2073
  id: google.genai.types.CreateFileConfig
  name: CreateFileConfig
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Used to override the default configuration.


    [Note: Inherited members from _common.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, http_options: typing.Optional[google.genai.types.HttpOptions] = None, should_return_http_response: typing.Optional[bool] = None):'
  properties:
  - signature: 'http_options: typing.Optional[google.genai.types.HttpOptions]'
  - signature: 'should_return_http_response: typing.Optional[bool]'
  omitted_inherited_members_from:
  - _common.BaseModel
- rank: 2074
  id: google.genai.types.CreateFileConfigDict
  name: CreateFileConfigDict
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Used to override the default configuration.


    [Note: Inherited members from TypedDict are omitted.]'
  properties:
  - signature: 'http_options: typing.Optional[google.genai.types.HttpOptionsDict]'
    docstring: Used to override HTTP request options.
  - signature: 'should_return_http_response: typing.Optional[bool]'
    docstring: If true, the raw HTTP response will be returned in the 'sdk_http_response' field.
  omitted_inherited_members_from:
  - TypedDict
- rank: 2075
  id: google.genai.types.CreateFileResponse
  name: CreateFileResponse
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Response for the create file method.


    [Note: Inherited members from _common.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, sdk_http_response: typing.Optional[google.genai.types.HttpResponse] = None):'
  properties:
  - signature: 'sdk_http_response: typing.Optional[google.genai.types.HttpResponse]'
  omitted_inherited_members_from:
  - _common.BaseModel
- rank: 2076
  id: google.genai.types.CreateFileResponseDict
  name: CreateFileResponseDict
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Response for the create file method.


    [Note: Inherited members from TypedDict are omitted.]'
  properties:
  - signature: 'sdk_http_response: typing.Optional[google.genai.types.HttpResponseDict]'
    docstring: Used to retain the full HTTP response.
  omitted_inherited_members_from:
  - TypedDict
- rank: 2077
  id: google.genai.types.CreateFileSearchStoreConfig
  name: CreateFileSearchStoreConfig
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Optional parameters for creating a file search store.


    [Note: Inherited members from _common.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, http_options: typing.Optional[google.genai.types.HttpOptions] = None, display_name: typing.Optional[str] = None):'
  properties:
  - signature: 'http_options: typing.Optional[google.genai.types.HttpOptions]'
  - signature: 'display_name: typing.Optional[str]'
  omitted_inherited_members_from:
  - _common.BaseModel
- rank: 2078
  id: google.genai.types.CreateFileSearchStoreConfigDict
  name: CreateFileSearchStoreConfigDict
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Optional parameters for creating a file search store.


    [Note: Inherited members from TypedDict are omitted.]'
  properties:
  - signature: 'http_options: typing.Optional[google.genai.types.HttpOptionsDict]'
    docstring: Used to override HTTP request options.
  - signature: 'display_name: typing.Optional[str]'
    docstring: "The human-readable display name for the file search store.\n      "
  omitted_inherited_members_from:
  - TypedDict
- rank: 2079
  id: google.genai.types.CreateTuningJobConfig
  name: CreateTuningJobConfig
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Fine-tuning job creation request - optional fields.


    [Note: Inherited members from _common.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, http_options: typing.Optional[google.genai.types.HttpOptions] = None, method: typing.Optional[google.genai.types.TuningMethod] = None, validation_dataset: typing.Optional[google.genai.types.TuningValidationDataset] = None, tuned_model_display_name: typing.Optional[str] = None, description: typing.Optional[str] = None, epoch_count: typing.Optional[int] = None, learning_rate_multiplier: typing.Optional[float] = None, export_last_checkpoint_only: typing.Optional[bool] = None, pre_tuned_model_checkpoint_id: typing.Optional[str] = None, adapter_size: typing.Optional[google.genai.types.AdapterSize] = None, batch_size: typing.Optional[int] = None, learning_rate: typing.Optional[float] = None, evaluation_config: typing.Optional[google.genai.types.EvaluationConfig] = None, labels: typing.Optional[dict[str, str]] = None, beta: typing.Optional[float] = None):'
  properties:
  - signature: 'http_options: typing.Optional[google.genai.types.HttpOptions]'
  - signature: 'method: typing.Optional[google.genai.types.TuningMethod]'
  - signature: 'validation_dataset: typing.Optional[google.genai.types.TuningValidationDataset]'
  - signature: 'tuned_model_display_name: typing.Optional[str]'
  - signature: 'description: typing.Optional[str]'
  - signature: 'epoch_count: typing.Optional[int]'
  - signature: 'learning_rate_multiplier: typing.Optional[float]'
  - signature: 'export_last_checkpoint_only: typing.Optional[bool]'
  - signature: 'pre_tuned_model_checkpoint_id: typing.Optional[str]'
  - signature: 'adapter_size: typing.Optional[google.genai.types.AdapterSize]'
  - signature: 'batch_size: typing.Optional[int]'
  - signature: 'learning_rate: typing.Optional[float]'
  - signature: 'evaluation_config: typing.Optional[google.genai.types.EvaluationConfig]'
  - signature: 'labels: typing.Optional[dict[str, str]]'
  - signature: 'beta: typing.Optional[float]'
  omitted_inherited_members_from:
  - _common.BaseModel
- rank: 2080
  id: google.genai.types.CreateTuningJobConfigDict
  name: CreateTuningJobConfigDict
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Fine-tuning job creation request - optional fields.


    [Note: Inherited members from TypedDict are omitted.]'
  properties:
  - signature: 'http_options: typing.Optional[google.genai.types.HttpOptionsDict]'
    docstring: Used to override HTTP request options.
  - signature: 'method: typing.Optional[google.genai.types.TuningMethod]'
    docstring: The method to use for tuning (SUPERVISED_FINE_TUNING or PREFERENCE_TUNING). If not set, the default method (SFT) will be used.
  - signature: 'validation_dataset: typing.Optional[google.genai.types.TuningValidationDatasetDict]'
    docstring: Validation dataset for tuning. The dataset must be formatted as a JSONL file.
  - signature: 'tuned_model_display_name: typing.Optional[str]'
    docstring: The display name of the tuned Model. The name can be up to 128 characters long and can consist of any UTF-8 characters.
  - signature: 'description: typing.Optional[str]'
    docstring: The description of the TuningJob
  - signature: 'epoch_count: typing.Optional[int]'
    docstring: Number of complete passes the model makes over the entire training dataset during training.
  - signature: 'learning_rate_multiplier: typing.Optional[float]'
    docstring: Multiplier for adjusting the default learning rate.
  - signature: 'export_last_checkpoint_only: typing.Optional[bool]'
    docstring: If set to true, disable intermediate checkpoints and only the last checkpoint will be exported. Otherwise, enable intermediate checkpoints.
  - signature: 'pre_tuned_model_checkpoint_id: typing.Optional[str]'
    docstring: The optional checkpoint id of the pre-tuned model to use for tuning, if applicable.
  - signature: 'adapter_size: typing.Optional[google.genai.types.AdapterSize]'
    docstring: Adapter size for tuning.
  - signature: 'batch_size: typing.Optional[int]'
    docstring: The batch size hyperparameter for tuning. If not set, a default of 4 or 16 will be used based on the number of training examples.
  - signature: 'learning_rate: typing.Optional[float]'
    docstring: The learning rate hyperparameter for tuning. If not set, a default of 0.001 or 0.0002 will be calculated based on the number of training examples.
  - signature: 'evaluation_config: typing.Optional[google.genai.types.EvaluationConfigDict]'
    docstring: Evaluation config for the tuning job.
  - signature: 'labels: typing.Optional[dict[str, str]]'
    docstring: Optional. The labels with user-defined metadata to organize TuningJob and generated resources such as Model and Endpoint. Label keys and values can be no longer than 64 characters (Unicode codepoints), can only contain lowercase letters, numeric characters, underscores and dashes. International characters are allowed. See https://goo.gl/xmQnxf for more information and examples of labels.
  - signature: 'beta: typing.Optional[float]'
    docstring: Weight for KL Divergence regularization, Preference Optimization tuning only.
  omitted_inherited_members_from:
  - TypedDict
- rank: 2081
  id: google.genai.types.CreateTuningJobParameters
  name: CreateTuningJobParameters
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Fine-tuning job creation parameters - optional fields.


    [Note: Inherited members from _common.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, base_model: typing.Optional[str] = None, training_dataset: typing.Optional[google.genai.types.TuningDataset] = None, config: typing.Optional[google.genai.types.CreateTuningJobConfig] = None):'
  properties:
  - signature: 'base_model: typing.Optional[str]'
  - signature: 'training_dataset: typing.Optional[google.genai.types.TuningDataset]'
  - signature: 'config: typing.Optional[google.genai.types.CreateTuningJobConfig]'
  omitted_inherited_members_from:
  - _common.BaseModel
- rank: 2082
  id: google.genai.types.CreateTuningJobParametersDict
  name: CreateTuningJobParametersDict
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Fine-tuning job creation parameters - optional fields.


    [Note: Inherited members from TypedDict are omitted.]'
  properties:
  - signature: 'base_model: typing.Optional[str]'
    docstring: The base model that is being tuned, e.g., "gemini-2.5-flash".
  - signature: 'training_dataset: typing.Optional[google.genai.types.TuningDatasetDict]'
    docstring: Cloud Storage path to file containing training dataset for tuning. The dataset must be formatted as a JSONL file.
  - signature: 'config: typing.Optional[google.genai.types.CreateTuningJobConfigDict]'
    docstring: Configuration for the tuning job.
  omitted_inherited_members_from:
  - TypedDict
- rank: 2083
  id: google.genai.types.CustomMetadata
  name: CustomMetadata
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'User provided metadata stored as key-value pairs.


    This data type is not supported in Vertex AI.


    [Note: Inherited members from _common.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, key: typing.Optional[str] = None, numeric_value: typing.Optional[float] = None, string_list_value: typing.Optional[google.genai.types.StringList] = None, string_value: typing.Optional[str] = None):'
  properties:
  - signature: 'key: typing.Optional[str]'
  - signature: 'numeric_value: typing.Optional[float]'
  - signature: 'string_list_value: typing.Optional[google.genai.types.StringList]'
  - signature: 'string_value: typing.Optional[str]'
  omitted_inherited_members_from:
  - _common.BaseModel
- rank: 2084
  id: google.genai.types.CustomMetadataDict
  name: CustomMetadataDict
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'User provided metadata stored as key-value pairs.


    This data type is not supported in Vertex AI.


    [Note: Inherited members from TypedDict are omitted.]'
  properties:
  - signature: 'key: typing.Optional[str]'
    docstring: Required. The key of the metadata to store.
  - signature: 'numeric_value: typing.Optional[float]'
    docstring: The numeric value of the metadata to store.
  - signature: 'string_list_value: typing.Optional[google.genai.types.StringListDict]'
    docstring: The StringList value of the metadata to store.
  - signature: 'string_value: typing.Optional[str]'
    docstring: The string value of the metadata to store.
  omitted_inherited_members_from:
  - TypedDict
- rank: 2085
  id: google.genai.types.CustomOutputFormatConfig
  name: CustomOutputFormatConfig
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Config for custom output format.


    [Note: Inherited members from _common.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, return_raw_output: typing.Optional[bool] = None):'
  properties:
  - signature: 'return_raw_output: typing.Optional[bool]'
  omitted_inherited_members_from:
  - _common.BaseModel
- rank: 2086
  id: google.genai.types.CustomOutputFormatConfigDict
  name: CustomOutputFormatConfigDict
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Config for custom output format.


    [Note: Inherited members from TypedDict are omitted.]'
  properties:
  - signature: 'return_raw_output: typing.Optional[bool]'
    docstring: Optional. Whether to return raw output.
  omitted_inherited_members_from:
  - TypedDict
- rank: 2087
  id: google.genai.types.DatasetDistribution
  name: DatasetDistribution
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Distribution computed over a tuning dataset.


    This data type is not supported in Gemini API.


    [Note: Inherited members from _common.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, buckets: typing.Optional[list[google.genai.types.DatasetDistributionDistributionBucket]] = None, max: typing.Optional[float] = None, mean: typing.Optional[float] = None, median: typing.Optional[float] = None, min: typing.Optional[float] = None, p5: typing.Optional[float] = None, p95: typing.Optional[float] = None, sum: typing.Optional[float] = None):'
  properties:
  - signature: 'buckets: typing.Optional[list[google.genai.types.DatasetDistributionDistributionBucket]]'
  - signature: 'max: typing.Optional[float]'
  - signature: 'mean: typing.Optional[float]'
  - signature: 'median: typing.Optional[float]'
  - signature: 'min: typing.Optional[float]'
  - signature: 'p5: typing.Optional[float]'
  - signature: 'p95: typing.Optional[float]'
  - signature: 'sum: typing.Optional[float]'
  omitted_inherited_members_from:
  - _common.BaseModel
- rank: 2088
  id: google.genai.types.DatasetDistributionDict
  name: DatasetDistributionDict
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Distribution computed over a tuning dataset.


    This data type is not supported in Gemini API.


    [Note: Inherited members from TypedDict are omitted.]'
  properties:
  - signature: 'buckets: typing.Optional[list[google.genai.types.DatasetDistributionDistributionBucketDict]]'
    docstring: Output only. Defines the histogram bucket.
  - signature: 'max: typing.Optional[float]'
    docstring: Output only. The maximum of the population values.
  - signature: 'mean: typing.Optional[float]'
    docstring: Output only. The arithmetic mean of the values in the population.
  - signature: 'median: typing.Optional[float]'
    docstring: Output only. The median of the values in the population.
  - signature: 'min: typing.Optional[float]'
    docstring: Output only. The minimum of the population values.
  - signature: 'p5: typing.Optional[float]'
    docstring: Output only. The 5th percentile of the values in the population.
  - signature: 'p95: typing.Optional[float]'
    docstring: Output only. The 95th percentile of the values in the population.
  - signature: 'sum: typing.Optional[float]'
    docstring: Output only. Sum of a given population of values.
  omitted_inherited_members_from:
  - TypedDict
- rank: 2089
  id: google.genai.types.DatasetDistributionDistributionBucket
  name: DatasetDistributionDistributionBucket
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Dataset bucket used to create a histogram for the distribution given a population of values.


    This data type is not supported in Gemini API.


    [Note: Inherited members from _common.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, count: typing.Optional[int] = None, left: typing.Optional[float] = None, right: typing.Optional[float] = None):'
  properties:
  - signature: 'count: typing.Optional[int]'
  - signature: 'left: typing.Optional[float]'
  - signature: 'right: typing.Optional[float]'
  omitted_inherited_members_from:
  - _common.BaseModel
- rank: 2090
  id: google.genai.types.DatasetDistributionDistributionBucketDict
  name: DatasetDistributionDistributionBucketDict
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Dataset bucket used to create a histogram for the distribution given a population of values.


    This data type is not supported in Gemini API.


    [Note: Inherited members from TypedDict are omitted.]'
  properties:
  - signature: 'count: typing.Optional[int]'
    docstring: Output only. Number of values in the bucket.
  - signature: 'left: typing.Optional[float]'
    docstring: Output only. Left bound of the bucket.
  - signature: 'right: typing.Optional[float]'
    docstring: Output only. Right bound of the bucket.
  omitted_inherited_members_from:
  - TypedDict
- rank: 2091
  id: google.genai.types.DatasetStats
  name: DatasetStats
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Statistics computed over a tuning dataset.


    This data type is not supported in Gemini API.


    [Note: Inherited members from _common.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, total_billable_character_count: typing.Optional[int] = None, total_tuning_character_count: typing.Optional[int] = None, tuning_dataset_example_count: typing.Optional[int] = None, tuning_step_count: typing.Optional[int] = None, user_dataset_examples: typing.Optional[list[google.genai.types.Content]] = None, user_input_token_distribution: typing.Optional[google.genai.types.DatasetDistribution] = None, user_message_per_example_distribution: typing.Optional[google.genai.types.DatasetDistribution] = None, user_output_token_distribution: typing.Optional[google.genai.types.DatasetDistribution] = None):'
  properties:
  - signature: 'total_billable_character_count: typing.Optional[int]'
  - signature: 'total_tuning_character_count: typing.Optional[int]'
  - signature: 'tuning_dataset_example_count: typing.Optional[int]'
  - signature: 'tuning_step_count: typing.Optional[int]'
  - signature: 'user_dataset_examples: typing.Optional[list[google.genai.types.Content]]'
  - signature: 'user_input_token_distribution: typing.Optional[google.genai.types.DatasetDistribution]'
  - signature: 'user_message_per_example_distribution: typing.Optional[google.genai.types.DatasetDistribution]'
  - signature: 'user_output_token_distribution: typing.Optional[google.genai.types.DatasetDistribution]'
  omitted_inherited_members_from:
  - _common.BaseModel
- rank: 2092
  id: google.genai.types.DatasetStatsDict
  name: DatasetStatsDict
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Statistics computed over a tuning dataset.


    This data type is not supported in Gemini API.


    [Note: Inherited members from TypedDict are omitted.]'
  properties:
  - signature: 'total_billable_character_count: typing.Optional[int]'
    docstring: Output only. Number of billable characters in the tuning dataset.
  - signature: 'total_tuning_character_count: typing.Optional[int]'
    docstring: Output only. Number of tuning characters in the tuning dataset.
  - signature: 'tuning_dataset_example_count: typing.Optional[int]'
    docstring: Output only. Number of examples in the tuning dataset.
  - signature: 'tuning_step_count: typing.Optional[int]'
    docstring: Output only. Number of tuning steps for this Tuning Job.
  - signature: 'user_dataset_examples: typing.Optional[list[google.genai.types.ContentDict]]'
    docstring: Output only. Sample user messages in the training dataset uri.
  - signature: 'user_input_token_distribution: typing.Optional[google.genai.types.DatasetDistributionDict]'
    docstring: Output only. Dataset distributions for the user input tokens.
  - signature: 'user_message_per_example_distribution: typing.Optional[google.genai.types.DatasetDistributionDict]'
    docstring: Output only. Dataset distributions for the messages per example.
  - signature: 'user_output_token_distribution: typing.Optional[google.genai.types.DatasetDistributionDict]'
    docstring: Output only. Dataset distributions for the user output tokens.
  omitted_inherited_members_from:
  - TypedDict
- rank: 2093
  id: google.genai.types.DeleteBatchJobConfig
  name: DeleteBatchJobConfig
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Optional parameters for models.get method.


    [Note: Inherited members from _common.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, http_options: typing.Optional[google.genai.types.HttpOptions] = None):'
  properties:
  - signature: 'http_options: typing.Optional[google.genai.types.HttpOptions]'
  omitted_inherited_members_from:
  - _common.BaseModel
- rank: 2094
  id: google.genai.types.DeleteBatchJobConfigDict
  name: DeleteBatchJobConfigDict
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Optional parameters for models.get method.


    [Note: Inherited members from TypedDict are omitted.]'
  properties:
  - signature: 'http_options: typing.Optional[google.genai.types.HttpOptionsDict]'
    docstring: Used to override HTTP request options.
  omitted_inherited_members_from:
  - TypedDict
- rank: 2095
  id: google.genai.types.DeleteCachedContentConfig
  name: DeleteCachedContentConfig
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Optional parameters for caches.delete method.


    [Note: Inherited members from _common.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, http_options: typing.Optional[google.genai.types.HttpOptions] = None):'
  properties:
  - signature: 'http_options: typing.Optional[google.genai.types.HttpOptions]'
  omitted_inherited_members_from:
  - _common.BaseModel
- rank: 2096
  id: google.genai.types.DeleteCachedContentConfigDict
  name: DeleteCachedContentConfigDict
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Optional parameters for caches.delete method.


    [Note: Inherited members from TypedDict are omitted.]'
  properties:
  - signature: 'http_options: typing.Optional[google.genai.types.HttpOptionsDict]'
    docstring: Used to override HTTP request options.
  omitted_inherited_members_from:
  - TypedDict
- rank: 2097
  id: google.genai.types.DeleteCachedContentResponse
  name: DeleteCachedContentResponse
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Empty response for caches.delete method.


    [Note: Inherited members from _common.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, sdk_http_response: typing.Optional[google.genai.types.HttpResponse] = None):'
  properties:
  - signature: 'sdk_http_response: typing.Optional[google.genai.types.HttpResponse]'
  omitted_inherited_members_from:
  - _common.BaseModel
- rank: 2098
  id: google.genai.types.DeleteCachedContentResponseDict
  name: DeleteCachedContentResponseDict
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Empty response for caches.delete method.


    [Note: Inherited members from TypedDict are omitted.]'
  properties:
  - signature: 'sdk_http_response: typing.Optional[google.genai.types.HttpResponseDict]'
    docstring: Used to retain the full HTTP response.
  omitted_inherited_members_from:
  - TypedDict
- rank: 2099
  id: google.genai.types.DeleteDocumentConfig
  name: DeleteDocumentConfig
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Config for optional parameters.


    [Note: Inherited members from _common.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, http_options: typing.Optional[google.genai.types.HttpOptions] = None, force: typing.Optional[bool] = None):'
  properties:
  - signature: 'http_options: typing.Optional[google.genai.types.HttpOptions]'
  - signature: 'force: typing.Optional[bool]'
  omitted_inherited_members_from:
  - _common.BaseModel
- rank: 2100
  id: google.genai.types.DeleteDocumentConfigDict
  name: DeleteDocumentConfigDict
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Config for optional parameters.


    [Note: Inherited members from TypedDict are omitted.]'
  properties:
  - signature: 'http_options: typing.Optional[google.genai.types.HttpOptionsDict]'
    docstring: Used to override HTTP request options.
  - signature: 'force: typing.Optional[bool]'
    docstring: 'If set to true, any `Chunk`s and objects related to this `Document` will

      also be deleted.'
  omitted_inherited_members_from:
  - TypedDict
- rank: 2101
  id: google.genai.types.DeleteFileConfig
  name: DeleteFileConfig
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Used to override the default configuration.


    [Note: Inherited members from _common.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, http_options: typing.Optional[google.genai.types.HttpOptions] = None):'
  properties:
  - signature: 'http_options: typing.Optional[google.genai.types.HttpOptions]'
  omitted_inherited_members_from:
  - _common.BaseModel
- rank: 2102
  id: google.genai.types.DeleteFileConfigDict
  name: DeleteFileConfigDict
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Used to override the default configuration.


    [Note: Inherited members from TypedDict are omitted.]'
  properties:
  - signature: 'http_options: typing.Optional[google.genai.types.HttpOptionsDict]'
    docstring: Used to override HTTP request options.
  omitted_inherited_members_from:
  - TypedDict
- rank: 2103
  id: google.genai.types.DeleteFileResponse
  name: DeleteFileResponse
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Response for the delete file method.


    [Note: Inherited members from _common.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, sdk_http_response: typing.Optional[google.genai.types.HttpResponse] = None):'
  properties:
  - signature: 'sdk_http_response: typing.Optional[google.genai.types.HttpResponse]'
  omitted_inherited_members_from:
  - _common.BaseModel
- rank: 2104
  id: google.genai.types.DeleteFileResponseDict
  name: DeleteFileResponseDict
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Response for the delete file method.


    [Note: Inherited members from TypedDict are omitted.]'
  properties:
  - signature: 'sdk_http_response: typing.Optional[google.genai.types.HttpResponseDict]'
    docstring: Used to retain the full HTTP response.
  omitted_inherited_members_from:
  - TypedDict
- rank: 2105
  id: google.genai.types.DeleteFileSearchStoreConfig
  name: DeleteFileSearchStoreConfig
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Optional parameters for deleting a FileSearchStore.


    [Note: Inherited members from _common.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, http_options: typing.Optional[google.genai.types.HttpOptions] = None, force: typing.Optional[bool] = None):'
  properties:
  - signature: 'http_options: typing.Optional[google.genai.types.HttpOptions]'
  - signature: 'force: typing.Optional[bool]'
  omitted_inherited_members_from:
  - _common.BaseModel
- rank: 2106
  id: google.genai.types.DeleteFileSearchStoreConfigDict
  name: DeleteFileSearchStoreConfigDict
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Optional parameters for deleting a FileSearchStore.


    [Note: Inherited members from TypedDict are omitted.]'
  properties:
  - signature: 'http_options: typing.Optional[google.genai.types.HttpOptionsDict]'
    docstring: Used to override HTTP request options.
  - signature: 'force: typing.Optional[bool]'
    docstring: 'If set to true, any Documents and objects related to this FileSearchStore will also be deleted.

      If false (the default), a FAILED_PRECONDITION error will be returned if

      the FileSearchStore contains any Documents.'
  omitted_inherited_members_from:
  - TypedDict
- rank: 2107
  id: google.genai.types.DeleteModelConfig
  name: DeleteModelConfig
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Configuration for deleting a tuned model.


    [Note: Inherited members from _common.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, http_options: typing.Optional[google.genai.types.HttpOptions] = None):'
  properties:
  - signature: 'http_options: typing.Optional[google.genai.types.HttpOptions]'
  omitted_inherited_members_from:
  - _common.BaseModel
- rank: 2108
  id: google.genai.types.DeleteModelConfigDict
  name: DeleteModelConfigDict
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Configuration for deleting a tuned model.


    [Note: Inherited members from TypedDict are omitted.]'
  properties:
  - signature: 'http_options: typing.Optional[google.genai.types.HttpOptionsDict]'
    docstring: Used to override HTTP request options.
  omitted_inherited_members_from:
  - TypedDict
- rank: 2109
  id: google.genai.types.DeleteModelResponse
  name: DeleteModelResponse
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: '[Note: Inherited members from _common.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, sdk_http_response: typing.Optional[google.genai.types.HttpResponse] = None):'
  properties:
  - signature: 'sdk_http_response: typing.Optional[google.genai.types.HttpResponse]'
  omitted_inherited_members_from:
  - _common.BaseModel
- rank: 2110
  id: google.genai.types.DeleteModelResponseDict
  name: DeleteModelResponseDict
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: '[Note: Inherited members from TypedDict are omitted.]'
  properties:
  - signature: 'sdk_http_response: typing.Optional[google.genai.types.HttpResponseDict]'
    docstring: Used to retain the full HTTP response.
  omitted_inherited_members_from:
  - TypedDict
- rank: 2111
  id: google.genai.types.DeleteResourceJob
  name: DeleteResourceJob
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'The return value of delete operation.


    [Note: Inherited members from _common.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, sdk_http_response: typing.Optional[google.genai.types.HttpResponse] = None, name: typing.Optional[str] = None, done: typing.Optional[bool] = None, error: typing.Optional[google.genai.types.JobError] = None):'
  properties:
  - signature: 'sdk_http_response: typing.Optional[google.genai.types.HttpResponse]'
  - signature: 'name: typing.Optional[str]'
  - signature: 'done: typing.Optional[bool]'
  - signature: 'error: typing.Optional[google.genai.types.JobError]'
  omitted_inherited_members_from:
  - _common.BaseModel
- rank: 2112
  id: google.genai.types.DeleteResourceJobDict
  name: DeleteResourceJobDict
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'The return value of delete operation.


    [Note: Inherited members from TypedDict are omitted.]'
  properties:
  - signature: 'sdk_http_response: typing.Optional[google.genai.types.HttpResponseDict]'
    docstring: Used to retain the full HTTP response.
  - signature: 'name: typing.Optional[str]'
  - signature: 'done: typing.Optional[bool]'
  - signature: 'error: typing.Optional[google.genai.types.JobErrorDict]'
  omitted_inherited_members_from:
  - TypedDict
- rank: 2113
  id: google.genai.types.DistillationDataStats
  name: DistillationDataStats
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Statistics computed for datasets used for distillation.


    This data type is not supported in Gemini API.


    [Note: Inherited members from _common.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, training_dataset_stats: typing.Optional[google.genai.types.DatasetStats] = None):'
  properties:
  - signature: 'training_dataset_stats: typing.Optional[google.genai.types.DatasetStats]'
  omitted_inherited_members_from:
  - _common.BaseModel
- rank: 2114
  id: google.genai.types.DistillationDataStatsDict
  name: DistillationDataStatsDict
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Statistics computed for datasets used for distillation.


    This data type is not supported in Gemini API.


    [Note: Inherited members from TypedDict are omitted.]'
  properties:
  - signature: 'training_dataset_stats: typing.Optional[google.genai.types.DatasetStatsDict]'
    docstring: Output only. Statistics computed for the training dataset.
  omitted_inherited_members_from:
  - TypedDict
- rank: 2115
  id: google.genai.types.Document
  name: Document
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'A Document is a collection of Chunks.


    [Note: Inherited members from _common.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, name: typing.Optional[str] = None, display_name: typing.Optional[str] = None, state: typing.Optional[google.genai.types.DocumentState] = None, size_bytes: typing.Optional[int] = None, mime_type: typing.Optional[str] = None, create_time: typing.Optional[datetime.datetime] = None, custom_metadata: typing.Optional[list[google.genai.types.CustomMetadata]] = None, update_time: typing.Optional[datetime.datetime] = None):'
  properties:
  - signature: 'name: typing.Optional[str]'
  - signature: 'display_name: typing.Optional[str]'
  - signature: 'state: typing.Optional[google.genai.types.DocumentState]'
  - signature: 'size_bytes: typing.Optional[int]'
  - signature: 'mime_type: typing.Optional[str]'
  - signature: 'create_time: typing.Optional[datetime.datetime]'
  - signature: 'custom_metadata: typing.Optional[list[google.genai.types.CustomMetadata]]'
  - signature: 'update_time: typing.Optional[datetime.datetime]'
  omitted_inherited_members_from:
  - _common.BaseModel
- rank: 2116
  id: google.genai.types.DocumentDict
  name: DocumentDict
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'A Document is a collection of Chunks.


    [Note: Inherited members from TypedDict are omitted.]'
  properties:
  - signature: 'name: typing.Optional[str]'
    docstring: 'The resource name of the Document.

      Example: fileSearchStores/file-search-store-foo/documents/documents-bar'
  - signature: 'display_name: typing.Optional[str]'
    docstring: The human-readable display name for the Document.
  - signature: 'state: typing.Optional[google.genai.types.DocumentState]'
    docstring: The current state of the Document.
  - signature: 'size_bytes: typing.Optional[int]'
    docstring: The size of the Document in bytes.
  - signature: 'mime_type: typing.Optional[str]'
    docstring: The MIME type of the Document.
  - signature: 'create_time: typing.Optional[datetime.datetime]'
    docstring: Output only. The Timestamp of when the `Document` was created.
  - signature: 'custom_metadata: typing.Optional[list[google.genai.types.CustomMetadataDict]]'
    docstring: Optional. User provided custom metadata stored as key-value pairs used for querying. A `Document` can have a maximum of 20 `CustomMetadata`.
  - signature: 'update_time: typing.Optional[datetime.datetime]'
    docstring: Output only. The Timestamp of when the `Document` was last updated.
  omitted_inherited_members_from:
  - TypedDict
- rank: 2117
  id: google.genai.types.DocumentState
  name: DocumentState
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'State for the lifecycle of a Document.


    [Note: Inherited members from _common.CaseInSensitiveEnum are omitted.]'
  properties:
  - signature: 'STATE_UNSPECIFIED: str'
  - signature: 'STATE_PENDING: str'
  - signature: 'STATE_ACTIVE: str'
  - signature: 'STATE_FAILED: str'
  omitted_inherited_members_from:
  - _common.CaseInSensitiveEnum
- rank: 2118
  id: google.genai.types.DownloadFileConfig
  name: DownloadFileConfig
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Used to override the default configuration.


    [Note: Inherited members from _common.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, http_options: typing.Optional[google.genai.types.HttpOptions] = None):'
  properties:
  - signature: 'http_options: typing.Optional[google.genai.types.HttpOptions]'
  omitted_inherited_members_from:
  - _common.BaseModel
- rank: 2119
  id: google.genai.types.DownloadFileConfigDict
  name: DownloadFileConfigDict
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Used to override the default configuration.


    [Note: Inherited members from TypedDict are omitted.]'
  properties:
  - signature: 'http_options: typing.Optional[google.genai.types.HttpOptionsDict]'
    docstring: Used to override HTTP request options.
  omitted_inherited_members_from:
  - TypedDict
- rank: 2120
  id: google.genai.types.DynamicRetrievalConfig
  name: DynamicRetrievalConfig
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Describes the options to customize dynamic retrieval.


    [Note: Inherited members from _common.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, mode: typing.Optional[google.genai.types.DynamicRetrievalConfigMode] = None, dynamic_threshold: typing.Optional[float] = None):'
  properties:
  - signature: 'mode: typing.Optional[google.genai.types.DynamicRetrievalConfigMode]'
  - signature: 'dynamic_threshold: typing.Optional[float]'
  omitted_inherited_members_from:
  - _common.BaseModel
- rank: 2121
  id: google.genai.types.DynamicRetrievalConfigDict
  name: DynamicRetrievalConfigDict
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Describes the options to customize dynamic retrieval.


    [Note: Inherited members from TypedDict are omitted.]'
  properties:
  - signature: 'mode: typing.Optional[google.genai.types.DynamicRetrievalConfigMode]'
    docstring: The mode of the predictor to be used in dynamic retrieval.
  - signature: 'dynamic_threshold: typing.Optional[float]'
    docstring: Optional. The threshold to be used in dynamic retrieval. If not set, a system default value is used.
  omitted_inherited_members_from:
  - TypedDict
- rank: 2122
  id: google.genai.types.DynamicRetrievalConfigMode
  name: DynamicRetrievalConfigMode
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Config for the dynamic retrieval config mode.


    [Note: Inherited members from _common.CaseInSensitiveEnum are omitted.]'
  properties:
  - signature: 'MODE_UNSPECIFIED: str'
    docstring: Always trigger retrieval.
  - signature: 'MODE_DYNAMIC: str'
    docstring: Run retrieval only when system decides it is necessary.
  omitted_inherited_members_from:
  - _common.CaseInSensitiveEnum
- rank: 2123
  id: google.genai.types.EditImageConfig
  name: EditImageConfig
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Configuration for editing an image.


    [Note: Inherited members from _common.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, http_options: typing.Optional[google.genai.types.HttpOptions] = None, output_gcs_uri: typing.Optional[str] = None, negative_prompt: typing.Optional[str] = None, number_of_images: typing.Optional[int] = None, aspect_ratio: typing.Optional[str] = None, guidance_scale: typing.Optional[float] = None, seed: typing.Optional[int] = None, safety_filter_level: typing.Optional[google.genai.types.SafetyFilterLevel] = None, person_generation: typing.Optional[google.genai.types.PersonGeneration] = None, include_safety_attributes: typing.Optional[bool] = None, include_rai_reason: typing.Optional[bool] = None, language: typing.Optional[google.genai.types.ImagePromptLanguage] = None, output_mime_type: typing.Optional[str] = None, output_compression_quality: typing.Optional[int] = None, add_watermark: typing.Optional[bool] = None, labels: typing.Optional[dict[str, str]] = None, edit_mode: typing.Optional[google.genai.types.EditMode] = None, base_steps: typing.Optional[int]
    = None):'
  properties:
  - signature: 'http_options: typing.Optional[google.genai.types.HttpOptions]'
  - signature: 'output_gcs_uri: typing.Optional[str]'
  - signature: 'negative_prompt: typing.Optional[str]'
  - signature: 'number_of_images: typing.Optional[int]'
  - signature: 'aspect_ratio: typing.Optional[str]'
  - signature: 'guidance_scale: typing.Optional[float]'
  - signature: 'seed: typing.Optional[int]'
  - signature: 'safety_filter_level: typing.Optional[google.genai.types.SafetyFilterLevel]'
  - signature: 'person_generation: typing.Optional[google.genai.types.PersonGeneration]'
  - signature: 'include_safety_attributes: typing.Optional[bool]'
  - signature: 'include_rai_reason: typing.Optional[bool]'
  - signature: 'language: typing.Optional[google.genai.types.ImagePromptLanguage]'
  - signature: 'output_mime_type: typing.Optional[str]'
  - signature: 'output_compression_quality: typing.Optional[int]'
  - signature: 'add_watermark: typing.Optional[bool]'
  - signature: 'labels: typing.Optional[dict[str, str]]'
  - signature: 'edit_mode: typing.Optional[google.genai.types.EditMode]'
  - signature: 'base_steps: typing.Optional[int]'
  omitted_inherited_members_from:
  - _common.BaseModel
- rank: 2124
  id: google.genai.types.EditImageConfigDict
  name: EditImageConfigDict
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Configuration for editing an image.


    [Note: Inherited members from TypedDict are omitted.]'
  properties:
  - signature: 'http_options: typing.Optional[google.genai.types.HttpOptionsDict]'
    docstring: Used to override HTTP request options.
  - signature: 'output_gcs_uri: typing.Optional[str]'
    docstring: Cloud Storage URI used to store the generated images.
  - signature: 'negative_prompt: typing.Optional[str]'
    docstring: Description of what to discourage in the generated images.
  - signature: 'number_of_images: typing.Optional[int]'
    docstring: Number of images to generate.
  - signature: 'aspect_ratio: typing.Optional[str]'
    docstring: 'Aspect ratio of the generated images. Supported values are

      "1:1", "3:4", "4:3", "9:16", and "16:9".'
  - signature: 'guidance_scale: typing.Optional[float]'
    docstring: 'Controls how much the model adheres to the text prompt. Large

      values increase output and prompt alignment, but may compromise image

      quality.'
  - signature: 'seed: typing.Optional[int]'
    docstring: 'Random seed for image generation. This is not available when

      ``add_watermark`` is set to true.'
  - signature: 'safety_filter_level: typing.Optional[google.genai.types.SafetyFilterLevel]'
    docstring: Filter level for safety filtering.
  - signature: 'person_generation: typing.Optional[google.genai.types.PersonGeneration]'
    docstring: Allows generation of people by the model.
  - signature: 'include_safety_attributes: typing.Optional[bool]'
    docstring: 'Whether to report the safety scores of each generated image and

      the positive prompt in the response.'
  - signature: 'include_rai_reason: typing.Optional[bool]'
    docstring: 'Whether to include the Responsible AI filter reason if the image

      is filtered out of the response.'
  - signature: 'language: typing.Optional[google.genai.types.ImagePromptLanguage]'
    docstring: Language of the text in the prompt.
  - signature: 'output_mime_type: typing.Optional[str]'
    docstring: MIME type of the generated image.
  - signature: 'output_compression_quality: typing.Optional[int]'
    docstring: 'Compression quality of the generated image (for ``image/jpeg``

      only).'
  - signature: 'add_watermark: typing.Optional[bool]'
    docstring: Whether to add a watermark to the generated images.
  - signature: 'labels: typing.Optional[dict[str, str]]'
    docstring: User specified labels to track billing usage.
  - signature: 'edit_mode: typing.Optional[google.genai.types.EditMode]'
    docstring: Describes the editing mode for the request.
  - signature: 'base_steps: typing.Optional[int]'
    docstring: 'The number of sampling steps. A higher value has better image

      quality, while a lower value has better latency.'
  omitted_inherited_members_from:
  - TypedDict
- rank: 2125
  id: google.genai.types.EditImageResponse
  name: EditImageResponse
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Response for the request to edit an image.


    [Note: Inherited members from _common.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, sdk_http_response: typing.Optional[google.genai.types.HttpResponse] = None, generated_images: typing.Optional[list[google.genai.types.GeneratedImage]] = None):'
  properties:
  - signature: 'sdk_http_response: typing.Optional[google.genai.types.HttpResponse]'
  - signature: 'generated_images: typing.Optional[list[google.genai.types.GeneratedImage]]'
  omitted_inherited_members_from:
  - _common.BaseModel
- rank: 2126
  id: google.genai.types.EditImageResponseDict
  name: EditImageResponseDict
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Response for the request to edit an image.


    [Note: Inherited members from TypedDict are omitted.]'
  properties:
  - signature: 'sdk_http_response: typing.Optional[google.genai.types.HttpResponseDict]'
    docstring: Used to retain the full HTTP response.
  - signature: 'generated_images: typing.Optional[list[google.genai.types.GeneratedImageDict]]'
    docstring: Generated images.
  omitted_inherited_members_from:
  - TypedDict
- rank: 2127
  id: google.genai.types.EditMode
  name: EditMode
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Enum representing the editing mode.


    [Note: Inherited members from _common.CaseInSensitiveEnum are omitted.]'
  properties:
  - signature: 'EDIT_MODE_DEFAULT: str'
  - signature: 'EDIT_MODE_INPAINT_REMOVAL: str'
  - signature: 'EDIT_MODE_INPAINT_INSERTION: str'
  - signature: 'EDIT_MODE_OUTPAINT: str'
  - signature: 'EDIT_MODE_CONTROLLED_EDITING: str'
  - signature: 'EDIT_MODE_STYLE: str'
  - signature: 'EDIT_MODE_BGSWAP: str'
  - signature: 'EDIT_MODE_PRODUCT_IMAGE: str'
  omitted_inherited_members_from:
  - _common.CaseInSensitiveEnum
- rank: 2128
  id: google.genai.types.EmbedContentBatch
  name: EmbedContentBatch
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Parameters for the embed_content method.


    [Note: Inherited members from _common.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, contents: typing.Optional[google.genai.types.ContentListUnion] = None, config: typing.Optional[google.genai.types.EmbedContentConfig] = None):'
  properties:
  - signature: 'contents: typing.Optional[google.genai.types.ContentListUnion]'
  - signature: 'config: typing.Optional[google.genai.types.EmbedContentConfig]'
  omitted_inherited_members_from:
  - _common.BaseModel
- rank: 2129
  id: google.genai.types.EmbedContentBatchDict
  name: EmbedContentBatchDict
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Parameters for the embed_content method.


    [Note: Inherited members from TypedDict are omitted.]'
  properties:
  - signature: 'contents: typing.Optional[google.genai.types.ContentListUnionDict]'
    docstring: "The content to embed. Only the `parts.text` fields will be counted.\n      "
  - signature: 'config: typing.Optional[google.genai.types.EmbedContentConfigDict]'
    docstring: "Configuration that contains optional parameters.\n      "
  omitted_inherited_members_from:
  - TypedDict
- rank: 2130
  id: google.genai.types.EmbedContentConfig
  name: EmbedContentConfig
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Optional parameters for the embed_content method.


    [Note: Inherited members from _common.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, http_options: typing.Optional[google.genai.types.HttpOptions] = None, task_type: typing.Optional[str] = None, title: typing.Optional[str] = None, output_dimensionality: typing.Optional[int] = None, mime_type: typing.Optional[str] = None, auto_truncate: typing.Optional[bool] = None):'
  properties:
  - signature: 'http_options: typing.Optional[google.genai.types.HttpOptions]'
  - signature: 'task_type: typing.Optional[str]'
  - signature: 'title: typing.Optional[str]'
  - signature: 'output_dimensionality: typing.Optional[int]'
  - signature: 'mime_type: typing.Optional[str]'
  - signature: 'auto_truncate: typing.Optional[bool]'
  omitted_inherited_members_from:
  - _common.BaseModel
- rank: 2131
  id: google.genai.types.EmbedContentConfigDict
  name: EmbedContentConfigDict
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Optional parameters for the embed_content method.


    [Note: Inherited members from TypedDict are omitted.]'
  properties:
  - signature: 'http_options: typing.Optional[google.genai.types.HttpOptionsDict]'
    docstring: Used to override HTTP request options.
  - signature: 'task_type: typing.Optional[str]'
    docstring: "Type of task for which the embedding will be used.\n      "
  - signature: 'title: typing.Optional[str]'
    docstring: 'Title for the text. Only applicable when TaskType is

      `RETRIEVAL_DOCUMENT`.'
  - signature: 'output_dimensionality: typing.Optional[int]'
    docstring: 'Reduced dimension for the output embedding. If set,

      excessive values in the output embedding are truncated from the end.

      Supported by newer models since 2024 only. You cannot set this value if

      using the earlier model (`models/embedding-001`).'
  - signature: 'mime_type: typing.Optional[str]'
    docstring: "Vertex API only. The MIME type of the input.\n      "
  - signature: 'auto_truncate: typing.Optional[bool]'
    docstring: 'Vertex API only. Whether to silently truncate inputs longer than

      the max sequence length. If this option is set to false, oversized inputs

      will lead to an INVALID_ARGUMENT error, similar to other text APIs.'
  omitted_inherited_members_from:
  - TypedDict
- rank: 2132
  id: google.genai.types.EmbedContentMetadata
  name: EmbedContentMetadata
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Request-level metadata for the Vertex Embed Content API.


    [Note: Inherited members from _common.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, billable_character_count: typing.Optional[int] = None):'
  properties:
  - signature: 'billable_character_count: typing.Optional[int]'
  omitted_inherited_members_from:
  - _common.BaseModel
- rank: 2133
  id: google.genai.types.EmbedContentMetadataDict
  name: EmbedContentMetadataDict
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Request-level metadata for the Vertex Embed Content API.


    [Note: Inherited members from TypedDict are omitted.]'
  properties:
  - signature: 'billable_character_count: typing.Optional[int]'
    docstring: 'Vertex API only. The total number of billable characters included

      in the request.'
  omitted_inherited_members_from:
  - TypedDict
- rank: 2134
  id: google.genai.types.EmbedContentResponse
  name: EmbedContentResponse
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Response for the embed_content method.


    [Note: Inherited members from _common.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, sdk_http_response: typing.Optional[google.genai.types.HttpResponse] = None, embeddings: typing.Optional[list[google.genai.types.ContentEmbedding]] = None, metadata: typing.Optional[google.genai.types.EmbedContentMetadata] = None):'
  properties:
  - signature: 'sdk_http_response: typing.Optional[google.genai.types.HttpResponse]'
  - signature: 'embeddings: typing.Optional[list[google.genai.types.ContentEmbedding]]'
  - signature: 'metadata: typing.Optional[google.genai.types.EmbedContentMetadata]'
  omitted_inherited_members_from:
  - _common.BaseModel
- rank: 2135
  id: google.genai.types.EmbedContentResponseDict
  name: EmbedContentResponseDict
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Response for the embed_content method.


    [Note: Inherited members from TypedDict are omitted.]'
  properties:
  - signature: 'sdk_http_response: typing.Optional[google.genai.types.HttpResponseDict]'
    docstring: Used to retain the full HTTP response.
  - signature: 'embeddings: typing.Optional[list[google.genai.types.ContentEmbeddingDict]]'
    docstring: 'The embeddings for each request, in the same order as provided in

      the batch request.'
  - signature: 'metadata: typing.Optional[google.genai.types.EmbedContentMetadataDict]'
    docstring: "Vertex API only. Metadata about the request.\n      "
  omitted_inherited_members_from:
  - TypedDict
- rank: 2136
  id: google.genai.types.EmbeddingsBatchJobSource
  name: EmbeddingsBatchJobSource
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: '[Note: Inherited members from _common.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, file_name: typing.Optional[str] = None, inlined_requests: typing.Optional[google.genai.types.EmbedContentBatch] = None):'
  properties:
  - signature: 'file_name: typing.Optional[str]'
  - signature: 'inlined_requests: typing.Optional[google.genai.types.EmbedContentBatch]'
  omitted_inherited_members_from:
  - _common.BaseModel
- rank: 2137
  id: google.genai.types.EmbeddingsBatchJobSourceDict
  name: EmbeddingsBatchJobSourceDict
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: '[Note: Inherited members from TypedDict are omitted.]'
  properties:
  - signature: 'file_name: typing.Optional[str]'
    docstring: 'The Gemini Developer API''s file resource name of the input data

      (e.g. "files/12345").'
  - signature: 'inlined_requests: typing.Optional[google.genai.types.EmbedContentBatchDict]'
    docstring: "The Gemini Developer API's inlined input data to run batch job.\n      "
  omitted_inherited_members_from:
  - TypedDict
- rank: 2138
  id: google.genai.types.EncryptionSpec
  name: EncryptionSpec
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Represents a customer-managed encryption key spec that can be applied to a top-level resource.


    This data type is not supported in Gemini API.


    [Note: Inherited members from _common.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, kms_key_name: typing.Optional[str] = None):'
  properties:
  - signature: 'kms_key_name: typing.Optional[str]'
  omitted_inherited_members_from:
  - _common.BaseModel
- rank: 2139
  id: google.genai.types.EncryptionSpecDict
  name: EncryptionSpecDict
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Represents a customer-managed encryption key spec that can be applied to a top-level resource.


    This data type is not supported in Gemini API.


    [Note: Inherited members from TypedDict are omitted.]'
  properties:
  - signature: 'kms_key_name: typing.Optional[str]'
    docstring: 'Required. The Cloud KMS resource identifier of the customer managed encryption key used to protect a resource. Has the form: `projects/my-project/locations/my-region/keyRings/my-kr/cryptoKeys/my-key`. The key needs to be in the same region as where the compute resource is created.'
  omitted_inherited_members_from:
  - TypedDict
- rank: 2140
  id: google.genai.types.EndSensitivity
  name: EndSensitivity
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'End of speech sensitivity.


    [Note: Inherited members from _common.CaseInSensitiveEnum are omitted.]'
  properties:
  - signature: 'END_SENSITIVITY_UNSPECIFIED: str'
    docstring: The default is END_SENSITIVITY_LOW.
  - signature: 'END_SENSITIVITY_HIGH: str'
    docstring: Automatic detection ends speech more often.
  - signature: 'END_SENSITIVITY_LOW: str'
    docstring: Automatic detection ends speech less often.
  omitted_inherited_members_from:
  - _common.CaseInSensitiveEnum
- rank: 2141
  id: google.genai.types.Endpoint
  name: Endpoint
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'An endpoint where you deploy models.


    [Note: Inherited members from _common.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, name: typing.Optional[str] = None, deployed_model_id: typing.Optional[str] = None):'
  properties:
  - signature: 'name: typing.Optional[str]'
  - signature: 'deployed_model_id: typing.Optional[str]'
  omitted_inherited_members_from:
  - _common.BaseModel
- rank: 2142
  id: google.genai.types.EndpointDict
  name: EndpointDict
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'An endpoint where you deploy models.


    [Note: Inherited members from TypedDict are omitted.]'
  properties:
  - signature: 'name: typing.Optional[str]'
    docstring: Resource name of the endpoint.
  - signature: 'deployed_model_id: typing.Optional[str]'
    docstring: ID of the model that's deployed to the endpoint.
  omitted_inherited_members_from:
  - TypedDict
- rank: 2143
  id: google.genai.types.EnterpriseWebSearch
  name: EnterpriseWebSearch
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Tool to search public web data, powered by Vertex AI Search and Sec4 compliance.


    This data type is not supported in Gemini API.


    [Note: Inherited members from _common.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, exclude_domains: typing.Optional[list[str]] = None, blocking_confidence: typing.Optional[google.genai.types.PhishBlockThreshold] = None):'
  properties:
  - signature: 'exclude_domains: typing.Optional[list[str]]'
  - signature: 'blocking_confidence: typing.Optional[google.genai.types.PhishBlockThreshold]'
  omitted_inherited_members_from:
  - _common.BaseModel
- rank: 2144
  id: google.genai.types.EnterpriseWebSearchDict
  name: EnterpriseWebSearchDict
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Tool to search public web data, powered by Vertex AI Search and Sec4 compliance.


    This data type is not supported in Gemini API.


    [Note: Inherited members from TypedDict are omitted.]'
  properties:
  - signature: 'exclude_domains: typing.Optional[list[str]]'
    docstring: Optional. List of domains to be excluded from the search results. The default limit is 2000 domains.
  - signature: 'blocking_confidence: typing.Optional[google.genai.types.PhishBlockThreshold]'
    docstring: Optional. Sites with confidence level chosen & above this value will be blocked from the search results.
  omitted_inherited_members_from:
  - TypedDict
- rank: 2145
  id: google.genai.types.EntityLabel
  name: EntityLabel
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'An entity representing the segmented area.


    [Note: Inherited members from _common.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, label: typing.Optional[str] = None, score: typing.Optional[float] = None):'
  properties:
  - signature: 'label: typing.Optional[str]'
  - signature: 'score: typing.Optional[float]'
  omitted_inherited_members_from:
  - _common.BaseModel
- rank: 2146
  id: google.genai.types.EntityLabelDict
  name: EntityLabelDict
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'An entity representing the segmented area.


    [Note: Inherited members from TypedDict are omitted.]'
  properties:
  - signature: 'label: typing.Optional[str]'
    docstring: The label of the segmented entity.
  - signature: 'score: typing.Optional[float]'
    docstring: The confidence score of the detected label.
  omitted_inherited_members_from:
  - TypedDict
- rank: 2147
  id: google.genai.types.Environment
  name: Environment
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'The environment being operated.


    [Note: Inherited members from _common.CaseInSensitiveEnum are omitted.]'
  properties:
  - signature: 'ENVIRONMENT_UNSPECIFIED: str'
    docstring: Defaults to browser.
  - signature: 'ENVIRONMENT_BROWSER: str'
    docstring: Operates in a web browser.
  omitted_inherited_members_from:
  - _common.CaseInSensitiveEnum
- rank: 2148
  id: google.genai.types.EvaluationConfig
  name: EvaluationConfig
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Evaluation config for tuning.


    [Note: Inherited members from _common.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, metrics: typing.Optional[list[google.genai.types.Metric]] = None, output_config: typing.Optional[google.genai.types.OutputConfig] = None, autorater_config: typing.Optional[google.genai.types.AutoraterConfig] = None):'
  properties:
  - signature: 'metrics: typing.Optional[list[google.genai.types.Metric]]'
  - signature: 'output_config: typing.Optional[google.genai.types.OutputConfig]'
  - signature: 'autorater_config: typing.Optional[google.genai.types.AutoraterConfig]'
  omitted_inherited_members_from:
  - _common.BaseModel
- rank: 2149
  id: google.genai.types.EvaluationConfigDict
  name: EvaluationConfigDict
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Evaluation config for tuning.


    [Note: Inherited members from TypedDict are omitted.]'
  properties:
  - signature: 'metrics: typing.Optional[list[google.genai.types.MetricDict]]'
    docstring: The metrics used for evaluation.
  - signature: 'output_config: typing.Optional[google.genai.types.OutputConfigDict]'
    docstring: Config for evaluation output.
  - signature: 'autorater_config: typing.Optional[google.genai.types.AutoraterConfigDict]'
    docstring: Autorater config for evaluation.
  omitted_inherited_members_from:
  - TypedDict
- rank: 2150
  id: google.genai.types.ExecutableCode
  name: ExecutableCode
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Code generated by the model that is meant to be executed, and the result returned to the model.


    Generated when using the [CodeExecution] tool, in which the code will be

    automatically executed, and a corresponding [CodeExecutionResult] will also be

    generated.


    [Note: Inherited members from _common.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, code: typing.Optional[str] = None, language: typing.Optional[google.genai.types.Language] = None):'
  properties:
  - signature: 'code: typing.Optional[str]'
  - signature: 'language: typing.Optional[google.genai.types.Language]'
  omitted_inherited_members_from:
  - _common.BaseModel
- rank: 2151
  id: google.genai.types.ExecutableCodeDict
  name: ExecutableCodeDict
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Code generated by the model that is meant to be executed, and the result returned to the model.


    Generated when using the [CodeExecution] tool, in which the code will be

    automatically executed, and a corresponding [CodeExecutionResult] will also be

    generated.


    [Note: Inherited members from TypedDict are omitted.]'
  properties:
  - signature: 'code: typing.Optional[str]'
    docstring: Required. The code to be executed.
  - signature: 'language: typing.Optional[google.genai.types.Language]'
    docstring: Required. Programming language of the `code`.
  omitted_inherited_members_from:
  - TypedDict
- rank: 2152
  id: google.genai.types.ExternalApi
  name: ExternalApi
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Retrieve from data source powered by external API for grounding.


    The external API is not owned by Google, but need to follow the pre-defined

    API spec. This data type is not supported in Gemini API.


    [Note: Inherited members from _common.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, api_auth: typing.Optional[google.genai.types.ApiAuth] = None, api_spec: typing.Optional[google.genai.types.ApiSpec] = None, auth_config: typing.Optional[google.genai.types.AuthConfig] = None, elastic_search_params: typing.Optional[google.genai.types.ExternalApiElasticSearchParams] = None, endpoint: typing.Optional[str] = None, simple_search_params: typing.Optional[google.genai.types.ExternalApiSimpleSearchParams] = None):'
  properties:
  - signature: 'api_auth: typing.Optional[google.genai.types.ApiAuth]'
  - signature: 'api_spec: typing.Optional[google.genai.types.ApiSpec]'
  - signature: 'auth_config: typing.Optional[google.genai.types.AuthConfig]'
  - signature: 'elastic_search_params: typing.Optional[google.genai.types.ExternalApiElasticSearchParams]'
  - signature: 'endpoint: typing.Optional[str]'
  - signature: 'simple_search_params: typing.Optional[google.genai.types.ExternalApiSimpleSearchParams]'
  omitted_inherited_members_from:
  - _common.BaseModel
- rank: 2153
  id: google.genai.types.ExternalApiDict
  name: ExternalApiDict
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Retrieve from data source powered by external API for grounding.


    The external API is not owned by Google, but need to follow the pre-defined

    API spec. This data type is not supported in Gemini API.


    [Note: Inherited members from TypedDict are omitted.]'
  properties:
  - signature: 'api_auth: typing.Optional[google.genai.types.ApiAuthDict]'
    docstring: The authentication config to access the API. Deprecated. Please use auth_config instead.
  - signature: 'api_spec: typing.Optional[google.genai.types.ApiSpec]'
    docstring: The API spec that the external API implements.
  - signature: 'auth_config: typing.Optional[google.genai.types.AuthConfigDict]'
    docstring: The authentication config to access the API.
  - signature: 'elastic_search_params: typing.Optional[google.genai.types.ExternalApiElasticSearchParamsDict]'
    docstring: Parameters for the elastic search API.
  - signature: 'endpoint: typing.Optional[str]'
    docstring: 'The endpoint of the external API. The system will call the API at this endpoint to retrieve the data for grounding. Example: https://acme.com:443/search'
  - signature: 'simple_search_params: typing.Optional[google.genai.types.ExternalApiSimpleSearchParamsDict]'
    docstring: Parameters for the simple search API.
  omitted_inherited_members_from:
  - TypedDict
- rank: 2154
  id: google.genai.types.ExternalApiElasticSearchParams
  name: ExternalApiElasticSearchParams
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'The search parameters to use for the ELASTIC_SEARCH spec.


    This data type is not supported in Gemini API.


    [Note: Inherited members from _common.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, index: typing.Optional[str] = None, num_hits: typing.Optional[int] = None, search_template: typing.Optional[str] = None):'
  properties:
  - signature: 'index: typing.Optional[str]'
  - signature: 'num_hits: typing.Optional[int]'
  - signature: 'search_template: typing.Optional[str]'
  omitted_inherited_members_from:
  - _common.BaseModel
- rank: 2155
  id: google.genai.types.ExternalApiElasticSearchParamsDict
  name: ExternalApiElasticSearchParamsDict
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'The search parameters to use for the ELASTIC_SEARCH spec.


    This data type is not supported in Gemini API.


    [Note: Inherited members from TypedDict are omitted.]'
  properties:
  - signature: 'index: typing.Optional[str]'
    docstring: The ElasticSearch index to use.
  - signature: 'num_hits: typing.Optional[int]'
    docstring: Optional. Number of hits (chunks) to request. When specified, it is passed to Elasticsearch as the `num_hits` param.
  - signature: 'search_template: typing.Optional[str]'
    docstring: The ElasticSearch search template to use.
  omitted_inherited_members_from:
  - TypedDict
- rank: 2156
  id: google.genai.types.ExternalApiSimpleSearchParams
  name: ExternalApiSimpleSearchParams
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'The search parameters to use for SIMPLE_SEARCH spec.


    This data type is not supported in Gemini API.


    [Note: Inherited members from _common.BaseModel are omitted.]'
  omitted_inherited_members_from:
  - _common.BaseModel
- rank: 2157
  id: google.genai.types.ExternalApiSimpleSearchParamsDict
  name: ExternalApiSimpleSearchParamsDict
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'The search parameters to use for SIMPLE_SEARCH spec.


    This data type is not supported in Gemini API.


    [Note: Inherited members from TypedDict are omitted.]'
  omitted_inherited_members_from:
  - TypedDict
- rank: 2158
  id: google.genai.types.FeatureSelectionPreference
  name: FeatureSelectionPreference
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Options for feature selection preference.


    [Note: Inherited members from _common.CaseInSensitiveEnum are omitted.]'
  properties:
  - signature: 'FEATURE_SELECTION_PREFERENCE_UNSPECIFIED: str'
  - signature: 'PRIORITIZE_QUALITY: str'
  - signature: 'BALANCED: str'
  - signature: 'PRIORITIZE_COST: str'
  omitted_inherited_members_from:
  - _common.CaseInSensitiveEnum
- rank: 2159
  id: google.genai.types.FetchPredictOperationConfig
  name: FetchPredictOperationConfig
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: '[Note: Inherited members from _common.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, http_options: typing.Optional[google.genai.types.HttpOptions] = None):'
  properties:
  - signature: 'http_options: typing.Optional[google.genai.types.HttpOptions]'
  omitted_inherited_members_from:
  - _common.BaseModel
- rank: 2160
  id: google.genai.types.FetchPredictOperationConfigDict
  name: FetchPredictOperationConfigDict
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: '[Note: Inherited members from TypedDict are omitted.]'
  properties:
  - signature: 'http_options: typing.Optional[google.genai.types.HttpOptionsDict]'
    docstring: Used to override HTTP request options.
  omitted_inherited_members_from:
  - TypedDict
- rank: 2161
  id: google.genai.types.File
  name: File
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'A file uploaded to the API.


    [Note: Inherited members from _common.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, name: typing.Optional[str] = None, display_name: typing.Optional[str] = None, mime_type: typing.Optional[str] = None, size_bytes: typing.Optional[int] = None, create_time: typing.Optional[datetime.datetime] = None, expiration_time: typing.Optional[datetime.datetime] = None, update_time: typing.Optional[datetime.datetime] = None, sha256_hash: typing.Optional[str] = None, uri: typing.Optional[str] = None, download_uri: typing.Optional[str] = None, state: typing.Optional[google.genai.types.FileState] = None, source: typing.Optional[google.genai.types.FileSource] = None, video_metadata: typing.Optional[dict[str, typing.Any]] = None, error: typing.Optional[google.genai.types.FileStatus] = None):'
  properties:
  - signature: 'name: typing.Optional[str]'
  - signature: 'display_name: typing.Optional[str]'
  - signature: 'mime_type: typing.Optional[str]'
  - signature: 'size_bytes: typing.Optional[int]'
  - signature: 'create_time: typing.Optional[datetime.datetime]'
  - signature: 'expiration_time: typing.Optional[datetime.datetime]'
  - signature: 'update_time: typing.Optional[datetime.datetime]'
  - signature: 'sha256_hash: typing.Optional[str]'
  - signature: 'uri: typing.Optional[str]'
  - signature: 'download_uri: typing.Optional[str]'
  - signature: 'state: typing.Optional[google.genai.types.FileState]'
  - signature: 'source: typing.Optional[google.genai.types.FileSource]'
  - signature: 'video_metadata: typing.Optional[dict[str, typing.Any]]'
  - signature: 'error: typing.Optional[google.genai.types.FileStatus]'
  omitted_inherited_members_from:
  - _common.BaseModel
- rank: 2162
  id: google.genai.types.FileData
  name: FileData
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'URI based data.


    [Note: Inherited members from _common.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, display_name: typing.Optional[str] = None, file_uri: typing.Optional[str] = None, mime_type: typing.Optional[str] = None):'
  properties:
  - signature: 'display_name: typing.Optional[str]'
  - signature: 'file_uri: typing.Optional[str]'
  - signature: 'mime_type: typing.Optional[str]'
  omitted_inherited_members_from:
  - _common.BaseModel
- rank: 2163
  id: google.genai.types.FileDataDict
  name: FileDataDict
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'URI based data.


    [Note: Inherited members from TypedDict are omitted.]'
  properties:
  - signature: 'display_name: typing.Optional[str]'
    docstring: Optional. Display name of the file data. Used to provide a label or filename to distinguish file datas. This field is only returned in PromptMessage for prompt management. It is currently used in the Gemini GenerateContent calls only when server side tools (code_execution, google_search, and url_context) are enabled. This field is not supported in Gemini API.
  - signature: 'file_uri: typing.Optional[str]'
    docstring: Required. URI.
  - signature: 'mime_type: typing.Optional[str]'
    docstring: Required. The IANA standard MIME type of the source data.
  omitted_inherited_members_from:
  - TypedDict
- rank: 2164
  id: google.genai.types.FileDict
  name: FileDict
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'A file uploaded to the API.


    [Note: Inherited members from TypedDict are omitted.]'
  properties:
  - signature: 'name: typing.Optional[str]'
    docstring: 'The `File` resource name. The ID (name excluding the "files/" prefix) can contain up to 40 characters that are lowercase alphanumeric or dashes (-). The ID cannot start or end with a dash. If the name is empty on create, a unique name will be generated. Example: `files/123-456`'
  - signature: 'display_name: typing.Optional[str]'
    docstring: 'Optional. The human-readable display name for the `File`. The display name must be no more than 512 characters in length, including spaces. Example: ''Welcome Image'''
  - signature: 'mime_type: typing.Optional[str]'
    docstring: Output only. MIME type of the file.
  - signature: 'size_bytes: typing.Optional[int]'
    docstring: Output only. Size of the file in bytes.
  - signature: 'create_time: typing.Optional[datetime.datetime]'
    docstring: Output only. The timestamp of when the `File` was created.
  - signature: 'expiration_time: typing.Optional[datetime.datetime]'
    docstring: Output only. The timestamp of when the `File` will be deleted. Only set if the `File` is scheduled to expire.
  - signature: 'update_time: typing.Optional[datetime.datetime]'
    docstring: Output only. The timestamp of when the `File` was last updated.
  - signature: 'sha256_hash: typing.Optional[str]'
    docstring: Output only. SHA-256 hash of the uploaded bytes. The hash value is encoded in base64 format.
  - signature: 'uri: typing.Optional[str]'
    docstring: Output only. The URI of the `File`.
  - signature: 'download_uri: typing.Optional[str]'
    docstring: Output only. The URI of the `File`, only set for downloadable (generated) files.
  - signature: 'state: typing.Optional[google.genai.types.FileState]'
    docstring: Output only. Processing state of the File.
  - signature: 'source: typing.Optional[google.genai.types.FileSource]'
    docstring: Output only. The source of the `File`.
  - signature: 'video_metadata: typing.Optional[dict[str, typing.Any]]'
    docstring: Output only. Metadata for a video.
  - signature: 'error: typing.Optional[google.genai.types.FileStatusDict]'
    docstring: Output only. Error status if File processing failed.
  omitted_inherited_members_from:
  - TypedDict
- rank: 2165
  id: google.genai.types.FileSearch
  name: FileSearch
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Tool to retrieve knowledge from the File Search Stores.


    [Note: Inherited members from _common.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, file_search_store_names: typing.Optional[list[str]] = None, top_k: typing.Optional[int] = None, metadata_filter: typing.Optional[str] = None):'
  properties:
  - signature: 'file_search_store_names: typing.Optional[list[str]]'
  - signature: 'top_k: typing.Optional[int]'
  - signature: 'metadata_filter: typing.Optional[str]'
  omitted_inherited_members_from:
  - _common.BaseModel
- rank: 2166
  id: google.genai.types.FileSearchDict
  name: FileSearchDict
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Tool to retrieve knowledge from the File Search Stores.


    [Note: Inherited members from TypedDict are omitted.]'
  properties:
  - signature: 'file_search_store_names: typing.Optional[list[str]]'
    docstring: 'The names of the file_search_stores to retrieve from.

      Example: `fileSearchStores/my-file-search-store-123`'
  - signature: 'top_k: typing.Optional[int]'
    docstring: The number of file search retrieval chunks to retrieve.
  - signature: 'metadata_filter: typing.Optional[str]'
    docstring: Metadata filter to apply to the file search retrieval documents. See https://google.aip.dev/160 for the syntax of the filter expression.
  omitted_inherited_members_from:
  - TypedDict
- rank: 2167
  id: google.genai.types.FileSearchStore
  name: FileSearchStore
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'A collection of Documents.


    [Note: Inherited members from _common.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, name: typing.Optional[str] = None, display_name: typing.Optional[str] = None, create_time: typing.Optional[datetime.datetime] = None, update_time: typing.Optional[datetime.datetime] = None, active_documents_count: typing.Optional[int] = None, pending_documents_count: typing.Optional[int] = None, failed_documents_count: typing.Optional[int] = None, size_bytes: typing.Optional[int] = None):'
  properties:
  - signature: 'name: typing.Optional[str]'
  - signature: 'display_name: typing.Optional[str]'
  - signature: 'create_time: typing.Optional[datetime.datetime]'
  - signature: 'update_time: typing.Optional[datetime.datetime]'
  - signature: 'active_documents_count: typing.Optional[int]'
  - signature: 'pending_documents_count: typing.Optional[int]'
  - signature: 'failed_documents_count: typing.Optional[int]'
  - signature: 'size_bytes: typing.Optional[int]'
  omitted_inherited_members_from:
  - _common.BaseModel
- rank: 2168
  id: google.genai.types.FileSearchStoreDict
  name: FileSearchStoreDict
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'A collection of Documents.


    [Note: Inherited members from TypedDict are omitted.]'
  properties:
  - signature: 'name: typing.Optional[str]'
    docstring: 'The resource name of the FileSearchStore. Example: `fileSearchStores/my-file-search-store-123`'
  - signature: 'display_name: typing.Optional[str]'
    docstring: The human-readable display name for the FileSearchStore.
  - signature: 'create_time: typing.Optional[datetime.datetime]'
    docstring: The Timestamp of when the FileSearchStore was created.
  - signature: 'update_time: typing.Optional[datetime.datetime]'
    docstring: The Timestamp of when the FileSearchStore was last updated.
  - signature: 'active_documents_count: typing.Optional[int]'
    docstring: The number of documents in the FileSearchStore that are active and ready for retrieval.
  - signature: 'pending_documents_count: typing.Optional[int]'
    docstring: The number of documents in the FileSearchStore that are being processed.
  - signature: 'failed_documents_count: typing.Optional[int]'
    docstring: The number of documents in the FileSearchStore that have failed processing.
  - signature: 'size_bytes: typing.Optional[int]'
    docstring: 'The size of raw bytes ingested into the FileSearchStore. This is the

      total size of all the documents in the FileSearchStore.'
  omitted_inherited_members_from:
  - TypedDict
- rank: 2169
  id: google.genai.types.FileSource
  name: FileSource
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Source of the File.


    [Note: Inherited members from _common.CaseInSensitiveEnum are omitted.]'
  properties:
  - signature: 'SOURCE_UNSPECIFIED: str'
  - signature: 'UPLOADED: str'
  - signature: 'GENERATED: str'
  omitted_inherited_members_from:
  - _common.CaseInSensitiveEnum
- rank: 2170
  id: google.genai.types.FileState
  name: FileState
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'State for the lifecycle of a File.


    [Note: Inherited members from _common.CaseInSensitiveEnum are omitted.]'
  properties:
  - signature: 'STATE_UNSPECIFIED: str'
  - signature: 'PROCESSING: str'
  - signature: 'ACTIVE: str'
  - signature: 'FAILED: str'
  omitted_inherited_members_from:
  - _common.CaseInSensitiveEnum
- rank: 2171
  id: google.genai.types.FileStatus
  name: FileStatus
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Status of a File that uses a common error model.


    [Note: Inherited members from _common.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, details: typing.Optional[list[dict[str, typing.Any]]] = None, message: typing.Optional[str] = None, code: typing.Optional[int] = None):'
  properties:
  - signature: 'details: typing.Optional[list[dict[str, typing.Any]]]'
  - signature: 'message: typing.Optional[str]'
  - signature: 'code: typing.Optional[int]'
  omitted_inherited_members_from:
  - _common.BaseModel
- rank: 2172
  id: google.genai.types.FileStatusDict
  name: FileStatusDict
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Status of a File that uses a common error model.


    [Note: Inherited members from TypedDict are omitted.]'
  properties:
  - signature: 'details: typing.Optional[list[dict[str, typing.Any]]]'
    docstring: A list of messages that carry the error details. There is a common set of message types for APIs to use.
  - signature: 'message: typing.Optional[str]'
    docstring: A list of messages that carry the error details. There is a common set of message types for APIs to use.
  - signature: 'code: typing.Optional[int]'
    docstring: The status code. 0 for OK, 1 for CANCELLED
  omitted_inherited_members_from:
  - TypedDict
- rank: 2173
  id: google.genai.types.FinishReason
  name: FinishReason
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Output only. The reason why the model stopped generating tokens.


    If empty, the model has not stopped generating the tokens.


    [Note: Inherited members from _common.CaseInSensitiveEnum are omitted.]'
  properties:
  - signature: 'FINISH_REASON_UNSPECIFIED: str'
    docstring: The finish reason is unspecified.
  - signature: 'STOP: str'
    docstring: Token generation reached a natural stopping point or a configured stop sequence.
  - signature: 'MAX_TOKENS: str'
    docstring: Token generation reached the configured maximum output tokens.
  - signature: 'SAFETY: str'
    docstring: 'Token generation stopped because the content potentially contains safety violations. NOTE: When streaming, [content][] is empty if content filters blocks the output.'
  - signature: 'RECITATION: str'
    docstring: The token generation stopped because of potential recitation.
  - signature: 'LANGUAGE: str'
    docstring: The token generation stopped because of using an unsupported language.
  - signature: 'OTHER: str'
    docstring: All other reasons that stopped the token generation.
  - signature: 'BLOCKLIST: str'
    docstring: Token generation stopped because the content contains forbidden terms.
  - signature: 'PROHIBITED_CONTENT: str'
    docstring: Token generation stopped for potentially containing prohibited content.
  - signature: 'SPII: str'
    docstring: Token generation stopped because the content potentially contains Sensitive Personally Identifiable Information (SPII).
  - signature: 'MALFORMED_FUNCTION_CALL: str'
    docstring: The function call generated by the model is invalid.
  - signature: 'IMAGE_SAFETY: str'
    docstring: Token generation stopped because generated images have safety violations.
  - signature: 'UNEXPECTED_TOOL_CALL: str'
    docstring: The tool call generated by the model is invalid.
  - signature: 'IMAGE_PROHIBITED_CONTENT: str'
    docstring: Image generation stopped because the generated images have prohibited content.
  - signature: 'NO_IMAGE: str'
    docstring: The model was expected to generate an image, but none was generated.
  omitted_inherited_members_from:
  - _common.CaseInSensitiveEnum
- rank: 2174
  id: google.genai.types.FunctionCall
  name: FunctionCall
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'A function call.


    [Note: Inherited members from _common.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, id: typing.Optional[str] = None, args: typing.Optional[dict[str, typing.Any]] = None, name: typing.Optional[str] = None, partial_args: typing.Optional[list[google.genai.types.PartialArg]] = None, will_continue: typing.Optional[bool] = None):'
  properties:
  - signature: 'id: typing.Optional[str]'
  - signature: 'args: typing.Optional[dict[str, typing.Any]]'
  - signature: 'name: typing.Optional[str]'
  - signature: 'partial_args: typing.Optional[list[google.genai.types.PartialArg]]'
  - signature: 'will_continue: typing.Optional[bool]'
  omitted_inherited_members_from:
  - _common.BaseModel
- rank: 2175
  id: google.genai.types.FunctionCallDict
  name: FunctionCallDict
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'A function call.


    [Note: Inherited members from TypedDict are omitted.]'
  properties:
  - signature: 'id: typing.Optional[str]'
    docstring: 'The unique id of the function call. If populated, the client to execute the

      `function_call` and return the response with the matching `id`.'
  - signature: 'args: typing.Optional[dict[str, typing.Any]]'
    docstring: Optional. The function parameters and values in JSON object format. See [FunctionDeclaration.parameters] for parameter details.
  - signature: 'name: typing.Optional[str]'
    docstring: Optional. The name of the function to call. Matches [FunctionDeclaration.name].
  - signature: 'partial_args: typing.Optional[list[google.genai.types.PartialArgDict]]'
    docstring: Optional. The partial argument value of the function call. If provided, represents the arguments/fields that are streamed incrementally. This field is not supported in Gemini API.
  - signature: 'will_continue: typing.Optional[bool]'
    docstring: Optional. Whether this is the last part of the FunctionCall. If true, another partial message for the current FunctionCall is expected to follow. This field is not supported in Gemini API.
  omitted_inherited_members_from:
  - TypedDict
- rank: 2176
  id: google.genai.types.FunctionCallingConfig
  name: FunctionCallingConfig
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Function calling config.


    [Note: Inherited members from _common.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, mode: typing.Optional[google.genai.types.FunctionCallingConfigMode] = None, allowed_function_names: typing.Optional[list[str]] = None, stream_function_call_arguments: typing.Optional[bool] = None):'
  properties:
  - signature: 'mode: typing.Optional[google.genai.types.FunctionCallingConfigMode]'
  - signature: 'allowed_function_names: typing.Optional[list[str]]'
  - signature: 'stream_function_call_arguments: typing.Optional[bool]'
  omitted_inherited_members_from:
  - _common.BaseModel
- rank: 2177
  id: google.genai.types.FunctionCallingConfigDict
  name: FunctionCallingConfigDict
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Function calling config.


    [Note: Inherited members from TypedDict are omitted.]'
  properties:
  - signature: 'mode: typing.Optional[google.genai.types.FunctionCallingConfigMode]'
    docstring: Optional. Function calling mode.
  - signature: 'allowed_function_names: typing.Optional[list[str]]'
    docstring: Optional. Function names to call. Only set when the Mode is ANY. Function names should match [FunctionDeclaration.name]. With mode set to ANY, model will predict a function call from the set of function names provided.
  - signature: 'stream_function_call_arguments: typing.Optional[bool]'
    docstring: Optional. When set to true, arguments of a single function call will be streamed out in multiple parts/contents/responses. Partial parameter results will be returned in the [FunctionCall.partial_args] field. This field is not supported in Gemini API.
  omitted_inherited_members_from:
  - TypedDict
- rank: 2178
  id: google.genai.types.FunctionCallingConfigMode
  name: FunctionCallingConfigMode
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Config for the function calling config mode.


    [Note: Inherited members from _common.CaseInSensitiveEnum are omitted.]'
  properties:
  - signature: 'MODE_UNSPECIFIED: str'
    docstring: The function calling config mode is unspecified. Should not be used.
  - signature: 'AUTO: str'
    docstring: Default model behavior, model decides to predict either function calls or natural language response.
  - signature: 'ANY: str'
    docstring: Model is constrained to always predicting function calls only. If "allowed_function_names" are set, the predicted function calls will be limited to any one of "allowed_function_names", else the predicted function calls will be any one of the provided "function_declarations".
  - signature: 'NONE: str'
    docstring: Model will not predict any function calls. Model behavior is same as when not passing any function declarations.
  - signature: 'VALIDATED: str'
    docstring: Model decides to predict either a function call or a natural language response, but will validate function calls with constrained decoding. If "allowed_function_names" are set, the predicted function call will be limited to any one of "allowed_function_names", else the predicted function call will be any one of the provided "function_declarations".
  omitted_inherited_members_from:
  - _common.CaseInSensitiveEnum
- rank: 2179
  id: google.genai.types.FunctionDeclaration
  name: FunctionDeclaration
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Defines a function that the model can generate JSON inputs for.


    The inputs are based on `OpenAPI 3.0 specifications

    <https://spec.openapis.org/oas/v3.0.3>`_.


    [Note: Inherited members from _common.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, behavior: typing.Optional[google.genai.types.Behavior] = None, description: typing.Optional[str] = None, name: typing.Optional[str] = None, parameters: typing.Optional[google.genai.types.Schema] = None, parameters_json_schema: typing.Optional[typing.Any] = None, response: typing.Optional[google.genai.types.Schema] = None, response_json_schema: typing.Optional[typing.Any] = None):'
  methods:
  - signature: 'def from_callable_with_api_option(cls, *, callable: typing.Callable[Ellipsis, typing.Any], api_option: typing.Literal[VERTEX_AI, GEMINI_API]=''GEMINI_API'', behavior: typing.Optional[google.genai.types.Behavior]=None) -> google.genai.types.FunctionDeclaration:'
    docstring: 'Converts a Callable to a FunctionDeclaration based on the API option.


      Supported API option is ''VERTEX_AI'' or ''GEMINI_API''. If api_option is unset,

      it will default to ''GEMINI_API''. If unsupported api_option is provided, it

      will raise ValueError.'
  - signature: 'def from_callable(cls, *, client: google.genai._api_client.BaseApiClient, callable: typing.Callable[Ellipsis, typing.Any], behavior: typing.Optional[google.genai.types.Behavior]=None) -> google.genai.types.FunctionDeclaration:'
    docstring: 'Converts a Callable to a FunctionDeclaration based on the client.


      Note: For best results prefer

      [Google-style

      docstring](https://google.github.io/styleguide/pyguide.html#383-functions-and-methods)

      when describing arguments. This function does **not** parse argument

      descriptions into the property description slots of the resulting structure.

      Instead it sends the whole docstring in the top-level function description.

      Google-style docstring are closest to what the model is trained on.'
  properties:
  - signature: 'behavior: typing.Optional[google.genai.types.Behavior]'
  - signature: 'description: typing.Optional[str]'
  - signature: 'name: typing.Optional[str]'
  - signature: 'parameters: typing.Optional[google.genai.types.Schema]'
  - signature: 'parameters_json_schema: typing.Optional[typing.Any]'
  - signature: 'response: typing.Optional[google.genai.types.Schema]'
  - signature: 'response_json_schema: typing.Optional[typing.Any]'
  omitted_inherited_members_from:
  - _common.BaseModel
- rank: 2180
  id: google.genai.types.FunctionDeclaration.from_callable
  name: from_callable
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: 'Converts a Callable to a FunctionDeclaration based on the client.


    Note: For best results prefer

    [Google-style

    docstring](https://google.github.io/styleguide/pyguide.html#383-functions-and-methods)

    when describing arguments. This function does **not** parse argument

    descriptions into the property description slots of the resulting structure.

    Instead it sends the whole docstring in the top-level function description.

    Google-style docstring are closest to what the model is trained on.'
  signature: 'def from_callable(cls, *, client: google.genai._api_client.BaseApiClient, callable: typing.Callable[Ellipsis, typing.Any], behavior: typing.Optional[google.genai.types.Behavior]=None) -> google.genai.types.FunctionDeclaration:'
- rank: 2181
  id: google.genai.types.FunctionDeclaration.from_callable_with_api_option
  name: from_callable_with_api_option
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: 'Converts a Callable to a FunctionDeclaration based on the API option.


    Supported API option is ''VERTEX_AI'' or ''GEMINI_API''. If api_option is unset,

    it will default to ''GEMINI_API''. If unsupported api_option is provided, it

    will raise ValueError.'
  signature: 'def from_callable_with_api_option(cls, *, callable: typing.Callable[Ellipsis, typing.Any], api_option: typing.Literal[VERTEX_AI, GEMINI_API]=''GEMINI_API'', behavior: typing.Optional[google.genai.types.Behavior]=None) -> google.genai.types.FunctionDeclaration:'
- rank: 2182
  id: google.genai.types.FunctionDeclarationDict
  name: FunctionDeclarationDict
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Defines a function that the model can generate JSON inputs for.


    The inputs are based on `OpenAPI 3.0 specifications

    <https://spec.openapis.org/oas/v3.0.3>`_.


    [Note: Inherited members from TypedDict are omitted.]'
  properties:
  - signature: 'behavior: typing.Optional[google.genai.types.Behavior]'
    docstring: Defines the function behavior.
  - signature: 'description: typing.Optional[str]'
    docstring: Optional. Description and purpose of the function. Model uses it to decide how and whether to call the function.
  - signature: 'name: typing.Optional[str]'
    docstring: Required. The name of the function to call. Must start with a letter or an underscore. Must be a-z, A-Z, 0-9, or contain underscores, dots and dashes, with a maximum length of 64.
  - signature: 'parameters: typing.Optional[google.genai.types.SchemaDict]'
    docstring: 'Optional. Describes the parameters to this function in JSON Schema Object format. Reflects the Open API 3.03 Parameter Object. string Key: the name of the parameter. Parameter names are case sensitive. Schema Value: the Schema defining the type used for the parameter. For function with no parameters, this can be left unset. Parameter names must start with a letter or an underscore and must only contain chars a-z, A-Z, 0-9, or underscores with a maximum length of 64. Example with 1 required and 1 optional parameter: type: OBJECT properties: param1: type: STRING param2: type: INTEGER required: - param1'
  - signature: 'parameters_json_schema: typing.Optional[typing.Any]'
    docstring: 'Optional. Describes the parameters to the function in JSON Schema format. The schema must describe an object where the properties are the parameters to the function. For example: ``` { "type": "object", "properties": { "name": { "type": "string" }, "age": { "type": "integer" } }, "additionalProperties": false, "required": ["name", "age"], "propertyOrdering": ["name", "age"] } ``` This field is mutually exclusive with `parameters`.'
  - signature: 'response: typing.Optional[google.genai.types.SchemaDict]'
    docstring: Optional. Describes the output from this function in JSON Schema format. Reflects the Open API 3.03 Response Object. The Schema defines the type used for the response value of the function.
  - signature: 'response_json_schema: typing.Optional[typing.Any]'
    docstring: Optional. Describes the output from this function in JSON Schema format. The value specified by the schema is the response value of the function. This field is mutually exclusive with `response`.
  omitted_inherited_members_from:
  - TypedDict
- rank: 2183
  id: google.genai.types.FunctionResponse
  name: FunctionResponse
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'A function response.


    [Note: Inherited members from _common.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, will_continue: typing.Optional[bool] = None, scheduling: typing.Optional[google.genai.types.FunctionResponseScheduling] = None, parts: typing.Optional[list[google.genai.types.FunctionResponsePart]] = None, id: typing.Optional[str] = None, name: typing.Optional[str] = None, response: typing.Optional[dict[str, typing.Any]] = None):'
  methods:
  - signature: 'def from_mcp_response(cls, *, name: str, response: mcp.types.CallToolResult) -> google.genai.types.FunctionResponse:'
  properties:
  - signature: 'will_continue: typing.Optional[bool]'
  - signature: 'scheduling: typing.Optional[google.genai.types.FunctionResponseScheduling]'
  - signature: 'parts: typing.Optional[list[google.genai.types.FunctionResponsePart]]'
  - signature: 'id: typing.Optional[str]'
  - signature: 'name: typing.Optional[str]'
  - signature: 'response: typing.Optional[dict[str, typing.Any]]'
  omitted_inherited_members_from:
  - _common.BaseModel
- rank: 2184
  id: google.genai.types.FunctionResponse.from_mcp_response
  name: from_mcp_response
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def from_mcp_response(cls, *, name: str, response: mcp.types.CallToolResult) -> google.genai.types.FunctionResponse:'
- rank: 2185
  id: google.genai.types.FunctionResponseBlob
  name: FunctionResponseBlob
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Raw media bytes for function response.


    Text should not be sent as raw bytes, use the FunctionResponse.response

    field.


    [Note: Inherited members from _common.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, mime_type: typing.Optional[str] = None, data: typing.Optional[bytes] = None, display_name: typing.Optional[str] = None):'
  properties:
  - signature: 'mime_type: typing.Optional[str]'
  - signature: 'data: typing.Optional[bytes]'
  - signature: 'display_name: typing.Optional[str]'
  omitted_inherited_members_from:
  - _common.BaseModel
- rank: 2186
  id: google.genai.types.FunctionResponseBlobDict
  name: FunctionResponseBlobDict
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Raw media bytes for function response.


    Text should not be sent as raw bytes, use the FunctionResponse.response

    field.


    [Note: Inherited members from TypedDict are omitted.]'
  properties:
  - signature: 'mime_type: typing.Optional[str]'
    docstring: Required. The IANA standard MIME type of the source data.
  - signature: 'data: typing.Optional[bytes]'
    docstring: Required. Inline media bytes.
  - signature: 'display_name: typing.Optional[str]'
    docstring: 'Optional. Display name of the blob.

      Used to provide a label or filename to distinguish blobs.'
  omitted_inherited_members_from:
  - TypedDict
- rank: 2187
  id: google.genai.types.FunctionResponseDict
  name: FunctionResponseDict
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'A function response.


    [Note: Inherited members from TypedDict are omitted.]'
  properties:
  - signature: 'will_continue: typing.Optional[bool]'
    docstring: Signals that function call continues, and more responses will be returned, turning the function call into a generator. Is only applicable to NON_BLOCKING function calls (see FunctionDeclaration.behavior for details), ignored otherwise. If false, the default, future responses will not be considered. Is only applicable to NON_BLOCKING function calls, is ignored otherwise. If set to false, future responses will not be considered. It is allowed to return empty `response` with `will_continue=False` to signal that the function call is finished.
  - signature: 'scheduling: typing.Optional[google.genai.types.FunctionResponseScheduling]'
    docstring: Specifies how the response should be scheduled in the conversation. Only applicable to NON_BLOCKING function calls, is ignored otherwise. Defaults to WHEN_IDLE.
  - signature: 'parts: typing.Optional[list[google.genai.types.FunctionResponsePartDict]]'
    docstring: 'List of parts that constitute a function response. Each part may

      have a different IANA MIME type.'
  - signature: 'id: typing.Optional[str]'
    docstring: Optional. The id of the function call this response is for. Populated by the client to match the corresponding function call `id`.
  - signature: 'name: typing.Optional[str]'
    docstring: Required. The name of the function to call. Matches [FunctionDeclaration.name] and [FunctionCall.name].
  - signature: 'response: typing.Optional[dict[str, typing.Any]]'
    docstring: Required. The function response in JSON object format. Use "output" key to specify function output and "error" key to specify error details (if any). If "output" and "error" keys are not specified, then whole "response" is treated as function output.
  omitted_inherited_members_from:
  - TypedDict
- rank: 2188
  id: google.genai.types.FunctionResponseFileData
  name: FunctionResponseFileData
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'URI based data for function response.


    [Note: Inherited members from _common.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, file_uri: typing.Optional[str] = None, mime_type: typing.Optional[str] = None, display_name: typing.Optional[str] = None):'
  properties:
  - signature: 'file_uri: typing.Optional[str]'
  - signature: 'mime_type: typing.Optional[str]'
  - signature: 'display_name: typing.Optional[str]'
  omitted_inherited_members_from:
  - _common.BaseModel
- rank: 2189
  id: google.genai.types.FunctionResponseFileDataDict
  name: FunctionResponseFileDataDict
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'URI based data for function response.


    [Note: Inherited members from TypedDict are omitted.]'
  properties:
  - signature: 'file_uri: typing.Optional[str]'
    docstring: Required. URI.
  - signature: 'mime_type: typing.Optional[str]'
    docstring: Required. The IANA standard MIME type of the source data.
  - signature: 'display_name: typing.Optional[str]'
    docstring: 'Optional. Display name of the file.

      Used to provide a label or filename to distinguish files.'
  omitted_inherited_members_from:
  - TypedDict
- rank: 2190
  id: google.genai.types.FunctionResponsePart
  name: FunctionResponsePart
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'A datatype containing media that is part of a `FunctionResponse` message.


    A `FunctionResponsePart` consists of data which has an associated datatype. A

    `FunctionResponsePart` can only contain one of the accepted types in

    `FunctionResponsePart.data`.


    A `FunctionResponsePart` must have a fixed IANA MIME type identifying the

    type and subtype of the media if the `inline_data` field is filled with raw

    bytes.


    [Note: Inherited members from _common.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, inline_data: typing.Optional[google.genai.types.FunctionResponseBlob] = None, file_data: typing.Optional[google.genai.types.FunctionResponseFileData] = None):'
  methods:
  - signature: 'def from_bytes(cls, *, data: bytes, mime_type: str) -> google.genai.types.FunctionResponsePart:'
    docstring: "Creates a FunctionResponsePart from bytes and mime type.\n\nArgs:\n  data (bytes): The bytes of the data\n  mime_type (str): mime_type: The MIME type of the data."
  - signature: 'def from_uri(cls, *, file_uri: str, mime_type: typing.Optional[str]=None) -> google.genai.types.FunctionResponsePart:'
    docstring: "Creates a FunctionResponsePart from a file uri.\n\nArgs:\n  file_uri (str): The uri of the file\n  mime_type (str): mime_type: The MIME type of the file. If not provided,\n    the MIME type will be automatically determined."
  properties:
  - signature: 'inline_data: typing.Optional[google.genai.types.FunctionResponseBlob]'
  - signature: 'file_data: typing.Optional[google.genai.types.FunctionResponseFileData]'
  omitted_inherited_members_from:
  - _common.BaseModel
- rank: 2191
  id: google.genai.types.FunctionResponsePart.from_bytes
  name: from_bytes
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Creates a FunctionResponsePart from bytes and mime type.\n\nArgs:\n  data (bytes): The bytes of the data\n  mime_type (str): mime_type: The MIME type of the data."
  signature: 'def from_bytes(cls, *, data: bytes, mime_type: str) -> google.genai.types.FunctionResponsePart:'
- rank: 2192
  id: google.genai.types.FunctionResponsePart.from_uri
  name: from_uri
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Creates a FunctionResponsePart from a file uri.\n\nArgs:\n  file_uri (str): The uri of the file\n  mime_type (str): mime_type: The MIME type of the file. If not provided,\n    the MIME type will be automatically determined."
  signature: 'def from_uri(cls, *, file_uri: str, mime_type: typing.Optional[str]=None) -> google.genai.types.FunctionResponsePart:'
- rank: 2193
  id: google.genai.types.FunctionResponsePartDict
  name: FunctionResponsePartDict
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'A datatype containing media that is part of a `FunctionResponse` message.


    A `FunctionResponsePart` consists of data which has an associated datatype. A

    `FunctionResponsePart` can only contain one of the accepted types in

    `FunctionResponsePart.data`.


    A `FunctionResponsePart` must have a fixed IANA MIME type identifying the

    type and subtype of the media if the `inline_data` field is filled with raw

    bytes.


    [Note: Inherited members from TypedDict are omitted.]'
  properties:
  - signature: 'inline_data: typing.Optional[google.genai.types.FunctionResponseBlobDict]'
    docstring: Optional. Inline media bytes.
  - signature: 'file_data: typing.Optional[google.genai.types.FunctionResponseFileDataDict]'
    docstring: Optional. URI based data.
  omitted_inherited_members_from:
  - TypedDict
- rank: 2194
  id: google.genai.types.FunctionResponseScheduling
  name: FunctionResponseScheduling
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Specifies how the response should be scheduled in the conversation.


    [Note: Inherited members from _common.CaseInSensitiveEnum are omitted.]'
  properties:
  - signature: 'SCHEDULING_UNSPECIFIED: str'
    docstring: This value is unused.
  - signature: 'SILENT: str'
    docstring: Only add the result to the conversation context, do not interrupt or trigger generation.
  - signature: 'WHEN_IDLE: str'
    docstring: Add the result to the conversation context, and prompt to generate output without interrupting ongoing generation.
  - signature: 'INTERRUPT: str'
    docstring: Add the result to the conversation context, interrupt ongoing generation and prompt to generate output.
  omitted_inherited_members_from:
  - _common.CaseInSensitiveEnum
- rank: 2195
  id: google.genai.types.GcsDestination
  name: GcsDestination
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'The Google Cloud Storage location where the output is to be written to.


    [Note: Inherited members from _common.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, output_uri_prefix: typing.Optional[str] = None):'
  properties:
  - signature: 'output_uri_prefix: typing.Optional[str]'
  omitted_inherited_members_from:
  - _common.BaseModel
- rank: 2196
  id: google.genai.types.GcsDestinationDict
  name: GcsDestinationDict
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'The Google Cloud Storage location where the output is to be written to.


    [Note: Inherited members from TypedDict are omitted.]'
  properties:
  - signature: 'output_uri_prefix: typing.Optional[str]'
    docstring: Required. Google Cloud Storage URI to output directory. If the uri doesn't end with '/', a '/' will be automatically appended. The directory is created if it doesn't exist.
  omitted_inherited_members_from:
  - TypedDict
- rank: 2197
  id: google.genai.types.GeminiPreferenceExample
  name: GeminiPreferenceExample
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Input example for preference optimization.


    This data type is not supported in Gemini API.


    [Note: Inherited members from _common.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, completions: typing.Optional[list[google.genai.types.GeminiPreferenceExampleCompletion]] = None, contents: typing.Optional[list[google.genai.types.Content]] = None):'
  properties:
  - signature: 'completions: typing.Optional[list[google.genai.types.GeminiPreferenceExampleCompletion]]'
  - signature: 'contents: typing.Optional[list[google.genai.types.Content]]'
  omitted_inherited_members_from:
  - _common.BaseModel
- rank: 2198
  id: google.genai.types.GeminiPreferenceExampleCompletion
  name: GeminiPreferenceExampleCompletion
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Completion and its preference score.


    This data type is not supported in Gemini API.


    [Note: Inherited members from _common.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, completion: typing.Optional[google.genai.types.Content] = None, score: typing.Optional[float] = None):'
  properties:
  - signature: 'completion: typing.Optional[google.genai.types.Content]'
  - signature: 'score: typing.Optional[float]'
  omitted_inherited_members_from:
  - _common.BaseModel
- rank: 2199
  id: google.genai.types.GeminiPreferenceExampleCompletionDict
  name: GeminiPreferenceExampleCompletionDict
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Completion and its preference score.


    This data type is not supported in Gemini API.


    [Note: Inherited members from TypedDict are omitted.]'
  properties:
  - signature: 'completion: typing.Optional[google.genai.types.ContentDict]'
    docstring: Single turn completion for the given prompt.
  - signature: 'score: typing.Optional[float]'
    docstring: The score for the given completion.
  omitted_inherited_members_from:
  - TypedDict
- rank: 2200
  id: google.genai.types.GeminiPreferenceExampleDict
  name: GeminiPreferenceExampleDict
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Input example for preference optimization.


    This data type is not supported in Gemini API.


    [Note: Inherited members from TypedDict are omitted.]'
  properties:
  - signature: 'completions: typing.Optional[list[google.genai.types.GeminiPreferenceExampleCompletionDict]]'
    docstring: List of completions for a given prompt.
  - signature: 'contents: typing.Optional[list[google.genai.types.ContentDict]]'
    docstring: Multi-turn contents that represents the Prompt.
  omitted_inherited_members_from:
  - TypedDict
- rank: 2201
  id: google.genai.types.GenerateContentConfig
  name: GenerateContentConfig
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Optional model configuration parameters.


    For more information, see `Content generation parameters

    <https://cloud.google.com/vertex-ai/generative-ai/docs/multimodal/content-generation-parameters>`_.


    [Note: Inherited members from _common.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, http_options: typing.Optional[google.genai.types.HttpOptions] = None, should_return_http_response: typing.Optional[bool] = None, system_instruction: typing.Optional[google.genai.types.ContentUnion] = None, temperature: typing.Optional[float] = None, top_p: typing.Optional[float] = None, top_k: typing.Optional[float] = None, candidate_count: typing.Optional[int] = None, max_output_tokens: typing.Optional[int] = None, stop_sequences: typing.Optional[list[str]] = None, response_logprobs: typing.Optional[bool] = None, logprobs: typing.Optional[int] = None, presence_penalty: typing.Optional[float] = None, frequency_penalty: typing.Optional[float] = None, seed: typing.Optional[int] = None, response_mime_type: typing.Optional[str] = None, response_schema: typing.Optional[google.genai.types.SchemaUnion] = None, response_json_schema: typing.Optional[typing.Any] = None, routing_config: typing.Optional[google.genai.types.GenerationConfigRoutingConfig]
    = None, model_selection_config: typing.Optional[google.genai.types.ModelSelectionConfig] = None, safety_settings: typing.Optional[list[google.genai.types.SafetySetting]] = None, tools: typing.Optional[google.genai.types.ToolListUnion] = None, tool_config: typing.Optional[google.genai.types.ToolConfig] = None, labels: typing.Optional[dict[str, str]] = None, cached_content: typing.Optional[str] = None, response_modalities: typing.Optional[list[str]] = None, media_resolution: typing.Optional[google.genai.types.MediaResolution] = None, speech_config: typing.Optional[google.genai.types.SpeechConfigUnion] = None, audio_timestamp: typing.Optional[bool] = None, automatic_function_calling: typing.Optional[google.genai.types.AutomaticFunctionCallingConfig] = None, thinking_config: typing.Optional[google.genai.types.ThinkingConfig] = None, image_config: typing.Optional[google.genai.types.ImageConfig] = None):'
  properties:
  - signature: 'http_options: typing.Optional[google.genai.types.HttpOptions]'
  - signature: 'should_return_http_response: typing.Optional[bool]'
  - signature: 'system_instruction: typing.Optional[google.genai.types.ContentUnion]'
  - signature: 'temperature: typing.Optional[float]'
  - signature: 'top_p: typing.Optional[float]'
  - signature: 'top_k: typing.Optional[float]'
  - signature: 'candidate_count: typing.Optional[int]'
  - signature: 'max_output_tokens: typing.Optional[int]'
  - signature: 'stop_sequences: typing.Optional[list[str]]'
  - signature: 'response_logprobs: typing.Optional[bool]'
  - signature: 'logprobs: typing.Optional[int]'
  - signature: 'presence_penalty: typing.Optional[float]'
  - signature: 'frequency_penalty: typing.Optional[float]'
  - signature: 'seed: typing.Optional[int]'
  - signature: 'response_mime_type: typing.Optional[str]'
  - signature: 'response_schema: typing.Optional[google.genai.types.SchemaUnion]'
  - signature: 'response_json_schema: typing.Optional[typing.Any]'
  - signature: 'routing_config: typing.Optional[google.genai.types.GenerationConfigRoutingConfig]'
  - signature: 'model_selection_config: typing.Optional[google.genai.types.ModelSelectionConfig]'
  - signature: 'safety_settings: typing.Optional[list[google.genai.types.SafetySetting]]'
  - signature: 'tools: typing.Optional[google.genai.types.ToolListUnion]'
  - signature: 'tool_config: typing.Optional[google.genai.types.ToolConfig]'
  - signature: 'labels: typing.Optional[dict[str, str]]'
  - signature: 'cached_content: typing.Optional[str]'
  - signature: 'response_modalities: typing.Optional[list[str]]'
  - signature: 'media_resolution: typing.Optional[google.genai.types.MediaResolution]'
  - signature: 'speech_config: typing.Optional[google.genai.types.SpeechConfigUnion]'
  - signature: 'audio_timestamp: typing.Optional[bool]'
  - signature: 'automatic_function_calling: typing.Optional[google.genai.types.AutomaticFunctionCallingConfig]'
  - signature: 'thinking_config: typing.Optional[google.genai.types.ThinkingConfig]'
  - signature: 'image_config: typing.Optional[google.genai.types.ImageConfig]'
  omitted_inherited_members_from:
  - _common.BaseModel
- rank: 2202
  id: google.genai.types.GenerateContentConfigDict
  name: GenerateContentConfigDict
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Optional model configuration parameters.


    For more information, see `Content generation parameters

    <https://cloud.google.com/vertex-ai/generative-ai/docs/multimodal/content-generation-parameters>`_.


    [Note: Inherited members from TypedDict are omitted.]'
  properties:
  - signature: 'http_options: typing.Optional[google.genai.types.HttpOptionsDict]'
    docstring: Used to override HTTP request options.
  - signature: 'should_return_http_response: typing.Optional[bool]'
    docstring: If true, the raw HTTP response will be returned in the 'sdk_http_response' field.
  - signature: 'system_instruction: typing.Optional[google.genai.types.ContentUnionDict]'
    docstring: 'Instructions for the model to steer it toward better performance.

      For example, "Answer as concisely as possible" or "Don''t use technical

      terms in your response".'
  - signature: 'temperature: typing.Optional[float]'
    docstring: 'Value that controls the degree of randomness in token selection.

      Lower temperatures are good for prompts that require a less open-ended or

      creative response, while higher temperatures can lead to more diverse or

      creative results.'
  - signature: 'top_p: typing.Optional[float]'
    docstring: 'Tokens are selected from the most to least probable until the sum

      of their probabilities equals this value. Use a lower value for less

      random responses and a higher value for more random responses.'
  - signature: 'top_k: typing.Optional[float]'
    docstring: 'For each token selection step, the ``top_k`` tokens with the

      highest probabilities are sampled. Then tokens are further filtered based

      on ``top_p`` with the final token selected using temperature sampling. Use

      a lower number for less random responses and a higher number for more

      random responses.'
  - signature: 'candidate_count: typing.Optional[int]'
    docstring: "Number of response variations to return.\n      "
  - signature: 'max_output_tokens: typing.Optional[int]'
    docstring: "Maximum number of tokens that can be generated in the response.\n      "
  - signature: 'stop_sequences: typing.Optional[list[str]]'
    docstring: 'List of strings that tells the model to stop generating text if one

      of the strings is encountered in the response.'
  - signature: 'response_logprobs: typing.Optional[bool]'
    docstring: 'Whether to return the log probabilities of the tokens that were

      chosen by the model at each step.'
  - signature: 'logprobs: typing.Optional[int]'
    docstring: 'Number of top candidate tokens to return the log probabilities for

      at each generation step.'
  - signature: 'presence_penalty: typing.Optional[float]'
    docstring: 'Positive values penalize tokens that already appear in the

      generated text, increasing the probability of generating more diverse

      content.'
  - signature: 'frequency_penalty: typing.Optional[float]'
    docstring: 'Positive values penalize tokens that repeatedly appear in the

      generated text, increasing the probability of generating more diverse

      content.'
  - signature: 'seed: typing.Optional[int]'
    docstring: 'When ``seed`` is fixed to a specific number, the model makes a best

      effort to provide the same response for repeated requests. By default, a

      random number is used.'
  - signature: 'response_mime_type: typing.Optional[str]'
    docstring: "Output response mimetype of the generated candidate text.\nSupported mimetype:\n  - `text/plain`: (default) Text output.\n  - `application/json`: JSON response in the candidates.\nThe model needs to be prompted to output the appropriate response type,\notherwise the behavior is undefined.\nThis is a preview feature."
  - signature: 'response_schema: typing.Optional[google.genai.types.SchemaUnionDict]'
    docstring: 'The `Schema` object allows the definition of input and output data types.

      These types can be objects, but also primitives and arrays.

      Represents a select subset of an [OpenAPI 3.0 schema

      object](https://spec.openapis.org/oas/v3.0.3#schema).

      If set, a compatible response_mime_type must also be set.

      Compatible mimetypes: `application/json`: Schema for JSON response.


      If `response_schema` doesn''t process your schema correctly, try using

      `response_json_schema` instead.'
  - signature: 'response_json_schema: typing.Optional[typing.Any]'
    docstring: 'Optional. Output schema of the generated response.

      This is an alternative to `response_schema` that accepts [JSON

      Schema](https://json-schema.org/). If set, `response_schema` must be

      omitted, but `response_mime_type` is required. While the full JSON Schema

      may be sent, not all features are supported. Specifically, only the

      following properties are supported: - `$id` - `$defs` - `$ref` - `$anchor`

      - `type` - `format` - `title` - `description` - `enum` (for strings and

      numbers) - `items` - `prefixItems` - `minItems` - `maxItems` - `minimum` -

      `maximum` - `anyOf` - `oneOf` (interpreted the same as `anyOf`) -

      `properties` - `additionalProperties` - `required` The non-standard

      `propertyOrdering` property may also be set. Cyclic references are

      unrolled to a limited degree and, as such, may only be used within

      non-required properties. (Nullable properties are not sufficient.) If

      `$ref` is set on a sub-schema, no other properties, except for than those

      starting as a `$`, may be set.'
  - signature: 'routing_config: typing.Optional[google.genai.types.GenerationConfigRoutingConfigDict]'
    docstring: "Configuration for model router requests.\n      "
  - signature: 'model_selection_config: typing.Optional[google.genai.types.ModelSelectionConfigDict]'
    docstring: "Configuration for model selection.\n      "
  - signature: 'safety_settings: typing.Optional[list[google.genai.types.SafetySettingDict]]'
    docstring: 'Safety settings in the request to block unsafe content in the

      response.'
  - signature: 'tools: typing.Optional[google.genai.types.ToolListUnionDict]'
    docstring: 'Code that enables the system to interact with external systems to

      perform an action outside of the knowledge and scope of the model.'
  - signature: 'tool_config: typing.Optional[google.genai.types.ToolConfigDict]'
    docstring: "Associates model output to a specific function call.\n      "
  - signature: 'labels: typing.Optional[dict[str, str]]'
    docstring: Labels with user-defined metadata to break down billed charges.
  - signature: 'cached_content: typing.Optional[str]'
    docstring: 'Resource name of a context cache that can be used in subsequent

      requests.'
  - signature: 'response_modalities: typing.Optional[list[str]]'
    docstring: 'The requested modalities of the response. Represents the set of

      modalities that the model can return.'
  - signature: 'media_resolution: typing.Optional[google.genai.types.MediaResolution]'
    docstring: "If specified, the media resolution specified will be used.\n    "
  - signature: 'speech_config: typing.Optional[google.genai.types.SpeechConfigUnionDict]'
    docstring: "The speech generation configuration.\n      "
  - signature: 'audio_timestamp: typing.Optional[bool]'
    docstring: 'If enabled, audio timestamp will be included in the request to the

      model.'
  - signature: 'automatic_function_calling: typing.Optional[google.genai.types.AutomaticFunctionCallingConfigDict]'
    docstring: "The configuration for automatic function calling.\n      "
  - signature: 'thinking_config: typing.Optional[google.genai.types.ThinkingConfigDict]'
    docstring: "The thinking features configuration.\n      "
  - signature: 'image_config: typing.Optional[google.genai.types.ImageConfigDict]'
    docstring: "The image generation configuration.\n      "
  omitted_inherited_members_from:
  - TypedDict
- rank: 2203
  id: google.genai.types.GenerateContentResponse
  name: GenerateContentResponse
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Response message for PredictionService.GenerateContent.


    [Note: Inherited members from _common.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, sdk_http_response: typing.Optional[google.genai.types.HttpResponse] = None, candidates: typing.Optional[list[google.genai.types.Candidate]] = None, create_time: typing.Optional[datetime.datetime] = None, model_version: typing.Optional[str] = None, prompt_feedback: typing.Optional[google.genai.types.GenerateContentResponsePromptFeedback] = None, response_id: typing.Optional[str] = None, usage_metadata: typing.Optional[google.genai.types.GenerateContentResponseUsageMetadata] = None, automatic_function_calling_history: typing.Optional[list[google.genai.types.Content]] = None, parsed: typing.Optional[typing.Union[pydantic.BaseModel, dict[typing.Any, typing.Any], enum.Enum]] = None):'
  methods:
  - signature: 'def parts(self) -> typing.Optional[list[google.genai.types.Part]]:'
    docstring: 'Returns the content-parts in the response.


      If there are multiple candidates, returns the parts from only the first one.'
  - signature: 'def text(self) -> typing.Optional[str]:'
    docstring: 'Returns the concatenation of all text parts in the response.


      If there are multiple candidates, returns the text from only the first one.

      If there are non-text parts in the response, this returns only the text

      parts.'
  - signature: 'def function_calls(self) -> typing.Optional[list[google.genai.types.FunctionCall]]:'
    docstring: 'Returns the list of function calls in the response.


      If there are multiple candidates, this returns the function calls from only

      the

      first one.'
  - signature: 'def executable_code(self) -> typing.Optional[str]:'
    docstring: 'Returns the executable code in the response.


      If there are multiple candidates, this returns the executable code from only

      the

      first one.'
  - signature: 'def code_execution_result(self) -> typing.Optional[str]:'
    docstring: 'Returns the code execution result in the response.


      If there are multiple candidates, this returns the code execution result

      from only the

      first one.'
  properties:
  - signature: 'sdk_http_response: typing.Optional[google.genai.types.HttpResponse]'
  - signature: 'candidates: typing.Optional[list[google.genai.types.Candidate]]'
  - signature: 'create_time: typing.Optional[datetime.datetime]'
  - signature: 'model_version: typing.Optional[str]'
  - signature: 'prompt_feedback: typing.Optional[google.genai.types.GenerateContentResponsePromptFeedback]'
  - signature: 'response_id: typing.Optional[str]'
  - signature: 'usage_metadata: typing.Optional[google.genai.types.GenerateContentResponseUsageMetadata]'
  - signature: 'automatic_function_calling_history: typing.Optional[list[google.genai.types.Content]]'
  - signature: 'parsed: typing.Optional[typing.Union[pydantic.BaseModel, dict[typing.Any, typing.Any], enum.Enum]]'
  omitted_inherited_members_from:
  - _common.BaseModel
- rank: 2204
  id: google.genai.types.GenerateContentResponse.code_execution_result
  name: code_execution_result
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: 'Returns the code execution result in the response.


    If there are multiple candidates, this returns the code execution result

    from only the

    first one.'
  signature: 'def code_execution_result(self) -> typing.Optional[str]:'
- rank: 2205
  id: google.genai.types.GenerateContentResponse.executable_code
  name: executable_code
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: 'Returns the executable code in the response.


    If there are multiple candidates, this returns the executable code from only

    the

    first one.'
  signature: 'def executable_code(self) -> typing.Optional[str]:'
- rank: 2206
  id: google.genai.types.GenerateContentResponse.function_calls
  name: function_calls
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: 'Returns the list of function calls in the response.


    If there are multiple candidates, this returns the function calls from only

    the

    first one.'
  signature: 'def function_calls(self) -> typing.Optional[list[google.genai.types.FunctionCall]]:'
- rank: 2207
  id: google.genai.types.GenerateContentResponse.parts
  name: parts
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: 'Returns the content-parts in the response.


    If there are multiple candidates, returns the parts from only the first one.'
  signature: 'def parts(self) -> typing.Optional[list[google.genai.types.Part]]:'
- rank: 2208
  id: google.genai.types.GenerateContentResponse.text
  name: text
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: 'Returns the concatenation of all text parts in the response.


    If there are multiple candidates, returns the text from only the first one.

    If there are non-text parts in the response, this returns only the text

    parts.'
  signature: 'def text(self) -> typing.Optional[str]:'
- rank: 2209
  id: google.genai.types.GenerateContentResponseDict
  name: GenerateContentResponseDict
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Response message for PredictionService.GenerateContent.


    [Note: Inherited members from TypedDict are omitted.]'
  properties:
  - signature: 'sdk_http_response: typing.Optional[google.genai.types.HttpResponseDict]'
    docstring: Used to retain the full HTTP response.
  - signature: 'candidates: typing.Optional[list[google.genai.types.CandidateDict]]'
    docstring: "Response variations returned by the model.\n      "
  - signature: 'create_time: typing.Optional[datetime.datetime]'
    docstring: "Timestamp when the request is made to the server.\n      "
  - signature: 'model_version: typing.Optional[str]'
    docstring: Output only. The model version used to generate the response.
  - signature: 'prompt_feedback: typing.Optional[google.genai.types.GenerateContentResponsePromptFeedbackDict]'
    docstring: 'Output only. Content filter results for a prompt sent in the request. Note: Sent only in the first stream chunk. Only happens when no candidates were generated due to content violations.'
  - signature: 'response_id: typing.Optional[str]'
    docstring: Output only. response_id is used to identify each response. It is the encoding of the event_id.
  - signature: 'usage_metadata: typing.Optional[google.genai.types.GenerateContentResponseUsageMetadataDict]'
    docstring: Usage metadata about the response(s).
  omitted_inherited_members_from:
  - TypedDict
- rank: 2210
  id: google.genai.types.GenerateContentResponsePromptFeedback
  name: GenerateContentResponsePromptFeedback
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Content filter results for a prompt sent in the request.


    Note: This is sent only in the first stream chunk and only if no candidates

    were generated due to content violations.


    [Note: Inherited members from _common.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, block_reason: typing.Optional[google.genai.types.BlockedReason] = None, block_reason_message: typing.Optional[str] = None, safety_ratings: typing.Optional[list[google.genai.types.SafetyRating]] = None):'
  properties:
  - signature: 'block_reason: typing.Optional[google.genai.types.BlockedReason]'
  - signature: 'block_reason_message: typing.Optional[str]'
  - signature: 'safety_ratings: typing.Optional[list[google.genai.types.SafetyRating]]'
  omitted_inherited_members_from:
  - _common.BaseModel
- rank: 2211
  id: google.genai.types.GenerateContentResponsePromptFeedbackDict
  name: GenerateContentResponsePromptFeedbackDict
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Content filter results for a prompt sent in the request.


    Note: This is sent only in the first stream chunk and only if no candidates

    were generated due to content violations.


    [Note: Inherited members from TypedDict are omitted.]'
  properties:
  - signature: 'block_reason: typing.Optional[google.genai.types.BlockedReason]'
    docstring: Output only. The reason why the prompt was blocked.
  - signature: 'block_reason_message: typing.Optional[str]'
    docstring: Output only. A readable message that explains the reason why the prompt was blocked. This field is not supported in Gemini API.
  - signature: 'safety_ratings: typing.Optional[list[google.genai.types.SafetyRatingDict]]'
    docstring: Output only. A list of safety ratings for the prompt. There is one rating per category.
  omitted_inherited_members_from:
  - TypedDict
- rank: 2212
  id: google.genai.types.GenerateContentResponseUsageMetadata
  name: GenerateContentResponseUsageMetadata
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Usage metadata about the content generation request and response.


    This message provides a detailed breakdown of token usage and other relevant

    metrics. This data type is not supported in Gemini API.


    [Note: Inherited members from _common.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, cache_tokens_details: typing.Optional[list[google.genai.types.ModalityTokenCount]] = None, cached_content_token_count: typing.Optional[int] = None, candidates_token_count: typing.Optional[int] = None, candidates_tokens_details: typing.Optional[list[google.genai.types.ModalityTokenCount]] = None, prompt_token_count: typing.Optional[int] = None, prompt_tokens_details: typing.Optional[list[google.genai.types.ModalityTokenCount]] = None, thoughts_token_count: typing.Optional[int] = None, tool_use_prompt_token_count: typing.Optional[int] = None, tool_use_prompt_tokens_details: typing.Optional[list[google.genai.types.ModalityTokenCount]] = None, total_token_count: typing.Optional[int] = None, traffic_type: typing.Optional[google.genai.types.TrafficType] = None):'
  properties:
  - signature: 'cache_tokens_details: typing.Optional[list[google.genai.types.ModalityTokenCount]]'
  - signature: 'cached_content_token_count: typing.Optional[int]'
  - signature: 'candidates_token_count: typing.Optional[int]'
  - signature: 'candidates_tokens_details: typing.Optional[list[google.genai.types.ModalityTokenCount]]'
  - signature: 'prompt_token_count: typing.Optional[int]'
  - signature: 'prompt_tokens_details: typing.Optional[list[google.genai.types.ModalityTokenCount]]'
  - signature: 'thoughts_token_count: typing.Optional[int]'
  - signature: 'tool_use_prompt_token_count: typing.Optional[int]'
  - signature: 'tool_use_prompt_tokens_details: typing.Optional[list[google.genai.types.ModalityTokenCount]]'
  - signature: 'total_token_count: typing.Optional[int]'
  - signature: 'traffic_type: typing.Optional[google.genai.types.TrafficType]'
  omitted_inherited_members_from:
  - _common.BaseModel
- rank: 2213
  id: google.genai.types.GenerateContentResponseUsageMetadataDict
  name: GenerateContentResponseUsageMetadataDict
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Usage metadata about the content generation request and response.


    This message provides a detailed breakdown of token usage and other relevant

    metrics. This data type is not supported in Gemini API.


    [Note: Inherited members from TypedDict are omitted.]'
  properties:
  - signature: 'cache_tokens_details: typing.Optional[list[google.genai.types.ModalityTokenCountDict]]'
    docstring: Output only. A detailed breakdown of the token count for each modality in the cached content.
  - signature: 'cached_content_token_count: typing.Optional[int]'
    docstring: Output only. The number of tokens in the cached content that was used for this request.
  - signature: 'candidates_token_count: typing.Optional[int]'
    docstring: The total number of tokens in the generated candidates.
  - signature: 'candidates_tokens_details: typing.Optional[list[google.genai.types.ModalityTokenCountDict]]'
    docstring: Output only. A detailed breakdown of the token count for each modality in the generated candidates.
  - signature: 'prompt_token_count: typing.Optional[int]'
    docstring: The total number of tokens in the prompt. This includes any text, images, or other media provided in the request. When `cached_content` is set, this also includes the number of tokens in the cached content.
  - signature: 'prompt_tokens_details: typing.Optional[list[google.genai.types.ModalityTokenCountDict]]'
    docstring: Output only. A detailed breakdown of the token count for each modality in the prompt.
  - signature: 'thoughts_token_count: typing.Optional[int]'
    docstring: Output only. The number of tokens that were part of the model's generated "thoughts" output, if applicable.
  - signature: 'tool_use_prompt_token_count: typing.Optional[int]'
    docstring: Output only. The number of tokens in the results from tool executions, which are provided back to the model as input, if applicable.
  - signature: 'tool_use_prompt_tokens_details: typing.Optional[list[google.genai.types.ModalityTokenCountDict]]'
    docstring: Output only. A detailed breakdown by modality of the token counts from the results of tool executions, which are provided back to the model as input.
  - signature: 'total_token_count: typing.Optional[int]'
    docstring: The total number of tokens for the entire request. This is the sum of `prompt_token_count`, `candidates_token_count`, `tool_use_prompt_token_count`, and `thoughts_token_count`.
  - signature: 'traffic_type: typing.Optional[google.genai.types.TrafficType]'
    docstring: Output only. The traffic type for this request.
  omitted_inherited_members_from:
  - TypedDict
- rank: 2214
  id: google.genai.types.GenerateImagesConfig
  name: GenerateImagesConfig
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'The config for generating an images.


    [Note: Inherited members from _common.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, http_options: typing.Optional[google.genai.types.HttpOptions] = None, output_gcs_uri: typing.Optional[str] = None, negative_prompt: typing.Optional[str] = None, number_of_images: typing.Optional[int] = None, aspect_ratio: typing.Optional[str] = None, guidance_scale: typing.Optional[float] = None, seed: typing.Optional[int] = None, safety_filter_level: typing.Optional[google.genai.types.SafetyFilterLevel] = None, person_generation: typing.Optional[google.genai.types.PersonGeneration] = None, include_safety_attributes: typing.Optional[bool] = None, include_rai_reason: typing.Optional[bool] = None, language: typing.Optional[google.genai.types.ImagePromptLanguage] = None, output_mime_type: typing.Optional[str] = None, output_compression_quality: typing.Optional[int] = None, add_watermark: typing.Optional[bool] = None, labels: typing.Optional[dict[str, str]] = None, image_size: typing.Optional[str] = None, enhance_prompt: typing.Optional[bool] =
    None):'
  properties:
  - signature: 'http_options: typing.Optional[google.genai.types.HttpOptions]'
  - signature: 'output_gcs_uri: typing.Optional[str]'
  - signature: 'negative_prompt: typing.Optional[str]'
  - signature: 'number_of_images: typing.Optional[int]'
  - signature: 'aspect_ratio: typing.Optional[str]'
  - signature: 'guidance_scale: typing.Optional[float]'
  - signature: 'seed: typing.Optional[int]'
  - signature: 'safety_filter_level: typing.Optional[google.genai.types.SafetyFilterLevel]'
  - signature: 'person_generation: typing.Optional[google.genai.types.PersonGeneration]'
  - signature: 'include_safety_attributes: typing.Optional[bool]'
  - signature: 'include_rai_reason: typing.Optional[bool]'
  - signature: 'language: typing.Optional[google.genai.types.ImagePromptLanguage]'
  - signature: 'output_mime_type: typing.Optional[str]'
  - signature: 'output_compression_quality: typing.Optional[int]'
  - signature: 'add_watermark: typing.Optional[bool]'
  - signature: 'labels: typing.Optional[dict[str, str]]'
  - signature: 'image_size: typing.Optional[str]'
  - signature: 'enhance_prompt: typing.Optional[bool]'
  omitted_inherited_members_from:
  - _common.BaseModel
- rank: 2215
  id: google.genai.types.GenerateImagesConfigDict
  name: GenerateImagesConfigDict
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'The config for generating an images.


    [Note: Inherited members from TypedDict are omitted.]'
  properties:
  - signature: 'http_options: typing.Optional[google.genai.types.HttpOptionsDict]'
    docstring: Used to override HTTP request options.
  - signature: 'output_gcs_uri: typing.Optional[str]'
    docstring: Cloud Storage URI used to store the generated images.
  - signature: 'negative_prompt: typing.Optional[str]'
    docstring: Description of what to discourage in the generated images.
  - signature: 'number_of_images: typing.Optional[int]'
    docstring: Number of images to generate.
  - signature: 'aspect_ratio: typing.Optional[str]'
    docstring: 'Aspect ratio of the generated images. Supported values are

      "1:1", "3:4", "4:3", "9:16", and "16:9".'
  - signature: 'guidance_scale: typing.Optional[float]'
    docstring: 'Controls how much the model adheres to the text prompt. Large

      values increase output and prompt alignment, but may compromise image

      quality.'
  - signature: 'seed: typing.Optional[int]'
    docstring: 'Random seed for image generation. This is not available when

      ``add_watermark`` is set to true.'
  - signature: 'safety_filter_level: typing.Optional[google.genai.types.SafetyFilterLevel]'
    docstring: Filter level for safety filtering.
  - signature: 'person_generation: typing.Optional[google.genai.types.PersonGeneration]'
    docstring: Allows generation of people by the model.
  - signature: 'include_safety_attributes: typing.Optional[bool]'
    docstring: 'Whether to report the safety scores of each generated image and

      the positive prompt in the response.'
  - signature: 'include_rai_reason: typing.Optional[bool]'
    docstring: 'Whether to include the Responsible AI filter reason if the image

      is filtered out of the response.'
  - signature: 'language: typing.Optional[google.genai.types.ImagePromptLanguage]'
    docstring: Language of the text in the prompt.
  - signature: 'output_mime_type: typing.Optional[str]'
    docstring: MIME type of the generated image.
  - signature: 'output_compression_quality: typing.Optional[int]'
    docstring: 'Compression quality of the generated image (for ``image/jpeg``

      only).'
  - signature: 'add_watermark: typing.Optional[bool]'
    docstring: Whether to add a watermark to the generated images.
  - signature: 'labels: typing.Optional[dict[str, str]]'
    docstring: User specified labels to track billing usage.
  - signature: 'image_size: typing.Optional[str]'
    docstring: 'The size of the largest dimension of the generated image.

      Supported sizes are 1K and 2K (not supported for Imagen 3 models).'
  - signature: 'enhance_prompt: typing.Optional[bool]'
    docstring: Whether to use the prompt rewriting logic.
  omitted_inherited_members_from:
  - TypedDict
- rank: 2216
  id: google.genai.types.GenerateImagesResponse
  name: GenerateImagesResponse
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'The output images response.


    [Note: Inherited members from _common.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, sdk_http_response: typing.Optional[google.genai.types.HttpResponse] = None, generated_images: typing.Optional[list[google.genai.types.GeneratedImage]] = None, positive_prompt_safety_attributes: typing.Optional[google.genai.types.SafetyAttributes] = None):'
  methods:
  - signature: 'def images(self) -> list[typing.Optional[google.genai.types.Image]]:'
    docstring: 'Returns the list of all generated images.


      A convenience method for accessing the images. Some attributes of the

      generated image are only available through the ``GeneratedImage`` object.'
  properties:
  - signature: 'sdk_http_response: typing.Optional[google.genai.types.HttpResponse]'
  - signature: 'generated_images: typing.Optional[list[google.genai.types.GeneratedImage]]'
  - signature: 'positive_prompt_safety_attributes: typing.Optional[google.genai.types.SafetyAttributes]'
  omitted_inherited_members_from:
  - _common.BaseModel
- rank: 2217
  id: google.genai.types.GenerateImagesResponse.images
  name: images
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: 'Returns the list of all generated images.


    A convenience method for accessing the images. Some attributes of the

    generated image are only available through the ``GeneratedImage`` object.'
  signature: 'def images(self) -> list[typing.Optional[google.genai.types.Image]]:'
- rank: 2218
  id: google.genai.types.GenerateImagesResponseDict
  name: GenerateImagesResponseDict
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'The output images response.


    [Note: Inherited members from TypedDict are omitted.]'
  properties:
  - signature: 'sdk_http_response: typing.Optional[google.genai.types.HttpResponseDict]'
    docstring: Used to retain the full HTTP response.
  - signature: 'generated_images: typing.Optional[list[google.genai.types.GeneratedImageDict]]'
    docstring: List of generated images.
  - signature: 'positive_prompt_safety_attributes: typing.Optional[google.genai.types.SafetyAttributesDict]'
    docstring: 'Safety attributes of the positive prompt. Only populated if

      ``include_safety_attributes`` is set to True.'
  omitted_inherited_members_from:
  - TypedDict
- rank: 2219
  id: google.genai.types.GenerateVideosConfig
  name: GenerateVideosConfig
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Configuration for generating videos.


    [Note: Inherited members from _common.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, http_options: typing.Optional[google.genai.types.HttpOptions] = None, number_of_videos: typing.Optional[int] = None, output_gcs_uri: typing.Optional[str] = None, fps: typing.Optional[int] = None, duration_seconds: typing.Optional[int] = None, seed: typing.Optional[int] = None, aspect_ratio: typing.Optional[str] = None, resolution: typing.Optional[str] = None, person_generation: typing.Optional[str] = None, pubsub_topic: typing.Optional[str] = None, negative_prompt: typing.Optional[str] = None, enhance_prompt: typing.Optional[bool] = None, generate_audio: typing.Optional[bool] = None, last_frame: typing.Optional[google.genai.types.Image] = None, reference_images: typing.Optional[list[google.genai.types.VideoGenerationReferenceImage]] = None, mask: typing.Optional[google.genai.types.VideoGenerationMask] = None, compression_quality: typing.Optional[google.genai.types.VideoCompressionQuality] = None):'
  properties:
  - signature: 'http_options: typing.Optional[google.genai.types.HttpOptions]'
  - signature: 'number_of_videos: typing.Optional[int]'
  - signature: 'output_gcs_uri: typing.Optional[str]'
  - signature: 'fps: typing.Optional[int]'
  - signature: 'duration_seconds: typing.Optional[int]'
  - signature: 'seed: typing.Optional[int]'
  - signature: 'aspect_ratio: typing.Optional[str]'
  - signature: 'resolution: typing.Optional[str]'
  - signature: 'person_generation: typing.Optional[str]'
  - signature: 'pubsub_topic: typing.Optional[str]'
  - signature: 'negative_prompt: typing.Optional[str]'
  - signature: 'enhance_prompt: typing.Optional[bool]'
  - signature: 'generate_audio: typing.Optional[bool]'
  - signature: 'last_frame: typing.Optional[google.genai.types.Image]'
  - signature: 'reference_images: typing.Optional[list[google.genai.types.VideoGenerationReferenceImage]]'
  - signature: 'mask: typing.Optional[google.genai.types.VideoGenerationMask]'
  - signature: 'compression_quality: typing.Optional[google.genai.types.VideoCompressionQuality]'
  omitted_inherited_members_from:
  - _common.BaseModel
- rank: 2220
  id: google.genai.types.GenerateVideosConfigDict
  name: GenerateVideosConfigDict
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Configuration for generating videos.


    [Note: Inherited members from TypedDict are omitted.]'
  properties:
  - signature: 'http_options: typing.Optional[google.genai.types.HttpOptionsDict]'
    docstring: Used to override HTTP request options.
  - signature: 'number_of_videos: typing.Optional[int]'
    docstring: Number of output videos.
  - signature: 'output_gcs_uri: typing.Optional[str]'
    docstring: The gcs bucket where to save the generated videos.
  - signature: 'fps: typing.Optional[int]'
    docstring: Frames per second for video generation.
  - signature: 'duration_seconds: typing.Optional[int]'
    docstring: Duration of the clip for video generation in seconds.
  - signature: 'seed: typing.Optional[int]'
    docstring: 'The RNG seed. If RNG seed is exactly same for each request with

      unchanged inputs, the prediction results will be consistent. Otherwise,

      a random RNG seed will be used each time to produce a different

      result.'
  - signature: 'aspect_ratio: typing.Optional[str]'
    docstring: 'The aspect ratio for the generated video. 16:9 (landscape) and

      9:16 (portrait) are supported.'
  - signature: 'resolution: typing.Optional[str]'
    docstring: 'The resolution for the generated video. 720p and 1080p are

      supported.'
  - signature: 'person_generation: typing.Optional[str]'
    docstring: 'Whether allow to generate person videos, and restrict to specific

      ages. Supported values are: dont_allow, allow_adult.'
  - signature: 'pubsub_topic: typing.Optional[str]'
    docstring: 'The pubsub topic where to publish the video generation

      progress.'
  - signature: 'negative_prompt: typing.Optional[str]'
    docstring: 'Explicitly state what should not be included in the generated

      videos.'
  - signature: 'enhance_prompt: typing.Optional[bool]'
    docstring: Whether to use the prompt rewriting logic.
  - signature: 'generate_audio: typing.Optional[bool]'
    docstring: Whether to generate audio along with the video.
  - signature: 'last_frame: typing.Optional[google.genai.types.ImageDict]'
    docstring: 'Image to use as the last frame of generated videos.

      Only supported for image to video use cases.'
  - signature: 'reference_images: typing.Optional[list[google.genai.types.VideoGenerationReferenceImageDict]]'
    docstring: 'The images to use as the references to generate the videos.

      If this field is provided, the text prompt field must also be provided.

      The image, video, or last_frame field are not supported. Each image must

      be associated with a type. Veo 2 supports up to 3 asset images *or* 1

      style image.'
  - signature: 'mask: typing.Optional[google.genai.types.VideoGenerationMaskDict]'
    docstring: The mask to use for generating videos.
  - signature: 'compression_quality: typing.Optional[google.genai.types.VideoCompressionQuality]'
    docstring: Compression quality of the generated videos.
  omitted_inherited_members_from:
  - TypedDict
- rank: 2221
  id: google.genai.types.GenerateVideosOperation
  name: GenerateVideosOperation
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'A video generation operation.


    [Note: Inherited members from ABC, _common.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, name: typing.Optional[str] = None, metadata: typing.Optional[dict[str, typing.Any]] = None, done: typing.Optional[bool] = None, error: typing.Optional[dict[str, typing.Any]] = None, response: typing.Optional[google.genai.types.GenerateVideosResponse] = None, result: typing.Optional[google.genai.types.GenerateVideosResponse] = None):'
  methods:
  - signature: 'def from_api_response(cls, api_response: typing.Any, is_vertex_ai: bool) -> typing_extensions.Self:'
    docstring: Instantiates a GenerateVideosOperation from an API response.
  properties:
  - signature: 'response: typing.Optional[google.genai.types.GenerateVideosResponse]'
  - signature: 'result: typing.Optional[google.genai.types.GenerateVideosResponse]'
  inherited_methods:
    Operation:
    - signature: 'def from_api_response(cls, api_response: typing.Any, is_vertex_ai: bool) -> typing_extensions.Self:'
      docstring: Creates an Operation from an API response.
  inherited_properties:
    Operation:
    - signature: 'name: typing.Optional[str]'
    - signature: 'metadata: typing.Optional[dict[str, typing.Any]]'
    - signature: 'done: typing.Optional[bool]'
    - signature: 'error: typing.Optional[dict[str, typing.Any]]'
  omitted_inherited_members_from:
  - ABC
  - _common.BaseModel
- rank: 2222
  id: google.genai.types.GenerateVideosOperation.from_api_response
  name: from_api_response
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: Instantiates a GenerateVideosOperation from an API response.
  signature: 'def from_api_response(cls, api_response: typing.Any, is_vertex_ai: bool) -> typing_extensions.Self:'
- rank: 2223
  id: google.genai.types.GenerateVideosResponse
  name: GenerateVideosResponse
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Response with generated videos.


    [Note: Inherited members from _common.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, generated_videos: typing.Optional[list[google.genai.types.GeneratedVideo]] = None, rai_media_filtered_count: typing.Optional[int] = None, rai_media_filtered_reasons: typing.Optional[list[str]] = None):'
  properties:
  - signature: 'generated_videos: typing.Optional[list[google.genai.types.GeneratedVideo]]'
  - signature: 'rai_media_filtered_count: typing.Optional[int]'
  - signature: 'rai_media_filtered_reasons: typing.Optional[list[str]]'
  omitted_inherited_members_from:
  - _common.BaseModel
- rank: 2224
  id: google.genai.types.GenerateVideosResponseDict
  name: GenerateVideosResponseDict
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Response with generated videos.


    [Note: Inherited members from TypedDict are omitted.]'
  properties:
  - signature: 'generated_videos: typing.Optional[list[google.genai.types.GeneratedVideoDict]]'
    docstring: List of the generated videos
  - signature: 'rai_media_filtered_count: typing.Optional[int]'
    docstring: Returns if any videos were filtered due to RAI policies.
  - signature: 'rai_media_filtered_reasons: typing.Optional[list[str]]'
    docstring: Returns rai failure reasons if any.
  omitted_inherited_members_from:
  - TypedDict
- rank: 2225
  id: google.genai.types.GenerateVideosSource
  name: GenerateVideosSource
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'A set of source input(s) for video generation.


    [Note: Inherited members from _common.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, prompt: typing.Optional[str] = None, image: typing.Optional[google.genai.types.Image] = None, video: typing.Optional[google.genai.types.Video] = None):'
  properties:
  - signature: 'prompt: typing.Optional[str]'
  - signature: 'image: typing.Optional[google.genai.types.Image]'
  - signature: 'video: typing.Optional[google.genai.types.Video]'
  omitted_inherited_members_from:
  - _common.BaseModel
- rank: 2226
  id: google.genai.types.GenerateVideosSourceDict
  name: GenerateVideosSourceDict
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'A set of source input(s) for video generation.


    [Note: Inherited members from TypedDict are omitted.]'
  properties:
  - signature: 'prompt: typing.Optional[str]'
    docstring: 'The text prompt for generating the videos.

      Optional if image or video is provided.'
  - signature: 'image: typing.Optional[google.genai.types.ImageDict]'
    docstring: 'The input image for generating the videos.

      Optional if prompt is provided. Not allowed if video is provided.'
  - signature: 'video: typing.Optional[google.genai.types.VideoDict]'
    docstring: 'The input video for video extension use cases.

      Optional if prompt is provided. Not allowed if image is provided.'
  omitted_inherited_members_from:
  - TypedDict
- rank: 2227
  id: google.genai.types.GeneratedImage
  name: GeneratedImage
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'An output image.


    [Note: Inherited members from _common.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, image: typing.Optional[google.genai.types.Image] = None, rai_filtered_reason: typing.Optional[str] = None, safety_attributes: typing.Optional[google.genai.types.SafetyAttributes] = None, enhanced_prompt: typing.Optional[str] = None):'
  properties:
  - signature: 'image: typing.Optional[google.genai.types.Image]'
  - signature: 'rai_filtered_reason: typing.Optional[str]'
  - signature: 'safety_attributes: typing.Optional[google.genai.types.SafetyAttributes]'
  - signature: 'enhanced_prompt: typing.Optional[str]'
  omitted_inherited_members_from:
  - _common.BaseModel
- rank: 2228
  id: google.genai.types.GeneratedImageDict
  name: GeneratedImageDict
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'An output image.


    [Note: Inherited members from TypedDict are omitted.]'
  properties:
  - signature: 'image: typing.Optional[google.genai.types.ImageDict]'
    docstring: The output image data.
  - signature: 'rai_filtered_reason: typing.Optional[str]'
    docstring: 'Responsible AI filter reason if the image is filtered out of the

      response.'
  - signature: 'safety_attributes: typing.Optional[google.genai.types.SafetyAttributesDict]'
    docstring: 'Safety attributes of the image. Lists of RAI categories and their

      scores of each content.'
  - signature: 'enhanced_prompt: typing.Optional[str]'
    docstring: 'The rewritten prompt used for the image generation if the prompt

      enhancer is enabled.'
  omitted_inherited_members_from:
  - TypedDict
- rank: 2229
  id: google.genai.types.GeneratedImageMask
  name: GeneratedImageMask
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'A generated image mask.


    [Note: Inherited members from _common.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, mask: typing.Optional[google.genai.types.Image] = None, labels: typing.Optional[list[google.genai.types.EntityLabel]] = None):'
  properties:
  - signature: 'mask: typing.Optional[google.genai.types.Image]'
  - signature: 'labels: typing.Optional[list[google.genai.types.EntityLabel]]'
  omitted_inherited_members_from:
  - _common.BaseModel
- rank: 2230
  id: google.genai.types.GeneratedImageMaskDict
  name: GeneratedImageMaskDict
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'A generated image mask.


    [Note: Inherited members from TypedDict are omitted.]'
  properties:
  - signature: 'mask: typing.Optional[google.genai.types.ImageDict]'
    docstring: The generated image mask.
  - signature: 'labels: typing.Optional[list[google.genai.types.EntityLabelDict]]'
    docstring: The detected entities on the segmented area.
  omitted_inherited_members_from:
  - TypedDict
- rank: 2231
  id: google.genai.types.GeneratedVideo
  name: GeneratedVideo
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'A generated video.


    [Note: Inherited members from _common.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, video: typing.Optional[google.genai.types.Video] = None):'
  properties:
  - signature: 'video: typing.Optional[google.genai.types.Video]'
  omitted_inherited_members_from:
  - _common.BaseModel
- rank: 2232
  id: google.genai.types.GeneratedVideoDict
  name: GeneratedVideoDict
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'A generated video.


    [Note: Inherited members from TypedDict are omitted.]'
  properties:
  - signature: 'video: typing.Optional[google.genai.types.VideoDict]'
    docstring: The output video
  omitted_inherited_members_from:
  - TypedDict
- rank: 2233
  id: google.genai.types.GenerationConfig
  name: GenerationConfig
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Generation config.


    [Note: Inherited members from _common.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, model_selection_config: typing.Optional[google.genai.types.ModelSelectionConfig] = None, response_json_schema: typing.Optional[typing.Any] = None, audio_timestamp: typing.Optional[bool] = None, candidate_count: typing.Optional[int] = None, enable_affective_dialog: typing.Optional[bool] = None, frequency_penalty: typing.Optional[float] = None, logprobs: typing.Optional[int] = None, max_output_tokens: typing.Optional[int] = None, media_resolution: typing.Optional[google.genai.types.MediaResolution] = None, presence_penalty: typing.Optional[float] = None, response_logprobs: typing.Optional[bool] = None, response_mime_type: typing.Optional[str] = None, response_modalities: typing.Optional[list[google.genai.types.Modality]] = None, response_schema: typing.Optional[google.genai.types.Schema] = None, routing_config: typing.Optional[google.genai.types.GenerationConfigRoutingConfig] = None, seed: typing.Optional[int] = None, speech_config: typing.Optional[google.genai.types.SpeechConfig]
    = None, stop_sequences: typing.Optional[list[str]] = None, temperature: typing.Optional[float] = None, thinking_config: typing.Optional[google.genai.types.ThinkingConfig] = None, top_k: typing.Optional[float] = None, top_p: typing.Optional[float] = None, enable_enhanced_civic_answers: typing.Optional[bool] = None):'
  properties:
  - signature: 'model_selection_config: typing.Optional[google.genai.types.ModelSelectionConfig]'
  - signature: 'response_json_schema: typing.Optional[typing.Any]'
  - signature: 'audio_timestamp: typing.Optional[bool]'
  - signature: 'candidate_count: typing.Optional[int]'
  - signature: 'enable_affective_dialog: typing.Optional[bool]'
  - signature: 'frequency_penalty: typing.Optional[float]'
  - signature: 'logprobs: typing.Optional[int]'
  - signature: 'max_output_tokens: typing.Optional[int]'
  - signature: 'media_resolution: typing.Optional[google.genai.types.MediaResolution]'
  - signature: 'presence_penalty: typing.Optional[float]'
  - signature: 'response_logprobs: typing.Optional[bool]'
  - signature: 'response_mime_type: typing.Optional[str]'
  - signature: 'response_modalities: typing.Optional[list[google.genai.types.Modality]]'
  - signature: 'response_schema: typing.Optional[google.genai.types.Schema]'
  - signature: 'routing_config: typing.Optional[google.genai.types.GenerationConfigRoutingConfig]'
  - signature: 'seed: typing.Optional[int]'
  - signature: 'speech_config: typing.Optional[google.genai.types.SpeechConfig]'
  - signature: 'stop_sequences: typing.Optional[list[str]]'
  - signature: 'temperature: typing.Optional[float]'
  - signature: 'thinking_config: typing.Optional[google.genai.types.ThinkingConfig]'
  - signature: 'top_k: typing.Optional[float]'
  - signature: 'top_p: typing.Optional[float]'
  - signature: 'enable_enhanced_civic_answers: typing.Optional[bool]'
  omitted_inherited_members_from:
  - _common.BaseModel
- rank: 2234
  id: google.genai.types.GenerationConfigDict
  name: GenerationConfigDict
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Generation config.


    [Note: Inherited members from TypedDict are omitted.]'
  properties:
  - signature: 'model_selection_config: typing.Optional[google.genai.types.ModelSelectionConfigDict]'
    docstring: Optional. Config for model selection.
  - signature: 'response_json_schema: typing.Optional[typing.Any]'
    docstring: 'Output schema of the generated response. This is an alternative to

      `response_schema` that accepts [JSON Schema](https://json-schema.org/).'
  - signature: 'audio_timestamp: typing.Optional[bool]'
    docstring: Optional. If enabled, audio timestamp will be included in the request to the model. This field is not supported in Gemini API.
  - signature: 'candidate_count: typing.Optional[int]'
    docstring: Optional. Number of candidates to generate.
  - signature: 'enable_affective_dialog: typing.Optional[bool]'
    docstring: Optional. If enabled, the model will detect emotions and adapt its responses accordingly. This field is not supported in Gemini API.
  - signature: 'frequency_penalty: typing.Optional[float]'
    docstring: Optional. Frequency penalties.
  - signature: 'logprobs: typing.Optional[int]'
    docstring: Optional. Logit probabilities.
  - signature: 'max_output_tokens: typing.Optional[int]'
    docstring: Optional. The maximum number of output tokens to generate per message.
  - signature: 'media_resolution: typing.Optional[google.genai.types.MediaResolution]'
    docstring: Optional. If specified, the media resolution specified will be used.
  - signature: 'presence_penalty: typing.Optional[float]'
    docstring: Optional. Positive penalties.
  - signature: 'response_logprobs: typing.Optional[bool]'
    docstring: Optional. If true, export the logprobs results in response.
  - signature: 'response_mime_type: typing.Optional[str]'
    docstring: 'Optional. Output response mimetype of the generated candidate text. Supported mimetype: - `text/plain`: (default) Text output. - `application/json`: JSON response in the candidates. The model needs to be prompted to output the appropriate response type, otherwise the behavior is undefined. This is a preview feature.'
  - signature: 'response_modalities: typing.Optional[list[google.genai.types.Modality]]'
    docstring: Optional. The modalities of the response.
  - signature: 'response_schema: typing.Optional[google.genai.types.SchemaDict]'
    docstring: 'Optional. The `Schema` object allows the definition of input and output data types. These types can be objects, but also primitives and arrays. Represents a select subset of an [OpenAPI 3.0 schema object](https://spec.openapis.org/oas/v3.0.3#schema). If set, a compatible response_mime_type must also be set. Compatible mimetypes: `application/json`: Schema for JSON response.'
  - signature: 'routing_config: typing.Optional[google.genai.types.GenerationConfigRoutingConfigDict]'
    docstring: Optional. Routing configuration. This field is not supported in Gemini API.
  - signature: 'seed: typing.Optional[int]'
    docstring: Optional. Seed.
  - signature: 'speech_config: typing.Optional[google.genai.types.SpeechConfigDict]'
    docstring: Optional. The speech generation config.
  - signature: 'stop_sequences: typing.Optional[list[str]]'
    docstring: Optional. Stop sequences.
  - signature: 'temperature: typing.Optional[float]'
    docstring: Optional. Controls the randomness of predictions.
  - signature: 'thinking_config: typing.Optional[google.genai.types.ThinkingConfigDict]'
    docstring: Optional. Config for thinking features. An error will be returned if this field is set for models that don't support thinking.
  - signature: 'top_k: typing.Optional[float]'
    docstring: Optional. If specified, top-k sampling will be used.
  - signature: 'top_p: typing.Optional[float]'
    docstring: Optional. If specified, nucleus sampling will be used.
  - signature: 'enable_enhanced_civic_answers: typing.Optional[bool]'
    docstring: Optional. Enables enhanced civic answers. It may not be available for all models. This field is not supported in Vertex AI.
  omitted_inherited_members_from:
  - TypedDict
- rank: 2235
  id: google.genai.types.GenerationConfigRoutingConfig
  name: GenerationConfigRoutingConfig
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'The configuration for routing the request to a specific model.


    This data type is not supported in Gemini API.


    [Note: Inherited members from _common.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, auto_mode: typing.Optional[google.genai.types.GenerationConfigRoutingConfigAutoRoutingMode] = None, manual_mode: typing.Optional[google.genai.types.GenerationConfigRoutingConfigManualRoutingMode] = None):'
  properties:
  - signature: 'auto_mode: typing.Optional[google.genai.types.GenerationConfigRoutingConfigAutoRoutingMode]'
  - signature: 'manual_mode: typing.Optional[google.genai.types.GenerationConfigRoutingConfigManualRoutingMode]'
  omitted_inherited_members_from:
  - _common.BaseModel
- rank: 2236
  id: google.genai.types.GenerationConfigRoutingConfigAutoRoutingMode
  name: GenerationConfigRoutingConfigAutoRoutingMode
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'When automated routing is specified, the routing will be determined by the pretrained routing model and customer provided model routing preference.


    This data type is not supported in Gemini API.


    [Note: Inherited members from _common.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, model_routing_preference: typing.Optional[typing.Literal[UNKNOWN, PRIORITIZE_QUALITY, BALANCED, PRIORITIZE_COST]] = None):'
  properties:
  - signature: 'model_routing_preference: typing.Optional[typing.Literal[UNKNOWN, PRIORITIZE_QUALITY, BALANCED, PRIORITIZE_COST]]'
  omitted_inherited_members_from:
  - _common.BaseModel
- rank: 2237
  id: google.genai.types.GenerationConfigRoutingConfigAutoRoutingModeDict
  name: GenerationConfigRoutingConfigAutoRoutingModeDict
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'When automated routing is specified, the routing will be determined by the pretrained routing model and customer provided model routing preference.


    This data type is not supported in Gemini API.


    [Note: Inherited members from TypedDict are omitted.]'
  properties:
  - signature: 'model_routing_preference: typing.Optional[typing.Literal[UNKNOWN, PRIORITIZE_QUALITY, BALANCED, PRIORITIZE_COST]]'
    docstring: The model routing preference.
  omitted_inherited_members_from:
  - TypedDict
- rank: 2238
  id: google.genai.types.GenerationConfigRoutingConfigDict
  name: GenerationConfigRoutingConfigDict
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'The configuration for routing the request to a specific model.


    This data type is not supported in Gemini API.


    [Note: Inherited members from TypedDict are omitted.]'
  properties:
  - signature: 'auto_mode: typing.Optional[google.genai.types.GenerationConfigRoutingConfigAutoRoutingModeDict]'
    docstring: Automated routing.
  - signature: 'manual_mode: typing.Optional[google.genai.types.GenerationConfigRoutingConfigManualRoutingModeDict]'
    docstring: Manual routing.
  omitted_inherited_members_from:
  - TypedDict
- rank: 2239
  id: google.genai.types.GenerationConfigRoutingConfigManualRoutingMode
  name: GenerationConfigRoutingConfigManualRoutingMode
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'When manual routing is set, the specified model will be used directly.


    This data type is not supported in Gemini API.


    [Note: Inherited members from _common.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, model_name: typing.Optional[str] = None):'
  properties:
  - signature: 'model_name: typing.Optional[str]'
  omitted_inherited_members_from:
  - _common.BaseModel
- rank: 2240
  id: google.genai.types.GenerationConfigRoutingConfigManualRoutingModeDict
  name: GenerationConfigRoutingConfigManualRoutingModeDict
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'When manual routing is set, the specified model will be used directly.


    This data type is not supported in Gemini API.


    [Note: Inherited members from TypedDict are omitted.]'
  properties:
  - signature: 'model_name: typing.Optional[str]'
    docstring: The model name to use. Only the public LLM models are accepted. See [Supported models](https://cloud.google.com/vertex-ai/generative-ai/docs/model-reference/inference#supported-models).
  omitted_inherited_members_from:
  - TypedDict
- rank: 2241
  id: google.genai.types.GenerationConfigThinkingConfig
  name: GenerationConfigThinkingConfig
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Config for thinking feature.


    This class will be deprecated. Please use `ThinkingConfig` instead.


    [Note: Inherited members from _common.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, include_thoughts: typing.Optional[bool] = None, thinking_budget: typing.Optional[int] = None, thinking_level: typing.Optional[google.genai.types.ThinkingLevel] = None):'
  inherited_properties:
    ThinkingConfig:
    - signature: 'include_thoughts: typing.Optional[bool]'
    - signature: 'thinking_budget: typing.Optional[int]'
    - signature: 'thinking_level: typing.Optional[google.genai.types.ThinkingLevel]'
  omitted_inherited_members_from:
  - _common.BaseModel
- rank: 2242
  id: google.genai.types.GenerationConfigThinkingConfigDict
  name: GenerationConfigThinkingConfigDict
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Config for thinking feature.


    This class will be deprecated. Please use `ThinkingConfig` instead.


    [Note: Inherited members from TypedDict are omitted.]'
  inherited_properties:
    ThinkingConfigDict:
    - signature: 'include_thoughts: typing.Optional[bool]'
      docstring: "Indicates whether to include thoughts in the response. If true, thoughts are returned only if the model supports thought and thoughts are available.\n      "
    - signature: 'thinking_budget: typing.Optional[int]'
      docstring: "Indicates the thinking budget in tokens. 0 is DISABLED. -1 is AUTOMATIC. The default values and allowed ranges are model dependent.\n      "
    - signature: 'thinking_level: typing.Optional[google.genai.types.ThinkingLevel]'
      docstring: Optional. The level of thoughts tokens that the model should generate.
  omitted_inherited_members_from:
  - TypedDict
- rank: 2243
  id: google.genai.types.GetBatchJobConfig
  name: GetBatchJobConfig
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Optional parameters.


    [Note: Inherited members from _common.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, http_options: typing.Optional[google.genai.types.HttpOptions] = None):'
  properties:
  - signature: 'http_options: typing.Optional[google.genai.types.HttpOptions]'
  omitted_inherited_members_from:
  - _common.BaseModel
- rank: 2244
  id: google.genai.types.GetBatchJobConfigDict
  name: GetBatchJobConfigDict
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Optional parameters.


    [Note: Inherited members from TypedDict are omitted.]'
  properties:
  - signature: 'http_options: typing.Optional[google.genai.types.HttpOptionsDict]'
    docstring: Used to override HTTP request options.
  omitted_inherited_members_from:
  - TypedDict
- rank: 2245
  id: google.genai.types.GetCachedContentConfig
  name: GetCachedContentConfig
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Optional parameters for caches.get method.


    [Note: Inherited members from _common.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, http_options: typing.Optional[google.genai.types.HttpOptions] = None):'
  properties:
  - signature: 'http_options: typing.Optional[google.genai.types.HttpOptions]'
  omitted_inherited_members_from:
  - _common.BaseModel
- rank: 2246
  id: google.genai.types.GetCachedContentConfigDict
  name: GetCachedContentConfigDict
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Optional parameters for caches.get method.


    [Note: Inherited members from TypedDict are omitted.]'
  properties:
  - signature: 'http_options: typing.Optional[google.genai.types.HttpOptionsDict]'
    docstring: Used to override HTTP request options.
  omitted_inherited_members_from:
  - TypedDict
- rank: 2247
  id: google.genai.types.GetDocumentConfig
  name: GetDocumentConfig
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Optional Config.


    [Note: Inherited members from _common.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, http_options: typing.Optional[google.genai.types.HttpOptions] = None):'
  properties:
  - signature: 'http_options: typing.Optional[google.genai.types.HttpOptions]'
  omitted_inherited_members_from:
  - _common.BaseModel
- rank: 2248
  id: google.genai.types.GetDocumentConfigDict
  name: GetDocumentConfigDict
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Optional Config.


    [Note: Inherited members from TypedDict are omitted.]'
  properties:
  - signature: 'http_options: typing.Optional[google.genai.types.HttpOptionsDict]'
    docstring: Used to override HTTP request options.
  omitted_inherited_members_from:
  - TypedDict
- rank: 2249
  id: google.genai.types.GetFileConfig
  name: GetFileConfig
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Used to override the default configuration.


    [Note: Inherited members from _common.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, http_options: typing.Optional[google.genai.types.HttpOptions] = None):'
  properties:
  - signature: 'http_options: typing.Optional[google.genai.types.HttpOptions]'
  omitted_inherited_members_from:
  - _common.BaseModel
- rank: 2250
  id: google.genai.types.GetFileConfigDict
  name: GetFileConfigDict
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Used to override the default configuration.


    [Note: Inherited members from TypedDict are omitted.]'
  properties:
  - signature: 'http_options: typing.Optional[google.genai.types.HttpOptionsDict]'
    docstring: Used to override HTTP request options.
  omitted_inherited_members_from:
  - TypedDict
- rank: 2251
  id: google.genai.types.GetFileSearchStoreConfig
  name: GetFileSearchStoreConfig
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Optional parameters for getting a FileSearchStore.


    [Note: Inherited members from _common.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, http_options: typing.Optional[google.genai.types.HttpOptions] = None):'
  properties:
  - signature: 'http_options: typing.Optional[google.genai.types.HttpOptions]'
  omitted_inherited_members_from:
  - _common.BaseModel
- rank: 2252
  id: google.genai.types.GetFileSearchStoreConfigDict
  name: GetFileSearchStoreConfigDict
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Optional parameters for getting a FileSearchStore.


    [Note: Inherited members from TypedDict are omitted.]'
  properties:
  - signature: 'http_options: typing.Optional[google.genai.types.HttpOptionsDict]'
    docstring: Used to override HTTP request options.
  omitted_inherited_members_from:
  - TypedDict
- rank: 2253
  id: google.genai.types.GetModelConfig
  name: GetModelConfig
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Optional parameters for models.get method.


    [Note: Inherited members from _common.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, http_options: typing.Optional[google.genai.types.HttpOptions] = None):'
  properties:
  - signature: 'http_options: typing.Optional[google.genai.types.HttpOptions]'
  omitted_inherited_members_from:
  - _common.BaseModel
- rank: 2254
  id: google.genai.types.GetModelConfigDict
  name: GetModelConfigDict
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Optional parameters for models.get method.


    [Note: Inherited members from TypedDict are omitted.]'
  properties:
  - signature: 'http_options: typing.Optional[google.genai.types.HttpOptionsDict]'
    docstring: Used to override HTTP request options.
  omitted_inherited_members_from:
  - TypedDict
- rank: 2255
  id: google.genai.types.GetOperationConfig
  name: GetOperationConfig
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: '[Note: Inherited members from _common.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, http_options: typing.Optional[google.genai.types.HttpOptions] = None):'
  properties:
  - signature: 'http_options: typing.Optional[google.genai.types.HttpOptions]'
  omitted_inherited_members_from:
  - _common.BaseModel
- rank: 2256
  id: google.genai.types.GetOperationConfigDict
  name: GetOperationConfigDict
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: '[Note: Inherited members from TypedDict are omitted.]'
  properties:
  - signature: 'http_options: typing.Optional[google.genai.types.HttpOptionsDict]'
    docstring: Used to override HTTP request options.
  omitted_inherited_members_from:
  - TypedDict
- rank: 2257
  id: google.genai.types.GetTuningJobConfig
  name: GetTuningJobConfig
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Optional parameters for tunings.get method.


    [Note: Inherited members from _common.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, http_options: typing.Optional[google.genai.types.HttpOptions] = None):'
  properties:
  - signature: 'http_options: typing.Optional[google.genai.types.HttpOptions]'
  omitted_inherited_members_from:
  - _common.BaseModel
- rank: 2258
  id: google.genai.types.GetTuningJobConfigDict
  name: GetTuningJobConfigDict
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Optional parameters for tunings.get method.


    [Note: Inherited members from TypedDict are omitted.]'
  properties:
  - signature: 'http_options: typing.Optional[google.genai.types.HttpOptionsDict]'
    docstring: Used to override HTTP request options.
  omitted_inherited_members_from:
  - TypedDict
- rank: 2259
  id: google.genai.types.GoogleMaps
  name: GoogleMaps
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Tool to retrieve public maps data for grounding, powered by Google.


    [Note: Inherited members from _common.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, auth_config: typing.Optional[google.genai.types.AuthConfig] = None, enable_widget: typing.Optional[bool] = None):'
  properties:
  - signature: 'auth_config: typing.Optional[google.genai.types.AuthConfig]'
  - signature: 'enable_widget: typing.Optional[bool]'
  omitted_inherited_members_from:
  - _common.BaseModel
- rank: 2260
  id: google.genai.types.GoogleMapsDict
  name: GoogleMapsDict
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Tool to retrieve public maps data for grounding, powered by Google.


    [Note: Inherited members from TypedDict are omitted.]'
  properties:
  - signature: 'auth_config: typing.Optional[google.genai.types.AuthConfigDict]'
    docstring: The authentication config to access the API. Only API key is supported. This field is not supported in Gemini API.
  - signature: 'enable_widget: typing.Optional[bool]'
    docstring: Optional. If true, include the widget context token in the response.
  omitted_inherited_members_from:
  - TypedDict
- rank: 2261
  id: google.genai.types.GoogleRpcStatus
  name: GoogleRpcStatus
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'The `Status` type defines a logical error model that is suitable for different programming environments, including REST APIs and RPC APIs.


    It is used by [gRPC](https://github.com/grpc). Each `Status` message contains

    three pieces of data: error code, error message, and error details. You can

    find out more about this error model and how to work with it in the [API

    Design Guide](https://cloud.google.com/apis/design/errors). This data type is

    not supported in Gemini API.


    [Note: Inherited members from _common.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, code: typing.Optional[int] = None, details: typing.Optional[list[dict[str, typing.Any]]] = None, message: typing.Optional[str] = None):'
  properties:
  - signature: 'code: typing.Optional[int]'
  - signature: 'details: typing.Optional[list[dict[str, typing.Any]]]'
  - signature: 'message: typing.Optional[str]'
  omitted_inherited_members_from:
  - _common.BaseModel
- rank: 2262
  id: google.genai.types.GoogleRpcStatusDict
  name: GoogleRpcStatusDict
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'The `Status` type defines a logical error model that is suitable for different programming environments, including REST APIs and RPC APIs.


    It is used by [gRPC](https://github.com/grpc). Each `Status` message contains

    three pieces of data: error code, error message, and error details. You can

    find out more about this error model and how to work with it in the [API

    Design Guide](https://cloud.google.com/apis/design/errors). This data type is

    not supported in Gemini API.


    [Note: Inherited members from TypedDict are omitted.]'
  properties:
  - signature: 'code: typing.Optional[int]'
    docstring: The status code, which should be an enum value of google.rpc.Code.
  - signature: 'details: typing.Optional[list[dict[str, typing.Any]]]'
    docstring: A list of messages that carry the error details. There is a common set of message types for APIs to use.
  - signature: 'message: typing.Optional[str]'
    docstring: A developer-facing error message, which should be in English. Any user-facing error message should be localized and sent in the google.rpc.Status.details field, or localized by the client.
  omitted_inherited_members_from:
  - TypedDict
- rank: 2263
  id: google.genai.types.GoogleSearch
  name: GoogleSearch
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'GoogleSearch tool type.


    Tool to support Google Search in Model. Powered by Google.


    [Note: Inherited members from _common.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, exclude_domains: typing.Optional[list[str]] = None, blocking_confidence: typing.Optional[google.genai.types.PhishBlockThreshold] = None, time_range_filter: typing.Optional[google.genai.types.Interval] = None):'
  properties:
  - signature: 'exclude_domains: typing.Optional[list[str]]'
  - signature: 'blocking_confidence: typing.Optional[google.genai.types.PhishBlockThreshold]'
  - signature: 'time_range_filter: typing.Optional[google.genai.types.Interval]'
  omitted_inherited_members_from:
  - _common.BaseModel
- rank: 2264
  id: google.genai.types.GoogleSearchDict
  name: GoogleSearchDict
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'GoogleSearch tool type.


    Tool to support Google Search in Model. Powered by Google.


    [Note: Inherited members from TypedDict are omitted.]'
  properties:
  - signature: 'exclude_domains: typing.Optional[list[str]]'
    docstring: 'Optional. List of domains to be excluded from the search results. The default limit is 2000 domains. Example: ["amazon.com", "facebook.com"]. This field is not supported in Gemini API.'
  - signature: 'blocking_confidence: typing.Optional[google.genai.types.PhishBlockThreshold]'
    docstring: Optional. Sites with confidence level chosen & above this value will be blocked from the search results. This field is not supported in Gemini API.
  - signature: 'time_range_filter: typing.Optional[google.genai.types.IntervalDict]'
    docstring: Optional. Filter search results to a specific time range. If customers set a start time, they must set an end time (and vice versa). This field is not supported in Vertex AI.
  omitted_inherited_members_from:
  - TypedDict
- rank: 2265
  id: google.genai.types.GoogleSearchRetrieval
  name: GoogleSearchRetrieval
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Tool to retrieve public web data for grounding, powered by Google.


    [Note: Inherited members from _common.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, dynamic_retrieval_config: typing.Optional[google.genai.types.DynamicRetrievalConfig] = None):'
  properties:
  - signature: 'dynamic_retrieval_config: typing.Optional[google.genai.types.DynamicRetrievalConfig]'
  omitted_inherited_members_from:
  - _common.BaseModel
- rank: 2266
  id: google.genai.types.GoogleSearchRetrievalDict
  name: GoogleSearchRetrievalDict
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Tool to retrieve public web data for grounding, powered by Google.


    [Note: Inherited members from TypedDict are omitted.]'
  properties:
  - signature: 'dynamic_retrieval_config: typing.Optional[google.genai.types.DynamicRetrievalConfigDict]'
    docstring: Specifies the dynamic retrieval configuration for the given source.
  omitted_inherited_members_from:
  - TypedDict
- rank: 2267
  id: google.genai.types.GoogleTypeDate
  name: GoogleTypeDate
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Represents a whole or partial calendar date, such as a birthday.


    The time of day and time zone are either specified elsewhere or are

    insignificant. The date is relative to the Gregorian Calendar. This can

    represent one of the following: * A full date, with non-zero year, month, and

    day values. * A month and day, with a zero year (for example, an anniversary).

    * A year on its own, with a zero month and a zero day. * A year and month,

    with a zero day (for example, a credit card expiration date). Related types: *

    google.type.TimeOfDay * google.type.DateTime * google.protobuf.Timestamp. This

    data type is not supported in Gemini API.


    [Note: Inherited members from _common.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, day: typing.Optional[int] = None, month: typing.Optional[int] = None, year: typing.Optional[int] = None):'
  properties:
  - signature: 'day: typing.Optional[int]'
  - signature: 'month: typing.Optional[int]'
  - signature: 'year: typing.Optional[int]'
  omitted_inherited_members_from:
  - _common.BaseModel
- rank: 2268
  id: google.genai.types.GoogleTypeDateDict
  name: GoogleTypeDateDict
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Represents a whole or partial calendar date, such as a birthday.


    The time of day and time zone are either specified elsewhere or are

    insignificant. The date is relative to the Gregorian Calendar. This can

    represent one of the following: * A full date, with non-zero year, month, and

    day values. * A month and day, with a zero year (for example, an anniversary).

    * A year on its own, with a zero month and a zero day. * A year and month,

    with a zero day (for example, a credit card expiration date). Related types: *

    google.type.TimeOfDay * google.type.DateTime * google.protobuf.Timestamp. This

    data type is not supported in Gemini API.


    [Note: Inherited members from TypedDict are omitted.]'
  properties:
  - signature: 'day: typing.Optional[int]'
    docstring: Day of a month. Must be from 1 to 31 and valid for the year and month, or 0 to specify a year by itself or a year and month where the day isn't significant.
  - signature: 'month: typing.Optional[int]'
    docstring: Month of a year. Must be from 1 to 12, or 0 to specify a year without a month and day.
  - signature: 'year: typing.Optional[int]'
    docstring: Year of the date. Must be from 1 to 9999, or 0 to specify a date without a year.
  omitted_inherited_members_from:
  - TypedDict
- rank: 2269
  id: google.genai.types.GroundingChunk
  name: GroundingChunk
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Grounding chunk.


    [Note: Inherited members from _common.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, maps: typing.Optional[google.genai.types.GroundingChunkMaps] = None, retrieved_context: typing.Optional[google.genai.types.GroundingChunkRetrievedContext] = None, web: typing.Optional[google.genai.types.GroundingChunkWeb] = None):'
  properties:
  - signature: 'maps: typing.Optional[google.genai.types.GroundingChunkMaps]'
  - signature: 'retrieved_context: typing.Optional[google.genai.types.GroundingChunkRetrievedContext]'
  - signature: 'web: typing.Optional[google.genai.types.GroundingChunkWeb]'
  omitted_inherited_members_from:
  - _common.BaseModel
- rank: 2270
  id: google.genai.types.GroundingChunkDict
  name: GroundingChunkDict
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Grounding chunk.


    [Note: Inherited members from TypedDict are omitted.]'
  properties:
  - signature: 'maps: typing.Optional[google.genai.types.GroundingChunkMapsDict]'
    docstring: Grounding chunk from Google Maps. This field is not supported in Gemini API.
  - signature: 'retrieved_context: typing.Optional[google.genai.types.GroundingChunkRetrievedContextDict]'
    docstring: Grounding chunk from context retrieved by the retrieval tools. This field is not supported in Gemini API.
  - signature: 'web: typing.Optional[google.genai.types.GroundingChunkWebDict]'
    docstring: Grounding chunk from the web.
  omitted_inherited_members_from:
  - TypedDict
- rank: 2271
  id: google.genai.types.GroundingChunkMaps
  name: GroundingChunkMaps
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Chunk from Google Maps. This data type is not supported in Gemini API.


    [Note: Inherited members from _common.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, place_answer_sources: typing.Optional[google.genai.types.GroundingChunkMapsPlaceAnswerSources] = None, place_id: typing.Optional[str] = None, text: typing.Optional[str] = None, title: typing.Optional[str] = None, uri: typing.Optional[str] = None):'
  properties:
  - signature: 'place_answer_sources: typing.Optional[google.genai.types.GroundingChunkMapsPlaceAnswerSources]'
  - signature: 'place_id: typing.Optional[str]'
  - signature: 'text: typing.Optional[str]'
  - signature: 'title: typing.Optional[str]'
  - signature: 'uri: typing.Optional[str]'
  omitted_inherited_members_from:
  - _common.BaseModel
- rank: 2272
  id: google.genai.types.GroundingChunkMapsDict
  name: GroundingChunkMapsDict
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Chunk from Google Maps. This data type is not supported in Gemini API.


    [Note: Inherited members from TypedDict are omitted.]'
  properties:
  - signature: 'place_answer_sources: typing.Optional[google.genai.types.GroundingChunkMapsPlaceAnswerSourcesDict]'
    docstring: Sources used to generate the place answer. This includes review snippets and photos that were used to generate the answer, as well as uris to flag content.
  - signature: 'place_id: typing.Optional[str]'
    docstring: This Place's resource name, in `places/{place_id}` format. Can be used to look up the Place.
  - signature: 'text: typing.Optional[str]'
    docstring: Text of the place answer.
  - signature: 'title: typing.Optional[str]'
    docstring: Title of the place.
  - signature: 'uri: typing.Optional[str]'
    docstring: URI reference of the place.
  omitted_inherited_members_from:
  - TypedDict
- rank: 2273
  id: google.genai.types.GroundingChunkMapsPlaceAnswerSources
  name: GroundingChunkMapsPlaceAnswerSources
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Sources used to generate the place answer.


    This data type is not supported in Gemini API.


    [Note: Inherited members from _common.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, flag_content_uri: typing.Optional[str] = None, review_snippets: typing.Optional[list[google.genai.types.GroundingChunkMapsPlaceAnswerSourcesReviewSnippet]] = None):'
  properties:
  - signature: 'flag_content_uri: typing.Optional[str]'
  - signature: 'review_snippets: typing.Optional[list[google.genai.types.GroundingChunkMapsPlaceAnswerSourcesReviewSnippet]]'
  omitted_inherited_members_from:
  - _common.BaseModel
- rank: 2274
  id: google.genai.types.GroundingChunkMapsPlaceAnswerSourcesAuthorAttribution
  name: GroundingChunkMapsPlaceAnswerSourcesAuthorAttribution
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Author attribution for a photo or review.


    This data type is not supported in Gemini API.


    [Note: Inherited members from _common.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, display_name: typing.Optional[str] = None, photo_uri: typing.Optional[str] = None, uri: typing.Optional[str] = None):'
  properties:
  - signature: 'display_name: typing.Optional[str]'
  - signature: 'photo_uri: typing.Optional[str]'
  - signature: 'uri: typing.Optional[str]'
  omitted_inherited_members_from:
  - _common.BaseModel
- rank: 2275
  id: google.genai.types.GroundingChunkMapsPlaceAnswerSourcesAuthorAttributionDict
  name: GroundingChunkMapsPlaceAnswerSourcesAuthorAttributionDict
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Author attribution for a photo or review.


    This data type is not supported in Gemini API.


    [Note: Inherited members from TypedDict are omitted.]'
  properties:
  - signature: 'display_name: typing.Optional[str]'
    docstring: Name of the author of the Photo or Review.
  - signature: 'photo_uri: typing.Optional[str]'
    docstring: Profile photo URI of the author of the Photo or Review.
  - signature: 'uri: typing.Optional[str]'
    docstring: URI of the author of the Photo or Review.
  omitted_inherited_members_from:
  - TypedDict
- rank: 2276
  id: google.genai.types.GroundingChunkMapsPlaceAnswerSourcesDict
  name: GroundingChunkMapsPlaceAnswerSourcesDict
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Sources used to generate the place answer.


    This data type is not supported in Gemini API.


    [Note: Inherited members from TypedDict are omitted.]'
  properties:
  - signature: 'flag_content_uri: typing.Optional[str]'
    docstring: A link where users can flag a problem with the generated answer.
  - signature: 'review_snippets: typing.Optional[list[google.genai.types.GroundingChunkMapsPlaceAnswerSourcesReviewSnippetDict]]'
    docstring: Snippets of reviews that are used to generate the answer.
  omitted_inherited_members_from:
  - TypedDict
- rank: 2277
  id: google.genai.types.GroundingChunkMapsPlaceAnswerSourcesReviewSnippet
  name: GroundingChunkMapsPlaceAnswerSourcesReviewSnippet
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Encapsulates a review snippet.


    This data type is not supported in Gemini API.


    [Note: Inherited members from _common.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, author_attribution: typing.Optional[google.genai.types.GroundingChunkMapsPlaceAnswerSourcesAuthorAttribution] = None, flag_content_uri: typing.Optional[str] = None, google_maps_uri: typing.Optional[str] = None, relative_publish_time_description: typing.Optional[str] = None, review: typing.Optional[str] = None, review_id: typing.Optional[str] = None, title: typing.Optional[str] = None):'
  properties:
  - signature: 'author_attribution: typing.Optional[google.genai.types.GroundingChunkMapsPlaceAnswerSourcesAuthorAttribution]'
  - signature: 'flag_content_uri: typing.Optional[str]'
  - signature: 'google_maps_uri: typing.Optional[str]'
  - signature: 'relative_publish_time_description: typing.Optional[str]'
  - signature: 'review: typing.Optional[str]'
  - signature: 'review_id: typing.Optional[str]'
  - signature: 'title: typing.Optional[str]'
  omitted_inherited_members_from:
  - _common.BaseModel
- rank: 2278
  id: google.genai.types.GroundingChunkMapsPlaceAnswerSourcesReviewSnippetDict
  name: GroundingChunkMapsPlaceAnswerSourcesReviewSnippetDict
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Encapsulates a review snippet.


    This data type is not supported in Gemini API.


    [Note: Inherited members from TypedDict are omitted.]'
  properties:
  - signature: 'author_attribution: typing.Optional[google.genai.types.GroundingChunkMapsPlaceAnswerSourcesAuthorAttributionDict]'
    docstring: This review's author.
  - signature: 'flag_content_uri: typing.Optional[str]'
    docstring: A link where users can flag a problem with the review.
  - signature: 'google_maps_uri: typing.Optional[str]'
    docstring: A link to show the review on Google Maps.
  - signature: 'relative_publish_time_description: typing.Optional[str]'
    docstring: A string of formatted recent time, expressing the review time relative to the current time in a form appropriate for the language and country.
  - signature: 'review: typing.Optional[str]'
    docstring: A reference representing this place review which may be used to look up this place review again.
  - signature: 'review_id: typing.Optional[str]'
    docstring: Id of the review referencing the place.
  - signature: 'title: typing.Optional[str]'
    docstring: Title of the review.
  omitted_inherited_members_from:
  - TypedDict
- rank: 2279
  id: google.genai.types.GroundingChunkRetrievedContext
  name: GroundingChunkRetrievedContext
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Chunk from context retrieved by the retrieval tools.


    This data type is not supported in Gemini API.


    [Note: Inherited members from _common.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, document_name: typing.Optional[str] = None, rag_chunk: typing.Optional[google.genai.types.RagChunk] = None, text: typing.Optional[str] = None, title: typing.Optional[str] = None, uri: typing.Optional[str] = None):'
  properties:
  - signature: 'document_name: typing.Optional[str]'
  - signature: 'rag_chunk: typing.Optional[google.genai.types.RagChunk]'
  - signature: 'text: typing.Optional[str]'
  - signature: 'title: typing.Optional[str]'
  - signature: 'uri: typing.Optional[str]'
  omitted_inherited_members_from:
  - _common.BaseModel
- rank: 2280
  id: google.genai.types.GroundingChunkRetrievedContextDict
  name: GroundingChunkRetrievedContextDict
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Chunk from context retrieved by the retrieval tools.


    This data type is not supported in Gemini API.


    [Note: Inherited members from TypedDict are omitted.]'
  properties:
  - signature: 'document_name: typing.Optional[str]'
    docstring: Output only. The full document name for the referenced Vertex AI Search document.
  - signature: 'rag_chunk: typing.Optional[google.genai.types.RagChunkDict]'
    docstring: Additional context for the RAG retrieval result. This is only populated when using the RAG retrieval tool.
  - signature: 'text: typing.Optional[str]'
    docstring: Text of the attribution.
  - signature: 'title: typing.Optional[str]'
    docstring: Title of the attribution.
  - signature: 'uri: typing.Optional[str]'
    docstring: URI reference of the attribution.
  omitted_inherited_members_from:
  - TypedDict
- rank: 2281
  id: google.genai.types.GroundingChunkWeb
  name: GroundingChunkWeb
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Chunk from the web.


    [Note: Inherited members from _common.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, domain: typing.Optional[str] = None, title: typing.Optional[str] = None, uri: typing.Optional[str] = None):'
  properties:
  - signature: 'domain: typing.Optional[str]'
  - signature: 'title: typing.Optional[str]'
  - signature: 'uri: typing.Optional[str]'
  omitted_inherited_members_from:
  - _common.BaseModel
- rank: 2282
  id: google.genai.types.GroundingChunkWebDict
  name: GroundingChunkWebDict
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Chunk from the web.


    [Note: Inherited members from TypedDict are omitted.]'
  properties:
  - signature: 'domain: typing.Optional[str]'
    docstring: Domain of the (original) URI. This field is not supported in Gemini API.
  - signature: 'title: typing.Optional[str]'
    docstring: Title of the chunk.
  - signature: 'uri: typing.Optional[str]'
    docstring: URI reference of the chunk.
  omitted_inherited_members_from:
  - TypedDict
- rank: 2283
  id: google.genai.types.GroundingMetadata
  name: GroundingMetadata
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Metadata returned to client when grounding is enabled.


    [Note: Inherited members from _common.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, google_maps_widget_context_token: typing.Optional[str] = None, grounding_chunks: typing.Optional[list[google.genai.types.GroundingChunk]] = None, grounding_supports: typing.Optional[list[google.genai.types.GroundingSupport]] = None, retrieval_metadata: typing.Optional[google.genai.types.RetrievalMetadata] = None, retrieval_queries: typing.Optional[list[str]] = None, search_entry_point: typing.Optional[google.genai.types.SearchEntryPoint] = None, source_flagging_uris: typing.Optional[list[google.genai.types.GroundingMetadataSourceFlaggingUri]] = None, web_search_queries: typing.Optional[list[str]] = None):'
  properties:
  - signature: 'google_maps_widget_context_token: typing.Optional[str]'
  - signature: 'grounding_chunks: typing.Optional[list[google.genai.types.GroundingChunk]]'
  - signature: 'grounding_supports: typing.Optional[list[google.genai.types.GroundingSupport]]'
  - signature: 'retrieval_metadata: typing.Optional[google.genai.types.RetrievalMetadata]'
  - signature: 'retrieval_queries: typing.Optional[list[str]]'
  - signature: 'search_entry_point: typing.Optional[google.genai.types.SearchEntryPoint]'
  - signature: 'source_flagging_uris: typing.Optional[list[google.genai.types.GroundingMetadataSourceFlaggingUri]]'
  - signature: 'web_search_queries: typing.Optional[list[str]]'
  omitted_inherited_members_from:
  - _common.BaseModel
- rank: 2284
  id: google.genai.types.GroundingMetadataDict
  name: GroundingMetadataDict
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Metadata returned to client when grounding is enabled.


    [Note: Inherited members from TypedDict are omitted.]'
  properties:
  - signature: 'google_maps_widget_context_token: typing.Optional[str]'
    docstring: Optional. Output only. Resource name of the Google Maps widget context token to be used with the PlacesContextElement widget to render contextual data. This is populated only for Google Maps grounding. This field is not supported in Gemini API.
  - signature: 'grounding_chunks: typing.Optional[list[google.genai.types.GroundingChunkDict]]'
    docstring: List of supporting references retrieved from specified grounding source.
  - signature: 'grounding_supports: typing.Optional[list[google.genai.types.GroundingSupportDict]]'
    docstring: Optional. List of grounding support.
  - signature: 'retrieval_metadata: typing.Optional[google.genai.types.RetrievalMetadataDict]'
    docstring: Optional. Output only. Retrieval metadata.
  - signature: 'retrieval_queries: typing.Optional[list[str]]'
    docstring: Optional. Queries executed by the retrieval tools. This field is not supported in Gemini API.
  - signature: 'search_entry_point: typing.Optional[google.genai.types.SearchEntryPointDict]'
    docstring: Optional. Google search entry for the following-up web searches.
  - signature: 'source_flagging_uris: typing.Optional[list[google.genai.types.GroundingMetadataSourceFlaggingUriDict]]'
    docstring: Optional. Output only. List of source flagging uris. This is currently populated only for Google Maps grounding. This field is not supported in Gemini API.
  - signature: 'web_search_queries: typing.Optional[list[str]]'
    docstring: Optional. Web search queries for the following-up web search.
  omitted_inherited_members_from:
  - TypedDict
- rank: 2285
  id: google.genai.types.GroundingMetadataSourceFlaggingUri
  name: GroundingMetadataSourceFlaggingUri
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Source content flagging uri for a place or review.


    This is currently populated only for Google Maps grounding. This data type is

    not supported in Gemini API.


    [Note: Inherited members from _common.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, flag_content_uri: typing.Optional[str] = None, source_id: typing.Optional[str] = None):'
  properties:
  - signature: 'flag_content_uri: typing.Optional[str]'
  - signature: 'source_id: typing.Optional[str]'
  omitted_inherited_members_from:
  - _common.BaseModel
- rank: 2286
  id: google.genai.types.GroundingMetadataSourceFlaggingUriDict
  name: GroundingMetadataSourceFlaggingUriDict
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Source content flagging uri for a place or review.


    This is currently populated only for Google Maps grounding. This data type is

    not supported in Gemini API.


    [Note: Inherited members from TypedDict are omitted.]'
  properties:
  - signature: 'flag_content_uri: typing.Optional[str]'
    docstring: A link where users can flag a problem with the source (place or review).
  - signature: 'source_id: typing.Optional[str]'
    docstring: Id of the place or review.
  omitted_inherited_members_from:
  - TypedDict
- rank: 2287
  id: google.genai.types.GroundingSupport
  name: GroundingSupport
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Grounding support.


    [Note: Inherited members from _common.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, confidence_scores: typing.Optional[list[float]] = None, grounding_chunk_indices: typing.Optional[list[int]] = None, segment: typing.Optional[google.genai.types.Segment] = None):'
  properties:
  - signature: 'confidence_scores: typing.Optional[list[float]]'
  - signature: 'grounding_chunk_indices: typing.Optional[list[int]]'
  - signature: 'segment: typing.Optional[google.genai.types.Segment]'
  omitted_inherited_members_from:
  - _common.BaseModel
- rank: 2288
  id: google.genai.types.GroundingSupportDict
  name: GroundingSupportDict
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Grounding support.


    [Note: Inherited members from TypedDict are omitted.]'
  properties:
  - signature: 'confidence_scores: typing.Optional[list[float]]'
    docstring: Confidence score of the support references. Ranges from 0 to 1. 1 is the most confident. For Gemini 2.0 and before, this list must have the same size as the grounding_chunk_indices. For Gemini 2.5 and after, this list will be empty and should be ignored.
  - signature: 'grounding_chunk_indices: typing.Optional[list[int]]'
    docstring: A list of indices (into 'grounding_chunk') specifying the citations associated with the claim. For instance [1,3,4] means that grounding_chunk[1], grounding_chunk[3], grounding_chunk[4] are the retrieved content attributed to the claim.
  - signature: 'segment: typing.Optional[google.genai.types.SegmentDict]'
    docstring: Segment of the content this support belongs to.
  omitted_inherited_members_from:
  - TypedDict
- rank: 2289
  id: google.genai.types.HarmBlockMethod
  name: HarmBlockMethod
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Specify if the threshold is used for probability or severity score.


    If not specified, the threshold is used for probability score. This enum is

    not supported in Gemini API.


    [Note: Inherited members from _common.CaseInSensitiveEnum are omitted.]'
  properties:
  - signature: 'HARM_BLOCK_METHOD_UNSPECIFIED: str'
    docstring: The harm block method is unspecified.
  - signature: 'SEVERITY: str'
    docstring: The harm block method uses both probability and severity scores.
  - signature: 'PROBABILITY: str'
    docstring: The harm block method uses the probability score.
  omitted_inherited_members_from:
  - _common.CaseInSensitiveEnum
- rank: 2290
  id: google.genai.types.HarmBlockThreshold
  name: HarmBlockThreshold
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'The harm block threshold.


    [Note: Inherited members from _common.CaseInSensitiveEnum are omitted.]'
  properties:
  - signature: 'HARM_BLOCK_THRESHOLD_UNSPECIFIED: str'
    docstring: Unspecified harm block threshold.
  - signature: 'BLOCK_LOW_AND_ABOVE: str'
    docstring: Block low threshold and above (i.e. block more).
  - signature: 'BLOCK_MEDIUM_AND_ABOVE: str'
    docstring: Block medium threshold and above.
  - signature: 'BLOCK_ONLY_HIGH: str'
    docstring: Block only high threshold (i.e. block less).
  - signature: 'BLOCK_NONE: str'
    docstring: Block none.
  - signature: 'OFF: str'
    docstring: Turn off the safety filter.
  omitted_inherited_members_from:
  - _common.CaseInSensitiveEnum
- rank: 2291
  id: google.genai.types.HarmCategory
  name: HarmCategory
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Harm category.


    [Note: Inherited members from _common.CaseInSensitiveEnum are omitted.]'
  properties:
  - signature: 'HARM_CATEGORY_UNSPECIFIED: str'
    docstring: The harm category is unspecified.
  - signature: 'HARM_CATEGORY_HARASSMENT: str'
    docstring: The harm category is harassment.
  - signature: 'HARM_CATEGORY_HATE_SPEECH: str'
    docstring: The harm category is hate speech.
  - signature: 'HARM_CATEGORY_SEXUALLY_EXPLICIT: str'
    docstring: The harm category is sexually explicit content.
  - signature: 'HARM_CATEGORY_DANGEROUS_CONTENT: str'
    docstring: The harm category is dangerous content.
  - signature: 'HARM_CATEGORY_CIVIC_INTEGRITY: str'
    docstring: 'Deprecated: Election filter is not longer supported. The harm category is civic integrity.'
  - signature: 'HARM_CATEGORY_IMAGE_HATE: str'
    docstring: The harm category is image hate. This enum value is not supported in Gemini API.
  - signature: 'HARM_CATEGORY_IMAGE_DANGEROUS_CONTENT: str'
    docstring: The harm category is image dangerous content. This enum value is not supported in Gemini API.
  - signature: 'HARM_CATEGORY_IMAGE_HARASSMENT: str'
    docstring: The harm category is image harassment. This enum value is not supported in Gemini API.
  - signature: 'HARM_CATEGORY_IMAGE_SEXUALLY_EXPLICIT: str'
    docstring: The harm category is image sexually explicit content. This enum value is not supported in Gemini API.
  - signature: 'HARM_CATEGORY_JAILBREAK: str'
    docstring: The harm category is for jailbreak prompts. This enum value is not supported in Gemini API.
  omitted_inherited_members_from:
  - _common.CaseInSensitiveEnum
- rank: 2292
  id: google.genai.types.HarmProbability
  name: HarmProbability
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Output only. Harm probability levels in the content.


    [Note: Inherited members from _common.CaseInSensitiveEnum are omitted.]'
  properties:
  - signature: 'HARM_PROBABILITY_UNSPECIFIED: str'
    docstring: Harm probability unspecified.
  - signature: 'NEGLIGIBLE: str'
    docstring: Negligible level of harm.
  - signature: 'LOW: str'
    docstring: Low level of harm.
  - signature: 'MEDIUM: str'
    docstring: Medium level of harm.
  - signature: 'HIGH: str'
    docstring: High level of harm.
  omitted_inherited_members_from:
  - _common.CaseInSensitiveEnum
- rank: 2293
  id: google.genai.types.HarmSeverity
  name: HarmSeverity
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Output only.


    Harm severity levels in the content. This enum is not supported in Gemini API.


    [Note: Inherited members from _common.CaseInSensitiveEnum are omitted.]'
  properties:
  - signature: 'HARM_SEVERITY_UNSPECIFIED: str'
    docstring: Harm severity unspecified.
  - signature: 'HARM_SEVERITY_NEGLIGIBLE: str'
    docstring: Negligible level of harm severity.
  - signature: 'HARM_SEVERITY_LOW: str'
    docstring: Low level of harm severity.
  - signature: 'HARM_SEVERITY_MEDIUM: str'
    docstring: Medium level of harm severity.
  - signature: 'HARM_SEVERITY_HIGH: str'
    docstring: High level of harm severity.
  omitted_inherited_members_from:
  - _common.CaseInSensitiveEnum
- rank: 2294
  id: google.genai.types.HttpElementLocation
  name: HttpElementLocation
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'The location of the API key. This enum is not supported in Gemini API.


    [Note: Inherited members from _common.CaseInSensitiveEnum are omitted.]'
  properties:
  - signature: 'HTTP_IN_UNSPECIFIED: str'
  - signature: 'HTTP_IN_QUERY: str'
    docstring: Element is in the HTTP request query.
  - signature: 'HTTP_IN_HEADER: str'
    docstring: Element is in the HTTP request header.
  - signature: 'HTTP_IN_PATH: str'
    docstring: Element is in the HTTP request path.
  - signature: 'HTTP_IN_BODY: str'
    docstring: Element is in the HTTP request body.
  - signature: 'HTTP_IN_COOKIE: str'
    docstring: Element is in the HTTP request cookie.
  omitted_inherited_members_from:
  - _common.CaseInSensitiveEnum
- rank: 2295
  id: google.genai.types.HttpOptions
  name: HttpOptions
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'HTTP options to be used in each of the requests.


    [Note: Inherited members from _common.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, base_url: typing.Optional[str] = None, base_url_resource_scope: typing.Optional[google.genai.types.ResourceScope] = None, api_version: typing.Optional[str] = None, headers: typing.Optional[dict[str, str]] = None, timeout: typing.Optional[int] = None, client_args: typing.Optional[dict[str, typing.Any]] = None, async_client_args: typing.Optional[dict[str, typing.Any]] = None, extra_body: typing.Optional[dict[str, typing.Any]] = None, retry_options: typing.Optional[google.genai.types.HttpRetryOptions] = None, httpx_client: typing.Optional[HttpxClient] = None, httpx_async_client: typing.Optional[HttpxAsyncClient] = None):'
  properties:
  - signature: 'base_url: typing.Optional[str]'
  - signature: 'base_url_resource_scope: typing.Optional[google.genai.types.ResourceScope]'
  - signature: 'api_version: typing.Optional[str]'
  - signature: 'headers: typing.Optional[dict[str, str]]'
  - signature: 'timeout: typing.Optional[int]'
  - signature: 'client_args: typing.Optional[dict[str, typing.Any]]'
  - signature: 'async_client_args: typing.Optional[dict[str, typing.Any]]'
  - signature: 'extra_body: typing.Optional[dict[str, typing.Any]]'
  - signature: 'retry_options: typing.Optional[google.genai.types.HttpRetryOptions]'
  - signature: 'httpx_client: typing.Optional[HttpxClient]'
  - signature: 'httpx_async_client: typing.Optional[HttpxAsyncClient]'
  omitted_inherited_members_from:
  - _common.BaseModel
- rank: 2296
  id: google.genai.types.HttpOptionsDict
  name: HttpOptionsDict
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'HTTP options to be used in each of the requests.


    [Note: Inherited members from TypedDict are omitted.]'
  properties:
  - signature: 'base_url: typing.Optional[str]'
    docstring: The base URL for the AI platform service endpoint.
  - signature: 'base_url_resource_scope: typing.Optional[google.genai.types.ResourceScope]'
    docstring: The resource scope used to constructing the resource name when base_url is set
  - signature: 'api_version: typing.Optional[str]'
    docstring: Specifies the version of the API to use.
  - signature: 'headers: typing.Optional[dict[str, str]]'
    docstring: Additional HTTP headers to be sent with the request.
  - signature: 'timeout: typing.Optional[int]'
    docstring: Timeout for the request in milliseconds.
  - signature: 'client_args: typing.Optional[dict[str, typing.Any]]'
    docstring: Args passed to the HTTP client.
  - signature: 'async_client_args: typing.Optional[dict[str, typing.Any]]'
    docstring: Args passed to the async HTTP client.
  - signature: 'extra_body: typing.Optional[dict[str, typing.Any]]'
    docstring: 'Extra parameters to add to the request body.

      The structure must match the backend API''s request structure.

      - VertexAI backend API docs: https://cloud.google.com/vertex-ai/docs/reference/rest

      - GeminiAPI backend API docs: https://ai.google.dev/api/rest'
  - signature: 'retry_options: typing.Optional[google.genai.types.HttpRetryOptionsDict]'
    docstring: HTTP retry options for the request.
  omitted_inherited_members_from:
  - TypedDict
- rank: 2297
  id: google.genai.types.HttpResponse
  name: HttpResponse
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'A wrapper class for the http response.


    [Note: Inherited members from _common.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, headers: typing.Optional[dict[str, str]] = None, body: typing.Optional[str] = None):'
  properties:
  - signature: 'headers: typing.Optional[dict[str, str]]'
  - signature: 'body: typing.Optional[str]'
  omitted_inherited_members_from:
  - _common.BaseModel
- rank: 2298
  id: google.genai.types.HttpResponseDict
  name: HttpResponseDict
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'A wrapper class for the http response.


    [Note: Inherited members from TypedDict are omitted.]'
  properties:
  - signature: 'headers: typing.Optional[dict[str, str]]'
    docstring: Used to retain the processed HTTP headers in the response.
  - signature: 'body: typing.Optional[str]'
    docstring: The raw HTTP response body, in JSON format.
  omitted_inherited_members_from:
  - TypedDict
- rank: 2299
  id: google.genai.types.HttpRetryOptions
  name: HttpRetryOptions
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'HTTP retry options to be used in each of the requests.


    [Note: Inherited members from _common.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, attempts: typing.Optional[int] = None, initial_delay: typing.Optional[float] = None, max_delay: typing.Optional[float] = None, exp_base: typing.Optional[float] = None, jitter: typing.Optional[float] = None, http_status_codes: typing.Optional[list[int]] = None):'
  properties:
  - signature: 'attempts: typing.Optional[int]'
  - signature: 'initial_delay: typing.Optional[float]'
  - signature: 'max_delay: typing.Optional[float]'
  - signature: 'exp_base: typing.Optional[float]'
  - signature: 'jitter: typing.Optional[float]'
  - signature: 'http_status_codes: typing.Optional[list[int]]'
  omitted_inherited_members_from:
  - _common.BaseModel
- rank: 2300
  id: google.genai.types.HttpRetryOptionsDict
  name: HttpRetryOptionsDict
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'HTTP retry options to be used in each of the requests.


    [Note: Inherited members from TypedDict are omitted.]'
  properties:
  - signature: 'attempts: typing.Optional[int]'
    docstring: 'Maximum number of attempts, including the original request.

      If 0 or 1, it means no retries. If not specified, default to 5.'
  - signature: 'initial_delay: typing.Optional[float]'
    docstring: Initial delay before the first retry, in fractions of a second. If not specified, default to 1.0 second.
  - signature: 'max_delay: typing.Optional[float]'
    docstring: Maximum delay between retries, in fractions of a second. If not specified, default to 60.0 seconds.
  - signature: 'exp_base: typing.Optional[float]'
    docstring: Multiplier by which the delay increases after each attempt. If not specified, default to 2.0.
  - signature: 'jitter: typing.Optional[float]'
    docstring: Randomness factor for the delay. If not specified, default to 1.0.
  - signature: 'http_status_codes: typing.Optional[list[int]]'
    docstring: 'List of HTTP status codes that should trigger a retry.

      If not specified, a default set of retryable codes (408, 429, and 5xx) may be used.'
  omitted_inherited_members_from:
  - TypedDict
- rank: 2301
  id: google.genai.types.Image
  name: Image
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'An image.


    [Note: Inherited members from _common.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, gcs_uri: typing.Optional[str] = None, image_bytes: typing.Optional[bytes] = None, mime_type: typing.Optional[str] = None):'
  methods:
  - signature: 'def from_file(cls, *, location: str, mime_type: typing.Optional[str]=None) -> google.genai.types.Image:'
    docstring: "Lazy-loads an image from a local file or Google Cloud Storage.\n\nArgs:\n    location: The local path or Google Cloud Storage URI from which to load\n      the image.\n    mime_type: The MIME type of the image. If not provided, the MIME type\n      will be automatically determined.\n\nReturns:\n    A loaded image as an `Image` object."
  - signature: 'def show(self) -> None:'
    docstring: 'Shows the image.


      This method only works in a notebook environment.'
  - signature: 'def save(self, location: str) -> None:'
    docstring: "Saves the image to a file.\n\nArgs:\n    location: Local path where to save the image."
  properties:
  - signature: 'gcs_uri: typing.Optional[str]'
  - signature: 'image_bytes: typing.Optional[bytes]'
  - signature: 'mime_type: typing.Optional[str]'
  omitted_inherited_members_from:
  - _common.BaseModel
- rank: 2302
  id: google.genai.types.Image.from_file
  name: from_file
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Lazy-loads an image from a local file or Google Cloud Storage.\n\nArgs:\n    location: The local path or Google Cloud Storage URI from which to load\n      the image.\n    mime_type: The MIME type of the image. If not provided, the MIME type\n      will be automatically determined.\n\nReturns:\n    A loaded image as an `Image` object."
  signature: 'def from_file(cls, *, location: str, mime_type: typing.Optional[str]=None) -> google.genai.types.Image:'
- rank: 2303
  id: google.genai.types.Image.save
  name: save
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Saves the image to a file.\n\nArgs:\n    location: Local path where to save the image."
  signature: 'def save(self, location: str) -> None:'
- rank: 2304
  id: google.genai.types.Image.show
  name: show
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: 'Shows the image.


    This method only works in a notebook environment.'
  signature: 'def show(self) -> None:'
- rank: 2305
  id: google.genai.types.ImageConfig
  name: ImageConfig
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'The image generation configuration to be used in GenerateContentConfig.


    [Note: Inherited members from _common.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, aspect_ratio: typing.Optional[str] = None, image_size: typing.Optional[str] = None, output_mime_type: typing.Optional[str] = None, output_compression_quality: typing.Optional[int] = None):'
  properties:
  - signature: 'aspect_ratio: typing.Optional[str]'
  - signature: 'image_size: typing.Optional[str]'
  - signature: 'output_mime_type: typing.Optional[str]'
  - signature: 'output_compression_quality: typing.Optional[int]'
  omitted_inherited_members_from:
  - _common.BaseModel
- rank: 2306
  id: google.genai.types.ImageConfigDict
  name: ImageConfigDict
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'The image generation configuration to be used in GenerateContentConfig.


    [Note: Inherited members from TypedDict are omitted.]'
  properties:
  - signature: 'aspect_ratio: typing.Optional[str]'
    docstring: 'Aspect ratio of the generated images. Supported values are

      "1:1", "2:3", "3:2", "3:4", "4:3", "9:16", "16:9", and "21:9".'
  - signature: 'image_size: typing.Optional[str]'
    docstring: 'Optional. Specifies the size of generated images. Supported

      values are `1K`, `2K`, `4K`. If not specified, the model will use default

      value `1K`.'
  - signature: 'output_mime_type: typing.Optional[str]'
    docstring: 'MIME type of the generated image. This field is not

      supported in Gemini API.'
  - signature: 'output_compression_quality: typing.Optional[int]'
    docstring: 'Compression quality of the generated image (for

      ``image/jpeg`` only). This field is not supported in Gemini API.'
  omitted_inherited_members_from:
  - TypedDict
- rank: 2307
  id: google.genai.types.ImageDict
  name: ImageDict
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'An image.


    [Note: Inherited members from TypedDict are omitted.]'
  properties:
  - signature: 'gcs_uri: typing.Optional[str]'
    docstring: 'The Cloud Storage URI of the image. ``Image`` can contain a value

      for this field or the ``image_bytes`` field but not both.'
  - signature: 'image_bytes: typing.Optional[bytes]'
    docstring: 'The image bytes data. ``Image`` can contain a value for this field

      or the ``gcs_uri`` field but not both.'
  - signature: 'mime_type: typing.Optional[str]'
    docstring: The MIME type of the image.
  omitted_inherited_members_from:
  - TypedDict
- rank: 2308
  id: google.genai.types.ImagePromptLanguage
  name: ImagePromptLanguage
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Enum that specifies the language of the text in the prompt.


    [Note: Inherited members from _common.CaseInSensitiveEnum are omitted.]'
  properties:
  - signature: 'auto: str'
    docstring: Auto-detect the language.
  - signature: 'en: str'
    docstring: English
  - signature: 'ja: str'
    docstring: Japanese
  - signature: 'ko: str'
    docstring: Korean
  - signature: 'hi: str'
    docstring: Hindi
  - signature: 'zh: str'
    docstring: Chinese
  - signature: 'pt: str'
    docstring: Portuguese
  - signature: 'es: str'
    docstring: Spanish
  omitted_inherited_members_from:
  - _common.CaseInSensitiveEnum
- rank: 2309
  id: google.genai.types.ImportFileConfig
  name: ImportFileConfig
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Optional parameters for importing a file.


    [Note: Inherited members from _common.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, http_options: typing.Optional[google.genai.types.HttpOptions] = None, custom_metadata: typing.Optional[list[google.genai.types.CustomMetadata]] = None, chunking_config: typing.Optional[google.genai.types.ChunkingConfig] = None):'
  properties:
  - signature: 'http_options: typing.Optional[google.genai.types.HttpOptions]'
  - signature: 'custom_metadata: typing.Optional[list[google.genai.types.CustomMetadata]]'
  - signature: 'chunking_config: typing.Optional[google.genai.types.ChunkingConfig]'
  omitted_inherited_members_from:
  - _common.BaseModel
- rank: 2310
  id: google.genai.types.ImportFileConfigDict
  name: ImportFileConfigDict
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Optional parameters for importing a file.


    [Note: Inherited members from TypedDict are omitted.]'
  properties:
  - signature: 'http_options: typing.Optional[google.genai.types.HttpOptionsDict]'
    docstring: Used to override HTTP request options.
  - signature: 'custom_metadata: typing.Optional[list[google.genai.types.CustomMetadataDict]]'
    docstring: User provided custom metadata stored as key-value pairs used for querying.
  - signature: 'chunking_config: typing.Optional[google.genai.types.ChunkingConfigDict]'
    docstring: Config for telling the service how to chunk the file.
  omitted_inherited_members_from:
  - TypedDict
- rank: 2311
  id: google.genai.types.ImportFileOperation
  name: ImportFileOperation
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Long-running operation for importing a file to a FileSearchStore.


    [Note: Inherited members from ABC, _common.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, name: typing.Optional[str] = None, metadata: typing.Optional[dict[str, typing.Any]] = None, done: typing.Optional[bool] = None, error: typing.Optional[dict[str, typing.Any]] = None, response: typing.Optional[google.genai.types.ImportFileResponse] = None):'
  methods:
  - signature: 'def from_api_response(cls, api_response: typing.Any, is_vertex_ai: bool) -> typing_extensions.Self:'
    docstring: Instantiates a ImportFileOperation from an API response.
  properties:
  - signature: 'response: typing.Optional[google.genai.types.ImportFileResponse]'
  inherited_methods:
    Operation:
    - signature: 'def from_api_response(cls, api_response: typing.Any, is_vertex_ai: bool) -> typing_extensions.Self:'
      docstring: Creates an Operation from an API response.
  inherited_properties:
    Operation:
    - signature: 'name: typing.Optional[str]'
    - signature: 'metadata: typing.Optional[dict[str, typing.Any]]'
    - signature: 'done: typing.Optional[bool]'
    - signature: 'error: typing.Optional[dict[str, typing.Any]]'
  omitted_inherited_members_from:
  - ABC
  - _common.BaseModel
- rank: 2312
  id: google.genai.types.ImportFileOperation.from_api_response
  name: from_api_response
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: Instantiates a ImportFileOperation from an API response.
  signature: 'def from_api_response(cls, api_response: typing.Any, is_vertex_ai: bool) -> typing_extensions.Self:'
- rank: 2313
  id: google.genai.types.ImportFileResponse
  name: ImportFileResponse
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Response for ImportFile to import a File API file with a file search store.


    [Note: Inherited members from _common.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, sdk_http_response: typing.Optional[google.genai.types.HttpResponse] = None, parent: typing.Optional[str] = None, document_name: typing.Optional[str] = None):'
  properties:
  - signature: 'sdk_http_response: typing.Optional[google.genai.types.HttpResponse]'
  - signature: 'parent: typing.Optional[str]'
  - signature: 'document_name: typing.Optional[str]'
  omitted_inherited_members_from:
  - _common.BaseModel
- rank: 2314
  id: google.genai.types.ImportFileResponseDict
  name: ImportFileResponseDict
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Response for ImportFile to import a File API file with a file search store.


    [Note: Inherited members from TypedDict are omitted.]'
  properties:
  - signature: 'sdk_http_response: typing.Optional[google.genai.types.HttpResponseDict]'
    docstring: Used to retain the full HTTP response.
  - signature: 'parent: typing.Optional[str]'
    docstring: The name of the FileSearchStore containing Documents.
  - signature: 'document_name: typing.Optional[str]'
    docstring: The identifier for the Document imported.
  omitted_inherited_members_from:
  - TypedDict
- rank: 2315
  id: google.genai.types.InlinedEmbedContentResponse
  name: InlinedEmbedContentResponse
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Config for `inlined_embedding_responses` parameter.


    [Note: Inherited members from _common.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, response: typing.Optional[google.genai.types.SingleEmbedContentResponse] = None, error: typing.Optional[google.genai.types.JobError] = None):'
  properties:
  - signature: 'response: typing.Optional[google.genai.types.SingleEmbedContentResponse]'
  - signature: 'error: typing.Optional[google.genai.types.JobError]'
  omitted_inherited_members_from:
  - _common.BaseModel
- rank: 2316
  id: google.genai.types.InlinedEmbedContentResponseDict
  name: InlinedEmbedContentResponseDict
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Config for `inlined_embedding_responses` parameter.


    [Note: Inherited members from TypedDict are omitted.]'
  properties:
  - signature: 'response: typing.Optional[google.genai.types.SingleEmbedContentResponseDict]'
    docstring: "The response to the request.\n      "
  - signature: 'error: typing.Optional[google.genai.types.JobErrorDict]'
    docstring: "The error encountered while processing the request.\n      "
  omitted_inherited_members_from:
  - TypedDict
- rank: 2317
  id: google.genai.types.InlinedRequest
  name: InlinedRequest
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Config for inlined request.


    [Note: Inherited members from _common.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, model: typing.Optional[str] = None, contents: typing.Optional[google.genai.types.ContentListUnion] = None, metadata: typing.Optional[dict[str, str]] = None, config: typing.Optional[google.genai.types.GenerateContentConfig] = None):'
  properties:
  - signature: 'model: typing.Optional[str]'
  - signature: 'contents: typing.Optional[google.genai.types.ContentListUnion]'
  - signature: 'metadata: typing.Optional[dict[str, str]]'
  - signature: 'config: typing.Optional[google.genai.types.GenerateContentConfig]'
  omitted_inherited_members_from:
  - _common.BaseModel
- rank: 2318
  id: google.genai.types.InlinedRequestDict
  name: InlinedRequestDict
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Config for inlined request.


    [Note: Inherited members from TypedDict are omitted.]'
  properties:
  - signature: 'model: typing.Optional[str]'
    docstring: 'ID of the model to use. For a list of models, see `Google models

      <https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models>`_.'
  - signature: 'contents: typing.Optional[google.genai.types.ContentListUnionDict]'
    docstring: "Content of the request.\n      "
  - signature: 'metadata: typing.Optional[dict[str, str]]'
    docstring: The metadata to be associated with the request.
  - signature: 'config: typing.Optional[google.genai.types.GenerateContentConfigDict]'
    docstring: "Configuration that contains optional model parameters.\n      "
  omitted_inherited_members_from:
  - TypedDict
- rank: 2319
  id: google.genai.types.InlinedResponse
  name: InlinedResponse
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Config for `inlined_responses` parameter.


    [Note: Inherited members from _common.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, response: typing.Optional[google.genai.types.GenerateContentResponse] = None, error: typing.Optional[google.genai.types.JobError] = None):'
  properties:
  - signature: 'response: typing.Optional[google.genai.types.GenerateContentResponse]'
  - signature: 'error: typing.Optional[google.genai.types.JobError]'
  omitted_inherited_members_from:
  - _common.BaseModel
- rank: 2320
  id: google.genai.types.InlinedResponseDict
  name: InlinedResponseDict
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Config for `inlined_responses` parameter.


    [Note: Inherited members from TypedDict are omitted.]'
  properties:
  - signature: 'response: typing.Optional[google.genai.types.GenerateContentResponseDict]'
    docstring: "The response to the request.\n      "
  - signature: 'error: typing.Optional[google.genai.types.JobErrorDict]'
    docstring: "The error encountered while processing the request.\n      "
  omitted_inherited_members_from:
  - TypedDict
- rank: 2321
  id: google.genai.types.Interval
  name: Interval
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Represents a time interval, encoded as a Timestamp start (inclusive) and a Timestamp end (exclusive).


    The start must be less than or equal to the end. When the start equals the

    end, the interval is empty (matches no time). When both start and end are

    unspecified, the interval matches any time.


    [Note: Inherited members from _common.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, end_time: typing.Optional[datetime.datetime] = None, start_time: typing.Optional[datetime.datetime] = None):'
  properties:
  - signature: 'end_time: typing.Optional[datetime.datetime]'
  - signature: 'start_time: typing.Optional[datetime.datetime]'
  omitted_inherited_members_from:
  - _common.BaseModel
- rank: 2322
  id: google.genai.types.IntervalDict
  name: IntervalDict
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Represents a time interval, encoded as a Timestamp start (inclusive) and a Timestamp end (exclusive).


    The start must be less than or equal to the end. When the start equals the

    end, the interval is empty (matches no time). When both start and end are

    unspecified, the interval matches any time.


    [Note: Inherited members from TypedDict are omitted.]'
  properties:
  - signature: 'end_time: typing.Optional[datetime.datetime]'
    docstring: Optional. Exclusive end of the interval. If specified, a Timestamp matching this interval will have to be before the end.
  - signature: 'start_time: typing.Optional[datetime.datetime]'
    docstring: Optional. Inclusive start of the interval. If specified, a Timestamp matching this interval will have to be the same or after the start.
  omitted_inherited_members_from:
  - TypedDict
- rank: 2323
  id: google.genai.types.JSONSchema
  name: JSONSchema
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'A subset of JSON Schema according to 2020-12 JSON Schema draft.


    Represents a subset of a JSON Schema object that is used by the Gemini model.

    The difference between this class and the Schema class is that this class is

    compatible with OpenAPI 3.1 schema objects. And the Schema class is used to

    make API call to Gemini model.


    [Note: Inherited members from _common.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, type: typing.Optional[typing.Union[google.genai.types.JSONSchemaType, list[google.genai.types.JSONSchemaType]]] = None, format: typing.Optional[str] = None, title: typing.Optional[str] = None, description: typing.Optional[str] = None, default: typing.Optional[typing.Any] = None, items: typing.Optional[google.genai.types.JSONSchema] = None, min_items: typing.Optional[int] = None, max_items: typing.Optional[int] = None, enum: typing.Optional[list[typing.Any]] = None, properties: typing.Optional[dict[str, google.genai.types.JSONSchema]] = None, required: typing.Optional[list[str]] = None, min_properties: typing.Optional[int] = None, max_properties: typing.Optional[int] = None, minimum: typing.Optional[float] = None, maximum: typing.Optional[float] = None, min_length: typing.Optional[int] = None, max_length: typing.Optional[int] = None, pattern: typing.Optional[str] = None, additional_properties: typing.Optional[typing.Any] = None, any_of: typing.Optional[list[google.genai.types.JSONSchema]]
    = None, unique_items: typing.Optional[bool] = None, ref: typing.Optional[str] = None, defs: typing.Optional[dict[str, google.genai.types.JSONSchema]] = None):'
  properties:
  - signature: 'type: typing.Optional[typing.Union[google.genai.types.JSONSchemaType, list[google.genai.types.JSONSchemaType]]]'
  - signature: 'format: typing.Optional[str]'
  - signature: 'title: typing.Optional[str]'
  - signature: 'description: typing.Optional[str]'
  - signature: 'default: typing.Optional[typing.Any]'
  - signature: 'items: typing.Optional[google.genai.types.JSONSchema]'
  - signature: 'min_items: typing.Optional[int]'
  - signature: 'max_items: typing.Optional[int]'
  - signature: 'enum: typing.Optional[list[typing.Any]]'
  - signature: 'properties: typing.Optional[dict[str, google.genai.types.JSONSchema]]'
  - signature: 'required: typing.Optional[list[str]]'
  - signature: 'min_properties: typing.Optional[int]'
  - signature: 'max_properties: typing.Optional[int]'
  - signature: 'minimum: typing.Optional[float]'
  - signature: 'maximum: typing.Optional[float]'
  - signature: 'min_length: typing.Optional[int]'
  - signature: 'max_length: typing.Optional[int]'
  - signature: 'pattern: typing.Optional[str]'
  - signature: 'additional_properties: typing.Optional[typing.Any]'
  - signature: 'any_of: typing.Optional[list[google.genai.types.JSONSchema]]'
  - signature: 'unique_items: typing.Optional[bool]'
  - signature: 'ref: typing.Optional[str]'
  - signature: 'defs: typing.Optional[dict[str, google.genai.types.JSONSchema]]'
  omitted_inherited_members_from:
  - _common.BaseModel
- rank: 2324
  id: google.genai.types.JSONSchemaType
  name: JSONSchemaType
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'The type of the data supported by JSON Schema.


    The values of the enums are lower case strings, while the values of the enums

    for the Type class are upper case strings.


    [Note: Inherited members from Enum are omitted.]'
  properties:
  - signature: 'NULL: str'
  - signature: 'BOOLEAN: str'
  - signature: 'OBJECT: str'
  - signature: 'ARRAY: str'
  - signature: 'NUMBER: str'
  - signature: 'INTEGER: str'
  - signature: 'STRING: str'
  omitted_inherited_members_from:
  - Enum
- rank: 2325
  id: google.genai.types.JobError
  name: JobError
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Job error.


    [Note: Inherited members from _common.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, details: typing.Optional[list[str]] = None, code: typing.Optional[int] = None, message: typing.Optional[str] = None):'
  properties:
  - signature: 'details: typing.Optional[list[str]]'
  - signature: 'code: typing.Optional[int]'
  - signature: 'message: typing.Optional[str]'
  omitted_inherited_members_from:
  - _common.BaseModel
- rank: 2326
  id: google.genai.types.JobErrorDict
  name: JobErrorDict
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Job error.


    [Note: Inherited members from TypedDict are omitted.]'
  properties:
  - signature: 'details: typing.Optional[list[str]]'
    docstring: A list of messages that carry the error details. There is a common set of message types for APIs to use.
  - signature: 'code: typing.Optional[int]'
    docstring: The status code.
  - signature: 'message: typing.Optional[str]'
    docstring: A developer-facing error message, which should be in English. Any user-facing error message should be localized and sent in the `details` field.
  omitted_inherited_members_from:
  - TypedDict
- rank: 2327
  id: google.genai.types.JobState
  name: JobState
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Job state.


    [Note: Inherited members from _common.CaseInSensitiveEnum are omitted.]'
  properties:
  - signature: 'JOB_STATE_UNSPECIFIED: str'
    docstring: The job state is unspecified.
  - signature: 'JOB_STATE_QUEUED: str'
    docstring: The job has been just created or resumed and processing has not yet begun.
  - signature: 'JOB_STATE_PENDING: str'
    docstring: The service is preparing to run the job.
  - signature: 'JOB_STATE_RUNNING: str'
    docstring: The job is in progress.
  - signature: 'JOB_STATE_SUCCEEDED: str'
    docstring: The job completed successfully.
  - signature: 'JOB_STATE_FAILED: str'
    docstring: The job failed.
  - signature: 'JOB_STATE_CANCELLING: str'
    docstring: The job is being cancelled. From this state the job may only go to either `JOB_STATE_SUCCEEDED`, `JOB_STATE_FAILED` or `JOB_STATE_CANCELLED`.
  - signature: 'JOB_STATE_CANCELLED: str'
    docstring: The job has been cancelled.
  - signature: 'JOB_STATE_PAUSED: str'
    docstring: The job has been stopped, and can be resumed.
  - signature: 'JOB_STATE_EXPIRED: str'
    docstring: The job has expired.
  - signature: 'JOB_STATE_UPDATING: str'
    docstring: The job is being updated. Only jobs in the `JOB_STATE_RUNNING` state can be updated. After updating, the job goes back to the `JOB_STATE_RUNNING` state.
  - signature: 'JOB_STATE_PARTIALLY_SUCCEEDED: str'
    docstring: The job is partially succeeded, some results may be missing due to errors.
  omitted_inherited_members_from:
  - _common.CaseInSensitiveEnum
- rank: 2328
  id: google.genai.types.Language
  name: Language
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Programming language of the `code`.


    [Note: Inherited members from _common.CaseInSensitiveEnum are omitted.]'
  properties:
  - signature: 'LANGUAGE_UNSPECIFIED: str'
    docstring: Unspecified language. This value should not be used.
  - signature: 'PYTHON: str'
    docstring: Python >= 3.10, with numpy and simpy available.
  omitted_inherited_members_from:
  - _common.CaseInSensitiveEnum
- rank: 2329
  id: google.genai.types.LatLng
  name: LatLng
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'An object that represents a latitude/longitude pair.


    This is expressed as a pair of doubles to represent degrees latitude and

    degrees longitude. Unless specified otherwise, this object must conform to the

    <a href="https://en.wikipedia.org/wiki/World_Geodetic_System#1984_version">

    WGS84 standard</a>. Values must be within normalized ranges.


    [Note: Inherited members from _common.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, latitude: typing.Optional[float] = None, longitude: typing.Optional[float] = None):'
  properties:
  - signature: 'latitude: typing.Optional[float]'
  - signature: 'longitude: typing.Optional[float]'
  omitted_inherited_members_from:
  - _common.BaseModel
- rank: 2330
  id: google.genai.types.LatLngDict
  name: LatLngDict
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'An object that represents a latitude/longitude pair.


    This is expressed as a pair of doubles to represent degrees latitude and

    degrees longitude. Unless specified otherwise, this object must conform to the

    <a href="https://en.wikipedia.org/wiki/World_Geodetic_System#1984_version">

    WGS84 standard</a>. Values must be within normalized ranges.


    [Note: Inherited members from TypedDict are omitted.]'
  properties:
  - signature: 'latitude: typing.Optional[float]'
    docstring: The latitude in degrees. It must be in the range [-90.0, +90.0].
  - signature: 'longitude: typing.Optional[float]'
    docstring: The longitude in degrees. It must be in the range [-180.0, +180.0]
  omitted_inherited_members_from:
  - TypedDict
- rank: 2331
  id: google.genai.types.ListBatchJobsConfig
  name: ListBatchJobsConfig
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Config for optional parameters.


    [Note: Inherited members from _common.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, http_options: typing.Optional[google.genai.types.HttpOptions] = None, page_size: typing.Optional[int] = None, page_token: typing.Optional[str] = None, filter: typing.Optional[str] = None):'
  properties:
  - signature: 'http_options: typing.Optional[google.genai.types.HttpOptions]'
  - signature: 'page_size: typing.Optional[int]'
  - signature: 'page_token: typing.Optional[str]'
  - signature: 'filter: typing.Optional[str]'
  omitted_inherited_members_from:
  - _common.BaseModel
- rank: 2332
  id: google.genai.types.ListBatchJobsConfigDict
  name: ListBatchJobsConfigDict
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Config for optional parameters.


    [Note: Inherited members from TypedDict are omitted.]'
  properties:
  - signature: 'http_options: typing.Optional[google.genai.types.HttpOptionsDict]'
    docstring: Used to override HTTP request options.
  - signature: 'page_size: typing.Optional[int]'
  - signature: 'page_token: typing.Optional[str]'
  - signature: 'filter: typing.Optional[str]'
  omitted_inherited_members_from:
  - TypedDict
- rank: 2333
  id: google.genai.types.ListBatchJobsResponse
  name: ListBatchJobsResponse
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Config for batches.list return value.


    [Note: Inherited members from _common.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, sdk_http_response: typing.Optional[google.genai.types.HttpResponse] = None, next_page_token: typing.Optional[str] = None, batch_jobs: typing.Optional[list[google.genai.types.BatchJob]] = None):'
  properties:
  - signature: 'sdk_http_response: typing.Optional[google.genai.types.HttpResponse]'
  - signature: 'next_page_token: typing.Optional[str]'
  - signature: 'batch_jobs: typing.Optional[list[google.genai.types.BatchJob]]'
  omitted_inherited_members_from:
  - _common.BaseModel
- rank: 2334
  id: google.genai.types.ListBatchJobsResponseDict
  name: ListBatchJobsResponseDict
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Config for batches.list return value.


    [Note: Inherited members from TypedDict are omitted.]'
  properties:
  - signature: 'sdk_http_response: typing.Optional[google.genai.types.HttpResponseDict]'
    docstring: Used to retain the full HTTP response.
  - signature: 'next_page_token: typing.Optional[str]'
  - signature: 'batch_jobs: typing.Optional[list[google.genai.types.BatchJobDict]]'
  omitted_inherited_members_from:
  - TypedDict
- rank: 2335
  id: google.genai.types.ListCachedContentsConfig
  name: ListCachedContentsConfig
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Config for caches.list method.


    [Note: Inherited members from _common.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, http_options: typing.Optional[google.genai.types.HttpOptions] = None, page_size: typing.Optional[int] = None, page_token: typing.Optional[str] = None):'
  properties:
  - signature: 'http_options: typing.Optional[google.genai.types.HttpOptions]'
  - signature: 'page_size: typing.Optional[int]'
  - signature: 'page_token: typing.Optional[str]'
  omitted_inherited_members_from:
  - _common.BaseModel
- rank: 2336
  id: google.genai.types.ListCachedContentsConfigDict
  name: ListCachedContentsConfigDict
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Config for caches.list method.


    [Note: Inherited members from TypedDict are omitted.]'
  properties:
  - signature: 'http_options: typing.Optional[google.genai.types.HttpOptionsDict]'
    docstring: Used to override HTTP request options.
  - signature: 'page_size: typing.Optional[int]'
  - signature: 'page_token: typing.Optional[str]'
  omitted_inherited_members_from:
  - TypedDict
- rank: 2337
  id: google.genai.types.ListCachedContentsResponse
  name: ListCachedContentsResponse
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: '[Note: Inherited members from _common.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, sdk_http_response: typing.Optional[google.genai.types.HttpResponse] = None, next_page_token: typing.Optional[str] = None, cached_contents: typing.Optional[list[google.genai.types.CachedContent]] = None):'
  properties:
  - signature: 'sdk_http_response: typing.Optional[google.genai.types.HttpResponse]'
  - signature: 'next_page_token: typing.Optional[str]'
  - signature: 'cached_contents: typing.Optional[list[google.genai.types.CachedContent]]'
  omitted_inherited_members_from:
  - _common.BaseModel
- rank: 2338
  id: google.genai.types.ListCachedContentsResponseDict
  name: ListCachedContentsResponseDict
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: '[Note: Inherited members from TypedDict are omitted.]'
  properties:
  - signature: 'sdk_http_response: typing.Optional[google.genai.types.HttpResponseDict]'
    docstring: Used to retain the full HTTP response.
  - signature: 'next_page_token: typing.Optional[str]'
  - signature: 'cached_contents: typing.Optional[list[google.genai.types.CachedContentDict]]'
    docstring: "List of cached contents.\n      "
  omitted_inherited_members_from:
  - TypedDict
- rank: 2339
  id: google.genai.types.ListDocumentsConfig
  name: ListDocumentsConfig
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Config for optional parameters.


    [Note: Inherited members from _common.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, http_options: typing.Optional[google.genai.types.HttpOptions] = None, page_size: typing.Optional[int] = None, page_token: typing.Optional[str] = None):'
  properties:
  - signature: 'http_options: typing.Optional[google.genai.types.HttpOptions]'
  - signature: 'page_size: typing.Optional[int]'
  - signature: 'page_token: typing.Optional[str]'
  omitted_inherited_members_from:
  - _common.BaseModel
- rank: 2340
  id: google.genai.types.ListDocumentsConfigDict
  name: ListDocumentsConfigDict
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Config for optional parameters.


    [Note: Inherited members from TypedDict are omitted.]'
  properties:
  - signature: 'http_options: typing.Optional[google.genai.types.HttpOptionsDict]'
    docstring: Used to override HTTP request options.
  - signature: 'page_size: typing.Optional[int]'
  - signature: 'page_token: typing.Optional[str]'
  omitted_inherited_members_from:
  - TypedDict
- rank: 2341
  id: google.genai.types.ListDocumentsResponse
  name: ListDocumentsResponse
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Config for documents.list return value.


    [Note: Inherited members from _common.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, sdk_http_response: typing.Optional[google.genai.types.HttpResponse] = None, next_page_token: typing.Optional[str] = None, documents: typing.Optional[list[google.genai.types.Document]] = None):'
  properties:
  - signature: 'sdk_http_response: typing.Optional[google.genai.types.HttpResponse]'
  - signature: 'next_page_token: typing.Optional[str]'
  - signature: 'documents: typing.Optional[list[google.genai.types.Document]]'
  omitted_inherited_members_from:
  - _common.BaseModel
- rank: 2342
  id: google.genai.types.ListDocumentsResponseDict
  name: ListDocumentsResponseDict
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Config for documents.list return value.


    [Note: Inherited members from TypedDict are omitted.]'
  properties:
  - signature: 'sdk_http_response: typing.Optional[google.genai.types.HttpResponseDict]'
    docstring: Used to retain the full HTTP response.
  - signature: 'next_page_token: typing.Optional[str]'
    docstring: A token, which can be sent as `page_token` to retrieve the next page. If this field is omitted, there are no more pages.
  - signature: 'documents: typing.Optional[list[google.genai.types.DocumentDict]]'
    docstring: The returned `Document`s.
  omitted_inherited_members_from:
  - TypedDict
- rank: 2343
  id: google.genai.types.ListFileSearchStoresConfig
  name: ListFileSearchStoresConfig
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Optional parameters for listing FileSearchStore.


    [Note: Inherited members from _common.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, http_options: typing.Optional[google.genai.types.HttpOptions] = None, page_size: typing.Optional[int] = None, page_token: typing.Optional[str] = None):'
  properties:
  - signature: 'http_options: typing.Optional[google.genai.types.HttpOptions]'
  - signature: 'page_size: typing.Optional[int]'
  - signature: 'page_token: typing.Optional[str]'
  omitted_inherited_members_from:
  - _common.BaseModel
- rank: 2344
  id: google.genai.types.ListFileSearchStoresConfigDict
  name: ListFileSearchStoresConfigDict
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Optional parameters for listing FileSearchStore.


    [Note: Inherited members from TypedDict are omitted.]'
  properties:
  - signature: 'http_options: typing.Optional[google.genai.types.HttpOptionsDict]'
    docstring: Used to override HTTP request options.
  - signature: 'page_size: typing.Optional[int]'
  - signature: 'page_token: typing.Optional[str]'
  omitted_inherited_members_from:
  - TypedDict
- rank: 2345
  id: google.genai.types.ListFileSearchStoresResponse
  name: ListFileSearchStoresResponse
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Config for file_search_stores.list return value.


    [Note: Inherited members from _common.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, sdk_http_response: typing.Optional[google.genai.types.HttpResponse] = None, next_page_token: typing.Optional[str] = None, file_search_stores: typing.Optional[list[google.genai.types.FileSearchStore]] = None):'
  properties:
  - signature: 'sdk_http_response: typing.Optional[google.genai.types.HttpResponse]'
  - signature: 'next_page_token: typing.Optional[str]'
  - signature: 'file_search_stores: typing.Optional[list[google.genai.types.FileSearchStore]]'
  omitted_inherited_members_from:
  - _common.BaseModel
- rank: 2346
  id: google.genai.types.ListFileSearchStoresResponseDict
  name: ListFileSearchStoresResponseDict
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Config for file_search_stores.list return value.


    [Note: Inherited members from TypedDict are omitted.]'
  properties:
  - signature: 'sdk_http_response: typing.Optional[google.genai.types.HttpResponseDict]'
    docstring: Used to retain the full HTTP response.
  - signature: 'next_page_token: typing.Optional[str]'
  - signature: 'file_search_stores: typing.Optional[list[google.genai.types.FileSearchStoreDict]]'
    docstring: The returned file search stores.
  omitted_inherited_members_from:
  - TypedDict
- rank: 2347
  id: google.genai.types.ListFilesConfig
  name: ListFilesConfig
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Used to override the default configuration.


    [Note: Inherited members from _common.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, http_options: typing.Optional[google.genai.types.HttpOptions] = None, page_size: typing.Optional[int] = None, page_token: typing.Optional[str] = None):'
  properties:
  - signature: 'http_options: typing.Optional[google.genai.types.HttpOptions]'
  - signature: 'page_size: typing.Optional[int]'
  - signature: 'page_token: typing.Optional[str]'
  omitted_inherited_members_from:
  - _common.BaseModel
- rank: 2348
  id: google.genai.types.ListFilesConfigDict
  name: ListFilesConfigDict
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Used to override the default configuration.


    [Note: Inherited members from TypedDict are omitted.]'
  properties:
  - signature: 'http_options: typing.Optional[google.genai.types.HttpOptionsDict]'
    docstring: Used to override HTTP request options.
  - signature: 'page_size: typing.Optional[int]'
  - signature: 'page_token: typing.Optional[str]'
  omitted_inherited_members_from:
  - TypedDict
- rank: 2349
  id: google.genai.types.ListFilesResponse
  name: ListFilesResponse
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Response for the list files method.


    [Note: Inherited members from _common.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, sdk_http_response: typing.Optional[google.genai.types.HttpResponse] = None, next_page_token: typing.Optional[str] = None, files: typing.Optional[list[google.genai.types.File]] = None):'
  properties:
  - signature: 'sdk_http_response: typing.Optional[google.genai.types.HttpResponse]'
  - signature: 'next_page_token: typing.Optional[str]'
  - signature: 'files: typing.Optional[list[google.genai.types.File]]'
  omitted_inherited_members_from:
  - _common.BaseModel
- rank: 2350
  id: google.genai.types.ListFilesResponseDict
  name: ListFilesResponseDict
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Response for the list files method.


    [Note: Inherited members from TypedDict are omitted.]'
  properties:
  - signature: 'sdk_http_response: typing.Optional[google.genai.types.HttpResponseDict]'
    docstring: Used to retain the full HTTP response.
  - signature: 'next_page_token: typing.Optional[str]'
    docstring: A token that can be sent as a `page_token` into a subsequent `ListFiles` call.
  - signature: 'files: typing.Optional[list[google.genai.types.FileDict]]'
    docstring: The list of `File`s.
  omitted_inherited_members_from:
  - TypedDict
- rank: 2351
  id: google.genai.types.ListModelsConfig
  name: ListModelsConfig
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: '[Note: Inherited members from _common.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, http_options: typing.Optional[google.genai.types.HttpOptions] = None, page_size: typing.Optional[int] = None, page_token: typing.Optional[str] = None, filter: typing.Optional[str] = None, query_base: typing.Optional[bool] = None):'
  properties:
  - signature: 'http_options: typing.Optional[google.genai.types.HttpOptions]'
  - signature: 'page_size: typing.Optional[int]'
  - signature: 'page_token: typing.Optional[str]'
  - signature: 'filter: typing.Optional[str]'
  - signature: 'query_base: typing.Optional[bool]'
  omitted_inherited_members_from:
  - _common.BaseModel
- rank: 2352
  id: google.genai.types.ListModelsConfigDict
  name: ListModelsConfigDict
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: '[Note: Inherited members from TypedDict are omitted.]'
  properties:
  - signature: 'http_options: typing.Optional[google.genai.types.HttpOptionsDict]'
    docstring: Used to override HTTP request options.
  - signature: 'page_size: typing.Optional[int]'
  - signature: 'page_token: typing.Optional[str]'
  - signature: 'filter: typing.Optional[str]'
  - signature: 'query_base: typing.Optional[bool]'
    docstring: Set true to list base models, false to list tuned models.
  omitted_inherited_members_from:
  - TypedDict
- rank: 2353
  id: google.genai.types.ListModelsResponse
  name: ListModelsResponse
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: '[Note: Inherited members from _common.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, sdk_http_response: typing.Optional[google.genai.types.HttpResponse] = None, next_page_token: typing.Optional[str] = None, models: typing.Optional[list[google.genai.types.Model]] = None):'
  properties:
  - signature: 'sdk_http_response: typing.Optional[google.genai.types.HttpResponse]'
  - signature: 'next_page_token: typing.Optional[str]'
  - signature: 'models: typing.Optional[list[google.genai.types.Model]]'
  omitted_inherited_members_from:
  - _common.BaseModel
- rank: 2354
  id: google.genai.types.ListModelsResponseDict
  name: ListModelsResponseDict
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: '[Note: Inherited members from TypedDict are omitted.]'
  properties:
  - signature: 'sdk_http_response: typing.Optional[google.genai.types.HttpResponseDict]'
    docstring: Used to retain the full HTTP response.
  - signature: 'next_page_token: typing.Optional[str]'
  - signature: 'models: typing.Optional[list[google.genai.types.ModelDict]]'
  omitted_inherited_members_from:
  - TypedDict
- rank: 2355
  id: google.genai.types.ListTuningJobsConfig
  name: ListTuningJobsConfig
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Configuration for the list tuning jobs method.


    [Note: Inherited members from _common.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, http_options: typing.Optional[google.genai.types.HttpOptions] = None, page_size: typing.Optional[int] = None, page_token: typing.Optional[str] = None, filter: typing.Optional[str] = None):'
  properties:
  - signature: 'http_options: typing.Optional[google.genai.types.HttpOptions]'
  - signature: 'page_size: typing.Optional[int]'
  - signature: 'page_token: typing.Optional[str]'
  - signature: 'filter: typing.Optional[str]'
  omitted_inherited_members_from:
  - _common.BaseModel
- rank: 2356
  id: google.genai.types.ListTuningJobsConfigDict
  name: ListTuningJobsConfigDict
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Configuration for the list tuning jobs method.


    [Note: Inherited members from TypedDict are omitted.]'
  properties:
  - signature: 'http_options: typing.Optional[google.genai.types.HttpOptionsDict]'
    docstring: Used to override HTTP request options.
  - signature: 'page_size: typing.Optional[int]'
  - signature: 'page_token: typing.Optional[str]'
  - signature: 'filter: typing.Optional[str]'
  omitted_inherited_members_from:
  - TypedDict
- rank: 2357
  id: google.genai.types.ListTuningJobsResponse
  name: ListTuningJobsResponse
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Response for the list tuning jobs method.


    [Note: Inherited members from _common.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, sdk_http_response: typing.Optional[google.genai.types.HttpResponse] = None, next_page_token: typing.Optional[str] = None, tuning_jobs: typing.Optional[list[google.genai.types.TuningJob]] = None):'
  properties:
  - signature: 'sdk_http_response: typing.Optional[google.genai.types.HttpResponse]'
  - signature: 'next_page_token: typing.Optional[str]'
  - signature: 'tuning_jobs: typing.Optional[list[google.genai.types.TuningJob]]'
  omitted_inherited_members_from:
  - _common.BaseModel
- rank: 2358
  id: google.genai.types.ListTuningJobsResponseDict
  name: ListTuningJobsResponseDict
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Response for the list tuning jobs method.


    [Note: Inherited members from TypedDict are omitted.]'
  properties:
  - signature: 'sdk_http_response: typing.Optional[google.genai.types.HttpResponseDict]'
    docstring: Used to retain the full HTTP response.
  - signature: 'next_page_token: typing.Optional[str]'
    docstring: A token to retrieve the next page of results. Pass to ListTuningJobsRequest.page_token to obtain that page.
  - signature: 'tuning_jobs: typing.Optional[list[google.genai.types.TuningJobDict]]'
    docstring: List of TuningJobs in the requested page.
  omitted_inherited_members_from:
  - TypedDict
- rank: 2359
  id: google.genai.types.LiveClientContent
  name: LiveClientContent
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Incremental update of the current conversation delivered from the client.


    All the content here will unconditionally be appended to the conversation

    history and used as part of the prompt to the model to generate content.


    A message here will interrupt any current model generation.


    [Note: Inherited members from _common.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, turns: typing.Optional[list[google.genai.types.Content]] = None, turn_complete: typing.Optional[bool] = None):'
  properties:
  - signature: 'turns: typing.Optional[list[google.genai.types.Content]]'
  - signature: 'turn_complete: typing.Optional[bool]'
  omitted_inherited_members_from:
  - _common.BaseModel
- rank: 2360
  id: google.genai.types.LiveClientContentDict
  name: LiveClientContentDict
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Incremental update of the current conversation delivered from the client.


    All the content here will unconditionally be appended to the conversation

    history and used as part of the prompt to the model to generate content.


    A message here will interrupt any current model generation.


    [Note: Inherited members from TypedDict are omitted.]'
  properties:
  - signature: 'turns: typing.Optional[list[google.genai.types.ContentDict]]'
    docstring: 'The content appended to the current conversation with the model.


      For single-turn queries, this is a single instance. For multi-turn

      queries, this is a repeated field that contains conversation history and

      latest request.'
  - signature: 'turn_complete: typing.Optional[bool]'
    docstring: 'If true, indicates that the server content generation should start with

      the currently accumulated prompt. Otherwise, the server will await

      additional messages before starting generation.'
  omitted_inherited_members_from:
  - TypedDict
- rank: 2361
  id: google.genai.types.LiveClientMessage
  name: LiveClientMessage
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Messages sent by the client in the API call.


    [Note: Inherited members from _common.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, setup: typing.Optional[google.genai.types.LiveClientSetup] = None, client_content: typing.Optional[google.genai.types.LiveClientContent] = None, realtime_input: typing.Optional[google.genai.types.LiveClientRealtimeInput] = None, tool_response: typing.Optional[google.genai.types.LiveClientToolResponse] = None):'
  properties:
  - signature: 'setup: typing.Optional[google.genai.types.LiveClientSetup]'
  - signature: 'client_content: typing.Optional[google.genai.types.LiveClientContent]'
  - signature: 'realtime_input: typing.Optional[google.genai.types.LiveClientRealtimeInput]'
  - signature: 'tool_response: typing.Optional[google.genai.types.LiveClientToolResponse]'
  omitted_inherited_members_from:
  - _common.BaseModel
- rank: 2362
  id: google.genai.types.LiveClientMessageDict
  name: LiveClientMessageDict
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Messages sent by the client in the API call.


    [Note: Inherited members from TypedDict are omitted.]'
  properties:
  - signature: 'setup: typing.Optional[google.genai.types.LiveClientSetupDict]'
    docstring: Message to be sent by the system when connecting to the API. SDK users should not send this message.
  - signature: 'client_content: typing.Optional[google.genai.types.LiveClientContentDict]'
    docstring: Incremental update of the current conversation delivered from the client.
  - signature: 'realtime_input: typing.Optional[google.genai.types.LiveClientRealtimeInputDict]'
    docstring: User input that is sent in real time.
  - signature: 'tool_response: typing.Optional[google.genai.types.LiveClientToolResponseDict]'
    docstring: Response to a `ToolCallMessage` received from the server.
  omitted_inherited_members_from:
  - TypedDict
- rank: 2363
  id: google.genai.types.LiveClientRealtimeInput
  name: LiveClientRealtimeInput
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: "User input that is sent in real time.\n\nThis is different from `LiveClientContent` in a few ways:\n\n  - Can be sent continuously without interruption to model generation.\n  - If there is a need to mix data interleaved across the\n    `LiveClientContent` and the `LiveClientRealtimeInput`, server attempts to\n    optimize for best response, but there are no guarantees.\n  - End of turn is not explicitly specified, but is rather derived from user\n    activity (for example, end of speech).\n  - Even before the end of turn, the data is processed incrementally\n    to optimize for a fast start of the response from the model.\n  - Is always assumed to be the user's input (cannot be used to populate\n    conversation history).\n\n[Note: Inherited members from _common.BaseModel are omitted.]"
  constructor_signature: 'def __init__(self, *, media_chunks: typing.Optional[list[google.genai.types.Blob]] = None, audio: typing.Optional[google.genai.types.Blob] = None, audio_stream_end: typing.Optional[bool] = None, video: typing.Optional[google.genai.types.Blob] = None, text: typing.Optional[str] = None, activity_start: typing.Optional[google.genai.types.ActivityStart] = None, activity_end: typing.Optional[google.genai.types.ActivityEnd] = None):'
  properties:
  - signature: 'media_chunks: typing.Optional[list[google.genai.types.Blob]]'
  - signature: 'audio: typing.Optional[google.genai.types.Blob]'
  - signature: 'audio_stream_end: typing.Optional[bool]'
  - signature: 'video: typing.Optional[google.genai.types.Blob]'
  - signature: 'text: typing.Optional[str]'
  - signature: 'activity_start: typing.Optional[google.genai.types.ActivityStart]'
  - signature: 'activity_end: typing.Optional[google.genai.types.ActivityEnd]'
  omitted_inherited_members_from:
  - _common.BaseModel
- rank: 2364
  id: google.genai.types.LiveClientRealtimeInputDict
  name: LiveClientRealtimeInputDict
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: "User input that is sent in real time.\n\nThis is different from `LiveClientContent` in a few ways:\n\n  - Can be sent continuously without interruption to model generation.\n  - If there is a need to mix data interleaved across the\n    `LiveClientContent` and the `LiveClientRealtimeInput`, server attempts to\n    optimize for best response, but there are no guarantees.\n  - End of turn is not explicitly specified, but is rather derived from user\n    activity (for example, end of speech).\n  - Even before the end of turn, the data is processed incrementally\n    to optimize for a fast start of the response from the model.\n  - Is always assumed to be the user's input (cannot be used to populate\n    conversation history).\n\n[Note: Inherited members from TypedDict are omitted.]"
  properties:
  - signature: 'media_chunks: typing.Optional[list[google.genai.types.BlobDict]]'
    docstring: Inlined bytes data for media input.
  - signature: 'audio: typing.Optional[google.genai.types.BlobDict]'
    docstring: The realtime audio input stream.
  - signature: 'audio_stream_end: typing.Optional[bool]'
    docstring: 'Indicates that the audio stream has ended, e.g. because the microphone was

      turned off.


      This should only be sent when automatic activity detection is enabled

      (which is the default).


      The client can reopen the stream by sending an audio message.'
  - signature: 'video: typing.Optional[google.genai.types.BlobDict]'
    docstring: The realtime video input stream.
  - signature: 'text: typing.Optional[str]'
    docstring: The realtime text input stream.
  - signature: 'activity_start: typing.Optional[google.genai.types.ActivityStartDict]'
    docstring: Marks the start of user activity.
  - signature: 'activity_end: typing.Optional[google.genai.types.ActivityEndDict]'
    docstring: Marks the end of user activity.
  omitted_inherited_members_from:
  - TypedDict
- rank: 2365
  id: google.genai.types.LiveClientSetup
  name: LiveClientSetup
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Message contains configuration that will apply for the duration of the streaming session.


    [Note: Inherited members from _common.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, model: typing.Optional[str] = None, generation_config: typing.Optional[google.genai.types.GenerationConfig] = None, system_instruction: typing.Optional[google.genai.types.ContentUnion] = None, tools: typing.Optional[google.genai.types.ToolListUnion] = None, session_resumption: typing.Optional[google.genai.types.SessionResumptionConfig] = None, context_window_compression: typing.Optional[google.genai.types.ContextWindowCompressionConfig] = None, input_audio_transcription: typing.Optional[google.genai.types.AudioTranscriptionConfig] = None, output_audio_transcription: typing.Optional[google.genai.types.AudioTranscriptionConfig] = None, proactivity: typing.Optional[google.genai.types.ProactivityConfig] = None):'
  properties:
  - signature: 'model: typing.Optional[str]'
  - signature: 'generation_config: typing.Optional[google.genai.types.GenerationConfig]'
  - signature: 'system_instruction: typing.Optional[google.genai.types.ContentUnion]'
  - signature: 'tools: typing.Optional[google.genai.types.ToolListUnion]'
  - signature: 'session_resumption: typing.Optional[google.genai.types.SessionResumptionConfig]'
  - signature: 'context_window_compression: typing.Optional[google.genai.types.ContextWindowCompressionConfig]'
  - signature: 'input_audio_transcription: typing.Optional[google.genai.types.AudioTranscriptionConfig]'
  - signature: 'output_audio_transcription: typing.Optional[google.genai.types.AudioTranscriptionConfig]'
  - signature: 'proactivity: typing.Optional[google.genai.types.ProactivityConfig]'
  omitted_inherited_members_from:
  - _common.BaseModel
- rank: 2366
  id: google.genai.types.LiveClientSetupDict
  name: LiveClientSetupDict
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Message contains configuration that will apply for the duration of the streaming session.


    [Note: Inherited members from TypedDict are omitted.]'
  properties:
  - signature: 'model: typing.Optional[str]'
    docstring: 'The fully qualified name of the publisher model or tuned model endpoint to

      use.'
  - signature: 'generation_config: typing.Optional[google.genai.types.GenerationConfigDict]'
    docstring: 'The generation configuration for the session.

      Note: only a subset of fields are supported.'
  - signature: 'system_instruction: typing.Optional[google.genai.types.ContentUnionDict]'
    docstring: 'The user provided system instructions for the model.

      Note: only text should be used in parts and content in each part will be

      in a separate paragraph.'
  - signature: 'tools: typing.Optional[google.genai.types.ToolListUnionDict]'
    docstring: 'A list of `Tools` the model may use to generate the next response.


      A `Tool` is a piece of code that enables the system to interact with

      external systems to perform an action, or set of actions, outside of

      knowledge and scope of the model.'
  - signature: 'session_resumption: typing.Optional[google.genai.types.SessionResumptionConfigDict]'
    docstring: 'Configures session resumption mechanism.


      If included server will send SessionResumptionUpdate messages.'
  - signature: 'context_window_compression: typing.Optional[google.genai.types.ContextWindowCompressionConfigDict]'
    docstring: 'Configures context window compression mechanism.


      If included, server will compress context window to fit into given length.'
  - signature: 'input_audio_transcription: typing.Optional[google.genai.types.AudioTranscriptionConfigDict]'
    docstring: "The transcription of the input aligns with the input audio language.\n      "
  - signature: 'output_audio_transcription: typing.Optional[google.genai.types.AudioTranscriptionConfigDict]'
    docstring: 'The transcription of the output aligns with the language code

      specified for the output audio.'
  - signature: 'proactivity: typing.Optional[google.genai.types.ProactivityConfigDict]'
    docstring: 'Configures the proactivity of the model. This allows the model to respond proactively to

      the input and to ignore irrelevant input.'
  omitted_inherited_members_from:
  - TypedDict
- rank: 2367
  id: google.genai.types.LiveClientToolResponse
  name: LiveClientToolResponse
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Client generated response to a `ToolCall` received from the server.


    Individual `FunctionResponse` objects are matched to the respective

    `FunctionCall` objects by the `id` field.


    Note that in the unary and server-streaming GenerateContent APIs function

    calling happens by exchanging the `Content` parts, while in the bidi

    GenerateContent APIs function calling happens over this dedicated set of

    messages.


    [Note: Inherited members from _common.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, function_responses: typing.Optional[list[google.genai.types.FunctionResponse]] = None):'
  properties:
  - signature: 'function_responses: typing.Optional[list[google.genai.types.FunctionResponse]]'
  omitted_inherited_members_from:
  - _common.BaseModel
- rank: 2368
  id: google.genai.types.LiveClientToolResponseDict
  name: LiveClientToolResponseDict
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Client generated response to a `ToolCall` received from the server.


    Individual `FunctionResponse` objects are matched to the respective

    `FunctionCall` objects by the `id` field.


    Note that in the unary and server-streaming GenerateContent APIs function

    calling happens by exchanging the `Content` parts, while in the bidi

    GenerateContent APIs function calling happens over this dedicated set of

    messages.


    [Note: Inherited members from TypedDict are omitted.]'
  properties:
  - signature: 'function_responses: typing.Optional[list[google.genai.types.FunctionResponseDict]]'
    docstring: The response to the function calls.
  omitted_inherited_members_from:
  - TypedDict
- rank: 2369
  id: google.genai.types.LiveConnectConfig
  name: LiveConnectConfig
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Session config for the API connection.


    [Note: Inherited members from _common.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, http_options: typing.Optional[google.genai.types.HttpOptions] = None, generation_config: typing.Optional[google.genai.types.GenerationConfig] = None, response_modalities: typing.Optional[list[google.genai.types.Modality]] = None, temperature: typing.Optional[float] = None, top_p: typing.Optional[float] = None, top_k: typing.Optional[float] = None, max_output_tokens: typing.Optional[int] = None, media_resolution: typing.Optional[google.genai.types.MediaResolution] = None, seed: typing.Optional[int] = None, speech_config: typing.Optional[google.genai.types.SpeechConfig] = None, thinking_config: typing.Optional[google.genai.types.ThinkingConfig] = None, enable_affective_dialog: typing.Optional[bool] = None, system_instruction: typing.Optional[google.genai.types.ContentUnion] = None, tools: typing.Optional[google.genai.types.ToolListUnion] = None, session_resumption: typing.Optional[google.genai.types.SessionResumptionConfig] = None, input_audio_transcription:
    typing.Optional[google.genai.types.AudioTranscriptionConfig] = None, output_audio_transcription: typing.Optional[google.genai.types.AudioTranscriptionConfig] = None, realtime_input_config: typing.Optional[google.genai.types.RealtimeInputConfig] = None, context_window_compression: typing.Optional[google.genai.types.ContextWindowCompressionConfig] = None, proactivity: typing.Optional[google.genai.types.ProactivityConfig] = None):'
  properties:
  - signature: 'http_options: typing.Optional[google.genai.types.HttpOptions]'
  - signature: 'generation_config: typing.Optional[google.genai.types.GenerationConfig]'
  - signature: 'response_modalities: typing.Optional[list[google.genai.types.Modality]]'
  - signature: 'temperature: typing.Optional[float]'
  - signature: 'top_p: typing.Optional[float]'
  - signature: 'top_k: typing.Optional[float]'
  - signature: 'max_output_tokens: typing.Optional[int]'
  - signature: 'media_resolution: typing.Optional[google.genai.types.MediaResolution]'
  - signature: 'seed: typing.Optional[int]'
  - signature: 'speech_config: typing.Optional[google.genai.types.SpeechConfig]'
  - signature: 'thinking_config: typing.Optional[google.genai.types.ThinkingConfig]'
  - signature: 'enable_affective_dialog: typing.Optional[bool]'
  - signature: 'system_instruction: typing.Optional[google.genai.types.ContentUnion]'
  - signature: 'tools: typing.Optional[google.genai.types.ToolListUnion]'
  - signature: 'session_resumption: typing.Optional[google.genai.types.SessionResumptionConfig]'
  - signature: 'input_audio_transcription: typing.Optional[google.genai.types.AudioTranscriptionConfig]'
  - signature: 'output_audio_transcription: typing.Optional[google.genai.types.AudioTranscriptionConfig]'
  - signature: 'realtime_input_config: typing.Optional[google.genai.types.RealtimeInputConfig]'
  - signature: 'context_window_compression: typing.Optional[google.genai.types.ContextWindowCompressionConfig]'
  - signature: 'proactivity: typing.Optional[google.genai.types.ProactivityConfig]'
  omitted_inherited_members_from:
  - _common.BaseModel
- rank: 2370
  id: google.genai.types.LiveConnectConfigDict
  name: LiveConnectConfigDict
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Session config for the API connection.


    [Note: Inherited members from TypedDict are omitted.]'
  properties:
  - signature: 'http_options: typing.Optional[google.genai.types.HttpOptionsDict]'
    docstring: Used to override HTTP request options.
  - signature: 'generation_config: typing.Optional[google.genai.types.GenerationConfigDict]'
    docstring: The generation configuration for the session.
  - signature: 'response_modalities: typing.Optional[list[google.genai.types.Modality]]'
    docstring: 'The requested modalities of the response. Represents the set of

      modalities that the model can return. Defaults to AUDIO if not specified.'
  - signature: 'temperature: typing.Optional[float]'
    docstring: 'Value that controls the degree of randomness in token selection.

      Lower temperatures are good for prompts that require a less open-ended or

      creative response, while higher temperatures can lead to more diverse or

      creative results.'
  - signature: 'top_p: typing.Optional[float]'
    docstring: 'Tokens are selected from the most to least probable until the sum

      of their probabilities equals this value. Use a lower value for less

      random responses and a higher value for more random responses.'
  - signature: 'top_k: typing.Optional[float]'
    docstring: 'For each token selection step, the ``top_k`` tokens with the

      highest probabilities are sampled. Then tokens are further filtered based

      on ``top_p`` with the final token selected using temperature sampling. Use

      a lower number for less random responses and a higher number for more

      random responses.'
  - signature: 'max_output_tokens: typing.Optional[int]'
    docstring: "Maximum number of tokens that can be generated in the response.\n      "
  - signature: 'media_resolution: typing.Optional[google.genai.types.MediaResolution]'
    docstring: "If specified, the media resolution specified will be used.\n      "
  - signature: 'seed: typing.Optional[int]'
    docstring: 'When ``seed`` is fixed to a specific number, the model makes a best

      effort to provide the same response for repeated requests. By default, a

      random number is used.'
  - signature: 'speech_config: typing.Optional[google.genai.types.SpeechConfigDict]'
    docstring: "The speech generation configuration.\n      "
  - signature: 'thinking_config: typing.Optional[google.genai.types.ThinkingConfigDict]'
    docstring: 'Config for thinking features.

      An error will be returned if this field is set for models that don''t

      support thinking.'
  - signature: 'enable_affective_dialog: typing.Optional[bool]'
    docstring: If enabled, the model will detect emotions and adapt its responses accordingly.
  - signature: 'system_instruction: typing.Optional[google.genai.types.ContentUnionDict]'
    docstring: 'The user provided system instructions for the model.

      Note: only text should be used in parts and content in each part will be

      in a separate paragraph.'
  - signature: 'tools: typing.Optional[google.genai.types.ToolListUnionDict]'
    docstring: 'A list of `Tools` the model may use to generate the next response.


      A `Tool` is a piece of code that enables the system to interact with

      external systems to perform an action, or set of actions, outside of

      knowledge and scope of the model.'
  - signature: 'session_resumption: typing.Optional[google.genai.types.SessionResumptionConfigDict]'
    docstring: 'Configures session resumption mechanism.


      If included the server will send SessionResumptionUpdate messages.'
  - signature: 'input_audio_transcription: typing.Optional[google.genai.types.AudioTranscriptionConfigDict]'
    docstring: "The transcription of the input aligns with the input audio language.\n      "
  - signature: 'output_audio_transcription: typing.Optional[google.genai.types.AudioTranscriptionConfigDict]'
    docstring: 'The transcription of the output aligns with the language code

      specified for the output audio.'
  - signature: 'realtime_input_config: typing.Optional[google.genai.types.RealtimeInputConfigDict]'
    docstring: Configures the realtime input behavior in BidiGenerateContent.
  - signature: 'context_window_compression: typing.Optional[google.genai.types.ContextWindowCompressionConfigDict]'
    docstring: 'Configures context window compression mechanism.


      If included, server will compress context window to fit into given length.'
  - signature: 'proactivity: typing.Optional[google.genai.types.ProactivityConfigDict]'
    docstring: 'Configures the proactivity of the model. This allows the model to respond proactively to

      the input and to ignore irrelevant input.'
  omitted_inherited_members_from:
  - TypedDict
- rank: 2371
  id: google.genai.types.LiveConnectConstraints
  name: LiveConnectConstraints
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Config for LiveConnectConstraints for Auth Token creation.


    [Note: Inherited members from _common.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, model: typing.Optional[str] = None, config: typing.Optional[google.genai.types.LiveConnectConfig] = None):'
  properties:
  - signature: 'model: typing.Optional[str]'
  - signature: 'config: typing.Optional[google.genai.types.LiveConnectConfig]'
  omitted_inherited_members_from:
  - _common.BaseModel
- rank: 2372
  id: google.genai.types.LiveConnectConstraintsDict
  name: LiveConnectConstraintsDict
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Config for LiveConnectConstraints for Auth Token creation.


    [Note: Inherited members from TypedDict are omitted.]'
  properties:
  - signature: 'model: typing.Optional[str]'
    docstring: 'ID of the model to configure in the ephemeral token for Live API.

      For a list of models, see `Gemini models

      <https://ai.google.dev/gemini-api/docs/models>`.'
  - signature: 'config: typing.Optional[google.genai.types.LiveConnectConfigDict]'
    docstring: Configuration specific to Live API connections created using this token.
  omitted_inherited_members_from:
  - TypedDict
- rank: 2373
  id: google.genai.types.LiveConnectParameters
  name: LiveConnectParameters
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Parameters for connecting to the live API.


    [Note: Inherited members from _common.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, model: typing.Optional[str] = None, config: typing.Optional[google.genai.types.LiveConnectConfig] = None):'
  properties:
  - signature: 'model: typing.Optional[str]'
  - signature: 'config: typing.Optional[google.genai.types.LiveConnectConfig]'
  omitted_inherited_members_from:
  - _common.BaseModel
- rank: 2374
  id: google.genai.types.LiveConnectParametersDict
  name: LiveConnectParametersDict
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Parameters for connecting to the live API.


    [Note: Inherited members from TypedDict are omitted.]'
  properties:
  - signature: 'model: typing.Optional[str]'
    docstring: 'ID of the model to use. For a list of models, see `Google models

      <https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models>`_.'
  - signature: 'config: typing.Optional[google.genai.types.LiveConnectConfigDict]'
    docstring: "Optional configuration parameters for the request.\n      "
  omitted_inherited_members_from:
  - TypedDict
- rank: 2375
  id: google.genai.types.LiveMusicClientContent
  name: LiveMusicClientContent
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'User input to start or steer the music.


    [Note: Inherited members from _common.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, weighted_prompts: typing.Optional[list[google.genai.types.WeightedPrompt]] = None):'
  properties:
  - signature: 'weighted_prompts: typing.Optional[list[google.genai.types.WeightedPrompt]]'
  omitted_inherited_members_from:
  - _common.BaseModel
- rank: 2376
  id: google.genai.types.LiveMusicClientContentDict
  name: LiveMusicClientContentDict
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'User input to start or steer the music.


    [Note: Inherited members from TypedDict are omitted.]'
  properties:
  - signature: 'weighted_prompts: typing.Optional[list[google.genai.types.WeightedPromptDict]]'
    docstring: Weighted prompts as the model input.
  omitted_inherited_members_from:
  - TypedDict
- rank: 2377
  id: google.genai.types.LiveMusicClientMessage
  name: LiveMusicClientMessage
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Messages sent by the client in the LiveMusicClientMessage call.


    [Note: Inherited members from _common.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, setup: typing.Optional[google.genai.types.LiveMusicClientSetup] = None, client_content: typing.Optional[google.genai.types.LiveMusicClientContent] = None, music_generation_config: typing.Optional[google.genai.types.LiveMusicGenerationConfig] = None, playback_control: typing.Optional[google.genai.types.LiveMusicPlaybackControl] = None):'
  properties:
  - signature: 'setup: typing.Optional[google.genai.types.LiveMusicClientSetup]'
  - signature: 'client_content: typing.Optional[google.genai.types.LiveMusicClientContent]'
  - signature: 'music_generation_config: typing.Optional[google.genai.types.LiveMusicGenerationConfig]'
  - signature: 'playback_control: typing.Optional[google.genai.types.LiveMusicPlaybackControl]'
  omitted_inherited_members_from:
  - _common.BaseModel
- rank: 2378
  id: google.genai.types.LiveMusicClientMessageDict
  name: LiveMusicClientMessageDict
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Messages sent by the client in the LiveMusicClientMessage call.


    [Note: Inherited members from TypedDict are omitted.]'
  properties:
  - signature: 'setup: typing.Optional[google.genai.types.LiveMusicClientSetupDict]'
    docstring: 'Message to be sent in the first (and only in the first) `LiveMusicClientMessage`.

      Clients should wait for a `LiveMusicSetupComplete` message before

      sending any additional messages.'
  - signature: 'client_content: typing.Optional[google.genai.types.LiveMusicClientContentDict]'
    docstring: User input to influence music generation.
  - signature: 'music_generation_config: typing.Optional[google.genai.types.LiveMusicGenerationConfigDict]'
    docstring: Configuration for music generation.
  - signature: 'playback_control: typing.Optional[google.genai.types.LiveMusicPlaybackControl]'
    docstring: Playback control signal for the music generation.
  omitted_inherited_members_from:
  - TypedDict
- rank: 2379
  id: google.genai.types.LiveMusicClientSetup
  name: LiveMusicClientSetup
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Message to be sent by the system when connecting to the API.


    [Note: Inherited members from _common.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, model: typing.Optional[str] = None):'
  properties:
  - signature: 'model: typing.Optional[str]'
  omitted_inherited_members_from:
  - _common.BaseModel
- rank: 2380
  id: google.genai.types.LiveMusicClientSetupDict
  name: LiveMusicClientSetupDict
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Message to be sent by the system when connecting to the API.


    [Note: Inherited members from TypedDict are omitted.]'
  properties:
  - signature: 'model: typing.Optional[str]'
    docstring: 'The model''s resource name. Format: `models/{model}`.'
  omitted_inherited_members_from:
  - TypedDict
- rank: 2381
  id: google.genai.types.LiveMusicConnectParameters
  name: LiveMusicConnectParameters
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Parameters for connecting to the live API.


    [Note: Inherited members from _common.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, model: typing.Optional[str] = None):'
  properties:
  - signature: 'model: typing.Optional[str]'
  omitted_inherited_members_from:
  - _common.BaseModel
- rank: 2382
  id: google.genai.types.LiveMusicConnectParametersDict
  name: LiveMusicConnectParametersDict
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Parameters for connecting to the live API.


    [Note: Inherited members from TypedDict are omitted.]'
  properties:
  - signature: 'model: typing.Optional[str]'
    docstring: The model's resource name.
  omitted_inherited_members_from:
  - TypedDict
- rank: 2383
  id: google.genai.types.LiveMusicFilteredPrompt
  name: LiveMusicFilteredPrompt
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'A prompt that was filtered with the reason.


    [Note: Inherited members from _common.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, text: typing.Optional[str] = None, filtered_reason: typing.Optional[str] = None):'
  properties:
  - signature: 'text: typing.Optional[str]'
  - signature: 'filtered_reason: typing.Optional[str]'
  omitted_inherited_members_from:
  - _common.BaseModel
- rank: 2384
  id: google.genai.types.LiveMusicFilteredPromptDict
  name: LiveMusicFilteredPromptDict
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'A prompt that was filtered with the reason.


    [Note: Inherited members from TypedDict are omitted.]'
  properties:
  - signature: 'text: typing.Optional[str]'
    docstring: The text prompt that was filtered.
  - signature: 'filtered_reason: typing.Optional[str]'
    docstring: The reason the prompt was filtered.
  omitted_inherited_members_from:
  - TypedDict
- rank: 2385
  id: google.genai.types.LiveMusicGenerationConfig
  name: LiveMusicGenerationConfig
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Configuration for music generation.


    [Note: Inherited members from _common.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, temperature: typing.Optional[float] = None, top_k: typing.Optional[int] = None, seed: typing.Optional[int] = None, guidance: typing.Optional[float] = None, bpm: typing.Optional[int] = None, density: typing.Optional[float] = None, brightness: typing.Optional[float] = None, scale: typing.Optional[google.genai.types.Scale] = None, mute_bass: typing.Optional[bool] = None, mute_drums: typing.Optional[bool] = None, only_bass_and_drums: typing.Optional[bool] = None, music_generation_mode: typing.Optional[google.genai.types.MusicGenerationMode] = None):'
  properties:
  - signature: 'temperature: typing.Optional[float]'
  - signature: 'top_k: typing.Optional[int]'
  - signature: 'seed: typing.Optional[int]'
  - signature: 'guidance: typing.Optional[float]'
  - signature: 'bpm: typing.Optional[int]'
  - signature: 'density: typing.Optional[float]'
  - signature: 'brightness: typing.Optional[float]'
  - signature: 'scale: typing.Optional[google.genai.types.Scale]'
  - signature: 'mute_bass: typing.Optional[bool]'
  - signature: 'mute_drums: typing.Optional[bool]'
  - signature: 'only_bass_and_drums: typing.Optional[bool]'
  - signature: 'music_generation_mode: typing.Optional[google.genai.types.MusicGenerationMode]'
  omitted_inherited_members_from:
  - _common.BaseModel
- rank: 2386
  id: google.genai.types.LiveMusicGenerationConfigDict
  name: LiveMusicGenerationConfigDict
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Configuration for music generation.


    [Note: Inherited members from TypedDict are omitted.]'
  properties:
  - signature: 'temperature: typing.Optional[float]'
    docstring: 'Controls the variance in audio generation. Higher values produce

      higher variance. Range is [0.0, 3.0].'
  - signature: 'top_k: typing.Optional[int]'
    docstring: 'Controls how the model selects tokens for output. Samples the topK

      tokens with the highest probabilities. Range is [1, 1000].'
  - signature: 'seed: typing.Optional[int]'
    docstring: 'Seeds audio generation. If not set, the request uses a randomly

      generated seed.'
  - signature: 'guidance: typing.Optional[float]'
    docstring: 'Controls how closely the model follows prompts.

      Higher guidance follows more closely, but will make transitions more

      abrupt. Range is [0.0, 6.0].'
  - signature: 'bpm: typing.Optional[int]'
    docstring: Beats per minute. Range is [60, 200].
  - signature: 'density: typing.Optional[float]'
    docstring: Density of sounds. Range is [0.0, 1.0].
  - signature: 'brightness: typing.Optional[float]'
    docstring: Brightness of the music. Range is [0.0, 1.0].
  - signature: 'scale: typing.Optional[google.genai.types.Scale]'
    docstring: Scale of the generated music.
  - signature: 'mute_bass: typing.Optional[bool]'
    docstring: Whether the audio output should contain bass.
  - signature: 'mute_drums: typing.Optional[bool]'
    docstring: Whether the audio output should contain drums.
  - signature: 'only_bass_and_drums: typing.Optional[bool]'
    docstring: Whether the audio output should contain only bass and drums.
  - signature: 'music_generation_mode: typing.Optional[google.genai.types.MusicGenerationMode]'
    docstring: The mode of music generation. Default mode is QUALITY.
  omitted_inherited_members_from:
  - TypedDict
- rank: 2387
  id: google.genai.types.LiveMusicPlaybackControl
  name: LiveMusicPlaybackControl
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'The playback control signal to apply to the music generation.


    [Note: Inherited members from _common.CaseInSensitiveEnum are omitted.]'
  properties:
  - signature: 'PLAYBACK_CONTROL_UNSPECIFIED: str'
    docstring: This value is unused.
  - signature: 'PLAY: str'
    docstring: Start generating the music.
  - signature: 'PAUSE: str'
    docstring: Hold the music generation. Use PLAY to resume from the current position.
  - signature: 'STOP: str'
    docstring: 'Stop the music generation and reset the context (prompts retained).

      Use PLAY to restart the music generation.'
  - signature: 'RESET_CONTEXT: str'
    docstring: 'Reset the context of the music generation without stopping it.

      Retains the current prompts and config.'
  omitted_inherited_members_from:
  - _common.CaseInSensitiveEnum
- rank: 2388
  id: google.genai.types.LiveMusicServerContent
  name: LiveMusicServerContent
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Server update generated by the model in response to client messages.


    Content is generated as quickly as possible, and not in real time.

    Clients may choose to buffer and play it out in real time.


    [Note: Inherited members from _common.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, audio_chunks: typing.Optional[list[google.genai.types.AudioChunk]] = None):'
  properties:
  - signature: 'audio_chunks: typing.Optional[list[google.genai.types.AudioChunk]]'
  omitted_inherited_members_from:
  - _common.BaseModel
- rank: 2389
  id: google.genai.types.LiveMusicServerContentDict
  name: LiveMusicServerContentDict
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Server update generated by the model in response to client messages.


    Content is generated as quickly as possible, and not in real time.

    Clients may choose to buffer and play it out in real time.


    [Note: Inherited members from TypedDict are omitted.]'
  properties:
  - signature: 'audio_chunks: typing.Optional[list[google.genai.types.AudioChunkDict]]'
    docstring: The audio chunks that the model has generated.
  omitted_inherited_members_from:
  - TypedDict
- rank: 2390
  id: google.genai.types.LiveMusicServerMessage
  name: LiveMusicServerMessage
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Response message for the LiveMusicClientMessage call.


    [Note: Inherited members from _common.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, setup_complete: typing.Optional[google.genai.types.LiveMusicServerSetupComplete] = None, server_content: typing.Optional[google.genai.types.LiveMusicServerContent] = None, filtered_prompt: typing.Optional[google.genai.types.LiveMusicFilteredPrompt] = None):'
  properties:
  - signature: 'setup_complete: typing.Optional[google.genai.types.LiveMusicServerSetupComplete]'
  - signature: 'server_content: typing.Optional[google.genai.types.LiveMusicServerContent]'
  - signature: 'filtered_prompt: typing.Optional[google.genai.types.LiveMusicFilteredPrompt]'
  omitted_inherited_members_from:
  - _common.BaseModel
- rank: 2391
  id: google.genai.types.LiveMusicServerMessageDict
  name: LiveMusicServerMessageDict
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Response message for the LiveMusicClientMessage call.


    [Note: Inherited members from TypedDict are omitted.]'
  properties:
  - signature: 'setup_complete: typing.Optional[google.genai.types.LiveMusicServerSetupCompleteDict]'
    docstring: 'Message sent in response to a `LiveMusicClientSetup` message from the client.

      Clients should wait for this message before sending any additional messages.'
  - signature: 'server_content: typing.Optional[google.genai.types.LiveMusicServerContentDict]'
    docstring: Content generated by the model in response to client messages.
  - signature: 'filtered_prompt: typing.Optional[google.genai.types.LiveMusicFilteredPromptDict]'
    docstring: A prompt that was filtered with the reason.
  omitted_inherited_members_from:
  - TypedDict
- rank: 2392
  id: google.genai.types.LiveMusicServerSetupComplete
  name: LiveMusicServerSetupComplete
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Sent in response to a `LiveMusicClientSetup` message from the client.


    [Note: Inherited members from _common.BaseModel are omitted.]'
  omitted_inherited_members_from:
  - _common.BaseModel
- rank: 2393
  id: google.genai.types.LiveMusicServerSetupCompleteDict
  name: LiveMusicServerSetupCompleteDict
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Sent in response to a `LiveMusicClientSetup` message from the client.


    [Note: Inherited members from TypedDict are omitted.]'
  omitted_inherited_members_from:
  - TypedDict
- rank: 2394
  id: google.genai.types.LiveMusicSetConfigParameters
  name: LiveMusicSetConfigParameters
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Parameters for setting config for the live music API.


    [Note: Inherited members from _common.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, music_generation_config: typing.Optional[google.genai.types.LiveMusicGenerationConfig] = None):'
  properties:
  - signature: 'music_generation_config: typing.Optional[google.genai.types.LiveMusicGenerationConfig]'
  omitted_inherited_members_from:
  - _common.BaseModel
- rank: 2395
  id: google.genai.types.LiveMusicSetConfigParametersDict
  name: LiveMusicSetConfigParametersDict
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Parameters for setting config for the live music API.


    [Note: Inherited members from TypedDict are omitted.]'
  properties:
  - signature: 'music_generation_config: typing.Optional[google.genai.types.LiveMusicGenerationConfigDict]'
    docstring: Configuration for music generation.
  omitted_inherited_members_from:
  - TypedDict
- rank: 2396
  id: google.genai.types.LiveMusicSetWeightedPromptsParameters
  name: LiveMusicSetWeightedPromptsParameters
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Parameters for setting weighted prompts for the live music API.


    [Note: Inherited members from _common.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, weighted_prompts: typing.Optional[list[google.genai.types.WeightedPrompt]] = None):'
  properties:
  - signature: 'weighted_prompts: typing.Optional[list[google.genai.types.WeightedPrompt]]'
  omitted_inherited_members_from:
  - _common.BaseModel
- rank: 2397
  id: google.genai.types.LiveMusicSetWeightedPromptsParametersDict
  name: LiveMusicSetWeightedPromptsParametersDict
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Parameters for setting weighted prompts for the live music API.


    [Note: Inherited members from TypedDict are omitted.]'
  properties:
  - signature: 'weighted_prompts: typing.Optional[list[google.genai.types.WeightedPromptDict]]'
    docstring: A map of text prompts to weights to use for the generation request.
  omitted_inherited_members_from:
  - TypedDict
- rank: 2398
  id: google.genai.types.LiveMusicSourceMetadata
  name: LiveMusicSourceMetadata
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Prompts and config used for generating this audio chunk.


    [Note: Inherited members from _common.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, client_content: typing.Optional[google.genai.types.LiveMusicClientContent] = None, music_generation_config: typing.Optional[google.genai.types.LiveMusicGenerationConfig] = None):'
  properties:
  - signature: 'client_content: typing.Optional[google.genai.types.LiveMusicClientContent]'
  - signature: 'music_generation_config: typing.Optional[google.genai.types.LiveMusicGenerationConfig]'
  omitted_inherited_members_from:
  - _common.BaseModel
- rank: 2399
  id: google.genai.types.LiveMusicSourceMetadataDict
  name: LiveMusicSourceMetadataDict
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Prompts and config used for generating this audio chunk.


    [Note: Inherited members from TypedDict are omitted.]'
  properties:
  - signature: 'client_content: typing.Optional[google.genai.types.LiveMusicClientContentDict]'
    docstring: Weighted prompts for generating this audio chunk.
  - signature: 'music_generation_config: typing.Optional[google.genai.types.LiveMusicGenerationConfigDict]'
    docstring: Music generation config for generating this audio chunk.
  omitted_inherited_members_from:
  - TypedDict
- rank: 2400
  id: google.genai.types.LiveSendRealtimeInputParameters
  name: LiveSendRealtimeInputParameters
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Parameters for sending realtime input to the live API.


    [Note: Inherited members from _common.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, media: typing.Optional[BlobImageUnion] = None, audio: typing.Optional[google.genai.types.Blob] = None, audio_stream_end: typing.Optional[bool] = None, video: typing.Optional[BlobImageUnion] = None, text: typing.Optional[str] = None, activity_start: typing.Optional[google.genai.types.ActivityStart] = None, activity_end: typing.Optional[google.genai.types.ActivityEnd] = None):'
  properties:
  - signature: 'media: typing.Optional[BlobImageUnion]'
  - signature: 'audio: typing.Optional[google.genai.types.Blob]'
  - signature: 'audio_stream_end: typing.Optional[bool]'
  - signature: 'video: typing.Optional[BlobImageUnion]'
  - signature: 'text: typing.Optional[str]'
  - signature: 'activity_start: typing.Optional[google.genai.types.ActivityStart]'
  - signature: 'activity_end: typing.Optional[google.genai.types.ActivityEnd]'
  omitted_inherited_members_from:
  - _common.BaseModel
- rank: 2401
  id: google.genai.types.LiveSendRealtimeInputParametersDict
  name: LiveSendRealtimeInputParametersDict
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Parameters for sending realtime input to the live API.


    [Note: Inherited members from TypedDict are omitted.]'
  properties:
  - signature: 'media: typing.Optional[BlobImageUnionDict]'
    docstring: Realtime input to send to the session.
  - signature: 'audio: typing.Optional[google.genai.types.BlobDict]'
    docstring: The realtime audio input stream.
  - signature: 'audio_stream_end: typing.Optional[bool]'
    docstring: 'Indicates that the audio stream has ended, e.g. because the microphone was

      turned off.


      This should only be sent when automatic activity detection is enabled

      (which is the default).


      The client can reopen the stream by sending an audio message.'
  - signature: 'video: typing.Optional[BlobImageUnionDict]'
    docstring: The realtime video input stream.
  - signature: 'text: typing.Optional[str]'
    docstring: The realtime text input stream.
  - signature: 'activity_start: typing.Optional[google.genai.types.ActivityStartDict]'
    docstring: Marks the start of user activity.
  - signature: 'activity_end: typing.Optional[google.genai.types.ActivityEndDict]'
    docstring: Marks the end of user activity.
  omitted_inherited_members_from:
  - TypedDict
- rank: 2402
  id: google.genai.types.LiveServerContent
  name: LiveServerContent
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Incremental server update generated by the model in response to client messages.


    Content is generated as quickly as possible, and not in real time. Clients

    may choose to buffer and play it out in real time.


    [Note: Inherited members from _common.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, model_turn: typing.Optional[google.genai.types.Content] = None, turn_complete: typing.Optional[bool] = None, interrupted: typing.Optional[bool] = None, grounding_metadata: typing.Optional[google.genai.types.GroundingMetadata] = None, generation_complete: typing.Optional[bool] = None, input_transcription: typing.Optional[google.genai.types.Transcription] = None, output_transcription: typing.Optional[google.genai.types.Transcription] = None, url_context_metadata: typing.Optional[google.genai.types.UrlContextMetadata] = None, turn_complete_reason: typing.Optional[google.genai.types.TurnCompleteReason] = None, waiting_for_input: typing.Optional[bool] = None):'
  properties:
  - signature: 'model_turn: typing.Optional[google.genai.types.Content]'
  - signature: 'turn_complete: typing.Optional[bool]'
  - signature: 'interrupted: typing.Optional[bool]'
  - signature: 'grounding_metadata: typing.Optional[google.genai.types.GroundingMetadata]'
  - signature: 'generation_complete: typing.Optional[bool]'
  - signature: 'input_transcription: typing.Optional[google.genai.types.Transcription]'
  - signature: 'output_transcription: typing.Optional[google.genai.types.Transcription]'
  - signature: 'url_context_metadata: typing.Optional[google.genai.types.UrlContextMetadata]'
  - signature: 'turn_complete_reason: typing.Optional[google.genai.types.TurnCompleteReason]'
  - signature: 'waiting_for_input: typing.Optional[bool]'
  omitted_inherited_members_from:
  - _common.BaseModel
- rank: 2403
  id: google.genai.types.LiveServerContentDict
  name: LiveServerContentDict
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Incremental server update generated by the model in response to client messages.


    Content is generated as quickly as possible, and not in real time. Clients

    may choose to buffer and play it out in real time.


    [Note: Inherited members from TypedDict are omitted.]'
  properties:
  - signature: 'model_turn: typing.Optional[google.genai.types.ContentDict]'
    docstring: The content that the model has generated as part of the current conversation with the user.
  - signature: 'turn_complete: typing.Optional[bool]'
    docstring: If true, indicates that the model is done generating. Generation will only start in response to additional client messages. Can be set alongside `content`, indicating that the `content` is the last in the turn.
  - signature: 'interrupted: typing.Optional[bool]'
    docstring: If true, indicates that a client message has interrupted current model generation. If the client is playing out the content in realtime, this is a good signal to stop and empty the current queue.
  - signature: 'grounding_metadata: typing.Optional[google.genai.types.GroundingMetadataDict]'
    docstring: Metadata returned to client when grounding is enabled.
  - signature: 'generation_complete: typing.Optional[bool]'
    docstring: 'If true, indicates that the model is done generating. When model is

      interrupted while generating there will be no generation_complete message

      in interrupted turn, it will go through interrupted > turn_complete.

      When model assumes realtime playback there will be delay between

      generation_complete and turn_complete that is caused by model

      waiting for playback to finish. If true, indicates that the model

      has finished generating all content. This is a signal to the client

      that it can stop sending messages.'
  - signature: 'input_transcription: typing.Optional[google.genai.types.TranscriptionDict]'
    docstring: "Input transcription. The transcription is independent to the model\nturn which means it doesn\u2019t imply any ordering between transcription and\nmodel turn."
  - signature: 'output_transcription: typing.Optional[google.genai.types.TranscriptionDict]'
    docstring: "Output transcription. The transcription is independent to the model\nturn which means it doesn\u2019t imply any ordering between transcription and\nmodel turn."
  - signature: 'url_context_metadata: typing.Optional[google.genai.types.UrlContextMetadataDict]'
    docstring: Metadata related to url context retrieval tool.
  - signature: 'turn_complete_reason: typing.Optional[google.genai.types.TurnCompleteReason]'
    docstring: Reason for the turn is complete.
  - signature: 'waiting_for_input: typing.Optional[bool]'
    docstring: 'If true, indicates that the model is not generating content because

      it is waiting for more input from the user, e.g. because it expects the

      user to continue talking.'
  omitted_inherited_members_from:
  - TypedDict
- rank: 2404
  id: google.genai.types.LiveServerGoAway
  name: LiveServerGoAway
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Server will not be able to service client soon.


    [Note: Inherited members from _common.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, time_left: typing.Optional[str] = None):'
  properties:
  - signature: 'time_left: typing.Optional[str]'
  omitted_inherited_members_from:
  - _common.BaseModel
- rank: 2405
  id: google.genai.types.LiveServerGoAwayDict
  name: LiveServerGoAwayDict
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Server will not be able to service client soon.


    [Note: Inherited members from TypedDict are omitted.]'
  properties:
  - signature: 'time_left: typing.Optional[str]'
    docstring: The remaining time before the connection will be terminated as ABORTED. The minimal time returned here is specified differently together with the rate limits for a given model.
  omitted_inherited_members_from:
  - TypedDict
- rank: 2406
  id: google.genai.types.LiveServerMessage
  name: LiveServerMessage
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Response message for API call.


    [Note: Inherited members from _common.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, setup_complete: typing.Optional[google.genai.types.LiveServerSetupComplete] = None, server_content: typing.Optional[google.genai.types.LiveServerContent] = None, tool_call: typing.Optional[google.genai.types.LiveServerToolCall] = None, tool_call_cancellation: typing.Optional[google.genai.types.LiveServerToolCallCancellation] = None, usage_metadata: typing.Optional[google.genai.types.UsageMetadata] = None, go_away: typing.Optional[google.genai.types.LiveServerGoAway] = None, session_resumption_update: typing.Optional[google.genai.types.LiveServerSessionResumptionUpdate] = None):'
  methods:
  - signature: 'def text(self) -> typing.Optional[str]:'
    docstring: 'Returns the concatenation of all text parts in the response.


      If there are non-text parts in the response, only the concatenated text

      result from text parts will be returned.'
  - signature: 'def data(self) -> typing.Optional[bytes]:'
    docstring: 'Returns the concatenation of all inline data parts in the response.


      If there are non-data parts in the response, only the concatenated data

      result from the data parts will be returned.'
  properties:
  - signature: 'setup_complete: typing.Optional[google.genai.types.LiveServerSetupComplete]'
  - signature: 'server_content: typing.Optional[google.genai.types.LiveServerContent]'
  - signature: 'tool_call: typing.Optional[google.genai.types.LiveServerToolCall]'
  - signature: 'tool_call_cancellation: typing.Optional[google.genai.types.LiveServerToolCallCancellation]'
  - signature: 'usage_metadata: typing.Optional[google.genai.types.UsageMetadata]'
  - signature: 'go_away: typing.Optional[google.genai.types.LiveServerGoAway]'
  - signature: 'session_resumption_update: typing.Optional[google.genai.types.LiveServerSessionResumptionUpdate]'
  omitted_inherited_members_from:
  - _common.BaseModel
- rank: 2407
  id: google.genai.types.LiveServerMessage.data
  name: data
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: 'Returns the concatenation of all inline data parts in the response.


    If there are non-data parts in the response, only the concatenated data

    result from the data parts will be returned.'
  signature: 'def data(self) -> typing.Optional[bytes]:'
- rank: 2408
  id: google.genai.types.LiveServerMessage.text
  name: text
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: 'Returns the concatenation of all text parts in the response.


    If there are non-text parts in the response, only the concatenated text

    result from text parts will be returned.'
  signature: 'def text(self) -> typing.Optional[str]:'
- rank: 2409
  id: google.genai.types.LiveServerMessageDict
  name: LiveServerMessageDict
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Response message for API call.


    [Note: Inherited members from TypedDict are omitted.]'
  properties:
  - signature: 'setup_complete: typing.Optional[google.genai.types.LiveServerSetupCompleteDict]'
    docstring: Sent in response to a `LiveClientSetup` message from the client.
  - signature: 'server_content: typing.Optional[google.genai.types.LiveServerContentDict]'
    docstring: Content generated by the model in response to client messages.
  - signature: 'tool_call: typing.Optional[google.genai.types.LiveServerToolCallDict]'
    docstring: Request for the client to execute the `function_calls` and return the responses with the matching `id`s.
  - signature: 'tool_call_cancellation: typing.Optional[google.genai.types.LiveServerToolCallCancellationDict]'
    docstring: Notification for the client that a previously issued `ToolCallMessage` with the specified `id`s should have been not executed and should be cancelled.
  - signature: 'usage_metadata: typing.Optional[google.genai.types.UsageMetadataDict]'
    docstring: Usage metadata about model response(s).
  - signature: 'go_away: typing.Optional[google.genai.types.LiveServerGoAwayDict]'
    docstring: Server will disconnect soon.
  - signature: 'session_resumption_update: typing.Optional[google.genai.types.LiveServerSessionResumptionUpdateDict]'
    docstring: Update of the session resumption state.
  omitted_inherited_members_from:
  - TypedDict
- rank: 2410
  id: google.genai.types.LiveServerSessionResumptionUpdate
  name: LiveServerSessionResumptionUpdate
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Update of the session resumption state.


    Only sent if `session_resumption` was set in the connection config.


    [Note: Inherited members from _common.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, new_handle: typing.Optional[str] = None, resumable: typing.Optional[bool] = None, last_consumed_client_message_index: typing.Optional[int] = None):'
  properties:
  - signature: 'new_handle: typing.Optional[str]'
  - signature: 'resumable: typing.Optional[bool]'
  - signature: 'last_consumed_client_message_index: typing.Optional[int]'
  omitted_inherited_members_from:
  - _common.BaseModel
- rank: 2411
  id: google.genai.types.LiveServerSessionResumptionUpdateDict
  name: LiveServerSessionResumptionUpdateDict
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Update of the session resumption state.


    Only sent if `session_resumption` was set in the connection config.


    [Note: Inherited members from TypedDict are omitted.]'
  properties:
  - signature: 'new_handle: typing.Optional[str]'
    docstring: New handle that represents state that can be resumed. Empty if `resumable`=false.
  - signature: 'resumable: typing.Optional[bool]'
    docstring: True if session can be resumed at this point. It might be not possible to resume session at some points. In that case we send update empty new_handle and resumable=false. Example of such case could be model executing function calls or just generating. Resuming session (using previous session token) in such state will result in some data loss.
  - signature: 'last_consumed_client_message_index: typing.Optional[int]'
    docstring: 'Index of last message sent by client that is included in state represented by this SessionResumptionToken. Only sent when `SessionResumptionConfig.transparent` is set.


      Presence of this index allows users to transparently reconnect and avoid issue of losing some part of realtime audio input/video. If client wishes to temporarily disconnect (for example as result of receiving GoAway) they can do it without losing state by buffering messages sent since last `SessionResmumptionTokenUpdate`. This field will enable them to limit buffering (avoid keeping all requests in RAM).


      Note: This should not be used for when resuming a session at some time later -- in those cases partial audio and video frames arelikely not needed.'
  omitted_inherited_members_from:
  - TypedDict
- rank: 2412
  id: google.genai.types.LiveServerSetupComplete
  name: LiveServerSetupComplete
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Sent in response to a `LiveGenerateContentSetup` message from the client.


    [Note: Inherited members from _common.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, session_id: typing.Optional[str] = None):'
  properties:
  - signature: 'session_id: typing.Optional[str]'
  omitted_inherited_members_from:
  - _common.BaseModel
- rank: 2413
  id: google.genai.types.LiveServerSetupCompleteDict
  name: LiveServerSetupCompleteDict
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Sent in response to a `LiveGenerateContentSetup` message from the client.


    [Note: Inherited members from TypedDict are omitted.]'
  properties:
  - signature: 'session_id: typing.Optional[str]'
    docstring: The session id of the live session.
  omitted_inherited_members_from:
  - TypedDict
- rank: 2414
  id: google.genai.types.LiveServerToolCall
  name: LiveServerToolCall
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Request for the client to execute the `function_calls` and return the responses with the matching `id`s.


    [Note: Inherited members from _common.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, function_calls: typing.Optional[list[google.genai.types.FunctionCall]] = None):'
  properties:
  - signature: 'function_calls: typing.Optional[list[google.genai.types.FunctionCall]]'
  omitted_inherited_members_from:
  - _common.BaseModel
- rank: 2415
  id: google.genai.types.LiveServerToolCallCancellation
  name: LiveServerToolCallCancellation
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Notification for the client that a previously issued `ToolCallMessage` with the specified `id`s should have been not executed and should be cancelled.


    If there were side-effects to those tool calls, clients may attempt to undo

    the tool calls. This message occurs only in cases where the clients interrupt

    server turns.


    [Note: Inherited members from _common.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, ids: typing.Optional[list[str]] = None):'
  properties:
  - signature: 'ids: typing.Optional[list[str]]'
  omitted_inherited_members_from:
  - _common.BaseModel
- rank: 2416
  id: google.genai.types.LiveServerToolCallCancellationDict
  name: LiveServerToolCallCancellationDict
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Notification for the client that a previously issued `ToolCallMessage` with the specified `id`s should have been not executed and should be cancelled.


    If there were side-effects to those tool calls, clients may attempt to undo

    the tool calls. This message occurs only in cases where the clients interrupt

    server turns.


    [Note: Inherited members from TypedDict are omitted.]'
  properties:
  - signature: 'ids: typing.Optional[list[str]]'
    docstring: The ids of the tool calls to be cancelled.
  omitted_inherited_members_from:
  - TypedDict
- rank: 2417
  id: google.genai.types.LiveServerToolCallDict
  name: LiveServerToolCallDict
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Request for the client to execute the `function_calls` and return the responses with the matching `id`s.


    [Note: Inherited members from TypedDict are omitted.]'
  properties:
  - signature: 'function_calls: typing.Optional[list[google.genai.types.FunctionCallDict]]'
    docstring: The function call to be executed.
  omitted_inherited_members_from:
  - TypedDict
- rank: 2418
  id: google.genai.types.LogprobsResult
  name: LogprobsResult
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Logprobs Result


    [Note: Inherited members from _common.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, chosen_candidates: typing.Optional[list[google.genai.types.LogprobsResultCandidate]] = None, top_candidates: typing.Optional[list[google.genai.types.LogprobsResultTopCandidates]] = None):'
  properties:
  - signature: 'chosen_candidates: typing.Optional[list[google.genai.types.LogprobsResultCandidate]]'
  - signature: 'top_candidates: typing.Optional[list[google.genai.types.LogprobsResultTopCandidates]]'
  omitted_inherited_members_from:
  - _common.BaseModel
- rank: 2419
  id: google.genai.types.LogprobsResultCandidate
  name: LogprobsResultCandidate
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Candidate for the logprobs token and score.


    [Note: Inherited members from _common.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, log_probability: typing.Optional[float] = None, token: typing.Optional[str] = None, token_id: typing.Optional[int] = None):'
  properties:
  - signature: 'log_probability: typing.Optional[float]'
  - signature: 'token: typing.Optional[str]'
  - signature: 'token_id: typing.Optional[int]'
  omitted_inherited_members_from:
  - _common.BaseModel
- rank: 2420
  id: google.genai.types.LogprobsResultCandidateDict
  name: LogprobsResultCandidateDict
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Candidate for the logprobs token and score.


    [Note: Inherited members from TypedDict are omitted.]'
  properties:
  - signature: 'log_probability: typing.Optional[float]'
    docstring: The candidate's log probability.
  - signature: 'token: typing.Optional[str]'
    docstring: The candidate's token string value.
  - signature: 'token_id: typing.Optional[int]'
    docstring: The candidate's token id value.
  omitted_inherited_members_from:
  - TypedDict
- rank: 2421
  id: google.genai.types.LogprobsResultDict
  name: LogprobsResultDict
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Logprobs Result


    [Note: Inherited members from TypedDict are omitted.]'
  properties:
  - signature: 'chosen_candidates: typing.Optional[list[google.genai.types.LogprobsResultCandidateDict]]'
    docstring: Length = total number of decoding steps. The chosen candidates may or may not be in top_candidates.
  - signature: 'top_candidates: typing.Optional[list[google.genai.types.LogprobsResultTopCandidatesDict]]'
    docstring: Length = total number of decoding steps.
  omitted_inherited_members_from:
  - TypedDict
- rank: 2422
  id: google.genai.types.LogprobsResultTopCandidates
  name: LogprobsResultTopCandidates
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Candidates with top log probabilities at each decoding step.


    [Note: Inherited members from _common.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, candidates: typing.Optional[list[google.genai.types.LogprobsResultCandidate]] = None):'
  properties:
  - signature: 'candidates: typing.Optional[list[google.genai.types.LogprobsResultCandidate]]'
  omitted_inherited_members_from:
  - _common.BaseModel
- rank: 2423
  id: google.genai.types.LogprobsResultTopCandidatesDict
  name: LogprobsResultTopCandidatesDict
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Candidates with top log probabilities at each decoding step.


    [Note: Inherited members from TypedDict are omitted.]'
  properties:
  - signature: 'candidates: typing.Optional[list[google.genai.types.LogprobsResultCandidateDict]]'
    docstring: Sorted by log probability in descending order.
  omitted_inherited_members_from:
  - TypedDict
- rank: 2424
  id: google.genai.types.MaskReferenceConfig
  name: MaskReferenceConfig
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Configuration for a Mask reference image.


    [Note: Inherited members from _common.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, mask_mode: typing.Optional[google.genai.types.MaskReferenceMode] = None, segmentation_classes: typing.Optional[list[int]] = None, mask_dilation: typing.Optional[float] = None):'
  properties:
  - signature: 'mask_mode: typing.Optional[google.genai.types.MaskReferenceMode]'
  - signature: 'segmentation_classes: typing.Optional[list[int]]'
  - signature: 'mask_dilation: typing.Optional[float]'
  omitted_inherited_members_from:
  - _common.BaseModel
- rank: 2425
  id: google.genai.types.MaskReferenceConfigDict
  name: MaskReferenceConfigDict
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Configuration for a Mask reference image.


    [Note: Inherited members from TypedDict are omitted.]'
  properties:
  - signature: 'mask_mode: typing.Optional[google.genai.types.MaskReferenceMode]'
    docstring: 'Prompts the model to generate a mask instead of you needing to

      provide one (unless MASK_MODE_USER_PROVIDED is used).'
  - signature: 'segmentation_classes: typing.Optional[list[int]]'
    docstring: 'A list of up to 5 class ids to use for semantic segmentation.

      Automatically creates an image mask based on specific objects.'
  - signature: 'mask_dilation: typing.Optional[float]'
    docstring: 'Dilation percentage of the mask provided.

      Float between 0 and 1.'
  omitted_inherited_members_from:
  - TypedDict
- rank: 2426
  id: google.genai.types.MaskReferenceImage
  name: MaskReferenceImage
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'A mask reference image.


    This encapsulates either a mask image provided by the user and configs for

    the user provided mask, or only config parameters for the model to generate

    a mask.


    A mask image is an image whose non-zero values indicate where to edit the base

    image. If the user provides a mask image, the mask must be in the same

    dimensions as the raw image.


    [Note: Inherited members from _common.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, reference_image: typing.Optional[google.genai.types.Image] = None, reference_id: typing.Optional[int] = None, reference_type: typing.Optional[str] = None, config: typing.Optional[google.genai.types.MaskReferenceConfig] = None, mask_image_config: typing.Optional[google.genai.types.MaskReferenceConfig] = None):'
  properties:
  - signature: 'reference_image: typing.Optional[google.genai.types.Image]'
  - signature: 'reference_id: typing.Optional[int]'
  - signature: 'reference_type: typing.Optional[str]'
  - signature: 'config: typing.Optional[google.genai.types.MaskReferenceConfig]'
    docstring: Re-map config to mask_reference_config to send to API.
  - signature: 'mask_image_config: typing.Optional[google.genai.types.MaskReferenceConfig]'
  omitted_inherited_members_from:
  - _common.BaseModel
- rank: 2427
  id: google.genai.types.MaskReferenceImageDict
  name: MaskReferenceImageDict
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'A mask reference image.


    This encapsulates either a mask image provided by the user and configs for

    the user provided mask, or only config parameters for the model to generate

    a mask.


    A mask image is an image whose non-zero values indicate where to edit the base

    image. If the user provides a mask image, the mask must be in the same

    dimensions as the raw image.


    [Note: Inherited members from TypedDict are omitted.]'
  properties:
  - signature: 'reference_image: typing.Optional[google.genai.types.ImageDict]'
    docstring: The reference image for the editing operation.
  - signature: 'reference_id: typing.Optional[int]'
    docstring: The id of the reference image.
  - signature: 'reference_type: typing.Optional[str]'
    docstring: The type of the reference image. Only set by the SDK.
  - signature: 'config: typing.Optional[google.genai.types.MaskReferenceConfigDict]'
    docstring: Configuration for the mask reference image.
  omitted_inherited_members_from:
  - TypedDict
- rank: 2428
  id: google.genai.types.MaskReferenceMode
  name: MaskReferenceMode
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Enum representing the mask mode of a mask reference image.


    [Note: Inherited members from _common.CaseInSensitiveEnum are omitted.]'
  properties:
  - signature: 'MASK_MODE_DEFAULT: str'
  - signature: 'MASK_MODE_USER_PROVIDED: str'
  - signature: 'MASK_MODE_BACKGROUND: str'
  - signature: 'MASK_MODE_FOREGROUND: str'
  - signature: 'MASK_MODE_SEMANTIC: str'
  omitted_inherited_members_from:
  - _common.CaseInSensitiveEnum
- rank: 2429
  id: google.genai.types.MediaModality
  name: MediaModality
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Server content modalities.


    [Note: Inherited members from _common.CaseInSensitiveEnum are omitted.]'
  properties:
  - signature: 'MODALITY_UNSPECIFIED: str'
    docstring: The modality is unspecified.
  - signature: 'TEXT: str'
    docstring: Plain text.
  - signature: 'IMAGE: str'
    docstring: Images.
  - signature: 'VIDEO: str'
    docstring: Video.
  - signature: 'AUDIO: str'
    docstring: Audio.
  - signature: 'DOCUMENT: str'
    docstring: Document, e.g. PDF.
  omitted_inherited_members_from:
  - _common.CaseInSensitiveEnum
- rank: 2430
  id: google.genai.types.MediaResolution
  name: MediaResolution
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'The media resolution to use.


    [Note: Inherited members from _common.CaseInSensitiveEnum are omitted.]'
  properties:
  - signature: 'MEDIA_RESOLUTION_UNSPECIFIED: str'
    docstring: Media resolution has not been set
  - signature: 'MEDIA_RESOLUTION_LOW: str'
    docstring: Media resolution set to low (64 tokens).
  - signature: 'MEDIA_RESOLUTION_MEDIUM: str'
    docstring: Media resolution set to medium (256 tokens).
  - signature: 'MEDIA_RESOLUTION_HIGH: str'
    docstring: Media resolution set to high (zoomed reframing with 256 tokens).
  omitted_inherited_members_from:
  - _common.CaseInSensitiveEnum
- rank: 2431
  id: google.genai.types.Metric
  name: Metric
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'The metric used for evaluation.


    [Note: Inherited members from _common.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, name: typing.Optional[str] = None, custom_function: typing.Optional[typing.Callable[Ellipsis, typing.Any]] = None, prompt_template: typing.Optional[str] = None, judge_model_system_instruction: typing.Optional[str] = None, return_raw_output: typing.Optional[bool] = None, parse_and_reduce_fn: typing.Optional[typing.Callable[Ellipsis, typing.Any]] = None, aggregate_summary_fn: typing.Optional[typing.Callable[Ellipsis, typing.Any]] = None):'
  methods:
  - signature: 'def validate_name(self) -> google.genai.types.Metric:'
  - signature: 'def to_yaml_file(self, file_path: str, version: typing.Optional[str]) -> None:'
    docstring: "Dumps the metric object to a YAML file.\n\nArgs:\n    file_path: The path to the YAML file.\n    version: Optional version string to include in the YAML output.\n\nRaises:\n    ImportError: If the pyyaml library is not installed."
  properties:
  - signature: 'name: typing.Optional[str]'
  - signature: 'custom_function: typing.Optional[typing.Callable[Ellipsis, typing.Any]]'
  - signature: 'prompt_template: typing.Optional[str]'
  - signature: 'judge_model_system_instruction: typing.Optional[str]'
  - signature: 'return_raw_output: typing.Optional[bool]'
  - signature: 'parse_and_reduce_fn: typing.Optional[typing.Callable[Ellipsis, typing.Any]]'
  - signature: 'aggregate_summary_fn: typing.Optional[typing.Callable[Ellipsis, typing.Any]]'
  - signature: 'model_config: pydantic.ConfigDict'
  omitted_inherited_members_from:
  - _common.BaseModel
- rank: 2432
  id: google.genai.types.Metric.to_yaml_file
  name: to_yaml_file
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Dumps the metric object to a YAML file.\n\nArgs:\n    file_path: The path to the YAML file.\n    version: Optional version string to include in the YAML output.\n\nRaises:\n    ImportError: If the pyyaml library is not installed."
  signature: 'def to_yaml_file(self, file_path: str, version: typing.Optional[str]) -> None:'
- rank: 2433
  id: google.genai.types.Metric.validate_name
  name: validate_name
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def validate_name(self) -> google.genai.types.Metric:'
- rank: 2434
  id: google.genai.types.MetricDict
  name: MetricDict
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'The metric used for evaluation.


    [Note: Inherited members from TypedDict are omitted.]'
  properties:
  - signature: 'name: typing.Optional[str]'
    docstring: The name of the metric.
  - signature: 'custom_function: typing.Optional[typing.Callable[Ellipsis, typing.Any]]'
    docstring: The custom function that defines the end-to-end logic for metric computation.
  - signature: 'prompt_template: typing.Optional[str]'
    docstring: The prompt template for the metric.
  - signature: 'judge_model_system_instruction: typing.Optional[str]'
    docstring: The system instruction for the judge model.
  - signature: 'return_raw_output: typing.Optional[bool]'
    docstring: Whether to return the raw output from the judge model.
  - signature: 'parse_and_reduce_fn: typing.Optional[typing.Callable[Ellipsis, typing.Any]]'
    docstring: The parse and reduce function for the judge model.
  - signature: 'aggregate_summary_fn: typing.Optional[typing.Callable[Ellipsis, typing.Any]]'
    docstring: The aggregate summary function for the judge model.
  omitted_inherited_members_from:
  - TypedDict
- rank: 2435
  id: google.genai.types.Modality
  name: Modality
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Server content modalities.


    [Note: Inherited members from _common.CaseInSensitiveEnum are omitted.]'
  properties:
  - signature: 'MODALITY_UNSPECIFIED: str'
    docstring: The modality is unspecified.
  - signature: 'TEXT: str'
    docstring: Indicates the model should return text
  - signature: 'IMAGE: str'
    docstring: Indicates the model should return images.
  - signature: 'AUDIO: str'
    docstring: Indicates the model should return audio.
  omitted_inherited_members_from:
  - _common.CaseInSensitiveEnum
- rank: 2436
  id: google.genai.types.ModalityTokenCount
  name: ModalityTokenCount
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Represents token counting info for a single modality.


    [Note: Inherited members from _common.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, modality: typing.Optional[google.genai.types.MediaModality] = None, token_count: typing.Optional[int] = None):'
  properties:
  - signature: 'modality: typing.Optional[google.genai.types.MediaModality]'
  - signature: 'token_count: typing.Optional[int]'
  omitted_inherited_members_from:
  - _common.BaseModel
- rank: 2437
  id: google.genai.types.ModalityTokenCountDict
  name: ModalityTokenCountDict
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Represents token counting info for a single modality.


    [Note: Inherited members from TypedDict are omitted.]'
  properties:
  - signature: 'modality: typing.Optional[google.genai.types.MediaModality]'
    docstring: The modality associated with this token count.
  - signature: 'token_count: typing.Optional[int]'
    docstring: Number of tokens.
  omitted_inherited_members_from:
  - TypedDict
- rank: 2438
  id: google.genai.types.Mode
  name: Mode
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'The mode of the predictor to be used in dynamic retrieval.


    [Note: Inherited members from _common.CaseInSensitiveEnum are omitted.]'
  properties:
  - signature: 'MODE_UNSPECIFIED: str'
    docstring: Always trigger retrieval.
  - signature: 'MODE_DYNAMIC: str'
    docstring: Run retrieval only when system decides it is necessary.
  omitted_inherited_members_from:
  - _common.CaseInSensitiveEnum
- rank: 2439
  id: google.genai.types.Model
  name: Model
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'A trained machine learning model.


    [Note: Inherited members from _common.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, name: typing.Optional[str] = None, display_name: typing.Optional[str] = None, description: typing.Optional[str] = None, version: typing.Optional[str] = None, endpoints: typing.Optional[list[google.genai.types.Endpoint]] = None, labels: typing.Optional[dict[str, str]] = None, tuned_model_info: typing.Optional[google.genai.types.TunedModelInfo] = None, input_token_limit: typing.Optional[int] = None, output_token_limit: typing.Optional[int] = None, supported_actions: typing.Optional[list[str]] = None, default_checkpoint_id: typing.Optional[str] = None, checkpoints: typing.Optional[list[google.genai.types.Checkpoint]] = None, temperature: typing.Optional[float] = None, max_temperature: typing.Optional[float] = None, top_p: typing.Optional[float] = None, top_k: typing.Optional[int] = None, thinking: typing.Optional[bool] = None):'
  properties:
  - signature: 'name: typing.Optional[str]'
  - signature: 'display_name: typing.Optional[str]'
  - signature: 'description: typing.Optional[str]'
  - signature: 'version: typing.Optional[str]'
  - signature: 'endpoints: typing.Optional[list[google.genai.types.Endpoint]]'
  - signature: 'labels: typing.Optional[dict[str, str]]'
  - signature: 'tuned_model_info: typing.Optional[google.genai.types.TunedModelInfo]'
  - signature: 'input_token_limit: typing.Optional[int]'
  - signature: 'output_token_limit: typing.Optional[int]'
  - signature: 'supported_actions: typing.Optional[list[str]]'
  - signature: 'default_checkpoint_id: typing.Optional[str]'
  - signature: 'checkpoints: typing.Optional[list[google.genai.types.Checkpoint]]'
  - signature: 'temperature: typing.Optional[float]'
  - signature: 'max_temperature: typing.Optional[float]'
  - signature: 'top_p: typing.Optional[float]'
  - signature: 'top_k: typing.Optional[int]'
  - signature: 'thinking: typing.Optional[bool]'
  omitted_inherited_members_from:
  - _common.BaseModel
- rank: 2440
  id: google.genai.types.ModelContent
  name: ModelContent
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: "ModelContent facilitates the creation of a Content object with a model role.\n\nExample usages:\n\n- Create a model Content object with a string:\n  model_content = ModelContent(\"Why is the sky blue?\")\n- Create a model Content object with a file data Part object:\n  model_content = ModelContent(Part.from_uri(file_uril=\"gs://bucket/file.txt\",\n  mime_type=\"text/plain\"))\n- Create a model Content object with byte data Part object:\n  model_content = ModelContent(Part.from_bytes(data=b\"Hello, World!\",\n  mime_type=\"text/plain\"))\n\n  You can create a model Content object using other classmethods in the Part\n  class as well.\n  You can also create a model Content using a list of Part objects or strings.\n\n[Note: Inherited members from _common.BaseModel are omitted.]"
  constructor_signature: 'def __init__(self, parts: typing.Union[PartUnionDict, list[PartUnionDict], list[google.genai.types.Part]]):'
  properties:
  - signature: 'role: typing.Literal[model]'
  - signature: 'parts: list[google.genai.types.Part]'
  inherited_properties:
    Content:
    - signature: 'parts: typing.Optional[list[google.genai.types.Part]]'
    - signature: 'role: typing.Optional[str]'
  omitted_inherited_members_from:
  - _common.BaseModel
- rank: 2441
  id: google.genai.types.ModelContent.__init__
  name: __init__
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def __init__(self, parts: typing.Union[PartUnionDict, list[PartUnionDict], list[google.genai.types.Part]]):'
- rank: 2442
  id: google.genai.types.ModelDict
  name: ModelDict
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'A trained machine learning model.


    [Note: Inherited members from TypedDict are omitted.]'
  properties:
  - signature: 'name: typing.Optional[str]'
    docstring: Resource name of the model.
  - signature: 'display_name: typing.Optional[str]'
    docstring: Display name of the model.
  - signature: 'description: typing.Optional[str]'
    docstring: Description of the model.
  - signature: 'version: typing.Optional[str]'
    docstring: 'Version ID of the model. A new version is committed when a new

      model version is uploaded or trained under an existing model ID. The

      version ID is an auto-incrementing decimal number in string

      representation.'
  - signature: 'endpoints: typing.Optional[list[google.genai.types.EndpointDict]]'
    docstring: 'List of deployed models created from this base model. Note that a

      model could have been deployed to endpoints in different locations.'
  - signature: 'labels: typing.Optional[dict[str, str]]'
    docstring: Labels with user-defined metadata to organize your models.
  - signature: 'tuned_model_info: typing.Optional[google.genai.types.TunedModelInfoDict]'
    docstring: Information about the tuned model from the base model.
  - signature: 'input_token_limit: typing.Optional[int]'
    docstring: The maximum number of input tokens that the model can handle.
  - signature: 'output_token_limit: typing.Optional[int]'
    docstring: The maximum number of output tokens that the model can generate.
  - signature: 'supported_actions: typing.Optional[list[str]]'
    docstring: List of actions that are supported by the model.
  - signature: 'default_checkpoint_id: typing.Optional[str]'
    docstring: "The default checkpoint id of a model version.\n      "
  - signature: 'checkpoints: typing.Optional[list[google.genai.types.CheckpointDict]]'
    docstring: The checkpoints of the model.
  - signature: 'temperature: typing.Optional[float]'
    docstring: 'Temperature value used for sampling set when the dataset was saved.

      This value is used to tune the degree of randomness.'
  - signature: 'max_temperature: typing.Optional[float]'
    docstring: 'The maximum temperature value used for sampling set when the

      dataset was saved. This value is used to tune the degree of randomness.'
  - signature: 'top_p: typing.Optional[float]'
    docstring: 'Optional. Specifies the nucleus sampling threshold. The model

      considers only the smallest set of tokens whose cumulative probability is

      at least `top_p`. This helps generate more diverse and less repetitive

      responses. For example, a `top_p` of 0.9 means the model considers tokens

      until the cumulative probability of the tokens to select from reaches 0.9.

      It''s recommended to adjust either temperature or `top_p`, but not both.'
  - signature: 'top_k: typing.Optional[int]'
    docstring: 'Optional. Specifies the top-k sampling threshold. The model

      considers only the top k most probable tokens for the next token. This can

      be useful for generating more coherent and less random text. For example,

      a `top_k` of 40 means the model will choose the next word from the 40 most

      likely words.'
  - signature: 'thinking: typing.Optional[bool]'
    docstring: 'Whether the model supports thinking features. If true, thoughts are

      returned only if the model supports thought and thoughts are available.'
  omitted_inherited_members_from:
  - TypedDict
- rank: 2443
  id: google.genai.types.ModelSelectionConfig
  name: ModelSelectionConfig
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Config for model selection.


    [Note: Inherited members from _common.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, feature_selection_preference: typing.Optional[google.genai.types.FeatureSelectionPreference] = None):'
  properties:
  - signature: 'feature_selection_preference: typing.Optional[google.genai.types.FeatureSelectionPreference]'
  omitted_inherited_members_from:
  - _common.BaseModel
- rank: 2444
  id: google.genai.types.ModelSelectionConfigDict
  name: ModelSelectionConfigDict
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Config for model selection.


    [Note: Inherited members from TypedDict are omitted.]'
  properties:
  - signature: 'feature_selection_preference: typing.Optional[google.genai.types.FeatureSelectionPreference]'
    docstring: Options for feature selection preference.
  omitted_inherited_members_from:
  - TypedDict
- rank: 2445
  id: google.genai.types.MultiSpeakerVoiceConfig
  name: MultiSpeakerVoiceConfig
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'The configuration for the multi-speaker setup.


    This data type is not supported in Vertex AI.


    [Note: Inherited members from _common.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, speaker_voice_configs: typing.Optional[list[google.genai.types.SpeakerVoiceConfig]] = None):'
  properties:
  - signature: 'speaker_voice_configs: typing.Optional[list[google.genai.types.SpeakerVoiceConfig]]'
  omitted_inherited_members_from:
  - _common.BaseModel
- rank: 2446
  id: google.genai.types.MultiSpeakerVoiceConfigDict
  name: MultiSpeakerVoiceConfigDict
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'The configuration for the multi-speaker setup.


    This data type is not supported in Vertex AI.


    [Note: Inherited members from TypedDict are omitted.]'
  properties:
  - signature: 'speaker_voice_configs: typing.Optional[list[google.genai.types.SpeakerVoiceConfigDict]]'
    docstring: Required. All the enabled speaker voices.
  omitted_inherited_members_from:
  - TypedDict
- rank: 2447
  id: google.genai.types.MusicGenerationMode
  name: MusicGenerationMode
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'The mode of music generation.


    [Note: Inherited members from _common.CaseInSensitiveEnum are omitted.]'
  properties:
  - signature: 'MUSIC_GENERATION_MODE_UNSPECIFIED: str'
    docstring: Rely on the server default generation mode.
  - signature: 'QUALITY: str'
    docstring: 'Steer text prompts to regions of latent space with higher quality

      music.'
  - signature: 'DIVERSITY: str'
    docstring: 'Steer text prompts to regions of latent space with a larger

      diversity of music.'
  - signature: 'VOCALIZATION: str'
    docstring: 'Steer text prompts to regions of latent space more likely to

      generate music with vocals.'
  omitted_inherited_members_from:
  - _common.CaseInSensitiveEnum
- rank: 2448
  id: google.genai.types.Operation
  name: Operation
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'A long-running operation.


    [Note: Inherited members from ABC are omitted.]'
  methods:
  - signature: 'def from_api_response(cls, api_response: typing.Any, is_vertex_ai: bool) -> typing_extensions.Self:'
    docstring: Creates an Operation from an API response.
  properties:
  - signature: 'name: typing.Optional[str]'
  - signature: 'metadata: typing.Optional[dict[str, typing.Any]]'
  - signature: 'done: typing.Optional[bool]'
  - signature: 'error: typing.Optional[dict[str, typing.Any]]'
  omitted_inherited_members_from:
  - ABC
- rank: 2449
  id: google.genai.types.Operation.from_api_response
  name: from_api_response
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: Creates an Operation from an API response.
  signature: 'def from_api_response(cls, api_response: typing.Any, is_vertex_ai: bool) -> typing_extensions.Self:'
- rank: 2450
  id: google.genai.types.Outcome
  name: Outcome
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Outcome of the code execution.


    [Note: Inherited members from _common.CaseInSensitiveEnum are omitted.]'
  properties:
  - signature: 'OUTCOME_UNSPECIFIED: str'
    docstring: Unspecified status. This value should not be used.
  - signature: 'OUTCOME_OK: str'
    docstring: Code execution completed successfully.
  - signature: 'OUTCOME_FAILED: str'
    docstring: Code execution finished but with a failure. `stderr` should contain the reason.
  - signature: 'OUTCOME_DEADLINE_EXCEEDED: str'
    docstring: Code execution ran for too long, and was cancelled. There may or may not be a partial output present.
  omitted_inherited_members_from:
  - _common.CaseInSensitiveEnum
- rank: 2451
  id: google.genai.types.OutputConfig
  name: OutputConfig
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Config for evaluation output.


    [Note: Inherited members from _common.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, gcs_destination: typing.Optional[google.genai.types.GcsDestination] = None):'
  properties:
  - signature: 'gcs_destination: typing.Optional[google.genai.types.GcsDestination]'
  omitted_inherited_members_from:
  - _common.BaseModel
- rank: 2452
  id: google.genai.types.OutputConfigDict
  name: OutputConfigDict
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Config for evaluation output.


    [Note: Inherited members from TypedDict are omitted.]'
  properties:
  - signature: 'gcs_destination: typing.Optional[google.genai.types.GcsDestinationDict]'
    docstring: Cloud storage destination for evaluation output.
  omitted_inherited_members_from:
  - TypedDict
- rank: 2453
  id: google.genai.types.PairwiseMetricSpec
  name: PairwiseMetricSpec
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Spec for pairwise metric.


    [Note: Inherited members from _common.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, metric_prompt_template: typing.Optional[str] = None, baseline_response_field_name: typing.Optional[str] = None, candidate_response_field_name: typing.Optional[str] = None, custom_output_format_config: typing.Optional[google.genai.types.CustomOutputFormatConfig] = None, system_instruction: typing.Optional[str] = None):'
  properties:
  - signature: 'metric_prompt_template: typing.Optional[str]'
  - signature: 'baseline_response_field_name: typing.Optional[str]'
  - signature: 'candidate_response_field_name: typing.Optional[str]'
  - signature: 'custom_output_format_config: typing.Optional[google.genai.types.CustomOutputFormatConfig]'
  - signature: 'system_instruction: typing.Optional[str]'
  omitted_inherited_members_from:
  - _common.BaseModel
- rank: 2454
  id: google.genai.types.PairwiseMetricSpecDict
  name: PairwiseMetricSpecDict
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Spec for pairwise metric.


    [Note: Inherited members from TypedDict are omitted.]'
  properties:
  - signature: 'metric_prompt_template: typing.Optional[str]'
    docstring: Required. Metric prompt template for pairwise metric.
  - signature: 'baseline_response_field_name: typing.Optional[str]'
    docstring: Optional. The field name of the baseline response.
  - signature: 'candidate_response_field_name: typing.Optional[str]'
    docstring: Optional. The field name of the candidate response.
  - signature: 'custom_output_format_config: typing.Optional[google.genai.types.CustomOutputFormatConfigDict]'
    docstring: Optional. CustomOutputFormatConfig allows customization of metric output. When this config is set, the default output is replaced with the raw output string. If a custom format is chosen, the `pairwise_choice` and `explanation` fields in the corresponding metric result will be empty.
  - signature: 'system_instruction: typing.Optional[str]'
    docstring: Optional. System instructions for pairwise metric.
  omitted_inherited_members_from:
  - TypedDict
- rank: 2455
  id: google.genai.types.Part
  name: Part
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'A datatype containing media content.


    Exactly one field within a Part should be set, representing the specific type

    of content being conveyed. Using multiple fields within the same `Part`

    instance is considered invalid.


    [Note: Inherited members from _common.BaseModel are omitted.]'
  constructor_signature: 'def __init__(*, video_metadata: typing.Optional[google.genai.types.VideoMetadata]=None, thought: typing.Optional[bool]=None, inline_data: typing.Optional[google.genai.types.Blob]=None, file_data: typing.Optional[google.genai.types.FileData]=None, thought_signature: typing.Optional[bytes]=None, function_call: typing.Optional[google.genai.types.FunctionCall]=None, code_execution_result: typing.Optional[google.genai.types.CodeExecutionResult]=None, executable_code: typing.Optional[google.genai.types.ExecutableCode]=None, function_response: typing.Optional[google.genai.types.FunctionResponse]=None, text: typing.Optional[str]=None):'
  methods:
  - signature: 'def as_image(self) -> typing.Optional[google.genai.types.Image]:'
    docstring: Returns the part as a PIL Image, or None if the part is not an image.
  - signature: 'def from_uri(cls, *, file_uri: str, mime_type: typing.Optional[str]=None, media_resolution: typing.Optional[typing.Union[google.genai.types.PartMediaResolutionOrDict, google.genai.types.PartMediaResolutionLevel, str]]=None) -> google.genai.types.Part:'
    docstring: "Creates a Part from a file uri.\n\nArgs:\n  file_uri (str): The uri of the file\n  mime_type (str): mime_type: The MIME type of the file. If not provided,\n    the MIME type will be automatically determined."
  - signature: 'def from_text(cls, *, text: str) -> google.genai.types.Part:'
  - signature: 'def from_bytes(cls, *, data: bytes, mime_type: str, media_resolution: typing.Optional[typing.Union[google.genai.types.PartMediaResolutionOrDict, google.genai.types.PartMediaResolutionLevel, str]]=None) -> google.genai.types.Part:'
  - signature: 'def from_function_call(cls, *, name: str, args: dict[str, typing.Any]) -> google.genai.types.Part:'
  - signature: 'def from_function_response(cls, *, name: str, response: dict[str, typing.Any], parts: typing.Optional[list[google.genai.types.FunctionResponsePart]]=None) -> google.genai.types.Part:'
  - signature: 'def from_executable_code(cls, *, code: str, language: google.genai.types.Language) -> google.genai.types.Part:'
  - signature: 'def from_code_execution_result(cls, *, outcome: google.genai.types.Outcome, output: str) -> google.genai.types.Part:'
  properties:
  - signature: 'media_resolution: typing.Optional[google.genai.types.PartMediaResolution]'
  - signature: 'code_execution_result: typing.Optional[google.genai.types.CodeExecutionResult]'
  - signature: 'executable_code: typing.Optional[google.genai.types.ExecutableCode]'
  - signature: 'file_data: typing.Optional[google.genai.types.FileData]'
  - signature: 'function_call: typing.Optional[google.genai.types.FunctionCall]'
  - signature: 'function_response: typing.Optional[google.genai.types.FunctionResponse]'
  - signature: 'inline_data: typing.Optional[google.genai.types.Blob]'
  - signature: 'text: typing.Optional[str]'
  - signature: 'thought: typing.Optional[bool]'
  - signature: 'thought_signature: typing.Optional[bytes]'
  - signature: 'video_metadata: typing.Optional[google.genai.types.VideoMetadata]'
  omitted_inherited_members_from:
  - _common.BaseModel
- rank: 2456
  id: google.genai.types.Part.__init__
  name: __init__
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def __init__(*, video_metadata: typing.Optional[google.genai.types.VideoMetadata]=None, thought: typing.Optional[bool]=None, inline_data: typing.Optional[google.genai.types.Blob]=None, file_data: typing.Optional[google.genai.types.FileData]=None, thought_signature: typing.Optional[bytes]=None, function_call: typing.Optional[google.genai.types.FunctionCall]=None, code_execution_result: typing.Optional[google.genai.types.CodeExecutionResult]=None, executable_code: typing.Optional[google.genai.types.ExecutableCode]=None, function_response: typing.Optional[google.genai.types.FunctionResponse]=None, text: typing.Optional[str]=None):'
- rank: 2457
  id: google.genai.types.Part.as_image
  name: as_image
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: Returns the part as a PIL Image, or None if the part is not an image.
  signature: 'def as_image(self) -> typing.Optional[google.genai.types.Image]:'
- rank: 2458
  id: google.genai.types.Part.from_bytes
  name: from_bytes
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def from_bytes(cls, *, data: bytes, mime_type: str, media_resolution: typing.Optional[typing.Union[google.genai.types.PartMediaResolutionOrDict, google.genai.types.PartMediaResolutionLevel, str]]=None) -> google.genai.types.Part:'
- rank: 2459
  id: google.genai.types.Part.from_code_execution_result
  name: from_code_execution_result
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def from_code_execution_result(cls, *, outcome: google.genai.types.Outcome, output: str) -> google.genai.types.Part:'
- rank: 2460
  id: google.genai.types.Part.from_function_response
  name: from_function_response
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def from_function_response(cls, *, name: str, response: dict[str, typing.Any], parts: typing.Optional[list[google.genai.types.FunctionResponsePart]]=None) -> google.genai.types.Part:'
- rank: 2461
  id: google.genai.types.Part.from_uri
  name: from_uri
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Creates a Part from a file uri.\n\nArgs:\n  file_uri (str): The uri of the file\n  mime_type (str): mime_type: The MIME type of the file. If not provided,\n    the MIME type will be automatically determined."
  signature: 'def from_uri(cls, *, file_uri: str, mime_type: typing.Optional[str]=None, media_resolution: typing.Optional[typing.Union[google.genai.types.PartMediaResolutionOrDict, google.genai.types.PartMediaResolutionLevel, str]]=None) -> google.genai.types.Part:'
- rank: 2462
  id: google.genai.types.PartDict
  name: PartDict
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'A datatype containing media content.


    Exactly one field within a Part should be set, representing the specific type

    of content being conveyed. Using multiple fields within the same `Part`

    instance is considered invalid.


    [Note: Inherited members from TypedDict are omitted.]'
  properties:
  - signature: 'media_resolution: typing.Optional[google.genai.types.PartMediaResolutionDict]'
    docstring: "Media resolution for the input media.\n    "
  - signature: 'code_execution_result: typing.Optional[google.genai.types.CodeExecutionResultDict]'
    docstring: Optional. Result of executing the [ExecutableCode].
  - signature: 'executable_code: typing.Optional[google.genai.types.ExecutableCodeDict]'
    docstring: Optional. Code generated by the model that is meant to be executed.
  - signature: 'file_data: typing.Optional[google.genai.types.FileDataDict]'
    docstring: Optional. URI based data.
  - signature: 'function_call: typing.Optional[google.genai.types.FunctionCallDict]'
    docstring: Optional. A predicted [FunctionCall] returned from the model that contains a string representing the [FunctionDeclaration.name] with the parameters and their values.
  - signature: 'function_response: typing.Optional[google.genai.types.FunctionResponseDict]'
    docstring: Optional. The result output of a [FunctionCall] that contains a string representing the [FunctionDeclaration.name] and a structured JSON object containing any output from the function call. It is used as context to the model.
  - signature: 'inline_data: typing.Optional[google.genai.types.BlobDict]'
    docstring: Optional. Inlined bytes data.
  - signature: 'text: typing.Optional[str]'
    docstring: Optional. Text part (can be code).
  - signature: 'thought: typing.Optional[bool]'
    docstring: Optional. Indicates if the part is thought from the model.
  - signature: 'thought_signature: typing.Optional[bytes]'
    docstring: Optional. An opaque signature for the thought so it can be reused in subsequent requests.
  - signature: 'video_metadata: typing.Optional[google.genai.types.VideoMetadataDict]'
    docstring: Optional. Video metadata. The metadata should only be specified while the video data is presented in inline_data or file_data.
  omitted_inherited_members_from:
  - TypedDict
- rank: 2463
  id: google.genai.types.PartMediaResolution
  name: PartMediaResolution
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Media resolution for the input media.


    [Note: Inherited members from _common.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, level: typing.Optional[google.genai.types.PartMediaResolutionLevel] = None, num_tokens: typing.Optional[int] = None):'
  properties:
  - signature: 'level: typing.Optional[google.genai.types.PartMediaResolutionLevel]'
  - signature: 'num_tokens: typing.Optional[int]'
  omitted_inherited_members_from:
  - _common.BaseModel
- rank: 2464
  id: google.genai.types.PartMediaResolutionDict
  name: PartMediaResolutionDict
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Media resolution for the input media.


    [Note: Inherited members from TypedDict are omitted.]'
  properties:
  - signature: 'level: typing.Optional[google.genai.types.PartMediaResolutionLevel]'
    docstring: "The tokenization quality used for given media.\n    "
  - signature: 'num_tokens: typing.Optional[int]'
    docstring: "Specifies the required sequence length for media tokenization.\n    "
  omitted_inherited_members_from:
  - TypedDict
- rank: 2465
  id: google.genai.types.PartMediaResolutionLevel
  name: PartMediaResolutionLevel
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'The tokenization quality used for given media.


    [Note: Inherited members from _common.CaseInSensitiveEnum are omitted.]'
  properties:
  - signature: 'MEDIA_RESOLUTION_UNSPECIFIED: str'
    docstring: Media resolution has not been set.
  - signature: 'MEDIA_RESOLUTION_LOW: str'
    docstring: Media resolution set to low.
  - signature: 'MEDIA_RESOLUTION_MEDIUM: str'
    docstring: Media resolution set to medium.
  - signature: 'MEDIA_RESOLUTION_HIGH: str'
    docstring: Media resolution set to high.
  omitted_inherited_members_from:
  - _common.CaseInSensitiveEnum
- rank: 2466
  id: google.genai.types.PartialArg
  name: PartialArg
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Partial argument value of the function call.


    This data type is not supported in Gemini API.


    [Note: Inherited members from _common.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, null_value: typing.Optional[typing.Literal[NULL_VALUE]] = None, number_value: typing.Optional[float] = None, string_value: typing.Optional[str] = None, bool_value: typing.Optional[bool] = None, json_path: typing.Optional[str] = None, will_continue: typing.Optional[bool] = None):'
  properties:
  - signature: 'null_value: typing.Optional[typing.Literal[NULL_VALUE]]'
  - signature: 'number_value: typing.Optional[float]'
  - signature: 'string_value: typing.Optional[str]'
  - signature: 'bool_value: typing.Optional[bool]'
  - signature: 'json_path: typing.Optional[str]'
  - signature: 'will_continue: typing.Optional[bool]'
  omitted_inherited_members_from:
  - _common.BaseModel
- rank: 2467
  id: google.genai.types.PartialArgDict
  name: PartialArgDict
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Partial argument value of the function call.


    This data type is not supported in Gemini API.


    [Note: Inherited members from TypedDict are omitted.]'
  properties:
  - signature: 'null_value: typing.Optional[typing.Literal[NULL_VALUE]]'
    docstring: Optional. Represents a null value.
  - signature: 'number_value: typing.Optional[float]'
    docstring: Optional. Represents a double value.
  - signature: 'string_value: typing.Optional[str]'
    docstring: Optional. Represents a string value.
  - signature: 'bool_value: typing.Optional[bool]'
    docstring: Optional. Represents a boolean value.
  - signature: 'json_path: typing.Optional[str]'
    docstring: Required. A JSON Path (RFC 9535) to the argument being streamed. https://datatracker.ietf.org/doc/html/rfc9535. e.g. "$.foo.bar[0].data".
  - signature: 'will_continue: typing.Optional[bool]'
    docstring: Optional. Whether this is not the last part of the same json_path. If true, another PartialArg message for the current json_path is expected to follow.
  omitted_inherited_members_from:
  - TypedDict
- rank: 2468
  id: google.genai.types.PartnerModelTuningSpec
  name: PartnerModelTuningSpec
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Tuning spec for Partner models.


    This data type is not supported in Gemini API.


    [Note: Inherited members from _common.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, hyper_parameters: typing.Optional[dict[str, typing.Any]] = None, training_dataset_uri: typing.Optional[str] = None, validation_dataset_uri: typing.Optional[str] = None):'
  properties:
  - signature: 'hyper_parameters: typing.Optional[dict[str, typing.Any]]'
  - signature: 'training_dataset_uri: typing.Optional[str]'
  - signature: 'validation_dataset_uri: typing.Optional[str]'
  omitted_inherited_members_from:
  - _common.BaseModel
- rank: 2469
  id: google.genai.types.PartnerModelTuningSpecDict
  name: PartnerModelTuningSpecDict
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Tuning spec for Partner models.


    This data type is not supported in Gemini API.


    [Note: Inherited members from TypedDict are omitted.]'
  properties:
  - signature: 'hyper_parameters: typing.Optional[dict[str, typing.Any]]'
    docstring: Hyperparameters for tuning. The accepted hyper_parameters and their valid range of values will differ depending on the base model.
  - signature: 'training_dataset_uri: typing.Optional[str]'
    docstring: Required. Cloud Storage path to file containing training dataset for tuning. The dataset must be formatted as a JSONL file.
  - signature: 'validation_dataset_uri: typing.Optional[str]'
    docstring: Optional. Cloud Storage path to file containing validation dataset for tuning. The dataset must be formatted as a JSONL file.
  omitted_inherited_members_from:
  - TypedDict
- rank: 2470
  id: google.genai.types.PersonGeneration
  name: PersonGeneration
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Enum that controls the generation of people.


    [Note: Inherited members from _common.CaseInSensitiveEnum are omitted.]'
  properties:
  - signature: 'DONT_ALLOW: str'
    docstring: Block generation of images of people.
  - signature: 'ALLOW_ADULT: str'
    docstring: Generate images of adults, but not children.
  - signature: 'ALLOW_ALL: str'
    docstring: Generate images that include adults and children.
  omitted_inherited_members_from:
  - _common.CaseInSensitiveEnum
- rank: 2471
  id: google.genai.types.PhishBlockThreshold
  name: PhishBlockThreshold
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Sites with confidence level chosen & above this value will be blocked from the search results.


    This enum is not supported in Gemini API.


    [Note: Inherited members from _common.CaseInSensitiveEnum are omitted.]'
  properties:
  - signature: 'PHISH_BLOCK_THRESHOLD_UNSPECIFIED: str'
    docstring: Defaults to unspecified.
  - signature: 'BLOCK_LOW_AND_ABOVE: str'
    docstring: Blocks Low and above confidence URL that is risky.
  - signature: 'BLOCK_MEDIUM_AND_ABOVE: str'
    docstring: Blocks Medium and above confidence URL that is risky.
  - signature: 'BLOCK_HIGH_AND_ABOVE: str'
    docstring: Blocks High and above confidence URL that is risky.
  - signature: 'BLOCK_HIGHER_AND_ABOVE: str'
    docstring: Blocks Higher and above confidence URL that is risky.
  - signature: 'BLOCK_VERY_HIGH_AND_ABOVE: str'
    docstring: Blocks Very high and above confidence URL that is risky.
  - signature: 'BLOCK_ONLY_EXTREMELY_HIGH: str'
    docstring: Blocks Extremely high confidence URL that is risky.
  omitted_inherited_members_from:
  - _common.CaseInSensitiveEnum
- rank: 2472
  id: google.genai.types.Placeholder
  name: Placeholder
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: '[Note: Inherited members from pydantic.BaseModel are omitted.]'
  omitted_inherited_members_from:
  - pydantic.BaseModel
- rank: 2473
  id: google.genai.types.Placeholder
  name: Placeholder
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: '[Note: Inherited members from pydantic.BaseModel are omitted.]'
  omitted_inherited_members_from:
  - pydantic.BaseModel
- rank: 2474
  id: google.genai.types.PointwiseMetricSpec
  name: PointwiseMetricSpec
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Spec for pointwise metric.


    [Note: Inherited members from _common.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, metric_prompt_template: typing.Optional[str] = None, custom_output_format_config: typing.Optional[google.genai.types.CustomOutputFormatConfig] = None, system_instruction: typing.Optional[str] = None):'
  properties:
  - signature: 'metric_prompt_template: typing.Optional[str]'
  - signature: 'custom_output_format_config: typing.Optional[google.genai.types.CustomOutputFormatConfig]'
  - signature: 'system_instruction: typing.Optional[str]'
  omitted_inherited_members_from:
  - _common.BaseModel
- rank: 2475
  id: google.genai.types.PointwiseMetricSpecDict
  name: PointwiseMetricSpecDict
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Spec for pointwise metric.


    [Note: Inherited members from TypedDict are omitted.]'
  properties:
  - signature: 'metric_prompt_template: typing.Optional[str]'
    docstring: Required. Metric prompt template for pointwise metric.
  - signature: 'custom_output_format_config: typing.Optional[google.genai.types.CustomOutputFormatConfigDict]'
    docstring: 'Optional. CustomOutputFormatConfig allows customization of metric output. By default, metrics return a score and explanation. When this config is set, the default output is replaced with either: - The raw output string. - A parsed output based on a user-defined schema. If a custom format is chosen, the `score` and `explanation` fields in the corresponding metric result will be empty.'
  - signature: 'system_instruction: typing.Optional[str]'
    docstring: Optional. System instructions for pointwise metric.
  omitted_inherited_members_from:
  - TypedDict
- rank: 2476
  id: google.genai.types.PreTunedModel
  name: PreTunedModel
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'A pre-tuned model for continuous tuning.


    This data type is not supported in Gemini API.


    [Note: Inherited members from _common.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, base_model: typing.Optional[str] = None, checkpoint_id: typing.Optional[str] = None, tuned_model_name: typing.Optional[str] = None):'
  properties:
  - signature: 'base_model: typing.Optional[str]'
  - signature: 'checkpoint_id: typing.Optional[str]'
  - signature: 'tuned_model_name: typing.Optional[str]'
  omitted_inherited_members_from:
  - _common.BaseModel
- rank: 2477
  id: google.genai.types.PreTunedModelDict
  name: PreTunedModelDict
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'A pre-tuned model for continuous tuning.


    This data type is not supported in Gemini API.


    [Note: Inherited members from TypedDict are omitted.]'
  properties:
  - signature: 'base_model: typing.Optional[str]'
    docstring: Output only. The name of the base model this PreTunedModel was tuned from.
  - signature: 'checkpoint_id: typing.Optional[str]'
    docstring: Optional. The source checkpoint id. If not specified, the default checkpoint will be used.
  - signature: 'tuned_model_name: typing.Optional[str]'
    docstring: 'The resource name of the Model. E.g., a model resource name with a specified version id or alias: `projects/{project}/locations/{location}/models/{model}@{version_id}` `projects/{project}/locations/{location}/models/{model}@{alias}` Or, omit the version id to use the default version: `projects/{project}/locations/{location}/models/{model}`'
  omitted_inherited_members_from:
  - TypedDict
- rank: 2478
  id: google.genai.types.PrebuiltVoiceConfig
  name: PrebuiltVoiceConfig
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'The configuration for the prebuilt speaker to use.


    [Note: Inherited members from _common.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, voice_name: typing.Optional[str] = None):'
  properties:
  - signature: 'voice_name: typing.Optional[str]'
  omitted_inherited_members_from:
  - _common.BaseModel
- rank: 2479
  id: google.genai.types.PrebuiltVoiceConfigDict
  name: PrebuiltVoiceConfigDict
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'The configuration for the prebuilt speaker to use.


    [Note: Inherited members from TypedDict are omitted.]'
  properties:
  - signature: 'voice_name: typing.Optional[str]'
    docstring: The name of the preset voice to use.
  omitted_inherited_members_from:
  - TypedDict
- rank: 2480
  id: google.genai.types.PreferenceOptimizationDataStats
  name: PreferenceOptimizationDataStats
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Statistics computed for datasets used for preference optimization.


    This data type is not supported in Gemini API.


    [Note: Inherited members from _common.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, score_variance_per_example_distribution: typing.Optional[google.genai.types.DatasetDistribution] = None, scores_distribution: typing.Optional[google.genai.types.DatasetDistribution] = None, total_billable_token_count: typing.Optional[int] = None, tuning_dataset_example_count: typing.Optional[int] = None, tuning_step_count: typing.Optional[int] = None, user_dataset_examples: typing.Optional[list[google.genai.types.GeminiPreferenceExample]] = None, user_input_token_distribution: typing.Optional[google.genai.types.DatasetDistribution] = None, user_output_token_distribution: typing.Optional[google.genai.types.DatasetDistribution] = None):'
  properties:
  - signature: 'score_variance_per_example_distribution: typing.Optional[google.genai.types.DatasetDistribution]'
  - signature: 'scores_distribution: typing.Optional[google.genai.types.DatasetDistribution]'
  - signature: 'total_billable_token_count: typing.Optional[int]'
  - signature: 'tuning_dataset_example_count: typing.Optional[int]'
  - signature: 'tuning_step_count: typing.Optional[int]'
  - signature: 'user_dataset_examples: typing.Optional[list[google.genai.types.GeminiPreferenceExample]]'
  - signature: 'user_input_token_distribution: typing.Optional[google.genai.types.DatasetDistribution]'
  - signature: 'user_output_token_distribution: typing.Optional[google.genai.types.DatasetDistribution]'
  omitted_inherited_members_from:
  - _common.BaseModel
- rank: 2481
  id: google.genai.types.PreferenceOptimizationDataStatsDict
  name: PreferenceOptimizationDataStatsDict
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Statistics computed for datasets used for preference optimization.


    This data type is not supported in Gemini API.


    [Note: Inherited members from TypedDict are omitted.]'
  properties:
  - signature: 'score_variance_per_example_distribution: typing.Optional[google.genai.types.DatasetDistributionDict]'
    docstring: Output only. Dataset distributions for scores variance per example.
  - signature: 'scores_distribution: typing.Optional[google.genai.types.DatasetDistributionDict]'
    docstring: Output only. Dataset distributions for scores.
  - signature: 'total_billable_token_count: typing.Optional[int]'
    docstring: Output only. Number of billable tokens in the tuning dataset.
  - signature: 'tuning_dataset_example_count: typing.Optional[int]'
    docstring: Output only. Number of examples in the tuning dataset.
  - signature: 'tuning_step_count: typing.Optional[int]'
    docstring: Output only. Number of tuning steps for this Tuning Job.
  - signature: 'user_dataset_examples: typing.Optional[list[google.genai.types.GeminiPreferenceExampleDict]]'
    docstring: Output only. Sample user examples in the training dataset.
  - signature: 'user_input_token_distribution: typing.Optional[google.genai.types.DatasetDistributionDict]'
    docstring: Output only. Dataset distributions for the user input tokens.
  - signature: 'user_output_token_distribution: typing.Optional[google.genai.types.DatasetDistributionDict]'
    docstring: Output only. Dataset distributions for the user output tokens.
  omitted_inherited_members_from:
  - TypedDict
- rank: 2482
  id: google.genai.types.PreferenceOptimizationHyperParameters
  name: PreferenceOptimizationHyperParameters
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Hyperparameters for Preference Optimization.


    This data type is not supported in Gemini API.


    [Note: Inherited members from _common.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, adapter_size: typing.Optional[google.genai.types.AdapterSize] = None, beta: typing.Optional[float] = None, epoch_count: typing.Optional[int] = None, learning_rate_multiplier: typing.Optional[float] = None):'
  properties:
  - signature: 'adapter_size: typing.Optional[google.genai.types.AdapterSize]'
  - signature: 'beta: typing.Optional[float]'
  - signature: 'epoch_count: typing.Optional[int]'
  - signature: 'learning_rate_multiplier: typing.Optional[float]'
  omitted_inherited_members_from:
  - _common.BaseModel
- rank: 2483
  id: google.genai.types.PreferenceOptimizationHyperParametersDict
  name: PreferenceOptimizationHyperParametersDict
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Hyperparameters for Preference Optimization.


    This data type is not supported in Gemini API.


    [Note: Inherited members from TypedDict are omitted.]'
  properties:
  - signature: 'adapter_size: typing.Optional[google.genai.types.AdapterSize]'
    docstring: Optional. Adapter size for preference optimization.
  - signature: 'beta: typing.Optional[float]'
    docstring: Optional. Weight for KL Divergence regularization.
  - signature: 'epoch_count: typing.Optional[int]'
    docstring: Optional. Number of complete passes the model makes over the entire training dataset during training.
  - signature: 'learning_rate_multiplier: typing.Optional[float]'
    docstring: Optional. Multiplier for adjusting the default learning rate.
  omitted_inherited_members_from:
  - TypedDict
- rank: 2484
  id: google.genai.types.PreferenceOptimizationSpec
  name: PreferenceOptimizationSpec
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Preference optimization tuning spec for tuning.


    [Note: Inherited members from _common.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, export_last_checkpoint_only: typing.Optional[bool] = None, hyper_parameters: typing.Optional[google.genai.types.PreferenceOptimizationHyperParameters] = None, training_dataset_uri: typing.Optional[str] = None, validation_dataset_uri: typing.Optional[str] = None):'
  properties:
  - signature: 'export_last_checkpoint_only: typing.Optional[bool]'
  - signature: 'hyper_parameters: typing.Optional[google.genai.types.PreferenceOptimizationHyperParameters]'
  - signature: 'training_dataset_uri: typing.Optional[str]'
  - signature: 'validation_dataset_uri: typing.Optional[str]'
  omitted_inherited_members_from:
  - _common.BaseModel
- rank: 2485
  id: google.genai.types.PreferenceOptimizationSpecDict
  name: PreferenceOptimizationSpecDict
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Preference optimization tuning spec for tuning.


    [Note: Inherited members from TypedDict are omitted.]'
  properties:
  - signature: 'export_last_checkpoint_only: typing.Optional[bool]'
    docstring: Optional. If set to true, disable intermediate checkpoints for Preference Optimization and only the last checkpoint will be exported. Otherwise, enable intermediate checkpoints for Preference Optimization. Default is false.
  - signature: 'hyper_parameters: typing.Optional[google.genai.types.PreferenceOptimizationHyperParametersDict]'
    docstring: Optional. Hyperparameters for Preference Optimization.
  - signature: 'training_dataset_uri: typing.Optional[str]'
    docstring: Required. Cloud Storage path to file containing training dataset for preference optimization tuning. The dataset must be formatted as a JSONL file.
  - signature: 'validation_dataset_uri: typing.Optional[str]'
    docstring: Optional. Cloud Storage path to file containing validation dataset for preference optimization tuning. The dataset must be formatted as a JSONL file.
  omitted_inherited_members_from:
  - TypedDict
- rank: 2486
  id: google.genai.types.ProactivityConfig
  name: ProactivityConfig
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Config for proactivity features.


    [Note: Inherited members from _common.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, proactive_audio: typing.Optional[bool] = None):'
  properties:
  - signature: 'proactive_audio: typing.Optional[bool]'
  omitted_inherited_members_from:
  - _common.BaseModel
- rank: 2487
  id: google.genai.types.ProactivityConfigDict
  name: ProactivityConfigDict
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Config for proactivity features.


    [Note: Inherited members from TypedDict are omitted.]'
  properties:
  - signature: 'proactive_audio: typing.Optional[bool]'
    docstring: 'If enabled, the model can reject responding to the last prompt. For

      example, this allows the model to ignore out of context speech or to stay

      silent if the user did not make a request, yet.'
  omitted_inherited_members_from:
  - TypedDict
- rank: 2488
  id: google.genai.types.ProductImage
  name: ProductImage
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'An image of the product.


    [Note: Inherited members from _common.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, product_image: typing.Optional[google.genai.types.Image] = None):'
  properties:
  - signature: 'product_image: typing.Optional[google.genai.types.Image]'
  omitted_inherited_members_from:
  - _common.BaseModel
- rank: 2489
  id: google.genai.types.ProductImageDict
  name: ProductImageDict
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'An image of the product.


    [Note: Inherited members from TypedDict are omitted.]'
  properties:
  - signature: 'product_image: typing.Optional[google.genai.types.ImageDict]'
    docstring: An image of the product to be recontextualized.
  omitted_inherited_members_from:
  - TypedDict
- rank: 2490
  id: google.genai.types.ProjectOperation
  name: ProjectOperation
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'A project-level operation in Vertex.


    [Note: Inherited members from _common.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, name: typing.Optional[str] = None, metadata: typing.Optional[dict[str, typing.Any]] = None, done: typing.Optional[bool] = None, error: typing.Optional[dict[str, typing.Any]] = None):'
  properties:
  - signature: 'name: typing.Optional[str]'
  - signature: 'metadata: typing.Optional[dict[str, typing.Any]]'
  - signature: 'done: typing.Optional[bool]'
  - signature: 'error: typing.Optional[dict[str, typing.Any]]'
  omitted_inherited_members_from:
  - _common.BaseModel
- rank: 2491
  id: google.genai.types.ProjectOperationDict
  name: ProjectOperationDict
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'A project-level operation in Vertex.


    [Note: Inherited members from TypedDict are omitted.]'
  properties:
  - signature: 'name: typing.Optional[str]'
    docstring: The server-assigned name, which is only unique within the same service that originally returns it. If you use the default HTTP mapping, the `name` should be a resource name ending with `operations/{unique_id}`.
  - signature: 'metadata: typing.Optional[dict[str, typing.Any]]'
    docstring: Service-specific metadata associated with the operation. It typically contains progress information and common metadata such as create time. Some services might not provide such metadata.  Any method that returns a long-running operation should document the metadata type, if any.
  - signature: 'done: typing.Optional[bool]'
    docstring: If the value is `false`, it means the operation is still in progress. If `true`, the operation is completed, and either `error` or `response` is available.
  - signature: 'error: typing.Optional[dict[str, typing.Any]]'
    docstring: The error result of the operation in case of failure or cancellation.
  omitted_inherited_members_from:
  - TypedDict
- rank: 2492
  id: google.genai.types.RagChunk
  name: RagChunk
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'A RagChunk includes the content of a chunk of a RagFile, and associated metadata.


    This data type is not supported in Gemini API.


    [Note: Inherited members from _common.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, page_span: typing.Optional[google.genai.types.RagChunkPageSpan] = None, text: typing.Optional[str] = None):'
  properties:
  - signature: 'page_span: typing.Optional[google.genai.types.RagChunkPageSpan]'
  - signature: 'text: typing.Optional[str]'
  omitted_inherited_members_from:
  - _common.BaseModel
- rank: 2493
  id: google.genai.types.RagChunkDict
  name: RagChunkDict
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'A RagChunk includes the content of a chunk of a RagFile, and associated metadata.


    This data type is not supported in Gemini API.


    [Note: Inherited members from TypedDict are omitted.]'
  properties:
  - signature: 'page_span: typing.Optional[google.genai.types.RagChunkPageSpanDict]'
    docstring: If populated, represents where the chunk starts and ends in the document.
  - signature: 'text: typing.Optional[str]'
    docstring: The content of the chunk.
  omitted_inherited_members_from:
  - TypedDict
- rank: 2494
  id: google.genai.types.RagChunkPageSpan
  name: RagChunkPageSpan
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Represents where the chunk starts and ends in the document.


    This data type is not supported in Gemini API.


    [Note: Inherited members from _common.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, first_page: typing.Optional[int] = None, last_page: typing.Optional[int] = None):'
  properties:
  - signature: 'first_page: typing.Optional[int]'
  - signature: 'last_page: typing.Optional[int]'
  omitted_inherited_members_from:
  - _common.BaseModel
- rank: 2495
  id: google.genai.types.RagChunkPageSpanDict
  name: RagChunkPageSpanDict
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Represents where the chunk starts and ends in the document.


    This data type is not supported in Gemini API.


    [Note: Inherited members from TypedDict are omitted.]'
  properties:
  - signature: 'first_page: typing.Optional[int]'
    docstring: Page where chunk starts in the document. Inclusive. 1-indexed.
  - signature: 'last_page: typing.Optional[int]'
    docstring: Page where chunk ends in the document. Inclusive. 1-indexed.
  omitted_inherited_members_from:
  - TypedDict
- rank: 2496
  id: google.genai.types.RagRetrievalConfig
  name: RagRetrievalConfig
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Specifies the context retrieval config.


    This data type is not supported in Gemini API.


    [Note: Inherited members from _common.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, filter: typing.Optional[google.genai.types.RagRetrievalConfigFilter] = None, hybrid_search: typing.Optional[google.genai.types.RagRetrievalConfigHybridSearch] = None, ranking: typing.Optional[google.genai.types.RagRetrievalConfigRanking] = None, top_k: typing.Optional[int] = None):'
  properties:
  - signature: 'filter: typing.Optional[google.genai.types.RagRetrievalConfigFilter]'
  - signature: 'hybrid_search: typing.Optional[google.genai.types.RagRetrievalConfigHybridSearch]'
  - signature: 'ranking: typing.Optional[google.genai.types.RagRetrievalConfigRanking]'
  - signature: 'top_k: typing.Optional[int]'
  omitted_inherited_members_from:
  - _common.BaseModel
- rank: 2497
  id: google.genai.types.RagRetrievalConfigDict
  name: RagRetrievalConfigDict
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Specifies the context retrieval config.


    This data type is not supported in Gemini API.


    [Note: Inherited members from TypedDict are omitted.]'
  properties:
  - signature: 'filter: typing.Optional[google.genai.types.RagRetrievalConfigFilterDict]'
    docstring: Optional. Config for filters.
  - signature: 'hybrid_search: typing.Optional[google.genai.types.RagRetrievalConfigHybridSearchDict]'
    docstring: Optional. Config for Hybrid Search.
  - signature: 'ranking: typing.Optional[google.genai.types.RagRetrievalConfigRankingDict]'
    docstring: Optional. Config for ranking and reranking.
  - signature: 'top_k: typing.Optional[int]'
    docstring: Optional. The number of contexts to retrieve.
  omitted_inherited_members_from:
  - TypedDict
- rank: 2498
  id: google.genai.types.RagRetrievalConfigFilter
  name: RagRetrievalConfigFilter
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Config for filters. This data type is not supported in Gemini API.


    [Note: Inherited members from _common.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, metadata_filter: typing.Optional[str] = None, vector_distance_threshold: typing.Optional[float] = None, vector_similarity_threshold: typing.Optional[float] = None):'
  properties:
  - signature: 'metadata_filter: typing.Optional[str]'
  - signature: 'vector_distance_threshold: typing.Optional[float]'
  - signature: 'vector_similarity_threshold: typing.Optional[float]'
  omitted_inherited_members_from:
  - _common.BaseModel
- rank: 2499
  id: google.genai.types.RagRetrievalConfigFilterDict
  name: RagRetrievalConfigFilterDict
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Config for filters. This data type is not supported in Gemini API.


    [Note: Inherited members from TypedDict are omitted.]'
  properties:
  - signature: 'metadata_filter: typing.Optional[str]'
    docstring: Optional. String for metadata filtering.
  - signature: 'vector_distance_threshold: typing.Optional[float]'
    docstring: Optional. Only returns contexts with vector distance smaller than the threshold.
  - signature: 'vector_similarity_threshold: typing.Optional[float]'
    docstring: Optional. Only returns contexts with vector similarity larger than the threshold.
  omitted_inherited_members_from:
  - TypedDict
- rank: 2500
  id: google.genai.types.RagRetrievalConfigHybridSearch
  name: RagRetrievalConfigHybridSearch
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Config for Hybrid Search. This data type is not supported in Gemini API.


    [Note: Inherited members from _common.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, alpha: typing.Optional[float] = None):'
  properties:
  - signature: 'alpha: typing.Optional[float]'
  omitted_inherited_members_from:
  - _common.BaseModel
- rank: 2501
  id: google.genai.types.RagRetrievalConfigHybridSearchDict
  name: RagRetrievalConfigHybridSearchDict
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Config for Hybrid Search. This data type is not supported in Gemini API.


    [Note: Inherited members from TypedDict are omitted.]'
  properties:
  - signature: 'alpha: typing.Optional[float]'
    docstring: Optional. Alpha value controls the weight between dense and sparse vector search results. The range is [0, 1], while 0 means sparse vector search only and 1 means dense vector search only. The default value is 0.5 which balances sparse and dense vector search equally.
  omitted_inherited_members_from:
  - TypedDict
- rank: 2502
  id: google.genai.types.RagRetrievalConfigRanking
  name: RagRetrievalConfigRanking
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Config for ranking and reranking.


    This data type is not supported in Gemini API.


    [Note: Inherited members from _common.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, llm_ranker: typing.Optional[google.genai.types.RagRetrievalConfigRankingLlmRanker] = None, rank_service: typing.Optional[google.genai.types.RagRetrievalConfigRankingRankService] = None):'
  properties:
  - signature: 'llm_ranker: typing.Optional[google.genai.types.RagRetrievalConfigRankingLlmRanker]'
  - signature: 'rank_service: typing.Optional[google.genai.types.RagRetrievalConfigRankingRankService]'
  omitted_inherited_members_from:
  - _common.BaseModel
- rank: 2503
  id: google.genai.types.RagRetrievalConfigRankingDict
  name: RagRetrievalConfigRankingDict
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Config for ranking and reranking.


    This data type is not supported in Gemini API.


    [Note: Inherited members from TypedDict are omitted.]'
  properties:
  - signature: 'llm_ranker: typing.Optional[google.genai.types.RagRetrievalConfigRankingLlmRankerDict]'
    docstring: Optional. Config for LlmRanker.
  - signature: 'rank_service: typing.Optional[google.genai.types.RagRetrievalConfigRankingRankServiceDict]'
    docstring: Optional. Config for Rank Service.
  omitted_inherited_members_from:
  - TypedDict
- rank: 2504
  id: google.genai.types.RagRetrievalConfigRankingLlmRanker
  name: RagRetrievalConfigRankingLlmRanker
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Config for LlmRanker. This data type is not supported in Gemini API.


    [Note: Inherited members from _common.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, model_name: typing.Optional[str] = None):'
  properties:
  - signature: 'model_name: typing.Optional[str]'
  omitted_inherited_members_from:
  - _common.BaseModel
- rank: 2505
  id: google.genai.types.RagRetrievalConfigRankingLlmRankerDict
  name: RagRetrievalConfigRankingLlmRankerDict
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Config for LlmRanker. This data type is not supported in Gemini API.


    [Note: Inherited members from TypedDict are omitted.]'
  properties:
  - signature: 'model_name: typing.Optional[str]'
    docstring: Optional. The model name used for ranking. See [Supported models](https://cloud.google.com/vertex-ai/generative-ai/docs/model-reference/inference#supported-models).
  omitted_inherited_members_from:
  - TypedDict
- rank: 2506
  id: google.genai.types.RagRetrievalConfigRankingRankService
  name: RagRetrievalConfigRankingRankService
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Config for Rank Service. This data type is not supported in Gemini API.


    [Note: Inherited members from _common.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, model_name: typing.Optional[str] = None):'
  properties:
  - signature: 'model_name: typing.Optional[str]'
  omitted_inherited_members_from:
  - _common.BaseModel
- rank: 2507
  id: google.genai.types.RagRetrievalConfigRankingRankServiceDict
  name: RagRetrievalConfigRankingRankServiceDict
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Config for Rank Service. This data type is not supported in Gemini API.


    [Note: Inherited members from TypedDict are omitted.]'
  properties:
  - signature: 'model_name: typing.Optional[str]'
    docstring: 'Optional. The model name of the rank service. Format: `semantic-ranker-512@latest`'
  omitted_inherited_members_from:
  - TypedDict
- rank: 2508
  id: google.genai.types.RawReferenceImage
  name: RawReferenceImage
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'A raw reference image.


    A raw reference image represents the base image to edit, provided by the user.

    It can optionally be provided in addition to a mask reference image or

    a style reference image.


    [Note: Inherited members from _common.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, reference_image: typing.Optional[google.genai.types.Image] = None, reference_id: typing.Optional[int] = None, reference_type: typing.Optional[str] = None):'
  properties:
  - signature: 'reference_image: typing.Optional[google.genai.types.Image]'
  - signature: 'reference_id: typing.Optional[int]'
  - signature: 'reference_type: typing.Optional[str]'
  omitted_inherited_members_from:
  - _common.BaseModel
- rank: 2509
  id: google.genai.types.RawReferenceImageDict
  name: RawReferenceImageDict
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'A raw reference image.


    A raw reference image represents the base image to edit, provided by the user.

    It can optionally be provided in addition to a mask reference image or

    a style reference image.


    [Note: Inherited members from TypedDict are omitted.]'
  properties:
  - signature: 'reference_image: typing.Optional[google.genai.types.ImageDict]'
    docstring: The reference image for the editing operation.
  - signature: 'reference_id: typing.Optional[int]'
    docstring: The id of the reference image.
  - signature: 'reference_type: typing.Optional[str]'
    docstring: The type of the reference image. Only set by the SDK.
  omitted_inherited_members_from:
  - TypedDict
- rank: 2510
  id: google.genai.types.RealtimeInputConfig
  name: RealtimeInputConfig
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Marks the end of user activity.


    This can only be sent if automatic (i.e. server-side) activity detection is

    disabled.


    [Note: Inherited members from _common.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, automatic_activity_detection: typing.Optional[google.genai.types.AutomaticActivityDetection] = None, activity_handling: typing.Optional[google.genai.types.ActivityHandling] = None, turn_coverage: typing.Optional[google.genai.types.TurnCoverage] = None):'
  properties:
  - signature: 'automatic_activity_detection: typing.Optional[google.genai.types.AutomaticActivityDetection]'
  - signature: 'activity_handling: typing.Optional[google.genai.types.ActivityHandling]'
  - signature: 'turn_coverage: typing.Optional[google.genai.types.TurnCoverage]'
  omitted_inherited_members_from:
  - _common.BaseModel
- rank: 2511
  id: google.genai.types.RealtimeInputConfigDict
  name: RealtimeInputConfigDict
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Marks the end of user activity.


    This can only be sent if automatic (i.e. server-side) activity detection is

    disabled.


    [Note: Inherited members from TypedDict are omitted.]'
  properties:
  - signature: 'automatic_activity_detection: typing.Optional[google.genai.types.AutomaticActivityDetectionDict]'
    docstring: If not set, automatic activity detection is enabled by default. If automatic voice detection is disabled, the client must send activity signals.
  - signature: 'activity_handling: typing.Optional[google.genai.types.ActivityHandling]'
    docstring: Defines what effect activity has.
  - signature: 'turn_coverage: typing.Optional[google.genai.types.TurnCoverage]'
    docstring: Defines which input is included in the user's turn.
  omitted_inherited_members_from:
  - TypedDict
- rank: 2512
  id: google.genai.types.RecontextImageConfig
  name: RecontextImageConfig
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Configuration for recontextualizing an image.


    [Note: Inherited members from _common.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, http_options: typing.Optional[google.genai.types.HttpOptions] = None, number_of_images: typing.Optional[int] = None, base_steps: typing.Optional[int] = None, output_gcs_uri: typing.Optional[str] = None, seed: typing.Optional[int] = None, safety_filter_level: typing.Optional[google.genai.types.SafetyFilterLevel] = None, person_generation: typing.Optional[google.genai.types.PersonGeneration] = None, add_watermark: typing.Optional[bool] = None, output_mime_type: typing.Optional[str] = None, output_compression_quality: typing.Optional[int] = None, enhance_prompt: typing.Optional[bool] = None, labels: typing.Optional[dict[str, str]] = None):'
  properties:
  - signature: 'http_options: typing.Optional[google.genai.types.HttpOptions]'
  - signature: 'number_of_images: typing.Optional[int]'
  - signature: 'base_steps: typing.Optional[int]'
  - signature: 'output_gcs_uri: typing.Optional[str]'
  - signature: 'seed: typing.Optional[int]'
  - signature: 'safety_filter_level: typing.Optional[google.genai.types.SafetyFilterLevel]'
  - signature: 'person_generation: typing.Optional[google.genai.types.PersonGeneration]'
  - signature: 'add_watermark: typing.Optional[bool]'
  - signature: 'output_mime_type: typing.Optional[str]'
  - signature: 'output_compression_quality: typing.Optional[int]'
  - signature: 'enhance_prompt: typing.Optional[bool]'
  - signature: 'labels: typing.Optional[dict[str, str]]'
  omitted_inherited_members_from:
  - _common.BaseModel
- rank: 2513
  id: google.genai.types.RecontextImageConfigDict
  name: RecontextImageConfigDict
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Configuration for recontextualizing an image.


    [Note: Inherited members from TypedDict are omitted.]'
  properties:
  - signature: 'http_options: typing.Optional[google.genai.types.HttpOptionsDict]'
    docstring: Used to override HTTP request options.
  - signature: 'number_of_images: typing.Optional[int]'
    docstring: Number of images to generate.
  - signature: 'base_steps: typing.Optional[int]'
    docstring: 'The number of sampling steps. A higher value has better image

      quality, while a lower value has better latency.'
  - signature: 'output_gcs_uri: typing.Optional[str]'
    docstring: Cloud Storage URI used to store the generated images.
  - signature: 'seed: typing.Optional[int]'
    docstring: Random seed for image generation.
  - signature: 'safety_filter_level: typing.Optional[google.genai.types.SafetyFilterLevel]'
    docstring: Filter level for safety filtering.
  - signature: 'person_generation: typing.Optional[google.genai.types.PersonGeneration]'
    docstring: 'Whether allow to generate person images, and restrict to specific

      ages.'
  - signature: 'add_watermark: typing.Optional[bool]'
    docstring: Whether to add a SynthID watermark to the generated images.
  - signature: 'output_mime_type: typing.Optional[str]'
    docstring: MIME type of the generated image.
  - signature: 'output_compression_quality: typing.Optional[int]'
    docstring: 'Compression quality of the generated image (for ``image/jpeg``

      only).'
  - signature: 'enhance_prompt: typing.Optional[bool]'
    docstring: Whether to use the prompt rewriting logic.
  - signature: 'labels: typing.Optional[dict[str, str]]'
    docstring: User specified labels to track billing usage.
  omitted_inherited_members_from:
  - TypedDict
- rank: 2514
  id: google.genai.types.RecontextImageResponse
  name: RecontextImageResponse
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'The output images response.


    [Note: Inherited members from _common.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, generated_images: typing.Optional[list[google.genai.types.GeneratedImage]] = None):'
  properties:
  - signature: 'generated_images: typing.Optional[list[google.genai.types.GeneratedImage]]'
  omitted_inherited_members_from:
  - _common.BaseModel
- rank: 2515
  id: google.genai.types.RecontextImageResponseDict
  name: RecontextImageResponseDict
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'The output images response.


    [Note: Inherited members from TypedDict are omitted.]'
  properties:
  - signature: 'generated_images: typing.Optional[list[google.genai.types.GeneratedImageDict]]'
    docstring: List of generated images.
  omitted_inherited_members_from:
  - TypedDict
- rank: 2516
  id: google.genai.types.RecontextImageSource
  name: RecontextImageSource
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'A set of source input(s) for image recontextualization.


    [Note: Inherited members from _common.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, prompt: typing.Optional[str] = None, person_image: typing.Optional[google.genai.types.Image] = None, product_images: typing.Optional[list[google.genai.types.ProductImage]] = None):'
  properties:
  - signature: 'prompt: typing.Optional[str]'
  - signature: 'person_image: typing.Optional[google.genai.types.Image]'
  - signature: 'product_images: typing.Optional[list[google.genai.types.ProductImage]]'
  omitted_inherited_members_from:
  - _common.BaseModel
- rank: 2517
  id: google.genai.types.RecontextImageSourceDict
  name: RecontextImageSourceDict
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'A set of source input(s) for image recontextualization.


    [Note: Inherited members from TypedDict are omitted.]'
  properties:
  - signature: 'prompt: typing.Optional[str]'
    docstring: 'A text prompt for guiding the model during image

      recontextualization. Not supported for Virtual Try-On.'
  - signature: 'person_image: typing.Optional[google.genai.types.ImageDict]'
    docstring: 'Image of the person or subject who will be wearing the

      product(s).'
  - signature: 'product_images: typing.Optional[list[google.genai.types.ProductImageDict]]'
    docstring: A list of product images.
  omitted_inherited_members_from:
  - TypedDict
- rank: 2518
  id: google.genai.types.ReplayFile
  name: ReplayFile
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Represents a recorded session.


    [Note: Inherited members from _common.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, replay_id: typing.Optional[str] = None, interactions: typing.Optional[list[google.genai.types.ReplayInteraction]] = None):'
  properties:
  - signature: 'replay_id: typing.Optional[str]'
  - signature: 'interactions: typing.Optional[list[google.genai.types.ReplayInteraction]]'
  omitted_inherited_members_from:
  - _common.BaseModel
- rank: 2519
  id: google.genai.types.ReplayFileDict
  name: ReplayFileDict
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Represents a recorded session.


    [Note: Inherited members from TypedDict are omitted.]'
  properties:
  - signature: 'replay_id: typing.Optional[str]'
  - signature: 'interactions: typing.Optional[list[google.genai.types.ReplayInteractionDict]]'
  omitted_inherited_members_from:
  - TypedDict
- rank: 2520
  id: google.genai.types.ReplayInteraction
  name: ReplayInteraction
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Represents a single interaction, request and response in a replay.


    [Note: Inherited members from _common.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, request: typing.Optional[google.genai.types.ReplayRequest] = None, response: typing.Optional[google.genai.types.ReplayResponse] = None):'
  properties:
  - signature: 'request: typing.Optional[google.genai.types.ReplayRequest]'
  - signature: 'response: typing.Optional[google.genai.types.ReplayResponse]'
  omitted_inherited_members_from:
  - _common.BaseModel
- rank: 2521
  id: google.genai.types.ReplayInteractionDict
  name: ReplayInteractionDict
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Represents a single interaction, request and response in a replay.


    [Note: Inherited members from TypedDict are omitted.]'
  properties:
  - signature: 'request: typing.Optional[google.genai.types.ReplayRequestDict]'
  - signature: 'response: typing.Optional[google.genai.types.ReplayResponseDict]'
  omitted_inherited_members_from:
  - TypedDict
- rank: 2522
  id: google.genai.types.ReplayRequest
  name: ReplayRequest
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Represents a single request in a replay.


    [Note: Inherited members from _common.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, method: typing.Optional[str] = None, url: typing.Optional[str] = None, headers: typing.Optional[dict[str, str]] = None, body_segments: typing.Optional[list[dict[str, typing.Any]]] = None):'
  properties:
  - signature: 'method: typing.Optional[str]'
  - signature: 'url: typing.Optional[str]'
  - signature: 'headers: typing.Optional[dict[str, str]]'
  - signature: 'body_segments: typing.Optional[list[dict[str, typing.Any]]]'
  omitted_inherited_members_from:
  - _common.BaseModel
- rank: 2523
  id: google.genai.types.ReplayRequestDict
  name: ReplayRequestDict
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Represents a single request in a replay.


    [Note: Inherited members from TypedDict are omitted.]'
  properties:
  - signature: 'method: typing.Optional[str]'
  - signature: 'url: typing.Optional[str]'
  - signature: 'headers: typing.Optional[dict[str, str]]'
  - signature: 'body_segments: typing.Optional[list[dict[str, typing.Any]]]'
  omitted_inherited_members_from:
  - TypedDict
- rank: 2524
  id: google.genai.types.ReplayResponse
  name: ReplayResponse
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Represents a single response in a replay.


    [Note: Inherited members from _common.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, status_code: typing.Optional[int] = None, headers: typing.Optional[dict[str, str]] = None, body_segments: typing.Optional[list[dict[str, typing.Any]]] = None, sdk_response_segments: typing.Optional[list[dict[str, typing.Any]]] = None):'
  properties:
  - signature: 'status_code: typing.Optional[int]'
  - signature: 'headers: typing.Optional[dict[str, str]]'
  - signature: 'body_segments: typing.Optional[list[dict[str, typing.Any]]]'
  - signature: 'sdk_response_segments: typing.Optional[list[dict[str, typing.Any]]]'
  omitted_inherited_members_from:
  - _common.BaseModel
- rank: 2525
  id: google.genai.types.ReplayResponseDict
  name: ReplayResponseDict
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Represents a single response in a replay.


    [Note: Inherited members from TypedDict are omitted.]'
  properties:
  - signature: 'status_code: typing.Optional[int]'
  - signature: 'headers: typing.Optional[dict[str, str]]'
  - signature: 'body_segments: typing.Optional[list[dict[str, typing.Any]]]'
  - signature: 'sdk_response_segments: typing.Optional[list[dict[str, typing.Any]]]'
  omitted_inherited_members_from:
  - TypedDict
- rank: 2526
  id: google.genai.types.ResourceScope
  name: ResourceScope
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Resource scope.


    [Note: Inherited members from _common.CaseInSensitiveEnum are omitted.]'
  properties:
  - signature: 'COLLECTION: str'
    docstring: 'When setting base_url, this value configures resource scope to be the collection.

      The resource name will not include api version, project, or location.

      For example, if base_url is set to "https://aiplatform.googleapis.com",

      then the resource name for a Model would be

      "https://aiplatform.googleapis.com/publishers/google/models/gemini-3-pro-preview'
  omitted_inherited_members_from:
  - _common.CaseInSensitiveEnum
- rank: 2527
  id: google.genai.types.Retrieval
  name: Retrieval
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Defines a retrieval tool that model can call to access external knowledge.


    This data type is not supported in Gemini API.


    [Note: Inherited members from _common.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, disable_attribution: typing.Optional[bool] = None, external_api: typing.Optional[google.genai.types.ExternalApi] = None, vertex_ai_search: typing.Optional[google.genai.types.VertexAISearch] = None, vertex_rag_store: typing.Optional[google.genai.types.VertexRagStore] = None):'
  properties:
  - signature: 'disable_attribution: typing.Optional[bool]'
  - signature: 'external_api: typing.Optional[google.genai.types.ExternalApi]'
  - signature: 'vertex_ai_search: typing.Optional[google.genai.types.VertexAISearch]'
  - signature: 'vertex_rag_store: typing.Optional[google.genai.types.VertexRagStore]'
  omitted_inherited_members_from:
  - _common.BaseModel
- rank: 2528
  id: google.genai.types.RetrievalConfig
  name: RetrievalConfig
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Retrieval config.


    [Note: Inherited members from _common.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, lat_lng: typing.Optional[google.genai.types.LatLng] = None, language_code: typing.Optional[str] = None):'
  properties:
  - signature: 'lat_lng: typing.Optional[google.genai.types.LatLng]'
  - signature: 'language_code: typing.Optional[str]'
  omitted_inherited_members_from:
  - _common.BaseModel
- rank: 2529
  id: google.genai.types.RetrievalConfigDict
  name: RetrievalConfigDict
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Retrieval config.


    [Note: Inherited members from TypedDict are omitted.]'
  properties:
  - signature: 'lat_lng: typing.Optional[google.genai.types.LatLngDict]'
    docstring: Optional. The location of the user.
  - signature: 'language_code: typing.Optional[str]'
    docstring: The language code of the user.
  omitted_inherited_members_from:
  - TypedDict
- rank: 2530
  id: google.genai.types.RetrievalDict
  name: RetrievalDict
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Defines a retrieval tool that model can call to access external knowledge.


    This data type is not supported in Gemini API.


    [Note: Inherited members from TypedDict are omitted.]'
  properties:
  - signature: 'disable_attribution: typing.Optional[bool]'
    docstring: Optional. Deprecated. This option is no longer supported.
  - signature: 'external_api: typing.Optional[google.genai.types.ExternalApiDict]'
    docstring: Use data source powered by external API for grounding.
  - signature: 'vertex_ai_search: typing.Optional[google.genai.types.VertexAISearchDict]'
    docstring: Set to use data source powered by Vertex AI Search.
  - signature: 'vertex_rag_store: typing.Optional[google.genai.types.VertexRagStoreDict]'
    docstring: Set to use data source powered by Vertex RAG store. User data is uploaded via the VertexRagDataService.
  omitted_inherited_members_from:
  - TypedDict
- rank: 2531
  id: google.genai.types.RetrievalMetadata
  name: RetrievalMetadata
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Metadata related to retrieval in the grounding flow.


    [Note: Inherited members from _common.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, google_search_dynamic_retrieval_score: typing.Optional[float] = None):'
  properties:
  - signature: 'google_search_dynamic_retrieval_score: typing.Optional[float]'
  omitted_inherited_members_from:
  - _common.BaseModel
- rank: 2532
  id: google.genai.types.RetrievalMetadataDict
  name: RetrievalMetadataDict
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Metadata related to retrieval in the grounding flow.


    [Note: Inherited members from TypedDict are omitted.]'
  properties:
  - signature: 'google_search_dynamic_retrieval_score: typing.Optional[float]'
    docstring: Optional. Score indicating how likely information from Google Search could help answer the prompt. The score is in the range `[0, 1]`, where 0 is the least likely and 1 is the most likely. This score is only populated when Google Search grounding and dynamic retrieval is enabled. It will be compared to the threshold to determine whether to trigger Google Search.
  omitted_inherited_members_from:
  - TypedDict
- rank: 2533
  id: google.genai.types.RougeSpec
  name: RougeSpec
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Spec for rouge metric.


    [Note: Inherited members from _common.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, rouge_type: typing.Optional[str] = None, split_summaries: typing.Optional[bool] = None, use_stemmer: typing.Optional[bool] = None):'
  properties:
  - signature: 'rouge_type: typing.Optional[str]'
  - signature: 'split_summaries: typing.Optional[bool]'
  - signature: 'use_stemmer: typing.Optional[bool]'
  omitted_inherited_members_from:
  - _common.BaseModel
- rank: 2534
  id: google.genai.types.RougeSpecDict
  name: RougeSpecDict
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Spec for rouge metric.


    [Note: Inherited members from TypedDict are omitted.]'
  properties:
  - signature: 'rouge_type: typing.Optional[str]'
    docstring: Optional. Supported rouge types are rougen[1-9], rougeL, and rougeLsum.
  - signature: 'split_summaries: typing.Optional[bool]'
    docstring: Optional. Whether to split summaries while using rougeLsum.
  - signature: 'use_stemmer: typing.Optional[bool]'
    docstring: Optional. Whether to use stemmer to compute rouge score.
  omitted_inherited_members_from:
  - TypedDict
- rank: 2535
  id: google.genai.types.SafetyAttributes
  name: SafetyAttributes
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Safety attributes of a GeneratedImage or the user-provided prompt.


    [Note: Inherited members from _common.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, categories: typing.Optional[list[str]] = None, scores: typing.Optional[list[float]] = None, content_type: typing.Optional[str] = None):'
  properties:
  - signature: 'categories: typing.Optional[list[str]]'
  - signature: 'scores: typing.Optional[list[float]]'
  - signature: 'content_type: typing.Optional[str]'
  omitted_inherited_members_from:
  - _common.BaseModel
- rank: 2536
  id: google.genai.types.SafetyAttributesDict
  name: SafetyAttributesDict
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Safety attributes of a GeneratedImage or the user-provided prompt.


    [Note: Inherited members from TypedDict are omitted.]'
  properties:
  - signature: 'categories: typing.Optional[list[str]]'
    docstring: List of RAI categories.
  - signature: 'scores: typing.Optional[list[float]]'
    docstring: List of scores of each categories.
  - signature: 'content_type: typing.Optional[str]'
    docstring: Internal use only.
  omitted_inherited_members_from:
  - TypedDict
- rank: 2537
  id: google.genai.types.SafetyFilterLevel
  name: SafetyFilterLevel
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Enum that controls the safety filter level for objectionable content.


    [Note: Inherited members from _common.CaseInSensitiveEnum are omitted.]'
  properties:
  - signature: 'BLOCK_LOW_AND_ABOVE: str'
  - signature: 'BLOCK_MEDIUM_AND_ABOVE: str'
  - signature: 'BLOCK_ONLY_HIGH: str'
  - signature: 'BLOCK_NONE: str'
  omitted_inherited_members_from:
  - _common.CaseInSensitiveEnum
- rank: 2538
  id: google.genai.types.SafetyRating
  name: SafetyRating
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Safety rating corresponding to the generated content.


    [Note: Inherited members from _common.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, blocked: typing.Optional[bool] = None, category: typing.Optional[google.genai.types.HarmCategory] = None, overwritten_threshold: typing.Optional[google.genai.types.HarmBlockThreshold] = None, probability: typing.Optional[google.genai.types.HarmProbability] = None, probability_score: typing.Optional[float] = None, severity: typing.Optional[google.genai.types.HarmSeverity] = None, severity_score: typing.Optional[float] = None):'
  properties:
  - signature: 'blocked: typing.Optional[bool]'
  - signature: 'category: typing.Optional[google.genai.types.HarmCategory]'
  - signature: 'overwritten_threshold: typing.Optional[google.genai.types.HarmBlockThreshold]'
  - signature: 'probability: typing.Optional[google.genai.types.HarmProbability]'
  - signature: 'probability_score: typing.Optional[float]'
  - signature: 'severity: typing.Optional[google.genai.types.HarmSeverity]'
  - signature: 'severity_score: typing.Optional[float]'
  omitted_inherited_members_from:
  - _common.BaseModel
- rank: 2539
  id: google.genai.types.SafetyRatingDict
  name: SafetyRatingDict
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Safety rating corresponding to the generated content.


    [Note: Inherited members from TypedDict are omitted.]'
  properties:
  - signature: 'blocked: typing.Optional[bool]'
    docstring: Output only. Indicates whether the content was filtered out because of this rating.
  - signature: 'category: typing.Optional[google.genai.types.HarmCategory]'
    docstring: Output only. Harm category.
  - signature: 'overwritten_threshold: typing.Optional[google.genai.types.HarmBlockThreshold]'
    docstring: Output only. The overwritten threshold for the safety category of Gemini 2.0 image out. If minors are detected in the output image, the threshold of each safety category will be overwritten if user sets a lower threshold. This field is not supported in Gemini API.
  - signature: 'probability: typing.Optional[google.genai.types.HarmProbability]'
    docstring: Output only. Harm probability levels in the content.
  - signature: 'probability_score: typing.Optional[float]'
    docstring: Output only. Harm probability score. This field is not supported in Gemini API.
  - signature: 'severity: typing.Optional[google.genai.types.HarmSeverity]'
    docstring: Output only. Harm severity levels in the content. This field is not supported in Gemini API.
  - signature: 'severity_score: typing.Optional[float]'
    docstring: Output only. Harm severity score. This field is not supported in Gemini API.
  omitted_inherited_members_from:
  - TypedDict
- rank: 2540
  id: google.genai.types.SafetySetting
  name: SafetySetting
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Safety settings.


    [Note: Inherited members from _common.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, category: typing.Optional[google.genai.types.HarmCategory] = None, method: typing.Optional[google.genai.types.HarmBlockMethod] = None, threshold: typing.Optional[google.genai.types.HarmBlockThreshold] = None):'
  properties:
  - signature: 'category: typing.Optional[google.genai.types.HarmCategory]'
  - signature: 'method: typing.Optional[google.genai.types.HarmBlockMethod]'
  - signature: 'threshold: typing.Optional[google.genai.types.HarmBlockThreshold]'
  omitted_inherited_members_from:
  - _common.BaseModel
- rank: 2541
  id: google.genai.types.SafetySettingDict
  name: SafetySettingDict
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Safety settings.


    [Note: Inherited members from TypedDict are omitted.]'
  properties:
  - signature: 'category: typing.Optional[google.genai.types.HarmCategory]'
    docstring: Required. Harm category.
  - signature: 'method: typing.Optional[google.genai.types.HarmBlockMethod]'
    docstring: Optional. Specify if the threshold is used for probability or severity score. If not specified, the threshold is used for probability score. This field is not supported in Gemini API.
  - signature: 'threshold: typing.Optional[google.genai.types.HarmBlockThreshold]'
    docstring: Required. The harm block threshold.
  omitted_inherited_members_from:
  - TypedDict
- rank: 2542
  id: google.genai.types.Scale
  name: Scale
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Scale of the generated music.


    [Note: Inherited members from _common.CaseInSensitiveEnum are omitted.]'
  properties:
  - signature: 'SCALE_UNSPECIFIED: str'
    docstring: Default value. This value is unused.
  - signature: 'C_MAJOR_A_MINOR: str'
    docstring: C major or A minor.
  - signature: 'D_FLAT_MAJOR_B_FLAT_MINOR: str'
    docstring: Db major or Bb minor.
  - signature: 'D_MAJOR_B_MINOR: str'
    docstring: D major or B minor.
  - signature: 'E_FLAT_MAJOR_C_MINOR: str'
    docstring: Eb major or C minor
  - signature: 'E_MAJOR_D_FLAT_MINOR: str'
    docstring: E major or Db minor.
  - signature: 'F_MAJOR_D_MINOR: str'
    docstring: F major or D minor.
  - signature: 'G_FLAT_MAJOR_E_FLAT_MINOR: str'
    docstring: Gb major or Eb minor.
  - signature: 'G_MAJOR_E_MINOR: str'
    docstring: G major or E minor.
  - signature: 'A_FLAT_MAJOR_F_MINOR: str'
    docstring: Ab major or F minor.
  - signature: 'A_MAJOR_G_FLAT_MINOR: str'
    docstring: A major or Gb minor.
  - signature: 'B_FLAT_MAJOR_G_MINOR: str'
    docstring: Bb major or G minor.
  - signature: 'B_MAJOR_A_FLAT_MINOR: str'
    docstring: B major or Ab minor.
  omitted_inherited_members_from:
  - _common.CaseInSensitiveEnum
- rank: 2543
  id: google.genai.types.Schema
  name: Schema
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Schema is used to define the format of input/output data.


    Represents a select subset of an [OpenAPI 3.0 schema

    object](https://spec.openapis.org/oas/v3.0.3#schema-object). More fields may

    be added in the future as needed.


    [Note: Inherited members from _common.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, additional_properties: typing.Optional[typing.Any] = None, defs: typing.Optional[dict[str, google.genai.types.Schema]] = None, ref: typing.Optional[str] = None, any_of: typing.Optional[list[google.genai.types.Schema]] = None, default: typing.Optional[typing.Any] = None, description: typing.Optional[str] = None, enum: typing.Optional[list[str]] = None, example: typing.Optional[typing.Any] = None, format: typing.Optional[str] = None, items: typing.Optional[google.genai.types.Schema] = None, max_items: typing.Optional[int] = None, max_length: typing.Optional[int] = None, max_properties: typing.Optional[int] = None, maximum: typing.Optional[float] = None, min_items: typing.Optional[int] = None, min_length: typing.Optional[int] = None, min_properties: typing.Optional[int] = None, minimum: typing.Optional[float] = None, nullable: typing.Optional[bool] = None, pattern: typing.Optional[str] = None, properties: typing.Optional[dict[str, google.genai.types.Schema]]
    = None, property_ordering: typing.Optional[list[str]] = None, required: typing.Optional[list[str]] = None, title: typing.Optional[str] = None, type: typing.Optional[google.genai.types.Type] = None):'
  methods:
  - signature: 'def json_schema(self) -> google.genai.types.JSONSchema:'
    docstring: "Converts the Schema object to a JSONSchema object, that is compatible with 2020-12 JSON Schema draft.\n\n Note: Conversion of fields that are not included in the JSONSchema class\n are ignored.\n Json Schema is now supported natively by both Vertex AI and Gemini API.\n Users\n are recommended to pass/receive Json Schema directly to/from the API. For\n example:\n 1. the counter part of GenerateContentConfig.response_schema is\n    GenerateContentConfig.response_json_schema, which accepts [JSON\n   Schema](https://json-schema.org/)\n 2. the counter part of FunctionDeclaration.parameters is\n    FunctionDeclaration.parameters_json_schema, which accepts [JSON\n    Schema](https://json-schema.org/)\n 3. the counter part of FunctionDeclaration.response is\n    FunctionDeclaration.response_json_schema, which accepts [JSON\nSchema](https://json-schema.org/)"
  - signature: 'def convert_schema(schema: typing.Union[google.genai.types.Schema, dict[str, typing.Any]]) -> google.genai.types.JSONSchema:'
  - signature: 'def from_json_schema(cls, *, json_schema: google.genai.types.JSONSchema, api_option: typing.Literal[VERTEX_AI, GEMINI_API]=''GEMINI_API'', raise_error_on_unsupported_field: bool=False) -> google.genai.types.Schema:'
    docstring: "Converts a JSONSchema object to a Schema object.\n\n Note: Conversion of fields that are not included in the JSONSchema class\n are ignored.\n Json Schema is now supported natively by both Vertex AI and Gemini API.\n Users\n are recommended to pass/receive Json Schema directly to/from the API. For\n example:\n 1. the counter part of GenerateContentConfig.response_schema is\n    GenerateContentConfig.response_json_schema, which accepts [JSON\n   Schema](https://json-schema.org/)\n 2. the counter part of FunctionDeclaration.parameters is\n    FunctionDeclaration.parameters_json_schema, which accepts [JSON\n    Schema](https://json-schema.org/)\n 3. the counter part of FunctionDeclaration.response is\n    FunctionDeclaration.response_json_schema, which accepts [JSON\nSchema](https://json-schema.org/)\n The JSONSchema is compatible with 2020-12 JSON Schema draft, specified by\n OpenAPI 3.1.\n\n Args:\n     json_schema: JSONSchema object to be converted.\n     api_option: API\
      \ option to be used. If set to 'VERTEX_AI', the\n       JSONSchema will be converted to a Schema object that is compatible\n       with Vertex AI API. If set to 'GEMINI_API', the JSONSchema will be\n       converted to a Schema object that is compatible with Gemini API.\n       Default is 'GEMINI_API'.\n     raise_error_on_unsupported_field: If set to True, an error will be\n       raised if the JSONSchema contains any unsupported fields. Default is\n       False.\n\n Returns:\n     Schema object that is compatible with the specified API option.\n Raises:\n     ValueError: If the JSONSchema contains any unsupported fields and\n       raise_error_on_unsupported_field is set to True. Or if the JSONSchema\n       is not compatible with the specified API option."
  - signature: 'def normalize_json_schema_type(json_schema_type: typing.Optional[typing.Union[google.genai.types.JSONSchemaType, typing.Sequence[google.genai.types.JSONSchemaType], str, typing.Sequence[str]]]) -> tuple[list[str], bool]:'
    docstring: Returns (non_null_types, nullable)
  - signature: 'def raise_error_if_cannot_convert(json_schema_dict: dict[str, typing.Any], api_option: typing.Literal[VERTEX_AI, GEMINI_API], raise_error_on_unsupported_field: bool) -> None:'
    docstring: Raises an error if the JSONSchema cannot be converted to the specified Schema object.
  - signature: 'def copy_schema_fields(json_schema_dict: dict[str, typing.Any], related_fields_to_copy: tuple[str, Ellipsis], sub_schema_in_any_of: dict[str, typing.Any]) -> None:'
    docstring: Copies the fields from json_schema_dict to sub_schema_in_any_of.
  - signature: 'def convert_json_schema(current_json_schema: google.genai.types.JSONSchema, root_json_schema_dict: dict[str, typing.Any], api_option: typing.Literal[VERTEX_AI, GEMINI_API], raise_error_on_unsupported_field: bool) -> google.genai.types.Schema:'
  properties:
  - signature: 'additional_properties: typing.Optional[typing.Any]'
  - signature: 'defs: typing.Optional[dict[str, google.genai.types.Schema]]'
  - signature: 'ref: typing.Optional[str]'
  - signature: 'any_of: typing.Optional[list[google.genai.types.Schema]]'
  - signature: 'default: typing.Optional[typing.Any]'
  - signature: 'description: typing.Optional[str]'
  - signature: 'enum: typing.Optional[list[str]]'
  - signature: 'example: typing.Optional[typing.Any]'
  - signature: 'format: typing.Optional[str]'
  - signature: 'items: typing.Optional[google.genai.types.Schema]'
  - signature: 'max_items: typing.Optional[int]'
  - signature: 'max_length: typing.Optional[int]'
  - signature: 'max_properties: typing.Optional[int]'
  - signature: 'maximum: typing.Optional[float]'
  - signature: 'min_items: typing.Optional[int]'
  - signature: 'min_length: typing.Optional[int]'
  - signature: 'min_properties: typing.Optional[int]'
  - signature: 'minimum: typing.Optional[float]'
  - signature: 'nullable: typing.Optional[bool]'
  - signature: 'pattern: typing.Optional[str]'
  - signature: 'properties: typing.Optional[dict[str, google.genai.types.Schema]]'
  - signature: 'property_ordering: typing.Optional[list[str]]'
  - signature: 'required: typing.Optional[list[str]]'
  - signature: 'title: typing.Optional[str]'
  - signature: 'type: typing.Optional[google.genai.types.Type]'
  omitted_inherited_members_from:
  - _common.BaseModel
- rank: 2544
  id: google.genai.types.Schema.convert_json_schema
  name: convert_json_schema
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def convert_json_schema(current_json_schema: google.genai.types.JSONSchema, root_json_schema_dict: dict[str, typing.Any], api_option: typing.Literal[VERTEX_AI, GEMINI_API], raise_error_on_unsupported_field: bool) -> google.genai.types.Schema:'
- rank: 2545
  id: google.genai.types.Schema.convert_schema
  name: convert_schema
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def convert_schema(schema: typing.Union[google.genai.types.Schema, dict[str, typing.Any]]) -> google.genai.types.JSONSchema:'
- rank: 2546
  id: google.genai.types.Schema.copy_schema_fields
  name: copy_schema_fields
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: Copies the fields from json_schema_dict to sub_schema_in_any_of.
  signature: 'def copy_schema_fields(json_schema_dict: dict[str, typing.Any], related_fields_to_copy: tuple[str, Ellipsis], sub_schema_in_any_of: dict[str, typing.Any]) -> None:'
- rank: 2547
  id: google.genai.types.Schema.from_json_schema
  name: from_json_schema
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Converts a JSONSchema object to a Schema object.\n\n Note: Conversion of fields that are not included in the JSONSchema class\n are ignored.\n Json Schema is now supported natively by both Vertex AI and Gemini API.\n Users\n are recommended to pass/receive Json Schema directly to/from the API. For\n example:\n 1. the counter part of GenerateContentConfig.response_schema is\n    GenerateContentConfig.response_json_schema, which accepts [JSON\n   Schema](https://json-schema.org/)\n 2. the counter part of FunctionDeclaration.parameters is\n    FunctionDeclaration.parameters_json_schema, which accepts [JSON\n    Schema](https://json-schema.org/)\n 3. the counter part of FunctionDeclaration.response is\n    FunctionDeclaration.response_json_schema, which accepts [JSON\nSchema](https://json-schema.org/)\n The JSONSchema is compatible with 2020-12 JSON Schema draft, specified by\n OpenAPI 3.1.\n\n Args:\n     json_schema: JSONSchema object to be converted.\n     api_option: API option\
    \ to be used. If set to 'VERTEX_AI', the\n       JSONSchema will be converted to a Schema object that is compatible\n       with Vertex AI API. If set to 'GEMINI_API', the JSONSchema will be\n       converted to a Schema object that is compatible with Gemini API.\n       Default is 'GEMINI_API'.\n     raise_error_on_unsupported_field: If set to True, an error will be\n       raised if the JSONSchema contains any unsupported fields. Default is\n       False.\n\n Returns:\n     Schema object that is compatible with the specified API option.\n Raises:\n     ValueError: If the JSONSchema contains any unsupported fields and\n       raise_error_on_unsupported_field is set to True. Or if the JSONSchema\n       is not compatible with the specified API option."
  signature: 'def from_json_schema(cls, *, json_schema: google.genai.types.JSONSchema, api_option: typing.Literal[VERTEX_AI, GEMINI_API]=''GEMINI_API'', raise_error_on_unsupported_field: bool=False) -> google.genai.types.Schema:'
- rank: 2548
  id: google.genai.types.Schema.json_schema
  name: json_schema
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Converts the Schema object to a JSONSchema object, that is compatible with 2020-12 JSON Schema draft.\n\n Note: Conversion of fields that are not included in the JSONSchema class\n are ignored.\n Json Schema is now supported natively by both Vertex AI and Gemini API.\n Users\n are recommended to pass/receive Json Schema directly to/from the API. For\n example:\n 1. the counter part of GenerateContentConfig.response_schema is\n    GenerateContentConfig.response_json_schema, which accepts [JSON\n   Schema](https://json-schema.org/)\n 2. the counter part of FunctionDeclaration.parameters is\n    FunctionDeclaration.parameters_json_schema, which accepts [JSON\n    Schema](https://json-schema.org/)\n 3. the counter part of FunctionDeclaration.response is\n    FunctionDeclaration.response_json_schema, which accepts [JSON\nSchema](https://json-schema.org/)"
  signature: 'def json_schema(self) -> google.genai.types.JSONSchema:'
- rank: 2549
  id: google.genai.types.Schema.normalize_json_schema_type
  name: normalize_json_schema_type
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: Returns (non_null_types, nullable)
  signature: 'def normalize_json_schema_type(json_schema_type: typing.Optional[typing.Union[google.genai.types.JSONSchemaType, typing.Sequence[google.genai.types.JSONSchemaType], str, typing.Sequence[str]]]) -> tuple[list[str], bool]:'
- rank: 2550
  id: google.genai.types.Schema.raise_error_if_cannot_convert
  name: raise_error_if_cannot_convert
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: Raises an error if the JSONSchema cannot be converted to the specified Schema object.
  signature: 'def raise_error_if_cannot_convert(json_schema_dict: dict[str, typing.Any], api_option: typing.Literal[VERTEX_AI, GEMINI_API], raise_error_on_unsupported_field: bool) -> None:'
- rank: 2551
  id: google.genai.types.SchemaDict
  name: SchemaDict
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Schema is used to define the format of input/output data.


    Represents a select subset of an [OpenAPI 3.0 schema

    object](https://spec.openapis.org/oas/v3.0.3#schema-object). More fields may

    be added in the future as needed.


    [Note: Inherited members from TypedDict are omitted.]'
  properties:
  - signature: 'additional_properties: typing.Optional[typing.Any]'
    docstring: Optional. Can either be a boolean or an object; controls the presence of additional properties.
  - signature: 'defs: typing.Optional[dict[str, google.genai.types.SchemaDict]]'
    docstring: Optional. A map of definitions for use by `ref` Only allowed at the root of the schema.
  - signature: 'ref: typing.Optional[str]'
    docstring: 'Optional. Allows indirect references between schema nodes. The value should be a valid reference to a child of the root `defs`. For example, the following schema defines a reference to a schema node named "Pet": type: object properties: pet: ref: #/defs/Pet defs: Pet: type: object properties: name: type: string The value of the "pet" property is a reference to the schema node named "Pet". See details in https://json-schema.org/understanding-json-schema/structuring'
  - signature: 'any_of: typing.Optional[list[google.genai.types.SchemaDict]]'
    docstring: Optional. The value should be validated against any (one or more) of the subschemas in the list.
  - signature: 'default: typing.Optional[typing.Any]'
    docstring: Optional. Default value of the data.
  - signature: 'description: typing.Optional[str]'
    docstring: Optional. The description of the data.
  - signature: 'enum: typing.Optional[list[str]]'
    docstring: 'Optional. Possible values of the element of primitive type with enum format. Examples: 1. We can define direction as : {type:STRING, format:enum, enum:["EAST", NORTH", "SOUTH", "WEST"]} 2. We can define apartment number as : {type:INTEGER, format:enum, enum:["101", "201", "301"]}'
  - signature: 'example: typing.Optional[typing.Any]'
    docstring: Optional. Example of the object. Will only populated when the object is the root.
  - signature: 'format: typing.Optional[str]'
    docstring: 'Optional. The format of the data. Supported formats: for NUMBER type: "float", "double" for INTEGER type: "int32", "int64" for STRING type: "email", "byte", etc'
  - signature: 'items: typing.Optional[google.genai.types.SchemaDict]'
    docstring: Optional. SCHEMA FIELDS FOR TYPE ARRAY Schema of the elements of Type.ARRAY.
  - signature: 'max_items: typing.Optional[int]'
    docstring: Optional. Maximum number of the elements for Type.ARRAY.
  - signature: 'max_length: typing.Optional[int]'
    docstring: Optional. Maximum length of the Type.STRING
  - signature: 'max_properties: typing.Optional[int]'
    docstring: Optional. Maximum number of the properties for Type.OBJECT.
  - signature: 'maximum: typing.Optional[float]'
    docstring: Optional. Maximum value of the Type.INTEGER and Type.NUMBER
  - signature: 'min_items: typing.Optional[int]'
    docstring: Optional. Minimum number of the elements for Type.ARRAY.
  - signature: 'min_length: typing.Optional[int]'
    docstring: Optional. SCHEMA FIELDS FOR TYPE STRING Minimum length of the Type.STRING
  - signature: 'min_properties: typing.Optional[int]'
    docstring: Optional. Minimum number of the properties for Type.OBJECT.
  - signature: 'minimum: typing.Optional[float]'
    docstring: Optional. SCHEMA FIELDS FOR TYPE INTEGER and NUMBER Minimum value of the Type.INTEGER and Type.NUMBER
  - signature: 'nullable: typing.Optional[bool]'
    docstring: Optional. Indicates if the value may be null.
  - signature: 'pattern: typing.Optional[str]'
    docstring: Optional. Pattern of the Type.STRING to restrict a string to a regular expression.
  - signature: 'properties: typing.Optional[dict[str, google.genai.types.SchemaDict]]'
    docstring: Optional. SCHEMA FIELDS FOR TYPE OBJECT Properties of Type.OBJECT.
  - signature: 'property_ordering: typing.Optional[list[str]]'
    docstring: Optional. The order of the properties. Not a standard field in open api spec. Only used to support the order of the properties.
  - signature: 'required: typing.Optional[list[str]]'
    docstring: Optional. Required properties of Type.OBJECT.
  - signature: 'title: typing.Optional[str]'
    docstring: Optional. The title of the Schema.
  - signature: 'type: typing.Optional[google.genai.types.Type]'
    docstring: Optional. The type of the data.
  omitted_inherited_members_from:
  - TypedDict
- rank: 2552
  id: google.genai.types.ScribbleImage
  name: ScribbleImage
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'An image mask representing a brush scribble.


    [Note: Inherited members from _common.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, image: typing.Optional[google.genai.types.Image] = None):'
  properties:
  - signature: 'image: typing.Optional[google.genai.types.Image]'
  omitted_inherited_members_from:
  - _common.BaseModel
- rank: 2553
  id: google.genai.types.ScribbleImageDict
  name: ScribbleImageDict
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'An image mask representing a brush scribble.


    [Note: Inherited members from TypedDict are omitted.]'
  properties:
  - signature: 'image: typing.Optional[google.genai.types.ImageDict]'
    docstring: The brush scribble to guide segmentation. Valid for the interactive mode.
  omitted_inherited_members_from:
  - TypedDict
- rank: 2554
  id: google.genai.types.SearchEntryPoint
  name: SearchEntryPoint
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Google search entry point.


    [Note: Inherited members from _common.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, rendered_content: typing.Optional[str] = None, sdk_blob: typing.Optional[bytes] = None):'
  properties:
  - signature: 'rendered_content: typing.Optional[str]'
  - signature: 'sdk_blob: typing.Optional[bytes]'
  omitted_inherited_members_from:
  - _common.BaseModel
- rank: 2555
  id: google.genai.types.SearchEntryPointDict
  name: SearchEntryPointDict
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Google search entry point.


    [Note: Inherited members from TypedDict are omitted.]'
  properties:
  - signature: 'rendered_content: typing.Optional[str]'
    docstring: Optional. Web content snippet that can be embedded in a web page or an app webview.
  - signature: 'sdk_blob: typing.Optional[bytes]'
    docstring: Optional. Base64 encoded JSON representing array of tuple.
  omitted_inherited_members_from:
  - TypedDict
- rank: 2556
  id: google.genai.types.Segment
  name: Segment
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Segment of the content.


    [Note: Inherited members from _common.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, end_index: typing.Optional[int] = None, part_index: typing.Optional[int] = None, start_index: typing.Optional[int] = None, text: typing.Optional[str] = None):'
  properties:
  - signature: 'end_index: typing.Optional[int]'
  - signature: 'part_index: typing.Optional[int]'
  - signature: 'start_index: typing.Optional[int]'
  - signature: 'text: typing.Optional[str]'
  omitted_inherited_members_from:
  - _common.BaseModel
- rank: 2557
  id: google.genai.types.SegmentDict
  name: SegmentDict
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Segment of the content.


    [Note: Inherited members from TypedDict are omitted.]'
  properties:
  - signature: 'end_index: typing.Optional[int]'
    docstring: Output only. End index in the given Part, measured in bytes. Offset from the start of the Part, exclusive, starting at zero.
  - signature: 'part_index: typing.Optional[int]'
    docstring: Output only. The index of a Part object within its parent Content object.
  - signature: 'start_index: typing.Optional[int]'
    docstring: Output only. Start index in the given Part, measured in bytes. Offset from the start of the Part, inclusive, starting at zero.
  - signature: 'text: typing.Optional[str]'
    docstring: Output only. The text corresponding to the segment from the response.
  omitted_inherited_members_from:
  - TypedDict
- rank: 2558
  id: google.genai.types.SegmentImageConfig
  name: SegmentImageConfig
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Configuration for segmenting an image.


    [Note: Inherited members from _common.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, http_options: typing.Optional[google.genai.types.HttpOptions] = None, mode: typing.Optional[google.genai.types.SegmentMode] = None, max_predictions: typing.Optional[int] = None, confidence_threshold: typing.Optional[float] = None, mask_dilation: typing.Optional[float] = None, binary_color_threshold: typing.Optional[float] = None, labels: typing.Optional[dict[str, str]] = None):'
  properties:
  - signature: 'http_options: typing.Optional[google.genai.types.HttpOptions]'
  - signature: 'mode: typing.Optional[google.genai.types.SegmentMode]'
  - signature: 'max_predictions: typing.Optional[int]'
  - signature: 'confidence_threshold: typing.Optional[float]'
  - signature: 'mask_dilation: typing.Optional[float]'
  - signature: 'binary_color_threshold: typing.Optional[float]'
  - signature: 'labels: typing.Optional[dict[str, str]]'
  omitted_inherited_members_from:
  - _common.BaseModel
- rank: 2559
  id: google.genai.types.SegmentImageConfigDict
  name: SegmentImageConfigDict
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Configuration for segmenting an image.


    [Note: Inherited members from TypedDict are omitted.]'
  properties:
  - signature: 'http_options: typing.Optional[google.genai.types.HttpOptionsDict]'
    docstring: Used to override HTTP request options.
  - signature: 'mode: typing.Optional[google.genai.types.SegmentMode]'
    docstring: The segmentation mode to use.
  - signature: 'max_predictions: typing.Optional[int]'
    docstring: 'The maximum number of predictions to return up to, by top

      confidence score.'
  - signature: 'confidence_threshold: typing.Optional[float]'
    docstring: 'The confidence score threshold for the detections as a decimal

      value. Only predictions with a confidence score higher than this

      threshold will be returned.'
  - signature: 'mask_dilation: typing.Optional[float]'
    docstring: 'A decimal value representing how much dilation to apply to the

      masks. 0 for no dilation. 1.0 means the masked area covers the whole

      image.'
  - signature: 'binary_color_threshold: typing.Optional[float]'
    docstring: 'The binary color threshold to apply to the masks. The threshold

      can be set to a decimal value between 0 and 255 non-inclusive.

      Set to -1 for no binary color thresholding.'
  - signature: 'labels: typing.Optional[dict[str, str]]'
    docstring: User specified labels to track billing usage.
  omitted_inherited_members_from:
  - TypedDict
- rank: 2560
  id: google.genai.types.SegmentImageResponse
  name: SegmentImageResponse
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'The output images response.


    [Note: Inherited members from _common.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, generated_masks: typing.Optional[list[google.genai.types.GeneratedImageMask]] = None):'
  properties:
  - signature: 'generated_masks: typing.Optional[list[google.genai.types.GeneratedImageMask]]'
  omitted_inherited_members_from:
  - _common.BaseModel
- rank: 2561
  id: google.genai.types.SegmentImageResponseDict
  name: SegmentImageResponseDict
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'The output images response.


    [Note: Inherited members from TypedDict are omitted.]'
  properties:
  - signature: 'generated_masks: typing.Optional[list[google.genai.types.GeneratedImageMaskDict]]'
    docstring: "List of generated image masks.\n      "
  omitted_inherited_members_from:
  - TypedDict
- rank: 2562
  id: google.genai.types.SegmentImageSource
  name: SegmentImageSource
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'A set of source input(s) for image segmentation.


    [Note: Inherited members from _common.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, prompt: typing.Optional[str] = None, image: typing.Optional[google.genai.types.Image] = None, scribble_image: typing.Optional[google.genai.types.ScribbleImage] = None):'
  properties:
  - signature: 'prompt: typing.Optional[str]'
  - signature: 'image: typing.Optional[google.genai.types.Image]'
  - signature: 'scribble_image: typing.Optional[google.genai.types.ScribbleImage]'
  omitted_inherited_members_from:
  - _common.BaseModel
- rank: 2563
  id: google.genai.types.SegmentImageSourceDict
  name: SegmentImageSourceDict
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'A set of source input(s) for image segmentation.


    [Note: Inherited members from TypedDict are omitted.]'
  properties:
  - signature: 'prompt: typing.Optional[str]'
    docstring: 'A text prompt for guiding the model during image segmentation.

      Required for prompt mode and semantic mode, disallowed for other modes.'
  - signature: 'image: typing.Optional[google.genai.types.ImageDict]'
    docstring: The image to be segmented.
  - signature: 'scribble_image: typing.Optional[google.genai.types.ScribbleImageDict]'
    docstring: 'The brush scribble to guide segmentation.

      Required for the interactive mode, disallowed for other modes.'
  omitted_inherited_members_from:
  - TypedDict
- rank: 2564
  id: google.genai.types.SegmentMode
  name: SegmentMode
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Enum that represents the segmentation mode.


    [Note: Inherited members from _common.CaseInSensitiveEnum are omitted.]'
  properties:
  - signature: 'FOREGROUND: str'
  - signature: 'BACKGROUND: str'
  - signature: 'PROMPT: str'
  - signature: 'SEMANTIC: str'
  - signature: 'INTERACTIVE: str'
  omitted_inherited_members_from:
  - _common.CaseInSensitiveEnum
- rank: 2565
  id: google.genai.types.SessionResumptionConfig
  name: SessionResumptionConfig
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Configuration of session resumption mechanism.


    Included in `LiveConnectConfig.session_resumption`. If included server

    will send `LiveServerSessionResumptionUpdate` messages.


    [Note: Inherited members from _common.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, handle: typing.Optional[str] = None, transparent: typing.Optional[bool] = None):'
  properties:
  - signature: 'handle: typing.Optional[str]'
  - signature: 'transparent: typing.Optional[bool]'
  omitted_inherited_members_from:
  - _common.BaseModel
- rank: 2566
  id: google.genai.types.SessionResumptionConfigDict
  name: SessionResumptionConfigDict
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Configuration of session resumption mechanism.


    Included in `LiveConnectConfig.session_resumption`. If included server

    will send `LiveServerSessionResumptionUpdate` messages.


    [Note: Inherited members from TypedDict are omitted.]'
  properties:
  - signature: 'handle: typing.Optional[str]'
    docstring: 'Session resumption handle of previous session (session to restore).


      If not present new session will be started.'
  - signature: 'transparent: typing.Optional[bool]'
    docstring: If set the server will send `last_consumed_client_message_index` in the `session_resumption_update` messages to allow for transparent reconnections.
  omitted_inherited_members_from:
  - TypedDict
- rank: 2567
  id: google.genai.types.SingleEmbedContentResponse
  name: SingleEmbedContentResponse
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Config for `response` parameter.


    [Note: Inherited members from _common.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, embedding: typing.Optional[google.genai.types.ContentEmbedding] = None, token_count: typing.Optional[int] = None):'
  properties:
  - signature: 'embedding: typing.Optional[google.genai.types.ContentEmbedding]'
  - signature: 'token_count: typing.Optional[int]'
  omitted_inherited_members_from:
  - _common.BaseModel
- rank: 2568
  id: google.genai.types.SingleEmbedContentResponseDict
  name: SingleEmbedContentResponseDict
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Config for `response` parameter.


    [Note: Inherited members from TypedDict are omitted.]'
  properties:
  - signature: 'embedding: typing.Optional[google.genai.types.ContentEmbeddingDict]'
    docstring: "The response to the request.\n      "
  - signature: 'token_count: typing.Optional[int]'
    docstring: "The error encountered while processing the request.\n      "
  omitted_inherited_members_from:
  - TypedDict
- rank: 2569
  id: google.genai.types.SlidingWindow
  name: SlidingWindow
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Context window will be truncated by keeping only suffix of it.


    Context window will always be cut at start of USER role turn. System

    instructions and `BidiGenerateContentSetup.prefix_turns` will not be

    subject to the sliding window mechanism, they will always stay at the

    beginning of context window.


    [Note: Inherited members from _common.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, target_tokens: typing.Optional[int] = None):'
  properties:
  - signature: 'target_tokens: typing.Optional[int]'
  omitted_inherited_members_from:
  - _common.BaseModel
- rank: 2570
  id: google.genai.types.SlidingWindowDict
  name: SlidingWindowDict
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Context window will be truncated by keeping only suffix of it.


    Context window will always be cut at start of USER role turn. System

    instructions and `BidiGenerateContentSetup.prefix_turns` will not be

    subject to the sliding window mechanism, they will always stay at the

    beginning of context window.


    [Note: Inherited members from TypedDict are omitted.]'
  properties:
  - signature: 'target_tokens: typing.Optional[int]'
    docstring: Session reduction target -- how many tokens we should keep. Window shortening operation has some latency costs, so we should avoid running it on every turn. Should be < trigger_tokens. If not set, trigger_tokens/2 is assumed.
  omitted_inherited_members_from:
  - TypedDict
- rank: 2571
  id: google.genai.types.SpeakerVoiceConfig
  name: SpeakerVoiceConfig
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Configuration for a single speaker in a multi speaker setup.


    [Note: Inherited members from _common.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, speaker: typing.Optional[str] = None, voice_config: typing.Optional[google.genai.types.VoiceConfig] = None):'
  properties:
  - signature: 'speaker: typing.Optional[str]'
  - signature: 'voice_config: typing.Optional[google.genai.types.VoiceConfig]'
  omitted_inherited_members_from:
  - _common.BaseModel
- rank: 2572
  id: google.genai.types.SpeakerVoiceConfigDict
  name: SpeakerVoiceConfigDict
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Configuration for a single speaker in a multi speaker setup.


    [Note: Inherited members from TypedDict are omitted.]'
  properties:
  - signature: 'speaker: typing.Optional[str]'
    docstring: Required. The name of the speaker. This should be the same as the speaker name used in the prompt.
  - signature: 'voice_config: typing.Optional[google.genai.types.VoiceConfigDict]'
    docstring: Required. The configuration for the voice of this speaker.
  omitted_inherited_members_from:
  - TypedDict
- rank: 2573
  id: google.genai.types.SpeechConfig
  name: SpeechConfig
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'The speech generation config.


    [Note: Inherited members from _common.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, language_code: typing.Optional[str] = None, voice_config: typing.Optional[google.genai.types.VoiceConfig] = None, multi_speaker_voice_config: typing.Optional[google.genai.types.MultiSpeakerVoiceConfig] = None):'
  properties:
  - signature: 'language_code: typing.Optional[str]'
  - signature: 'voice_config: typing.Optional[google.genai.types.VoiceConfig]'
  - signature: 'multi_speaker_voice_config: typing.Optional[google.genai.types.MultiSpeakerVoiceConfig]'
  omitted_inherited_members_from:
  - _common.BaseModel
- rank: 2574
  id: google.genai.types.SpeechConfigDict
  name: SpeechConfigDict
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'The speech generation config.


    [Note: Inherited members from TypedDict are omitted.]'
  properties:
  - signature: 'language_code: typing.Optional[str]'
    docstring: Optional. Language code (ISO 639. e.g. en-US) for the speech synthesization.
  - signature: 'voice_config: typing.Optional[google.genai.types.VoiceConfigDict]'
    docstring: The configuration for the speaker to use.
  - signature: 'multi_speaker_voice_config: typing.Optional[google.genai.types.MultiSpeakerVoiceConfigDict]'
    docstring: Optional. The configuration for the multi-speaker setup. It is mutually exclusive with the voice_config field. This field is not supported in Vertex AI.
  omitted_inherited_members_from:
  - TypedDict
- rank: 2575
  id: google.genai.types.StartSensitivity
  name: StartSensitivity
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Start of speech sensitivity.


    [Note: Inherited members from _common.CaseInSensitiveEnum are omitted.]'
  properties:
  - signature: 'START_SENSITIVITY_UNSPECIFIED: str'
    docstring: The default is START_SENSITIVITY_LOW.
  - signature: 'START_SENSITIVITY_HIGH: str'
    docstring: Automatic detection will detect the start of speech more often.
  - signature: 'START_SENSITIVITY_LOW: str'
    docstring: Automatic detection will detect the start of speech less often.
  omitted_inherited_members_from:
  - _common.CaseInSensitiveEnum
- rank: 2576
  id: google.genai.types.StringList
  name: StringList
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'User provided string values assigned to a single metadata key.


    This data type is not supported in Vertex AI.


    [Note: Inherited members from _common.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, values: typing.Optional[list[str]] = None):'
  properties:
  - signature: 'values: typing.Optional[list[str]]'
  omitted_inherited_members_from:
  - _common.BaseModel
- rank: 2577
  id: google.genai.types.StringListDict
  name: StringListDict
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'User provided string values assigned to a single metadata key.


    This data type is not supported in Vertex AI.


    [Note: Inherited members from TypedDict are omitted.]'
  properties:
  - signature: 'values: typing.Optional[list[str]]'
    docstring: The string values of the metadata to store.
  omitted_inherited_members_from:
  - TypedDict
- rank: 2578
  id: google.genai.types.StyleReferenceConfig
  name: StyleReferenceConfig
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Configuration for a Style reference image.


    [Note: Inherited members from _common.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, style_description: typing.Optional[str] = None):'
  properties:
  - signature: 'style_description: typing.Optional[str]'
  omitted_inherited_members_from:
  - _common.BaseModel
- rank: 2579
  id: google.genai.types.StyleReferenceConfigDict
  name: StyleReferenceConfigDict
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Configuration for a Style reference image.


    [Note: Inherited members from TypedDict are omitted.]'
  properties:
  - signature: 'style_description: typing.Optional[str]'
    docstring: A text description of the style to use for the generated image.
  omitted_inherited_members_from:
  - TypedDict
- rank: 2580
  id: google.genai.types.StyleReferenceImage
  name: StyleReferenceImage
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'A style reference image.


    This encapsulates a style reference image provided by the user, and

    additionally optional config parameters for the style reference image.


    A raw reference image can also be provided as a destination for the style to

    be applied to.


    [Note: Inherited members from _common.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, reference_image: typing.Optional[google.genai.types.Image] = None, reference_id: typing.Optional[int] = None, reference_type: typing.Optional[str] = None, config: typing.Optional[google.genai.types.StyleReferenceConfig] = None, style_image_config: typing.Optional[google.genai.types.StyleReferenceConfig] = None):'
  properties:
  - signature: 'reference_image: typing.Optional[google.genai.types.Image]'
  - signature: 'reference_id: typing.Optional[int]'
  - signature: 'reference_type: typing.Optional[str]'
  - signature: 'config: typing.Optional[google.genai.types.StyleReferenceConfig]'
    docstring: Re-map config to style_reference_config to send to API.
  - signature: 'style_image_config: typing.Optional[google.genai.types.StyleReferenceConfig]'
  omitted_inherited_members_from:
  - _common.BaseModel
- rank: 2581
  id: google.genai.types.StyleReferenceImageDict
  name: StyleReferenceImageDict
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'A style reference image.


    This encapsulates a style reference image provided by the user, and

    additionally optional config parameters for the style reference image.


    A raw reference image can also be provided as a destination for the style to

    be applied to.


    [Note: Inherited members from TypedDict are omitted.]'
  properties:
  - signature: 'reference_image: typing.Optional[google.genai.types.ImageDict]'
    docstring: The reference image for the editing operation.
  - signature: 'reference_id: typing.Optional[int]'
    docstring: The id of the reference image.
  - signature: 'reference_type: typing.Optional[str]'
    docstring: The type of the reference image. Only set by the SDK.
  - signature: 'config: typing.Optional[google.genai.types.StyleReferenceConfigDict]'
    docstring: Configuration for the style reference image.
  omitted_inherited_members_from:
  - TypedDict
- rank: 2582
  id: google.genai.types.SubjectReferenceConfig
  name: SubjectReferenceConfig
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Configuration for a Subject reference image.


    [Note: Inherited members from _common.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, subject_type: typing.Optional[google.genai.types.SubjectReferenceType] = None, subject_description: typing.Optional[str] = None):'
  properties:
  - signature: 'subject_type: typing.Optional[google.genai.types.SubjectReferenceType]'
  - signature: 'subject_description: typing.Optional[str]'
  omitted_inherited_members_from:
  - _common.BaseModel
- rank: 2583
  id: google.genai.types.SubjectReferenceConfigDict
  name: SubjectReferenceConfigDict
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Configuration for a Subject reference image.


    [Note: Inherited members from TypedDict are omitted.]'
  properties:
  - signature: 'subject_type: typing.Optional[google.genai.types.SubjectReferenceType]'
    docstring: The subject type of a subject reference image.
  - signature: 'subject_description: typing.Optional[str]'
    docstring: Subject description for the image.
  omitted_inherited_members_from:
  - TypedDict
- rank: 2584
  id: google.genai.types.SubjectReferenceImage
  name: SubjectReferenceImage
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'A subject reference image.


    This encapsulates a subject reference image provided by the user, and

    additionally optional config parameters for the subject reference image.


    A raw reference image can also be provided as a destination for the subject to

    be applied to.


    [Note: Inherited members from _common.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, reference_image: typing.Optional[google.genai.types.Image] = None, reference_id: typing.Optional[int] = None, reference_type: typing.Optional[str] = None, config: typing.Optional[google.genai.types.SubjectReferenceConfig] = None, subject_image_config: typing.Optional[google.genai.types.SubjectReferenceConfig] = None):'
  properties:
  - signature: 'reference_image: typing.Optional[google.genai.types.Image]'
  - signature: 'reference_id: typing.Optional[int]'
  - signature: 'reference_type: typing.Optional[str]'
  - signature: 'config: typing.Optional[google.genai.types.SubjectReferenceConfig]'
    docstring: Re-map config to subject_reference_config to send to API.
  - signature: 'subject_image_config: typing.Optional[google.genai.types.SubjectReferenceConfig]'
  omitted_inherited_members_from:
  - _common.BaseModel
- rank: 2585
  id: google.genai.types.SubjectReferenceImageDict
  name: SubjectReferenceImageDict
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'A subject reference image.


    This encapsulates a subject reference image provided by the user, and

    additionally optional config parameters for the subject reference image.


    A raw reference image can also be provided as a destination for the subject to

    be applied to.


    [Note: Inherited members from TypedDict are omitted.]'
  properties:
  - signature: 'reference_image: typing.Optional[google.genai.types.ImageDict]'
    docstring: The reference image for the editing operation.
  - signature: 'reference_id: typing.Optional[int]'
    docstring: The id of the reference image.
  - signature: 'reference_type: typing.Optional[str]'
    docstring: The type of the reference image. Only set by the SDK.
  - signature: 'config: typing.Optional[google.genai.types.SubjectReferenceConfigDict]'
    docstring: Configuration for the subject reference image.
  omitted_inherited_members_from:
  - TypedDict
- rank: 2586
  id: google.genai.types.SubjectReferenceType
  name: SubjectReferenceType
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Enum representing the subject type of a subject reference image.


    [Note: Inherited members from _common.CaseInSensitiveEnum are omitted.]'
  properties:
  - signature: 'SUBJECT_TYPE_DEFAULT: str'
  - signature: 'SUBJECT_TYPE_PERSON: str'
  - signature: 'SUBJECT_TYPE_ANIMAL: str'
  - signature: 'SUBJECT_TYPE_PRODUCT: str'
  omitted_inherited_members_from:
  - _common.CaseInSensitiveEnum
- rank: 2587
  id: google.genai.types.SupervisedHyperParameters
  name: SupervisedHyperParameters
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Hyperparameters for SFT. This data type is not supported in Gemini API.


    [Note: Inherited members from _common.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, adapter_size: typing.Optional[google.genai.types.AdapterSize] = None, batch_size: typing.Optional[int] = None, epoch_count: typing.Optional[int] = None, learning_rate: typing.Optional[float] = None, learning_rate_multiplier: typing.Optional[float] = None):'
  properties:
  - signature: 'adapter_size: typing.Optional[google.genai.types.AdapterSize]'
  - signature: 'batch_size: typing.Optional[int]'
  - signature: 'epoch_count: typing.Optional[int]'
  - signature: 'learning_rate: typing.Optional[float]'
  - signature: 'learning_rate_multiplier: typing.Optional[float]'
  omitted_inherited_members_from:
  - _common.BaseModel
- rank: 2588
  id: google.genai.types.SupervisedHyperParametersDict
  name: SupervisedHyperParametersDict
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Hyperparameters for SFT. This data type is not supported in Gemini API.


    [Note: Inherited members from TypedDict are omitted.]'
  properties:
  - signature: 'adapter_size: typing.Optional[google.genai.types.AdapterSize]'
    docstring: Optional. Adapter size for tuning.
  - signature: 'batch_size: typing.Optional[int]'
    docstring: Optional. Batch size for tuning. This feature is only available for open source models.
  - signature: 'epoch_count: typing.Optional[int]'
    docstring: Optional. Number of complete passes the model makes over the entire training dataset during training.
  - signature: 'learning_rate: typing.Optional[float]'
    docstring: Optional. Learning rate for tuning. Mutually exclusive with `learning_rate_multiplier`. This feature is only available for open source models.
  - signature: 'learning_rate_multiplier: typing.Optional[float]'
    docstring: Optional. Multiplier for adjusting the default learning rate. Mutually exclusive with `learning_rate`. This feature is only available for 1P models.
  omitted_inherited_members_from:
  - TypedDict
- rank: 2589
  id: google.genai.types.SupervisedTuningDataStats
  name: SupervisedTuningDataStats
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Tuning data statistics for Supervised Tuning.


    This data type is not supported in Gemini API.


    [Note: Inherited members from _common.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, dropped_example_reasons: typing.Optional[list[str]] = None, total_billable_character_count: typing.Optional[int] = None, total_billable_token_count: typing.Optional[int] = None, total_truncated_example_count: typing.Optional[int] = None, total_tuning_character_count: typing.Optional[int] = None, truncated_example_indices: typing.Optional[list[int]] = None, tuning_dataset_example_count: typing.Optional[int] = None, tuning_step_count: typing.Optional[int] = None, user_dataset_examples: typing.Optional[list[google.genai.types.Content]] = None, user_input_token_distribution: typing.Optional[google.genai.types.SupervisedTuningDatasetDistribution] = None, user_message_per_example_distribution: typing.Optional[google.genai.types.SupervisedTuningDatasetDistribution] = None, user_output_token_distribution: typing.Optional[google.genai.types.SupervisedTuningDatasetDistribution] = None):'
  properties:
  - signature: 'dropped_example_reasons: typing.Optional[list[str]]'
  - signature: 'total_billable_character_count: typing.Optional[int]'
  - signature: 'total_billable_token_count: typing.Optional[int]'
  - signature: 'total_truncated_example_count: typing.Optional[int]'
  - signature: 'total_tuning_character_count: typing.Optional[int]'
  - signature: 'truncated_example_indices: typing.Optional[list[int]]'
  - signature: 'tuning_dataset_example_count: typing.Optional[int]'
  - signature: 'tuning_step_count: typing.Optional[int]'
  - signature: 'user_dataset_examples: typing.Optional[list[google.genai.types.Content]]'
  - signature: 'user_input_token_distribution: typing.Optional[google.genai.types.SupervisedTuningDatasetDistribution]'
  - signature: 'user_message_per_example_distribution: typing.Optional[google.genai.types.SupervisedTuningDatasetDistribution]'
  - signature: 'user_output_token_distribution: typing.Optional[google.genai.types.SupervisedTuningDatasetDistribution]'
  omitted_inherited_members_from:
  - _common.BaseModel
- rank: 2590
  id: google.genai.types.SupervisedTuningDataStatsDict
  name: SupervisedTuningDataStatsDict
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Tuning data statistics for Supervised Tuning.


    This data type is not supported in Gemini API.


    [Note: Inherited members from TypedDict are omitted.]'
  properties:
  - signature: 'dropped_example_reasons: typing.Optional[list[str]]'
    docstring: Output only. For each index in `truncated_example_indices`, the user-facing reason why the example was dropped.
  - signature: 'total_billable_character_count: typing.Optional[int]'
    docstring: Output only. Number of billable characters in the tuning dataset.
  - signature: 'total_billable_token_count: typing.Optional[int]'
    docstring: Output only. Number of billable tokens in the tuning dataset.
  - signature: 'total_truncated_example_count: typing.Optional[int]'
    docstring: 'Output only. The number of examples in the dataset that have been dropped. An example can be dropped for reasons including: too many tokens, contains an invalid image, contains too many images, etc.'
  - signature: 'total_tuning_character_count: typing.Optional[int]'
    docstring: Output only. Number of tuning characters in the tuning dataset.
  - signature: 'truncated_example_indices: typing.Optional[list[int]]'
    docstring: Output only. A partial sample of the indices (starting from 1) of the dropped examples.
  - signature: 'tuning_dataset_example_count: typing.Optional[int]'
    docstring: Output only. Number of examples in the tuning dataset.
  - signature: 'tuning_step_count: typing.Optional[int]'
    docstring: Output only. Number of tuning steps for this Tuning Job.
  - signature: 'user_dataset_examples: typing.Optional[list[google.genai.types.ContentDict]]'
    docstring: Output only. Sample user messages in the training dataset uri.
  - signature: 'user_input_token_distribution: typing.Optional[google.genai.types.SupervisedTuningDatasetDistributionDict]'
    docstring: Output only. Dataset distributions for the user input tokens.
  - signature: 'user_message_per_example_distribution: typing.Optional[google.genai.types.SupervisedTuningDatasetDistributionDict]'
    docstring: Output only. Dataset distributions for the messages per example.
  - signature: 'user_output_token_distribution: typing.Optional[google.genai.types.SupervisedTuningDatasetDistributionDict]'
    docstring: Output only. Dataset distributions for the user output tokens.
  omitted_inherited_members_from:
  - TypedDict
- rank: 2591
  id: google.genai.types.SupervisedTuningDatasetDistribution
  name: SupervisedTuningDatasetDistribution
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Dataset distribution for Supervised Tuning.


    This data type is not supported in Gemini API.


    [Note: Inherited members from _common.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, billable_sum: typing.Optional[int] = None, buckets: typing.Optional[list[google.genai.types.SupervisedTuningDatasetDistributionDatasetBucket]] = None, max: typing.Optional[float] = None, mean: typing.Optional[float] = None, median: typing.Optional[float] = None, min: typing.Optional[float] = None, p5: typing.Optional[float] = None, p95: typing.Optional[float] = None, sum: typing.Optional[int] = None):'
  properties:
  - signature: 'billable_sum: typing.Optional[int]'
  - signature: 'buckets: typing.Optional[list[google.genai.types.SupervisedTuningDatasetDistributionDatasetBucket]]'
  - signature: 'max: typing.Optional[float]'
  - signature: 'mean: typing.Optional[float]'
  - signature: 'median: typing.Optional[float]'
  - signature: 'min: typing.Optional[float]'
  - signature: 'p5: typing.Optional[float]'
  - signature: 'p95: typing.Optional[float]'
  - signature: 'sum: typing.Optional[int]'
  omitted_inherited_members_from:
  - _common.BaseModel
- rank: 2592
  id: google.genai.types.SupervisedTuningDatasetDistributionDatasetBucket
  name: SupervisedTuningDatasetDistributionDatasetBucket
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Dataset bucket used to create a histogram for the distribution given a population of values.


    This data type is not supported in Gemini API.


    [Note: Inherited members from _common.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, count: typing.Optional[float] = None, left: typing.Optional[float] = None, right: typing.Optional[float] = None):'
  properties:
  - signature: 'count: typing.Optional[float]'
  - signature: 'left: typing.Optional[float]'
  - signature: 'right: typing.Optional[float]'
  omitted_inherited_members_from:
  - _common.BaseModel
- rank: 2593
  id: google.genai.types.SupervisedTuningDatasetDistributionDatasetBucketDict
  name: SupervisedTuningDatasetDistributionDatasetBucketDict
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Dataset bucket used to create a histogram for the distribution given a population of values.


    This data type is not supported in Gemini API.


    [Note: Inherited members from TypedDict are omitted.]'
  properties:
  - signature: 'count: typing.Optional[float]'
    docstring: Output only. Number of values in the bucket.
  - signature: 'left: typing.Optional[float]'
    docstring: Output only. Left bound of the bucket.
  - signature: 'right: typing.Optional[float]'
    docstring: Output only. Right bound of the bucket.
  omitted_inherited_members_from:
  - TypedDict
- rank: 2594
  id: google.genai.types.SupervisedTuningDatasetDistributionDict
  name: SupervisedTuningDatasetDistributionDict
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Dataset distribution for Supervised Tuning.


    This data type is not supported in Gemini API.


    [Note: Inherited members from TypedDict are omitted.]'
  properties:
  - signature: 'billable_sum: typing.Optional[int]'
    docstring: Output only. Sum of a given population of values that are billable.
  - signature: 'buckets: typing.Optional[list[google.genai.types.SupervisedTuningDatasetDistributionDatasetBucketDict]]'
    docstring: Output only. Defines the histogram bucket.
  - signature: 'max: typing.Optional[float]'
    docstring: Output only. The maximum of the population values.
  - signature: 'mean: typing.Optional[float]'
    docstring: Output only. The arithmetic mean of the values in the population.
  - signature: 'median: typing.Optional[float]'
    docstring: Output only. The median of the values in the population.
  - signature: 'min: typing.Optional[float]'
    docstring: Output only. The minimum of the population values.
  - signature: 'p5: typing.Optional[float]'
    docstring: Output only. The 5th percentile of the values in the population.
  - signature: 'p95: typing.Optional[float]'
    docstring: Output only. The 95th percentile of the values in the population.
  - signature: 'sum: typing.Optional[int]'
    docstring: Output only. Sum of a given population of values.
  omitted_inherited_members_from:
  - TypedDict
- rank: 2595
  id: google.genai.types.SupervisedTuningSpec
  name: SupervisedTuningSpec
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Supervised tuning spec for tuning.


    [Note: Inherited members from _common.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, export_last_checkpoint_only: typing.Optional[bool] = None, hyper_parameters: typing.Optional[google.genai.types.SupervisedHyperParameters] = None, training_dataset_uri: typing.Optional[str] = None, tuning_mode: typing.Optional[google.genai.types.TuningMode] = None, validation_dataset_uri: typing.Optional[str] = None):'
  properties:
  - signature: 'export_last_checkpoint_only: typing.Optional[bool]'
  - signature: 'hyper_parameters: typing.Optional[google.genai.types.SupervisedHyperParameters]'
  - signature: 'training_dataset_uri: typing.Optional[str]'
  - signature: 'tuning_mode: typing.Optional[google.genai.types.TuningMode]'
  - signature: 'validation_dataset_uri: typing.Optional[str]'
  omitted_inherited_members_from:
  - _common.BaseModel
- rank: 2596
  id: google.genai.types.SupervisedTuningSpecDict
  name: SupervisedTuningSpecDict
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Supervised tuning spec for tuning.


    [Note: Inherited members from TypedDict are omitted.]'
  properties:
  - signature: 'export_last_checkpoint_only: typing.Optional[bool]'
    docstring: Optional. If set to true, disable intermediate checkpoints for SFT and only the last checkpoint will be exported. Otherwise, enable intermediate checkpoints for SFT. Default is false.
  - signature: 'hyper_parameters: typing.Optional[google.genai.types.SupervisedHyperParametersDict]'
    docstring: Optional. Hyperparameters for SFT.
  - signature: 'training_dataset_uri: typing.Optional[str]'
    docstring: Required. Training dataset used for tuning. The dataset can be specified as either a Cloud Storage path to a JSONL file or as the resource name of a Vertex Multimodal Dataset.
  - signature: 'tuning_mode: typing.Optional[google.genai.types.TuningMode]'
    docstring: Tuning mode.
  - signature: 'validation_dataset_uri: typing.Optional[str]'
    docstring: Optional. Validation dataset used for tuning. The dataset can be specified as either a Cloud Storage path to a JSONL file or as the resource name of a Vertex Multimodal Dataset.
  omitted_inherited_members_from:
  - TypedDict
- rank: 2597
  id: google.genai.types.TestTableFile
  name: TestTableFile
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: '[Note: Inherited members from _common.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, comment: typing.Optional[str] = None, test_method: typing.Optional[str] = None, parameter_names: typing.Optional[list[str]] = None, test_table: typing.Optional[list[google.genai.types.TestTableItem]] = None):'
  properties:
  - signature: 'comment: typing.Optional[str]'
  - signature: 'test_method: typing.Optional[str]'
  - signature: 'parameter_names: typing.Optional[list[str]]'
  - signature: 'test_table: typing.Optional[list[google.genai.types.TestTableItem]]'
  omitted_inherited_members_from:
  - _common.BaseModel
- rank: 2598
  id: google.genai.types.TestTableFileDict
  name: TestTableFileDict
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: '[Note: Inherited members from TypedDict are omitted.]'
  properties:
  - signature: 'comment: typing.Optional[str]'
  - signature: 'test_method: typing.Optional[str]'
  - signature: 'parameter_names: typing.Optional[list[str]]'
  - signature: 'test_table: typing.Optional[list[google.genai.types.TestTableItemDict]]'
  omitted_inherited_members_from:
  - TypedDict
- rank: 2599
  id: google.genai.types.TestTableItem
  name: TestTableItem
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: '[Note: Inherited members from _common.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, name: typing.Optional[str] = None, parameters: typing.Optional[dict[str, typing.Any]] = None, exception_if_mldev: typing.Optional[str] = None, exception_if_vertex: typing.Optional[str] = None, override_replay_id: typing.Optional[str] = None, has_union: typing.Optional[bool] = None, skip_in_api_mode: typing.Optional[str] = None, ignore_keys: typing.Optional[list[str]] = None):'
  properties:
  - signature: 'name: typing.Optional[str]'
  - signature: 'parameters: typing.Optional[dict[str, typing.Any]]'
  - signature: 'exception_if_mldev: typing.Optional[str]'
  - signature: 'exception_if_vertex: typing.Optional[str]'
  - signature: 'override_replay_id: typing.Optional[str]'
  - signature: 'has_union: typing.Optional[bool]'
  - signature: 'skip_in_api_mode: typing.Optional[str]'
  - signature: 'ignore_keys: typing.Optional[list[str]]'
  omitted_inherited_members_from:
  - _common.BaseModel
- rank: 2600
  id: google.genai.types.TestTableItemDict
  name: TestTableItemDict
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: '[Note: Inherited members from TypedDict are omitted.]'
  properties:
  - signature: 'name: typing.Optional[str]'
    docstring: The name of the test. This is used to derive the replay id.
  - signature: 'parameters: typing.Optional[dict[str, typing.Any]]'
    docstring: The parameters to the test. Use pydantic models.
  - signature: 'exception_if_mldev: typing.Optional[str]'
    docstring: Expects an exception for MLDev matching the string.
  - signature: 'exception_if_vertex: typing.Optional[str]'
    docstring: Expects an exception for Vertex matching the string.
  - signature: 'override_replay_id: typing.Optional[str]'
    docstring: Use if you don't want to use the default replay id which is derived from the test name.
  - signature: 'has_union: typing.Optional[bool]'
    docstring: True if the parameters contain an unsupported union type. This test  will be skipped for languages that do not support the union type.
  - signature: 'skip_in_api_mode: typing.Optional[str]'
    docstring: When set to a reason string, this test will be skipped in the API mode. Use this flag for tests that can not be reproduced with the real API. E.g. a test that deletes a resource.
  - signature: 'ignore_keys: typing.Optional[list[str]]'
    docstring: Keys to ignore when comparing the request and response. This is useful for tests that are not deterministic.
  omitted_inherited_members_from:
  - TypedDict
- rank: 2601
  id: google.genai.types.ThinkingConfig
  name: ThinkingConfig
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'The thinking features configuration.


    [Note: Inherited members from _common.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, include_thoughts: typing.Optional[bool] = None, thinking_budget: typing.Optional[int] = None, thinking_level: typing.Optional[google.genai.types.ThinkingLevel] = None):'
  properties:
  - signature: 'include_thoughts: typing.Optional[bool]'
  - signature: 'thinking_budget: typing.Optional[int]'
  - signature: 'thinking_level: typing.Optional[google.genai.types.ThinkingLevel]'
  omitted_inherited_members_from:
  - _common.BaseModel
- rank: 2602
  id: google.genai.types.ThinkingConfigDict
  name: ThinkingConfigDict
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'The thinking features configuration.


    [Note: Inherited members from TypedDict are omitted.]'
  properties:
  - signature: 'include_thoughts: typing.Optional[bool]'
    docstring: "Indicates whether to include thoughts in the response. If true, thoughts are returned only if the model supports thought and thoughts are available.\n      "
  - signature: 'thinking_budget: typing.Optional[int]'
    docstring: "Indicates the thinking budget in tokens. 0 is DISABLED. -1 is AUTOMATIC. The default values and allowed ranges are model dependent.\n      "
  - signature: 'thinking_level: typing.Optional[google.genai.types.ThinkingLevel]'
    docstring: Optional. The level of thoughts tokens that the model should generate.
  omitted_inherited_members_from:
  - TypedDict
- rank: 2603
  id: google.genai.types.ThinkingLevel
  name: ThinkingLevel
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'The level of thoughts tokens that the model should generate.


    [Note: Inherited members from _common.CaseInSensitiveEnum are omitted.]'
  properties:
  - signature: 'THINKING_LEVEL_UNSPECIFIED: str'
    docstring: Default value.
  - signature: 'LOW: str'
    docstring: Low thinking level.
  - signature: 'HIGH: str'
    docstring: High thinking level.
  omitted_inherited_members_from:
  - _common.CaseInSensitiveEnum
- rank: 2604
  id: google.genai.types.TokensInfo
  name: TokensInfo
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Tokens info with a list of tokens and the corresponding list of token ids.


    [Note: Inherited members from _common.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, role: typing.Optional[str] = None, token_ids: typing.Optional[list[int]] = None, tokens: typing.Optional[list[bytes]] = None):'
  properties:
  - signature: 'role: typing.Optional[str]'
  - signature: 'token_ids: typing.Optional[list[int]]'
  - signature: 'tokens: typing.Optional[list[bytes]]'
  omitted_inherited_members_from:
  - _common.BaseModel
- rank: 2605
  id: google.genai.types.TokensInfoDict
  name: TokensInfoDict
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Tokens info with a list of tokens and the corresponding list of token ids.


    [Note: Inherited members from TypedDict are omitted.]'
  properties:
  - signature: 'role: typing.Optional[str]'
    docstring: Optional fields for the role from the corresponding Content.
  - signature: 'token_ids: typing.Optional[list[int]]'
    docstring: A list of token ids from the input.
  - signature: 'tokens: typing.Optional[list[bytes]]'
    docstring: A list of tokens from the input.
  omitted_inherited_members_from:
  - TypedDict
- rank: 2606
  id: google.genai.types.Tool
  name: Tool
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Tool details of a tool that the model may use to generate a response.


    [Note: Inherited members from _common.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, function_declarations: typing.Optional[list[google.genai.types.FunctionDeclaration]] = None, retrieval: typing.Optional[google.genai.types.Retrieval] = None, google_search_retrieval: typing.Optional[google.genai.types.GoogleSearchRetrieval] = None, computer_use: typing.Optional[google.genai.types.ComputerUse] = None, file_search: typing.Optional[google.genai.types.FileSearch] = None, code_execution: typing.Optional[google.genai.types.ToolCodeExecution] = None, enterprise_web_search: typing.Optional[google.genai.types.EnterpriseWebSearch] = None, google_maps: typing.Optional[google.genai.types.GoogleMaps] = None, google_search: typing.Optional[google.genai.types.GoogleSearch] = None, url_context: typing.Optional[google.genai.types.UrlContext] = None):'
  properties:
  - signature: 'function_declarations: typing.Optional[list[google.genai.types.FunctionDeclaration]]'
  - signature: 'retrieval: typing.Optional[google.genai.types.Retrieval]'
  - signature: 'google_search_retrieval: typing.Optional[google.genai.types.GoogleSearchRetrieval]'
  - signature: 'computer_use: typing.Optional[google.genai.types.ComputerUse]'
  - signature: 'file_search: typing.Optional[google.genai.types.FileSearch]'
  - signature: 'code_execution: typing.Optional[google.genai.types.ToolCodeExecution]'
  - signature: 'enterprise_web_search: typing.Optional[google.genai.types.EnterpriseWebSearch]'
  - signature: 'google_maps: typing.Optional[google.genai.types.GoogleMaps]'
  - signature: 'google_search: typing.Optional[google.genai.types.GoogleSearch]'
  - signature: 'url_context: typing.Optional[google.genai.types.UrlContext]'
  omitted_inherited_members_from:
  - _common.BaseModel
- rank: 2607
  id: google.genai.types.ToolCodeExecution
  name: ToolCodeExecution
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Tool that executes code generated by the model, and automatically returns the result to the model.


    See also [ExecutableCode]and [CodeExecutionResult] which are input and output

    to this tool. This data type is not supported in Gemini API.


    [Note: Inherited members from _common.BaseModel are omitted.]'
  omitted_inherited_members_from:
  - _common.BaseModel
- rank: 2608
  id: google.genai.types.ToolCodeExecutionDict
  name: ToolCodeExecutionDict
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Tool that executes code generated by the model, and automatically returns the result to the model.


    See also [ExecutableCode]and [CodeExecutionResult] which are input and output

    to this tool. This data type is not supported in Gemini API.


    [Note: Inherited members from TypedDict are omitted.]'
  omitted_inherited_members_from:
  - TypedDict
- rank: 2609
  id: google.genai.types.ToolConfig
  name: ToolConfig
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Tool config.


    This config is shared for all tools provided in the request.


    [Note: Inherited members from _common.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, function_calling_config: typing.Optional[google.genai.types.FunctionCallingConfig] = None, retrieval_config: typing.Optional[google.genai.types.RetrievalConfig] = None):'
  properties:
  - signature: 'function_calling_config: typing.Optional[google.genai.types.FunctionCallingConfig]'
  - signature: 'retrieval_config: typing.Optional[google.genai.types.RetrievalConfig]'
  omitted_inherited_members_from:
  - _common.BaseModel
- rank: 2610
  id: google.genai.types.ToolConfigDict
  name: ToolConfigDict
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Tool config.


    This config is shared for all tools provided in the request.


    [Note: Inherited members from TypedDict are omitted.]'
  properties:
  - signature: 'function_calling_config: typing.Optional[google.genai.types.FunctionCallingConfigDict]'
    docstring: Optional. Function calling config.
  - signature: 'retrieval_config: typing.Optional[google.genai.types.RetrievalConfigDict]'
    docstring: Optional. Retrieval config.
  omitted_inherited_members_from:
  - TypedDict
- rank: 2611
  id: google.genai.types.ToolDict
  name: ToolDict
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Tool details of a tool that the model may use to generate a response.


    [Note: Inherited members from TypedDict are omitted.]'
  properties:
  - signature: 'function_declarations: typing.Optional[list[google.genai.types.FunctionDeclarationDict]]'
    docstring: List of function declarations that the tool supports.
  - signature: 'retrieval: typing.Optional[google.genai.types.RetrievalDict]'
    docstring: Optional. Retrieval tool type. System will always execute the provided retrieval tool(s) to get external knowledge to answer the prompt. Retrieval results are presented to the model for generation. This field is not supported in Gemini API.
  - signature: 'google_search_retrieval: typing.Optional[google.genai.types.GoogleSearchRetrievalDict]'
    docstring: Optional. Specialized retrieval tool that is powered by Google Search.
  - signature: 'computer_use: typing.Optional[google.genai.types.ComputerUseDict]'
    docstring: 'Optional. Tool to support the model interacting directly with the

      computer. If enabled, it automatically populates computer-use specific

      Function Declarations.'
  - signature: 'file_search: typing.Optional[google.genai.types.FileSearchDict]'
    docstring: Optional. Tool to retrieve knowledge from the File Search Stores.
  - signature: 'code_execution: typing.Optional[google.genai.types.ToolCodeExecutionDict]'
    docstring: Optional. CodeExecution tool type. Enables the model to execute code as part of generation.
  - signature: 'enterprise_web_search: typing.Optional[google.genai.types.EnterpriseWebSearchDict]'
    docstring: Optional. Tool to support searching public web data, powered by Vertex AI Search and Sec4 compliance. This field is not supported in Gemini API.
  - signature: 'google_maps: typing.Optional[google.genai.types.GoogleMapsDict]'
    docstring: Optional. GoogleMaps tool type. Tool to support Google Maps in Model.
  - signature: 'google_search: typing.Optional[google.genai.types.GoogleSearchDict]'
    docstring: Optional. GoogleSearch tool type. Tool to support Google Search in Model. Powered by Google.
  - signature: 'url_context: typing.Optional[google.genai.types.UrlContextDict]'
    docstring: Optional. Tool to support URL context retrieval.
  omitted_inherited_members_from:
  - TypedDict
- rank: 2612
  id: google.genai.types.TrafficType
  name: TrafficType
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Output only.


    The traffic type for this request. This enum is not supported in Gemini API.


    [Note: Inherited members from _common.CaseInSensitiveEnum are omitted.]'
  properties:
  - signature: 'TRAFFIC_TYPE_UNSPECIFIED: str'
    docstring: Unspecified request traffic type.
  - signature: 'ON_DEMAND: str'
    docstring: The request was processed using Pay-As-You-Go quota.
  - signature: 'PROVISIONED_THROUGHPUT: str'
    docstring: Type for Provisioned Throughput traffic.
  omitted_inherited_members_from:
  - _common.CaseInSensitiveEnum
- rank: 2613
  id: google.genai.types.Transcription
  name: Transcription
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Audio transcription in Server Conent.


    [Note: Inherited members from _common.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, text: typing.Optional[str] = None, finished: typing.Optional[bool] = None):'
  properties:
  - signature: 'text: typing.Optional[str]'
  - signature: 'finished: typing.Optional[bool]'
  omitted_inherited_members_from:
  - _common.BaseModel
- rank: 2614
  id: google.genai.types.TranscriptionDict
  name: TranscriptionDict
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Audio transcription in Server Conent.


    [Note: Inherited members from TypedDict are omitted.]'
  properties:
  - signature: 'text: typing.Optional[str]'
    docstring: "Transcription text.\n      "
  - signature: 'finished: typing.Optional[bool]'
    docstring: "The bool indicates the end of the transcription.\n      "
  omitted_inherited_members_from:
  - TypedDict
- rank: 2615
  id: google.genai.types.TunedModel
  name: TunedModel
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'TunedModel for the Tuned Model of a Tuning Job.


    [Note: Inherited members from _common.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, model: typing.Optional[str] = None, endpoint: typing.Optional[str] = None, checkpoints: typing.Optional[list[google.genai.types.TunedModelCheckpoint]] = None):'
  properties:
  - signature: 'model: typing.Optional[str]'
  - signature: 'endpoint: typing.Optional[str]'
  - signature: 'checkpoints: typing.Optional[list[google.genai.types.TunedModelCheckpoint]]'
  omitted_inherited_members_from:
  - _common.BaseModel
- rank: 2616
  id: google.genai.types.TunedModelCheckpoint
  name: TunedModelCheckpoint
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'TunedModelCheckpoint for the Tuned Model of a Tuning Job.


    [Note: Inherited members from _common.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, checkpoint_id: typing.Optional[str] = None, epoch: typing.Optional[int] = None, step: typing.Optional[int] = None, endpoint: typing.Optional[str] = None):'
  properties:
  - signature: 'checkpoint_id: typing.Optional[str]'
  - signature: 'epoch: typing.Optional[int]'
  - signature: 'step: typing.Optional[int]'
  - signature: 'endpoint: typing.Optional[str]'
  omitted_inherited_members_from:
  - _common.BaseModel
- rank: 2617
  id: google.genai.types.TunedModelCheckpointDict
  name: TunedModelCheckpointDict
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'TunedModelCheckpoint for the Tuned Model of a Tuning Job.


    [Note: Inherited members from TypedDict are omitted.]'
  properties:
  - signature: 'checkpoint_id: typing.Optional[str]'
    docstring: "The ID of the checkpoint.\n      "
  - signature: 'epoch: typing.Optional[int]'
    docstring: "The epoch of the checkpoint.\n      "
  - signature: 'step: typing.Optional[int]'
    docstring: "The step of the checkpoint.\n      "
  - signature: 'endpoint: typing.Optional[str]'
    docstring: 'The Endpoint resource name that the checkpoint is deployed to.

      Format: `projects/{project}/locations/{location}/endpoints/{endpoint}`.'
  omitted_inherited_members_from:
  - TypedDict
- rank: 2618
  id: google.genai.types.TunedModelDict
  name: TunedModelDict
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'TunedModel for the Tuned Model of a Tuning Job.


    [Note: Inherited members from TypedDict are omitted.]'
  properties:
  - signature: 'model: typing.Optional[str]'
    docstring: 'Output only. The resource name of the TunedModel.

      Format: `projects/{project}/locations/{location}/models/{model}@{version_id}`

      When tuning from a base model, the version_id will be 1.

      For continuous tuning, the version id will be incremented by 1 from the

      last version id in the parent model. E.g., `projects/{project}/locations/{location}/models/{model}@{last_version_id + 1}`'
  - signature: 'endpoint: typing.Optional[str]'
    docstring: 'Output only. A resource name of an Endpoint.

      Format: `projects/{project}/locations/{location}/endpoints/{endpoint}`.'
  - signature: 'checkpoints: typing.Optional[list[google.genai.types.TunedModelCheckpointDict]]'
    docstring: 'The checkpoints associated with this TunedModel.

      This field is only populated for tuning jobs that enable intermediate

      checkpoints.'
  omitted_inherited_members_from:
  - TypedDict
- rank: 2619
  id: google.genai.types.TunedModelInfo
  name: TunedModelInfo
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'A tuned machine learning model.


    [Note: Inherited members from _common.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, base_model: typing.Optional[str] = None, create_time: typing.Optional[datetime.datetime] = None, update_time: typing.Optional[datetime.datetime] = None):'
  properties:
  - signature: 'base_model: typing.Optional[str]'
  - signature: 'create_time: typing.Optional[datetime.datetime]'
  - signature: 'update_time: typing.Optional[datetime.datetime]'
  omitted_inherited_members_from:
  - _common.BaseModel
- rank: 2620
  id: google.genai.types.TunedModelInfoDict
  name: TunedModelInfoDict
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'A tuned machine learning model.


    [Note: Inherited members from TypedDict are omitted.]'
  properties:
  - signature: 'base_model: typing.Optional[str]'
    docstring: ID of the base model that you want to tune.
  - signature: 'create_time: typing.Optional[datetime.datetime]'
    docstring: Date and time when the base model was created.
  - signature: 'update_time: typing.Optional[datetime.datetime]'
    docstring: Date and time when the base model was last updated.
  omitted_inherited_members_from:
  - TypedDict
- rank: 2621
  id: google.genai.types.TuningDataStats
  name: TuningDataStats
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'The tuning data statistic values for TuningJob.


    This data type is not supported in Gemini API.


    [Note: Inherited members from _common.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, distillation_data_stats: typing.Optional[google.genai.types.DistillationDataStats] = None, preference_optimization_data_stats: typing.Optional[google.genai.types.PreferenceOptimizationDataStats] = None, supervised_tuning_data_stats: typing.Optional[google.genai.types.SupervisedTuningDataStats] = None):'
  properties:
  - signature: 'distillation_data_stats: typing.Optional[google.genai.types.DistillationDataStats]'
  - signature: 'preference_optimization_data_stats: typing.Optional[google.genai.types.PreferenceOptimizationDataStats]'
  - signature: 'supervised_tuning_data_stats: typing.Optional[google.genai.types.SupervisedTuningDataStats]'
  omitted_inherited_members_from:
  - _common.BaseModel
- rank: 2622
  id: google.genai.types.TuningDataStatsDict
  name: TuningDataStatsDict
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'The tuning data statistic values for TuningJob.


    This data type is not supported in Gemini API.


    [Note: Inherited members from TypedDict are omitted.]'
  properties:
  - signature: 'distillation_data_stats: typing.Optional[google.genai.types.DistillationDataStatsDict]'
    docstring: Output only. Statistics for distillation.
  - signature: 'preference_optimization_data_stats: typing.Optional[google.genai.types.PreferenceOptimizationDataStatsDict]'
    docstring: Output only. Statistics for preference optimization.
  - signature: 'supervised_tuning_data_stats: typing.Optional[google.genai.types.SupervisedTuningDataStatsDict]'
    docstring: The SFT Tuning data stats.
  omitted_inherited_members_from:
  - TypedDict
- rank: 2623
  id: google.genai.types.TuningDataset
  name: TuningDataset
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Supervised fine-tuning training dataset.


    [Note: Inherited members from _common.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, gcs_uri: typing.Optional[str] = None, vertex_dataset_resource: typing.Optional[str] = None, examples: typing.Optional[list[google.genai.types.TuningExample]] = None):'
  properties:
  - signature: 'gcs_uri: typing.Optional[str]'
  - signature: 'vertex_dataset_resource: typing.Optional[str]'
  - signature: 'examples: typing.Optional[list[google.genai.types.TuningExample]]'
  omitted_inherited_members_from:
  - _common.BaseModel
- rank: 2624
  id: google.genai.types.TuningDatasetDict
  name: TuningDatasetDict
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Supervised fine-tuning training dataset.


    [Note: Inherited members from TypedDict are omitted.]'
  properties:
  - signature: 'gcs_uri: typing.Optional[str]'
    docstring: GCS URI of the file containing training dataset in JSONL format.
  - signature: 'vertex_dataset_resource: typing.Optional[str]'
    docstring: 'The resource name of the Vertex Multimodal Dataset that is used as training dataset. Example: ''projects/my-project-id-or-number/locations/my-location/datasets/my-dataset-id''.'
  - signature: 'examples: typing.Optional[list[google.genai.types.TuningExampleDict]]'
    docstring: Inline examples with simple input/output text.
  omitted_inherited_members_from:
  - TypedDict
- rank: 2625
  id: google.genai.types.TuningExample
  name: TuningExample
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'A single example for tuning.


    This data type is not supported in Vertex AI.


    [Note: Inherited members from _common.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, output: typing.Optional[str] = None, text_input: typing.Optional[str] = None):'
  properties:
  - signature: 'output: typing.Optional[str]'
  - signature: 'text_input: typing.Optional[str]'
  omitted_inherited_members_from:
  - _common.BaseModel
- rank: 2626
  id: google.genai.types.TuningExampleDict
  name: TuningExampleDict
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'A single example for tuning.


    This data type is not supported in Vertex AI.


    [Note: Inherited members from TypedDict are omitted.]'
  properties:
  - signature: 'output: typing.Optional[str]'
    docstring: Required. The expected model output.
  - signature: 'text_input: typing.Optional[str]'
    docstring: Optional. Text model input.
  omitted_inherited_members_from:
  - TypedDict
- rank: 2627
  id: google.genai.types.TuningJob
  name: TuningJob
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'A tuning job.


    [Note: Inherited members from _common.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, sdk_http_response: typing.Optional[google.genai.types.HttpResponse] = None, name: typing.Optional[str] = None, state: typing.Optional[google.genai.types.JobState] = None, create_time: typing.Optional[datetime.datetime] = None, start_time: typing.Optional[datetime.datetime] = None, end_time: typing.Optional[datetime.datetime] = None, update_time: typing.Optional[datetime.datetime] = None, error: typing.Optional[google.genai.types.GoogleRpcStatus] = None, description: typing.Optional[str] = None, base_model: typing.Optional[str] = None, tuned_model: typing.Optional[google.genai.types.TunedModel] = None, pre_tuned_model: typing.Optional[google.genai.types.PreTunedModel] = None, supervised_tuning_spec: typing.Optional[google.genai.types.SupervisedTuningSpec] = None, preference_optimization_spec: typing.Optional[google.genai.types.PreferenceOptimizationSpec] = None, tuning_data_stats: typing.Optional[google.genai.types.TuningDataStats] = None, encryption_spec:
    typing.Optional[google.genai.types.EncryptionSpec] = None, partner_model_tuning_spec: typing.Optional[google.genai.types.PartnerModelTuningSpec] = None, evaluation_config: typing.Optional[google.genai.types.EvaluationConfig] = None, custom_base_model: typing.Optional[str] = None, experiment: typing.Optional[str] = None, labels: typing.Optional[dict[str, str]] = None, output_uri: typing.Optional[str] = None, pipeline_job: typing.Optional[str] = None, service_account: typing.Optional[str] = None, tuned_model_display_name: typing.Optional[str] = None, veo_tuning_spec: typing.Optional[google.genai.types.VeoTuningSpec] = None):'
  methods:
  - signature: 'def has_ended(self) -> bool:'
    docstring: Whether the tuning job has ended.
  - signature: 'def has_succeeded(self) -> bool:'
    docstring: Whether the tuning job has succeeded.
  properties:
  - signature: 'sdk_http_response: typing.Optional[google.genai.types.HttpResponse]'
  - signature: 'name: typing.Optional[str]'
  - signature: 'state: typing.Optional[google.genai.types.JobState]'
  - signature: 'create_time: typing.Optional[datetime.datetime]'
  - signature: 'start_time: typing.Optional[datetime.datetime]'
  - signature: 'end_time: typing.Optional[datetime.datetime]'
  - signature: 'update_time: typing.Optional[datetime.datetime]'
  - signature: 'error: typing.Optional[google.genai.types.GoogleRpcStatus]'
  - signature: 'description: typing.Optional[str]'
  - signature: 'base_model: typing.Optional[str]'
  - signature: 'tuned_model: typing.Optional[google.genai.types.TunedModel]'
  - signature: 'pre_tuned_model: typing.Optional[google.genai.types.PreTunedModel]'
  - signature: 'supervised_tuning_spec: typing.Optional[google.genai.types.SupervisedTuningSpec]'
  - signature: 'preference_optimization_spec: typing.Optional[google.genai.types.PreferenceOptimizationSpec]'
  - signature: 'tuning_data_stats: typing.Optional[google.genai.types.TuningDataStats]'
  - signature: 'encryption_spec: typing.Optional[google.genai.types.EncryptionSpec]'
  - signature: 'partner_model_tuning_spec: typing.Optional[google.genai.types.PartnerModelTuningSpec]'
  - signature: 'evaluation_config: typing.Optional[google.genai.types.EvaluationConfig]'
  - signature: 'custom_base_model: typing.Optional[str]'
  - signature: 'experiment: typing.Optional[str]'
  - signature: 'labels: typing.Optional[dict[str, str]]'
  - signature: 'output_uri: typing.Optional[str]'
  - signature: 'pipeline_job: typing.Optional[str]'
  - signature: 'service_account: typing.Optional[str]'
  - signature: 'tuned_model_display_name: typing.Optional[str]'
  - signature: 'veo_tuning_spec: typing.Optional[google.genai.types.VeoTuningSpec]'
  omitted_inherited_members_from:
  - _common.BaseModel
- rank: 2628
  id: google.genai.types.TuningJobDict
  name: TuningJobDict
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'A tuning job.


    [Note: Inherited members from TypedDict are omitted.]'
  properties:
  - signature: 'sdk_http_response: typing.Optional[google.genai.types.HttpResponseDict]'
    docstring: Used to retain the full HTTP response.
  - signature: 'name: typing.Optional[str]'
    docstring: 'Output only. Identifier. Resource name of a TuningJob. Format: `projects/{project}/locations/{location}/tuningJobs/{tuning_job}`'
  - signature: 'state: typing.Optional[google.genai.types.JobState]'
    docstring: Output only. The detailed state of the job.
  - signature: 'create_time: typing.Optional[datetime.datetime]'
    docstring: Output only. Time when the TuningJob was created.
  - signature: 'start_time: typing.Optional[datetime.datetime]'
    docstring: Output only. Time when the TuningJob for the first time entered the `JOB_STATE_RUNNING` state.
  - signature: 'end_time: typing.Optional[datetime.datetime]'
    docstring: 'Output only. Time when the TuningJob entered any of the following JobStates: `JOB_STATE_SUCCEEDED`, `JOB_STATE_FAILED`, `JOB_STATE_CANCELLED`, `JOB_STATE_EXPIRED`.'
  - signature: 'update_time: typing.Optional[datetime.datetime]'
    docstring: Output only. Time when the TuningJob was most recently updated.
  - signature: 'error: typing.Optional[google.genai.types.GoogleRpcStatusDict]'
    docstring: Output only. Only populated when job's state is `JOB_STATE_FAILED` or `JOB_STATE_CANCELLED`.
  - signature: 'description: typing.Optional[str]'
    docstring: Optional. The description of the TuningJob.
  - signature: 'base_model: typing.Optional[str]'
    docstring: The base model that is being tuned. See [Supported models](https://cloud.google.com/vertex-ai/generative-ai/docs/model-reference/tuning#supported_models).
  - signature: 'tuned_model: typing.Optional[google.genai.types.TunedModelDict]'
    docstring: Output only. The tuned model resources associated with this TuningJob.
  - signature: 'pre_tuned_model: typing.Optional[google.genai.types.PreTunedModelDict]'
    docstring: The pre-tuned model for continuous tuning.
  - signature: 'supervised_tuning_spec: typing.Optional[google.genai.types.SupervisedTuningSpecDict]'
    docstring: Tuning Spec for Supervised Fine Tuning.
  - signature: 'preference_optimization_spec: typing.Optional[google.genai.types.PreferenceOptimizationSpecDict]'
    docstring: Tuning Spec for Preference Optimization.
  - signature: 'tuning_data_stats: typing.Optional[google.genai.types.TuningDataStatsDict]'
    docstring: Output only. The tuning data statistics associated with this TuningJob.
  - signature: 'encryption_spec: typing.Optional[google.genai.types.EncryptionSpecDict]'
    docstring: Customer-managed encryption key options for a TuningJob. If this is set, then all resources created by the TuningJob will be encrypted with the provided encryption key.
  - signature: 'partner_model_tuning_spec: typing.Optional[google.genai.types.PartnerModelTuningSpecDict]'
    docstring: Tuning Spec for open sourced and third party Partner models.
  - signature: 'evaluation_config: typing.Optional[google.genai.types.EvaluationConfigDict]'
    docstring: Evaluation config for the tuning job.
  - signature: 'custom_base_model: typing.Optional[str]'
    docstring: Optional. The user-provided path to custom model weights. Set this field to tune a custom model. The path must be a Cloud Storage directory that contains the model weights in .safetensors format along with associated model metadata files. If this field is set, the base_model field must still be set to indicate which base model the custom model is derived from. This feature is only available for open source models.
  - signature: 'experiment: typing.Optional[str]'
    docstring: Output only. The Experiment associated with this TuningJob.
  - signature: 'labels: typing.Optional[dict[str, str]]'
    docstring: Optional. The labels with user-defined metadata to organize TuningJob and generated resources such as Model and Endpoint. Label keys and values can be no longer than 64 characters (Unicode codepoints), can only contain lowercase letters, numeric characters, underscores and dashes. International characters are allowed. See https://goo.gl/xmQnxf for more information and examples of labels.
  - signature: 'output_uri: typing.Optional[str]'
    docstring: Optional. Cloud Storage path to the directory where tuning job outputs are written to. This field is only available and required for open source models.
  - signature: 'pipeline_job: typing.Optional[str]'
    docstring: 'Output only. The resource name of the PipelineJob associated with the TuningJob. Format: `projects/{project}/locations/{location}/pipelineJobs/{pipeline_job}`.'
  - signature: 'service_account: typing.Optional[str]'
    docstring: The service account that the tuningJob workload runs as. If not specified, the Vertex AI Secure Fine-Tuned Service Agent in the project will be used. See https://cloud.google.com/iam/docs/service-agents#vertex-ai-secure-fine-tuning-service-agent Users starting the pipeline must have the `iam.serviceAccounts.actAs` permission on this service account.
  - signature: 'tuned_model_display_name: typing.Optional[str]'
    docstring: Optional. The display name of the TunedModel. The name can be up to 128 characters long and can consist of any UTF-8 characters. For continuous tuning, tuned_model_display_name will by default use the same display name as the pre-tuned model. If a new display name is provided, the tuning job will create a new model instead of a new version.
  - signature: 'veo_tuning_spec: typing.Optional[google.genai.types.VeoTuningSpecDict]'
    docstring: Tuning Spec for Veo Tuning.
  omitted_inherited_members_from:
  - TypedDict
- rank: 2629
  id: google.genai.types.TuningMethod
  name: TuningMethod
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Enum representing the tuning method.


    [Note: Inherited members from _common.CaseInSensitiveEnum are omitted.]'
  properties:
  - signature: 'SUPERVISED_FINE_TUNING: str'
    docstring: Supervised fine tuning.
  - signature: 'PREFERENCE_TUNING: str'
    docstring: Preference optimization tuning.
  omitted_inherited_members_from:
  - _common.CaseInSensitiveEnum
- rank: 2630
  id: google.genai.types.TuningMode
  name: TuningMode
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Tuning mode. This enum is not supported in Gemini API.


    [Note: Inherited members from _common.CaseInSensitiveEnum are omitted.]'
  properties:
  - signature: 'TUNING_MODE_UNSPECIFIED: str'
    docstring: Tuning mode is unspecified.
  - signature: 'TUNING_MODE_FULL: str'
    docstring: Full fine-tuning mode.
  - signature: 'TUNING_MODE_PEFT_ADAPTER: str'
    docstring: PEFT adapter tuning mode.
  omitted_inherited_members_from:
  - _common.CaseInSensitiveEnum
- rank: 2631
  id: google.genai.types.TuningOperation
  name: TuningOperation
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'A long-running operation.


    [Note: Inherited members from _common.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, sdk_http_response: typing.Optional[google.genai.types.HttpResponse] = None, name: typing.Optional[str] = None, metadata: typing.Optional[dict[str, typing.Any]] = None, done: typing.Optional[bool] = None, error: typing.Optional[dict[str, typing.Any]] = None):'
  properties:
  - signature: 'sdk_http_response: typing.Optional[google.genai.types.HttpResponse]'
  - signature: 'name: typing.Optional[str]'
  - signature: 'metadata: typing.Optional[dict[str, typing.Any]]'
  - signature: 'done: typing.Optional[bool]'
  - signature: 'error: typing.Optional[dict[str, typing.Any]]'
  omitted_inherited_members_from:
  - _common.BaseModel
- rank: 2632
  id: google.genai.types.TuningOperationDict
  name: TuningOperationDict
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'A long-running operation.


    [Note: Inherited members from TypedDict are omitted.]'
  properties:
  - signature: 'sdk_http_response: typing.Optional[google.genai.types.HttpResponseDict]'
    docstring: Used to retain the full HTTP response.
  - signature: 'name: typing.Optional[str]'
    docstring: The server-assigned name, which is only unique within the same service that originally returns it. If you use the default HTTP mapping, the `name` should be a resource name ending with `operations/{unique_id}`.
  - signature: 'metadata: typing.Optional[dict[str, typing.Any]]'
    docstring: Service-specific metadata associated with the operation. It typically contains progress information and common metadata such as create time. Some services might not provide such metadata.  Any method that returns a long-running operation should document the metadata type, if any.
  - signature: 'done: typing.Optional[bool]'
    docstring: If the value is `false`, it means the operation is still in progress. If `true`, the operation is completed, and either `error` or `response` is available.
  - signature: 'error: typing.Optional[dict[str, typing.Any]]'
    docstring: The error result of the operation in case of failure or cancellation.
  omitted_inherited_members_from:
  - TypedDict
- rank: 2633
  id: google.genai.types.TuningTask
  name: TuningTask
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'The tuning task.


    Either I2V or T2V. This enum is not supported in Gemini API.


    [Note: Inherited members from _common.CaseInSensitiveEnum are omitted.]'
  properties:
  - signature: 'TUNING_TASK_UNSPECIFIED: str'
    docstring: Default value. This value is unused.
  - signature: 'TUNING_TASK_I2V: str'
    docstring: Tuning task for image to video.
  - signature: 'TUNING_TASK_T2V: str'
    docstring: Tuning task for text to video.
  - signature: 'TUNING_TASK_R2V: str'
    docstring: Tuning task for reference to video.
  omitted_inherited_members_from:
  - _common.CaseInSensitiveEnum
- rank: 2634
  id: google.genai.types.TuningValidationDataset
  name: TuningValidationDataset
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: '[Note: Inherited members from _common.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, gcs_uri: typing.Optional[str] = None, vertex_dataset_resource: typing.Optional[str] = None):'
  properties:
  - signature: 'gcs_uri: typing.Optional[str]'
  - signature: 'vertex_dataset_resource: typing.Optional[str]'
  omitted_inherited_members_from:
  - _common.BaseModel
- rank: 2635
  id: google.genai.types.TuningValidationDatasetDict
  name: TuningValidationDatasetDict
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: '[Note: Inherited members from TypedDict are omitted.]'
  properties:
  - signature: 'gcs_uri: typing.Optional[str]'
    docstring: GCS URI of the file containing validation dataset in JSONL format.
  - signature: 'vertex_dataset_resource: typing.Optional[str]'
    docstring: 'The resource name of the Vertex Multimodal Dataset that is used as validation dataset. Example: ''projects/my-project-id-or-number/locations/my-location/datasets/my-dataset-id''.'
  omitted_inherited_members_from:
  - TypedDict
- rank: 2636
  id: google.genai.types.TurnCompleteReason
  name: TurnCompleteReason
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'The reason why the turn is complete.


    [Note: Inherited members from _common.CaseInSensitiveEnum are omitted.]'
  properties:
  - signature: 'TURN_COMPLETE_REASON_UNSPECIFIED: str'
    docstring: Default value. Reason is unspecified.
  - signature: 'MALFORMED_FUNCTION_CALL: str'
    docstring: The function call generated by the model is invalid.
  - signature: 'RESPONSE_REJECTED: str'
    docstring: The response is rejected by the model.
  - signature: 'NEED_MORE_INPUT: str'
    docstring: Needs more input from the user.
  omitted_inherited_members_from:
  - _common.CaseInSensitiveEnum
- rank: 2637
  id: google.genai.types.TurnCoverage
  name: TurnCoverage
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Options about which input is included in the user''s turn.


    [Note: Inherited members from _common.CaseInSensitiveEnum are omitted.]'
  properties:
  - signature: 'TURN_COVERAGE_UNSPECIFIED: str'
    docstring: If unspecified, the default behavior is `TURN_INCLUDES_ONLY_ACTIVITY`.
  - signature: 'TURN_INCLUDES_ONLY_ACTIVITY: str'
    docstring: The users turn only includes activity since the last turn, excluding inactivity (e.g. silence on the audio stream). This is the default behavior.
  - signature: 'TURN_INCLUDES_ALL_INPUT: str'
    docstring: The users turn includes all realtime input since the last turn, including inactivity (e.g. silence on the audio stream).
  omitted_inherited_members_from:
  - _common.CaseInSensitiveEnum
- rank: 2638
  id: google.genai.types.Type
  name: Type
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'The type of the data.


    [Note: Inherited members from _common.CaseInSensitiveEnum are omitted.]'
  properties:
  - signature: 'TYPE_UNSPECIFIED: str'
    docstring: Not specified, should not be used.
  - signature: 'STRING: str'
    docstring: OpenAPI string type
  - signature: 'NUMBER: str'
    docstring: OpenAPI number type
  - signature: 'INTEGER: str'
    docstring: OpenAPI integer type
  - signature: 'BOOLEAN: str'
    docstring: OpenAPI boolean type
  - signature: 'ARRAY: str'
    docstring: OpenAPI array type
  - signature: 'OBJECT: str'
    docstring: OpenAPI object type
  - signature: 'NULL: str'
    docstring: Null type
  omitted_inherited_members_from:
  - _common.CaseInSensitiveEnum
- rank: 2639
  id: google.genai.types.UpdateCachedContentConfig
  name: UpdateCachedContentConfig
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Optional parameters for caches.update method.


    [Note: Inherited members from _common.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, http_options: typing.Optional[google.genai.types.HttpOptions] = None, ttl: typing.Optional[str] = None, expire_time: typing.Optional[datetime.datetime] = None):'
  properties:
  - signature: 'http_options: typing.Optional[google.genai.types.HttpOptions]'
  - signature: 'ttl: typing.Optional[str]'
  - signature: 'expire_time: typing.Optional[datetime.datetime]'
  omitted_inherited_members_from:
  - _common.BaseModel
- rank: 2640
  id: google.genai.types.UpdateCachedContentConfigDict
  name: UpdateCachedContentConfigDict
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Optional parameters for caches.update method.


    [Note: Inherited members from TypedDict are omitted.]'
  properties:
  - signature: 'http_options: typing.Optional[google.genai.types.HttpOptionsDict]'
    docstring: Used to override HTTP request options.
  - signature: 'ttl: typing.Optional[str]'
    docstring: 'The TTL for this resource. The expiration time is computed: now + TTL. It is a duration string, with up to nine fractional digits, terminated by ''s''. Example: "3.5s".'
  - signature: 'expire_time: typing.Optional[datetime.datetime]'
    docstring: 'Timestamp of when this resource is considered expired. Uses RFC 3339 format, Example: 2014-10-02T15:01:23Z.'
  omitted_inherited_members_from:
  - TypedDict
- rank: 2641
  id: google.genai.types.UpdateModelConfig
  name: UpdateModelConfig
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Configuration for updating a tuned model.


    [Note: Inherited members from _common.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, http_options: typing.Optional[google.genai.types.HttpOptions] = None, display_name: typing.Optional[str] = None, description: typing.Optional[str] = None, default_checkpoint_id: typing.Optional[str] = None):'
  properties:
  - signature: 'http_options: typing.Optional[google.genai.types.HttpOptions]'
  - signature: 'display_name: typing.Optional[str]'
  - signature: 'description: typing.Optional[str]'
  - signature: 'default_checkpoint_id: typing.Optional[str]'
  omitted_inherited_members_from:
  - _common.BaseModel
- rank: 2642
  id: google.genai.types.UpdateModelConfigDict
  name: UpdateModelConfigDict
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Configuration for updating a tuned model.


    [Note: Inherited members from TypedDict are omitted.]'
  properties:
  - signature: 'http_options: typing.Optional[google.genai.types.HttpOptionsDict]'
    docstring: Used to override HTTP request options.
  - signature: 'display_name: typing.Optional[str]'
  - signature: 'description: typing.Optional[str]'
  - signature: 'default_checkpoint_id: typing.Optional[str]'
  omitted_inherited_members_from:
  - TypedDict
- rank: 2643
  id: google.genai.types.UploadFileConfig
  name: UploadFileConfig
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Used to override the default configuration.


    [Note: Inherited members from _common.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, http_options: typing.Optional[google.genai.types.HttpOptions] = None, name: typing.Optional[str] = None, mime_type: typing.Optional[str] = None, display_name: typing.Optional[str] = None):'
  properties:
  - signature: 'http_options: typing.Optional[google.genai.types.HttpOptions]'
  - signature: 'name: typing.Optional[str]'
  - signature: 'mime_type: typing.Optional[str]'
  - signature: 'display_name: typing.Optional[str]'
  omitted_inherited_members_from:
  - _common.BaseModel
- rank: 2644
  id: google.genai.types.UploadFileConfigDict
  name: UploadFileConfigDict
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Used to override the default configuration.


    [Note: Inherited members from TypedDict are omitted.]'
  properties:
  - signature: 'http_options: typing.Optional[google.genai.types.HttpOptionsDict]'
    docstring: Used to override HTTP request options.
  - signature: 'name: typing.Optional[str]'
    docstring: The name of the file in the destination (e.g., 'files/sample-image'. If not provided one will be generated.
  - signature: 'mime_type: typing.Optional[str]'
    docstring: 'mime_type: The MIME type of the file. If not provided, it will be inferred from the file extension.'
  - signature: 'display_name: typing.Optional[str]'
    docstring: Optional display name of the file.
  omitted_inherited_members_from:
  - TypedDict
- rank: 2645
  id: google.genai.types.UploadToFileSearchStoreConfig
  name: UploadToFileSearchStoreConfig
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Optional parameters for uploading a file to a FileSearchStore.


    [Note: Inherited members from _common.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, http_options: typing.Optional[google.genai.types.HttpOptions] = None, should_return_http_response: typing.Optional[bool] = None, mime_type: typing.Optional[str] = None, display_name: typing.Optional[str] = None, custom_metadata: typing.Optional[list[google.genai.types.CustomMetadata]] = None, chunking_config: typing.Optional[google.genai.types.ChunkingConfig] = None):'
  properties:
  - signature: 'http_options: typing.Optional[google.genai.types.HttpOptions]'
  - signature: 'should_return_http_response: typing.Optional[bool]'
  - signature: 'mime_type: typing.Optional[str]'
  - signature: 'display_name: typing.Optional[str]'
  - signature: 'custom_metadata: typing.Optional[list[google.genai.types.CustomMetadata]]'
  - signature: 'chunking_config: typing.Optional[google.genai.types.ChunkingConfig]'
  omitted_inherited_members_from:
  - _common.BaseModel
- rank: 2646
  id: google.genai.types.UploadToFileSearchStoreConfigDict
  name: UploadToFileSearchStoreConfigDict
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Optional parameters for uploading a file to a FileSearchStore.


    [Note: Inherited members from TypedDict are omitted.]'
  properties:
  - signature: 'http_options: typing.Optional[google.genai.types.HttpOptionsDict]'
    docstring: Used to override HTTP request options.
  - signature: 'should_return_http_response: typing.Optional[bool]'
    docstring: If true, the raw HTTP response will be returned in the 'sdk_http_response' field.
  - signature: 'mime_type: typing.Optional[str]'
    docstring: MIME type of the file to be uploaded. If not provided, it will be inferred from the file extension.
  - signature: 'display_name: typing.Optional[str]'
    docstring: Display name of the created document.
  - signature: 'custom_metadata: typing.Optional[list[google.genai.types.CustomMetadataDict]]'
    docstring: User provided custom metadata stored as key-value pairs used for querying.
  - signature: 'chunking_config: typing.Optional[google.genai.types.ChunkingConfigDict]'
    docstring: Config for telling the service how to chunk the file.
  omitted_inherited_members_from:
  - TypedDict
- rank: 2647
  id: google.genai.types.UploadToFileSearchStoreOperation
  name: UploadToFileSearchStoreOperation
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Long-running operation for uploading a file to a FileSearchStore.


    [Note: Inherited members from ABC, _common.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, name: typing.Optional[str] = None, metadata: typing.Optional[dict[str, typing.Any]] = None, done: typing.Optional[bool] = None, error: typing.Optional[dict[str, typing.Any]] = None, response: typing.Optional[google.genai.types.UploadToFileSearchStoreResponse] = None):'
  methods:
  - signature: 'def from_api_response(cls, api_response: typing.Any, is_vertex_ai: bool) -> typing_extensions.Self:'
    docstring: Instantiates a UploadToFileSearchStoreOperation from an API response.
  properties:
  - signature: 'response: typing.Optional[google.genai.types.UploadToFileSearchStoreResponse]'
  inherited_methods:
    Operation:
    - signature: 'def from_api_response(cls, api_response: typing.Any, is_vertex_ai: bool) -> typing_extensions.Self:'
      docstring: Creates an Operation from an API response.
  inherited_properties:
    Operation:
    - signature: 'name: typing.Optional[str]'
    - signature: 'metadata: typing.Optional[dict[str, typing.Any]]'
    - signature: 'done: typing.Optional[bool]'
    - signature: 'error: typing.Optional[dict[str, typing.Any]]'
  omitted_inherited_members_from:
  - ABC
  - _common.BaseModel
- rank: 2648
  id: google.genai.types.UploadToFileSearchStoreOperation.from_api_response
  name: from_api_response
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: Instantiates a UploadToFileSearchStoreOperation from an API response.
  signature: 'def from_api_response(cls, api_response: typing.Any, is_vertex_ai: bool) -> typing_extensions.Self:'
- rank: 2649
  id: google.genai.types.UploadToFileSearchStoreResponse
  name: UploadToFileSearchStoreResponse
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'The response when long-running operation for uploading a file to a FileSearchStore complete.


    [Note: Inherited members from _common.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, sdk_http_response: typing.Optional[google.genai.types.HttpResponse] = None, parent: typing.Optional[str] = None, document_name: typing.Optional[str] = None):'
  properties:
  - signature: 'sdk_http_response: typing.Optional[google.genai.types.HttpResponse]'
  - signature: 'parent: typing.Optional[str]'
  - signature: 'document_name: typing.Optional[str]'
  omitted_inherited_members_from:
  - _common.BaseModel
- rank: 2650
  id: google.genai.types.UploadToFileSearchStoreResponseDict
  name: UploadToFileSearchStoreResponseDict
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'The response when long-running operation for uploading a file to a FileSearchStore complete.


    [Note: Inherited members from TypedDict are omitted.]'
  properties:
  - signature: 'sdk_http_response: typing.Optional[google.genai.types.HttpResponseDict]'
    docstring: Used to retain the full HTTP response.
  - signature: 'parent: typing.Optional[str]'
    docstring: The name of the FileSearchStore containing Documents.
  - signature: 'document_name: typing.Optional[str]'
    docstring: The identifier for the Document imported.
  omitted_inherited_members_from:
  - TypedDict
- rank: 2651
  id: google.genai.types.UploadToFileSearchStoreResumableResponse
  name: UploadToFileSearchStoreResumableResponse
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Response for the resumable upload method.


    [Note: Inherited members from _common.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, sdk_http_response: typing.Optional[google.genai.types.HttpResponse] = None):'
  properties:
  - signature: 'sdk_http_response: typing.Optional[google.genai.types.HttpResponse]'
  omitted_inherited_members_from:
  - _common.BaseModel
- rank: 2652
  id: google.genai.types.UploadToFileSearchStoreResumableResponseDict
  name: UploadToFileSearchStoreResumableResponseDict
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Response for the resumable upload method.


    [Note: Inherited members from TypedDict are omitted.]'
  properties:
  - signature: 'sdk_http_response: typing.Optional[google.genai.types.HttpResponseDict]'
    docstring: Used to retain the full HTTP response.
  omitted_inherited_members_from:
  - TypedDict
- rank: 2653
  id: google.genai.types.UpscaleImageConfig
  name: UpscaleImageConfig
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Configuration for upscaling an image.


    For more information on this configuration, refer to

    the `Imagen API reference documentation

    <https://cloud.google.com/vertex-ai/generative-ai/docs/model-reference/imagen-api>`_.


    [Note: Inherited members from _common.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, http_options: typing.Optional[google.genai.types.HttpOptions] = None, output_gcs_uri: typing.Optional[str] = None, safety_filter_level: typing.Optional[google.genai.types.SafetyFilterLevel] = None, person_generation: typing.Optional[google.genai.types.PersonGeneration] = None, include_rai_reason: typing.Optional[bool] = None, output_mime_type: typing.Optional[str] = None, output_compression_quality: typing.Optional[int] = None, enhance_input_image: typing.Optional[bool] = None, image_preservation_factor: typing.Optional[float] = None, labels: typing.Optional[dict[str, str]] = None):'
  properties:
  - signature: 'http_options: typing.Optional[google.genai.types.HttpOptions]'
  - signature: 'output_gcs_uri: typing.Optional[str]'
  - signature: 'safety_filter_level: typing.Optional[google.genai.types.SafetyFilterLevel]'
  - signature: 'person_generation: typing.Optional[google.genai.types.PersonGeneration]'
  - signature: 'include_rai_reason: typing.Optional[bool]'
  - signature: 'output_mime_type: typing.Optional[str]'
  - signature: 'output_compression_quality: typing.Optional[int]'
  - signature: 'enhance_input_image: typing.Optional[bool]'
  - signature: 'image_preservation_factor: typing.Optional[float]'
  - signature: 'labels: typing.Optional[dict[str, str]]'
  omitted_inherited_members_from:
  - _common.BaseModel
- rank: 2654
  id: google.genai.types.UpscaleImageConfigDict
  name: UpscaleImageConfigDict
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Configuration for upscaling an image.


    For more information on this configuration, refer to

    the `Imagen API reference documentation

    <https://cloud.google.com/vertex-ai/generative-ai/docs/model-reference/imagen-api>`_.


    [Note: Inherited members from TypedDict are omitted.]'
  properties:
  - signature: 'http_options: typing.Optional[google.genai.types.HttpOptionsDict]'
    docstring: Used to override HTTP request options.
  - signature: 'output_gcs_uri: typing.Optional[str]'
    docstring: Cloud Storage URI used to store the generated images.
  - signature: 'safety_filter_level: typing.Optional[google.genai.types.SafetyFilterLevel]'
    docstring: Filter level for safety filtering.
  - signature: 'person_generation: typing.Optional[google.genai.types.PersonGeneration]'
    docstring: Allows generation of people by the model.
  - signature: 'include_rai_reason: typing.Optional[bool]'
    docstring: 'Whether to include a reason for filtered-out images in the

      response.'
  - signature: 'output_mime_type: typing.Optional[str]'
    docstring: The image format that the output should be saved as.
  - signature: 'output_compression_quality: typing.Optional[int]'
    docstring: 'The level of compression. Only applicable if the

      ``output_mime_type`` is ``image/jpeg``.'
  - signature: 'enhance_input_image: typing.Optional[bool]'
    docstring: 'Whether to add an image enhancing step before upscaling.

      It is expected to suppress the noise and JPEG compression artifacts

      from the input image.'
  - signature: 'image_preservation_factor: typing.Optional[float]'
    docstring: 'With a higher image preservation factor, the original image

      pixels are more respected. With a lower image preservation factor, the

      output image will have be more different from the input image, but

      with finer details and less noise.'
  - signature: 'labels: typing.Optional[dict[str, str]]'
    docstring: User specified labels to track billing usage.
  omitted_inherited_members_from:
  - TypedDict
- rank: 2655
  id: google.genai.types.UpscaleImageParameters
  name: UpscaleImageParameters
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'User-facing config UpscaleImageParameters.


    [Note: Inherited members from _common.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, model: typing.Optional[str] = None, image: typing.Optional[google.genai.types.Image] = None, upscale_factor: typing.Optional[str] = None, config: typing.Optional[google.genai.types.UpscaleImageConfig] = None):'
  properties:
  - signature: 'model: typing.Optional[str]'
  - signature: 'image: typing.Optional[google.genai.types.Image]'
  - signature: 'upscale_factor: typing.Optional[str]'
  - signature: 'config: typing.Optional[google.genai.types.UpscaleImageConfig]'
  omitted_inherited_members_from:
  - _common.BaseModel
- rank: 2656
  id: google.genai.types.UpscaleImageParametersDict
  name: UpscaleImageParametersDict
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'User-facing config UpscaleImageParameters.


    [Note: Inherited members from TypedDict are omitted.]'
  properties:
  - signature: 'model: typing.Optional[str]'
    docstring: The model to use.
  - signature: 'image: typing.Optional[google.genai.types.ImageDict]'
    docstring: The input image to upscale.
  - signature: 'upscale_factor: typing.Optional[str]'
    docstring: The factor to upscale the image (x2 or x4).
  - signature: 'config: typing.Optional[google.genai.types.UpscaleImageConfigDict]'
    docstring: Configuration for upscaling.
  omitted_inherited_members_from:
  - TypedDict
- rank: 2657
  id: google.genai.types.UpscaleImageResponse
  name: UpscaleImageResponse
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: '[Note: Inherited members from _common.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, sdk_http_response: typing.Optional[google.genai.types.HttpResponse] = None, generated_images: typing.Optional[list[google.genai.types.GeneratedImage]] = None):'
  properties:
  - signature: 'sdk_http_response: typing.Optional[google.genai.types.HttpResponse]'
  - signature: 'generated_images: typing.Optional[list[google.genai.types.GeneratedImage]]'
  omitted_inherited_members_from:
  - _common.BaseModel
- rank: 2658
  id: google.genai.types.UpscaleImageResponseDict
  name: UpscaleImageResponseDict
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: '[Note: Inherited members from TypedDict are omitted.]'
  properties:
  - signature: 'sdk_http_response: typing.Optional[google.genai.types.HttpResponseDict]'
    docstring: Used to retain the full HTTP response.
  - signature: 'generated_images: typing.Optional[list[google.genai.types.GeneratedImageDict]]'
    docstring: Generated images.
  omitted_inherited_members_from:
  - TypedDict
- rank: 2659
  id: google.genai.types.UrlContext
  name: UrlContext
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Tool to support URL context.


    [Note: Inherited members from _common.BaseModel are omitted.]'
  omitted_inherited_members_from:
  - _common.BaseModel
- rank: 2660
  id: google.genai.types.UrlContextDict
  name: UrlContextDict
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Tool to support URL context.


    [Note: Inherited members from TypedDict are omitted.]'
  omitted_inherited_members_from:
  - TypedDict
- rank: 2661
  id: google.genai.types.UrlContextMetadata
  name: UrlContextMetadata
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Metadata related to url context retrieval tool.


    [Note: Inherited members from _common.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, url_metadata: typing.Optional[list[google.genai.types.UrlMetadata]] = None):'
  properties:
  - signature: 'url_metadata: typing.Optional[list[google.genai.types.UrlMetadata]]'
  omitted_inherited_members_from:
  - _common.BaseModel
- rank: 2662
  id: google.genai.types.UrlContextMetadataDict
  name: UrlContextMetadataDict
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Metadata related to url context retrieval tool.


    [Note: Inherited members from TypedDict are omitted.]'
  properties:
  - signature: 'url_metadata: typing.Optional[list[google.genai.types.UrlMetadataDict]]'
    docstring: Output only. List of url context.
  omitted_inherited_members_from:
  - TypedDict
- rank: 2663
  id: google.genai.types.UrlMetadata
  name: UrlMetadata
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Context of the a single url retrieval.


    [Note: Inherited members from _common.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, retrieved_url: typing.Optional[str] = None, url_retrieval_status: typing.Optional[google.genai.types.UrlRetrievalStatus] = None):'
  properties:
  - signature: 'retrieved_url: typing.Optional[str]'
  - signature: 'url_retrieval_status: typing.Optional[google.genai.types.UrlRetrievalStatus]'
  omitted_inherited_members_from:
  - _common.BaseModel
- rank: 2664
  id: google.genai.types.UrlMetadataDict
  name: UrlMetadataDict
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Context of the a single url retrieval.


    [Note: Inherited members from TypedDict are omitted.]'
  properties:
  - signature: 'retrieved_url: typing.Optional[str]'
    docstring: Retrieved url by the tool.
  - signature: 'url_retrieval_status: typing.Optional[google.genai.types.UrlRetrievalStatus]'
    docstring: Status of the url retrieval.
  omitted_inherited_members_from:
  - TypedDict
- rank: 2665
  id: google.genai.types.UrlRetrievalStatus
  name: UrlRetrievalStatus
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Status of the url retrieval.


    [Note: Inherited members from _common.CaseInSensitiveEnum are omitted.]'
  properties:
  - signature: 'URL_RETRIEVAL_STATUS_UNSPECIFIED: str'
    docstring: Default value. This value is unused.
  - signature: 'URL_RETRIEVAL_STATUS_SUCCESS: str'
    docstring: Url retrieval is successful.
  - signature: 'URL_RETRIEVAL_STATUS_ERROR: str'
    docstring: Url retrieval is failed due to error.
  - signature: 'URL_RETRIEVAL_STATUS_PAYWALL: str'
    docstring: Url retrieval is failed because the content is behind paywall. This enum value is not supported in Vertex AI.
  - signature: 'URL_RETRIEVAL_STATUS_UNSAFE: str'
    docstring: Url retrieval is failed because the content is unsafe. This enum value is not supported in Vertex AI.
  omitted_inherited_members_from:
  - _common.CaseInSensitiveEnum
- rank: 2666
  id: google.genai.types.UsageMetadata
  name: UsageMetadata
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Usage metadata about response(s).


    [Note: Inherited members from _common.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, prompt_token_count: typing.Optional[int] = None, cached_content_token_count: typing.Optional[int] = None, response_token_count: typing.Optional[int] = None, tool_use_prompt_token_count: typing.Optional[int] = None, thoughts_token_count: typing.Optional[int] = None, total_token_count: typing.Optional[int] = None, prompt_tokens_details: typing.Optional[list[google.genai.types.ModalityTokenCount]] = None, cache_tokens_details: typing.Optional[list[google.genai.types.ModalityTokenCount]] = None, response_tokens_details: typing.Optional[list[google.genai.types.ModalityTokenCount]] = None, tool_use_prompt_tokens_details: typing.Optional[list[google.genai.types.ModalityTokenCount]] = None, traffic_type: typing.Optional[google.genai.types.TrafficType] = None):'
  properties:
  - signature: 'prompt_token_count: typing.Optional[int]'
  - signature: 'cached_content_token_count: typing.Optional[int]'
  - signature: 'response_token_count: typing.Optional[int]'
  - signature: 'tool_use_prompt_token_count: typing.Optional[int]'
  - signature: 'thoughts_token_count: typing.Optional[int]'
  - signature: 'total_token_count: typing.Optional[int]'
  - signature: 'prompt_tokens_details: typing.Optional[list[google.genai.types.ModalityTokenCount]]'
  - signature: 'cache_tokens_details: typing.Optional[list[google.genai.types.ModalityTokenCount]]'
  - signature: 'response_tokens_details: typing.Optional[list[google.genai.types.ModalityTokenCount]]'
  - signature: 'tool_use_prompt_tokens_details: typing.Optional[list[google.genai.types.ModalityTokenCount]]'
  - signature: 'traffic_type: typing.Optional[google.genai.types.TrafficType]'
  omitted_inherited_members_from:
  - _common.BaseModel
- rank: 2667
  id: google.genai.types.UsageMetadataDict
  name: UsageMetadataDict
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Usage metadata about response(s).


    [Note: Inherited members from TypedDict are omitted.]'
  properties:
  - signature: 'prompt_token_count: typing.Optional[int]'
    docstring: Number of tokens in the prompt. When `cached_content` is set, this is still the total effective prompt size meaning this includes the number of tokens in the cached content.
  - signature: 'cached_content_token_count: typing.Optional[int]'
    docstring: Number of tokens in the cached part of the prompt (the cached content).
  - signature: 'response_token_count: typing.Optional[int]'
    docstring: Total number of tokens across all the generated response candidates.
  - signature: 'tool_use_prompt_token_count: typing.Optional[int]'
    docstring: Number of tokens present in tool-use prompt(s).
  - signature: 'thoughts_token_count: typing.Optional[int]'
    docstring: Number of tokens of thoughts for thinking models.
  - signature: 'total_token_count: typing.Optional[int]'
    docstring: Total token count for prompt, response candidates, and tool-use prompts(if present).
  - signature: 'prompt_tokens_details: typing.Optional[list[google.genai.types.ModalityTokenCountDict]]'
    docstring: List of modalities that were processed in the request input.
  - signature: 'cache_tokens_details: typing.Optional[list[google.genai.types.ModalityTokenCountDict]]'
    docstring: List of modalities that were processed in the cache input.
  - signature: 'response_tokens_details: typing.Optional[list[google.genai.types.ModalityTokenCountDict]]'
    docstring: List of modalities that were returned in the response.
  - signature: 'tool_use_prompt_tokens_details: typing.Optional[list[google.genai.types.ModalityTokenCountDict]]'
    docstring: List of modalities that were processed in the tool-use prompt.
  - signature: 'traffic_type: typing.Optional[google.genai.types.TrafficType]'
    docstring: 'Traffic type. This shows whether a request consumes Pay-As-You-Go

      or Provisioned Throughput quota.'
  omitted_inherited_members_from:
  - TypedDict
- rank: 2668
  id: google.genai.types.UserContent
  name: UserContent
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: "UserContent facilitates the creation of a Content object with a user role.\n\nExample usages:\n\n- Create a user Content object with a string:\n  user_content = UserContent(\"Why is the sky blue?\")\n- Create a user Content object with a file data Part object:\n  user_content = UserContent(Part.from_uri(file_uril=\"gs://bucket/file.txt\",\n  mime_type=\"text/plain\"))\n- Create a user Content object with byte data Part object:\n  user_content = UserContent(Part.from_bytes(data=b\"Hello, World!\",\n  mime_type=\"text/plain\"))\n\n  You can create a user Content object using other classmethods in the Part\n  class as well.\n  You can also create a user Content using a list of Part objects or strings.\n\n[Note: Inherited members from _common.BaseModel are omitted.]"
  constructor_signature: 'def __init__(self, parts: typing.Union[PartUnionDict, list[PartUnionDict], list[google.genai.types.Part]]):'
  properties:
  - signature: 'role: typing.Literal[user]'
  - signature: 'parts: list[google.genai.types.Part]'
  inherited_properties:
    Content:
    - signature: 'parts: typing.Optional[list[google.genai.types.Part]]'
    - signature: 'role: typing.Optional[str]'
  omitted_inherited_members_from:
  - _common.BaseModel
- rank: 2669
  id: google.genai.types.UserContent.__init__
  name: __init__
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def __init__(self, parts: typing.Union[PartUnionDict, list[PartUnionDict], list[google.genai.types.Part]]):'
- rank: 2670
  id: google.genai.types.VeoHyperParameters
  name: VeoHyperParameters
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Hyperparameters for Veo. This data type is not supported in Gemini API.


    [Note: Inherited members from _common.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, epoch_count: typing.Optional[int] = None, learning_rate_multiplier: typing.Optional[float] = None, tuning_task: typing.Optional[google.genai.types.TuningTask] = None):'
  properties:
  - signature: 'epoch_count: typing.Optional[int]'
  - signature: 'learning_rate_multiplier: typing.Optional[float]'
  - signature: 'tuning_task: typing.Optional[google.genai.types.TuningTask]'
  omitted_inherited_members_from:
  - _common.BaseModel
- rank: 2671
  id: google.genai.types.VeoHyperParametersDict
  name: VeoHyperParametersDict
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Hyperparameters for Veo. This data type is not supported in Gemini API.


    [Note: Inherited members from TypedDict are omitted.]'
  properties:
  - signature: 'epoch_count: typing.Optional[int]'
    docstring: Optional. Number of complete passes the model makes over the entire training dataset during training.
  - signature: 'learning_rate_multiplier: typing.Optional[float]'
    docstring: Optional. Multiplier for adjusting the default learning rate.
  - signature: 'tuning_task: typing.Optional[google.genai.types.TuningTask]'
    docstring: Optional. The tuning task. Either I2V or T2V.
  omitted_inherited_members_from:
  - TypedDict
- rank: 2672
  id: google.genai.types.VeoTuningSpec
  name: VeoTuningSpec
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Tuning Spec for Veo Model Tuning.


    This data type is not supported in Gemini API.


    [Note: Inherited members from _common.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, hyper_parameters: typing.Optional[google.genai.types.VeoHyperParameters] = None, training_dataset_uri: typing.Optional[str] = None, validation_dataset_uri: typing.Optional[str] = None):'
  properties:
  - signature: 'hyper_parameters: typing.Optional[google.genai.types.VeoHyperParameters]'
  - signature: 'training_dataset_uri: typing.Optional[str]'
  - signature: 'validation_dataset_uri: typing.Optional[str]'
  omitted_inherited_members_from:
  - _common.BaseModel
- rank: 2673
  id: google.genai.types.VeoTuningSpecDict
  name: VeoTuningSpecDict
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Tuning Spec for Veo Model Tuning.


    This data type is not supported in Gemini API.


    [Note: Inherited members from TypedDict are omitted.]'
  properties:
  - signature: 'hyper_parameters: typing.Optional[google.genai.types.VeoHyperParametersDict]'
    docstring: Optional. Hyperparameters for Veo.
  - signature: 'training_dataset_uri: typing.Optional[str]'
    docstring: Required. Training dataset used for tuning. The dataset can be specified as either a Cloud Storage path to a JSONL file or as the resource name of a Vertex Multimodal Dataset.
  - signature: 'validation_dataset_uri: typing.Optional[str]'
    docstring: Optional. Validation dataset used for tuning. The dataset can be specified as either a Cloud Storage path to a JSONL file or as the resource name of a Vertex Multimodal Dataset.
  omitted_inherited_members_from:
  - TypedDict
- rank: 2674
  id: google.genai.types.VertexAISearch
  name: VertexAISearch
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Retrieve from Vertex AI Search datastore or engine for grounding.


    datastore and engine are mutually exclusive. See

    https://cloud.google.com/products/agent-builder. This data type is not

    supported in Gemini API.


    [Note: Inherited members from _common.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, data_store_specs: typing.Optional[list[google.genai.types.VertexAISearchDataStoreSpec]] = None, datastore: typing.Optional[str] = None, engine: typing.Optional[str] = None, filter: typing.Optional[str] = None, max_results: typing.Optional[int] = None):'
  properties:
  - signature: 'data_store_specs: typing.Optional[list[google.genai.types.VertexAISearchDataStoreSpec]]'
  - signature: 'datastore: typing.Optional[str]'
  - signature: 'engine: typing.Optional[str]'
  - signature: 'filter: typing.Optional[str]'
  - signature: 'max_results: typing.Optional[int]'
  omitted_inherited_members_from:
  - _common.BaseModel
- rank: 2675
  id: google.genai.types.VertexAISearchDataStoreSpec
  name: VertexAISearchDataStoreSpec
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Define data stores within engine to filter on in a search call and configurations for those data stores.


    For more information, see

    https://cloud.google.com/generative-ai-app-builder/docs/reference/rpc/google.cloud.discoveryengine.v1#datastorespec.

    This data type is not supported in Gemini API.


    [Note: Inherited members from _common.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, data_store: typing.Optional[str] = None, filter: typing.Optional[str] = None):'
  properties:
  - signature: 'data_store: typing.Optional[str]'
  - signature: 'filter: typing.Optional[str]'
  omitted_inherited_members_from:
  - _common.BaseModel
- rank: 2676
  id: google.genai.types.VertexAISearchDataStoreSpecDict
  name: VertexAISearchDataStoreSpecDict
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Define data stores within engine to filter on in a search call and configurations for those data stores.


    For more information, see

    https://cloud.google.com/generative-ai-app-builder/docs/reference/rpc/google.cloud.discoveryengine.v1#datastorespec.

    This data type is not supported in Gemini API.


    [Note: Inherited members from TypedDict are omitted.]'
  properties:
  - signature: 'data_store: typing.Optional[str]'
    docstring: 'Full resource name of DataStore, such as Format: `projects/{project}/locations/{location}/collections/{collection}/dataStores/{dataStore}`'
  - signature: 'filter: typing.Optional[str]'
    docstring: Optional. Filter specification to filter documents in the data store specified by data_store field. For more information on filtering, see [Filtering](https://cloud.google.com/generative-ai-app-builder/docs/filter-search-metadata)
  omitted_inherited_members_from:
  - TypedDict
- rank: 2677
  id: google.genai.types.VertexAISearchDict
  name: VertexAISearchDict
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Retrieve from Vertex AI Search datastore or engine for grounding.


    datastore and engine are mutually exclusive. See

    https://cloud.google.com/products/agent-builder. This data type is not

    supported in Gemini API.


    [Note: Inherited members from TypedDict are omitted.]'
  properties:
  - signature: 'data_store_specs: typing.Optional[list[google.genai.types.VertexAISearchDataStoreSpecDict]]'
    docstring: Specifications that define the specific DataStores to be searched, along with configurations for those data stores. This is only considered for Engines with multiple data stores. It should only be set if engine is used.
  - signature: 'datastore: typing.Optional[str]'
    docstring: 'Optional. Fully-qualified Vertex AI Search data store resource ID. Format: `projects/{project}/locations/{location}/collections/{collection}/dataStores/{dataStore}`'
  - signature: 'engine: typing.Optional[str]'
    docstring: 'Optional. Fully-qualified Vertex AI Search engine resource ID. Format: `projects/{project}/locations/{location}/collections/{collection}/engines/{engine}`'
  - signature: 'filter: typing.Optional[str]'
    docstring: Optional. Filter strings to be passed to the search API.
  - signature: 'max_results: typing.Optional[int]'
    docstring: Optional. Number of search results to return per query. The default value is 10. The maximumm allowed value is 10.
  omitted_inherited_members_from:
  - TypedDict
- rank: 2678
  id: google.genai.types.VertexRagStore
  name: VertexRagStore
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Retrieve from Vertex RAG Store for grounding.


    This data type is not supported in Gemini API.


    [Note: Inherited members from _common.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, rag_corpora: typing.Optional[list[str]] = None, rag_resources: typing.Optional[list[google.genai.types.VertexRagStoreRagResource]] = None, rag_retrieval_config: typing.Optional[google.genai.types.RagRetrievalConfig] = None, similarity_top_k: typing.Optional[int] = None, store_context: typing.Optional[bool] = None, vector_distance_threshold: typing.Optional[float] = None):'
  properties:
  - signature: 'rag_corpora: typing.Optional[list[str]]'
  - signature: 'rag_resources: typing.Optional[list[google.genai.types.VertexRagStoreRagResource]]'
  - signature: 'rag_retrieval_config: typing.Optional[google.genai.types.RagRetrievalConfig]'
  - signature: 'similarity_top_k: typing.Optional[int]'
  - signature: 'store_context: typing.Optional[bool]'
  - signature: 'vector_distance_threshold: typing.Optional[float]'
  omitted_inherited_members_from:
  - _common.BaseModel
- rank: 2679
  id: google.genai.types.VertexRagStoreDict
  name: VertexRagStoreDict
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Retrieve from Vertex RAG Store for grounding.


    This data type is not supported in Gemini API.


    [Note: Inherited members from TypedDict are omitted.]'
  properties:
  - signature: 'rag_corpora: typing.Optional[list[str]]'
    docstring: Optional. Deprecated. Please use rag_resources instead.
  - signature: 'rag_resources: typing.Optional[list[google.genai.types.VertexRagStoreRagResourceDict]]'
    docstring: Optional. The representation of the rag source. It can be used to specify corpus only or ragfiles. Currently only support one corpus or multiple files from one corpus. In the future we may open up multiple corpora support.
  - signature: 'rag_retrieval_config: typing.Optional[google.genai.types.RagRetrievalConfigDict]'
    docstring: Optional. The retrieval config for the Rag query.
  - signature: 'similarity_top_k: typing.Optional[int]'
    docstring: Optional. Number of top k results to return from the selected corpora.
  - signature: 'store_context: typing.Optional[bool]'
    docstring: Optional. Currently only supported for Gemini Multimodal Live API. In Gemini Multimodal Live API, if `store_context` bool is specified, Gemini will leverage it to automatically memorize the interactions between the client and Gemini, and retrieve context when needed to augment the response generation for users' ongoing and future interactions.
  - signature: 'vector_distance_threshold: typing.Optional[float]'
    docstring: Optional. Only return results with vector distance smaller than the threshold.
  omitted_inherited_members_from:
  - TypedDict
- rank: 2680
  id: google.genai.types.VertexRagStoreRagResource
  name: VertexRagStoreRagResource
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'The definition of the Rag resource.


    This data type is not supported in Gemini API.


    [Note: Inherited members from _common.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, rag_corpus: typing.Optional[str] = None, rag_file_ids: typing.Optional[list[str]] = None):'
  properties:
  - signature: 'rag_corpus: typing.Optional[str]'
  - signature: 'rag_file_ids: typing.Optional[list[str]]'
  omitted_inherited_members_from:
  - _common.BaseModel
- rank: 2681
  id: google.genai.types.VertexRagStoreRagResourceDict
  name: VertexRagStoreRagResourceDict
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'The definition of the Rag resource.


    This data type is not supported in Gemini API.


    [Note: Inherited members from TypedDict are omitted.]'
  properties:
  - signature: 'rag_corpus: typing.Optional[str]'
    docstring: 'Optional. RagCorpora resource name. Format: `projects/{project}/locations/{location}/ragCorpora/{rag_corpus}`'
  - signature: 'rag_file_ids: typing.Optional[list[str]]'
    docstring: Optional. rag_file_id. The files should be in the same rag_corpus set in rag_corpus field.
  omitted_inherited_members_from:
  - TypedDict
- rank: 2682
  id: google.genai.types.Video
  name: Video
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'A generated video.


    [Note: Inherited members from _common.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, uri: typing.Optional[str] = None, video_bytes: typing.Optional[bytes] = None, mime_type: typing.Optional[str] = None):'
  methods:
  - signature: 'def from_file(cls, *, location: str, mime_type: typing.Optional[str]=None) -> google.genai.types.Video:'
    docstring: "Loads a video from a local file.\n\nArgs:\n    location: The local path to load the video from.\n    mime_type: The MIME type of the video. If not provided, the MIME type\n      will be automatically determined.\n\nReturns:\n    A loaded video as an `Video` object."
  - signature: 'def save(self, path: str) -> None:'
    docstring: "Saves the video to a file.\n\nArgs:\n    path: Local path where to save the video."
  - signature: 'def show(self) -> None:'
    docstring: 'Shows the video.


      If the video has no mime_type, it is assumed to be video/mp4.


      This method only works in a notebook environment.'
  properties:
  - signature: 'uri: typing.Optional[str]'
  - signature: 'video_bytes: typing.Optional[bytes]'
  - signature: 'mime_type: typing.Optional[str]'
  omitted_inherited_members_from:
  - _common.BaseModel
- rank: 2683
  id: google.genai.types.Video.from_file
  name: from_file
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Loads a video from a local file.\n\nArgs:\n    location: The local path to load the video from.\n    mime_type: The MIME type of the video. If not provided, the MIME type\n      will be automatically determined.\n\nReturns:\n    A loaded video as an `Video` object."
  signature: 'def from_file(cls, *, location: str, mime_type: typing.Optional[str]=None) -> google.genai.types.Video:'
- rank: 2684
  id: google.genai.types.Video.save
  name: save
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Saves the video to a file.\n\nArgs:\n    path: Local path where to save the video."
  signature: 'def save(self, path: str) -> None:'
- rank: 2685
  id: google.genai.types.Video.show
  name: show
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: 'Shows the video.


    If the video has no mime_type, it is assumed to be video/mp4.


    This method only works in a notebook environment.'
  signature: 'def show(self) -> None:'
- rank: 2686
  id: google.genai.types.VideoCompressionQuality
  name: VideoCompressionQuality
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Enum that controls the compression quality of the generated videos.


    [Note: Inherited members from _common.CaseInSensitiveEnum are omitted.]'
  properties:
  - signature: 'OPTIMIZED: str'
    docstring: 'Optimized video compression quality. This will produce videos

      with a compressed, smaller file size.'
  - signature: 'LOSSLESS: str'
    docstring: 'Lossless video compression quality. This will produce videos

      with a larger file size.'
  omitted_inherited_members_from:
  - _common.CaseInSensitiveEnum
- rank: 2687
  id: google.genai.types.VideoDict
  name: VideoDict
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'A generated video.


    [Note: Inherited members from TypedDict are omitted.]'
  properties:
  - signature: 'uri: typing.Optional[str]'
    docstring: Path to another storage.
  - signature: 'video_bytes: typing.Optional[bytes]'
    docstring: Video bytes.
  - signature: 'mime_type: typing.Optional[str]'
    docstring: Video encoding, for example ``video/mp4``.
  omitted_inherited_members_from:
  - TypedDict
- rank: 2688
  id: google.genai.types.VideoGenerationMask
  name: VideoGenerationMask
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'A mask for video generation.


    [Note: Inherited members from _common.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, image: typing.Optional[google.genai.types.Image] = None, mask_mode: typing.Optional[google.genai.types.VideoGenerationMaskMode] = None):'
  properties:
  - signature: 'image: typing.Optional[google.genai.types.Image]'
  - signature: 'mask_mode: typing.Optional[google.genai.types.VideoGenerationMaskMode]'
  omitted_inherited_members_from:
  - _common.BaseModel
- rank: 2689
  id: google.genai.types.VideoGenerationMaskDict
  name: VideoGenerationMaskDict
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'A mask for video generation.


    [Note: Inherited members from TypedDict are omitted.]'
  properties:
  - signature: 'image: typing.Optional[google.genai.types.ImageDict]'
    docstring: The image mask to use for generating videos.
  - signature: 'mask_mode: typing.Optional[google.genai.types.VideoGenerationMaskMode]'
    docstring: 'Describes how the mask will be used. Inpainting masks must

      match the aspect ratio of the input video. Outpainting masks can be

      either 9:16 or 16:9.'
  omitted_inherited_members_from:
  - TypedDict
- rank: 2690
  id: google.genai.types.VideoGenerationMaskMode
  name: VideoGenerationMaskMode
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Enum for the mask mode of a video generation mask.


    [Note: Inherited members from _common.CaseInSensitiveEnum are omitted.]'
  properties:
  - signature: 'INSERT: str'
    docstring: 'The image mask contains a masked rectangular region which is

      applied on the first frame of the input video. The object described in

      the prompt is inserted into this region and will appear in subsequent

      frames.'
  - signature: 'REMOVE: str'
    docstring: 'The image mask is used to determine an object in the

      first video frame to track. This object is removed from the video.'
  - signature: 'REMOVE_STATIC: str'
    docstring: 'The image mask is used to determine a region in the

      video. Objects in this region will be removed.'
  - signature: 'OUTPAINT: str'
    docstring: 'The image mask contains a masked rectangular region where

      the input video will go. The remaining area will be generated. Video

      masks are not supported.'
  omitted_inherited_members_from:
  - _common.CaseInSensitiveEnum
- rank: 2691
  id: google.genai.types.VideoGenerationReferenceImage
  name: VideoGenerationReferenceImage
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'A reference image for video generation.


    [Note: Inherited members from _common.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, image: typing.Optional[google.genai.types.Image] = None, reference_type: typing.Optional[google.genai.types.VideoGenerationReferenceType] = None):'
  properties:
  - signature: 'image: typing.Optional[google.genai.types.Image]'
  - signature: 'reference_type: typing.Optional[google.genai.types.VideoGenerationReferenceType]'
  omitted_inherited_members_from:
  - _common.BaseModel
- rank: 2692
  id: google.genai.types.VideoGenerationReferenceImageDict
  name: VideoGenerationReferenceImageDict
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'A reference image for video generation.


    [Note: Inherited members from TypedDict are omitted.]'
  properties:
  - signature: 'image: typing.Optional[google.genai.types.ImageDict]'
    docstring: The reference image.
  - signature: 'reference_type: typing.Optional[google.genai.types.VideoGenerationReferenceType]'
    docstring: 'The type of the reference image, which defines how the reference

      image will be used to generate the video.'
  omitted_inherited_members_from:
  - TypedDict
- rank: 2693
  id: google.genai.types.VideoGenerationReferenceType
  name: VideoGenerationReferenceType
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Enum for the reference type of a video generation reference image.


    [Note: Inherited members from _common.CaseInSensitiveEnum are omitted.]'
  properties:
  - signature: 'ASSET: str'
    docstring: 'A reference image that provides assets to the generated video,

      such as the scene, an object, a character, etc.'
  - signature: 'STYLE: str'
    docstring: 'A reference image that provides aesthetics including colors,

      lighting, texture, etc., to be used as the style of the generated video,

      such as ''anime'', ''photography'', ''origami'', etc.'
  omitted_inherited_members_from:
  - _common.CaseInSensitiveEnum
- rank: 2694
  id: google.genai.types.VideoMetadata
  name: VideoMetadata
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Metadata describes the input video content.


    [Note: Inherited members from _common.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, end_offset: typing.Optional[str] = None, fps: typing.Optional[float] = None, start_offset: typing.Optional[str] = None):'
  properties:
  - signature: 'end_offset: typing.Optional[str]'
  - signature: 'fps: typing.Optional[float]'
  - signature: 'start_offset: typing.Optional[str]'
  omitted_inherited_members_from:
  - _common.BaseModel
- rank: 2695
  id: google.genai.types.VideoMetadataDict
  name: VideoMetadataDict
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Metadata describes the input video content.


    [Note: Inherited members from TypedDict are omitted.]'
  properties:
  - signature: 'end_offset: typing.Optional[str]'
    docstring: Optional. The end offset of the video.
  - signature: 'fps: typing.Optional[float]'
    docstring: Optional. The frame rate of the video sent to the model. If not specified, the default value will be 1.0. The fps range is (0.0, 24.0].
  - signature: 'start_offset: typing.Optional[str]'
    docstring: Optional. The start offset of the video.
  omitted_inherited_members_from:
  - TypedDict
- rank: 2696
  id: google.genai.types.VoiceConfig
  name: VoiceConfig
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'The configuration for the voice to use.


    [Note: Inherited members from _common.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, prebuilt_voice_config: typing.Optional[google.genai.types.PrebuiltVoiceConfig] = None):'
  properties:
  - signature: 'prebuilt_voice_config: typing.Optional[google.genai.types.PrebuiltVoiceConfig]'
  omitted_inherited_members_from:
  - _common.BaseModel
- rank: 2697
  id: google.genai.types.VoiceConfigDict
  name: VoiceConfigDict
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'The configuration for the voice to use.


    [Note: Inherited members from TypedDict are omitted.]'
  properties:
  - signature: 'prebuilt_voice_config: typing.Optional[google.genai.types.PrebuiltVoiceConfigDict]'
    docstring: The configuration for the prebuilt voice to use.
  omitted_inherited_members_from:
  - TypedDict
- rank: 2698
  id: google.genai.types.WeightedPrompt
  name: WeightedPrompt
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Maps a prompt to a relative weight to steer music generation.


    [Note: Inherited members from _common.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, text: typing.Optional[str] = None, weight: typing.Optional[float] = None):'
  properties:
  - signature: 'text: typing.Optional[str]'
  - signature: 'weight: typing.Optional[float]'
  omitted_inherited_members_from:
  - _common.BaseModel
- rank: 2699
  id: google.genai.types.WeightedPromptDict
  name: WeightedPromptDict
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Maps a prompt to a relative weight to steer music generation.


    [Note: Inherited members from TypedDict are omitted.]'
  properties:
  - signature: 'text: typing.Optional[str]'
    docstring: Text prompt.
  - signature: 'weight: typing.Optional[float]'
    docstring: 'Weight of the prompt. The weight is used to control the relative

      importance of the prompt. Higher weights are more important than lower

      weights.


      Weight must not be 0. Weights of all weighted_prompts in this

      LiveMusicClientContent message will be normalized.'
  omitted_inherited_members_from:
  - TypedDict
- rank: 2700
  id: google.genai.types.WhiteSpaceConfig
  name: WhiteSpaceConfig
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Configuration for a white space chunking algorithm.


    [Note: Inherited members from _common.BaseModel are omitted.]'
  constructor_signature: 'def __init__(self, *, max_tokens_per_chunk: typing.Optional[int] = None, max_overlap_tokens: typing.Optional[int] = None):'
  properties:
  - signature: 'max_tokens_per_chunk: typing.Optional[int]'
  - signature: 'max_overlap_tokens: typing.Optional[int]'
  omitted_inherited_members_from:
  - _common.BaseModel
- rank: 2701
  id: google.genai.types.WhiteSpaceConfigDict
  name: WhiteSpaceConfigDict
  file_path: env/lib/python3.13/site-packages/google/genai/types.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Configuration for a white space chunking algorithm.


    [Note: Inherited members from TypedDict are omitted.]'
  properties:
  - signature: 'max_tokens_per_chunk: typing.Optional[int]'
    docstring: Maximum number of tokens per chunk.
  - signature: 'max_overlap_tokens: typing.Optional[int]'
    docstring: Maximum number of overlapping tokens between two adjacent chunks.
  omitted_inherited_members_from:
  - TypedDict
- rank: 2702
  id: google.genai.version
  name: version
  file_path: env/lib/python3.13/site-packages/google/genai/version.py
  type: MODULE
  group: Orphan
  usage_score: 0
- rank: 2703
  id: vertexai
  name: root
  file_path: env/lib/python3.13/site-packages/vertexai/__init__.py
  type: MODULE
  group: Orphan
  usage_score: 0
  docstring: The vertexai module.
- rank: 2704
  id: vertexai.agent_engines
  name: agent_engines
  file_path: env/lib/python3.13/site-packages/vertexai/agent_engines/__init__.py
  type: MODULE
  group: Orphan
  usage_score: 0
  docstring: Classes and functions for working with agent engines.
  methods:
  - signature: 'def get(resource_name: str) -> vertexai.agent_engines._agent_engines.AgentEngine:'
    docstring: "Retrieves an Agent Engine resource.\n\nArgs:\n    resource_name (str):\n        Required. A fully-qualified resource name or ID such as\n        \"projects/123/locations/us-central1/reasoningEngines/456\" or\n        \"456\" when project and location are initialized or passed."
  - signature: 'def create(agent_engine: typing.Optional[vertexai.agent_engines._agent_engines._AgentEngineInterface], *, requirements: typing.Optional[typing.Union[str, typing.Sequence[str]]]=None, display_name: typing.Optional[str]=None, description: typing.Optional[str]=None, gcs_dir_name: typing.Optional[str]=None, extra_packages: typing.Optional[typing.Sequence[str]]=None, env_vars: typing.Optional[typing.Union[typing.Sequence[str], typing.Dict[str, typing.Union[str, google.cloud.aiplatform_v1.types.SecretRef]]]]=None, build_options: typing.Optional[typing.Dict[str, typing.Sequence[str]]]=None, service_account: typing.Optional[str]=None, psc_interface_config: typing.Optional[google.cloud.aiplatform_v1.types.PscInterfaceConfig]=None, min_instances: typing.Optional[int]=None, max_instances: typing.Optional[int]=None, resource_limits: typing.Optional[typing.Dict[str, str]]=None, container_concurrency: typing.Optional[int]=None, encryption_spec: typing.Optional[google.cloud.aiplatform_v1.types.EncryptionSpec]=None)
      -> vertexai.agent_engines._agent_engines.AgentEngine:'
    docstring: "Creates a new Agent Engine.\n\nThe Agent Engine will be an instance of the `agent_engine` that\nwas passed in, running remotely on Vertex AI.\n\nSample ``src_dir`` contents (e.g. ``./user_src_dir``):\n\n.. code-block:: python\n\n    user_src_dir/\n    |-- main.py\n    |-- requirements.txt\n    |-- user_code/\n    |   |-- utils.py\n    |   |-- ...\n    |-- installation_scripts/\n    |   |-- install_package.sh\n    |   |-- ...\n    |-- ...\n\nTo build an Agent Engine with the above files, run:\n\n.. code-block:: python\n\n    remote_agent = agent_engines.create(\n        agent_engine=local_agent,\n        requirements=[\n            # I.e. the PyPI dependencies listed in requirements.txt\n            \"google-cloud-aiplatform==1.25.0\",\n            \"langchain==0.0.242\",\n            ...\n        ],\n        extra_packages=[\n            \"./user_src_dir/main.py\", # a single file\n            \"./user_src_dir/user_code\", # a directory\n            ...\n        ],\n    \
      \    build_options={\n            \"installation\": [\n                \"./user_src_dir/installation_scripts/install_package.sh\",\n                ...\n            ],\n        },\n    )\n\nArgs:\n    agent_engine (AgentEngineInterface):\n        Required. The Agent Engine to be created.\n    requirements (Union[str, Sequence[str]]):\n        Optional. The set of PyPI dependencies needed. It can either be\n        the path to a single file (requirements.txt), or an ordered list\n        of strings corresponding to each line of the requirements file.\n    display_name (str):\n        Optional. The user-defined name of the Agent Engine.\n        The name can be up to 128 characters long and can comprise any\n        UTF-8 character.\n    description (str):\n        Optional. The description of the Agent Engine.\n    gcs_dir_name (str):\n        Optional. The GCS bucket directory under `staging_bucket` to\n        use for staging the artifacts needed.\n    extra_packages (Sequence[str]):\n\
      \        Optional. The set of extra user-provided packages (if any).\n    env_vars (Union[Sequence[str], Dict[str, Union[str, SecretRef]]]):\n        Optional. The environment variables to be set when running the\n        Agent Engine. If it is a list of strings, each string should be\n        a valid key to `os.environ`. If it is a dictionary, the keys are\n        the environment variable names, and the values are the\n        corresponding values.\n    build_options (Dict[str, Sequence[str]]):\n        Optional. The build options for the Agent Engine. This includes\n        options such as installation scripts.\n    service_account (str):\n        Optional. The service account to be used for the Agent Engine. If\n        not specified, the default reasoning engine service agent service\n        account will be used.\n    psc_interface_config (PscInterfaceConfig):\n        Optional. The PSC interface config for the Agent Engine. If not\n        specified, the default PSC interface\
      \ config will be used.\n    min_instances (int):\n        Optional. The minimum number of instances to run the Agent Engine.\n        If not specified, the default value will be used.\n    max_instances (int):\n        Optional. The maximum number of instances to run the Agent Engine.\n        If not specified, the default value will be used.\n    resource_limits (Dict[str, str]):\n        Optional. The resource limits for the Agent Engine. If not\n        specified, the default value will be used.\n    container_concurrency (int):\n        Optional. The container concurrency for the Agent Engine. If not\n        specified, the default value will be used.\n    encryption_spec (EncryptionSpec):\n        Optional. The encryption spec for the Agent Engine. If not\n        specified, the default encryption spec will be used.\n\nReturns:\n    AgentEngine: The Agent Engine that was created.\n\nRaises:\n    ValueError: If the `project` was not set using `vertexai.init`.\n    ValueError: If\
      \ the `location` was not set using `vertexai.init`.\n    ValueError: If the `staging_bucket` was not set using vertexai.init.\n    ValueError: If the `staging_bucket` does not start with \"gs://\".\n    FileNotFoundError: If `extra_packages` includes a file or directory\n    that does not exist.\n    IOError: If requirements is a string that corresponds to a\n    nonexistent file."
  - signature: 'def list(*, filter: str='''') -> typing.Iterable[vertexai.agent_engines._agent_engines.AgentEngine]:'
    docstring: "List all instances of Agent Engine matching the filter.\n\nExample Usage:\n\n.. code-block:: python\n    import vertexai\n    from vertexai import agent_engines\n\n    vertexai.init(project=\"my_project\", location=\"us-central1\")\n    agent_engines.list(filter='display_name=\"My Custom Agent\"')\n\nArgs:\n    filter (str):\n        Optional. An expression for filtering the results of the request.\n        For field names both snake_case and camelCase are supported.\n\nReturns:\n    Iterable[AgentEngine]: An iterable of Agent Engines matching the filter."
  - signature: 'def delete(resource_name: str, *, force: bool=False) -> None:'
    docstring: "Delete an Agent Engine resource.\n\nArgs:\n    resource_name (str):\n        Required. The name of the Agent Engine to be deleted. Format:\n        `projects/{project}/locations/{location}/reasoningEngines/{resource_id}`\n    force (bool):\n        Optional. If set to True, child resources will also be deleted.\n        Otherwise, the request will fail with FAILED_PRECONDITION error\n        when the Agent Engine has undeleted child resources. Defaults to\n        False.\n    **kwargs (dict[str, Any]):\n        Optional. Additional keyword arguments to pass to the\n        delete_reasoning_engine method."
  - signature: 'def update(resource_name: str, *, agent_engine: typing.Optional[typing.Union[vertexai.agent_engines._agent_engines.Queryable, vertexai.agent_engines._agent_engines.OperationRegistrable]]=None, requirements: typing.Optional[typing.Union[str, typing.Sequence[str]]]=None, display_name: typing.Optional[str]=None, description: typing.Optional[str]=None, gcs_dir_name: typing.Optional[str]=None, extra_packages: typing.Optional[typing.Sequence[str]]=None, env_vars: typing.Optional[typing.Union[typing.Sequence[str], typing.Dict[str, typing.Union[str, google.cloud.aiplatform_v1.types.SecretRef]]]]=None, build_options: typing.Optional[typing.Dict[str, typing.Sequence[str]]]=None, service_account: typing.Optional[str]=None, psc_interface_config: typing.Optional[google.cloud.aiplatform_v1.types.PscInterfaceConfig]=None, min_instances: typing.Optional[int]=None, max_instances: typing.Optional[int]=None, resource_limits: typing.Optional[typing.Dict[str, str]]=None, container_concurrency:
      typing.Optional[int]=None, encryption_spec: typing.Optional[google.cloud.aiplatform_v1.types.EncryptionSpec]=None) -> vertexai.agent_engines._agent_engines.AgentEngine:'
    docstring: "Updates an existing Agent Engine.\n\nThis method updates the configuration of a deployed Agent Engine, identified\nby its resource name. Unlike the `create` function which requires an\n`agent_engine` object, all arguments in this method are optional. This\nmethod allows you to modify individual aspects of the configuration by\nproviding any of the optional arguments.\n\nArgs:\n    resource_name (str):\n        Required. The name of the Agent Engine to be updated. Format:\n        `projects/{project}/locations/{location}/reasoningEngines/{resource_id}`.\n    agent_engine (AgentEngineInterface):\n        Optional. The instance to be used as the updated Agent Engine. If it\n        is not specified, the existing instance will be used.\n    requirements (Union[str, Sequence[str]]):\n        Optional. The set of PyPI dependencies needed. It can either be\n        the path to a single file (requirements.txt), or an ordered list\n        of strings corresponding to each line of\
      \ the requirements file.\n        If it is not specified, the existing requirements will be used.\n        If it is set to an empty string or list, the existing\n        requirements will be removed.\n    display_name (str):\n        Optional. The user-defined name of the Agent Engine.\n        The name can be up to 128 characters long and can comprise any\n        UTF-8 character.\n    description (str):\n        Optional. The description of the Agent Engine.\n    gcs_dir_name (str):\n        Optional. The GCS bucket directory under `staging_bucket` to\n        use for staging the artifacts needed.\n    extra_packages (Sequence[str]):\n        Optional. The set of extra user-provided packages (if any). If\n        it is not specified, the existing extra packages will be used.\n        If it is set to an empty list, the existing extra packages will\n        be removed.\n    env_vars (Union[Sequence[str], Dict[str, Union[str, SecretRef]]]):\n        Optional. The environment variables\
      \ to be set when running the\n        Agent Engine. If it is a list of strings, each string should be\n        a valid key to `os.environ`. If it is a dictionary, the keys are\n        the environment variable names, and the values are the\n        corresponding values.\n    build_options (Dict[str, Sequence[str]]):\n        Optional. The build options for the Agent Engine. This includes\n        options such as installation scripts.\n    service_account (str):\n        Optional. The service account to be used for the Agent Engine. If\n        not specified, the default reasoning engine service agent service\n        account will be used.\n    min_instances (int):\n        Optional. The minimum number of instances to run the Agent Engine.\n        If not specified, the default value will be used.\n    max_instances (int):\n        Optional. The maximum number of instances to run the Agent Engine.\n        If not specified, the default value will be used.\n    resource_limits (Dict[str,\
      \ str]):\n        Optional. The resource limits for the Agent Engine. If not\n        specified, the default value will be used.\n    container_concurrency (int):\n        Optional. The container concurrency for the Agent Engine. If not\n        specified, the default value will be used.\n    encryption_spec (EncryptionSpec):\n        Optional. The encryption spec for the Agent Engine. If not\n        specified, the default encryption spec will be used.\n\nReturns:\n    AgentEngine: The Agent Engine that was updated.\n\nRaises:\n    ValueError: If the `staging_bucket` was not set using vertexai.init.\n    ValueError: If the `staging_bucket` does not start with \"gs://\".\n    FileNotFoundError: If `extra_packages` includes a file or directory\n    that does not exist.\n    ValueError: if none of `display_name`, `description`,\n    `requirements`, `extra_packages`, `agent_engine`, or `build_options`\n    were specified.\n    IOError: If requirements is a string that corresponds to a\n\
      \    nonexistent file."
- rank: 2705
  id: vertexai.agent_engines.create
  name: create
  file_path: env/lib/python3.13/site-packages/vertexai/agent_engines/__init__.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Creates a new Agent Engine.\n\nThe Agent Engine will be an instance of the `agent_engine` that\nwas passed in, running remotely on Vertex AI.\n\nSample ``src_dir`` contents (e.g. ``./user_src_dir``):\n\n.. code-block:: python\n\n    user_src_dir/\n    |-- main.py\n    |-- requirements.txt\n    |-- user_code/\n    |   |-- utils.py\n    |   |-- ...\n    |-- installation_scripts/\n    |   |-- install_package.sh\n    |   |-- ...\n    |-- ...\n\nTo build an Agent Engine with the above files, run:\n\n.. code-block:: python\n\n    remote_agent = agent_engines.create(\n        agent_engine=local_agent,\n        requirements=[\n            # I.e. the PyPI dependencies listed in requirements.txt\n            \"google-cloud-aiplatform==1.25.0\",\n            \"langchain==0.0.242\",\n            ...\n        ],\n        extra_packages=[\n            \"./user_src_dir/main.py\", # a single file\n            \"./user_src_dir/user_code\", # a directory\n            ...\n        ],\n      \
    \  build_options={\n            \"installation\": [\n                \"./user_src_dir/installation_scripts/install_package.sh\",\n                ...\n            ],\n        },\n    )\n\nArgs:\n    agent_engine (AgentEngineInterface):\n        Required. The Agent Engine to be created.\n    requirements (Union[str, Sequence[str]]):\n        Optional. The set of PyPI dependencies needed. It can either be\n        the path to a single file (requirements.txt), or an ordered list\n        of strings corresponding to each line of the requirements file.\n    display_name (str):\n        Optional. The user-defined name of the Agent Engine.\n        The name can be up to 128 characters long and can comprise any\n        UTF-8 character.\n    description (str):\n        Optional. The description of the Agent Engine.\n    gcs_dir_name (str):\n        Optional. The GCS bucket directory under `staging_bucket` to\n        use for staging the artifacts needed.\n    extra_packages (Sequence[str]):\n\
    \        Optional. The set of extra user-provided packages (if any).\n    env_vars (Union[Sequence[str], Dict[str, Union[str, SecretRef]]]):\n        Optional. The environment variables to be set when running the\n        Agent Engine. If it is a list of strings, each string should be\n        a valid key to `os.environ`. If it is a dictionary, the keys are\n        the environment variable names, and the values are the\n        corresponding values.\n    build_options (Dict[str, Sequence[str]]):\n        Optional. The build options for the Agent Engine. This includes\n        options such as installation scripts.\n    service_account (str):\n        Optional. The service account to be used for the Agent Engine. If\n        not specified, the default reasoning engine service agent service\n        account will be used.\n    psc_interface_config (PscInterfaceConfig):\n        Optional. The PSC interface config for the Agent Engine. If not\n        specified, the default PSC interface\
    \ config will be used.\n    min_instances (int):\n        Optional. The minimum number of instances to run the Agent Engine.\n        If not specified, the default value will be used.\n    max_instances (int):\n        Optional. The maximum number of instances to run the Agent Engine.\n        If not specified, the default value will be used.\n    resource_limits (Dict[str, str]):\n        Optional. The resource limits for the Agent Engine. If not\n        specified, the default value will be used.\n    container_concurrency (int):\n        Optional. The container concurrency for the Agent Engine. If not\n        specified, the default value will be used.\n    encryption_spec (EncryptionSpec):\n        Optional. The encryption spec for the Agent Engine. If not\n        specified, the default encryption spec will be used.\n\nReturns:\n    AgentEngine: The Agent Engine that was created.\n\nRaises:\n    ValueError: If the `project` was not set using `vertexai.init`.\n    ValueError: If\
    \ the `location` was not set using `vertexai.init`.\n    ValueError: If the `staging_bucket` was not set using vertexai.init.\n    ValueError: If the `staging_bucket` does not start with \"gs://\".\n    FileNotFoundError: If `extra_packages` includes a file or directory\n    that does not exist.\n    IOError: If requirements is a string that corresponds to a\n    nonexistent file."
  signature: 'def create(agent_engine: typing.Optional[vertexai.agent_engines._agent_engines._AgentEngineInterface], *, requirements: typing.Optional[typing.Union[str, typing.Sequence[str]]]=None, display_name: typing.Optional[str]=None, description: typing.Optional[str]=None, gcs_dir_name: typing.Optional[str]=None, extra_packages: typing.Optional[typing.Sequence[str]]=None, env_vars: typing.Optional[typing.Union[typing.Sequence[str], typing.Dict[str, typing.Union[str, google.cloud.aiplatform_v1.types.SecretRef]]]]=None, build_options: typing.Optional[typing.Dict[str, typing.Sequence[str]]]=None, service_account: typing.Optional[str]=None, psc_interface_config: typing.Optional[google.cloud.aiplatform_v1.types.PscInterfaceConfig]=None, min_instances: typing.Optional[int]=None, max_instances: typing.Optional[int]=None, resource_limits: typing.Optional[typing.Dict[str, str]]=None, container_concurrency: typing.Optional[int]=None, encryption_spec: typing.Optional[google.cloud.aiplatform_v1.types.EncryptionSpec]=None)
    -> vertexai.agent_engines._agent_engines.AgentEngine:'
- rank: 2706
  id: vertexai.agent_engines.delete
  name: delete
  file_path: env/lib/python3.13/site-packages/vertexai/agent_engines/__init__.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Delete an Agent Engine resource.\n\nArgs:\n    resource_name (str):\n        Required. The name of the Agent Engine to be deleted. Format:\n        `projects/{project}/locations/{location}/reasoningEngines/{resource_id}`\n    force (bool):\n        Optional. If set to True, child resources will also be deleted.\n        Otherwise, the request will fail with FAILED_PRECONDITION error\n        when the Agent Engine has undeleted child resources. Defaults to\n        False.\n    **kwargs (dict[str, Any]):\n        Optional. Additional keyword arguments to pass to the\n        delete_reasoning_engine method."
  signature: 'def delete(resource_name: str, *, force: bool=False) -> None:'
- rank: 2707
  id: vertexai.agent_engines.get
  name: get
  file_path: env/lib/python3.13/site-packages/vertexai/agent_engines/__init__.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Retrieves an Agent Engine resource.\n\nArgs:\n    resource_name (str):\n        Required. A fully-qualified resource name or ID such as\n        \"projects/123/locations/us-central1/reasoningEngines/456\" or\n        \"456\" when project and location are initialized or passed."
  signature: 'def get(resource_name: str) -> vertexai.agent_engines._agent_engines.AgentEngine:'
- rank: 2708
  id: vertexai.agent_engines.list
  name: list
  file_path: env/lib/python3.13/site-packages/vertexai/agent_engines/__init__.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "List all instances of Agent Engine matching the filter.\n\nExample Usage:\n\n.. code-block:: python\n    import vertexai\n    from vertexai import agent_engines\n\n    vertexai.init(project=\"my_project\", location=\"us-central1\")\n    agent_engines.list(filter='display_name=\"My Custom Agent\"')\n\nArgs:\n    filter (str):\n        Optional. An expression for filtering the results of the request.\n        For field names both snake_case and camelCase are supported.\n\nReturns:\n    Iterable[AgentEngine]: An iterable of Agent Engines matching the filter."
  signature: 'def list(*, filter: str='''') -> typing.Iterable[vertexai.agent_engines._agent_engines.AgentEngine]:'
- rank: 2709
  id: vertexai.agent_engines.templates.adk
  name: adk
  file_path: env/lib/python3.13/site-packages/vertexai/agent_engines/templates/adk.py
  type: MODULE
  group: Orphan
  usage_score: 0
  methods:
  - signature: 'def get_adk_version() -> typing.Optional[str]:'
    docstring: Returns the version of the ADK package.
  - signature: 'def is_version_sufficient(version_to_check: str) -> bool:'
    docstring: "Compares the existing version of ADK with the required version.\n\nArgs:\n    version_to_check: The version string to check.\n\nReturns:\n    True if the existing version is sufficient, False otherwise."
- rank: 2710
  id: vertexai.agent_engines.templates.adk.AdkApp
  name: AdkApp
  file_path: env/lib/python3.13/site-packages/vertexai/agent_engines/templates/adk.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: An ADK Application.
  constructor_signature: 'def __init__(self, *, app: google.adk.apps.App=None, agent: google.adk.agents.BaseAgent=None, app_name: typing.Optional[str]=None, plugins: typing.Optional[typing.List[google.adk.plugins.base_plugin.BasePlugin]]=None, enable_tracing: typing.Optional[bool]=None, session_service_builder: typing.Optional[typing.Callable[Ellipsis, google.adk.sessions.BaseSessionService]]=None, artifact_service_builder: typing.Optional[typing.Callable[Ellipsis, google.adk.artifacts.BaseArtifactService]]=None, memory_service_builder: typing.Optional[typing.Callable[Ellipsis, google.adk.memory.BaseMemoryService]]=None, instrumentor_builder: typing.Optional[typing.Callable[Ellipsis, typing.Any]]=None):'
  methods:
  - signature: 'def clone(self):'
    docstring: Returns a clone of the ADK application.
  - signature: 'def set_up(self):'
    docstring: Sets up the ADK application.
  - signature: 'def async_stream_query(self, *, message: typing.Union[str, typing.Dict[str, typing.Any]], user_id: str, session_id: typing.Optional[str]=None, run_config: typing.Optional[typing.Dict[str, typing.Any]]=None) -> typing.AsyncIterable[typing.Dict[str, typing.Any]]:'
    docstring: "Streams responses asynchronously from the ADK application.\n\nArgs:\n    message (str):\n        Required. The message to stream responses for.\n    user_id (str):\n        Required. The ID of the user.\n    session_id (str):\n        Optional. The ID of the session. If not provided, a new\n        session will be created for the user.\n    run_config (Optional[Dict[str, Any]]):\n        Optional. The run config to use for the query. If you want to\n        pass in a `run_config` pydantic object, you can pass in a dict\n        representing it as `run_config.model_dump(mode=\"json\")`.\n    **kwargs (dict[str, Any]):\n        Optional. Additional keyword arguments to pass to the\n        runner.\n\nYields:\n    Event dictionaries asynchronously."
  - signature: 'def stream_query(self, *, message: typing.Union[str, typing.Dict[str, typing.Any]], user_id: str, session_id: typing.Optional[str]=None, run_config: typing.Optional[typing.Dict[str, typing.Any]]=None):'
    docstring: "Deprecated. Use async_stream_query instead.\n\nStreams responses from the ADK application in response to a message.\n\nArgs:\n    message (Union[str, Dict[str, Any]]):\n        Required. The message to stream responses for.\n    user_id (str):\n        Required. The ID of the user.\n    session_id (str):\n        Optional. The ID of the session. If not provided, a new\n        session will be created for the user.\n    run_config (Optional[Dict[str, Any]]):\n        Optional. The run config to use for the query. If you want to\n        pass in a `run_config` pydantic object, you can pass in a dict\n        representing it as `run_config.model_dump(mode=\"json\")`.\n    **kwargs (dict[str, Any]):\n        Optional. Additional keyword arguments to pass to the\n        runner.\n\nYields:\n    The output of querying the ADK application."
  - signature: 'def streaming_agent_run_with_events(self, request_json: str):'
    docstring: "Streams responses asynchronously from the ADK application.\n\nIn general, you should use `async_stream_query` instead, as it has a\nmore structured API and works with the respective ADK services that\nyou have defined for the AdkApp. This method is primarily meant for\ninvocation from AgentSpace.\n\nArgs:\n    request_json (str):\n        Required. The request to stream responses for."
  - signature: 'def async_get_session(self, *, user_id: str, session_id: str):'
    docstring: "Get a session for the given user.\n\nArgs:\n    user_id (str):\n        Required. The ID of the user.\n    session_id (str):\n        Required. The ID of the session.\n    **kwargs (dict[str, Any]):\n        Optional. Additional keyword arguments to pass to the\n        session service.\n\nReturns:\n    Session: The session instance (if any). It returns None if the\n    session is not found.\n\nRaises:\n    RuntimeError: If the session is not found."
  - signature: 'def get_session(self, *, user_id: str, session_id: str):'
    docstring: 'Deprecated. Use async_get_session instead.


      Get a session for the given user.'
  - signature: 'def async_list_sessions(self, *, user_id: str):'
    docstring: "List sessions for the given user.\n\nArgs:\n    user_id (str):\n        Required. The ID of the user.\n    **kwargs (dict[str, Any]):\n        Optional. Additional keyword arguments to pass to the\n        session service.\n\nReturns:\n    ListSessionsResponse: The list of sessions."
  - signature: 'def list_sessions(self, *, user_id: str):'
    docstring: 'Deprecated. Use async_list_sessions instead.


      List sessions for the given user.'
  - signature: 'def async_create_session(self, *, user_id: str, session_id: typing.Optional[str]=None, state: typing.Optional[typing.Dict[str, typing.Any]]=None):'
    docstring: "Creates a new session.\n\nArgs:\n    user_id (str):\n        Required. The ID of the user.\n    session_id (str):\n        Optional. The ID of the session. If not provided, an ID\n        will be be generated for the session.\n    state (dict[str, Any]):\n        Optional. The initial state of the session.\n    **kwargs (dict[str, Any]):\n        Optional. Additional keyword arguments to pass to the\n        session service.\n\nReturns:\n    Session: The newly created session instance."
  - signature: 'def create_session(self, *, user_id: str, session_id: typing.Optional[str]=None, state: typing.Optional[typing.Dict[str, typing.Any]]=None):'
    docstring: 'Deprecated. Use async_create_session instead.


      Creates a new session.'
  - signature: 'def async_delete_session(self, *, user_id: str, session_id: str):'
    docstring: "Deletes a session for the given user.\n\nArgs:\n    user_id (str):\n        Required. The ID of the user.\n    session_id (str):\n        Required. The ID of the session.\n    **kwargs (dict[str, Any]):\n        Optional. Additional keyword arguments to pass to the\n        session service."
  - signature: 'def delete_session(self, *, user_id: str, session_id: str):'
    docstring: 'Deprecated. Use async_delete_session instead.


      Deletes a session for the given user.'
  - signature: 'def async_add_session_to_memory(self, *, session: typing.Dict[str, typing.Any]):'
    docstring: "Generates memories.\n\nArgs:\n    session (Dict[str, Any]):\n        Required. The session to use for generating memories. It should\n        be a dictionary representing an ADK Session object, e.g.\n        session.model_dump(mode=\"json\")."
  - signature: 'def async_search_memory(self, *, user_id: str, query: str):'
    docstring: "Searches memories for the given user.\n\nArgs:\n    user_id: The id of the user.\n    query: The query to match the memories on.\n\nReturns:\n    A SearchMemoryResponse containing the matching memories."
  - signature: 'def register_operations(self) -> typing.Dict[str, typing.List[str]]:'
    docstring: Registers the operations of the ADK application.
  - signature: 'def project_id(self) -> typing.Optional[str]:'
  properties:
  - signature: 'agent_framework: str'
- rank: 2711
  id: vertexai.agent_engines.templates.adk.AdkApp.__init__
  name: __init__
  file_path: env/lib/python3.13/site-packages/vertexai/agent_engines/templates/adk.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "An ADK Application.\n\nSee https://cloud.google.com/vertex-ai/generative-ai/docs/agent-engine/develop/adk\nfor details on how to develop ADK applications on Agent Engine.\n\nArgs:\n    agent (google.adk.agents.BaseAgent):\n        Required. The ADK agent to run.\n    app_name (str):\n        Optional. The name of the ADK application. Defaults to\n        \"default-app-name\" when running locally, and to the\n        corresponding agent engine ID when deployed on Agent Engine.\n    plugins (List[BasePlugin]):\n        Optional. The plugins to use for the ADK application.\n        Defaults to an empty list.\n    enable_tracing (bool):\n        Optional. Whether to enable tracing in Cloud Trace. Defaults to\n        False.\n    session_service_builder (Callable[..., BaseSessionService]):\n        Optional. A callable that returns an ADK session service.\n        Defaults to a callable that returns InMemorySessionService\n        when running locally and VertexAiSessionService\
    \ when running\n        on Agent Engine.\n    artifact_service_builder (Callable[..., BaseArtifactService]):\n        Optional. A callable that returns an ADK artifact service.\n        Defaults to a callable that returns InMemoryArtifactService.\n    memory_service_builder (Callable[..., BaseMemoryService]):\n        Optional. A callable that returns an ADK memory service.\n        Defaults to a callable that returns InMemoryMemoryService\n        when running locally and VertexAiMemoryBankService when running\n        on Agent Engine.\n    instrumentor_builder (Callable[..., Any]):\n        Optional. Callable that returns a new instrumentor. This can be\n        used for customizing the instrumentation logic of the Agent.\n        If not provided, a default instrumentor builder will be used.\n        This parameter is ignored if `enable_tracing` is False."
  signature: 'def __init__(self, *, app: google.adk.apps.App=None, agent: google.adk.agents.BaseAgent=None, app_name: typing.Optional[str]=None, plugins: typing.Optional[typing.List[google.adk.plugins.base_plugin.BasePlugin]]=None, enable_tracing: typing.Optional[bool]=None, session_service_builder: typing.Optional[typing.Callable[Ellipsis, google.adk.sessions.BaseSessionService]]=None, artifact_service_builder: typing.Optional[typing.Callable[Ellipsis, google.adk.artifacts.BaseArtifactService]]=None, memory_service_builder: typing.Optional[typing.Callable[Ellipsis, google.adk.memory.BaseMemoryService]]=None, instrumentor_builder: typing.Optional[typing.Callable[Ellipsis, typing.Any]]=None):'
- rank: 2712
  id: vertexai.agent_engines.templates.adk.AdkApp.async_add_session_to_memory
  name: async_add_session_to_memory
  file_path: env/lib/python3.13/site-packages/vertexai/agent_engines/templates/adk.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Generates memories.\n\nArgs:\n    session (Dict[str, Any]):\n        Required. The session to use for generating memories. It should\n        be a dictionary representing an ADK Session object, e.g.\n        session.model_dump(mode=\"json\")."
  signature: 'def async_add_session_to_memory(self, *, session: typing.Dict[str, typing.Any]):'
- rank: 2713
  id: vertexai.agent_engines.templates.adk.AdkApp.async_create_session
  name: async_create_session
  file_path: env/lib/python3.13/site-packages/vertexai/agent_engines/templates/adk.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Creates a new session.\n\nArgs:\n    user_id (str):\n        Required. The ID of the user.\n    session_id (str):\n        Optional. The ID of the session. If not provided, an ID\n        will be be generated for the session.\n    state (dict[str, Any]):\n        Optional. The initial state of the session.\n    **kwargs (dict[str, Any]):\n        Optional. Additional keyword arguments to pass to the\n        session service.\n\nReturns:\n    Session: The newly created session instance."
  signature: 'def async_create_session(self, *, user_id: str, session_id: typing.Optional[str]=None, state: typing.Optional[typing.Dict[str, typing.Any]]=None):'
- rank: 2714
  id: vertexai.agent_engines.templates.adk.AdkApp.async_delete_session
  name: async_delete_session
  file_path: env/lib/python3.13/site-packages/vertexai/agent_engines/templates/adk.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Deletes a session for the given user.\n\nArgs:\n    user_id (str):\n        Required. The ID of the user.\n    session_id (str):\n        Required. The ID of the session.\n    **kwargs (dict[str, Any]):\n        Optional. Additional keyword arguments to pass to the\n        session service."
  signature: 'def async_delete_session(self, *, user_id: str, session_id: str):'
- rank: 2715
  id: vertexai.agent_engines.templates.adk.AdkApp.async_get_session
  name: async_get_session
  file_path: env/lib/python3.13/site-packages/vertexai/agent_engines/templates/adk.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Get a session for the given user.\n\nArgs:\n    user_id (str):\n        Required. The ID of the user.\n    session_id (str):\n        Required. The ID of the session.\n    **kwargs (dict[str, Any]):\n        Optional. Additional keyword arguments to pass to the\n        session service.\n\nReturns:\n    Session: The session instance (if any). It returns None if the\n    session is not found.\n\nRaises:\n    RuntimeError: If the session is not found."
  signature: 'def async_get_session(self, *, user_id: str, session_id: str):'
- rank: 2716
  id: vertexai.agent_engines.templates.adk.AdkApp.async_list_sessions
  name: async_list_sessions
  file_path: env/lib/python3.13/site-packages/vertexai/agent_engines/templates/adk.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "List sessions for the given user.\n\nArgs:\n    user_id (str):\n        Required. The ID of the user.\n    **kwargs (dict[str, Any]):\n        Optional. Additional keyword arguments to pass to the\n        session service.\n\nReturns:\n    ListSessionsResponse: The list of sessions."
  signature: 'def async_list_sessions(self, *, user_id: str):'
- rank: 2717
  id: vertexai.agent_engines.templates.adk.AdkApp.async_search_memory
  name: async_search_memory
  file_path: env/lib/python3.13/site-packages/vertexai/agent_engines/templates/adk.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Searches memories for the given user.\n\nArgs:\n    user_id: The id of the user.\n    query: The query to match the memories on.\n\nReturns:\n    A SearchMemoryResponse containing the matching memories."
  signature: 'def async_search_memory(self, *, user_id: str, query: str):'
- rank: 2718
  id: vertexai.agent_engines.templates.adk.AdkApp.async_stream_query
  name: async_stream_query
  file_path: env/lib/python3.13/site-packages/vertexai/agent_engines/templates/adk.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Streams responses asynchronously from the ADK application.\n\nArgs:\n    message (str):\n        Required. The message to stream responses for.\n    user_id (str):\n        Required. The ID of the user.\n    session_id (str):\n        Optional. The ID of the session. If not provided, a new\n        session will be created for the user.\n    run_config (Optional[Dict[str, Any]]):\n        Optional. The run config to use for the query. If you want to\n        pass in a `run_config` pydantic object, you can pass in a dict\n        representing it as `run_config.model_dump(mode=\"json\")`.\n    **kwargs (dict[str, Any]):\n        Optional. Additional keyword arguments to pass to the\n        runner.\n\nYields:\n    Event dictionaries asynchronously."
  signature: 'def async_stream_query(self, *, message: typing.Union[str, typing.Dict[str, typing.Any]], user_id: str, session_id: typing.Optional[str]=None, run_config: typing.Optional[typing.Dict[str, typing.Any]]=None) -> typing.AsyncIterable[typing.Dict[str, typing.Any]]:'
- rank: 2719
  id: vertexai.agent_engines.templates.adk.AdkApp.clone
  name: clone
  file_path: env/lib/python3.13/site-packages/vertexai/agent_engines/templates/adk.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: Returns a clone of the ADK application.
  signature: 'def clone(self):'
- rank: 2720
  id: vertexai.agent_engines.templates.adk.AdkApp.create_session
  name: create_session
  file_path: env/lib/python3.13/site-packages/vertexai/agent_engines/templates/adk.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: 'Deprecated. Use async_create_session instead.


    Creates a new session.'
  signature: 'def create_session(self, *, user_id: str, session_id: typing.Optional[str]=None, state: typing.Optional[typing.Dict[str, typing.Any]]=None):'
- rank: 2721
  id: vertexai.agent_engines.templates.adk.AdkApp.delete_session
  name: delete_session
  file_path: env/lib/python3.13/site-packages/vertexai/agent_engines/templates/adk.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: 'Deprecated. Use async_delete_session instead.


    Deletes a session for the given user.'
  signature: 'def delete_session(self, *, user_id: str, session_id: str):'
- rank: 2722
  id: vertexai.agent_engines.templates.adk.AdkApp.get_session
  name: get_session
  file_path: env/lib/python3.13/site-packages/vertexai/agent_engines/templates/adk.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: 'Deprecated. Use async_get_session instead.


    Get a session for the given user.'
  signature: 'def get_session(self, *, user_id: str, session_id: str):'
- rank: 2723
  id: vertexai.agent_engines.templates.adk.AdkApp.list_sessions
  name: list_sessions
  file_path: env/lib/python3.13/site-packages/vertexai/agent_engines/templates/adk.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: 'Deprecated. Use async_list_sessions instead.


    List sessions for the given user.'
  signature: 'def list_sessions(self, *, user_id: str):'
- rank: 2724
  id: vertexai.agent_engines.templates.adk.AdkApp.project_id
  name: project_id
  file_path: env/lib/python3.13/site-packages/vertexai/agent_engines/templates/adk.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def project_id(self) -> typing.Optional[str]:'
- rank: 2725
  id: vertexai.agent_engines.templates.adk.AdkApp.register_operations
  name: register_operations
  file_path: env/lib/python3.13/site-packages/vertexai/agent_engines/templates/adk.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: Registers the operations of the ADK application.
  signature: 'def register_operations(self) -> typing.Dict[str, typing.List[str]]:'
- rank: 2726
  id: vertexai.agent_engines.templates.adk.AdkApp.set_up
  name: set_up
  file_path: env/lib/python3.13/site-packages/vertexai/agent_engines/templates/adk.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: Sets up the ADK application.
  signature: 'def set_up(self):'
- rank: 2727
  id: vertexai.agent_engines.templates.adk.AdkApp.stream_query
  name: stream_query
  file_path: env/lib/python3.13/site-packages/vertexai/agent_engines/templates/adk.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Deprecated. Use async_stream_query instead.\n\nStreams responses from the ADK application in response to a message.\n\nArgs:\n    message (Union[str, Dict[str, Any]]):\n        Required. The message to stream responses for.\n    user_id (str):\n        Required. The ID of the user.\n    session_id (str):\n        Optional. The ID of the session. If not provided, a new\n        session will be created for the user.\n    run_config (Optional[Dict[str, Any]]):\n        Optional. The run config to use for the query. If you want to\n        pass in a `run_config` pydantic object, you can pass in a dict\n        representing it as `run_config.model_dump(mode=\"json\")`.\n    **kwargs (dict[str, Any]):\n        Optional. Additional keyword arguments to pass to the\n        runner.\n\nYields:\n    The output of querying the ADK application."
  signature: 'def stream_query(self, *, message: typing.Union[str, typing.Dict[str, typing.Any]], user_id: str, session_id: typing.Optional[str]=None, run_config: typing.Optional[typing.Dict[str, typing.Any]]=None):'
- rank: 2728
  id: vertexai.agent_engines.templates.adk.AdkApp.streaming_agent_run_with_events
  name: streaming_agent_run_with_events
  file_path: env/lib/python3.13/site-packages/vertexai/agent_engines/templates/adk.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Streams responses asynchronously from the ADK application.\n\nIn general, you should use `async_stream_query` instead, as it has a\nmore structured API and works with the respective ADK services that\nyou have defined for the AdkApp. This method is primarily meant for\ninvocation from AgentSpace.\n\nArgs:\n    request_json (str):\n        Required. The request to stream responses for."
  signature: 'def streaming_agent_run_with_events(self, request_json: str):'
- rank: 2729
  id: vertexai.agent_engines.templates.adk.get_adk_version
  name: get_adk_version
  file_path: env/lib/python3.13/site-packages/vertexai/agent_engines/templates/adk.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: Returns the version of the ADK package.
  signature: 'def get_adk_version() -> typing.Optional[str]:'
- rank: 2730
  id: vertexai.agent_engines.templates.adk.is_version_sufficient
  name: is_version_sufficient
  file_path: env/lib/python3.13/site-packages/vertexai/agent_engines/templates/adk.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Compares the existing version of ADK with the required version.\n\nArgs:\n    version_to_check: The version string to check.\n\nReturns:\n    True if the existing version is sufficient, False otherwise."
  signature: 'def is_version_sufficient(version_to_check: str) -> bool:'
- rank: 2731
  id: vertexai.agent_engines.templates.ag2
  name: ag2
  file_path: env/lib/python3.13/site-packages/vertexai/agent_engines/templates/ag2.py
  type: MODULE
  group: Orphan
  usage_score: 0
- rank: 2732
  id: vertexai.agent_engines.templates.ag2.AG2Agent
  name: AG2Agent
  file_path: env/lib/python3.13/site-packages/vertexai/agent_engines/templates/ag2.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: An AG2 Agent.
  constructor_signature: 'def __init__(self, model: str, runnable_name: str, *, api_type: typing.Optional[str]=None, llm_config: typing.Optional[typing.Mapping[str, typing.Any]]=None, system_instruction: typing.Optional[str]=None, runnable_kwargs: typing.Optional[typing.Mapping[str, typing.Any]]=None, runnable_builder: typing.Optional[typing.Callable[Ellipsis, ConversableAgent]]=None, tools: typing.Optional[typing.Sequence[typing.Callable[Ellipsis, typing.Any]]]=None, enable_tracing: bool=False, instrumentor_builder: typing.Optional[typing.Callable[Ellipsis, typing.Any]]=None):'
  methods:
  - signature: 'def set_up(self):'
    docstring: 'Sets up the agent for execution of queries at runtime.


      It initializes the runnable, binds the runnable with tools.


      This method should not be called for an object that being passed to

      the ReasoningEngine service for deployment, as it initializes clients

      that can not be serialized.'
  - signature: 'def clone(self) -> vertexai.agent_engines.templates.ag2.AG2Agent:'
    docstring: Returns a clone of the AG2Agent.
  - signature: 'def query(self, *, input: typing.Union[str, typing.Mapping[str, typing.Any]], max_turns: typing.Optional[int]=None) -> typing.Dict[str, typing.Any]:'
    docstring: "Queries the Agent with the given input.\n\nArgs:\n    input (Union[str, Mapping[str, Any]]):\n        Required. The input to be passed to the Agent.\n    max_turns (int):\n        Optional. The maximum number of turns to run the agent for.\n        If not provided, the agent will run indefinitely.\n        If `max_turns` is a `float`, it will be converted to `int`\n        through rounding.\n    **kwargs:\n        Optional. Any additional keyword arguments to be passed to the\n        `.run()` method of the corresponding runnable.\n        Details of the kwargs can be found in\n        https://docs.ag2.ai/docs/api-reference/autogen/ConversableAgent#run.\n        The `user_input` parameter defaults to `False`, and should not\n        be passed through `kwargs`.\n\nReturns:\n    The output of querying the Agent with the given input."
  properties:
  - signature: 'agent_framework: str'
- rank: 2733
  id: vertexai.agent_engines.templates.ag2.AG2Agent.__init__
  name: __init__
  file_path: env/lib/python3.13/site-packages/vertexai/agent_engines/templates/ag2.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Initializes the AG2 Agent.\n\nUnder-the-hood, assuming .set_up() is called, this will correspond to\n```python\n# runnable_builder\nrunnable = runnable_builder(\n    llm_config=llm_config,\n    system_message=system_instruction,\n    **runnable_kwargs,\n)\n```\n\nWhen everything is based on their default values, this corresponds to\n```python\n# llm_config\nllm_config = {\n    \"config_list\": [{\n        \"project_id\":       initializer.global_config.project,\n        \"location\":         initializer.global_config.location,\n        \"model\":            \"gemini-1.0-pro-001\",\n        \"api_type\":         \"google\",\n    }]\n}\n\n# runnable_builder\nrunnable = ConversableAgent(\n    llm_config=llm_config,\n    name=\"Default AG2 Agent\"\n    system_message=\"You are a helpful AI Assistant.\",\n    human_input_mode=\"NEVER\",\n)\n```\n\nBy default, if `llm_config` is not specified, a default configuration\nwill be created using the provided `model` and `api_type`.\n\n\
    If `runnable_builder` is not specified, a default runnable builder will\nbe used, configured with the `system_instruction`, `runnable_name` and\n`runnable_kwargs`.\n\nArgs:\n    model (str):\n        Required. The name of the model (e.g. \"gemini-1.0-pro\").\n        Used to create a default `llm_config` if one is not provided.\n        This parameter is ignored if `llm_config` is provided.\n    runnable_name (str):\n        Required. The name of the runnable.\n        This name is used as the default `runnable_kwargs[\"name\"]`\n        unless `runnable_kwargs` already contains a \"name\", in which\n        case the provided `runnable_kwargs[\"name\"]` will be used.\n    api_type (str):\n        Optional. The API type to use for the language model.\n        Used to create a default `llm_config` if one is not provided.\n        This parameter is ignored if `llm_config` is provided.\n    llm_config (Mapping[str, Any]):\n        Optional. Configuration dictionary for the language model.\n\
    \        If provided, this configuration will be used directly.\n        Otherwise, a default `llm_config` will be created using `model`\n        and `api_type`. This `llm_config` is used as the default\n        `runnable_kwargs[\"llm_config\"]` unless `runnable_kwargs` already\n        contains a \"llm_config\", in which case the provided\n        `runnable_kwargs[\"llm_config\"]` will be used.\n    system_instruction (str):\n        Optional. The system instruction for the agent.\n        This instruction is used as the default\n        `runnable_kwargs[\"system_message\"]` unless `runnable_kwargs`\n        already contains a \"system_message\", in which case the provided\n        `runnable_kwargs[\"system_message\"]` will be used.\n    runnable_kwargs (Mapping[str, Any]):\n        Optional. Additional keyword arguments for the constructor of\n        the runnable. Details of the kwargs can be found in\n        https://docs.ag2.ai/docs/api-reference/autogen/ConversableAgent.\n    \
    \    `runnable_kwargs` only supports `human_input_mode=\"NEVER\"`.\n        Other `human_input_mode` values will trigger a warning.\n    runnable_builder (Callable[..., \"ConversableAgent\"]):\n        Optional. Callable that returns a new runnable. This can be used\n        for customizing the orchestration logic of the Agent.\n        If not provided, a default runnable builder will be used.\n    tools (Sequence[Callable[..., Any]]):\n        Optional. The tools for the agent to be able to use. All input\n        callables (e.g. function or class method) will be converted\n        to a AG2 tool . Defaults to None.\n    enable_tracing (bool):\n        Optional. Whether to enable tracing in Cloud Trace. Defaults to\n        False.\n    instrumentor_builder (Callable[..., Any]):\n        Optional. Callable that returns a new instrumentor. This can be\n        used for customizing the instrumentation logic of the Agent.\n        If not provided, a default instrumentor builder will be used.\n\
    \        This parameter is ignored if `enable_tracing` is False."
  signature: 'def __init__(self, model: str, runnable_name: str, *, api_type: typing.Optional[str]=None, llm_config: typing.Optional[typing.Mapping[str, typing.Any]]=None, system_instruction: typing.Optional[str]=None, runnable_kwargs: typing.Optional[typing.Mapping[str, typing.Any]]=None, runnable_builder: typing.Optional[typing.Callable[Ellipsis, ConversableAgent]]=None, tools: typing.Optional[typing.Sequence[typing.Callable[Ellipsis, typing.Any]]]=None, enable_tracing: bool=False, instrumentor_builder: typing.Optional[typing.Callable[Ellipsis, typing.Any]]=None):'
- rank: 2734
  id: vertexai.agent_engines.templates.ag2.AG2Agent.clone
  name: clone
  file_path: env/lib/python3.13/site-packages/vertexai/agent_engines/templates/ag2.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: Returns a clone of the AG2Agent.
  signature: 'def clone(self) -> vertexai.agent_engines.templates.ag2.AG2Agent:'
- rank: 2735
  id: vertexai.agent_engines.templates.ag2.AG2Agent.query
  name: query
  file_path: env/lib/python3.13/site-packages/vertexai/agent_engines/templates/ag2.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Queries the Agent with the given input.\n\nArgs:\n    input (Union[str, Mapping[str, Any]]):\n        Required. The input to be passed to the Agent.\n    max_turns (int):\n        Optional. The maximum number of turns to run the agent for.\n        If not provided, the agent will run indefinitely.\n        If `max_turns` is a `float`, it will be converted to `int`\n        through rounding.\n    **kwargs:\n        Optional. Any additional keyword arguments to be passed to the\n        `.run()` method of the corresponding runnable.\n        Details of the kwargs can be found in\n        https://docs.ag2.ai/docs/api-reference/autogen/ConversableAgent#run.\n        The `user_input` parameter defaults to `False`, and should not\n        be passed through `kwargs`.\n\nReturns:\n    The output of querying the Agent with the given input."
  signature: 'def query(self, *, input: typing.Union[str, typing.Mapping[str, typing.Any]], max_turns: typing.Optional[int]=None) -> typing.Dict[str, typing.Any]:'
- rank: 2736
  id: vertexai.agent_engines.templates.ag2.AG2Agent.set_up
  name: set_up
  file_path: env/lib/python3.13/site-packages/vertexai/agent_engines/templates/ag2.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: 'Sets up the agent for execution of queries at runtime.


    It initializes the runnable, binds the runnable with tools.


    This method should not be called for an object that being passed to

    the ReasoningEngine service for deployment, as it initializes clients

    that can not be serialized.'
  signature: 'def set_up(self):'
- rank: 2737
  id: vertexai.agent_engines.templates.langchain
  name: langchain
  file_path: env/lib/python3.13/site-packages/vertexai/agent_engines/templates/langchain.py
  type: MODULE
  group: Orphan
  usage_score: 0
- rank: 2738
  id: vertexai.agent_engines.templates.langchain.LangchainAgent
  name: LangchainAgent
  file_path: env/lib/python3.13/site-packages/vertexai/agent_engines/templates/langchain.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'A Langchain Agent.


    See https://cloud.google.com/vertex-ai/generative-ai/docs/reasoning-engine/develop

    for details.'
  constructor_signature: 'def __init__(self, model: str, *, system_instruction: typing.Optional[str]=None, prompt: typing.Optional[RunnableSerializable]=None, tools: typing.Optional[typing.Sequence[_ToolLike]]=None, output_parser: typing.Optional[RunnableSerializable]=None, chat_history: typing.Optional[GetSessionHistoryCallable]=None, model_kwargs: typing.Optional[typing.Mapping[str, typing.Any]]=None, model_tool_kwargs: typing.Optional[typing.Mapping[str, typing.Any]]=None, agent_executor_kwargs: typing.Optional[typing.Mapping[str, typing.Any]]=None, runnable_kwargs: typing.Optional[typing.Mapping[str, typing.Any]]=None, model_builder: typing.Optional[typing.Callable]=None, runnable_builder: typing.Optional[typing.Callable]=None, enable_tracing: bool=False, instrumentor_builder: typing.Optional[typing.Callable[Ellipsis, typing.Any]]=None):'
  methods:
  - signature: 'def set_up(self):'
    docstring: 'Sets up the agent for execution of queries at runtime.


      It initializes the model, binds the model with tools, and connects it

      with the prompt template and output parser.


      This method should not be called for an object being passed to the

      service for deployment, as it might initialize clients that can not be

      serialized.'
  - signature: 'def clone(self) -> vertexai.agent_engines.templates.langchain.LangchainAgent:'
    docstring: Returns a clone of the LangchainAgent.
  - signature: 'def query(self, *, input: typing.Union[str, typing.Mapping[str, typing.Any]], config: typing.Optional[RunnableConfig]=None) -> typing.Dict[str, typing.Any]:'
    docstring: "Queries the Agent with the given input and config.\n\nArgs:\n    input (Union[str, Mapping[str, Any]]):\n        Required. The input to be passed to the Agent.\n    config (langchain_core.runnables.RunnableConfig):\n        Optional. The config (if any) to be used for invoking the Agent.\n    **kwargs:\n        Optional. Any additional keyword arguments to be passed to the\n        `.invoke()` method of the corresponding AgentExecutor.\n\nReturns:\n    The output of querying the Agent with the given input and config."
  - signature: 'def stream_query(self, *, input: typing.Union[str, typing.Mapping[str, typing.Any]], config: typing.Optional[RunnableConfig]=None) -> typing.Iterable[typing.Any]:'
    docstring: "Stream queries the Agent with the given input and config.\n\nArgs:\n    input (Union[str, Mapping[str, Any]]):\n        Required. The input to be passed to the Agent.\n    config (langchain_core.runnables.RunnableConfig):\n        Optional. The config (if any) to be used for invoking the Agent.\n    **kwargs:\n        Optional. Any additional keyword arguments to be passed to the\n        `.invoke()` method of the corresponding AgentExecutor.\n\nYields:\n    The output of querying the Agent with the given input and config."
  properties:
  - signature: 'agent_framework: str'
- rank: 2739
  id: vertexai.agent_engines.templates.langchain.LangchainAgent.__init__
  name: __init__
  file_path: env/lib/python3.13/site-packages/vertexai/agent_engines/templates/langchain.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Initializes the LangchainAgent.\n\nUnder-the-hood, assuming .set_up() is called, this will correspond to\n\n```\nmodel = model_builder(model_name=model, model_kwargs=model_kwargs)\nrunnable = runnable_builder(\n    prompt=prompt,\n    model=model,\n    tools=tools,\n    output_parser=output_parser,\n    chat_history=chat_history,\n    agent_executor_kwargs=agent_executor_kwargs,\n    runnable_kwargs=runnable_kwargs,\n)\n```\n\nWhen everything is based on their default values, this corresponds to\n```\n# model_builder\nfrom langchain_google_vertexai import ChatVertexAI\nllm = ChatVertexAI(model_name=model, **model_kwargs)\n\n# runnable_builder\nfrom langchain import agents\nfrom langchain_core.runnables.history import RunnableWithMessageHistory\nllm_with_tools = llm.bind_tools(tools=tools, **model_tool_kwargs)\nagent_executor = agents.AgentExecutor(\n    agent=prompt | llm_with_tools | output_parser,\n    tools=tools,\n    **agent_executor_kwargs,\n)\nrunnable = RunnableWithMessageHistory(\n\
    \    runnable=agent_executor,\n    get_session_history=chat_history,\n    **runnable_kwargs,\n)\n```\n\nArgs:\n    model (str):\n        Optional. The name of the model (e.g. \"gemini-1.0-pro\").\n    system_instruction (str):\n        Optional. The system instruction to use for the agent. This\n        argument should not be specified if `prompt` is specified.\n    prompt (langchain_core.runnables.RunnableSerializable):\n        Optional. The prompt template for the model. Defaults to a\n        ChatPromptTemplate.\n    tools (Sequence[langchain_core.tools.BaseTool, Callable]):\n        Optional. The tools for the agent to be able to use. All input\n        callables (e.g. function or class method) will be converted\n        to a langchain.tools.base.StructuredTool. Defaults to None.\n    output_parser (langchain_core.runnables.RunnableSerializable):\n        Optional. The output parser for the model. Defaults to an\n        output parser that works with Gemini function-calling.\n \
    \   chat_history (langchain_core.runnables.history.GetSessionHistoryCallable):\n        Optional. Callable that returns a new BaseChatMessageHistory.\n        Defaults to None, i.e. chat_history is not preserved.\n    model_kwargs (Mapping[str, Any]):\n        Optional. Additional keyword arguments for the constructor of\n        chat_models.ChatVertexAI. An example would be\n        ```\n        {\n            # temperature (float): Sampling temperature, it controls the\n            # degree of randomness in token selection.\n            \"temperature\": 0.28,\n            # max_output_tokens (int): Token limit determines the\n            # maximum amount of text output from one prompt.\n            \"max_output_tokens\": 1000,\n            # top_p (float): Tokens are selected from most probable to\n            # least, until the sum of their probabilities equals the\n            # top_p value.\n            \"top_p\": 0.95,\n            # top_k (int): How the model selects tokens for\
    \ output, the\n            # next token is selected from among the top_k most probable\n            # tokens.\n            \"top_k\": 40,\n        }\n        ```\n    model_tool_kwargs (Mapping[str, Any]):\n        Optional. Additional keyword arguments when binding tools to the\n        model using `model.bind_tools()`.\n    agent_executor_kwargs (Mapping[str, Any]):\n        Optional. Additional keyword arguments for the constructor of\n        langchain.agents.AgentExecutor. An example would be\n        ```\n        {\n            # Whether to return the agent's trajectory of intermediate\n            # steps at the end in addition to the final output.\n            \"return_intermediate_steps\": False,\n            # The maximum number of steps to take before ending the\n            # execution loop.\n            \"max_iterations\": 15,\n            # The method to use for early stopping if the agent never\n            # returns `AgentFinish`. Either 'force' or 'generate'.\n     \
    \       \"early_stopping_method\": \"force\",\n            # How to handle errors raised by the agent's output parser.\n            # Defaults to `False`, which raises the error.\n            \"handle_parsing_errors\": False,\n        }\n        ```\n    runnable_kwargs (Mapping[str, Any]):\n        Optional. Additional keyword arguments for the constructor of\n        langchain.runnables.history.RunnableWithMessageHistory if\n        chat_history is specified. If chat_history is None, this will be\n        ignored.\n    model_builder (Callable):\n        Optional. Callable that returns a new language model. Defaults\n        to a a callable that returns ChatVertexAI based on `model`,\n        `model_kwargs` and the parameters in `vertexai.init`.\n    runnable_builder (Callable):\n        Optional. Callable that returns a new runnable. This can be used\n        for customizing the orchestration logic of the Agent based on\n        the model returned by `model_builder` and the rest of\
    \ the input\n        arguments.\n    enable_tracing (bool):\n        Optional. Whether to enable tracing in Cloud Trace. Defaults to\n        False.\n    instrumentor_builder (Callable[..., Any]):\n        Optional. Callable that returns a new instrumentor. This can be\n        used for customizing the instrumentation logic of the Agent.\n        If not provided, a default instrumentor builder will be used.\n        This parameter is ignored if `enable_tracing` is False.\n\nRaises:\n    ValueError: If both `prompt` and `system_instruction` are specified.\n    TypeError: If there is an invalid tool (e.g. function with an input\n    that did not specify its type)."
  signature: 'def __init__(self, model: str, *, system_instruction: typing.Optional[str]=None, prompt: typing.Optional[RunnableSerializable]=None, tools: typing.Optional[typing.Sequence[_ToolLike]]=None, output_parser: typing.Optional[RunnableSerializable]=None, chat_history: typing.Optional[GetSessionHistoryCallable]=None, model_kwargs: typing.Optional[typing.Mapping[str, typing.Any]]=None, model_tool_kwargs: typing.Optional[typing.Mapping[str, typing.Any]]=None, agent_executor_kwargs: typing.Optional[typing.Mapping[str, typing.Any]]=None, runnable_kwargs: typing.Optional[typing.Mapping[str, typing.Any]]=None, model_builder: typing.Optional[typing.Callable]=None, runnable_builder: typing.Optional[typing.Callable]=None, enable_tracing: bool=False, instrumentor_builder: typing.Optional[typing.Callable[Ellipsis, typing.Any]]=None):'
- rank: 2740
  id: vertexai.agent_engines.templates.langchain.LangchainAgent.clone
  name: clone
  file_path: env/lib/python3.13/site-packages/vertexai/agent_engines/templates/langchain.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: Returns a clone of the LangchainAgent.
  signature: 'def clone(self) -> vertexai.agent_engines.templates.langchain.LangchainAgent:'
- rank: 2741
  id: vertexai.agent_engines.templates.langchain.LangchainAgent.query
  name: query
  file_path: env/lib/python3.13/site-packages/vertexai/agent_engines/templates/langchain.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Queries the Agent with the given input and config.\n\nArgs:\n    input (Union[str, Mapping[str, Any]]):\n        Required. The input to be passed to the Agent.\n    config (langchain_core.runnables.RunnableConfig):\n        Optional. The config (if any) to be used for invoking the Agent.\n    **kwargs:\n        Optional. Any additional keyword arguments to be passed to the\n        `.invoke()` method of the corresponding AgentExecutor.\n\nReturns:\n    The output of querying the Agent with the given input and config."
  signature: 'def query(self, *, input: typing.Union[str, typing.Mapping[str, typing.Any]], config: typing.Optional[RunnableConfig]=None) -> typing.Dict[str, typing.Any]:'
- rank: 2742
  id: vertexai.agent_engines.templates.langchain.LangchainAgent.set_up
  name: set_up
  file_path: env/lib/python3.13/site-packages/vertexai/agent_engines/templates/langchain.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: 'Sets up the agent for execution of queries at runtime.


    It initializes the model, binds the model with tools, and connects it

    with the prompt template and output parser.


    This method should not be called for an object being passed to the

    service for deployment, as it might initialize clients that can not be

    serialized.'
  signature: 'def set_up(self):'
- rank: 2743
  id: vertexai.agent_engines.templates.langchain.LangchainAgent.stream_query
  name: stream_query
  file_path: env/lib/python3.13/site-packages/vertexai/agent_engines/templates/langchain.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Stream queries the Agent with the given input and config.\n\nArgs:\n    input (Union[str, Mapping[str, Any]]):\n        Required. The input to be passed to the Agent.\n    config (langchain_core.runnables.RunnableConfig):\n        Optional. The config (if any) to be used for invoking the Agent.\n    **kwargs:\n        Optional. Any additional keyword arguments to be passed to the\n        `.invoke()` method of the corresponding AgentExecutor.\n\nYields:\n    The output of querying the Agent with the given input and config."
  signature: 'def stream_query(self, *, input: typing.Union[str, typing.Mapping[str, typing.Any]], config: typing.Optional[RunnableConfig]=None) -> typing.Iterable[typing.Any]:'
- rank: 2744
  id: vertexai.agent_engines.templates.langgraph
  name: langgraph
  file_path: env/lib/python3.13/site-packages/vertexai/agent_engines/templates/langgraph.py
  type: MODULE
  group: Orphan
  usage_score: 0
- rank: 2745
  id: vertexai.agent_engines.templates.langgraph.LanggraphAgent
  name: LanggraphAgent
  file_path: env/lib/python3.13/site-packages/vertexai/agent_engines/templates/langgraph.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: A LangGraph Agent.
  constructor_signature: 'def __init__(self, model: str, *, tools: typing.Optional[typing.Sequence[_ToolLike]]=None, model_kwargs: typing.Optional[typing.Mapping[str, typing.Any]]=None, model_tool_kwargs: typing.Optional[typing.Mapping[str, typing.Any]]=None, model_builder: typing.Optional[typing.Callable[Ellipsis, BaseLanguageModel]]=None, runnable_kwargs: typing.Optional[typing.Mapping[str, typing.Any]]=None, runnable_builder: typing.Optional[typing.Callable[Ellipsis, typing.Any]]=None, checkpointer_kwargs: typing.Optional[typing.Mapping[str, typing.Any]]=None, checkpointer_builder: typing.Optional[typing.Callable[Ellipsis, BaseCheckpointSaver]]=None, enable_tracing: bool=False, instrumentor_builder: typing.Optional[typing.Callable[Ellipsis, typing.Any]]=None):'
  methods:
  - signature: 'def set_up(self):'
    docstring: 'Sets up the agent for execution of queries at runtime.


      It initializes the model, binds the model with tools, and connects it

      with the prompt template and output parser.


      This method should not be called for an object that being passed to

      the ReasoningEngine service for deployment, as it initializes clients

      that can not be serialized.'
  - signature: 'def clone(self) -> vertexai.agent_engines.templates.langgraph.LanggraphAgent:'
    docstring: Returns a clone of the LanggraphAgent.
  - signature: 'def query(self, *, input: typing.Union[str, typing.Mapping[str, typing.Any]], config: typing.Optional[dict[str, typing.Any]]=None) -> typing.Dict[str, typing.Any]:'
    docstring: "Queries the Agent with the given input and config.\n\nArgs:\n    input (Union[str, Mapping[str, Any]]):\n        Required. The input to be passed to the Agent.\n    config (langchain_core.runnables.RunnableConfig):\n        Optional. The config (if any) to be used for invoking the Agent.\n    **kwargs:\n        Optional. Any additional keyword arguments to be passed to the\n        `.invoke()` method of the corresponding AgentExecutor.\n\nReturns:\n    The output of querying the Agent with the given input and config."
  - signature: 'def stream_query(self, *, input: typing.Union[str, typing.Mapping[str, typing.Any]], config: typing.Optional[dict[str, typing.Any]]=None) -> typing.Iterable[typing.Any]:'
    docstring: "Stream queries the Agent with the given input and config.\n\nArgs:\n    input (Union[str, Mapping[str, Any]]):\n        Required. The input to be passed to the Agent.\n    config (langchain_core.runnables.RunnableConfig):\n        Optional. The config (if any) to be used for invoking the Agent.\n    **kwargs:\n        Optional. Any additional keyword arguments to be passed to the\n        `.invoke()` method of the corresponding AgentExecutor.\n\nYields:\n    The output of querying the Agent with the given input and config."
  - signature: 'def get_state_history(self, config: typing.Optional[dict[str, typing.Any]]) -> typing.Iterable[typing.Any]:'
    docstring: "Gets the state history of the Agent.\n\nArgs:\n    config (Optional[RunnableConfig]):\n        Optional. The config for invoking the Agent.\n    **kwargs:\n        Optional. Additional keyword arguments for the `.invoke()` method.\n\nYields:\n    Dict[str, Any]: The state history of the Agent."
  - signature: 'def get_state(self, config: typing.Optional[dict[str, typing.Any]]) -> typing.Dict[str, typing.Any]:'
    docstring: "Gets the current state of the Agent.\n\nArgs:\n    config (Optional[RunnableConfig]):\n        Optional. The config for invoking the Agent.\n    **kwargs:\n        Optional. Additional keyword arguments for the `.invoke()` method.\n\nReturns:\n    Dict[str, Any]: The current state of the Agent."
  - signature: 'def update_state(self, config: typing.Optional[dict[str, typing.Any]]) -> typing.Dict[str, typing.Any]:'
    docstring: "Updates the state of the Agent.\n\nArgs:\n    config (Optional[RunnableConfig]):\n        Optional. The config for invoking the Agent.\n    **kwargs:\n        Optional. Additional keyword arguments for the `.invoke()` method.\n\nReturns:\n    Dict[str, Any]: The updated state of the Agent."
  - signature: 'def register_operations(self) -> typing.Mapping[str, typing.Sequence[str]]:'
    docstring: "Registers the operations of the Agent.\n\nThis mapping defines how different operation modes (e.g., \"\", \"stream\")\nare implemented by specific methods of the Agent.  The \"default\" mode,\nrepresented by the empty string ``, is associated with the `query` API,\nwhile the \"stream\" mode is associated with the `stream_query` API.\n\nReturns:\n    Mapping[str, Sequence[str]]: A mapping of operation modes to a list\n    of method names that implement those operation modes."
  properties:
  - signature: 'agent_framework: str'
- rank: 2746
  id: vertexai.agent_engines.templates.langgraph.LanggraphAgent.__init__
  name: __init__
  file_path: env/lib/python3.13/site-packages/vertexai/agent_engines/templates/langgraph.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Initializes the LangGraph Agent.\n\nUnder-the-hood, assuming .set_up() is called, this will correspond to\n```python\nmodel = model_builder(model_name=model, model_kwargs=model_kwargs)\nrunnable = runnable_builder(\n    model=model,\n    tools=tools,\n    model_tool_kwargs=model_tool_kwargs,\n    runnable_kwargs=runnable_kwargs,\n)\n```\n\nWhen everything is based on their default values, this corresponds to\n```python\n# model_builder\nfrom langchain_google_vertexai import ChatVertexAI\nllm = ChatVertexAI(model_name=model, **model_kwargs)\n\n# runnable_builder\nfrom langgraph.prebuilt import create_react_agent\nllm_with_tools = llm.bind_tools(tools=tools, **model_tool_kwargs)\nrunnable = create_react_agent(\n    llm_with_tools,\n    tools=tools,\n    **runnable_kwargs,\n)\n```\n\nBy default, no checkpointer is used (i.e. there is no state history). To\nenable checkpointing, provide a `checkpointer_builder` function that\nreturns a checkpointer instance.\n\n**Example using\
    \ Spanner:**\n```python\ndef checkpointer_builder(instance_id, database_id, project_id, **kwargs):\n    from langchain_google_spanner import SpannerCheckpointSaver\n\n    checkpointer = SpannerCheckpointSaver(instance_id, database_id, project_id)\n    with checkpointer.cursor() as cur:\n        cur.execute(\"DROP TABLE IF EXISTS checkpoints\")\n        cur.execute(\"DROP TABLE IF EXISTS checkpoint_writes\")\n    checkpointer.setup()\n\n    return checkpointer\n```\n\n**Example using an in-memory checkpointer:**\n```python\ndef checkpointer_builder(**kwargs):\n    from langgraph.checkpoint.memory import MemorySaver\n\n    return MemorySaver()\n```\n\nThe `checkpointer_builder` function will be called with any keyword\narguments passed to the agent's constructor.  Ensure your\n`checkpointer_builder` function accepts `**kwargs` to handle these\narguments, even if unused.\n\nArgs:\n    model (str):\n        Optional. The name of the model (e.g. \"gemini-1.0-pro\").\n    tools (Sequence[langchain_core.tools.BaseTool,\
    \ Callable]):\n        Optional. The tools for the agent to be able to use. All input\n        callables (e.g. function or class method) will be converted\n        to a langchain.tools.base.StructuredTool. Defaults to None.\n    model_kwargs (Mapping[str, Any]):\n        Optional. Additional keyword arguments for the constructor of\n        chat_models.ChatVertexAI. An example would be\n        ```\n        {\n            # temperature (float): Sampling temperature, it controls the\n            # degree of randomness in token selection.\n            \"temperature\": 0.28,\n            # max_output_tokens (int): Token limit determines the\n            # maximum amount of text output from one prompt.\n            \"max_output_tokens\": 1000,\n            # top_p (float): Tokens are selected from most probable to\n            # least, until the sum of their probabilities equals the\n            # top_p value.\n            \"top_p\": 0.95,\n            # top_k (int): How the model selects\
    \ tokens for output, the\n            # next token is selected from among the top_k most probable\n            # tokens.\n            \"top_k\": 40,\n        }\n        ```\n    model_tool_kwargs (Mapping[str, Any]):\n        Optional. Additional keyword arguments when binding tools to the\n        model using `model.bind_tools()`.\n    model_builder (Callable[..., BaseLanguageModel]):\n        Optional. Callable that returns a new language model. Defaults\n        to a a callable that returns ChatVertexAI based on `model`,\n        `model_kwargs` and the parameters in `vertexai.init`.\n    runnable_kwargs (Mapping[str, Any]):\n        Optional. Additional keyword arguments for the constructor of\n        langchain.runnables.history.RunnableWithMessageHistory if\n        chat_history is specified. If chat_history is None, this will be\n        ignored.\n    runnable_builder (Callable[..., RunnableSerializable]):\n        Optional. Callable that returns a new runnable. This can be used\n\
    \        for customizing the orchestration logic of the Agent based on\n        the model returned by `model_builder` and the rest of the input\n        arguments.\n    checkpointer_kwargs (Mapping[str, Any]):\n        Optional. Additional keyword arguments for the constructor of\n        the checkpointer returned by `checkpointer_builder`.\n    checkpointer_builder (Callable[..., \"BaseCheckpointSaver\"]):\n        Optional. Callable that returns a checkpointer. This can be used\n        for defining the checkpointer of the Agent. Defaults to None.\n    enable_tracing (bool):\n        Optional. Whether to enable tracing in Cloud Trace. Defaults to\n        False.\n    instrumentor_builder (Callable[..., Any]):\n        Optional. Callable that returns a new instrumentor. This can be\n        used for customizing the instrumentation logic of the Agent.\n        If not provided, a default instrumentor builder will be used.\n        This parameter is ignored if `enable_tracing` is False.\n\
    \nRaises:\n    TypeError: If there is an invalid tool (e.g. function with an input\n    that did not specify its type)."
  signature: 'def __init__(self, model: str, *, tools: typing.Optional[typing.Sequence[_ToolLike]]=None, model_kwargs: typing.Optional[typing.Mapping[str, typing.Any]]=None, model_tool_kwargs: typing.Optional[typing.Mapping[str, typing.Any]]=None, model_builder: typing.Optional[typing.Callable[Ellipsis, BaseLanguageModel]]=None, runnable_kwargs: typing.Optional[typing.Mapping[str, typing.Any]]=None, runnable_builder: typing.Optional[typing.Callable[Ellipsis, typing.Any]]=None, checkpointer_kwargs: typing.Optional[typing.Mapping[str, typing.Any]]=None, checkpointer_builder: typing.Optional[typing.Callable[Ellipsis, BaseCheckpointSaver]]=None, enable_tracing: bool=False, instrumentor_builder: typing.Optional[typing.Callable[Ellipsis, typing.Any]]=None):'
- rank: 2747
  id: vertexai.agent_engines.templates.langgraph.LanggraphAgent.clone
  name: clone
  file_path: env/lib/python3.13/site-packages/vertexai/agent_engines/templates/langgraph.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: Returns a clone of the LanggraphAgent.
  signature: 'def clone(self) -> vertexai.agent_engines.templates.langgraph.LanggraphAgent:'
- rank: 2748
  id: vertexai.agent_engines.templates.langgraph.LanggraphAgent.get_state
  name: get_state
  file_path: env/lib/python3.13/site-packages/vertexai/agent_engines/templates/langgraph.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Gets the current state of the Agent.\n\nArgs:\n    config (Optional[RunnableConfig]):\n        Optional. The config for invoking the Agent.\n    **kwargs:\n        Optional. Additional keyword arguments for the `.invoke()` method.\n\nReturns:\n    Dict[str, Any]: The current state of the Agent."
  signature: 'def get_state(self, config: typing.Optional[dict[str, typing.Any]]) -> typing.Dict[str, typing.Any]:'
- rank: 2749
  id: vertexai.agent_engines.templates.langgraph.LanggraphAgent.get_state_history
  name: get_state_history
  file_path: env/lib/python3.13/site-packages/vertexai/agent_engines/templates/langgraph.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Gets the state history of the Agent.\n\nArgs:\n    config (Optional[RunnableConfig]):\n        Optional. The config for invoking the Agent.\n    **kwargs:\n        Optional. Additional keyword arguments for the `.invoke()` method.\n\nYields:\n    Dict[str, Any]: The state history of the Agent."
  signature: 'def get_state_history(self, config: typing.Optional[dict[str, typing.Any]]) -> typing.Iterable[typing.Any]:'
- rank: 2750
  id: vertexai.agent_engines.templates.langgraph.LanggraphAgent.query
  name: query
  file_path: env/lib/python3.13/site-packages/vertexai/agent_engines/templates/langgraph.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Queries the Agent with the given input and config.\n\nArgs:\n    input (Union[str, Mapping[str, Any]]):\n        Required. The input to be passed to the Agent.\n    config (langchain_core.runnables.RunnableConfig):\n        Optional. The config (if any) to be used for invoking the Agent.\n    **kwargs:\n        Optional. Any additional keyword arguments to be passed to the\n        `.invoke()` method of the corresponding AgentExecutor.\n\nReturns:\n    The output of querying the Agent with the given input and config."
  signature: 'def query(self, *, input: typing.Union[str, typing.Mapping[str, typing.Any]], config: typing.Optional[dict[str, typing.Any]]=None) -> typing.Dict[str, typing.Any]:'
- rank: 2751
  id: vertexai.agent_engines.templates.langgraph.LanggraphAgent.register_operations
  name: register_operations
  file_path: env/lib/python3.13/site-packages/vertexai/agent_engines/templates/langgraph.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Registers the operations of the Agent.\n\nThis mapping defines how different operation modes (e.g., \"\", \"stream\")\nare implemented by specific methods of the Agent.  The \"default\" mode,\nrepresented by the empty string ``, is associated with the `query` API,\nwhile the \"stream\" mode is associated with the `stream_query` API.\n\nReturns:\n    Mapping[str, Sequence[str]]: A mapping of operation modes to a list\n    of method names that implement those operation modes."
  signature: 'def register_operations(self) -> typing.Mapping[str, typing.Sequence[str]]:'
- rank: 2752
  id: vertexai.agent_engines.templates.langgraph.LanggraphAgent.set_up
  name: set_up
  file_path: env/lib/python3.13/site-packages/vertexai/agent_engines/templates/langgraph.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: 'Sets up the agent for execution of queries at runtime.


    It initializes the model, binds the model with tools, and connects it

    with the prompt template and output parser.


    This method should not be called for an object that being passed to

    the ReasoningEngine service for deployment, as it initializes clients

    that can not be serialized.'
  signature: 'def set_up(self):'
- rank: 2753
  id: vertexai.agent_engines.templates.langgraph.LanggraphAgent.stream_query
  name: stream_query
  file_path: env/lib/python3.13/site-packages/vertexai/agent_engines/templates/langgraph.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Stream queries the Agent with the given input and config.\n\nArgs:\n    input (Union[str, Mapping[str, Any]]):\n        Required. The input to be passed to the Agent.\n    config (langchain_core.runnables.RunnableConfig):\n        Optional. The config (if any) to be used for invoking the Agent.\n    **kwargs:\n        Optional. Any additional keyword arguments to be passed to the\n        `.invoke()` method of the corresponding AgentExecutor.\n\nYields:\n    The output of querying the Agent with the given input and config."
  signature: 'def stream_query(self, *, input: typing.Union[str, typing.Mapping[str, typing.Any]], config: typing.Optional[dict[str, typing.Any]]=None) -> typing.Iterable[typing.Any]:'
- rank: 2754
  id: vertexai.agent_engines.templates.langgraph.LanggraphAgent.update_state
  name: update_state
  file_path: env/lib/python3.13/site-packages/vertexai/agent_engines/templates/langgraph.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Updates the state of the Agent.\n\nArgs:\n    config (Optional[RunnableConfig]):\n        Optional. The config for invoking the Agent.\n    **kwargs:\n        Optional. Additional keyword arguments for the `.invoke()` method.\n\nReturns:\n    Dict[str, Any]: The updated state of the Agent."
  signature: 'def update_state(self, config: typing.Optional[dict[str, typing.Any]]) -> typing.Dict[str, typing.Any]:'
- rank: 2755
  id: vertexai.agent_engines.update
  name: update
  file_path: env/lib/python3.13/site-packages/vertexai/agent_engines/__init__.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Updates an existing Agent Engine.\n\nThis method updates the configuration of a deployed Agent Engine, identified\nby its resource name. Unlike the `create` function which requires an\n`agent_engine` object, all arguments in this method are optional. This\nmethod allows you to modify individual aspects of the configuration by\nproviding any of the optional arguments.\n\nArgs:\n    resource_name (str):\n        Required. The name of the Agent Engine to be updated. Format:\n        `projects/{project}/locations/{location}/reasoningEngines/{resource_id}`.\n    agent_engine (AgentEngineInterface):\n        Optional. The instance to be used as the updated Agent Engine. If it\n        is not specified, the existing instance will be used.\n    requirements (Union[str, Sequence[str]]):\n        Optional. The set of PyPI dependencies needed. It can either be\n        the path to a single file (requirements.txt), or an ordered list\n        of strings corresponding to each line of the\
    \ requirements file.\n        If it is not specified, the existing requirements will be used.\n        If it is set to an empty string or list, the existing\n        requirements will be removed.\n    display_name (str):\n        Optional. The user-defined name of the Agent Engine.\n        The name can be up to 128 characters long and can comprise any\n        UTF-8 character.\n    description (str):\n        Optional. The description of the Agent Engine.\n    gcs_dir_name (str):\n        Optional. The GCS bucket directory under `staging_bucket` to\n        use for staging the artifacts needed.\n    extra_packages (Sequence[str]):\n        Optional. The set of extra user-provided packages (if any). If\n        it is not specified, the existing extra packages will be used.\n        If it is set to an empty list, the existing extra packages will\n        be removed.\n    env_vars (Union[Sequence[str], Dict[str, Union[str, SecretRef]]]):\n        Optional. The environment variables to\
    \ be set when running the\n        Agent Engine. If it is a list of strings, each string should be\n        a valid key to `os.environ`. If it is a dictionary, the keys are\n        the environment variable names, and the values are the\n        corresponding values.\n    build_options (Dict[str, Sequence[str]]):\n        Optional. The build options for the Agent Engine. This includes\n        options such as installation scripts.\n    service_account (str):\n        Optional. The service account to be used for the Agent Engine. If\n        not specified, the default reasoning engine service agent service\n        account will be used.\n    min_instances (int):\n        Optional. The minimum number of instances to run the Agent Engine.\n        If not specified, the default value will be used.\n    max_instances (int):\n        Optional. The maximum number of instances to run the Agent Engine.\n        If not specified, the default value will be used.\n    resource_limits (Dict[str,\
    \ str]):\n        Optional. The resource limits for the Agent Engine. If not\n        specified, the default value will be used.\n    container_concurrency (int):\n        Optional. The container concurrency for the Agent Engine. If not\n        specified, the default value will be used.\n    encryption_spec (EncryptionSpec):\n        Optional. The encryption spec for the Agent Engine. If not\n        specified, the default encryption spec will be used.\n\nReturns:\n    AgentEngine: The Agent Engine that was updated.\n\nRaises:\n    ValueError: If the `staging_bucket` was not set using vertexai.init.\n    ValueError: If the `staging_bucket` does not start with \"gs://\".\n    FileNotFoundError: If `extra_packages` includes a file or directory\n    that does not exist.\n    ValueError: if none of `display_name`, `description`,\n    `requirements`, `extra_packages`, `agent_engine`, or `build_options`\n    were specified.\n    IOError: If requirements is a string that corresponds to a\n\
    \    nonexistent file."
  signature: 'def update(resource_name: str, *, agent_engine: typing.Optional[typing.Union[vertexai.agent_engines._agent_engines.Queryable, vertexai.agent_engines._agent_engines.OperationRegistrable]]=None, requirements: typing.Optional[typing.Union[str, typing.Sequence[str]]]=None, display_name: typing.Optional[str]=None, description: typing.Optional[str]=None, gcs_dir_name: typing.Optional[str]=None, extra_packages: typing.Optional[typing.Sequence[str]]=None, env_vars: typing.Optional[typing.Union[typing.Sequence[str], typing.Dict[str, typing.Union[str, google.cloud.aiplatform_v1.types.SecretRef]]]]=None, build_options: typing.Optional[typing.Dict[str, typing.Sequence[str]]]=None, service_account: typing.Optional[str]=None, psc_interface_config: typing.Optional[google.cloud.aiplatform_v1.types.PscInterfaceConfig]=None, min_instances: typing.Optional[int]=None, max_instances: typing.Optional[int]=None, resource_limits: typing.Optional[typing.Dict[str, str]]=None, container_concurrency:
    typing.Optional[int]=None, encryption_spec: typing.Optional[google.cloud.aiplatform_v1.types.EncryptionSpec]=None) -> vertexai.agent_engines._agent_engines.AgentEngine:'
- rank: 2756
  id: vertexai.batch_prediction
  name: batch_prediction
  file_path: env/lib/python3.13/site-packages/vertexai/batch_prediction/__init__.py
  type: MODULE
  group: Orphan
  usage_score: 0
  docstring: Classes for batch prediction.
- rank: 2757
  id: vertexai.caching
  name: caching
  file_path: env/lib/python3.13/site-packages/vertexai/caching/__init__.py
  type: MODULE
  group: Orphan
  usage_score: 0
  docstring: Classes for working with the Gemini models.
- rank: 2758
  id: vertexai.evaluation
  name: evaluation
  file_path: env/lib/python3.13/site-packages/vertexai/evaluation/__init__.py
  type: MODULE
  group: Orphan
  usage_score: 0
  docstring: Vertex Gen AI Evaluation Service Module.
- rank: 2759
  id: vertexai.evaluation.constants
  name: constants
  file_path: env/lib/python3.13/site-packages/vertexai/evaluation/constants.py
  type: MODULE
  group: Orphan
  usage_score: 0
  docstring: Constants for evaluation.
- rank: 2760
  id: vertexai.evaluation.constants.Dataset
  name: Dataset
  file_path: env/lib/python3.13/site-packages/vertexai/evaluation/constants.py
  type: CLASS
  group: Orphan
  usage_score: 0
  constructor_signature: 'def __init__(self, *, MODEL_RESPONSE_COLUMN: str = ''response'', BASELINE_MODEL_RESPONSE_COLUMN: str = ''baseline_model_response'', PROMPT_COLUMN: str = ''prompt'', REFERENCE_COLUMN: str = ''reference'', SOURCE_COLUMN: str = ''source''):'
  properties:
  - signature: 'MODEL_RESPONSE_COLUMN: str'
  - signature: 'BASELINE_MODEL_RESPONSE_COLUMN: str'
  - signature: 'PROMPT_COLUMN: str'
  - signature: 'REFERENCE_COLUMN: str'
  - signature: 'SOURCE_COLUMN: str'
- rank: 2761
  id: vertexai.evaluation.constants.Metric
  name: Metric
  file_path: env/lib/python3.13/site-packages/vertexai/evaluation/constants.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: Namespace for Metrics.
  constructor_signature: 'def __init__(self, *, COHERENCE: str = ''coherence'', FLUENCY: str = ''fluency'', SAFETY: str = ''safety'', GROUNDEDNESS: str = ''groundedness'', INSTRUCTION_FOLLOWING: str = ''instruction_following'', VERBOSITY: str = ''verbosity'', TEXT_QUALITY: str = ''text_quality'', SUMMARIZATION_QUALITY: str = ''summarization_quality'', QUESTION_ANSWERING_QUALITY: str = ''question_answering_quality'', MULTI_TURN_CHAT_QUALITY: str = ''multi_turn_chat_quality'', MULTI_TURN_SAFETY: str = ''multi_turn_safety'', PAIRWISE_COHERENCE: str = ''pairwise_coherence'', PAIRWISE_FLUENCY: str = ''pairwise_fluency'', PAIRWISE_SAFETY: str = ''pairwise_safety'', PAIRWISE_GROUNDEDNESS: str = ''pairwise_groundedness'', PAIRWISE_INSTRUCTION_FOLLOWING: str = ''pairwise_instruction_following'', PAIRWISE_VERBOSITY: str = ''pairwise_verbosity'', PAIRWISE_TEXT_QUALITY: str = ''pairwise_text_quality'', PAIRWISE_SUMMARIZATION_QUALITY: str = ''pairwise_summarization_quality'', PAIRWISE_QUESTION_ANSWERING_QUALITY:
    str = ''pairwise_question_answering_quality'', PAIRWISE_MULTI_TURN_CHAT_QUALITY: str = ''pairwise_multi_turn_chat_quality'', PAIRWISE_MULTI_TURN_SAFETY: str = ''pairwise_multi_turn_safety'', POINTWISE_METRIC: str = ''pointwise_metric'', PAIRWISE_METRIC: str = ''pairwise_metric'', COMET: str = ''comet'', METRICX: str = ''metricx'', EXACT_MATCH: str = ''exact_match'', BLEU: str = ''bleu'', ROUGE: str = ''rouge'', ROUGE_1: str = ''rouge_1'', ROUGE_2: str = ''rouge_2'', ROUGE_L: str = ''rouge_l'', ROUGE_L_SUM: str = ''rouge_l_sum'', TOOL_CALL_VALID: str = ''tool_call_valid'', TOOL_NAME_MATCH: str = ''tool_name_match'', TOOL_PARAMETER_KEY_MATCH: str = ''tool_parameter_key_match'', TOOL_PARAMETER_KV_MATCH: str = ''tool_parameter_kv_match'', AUTOMATIC_METRIC_LIST: Any = (EXACT_MATCH, BLEU, ROUGE, ROUGE_1, ROUGE_2, ROUGE_L, ROUGE_L_SUM, TOOL_CALL_VALID, TOOL_NAME_MATCH, TOOL_PARAMETER_KEY_MATCH, TOOL_PARAMETER_KV_MATCH), POINTWISE_METRIC_PROMPT_TEMPLATE_EXAMPLE_LIST: Any = (COHERENCE, FLUENCY,
    SAFETY, GROUNDEDNESS, INSTRUCTION_FOLLOWING, VERBOSITY, TEXT_QUALITY, SUMMARIZATION_QUALITY, QUESTION_ANSWERING_QUALITY, MULTI_TURN_CHAT_QUALITY, MULTI_TURN_SAFETY), PAIRWISE_METRIC_PROMPT_TEMPLATE_EXAMPLE_LIST: Any = (PAIRWISE_COHERENCE, PAIRWISE_FLUENCY, PAIRWISE_SAFETY, PAIRWISE_GROUNDEDNESS, PAIRWISE_INSTRUCTION_FOLLOWING, PAIRWISE_VERBOSITY, PAIRWISE_TEXT_QUALITY, PAIRWISE_SUMMARIZATION_QUALITY, PAIRWISE_QUESTION_ANSWERING_QUALITY, PAIRWISE_MULTI_TURN_CHAT_QUALITY, PAIRWISE_MULTI_TURN_SAFETY)):'
  properties:
  - signature: 'COHERENCE: str'
  - signature: 'FLUENCY: str'
  - signature: 'SAFETY: str'
  - signature: 'GROUNDEDNESS: str'
  - signature: 'INSTRUCTION_FOLLOWING: str'
  - signature: 'VERBOSITY: str'
  - signature: 'TEXT_QUALITY: str'
  - signature: 'SUMMARIZATION_QUALITY: str'
  - signature: 'QUESTION_ANSWERING_QUALITY: str'
  - signature: 'MULTI_TURN_CHAT_QUALITY: str'
  - signature: 'MULTI_TURN_SAFETY: str'
  - signature: 'PAIRWISE_COHERENCE: str'
  - signature: 'PAIRWISE_FLUENCY: str'
  - signature: 'PAIRWISE_SAFETY: str'
  - signature: 'PAIRWISE_GROUNDEDNESS: str'
  - signature: 'PAIRWISE_INSTRUCTION_FOLLOWING: str'
  - signature: 'PAIRWISE_VERBOSITY: str'
  - signature: 'PAIRWISE_TEXT_QUALITY: str'
  - signature: 'PAIRWISE_SUMMARIZATION_QUALITY: str'
  - signature: 'PAIRWISE_QUESTION_ANSWERING_QUALITY: str'
  - signature: 'PAIRWISE_MULTI_TURN_CHAT_QUALITY: str'
  - signature: 'PAIRWISE_MULTI_TURN_SAFETY: str'
  - signature: 'POINTWISE_METRIC: str'
  - signature: 'PAIRWISE_METRIC: str'
  - signature: 'COMET: str'
  - signature: 'METRICX: str'
  - signature: 'EXACT_MATCH: str'
  - signature: 'BLEU: str'
  - signature: 'ROUGE: str'
  - signature: 'ROUGE_1: str'
  - signature: 'ROUGE_2: str'
  - signature: 'ROUGE_L: str'
  - signature: 'ROUGE_L_SUM: str'
  - signature: 'TOOL_CALL_VALID: str'
  - signature: 'TOOL_NAME_MATCH: str'
  - signature: 'TOOL_PARAMETER_KEY_MATCH: str'
  - signature: 'TOOL_PARAMETER_KV_MATCH: str'
  - signature: 'AUTOMATIC_METRIC_LIST: Any'
  - signature: 'POINTWISE_METRIC_PROMPT_TEMPLATE_EXAMPLE_LIST: Any'
  - signature: 'PAIRWISE_METRIC_PROMPT_TEMPLATE_EXAMPLE_LIST: Any'
- rank: 2762
  id: vertexai.evaluation.constants.MetricResult
  name: MetricResult
  file_path: env/lib/python3.13/site-packages/vertexai/evaluation/constants.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: Namespace for Metric Results.
  constructor_signature: 'def __init__(self, *, ROW_COUNT_KEY: str = ''row_count'', SCORE_KEY: str = ''score'', EXPLANATION_KEY: str = ''explanation'', PAIRWISE_CHOICE_KEY: str = ''pairwise_choice'', EXACT_MATCH_RESULTS: str = ''exact_match_results'', BLEU_RESULTS: str = ''bleu_results'', ROUGE_RESULTS: str = ''rouge_results'', TOOL_CALL_VALID_RESULTS: str = ''tool_call_valid_results'', TOOL_NAME_MATCH_RESULTS: str = ''tool_name_match_results'', TOOL_PARAMETER_KEY_MATCH_RESULTS: str = ''tool_parameter_key_match_results'', TOOL_PARAMETER_KV_MATCH_RESULTS: str = ''tool_parameter_kv_match_results'', POINTWISE_METRIC_RESULT: str = ''pointwise_metric_result'', PAIRWISE_METRIC_RESULT: str = ''pairwise_metric_result'', COMET_RESULT: str = ''comet_result'', METRICX_RESULT: str = ''metricx_result'', AUTOMATIC_METRIC_RESULTS_LIST: Any = (EXACT_MATCH_RESULTS, BLEU_RESULTS, ROUGE_RESULTS, TOOL_CALL_VALID_RESULTS, TOOL_NAME_MATCH_RESULTS, TOOL_PARAMETER_KEY_MATCH_RESULTS, TOOL_PARAMETER_KV_MATCH_RESULTS)):'
  properties:
  - signature: 'ROW_COUNT_KEY: str'
  - signature: 'SCORE_KEY: str'
  - signature: 'EXPLANATION_KEY: str'
  - signature: 'PAIRWISE_CHOICE_KEY: str'
  - signature: 'EXACT_MATCH_RESULTS: str'
  - signature: 'BLEU_RESULTS: str'
  - signature: 'ROUGE_RESULTS: str'
  - signature: 'TOOL_CALL_VALID_RESULTS: str'
  - signature: 'TOOL_NAME_MATCH_RESULTS: str'
  - signature: 'TOOL_PARAMETER_KEY_MATCH_RESULTS: str'
  - signature: 'TOOL_PARAMETER_KV_MATCH_RESULTS: str'
  - signature: 'POINTWISE_METRIC_RESULT: str'
  - signature: 'PAIRWISE_METRIC_RESULT: str'
  - signature: 'COMET_RESULT: str'
  - signature: 'METRICX_RESULT: str'
  - signature: 'AUTOMATIC_METRIC_RESULTS_LIST: Any'
- rank: 2763
  id: vertexai.evaluation.constants.QuotaLimit
  name: QuotaLimit
  file_path: env/lib/python3.13/site-packages/vertexai/evaluation/constants.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: Generative AI on Vertex AI quota limits.
  constructor_signature: 'def __init__(self, *, EVAL_SERVICE_QPS: int = 10):'
  properties:
  - signature: 'EVAL_SERVICE_QPS: int'
- rank: 2764
  id: vertexai.evaluation.eval_task
  name: eval_task
  file_path: env/lib/python3.13/site-packages/vertexai/evaluation/eval_task.py
  type: MODULE
  group: Orphan
  usage_score: 0
- rank: 2765
  id: vertexai.evaluation.eval_task.EvalTask
  name: EvalTask
  file_path: env/lib/python3.13/site-packages/vertexai/evaluation/eval_task.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: "A class representing an EvalTask.\n\nAn evaluation task assesses the ability of a Gen AI model, agent or\napplication to perform a specific task in response to prompts.\nEach evaluation task includes an evaluation dataset, which can be a set of\ntest cases and a set of metrics for assessment. These tasks provide the\nframework for running evaluations in a standardized and repeatable way,\nallowing for comparative assessment with varying run-specific parameters.\n\nDataset Details:\n\n    Default dataset column names:\n        * prompt_column_name: \"prompt\"\n        * reference_column_name: \"reference\"\n        * response_column_name: \"response\"\n        * baseline_model_response_column_name: \"baseline_model_response\"\n        * rubrics_column_name: \"rubrics\"\n\n    Requirement for different use cases:\n      * Bring-your-own-response (BYOR): You already have the data that you\n          want to evaluate stored in the dataset. Response column name can be\n        \
    \  customized by providing `response_column_name` parameter, or in the\n          `metric_column_mapping`. For BYOR pairwise evaluation, the baseline\n          model response column name can be customized by providing\n          `baseline_model_response_column_name` parameter, or\n          in the `metric_column_mapping`. If the `response` column or\n          `baseline_model_response` column is present while the\n          corresponding model is specified, an error will be raised.\n\n      * Perform model/agent inference without a prompt template: You have a dataset\n          containing the input prompts to the model/agent and want to perform\n          inference before evaluation. A column named `prompt` is required\n          in the evaluation dataset and is used directly as input to the model/agent.\n\n      * Perform model/agent inference with a prompt template: You have a dataset\n          containing the input variables to the prompt template and want to\n          assemble\
    \ the prompts for inference. Evaluation dataset\n          must contain column names corresponding to the variable names in\n          the prompt template. For example, if prompt template is\n          \"Instruction: {instruction}, context: {context}\", the dataset must\n          contain `instruction` and `context` columns.\n\nMetrics Details:\n\n    The supported metrics descriptions, rating rubrics, and the required\n    input variables can be found on the Vertex AI public documentation page.\n    [Evaluation methods and metrics](https://cloud.google.com/vertex-ai/generative-ai/docs/models/determine-eval).\n\nUsage Examples:\n\n    1. To perform bring-your-own-response(BYOR) evaluation, provide the model\n    responses in the `response` column in the dataset. If a pairwise metric is\n    used for BYOR evaluation, provide the baseline model responses in the\n    `baseline_model_response` column.\n\n      ```\n      eval_dataset = pd.DataFrame({\n              \"prompt\"  : [...],\n\
    \              \"reference\": [...],\n              \"response\" : [...],\n              \"baseline_model_response\": [...],\n      })\n      eval_task = EvalTask(\n        dataset=eval_dataset,\n        metrics=[\n                \"bleu\",\n                \"rouge_l_sum\",\n                MetricPromptTemplateExamples.Pointwise.FLUENCY,\n                MetricPromptTemplateExamples.Pairwise.SAFETY\n        ],\n        experiment=\"my-experiment\",\n      )\n      eval_result = eval_task.evaluate(experiment_run_name=\"eval-experiment-run\")\n      ```\n\n    2. To perform evaluation with Gemini model inference, specify the `model`\n    parameter with a `GenerativeModel` instance.  The input column name to the\n    model is `prompt` and must be present in the dataset.\n\n      ```\n      eval_dataset = pd.DataFrame({\n            \"reference\": [...],\n            \"prompt\"  : [...],\n      })\n      result = EvalTask(\n          dataset=eval_dataset,\n          metrics=[\"exact_match\"\
    , \"bleu\", \"rouge_1\", \"rouge_l_sum\"],\n          experiment=\"my-experiment\",\n      ).evaluate(\n          model=GenerativeModel(\"gemini-1.5-pro\"),\n          experiment_run_name=\"gemini-eval-run\"\n      )\n      ```\n\n    3. If a `prompt_template` is specified, the `prompt` column is not required.\n    Prompts can be assembled from the evaluation dataset, and all prompt\n    template variable names must be present in the dataset columns.\n      ```\n      eval_dataset = pd.DataFrame({\n          \"context\"    : [...],\n          \"instruction\": [...],\n      })\n      result = EvalTask(\n          dataset=eval_dataset,\n          metrics=[MetricPromptTemplateExamples.Pointwise.SUMMARIZATION_QUALITY],\n      ).evaluate(\n          model=GenerativeModel(\"gemini-1.5-pro\"),\n          prompt_template=\"{instruction}. Article: {context}. Summary:\",\n      )\n      ```\n\n    4. To perform evaluation with custom model inference, specify the `model`\n    parameter with a custom\
    \ inference function. The input column name to the\n    custom inference function is `prompt` and must be present in the dataset.\n\n      ```\n      from openai import OpenAI\n      client = OpenAI()\n      def custom_model_fn(input: str) -> str:\n        response = client.chat.completions.create(\n          model=\"gpt-3.5-turbo\",\n          messages=[\n            {\"role\": \"user\", \"content\": input}\n          ]\n        )\n        return response.choices[0].message.content\n\n      eval_dataset = pd.DataFrame({\n            \"prompt\"  : [...],\n            \"reference\": [...],\n      })\n      result = EvalTask(\n          dataset=eval_dataset,\n          metrics=[MetricPromptTemplateExamples.Pointwise.SAFETY],\n          experiment=\"my-experiment\",\n      ).evaluate(\n          model=custom_model_fn,\n          experiment_run_name=\"gpt-eval-run\"\n      )\n      ```\n\n    5. To perform pairwise metric evaluation with model inference step, specify\n    the `baseline_model`\
    \ input to a `PairwiseMetric` instance and the candidate\n    `model` input to the `EvalTask.evaluate()` function. The input column name\n    to both models is `prompt` and must be present in the dataset.\n\n      ```\n      baseline_model = GenerativeModel(\"gemini-1.0-pro\")\n      candidate_model = GenerativeModel(\"gemini-1.5-pro\")\n\n      pairwise_groundedness = PairwiseMetric(\n          metric_prompt_template=MetricPromptTemplateExamples.get_prompt_template(\n              \"pairwise_groundedness\"\n          ),\n          baseline_model=baseline_model,\n      )\n      eval_dataset = pd.DataFrame({\n            \"prompt\"  : [...],\n      })\n      result = EvalTask(\n          dataset=eval_dataset,\n          metrics=[pairwise_groundedness],\n          experiment=\"my-pairwise-experiment\",\n      ).evaluate(\n          model=candidate_model,\n          experiment_run_name=\"gemini-pairwise-eval-run\",\n      )\n      ```"
  constructor_signature: 'def __init__(self, *, dataset: typing.Union[pandas.DataFrame, str, typing.Dict[str, typing.Any]], metrics: typing.List[typing.Union[typing.Literal[exact_match, bleu, rouge_1, rouge_2, rouge_l, rouge_l_sum, tool_call_valid, tool_name_match, tool_parameter_key_match, tool_parameter_kv_match], vertexai.evaluation.metrics._base.CustomMetric, vertexai.evaluation.metrics._base._AutomaticMetric, vertexai.evaluation.metrics._base._TranslationMetric, vertexai.evaluation.metrics.pointwise_metric.PointwiseMetric, vertexai.evaluation.metrics.pairwise_metric.PairwiseMetric]], experiment: typing.Optional[str]=None, metric_column_mapping: typing.Optional[typing.Dict[str, str]]=None, output_uri_prefix: typing.Optional[str]=''''):'
  methods:
  - signature: 'def dataset(self) -> pandas.DataFrame:'
    docstring: Returns evaluation dataset.
  - signature: 'def metrics(self) -> typing.List[typing.Union[str, vertexai.evaluation.metrics._base.CustomMetric]]:'
    docstring: Returns metrics.
  - signature: 'def experiment(self) -> typing.Optional[str]:'
    docstring: Returns experiment name.
  - signature: 'def evaluate(self, *, model: typing.Optional[typing.Union[vertexai.evaluation.eval_task.GenerativeModel, typing.Callable[[str], str]]]=None, prompt_template: typing.Optional[str]=None, experiment_run_name: typing.Optional[str]=None, response_column_name: typing.Optional[str]=None, baseline_model_response_column_name: typing.Optional[str]=None, evaluation_service_qps: typing.Optional[float]=None, retry_timeout: float=120.0, output_file_name: typing.Optional[str]=None) -> vertexai.evaluation.eval_task.EvalResult:'
    docstring: "Runs an evaluation for the EvalTask.\n\nArgs:\n  model: A GenerativeModel instance or a custom model function to generate\n    responses to evaluate. If not provided, the evaluation can be performed\n    in the bring-your-own-response (BYOR) mode.\n  prompt_template: The prompt template to use for the evaluation. If not\n    set, the prompt template that was used to create the EvalTask will be\n    used.\n  experiment_run_name: The name of the experiment run to log the evaluation\n    to if an experiment is set for this EvalTask. If not provided, a random\n    unique experiment run name is used.\n  response_column_name: The column name of model response in the dataset. If\n    provided, this will override the `metric_column_mapping` of the `EvalTask`.\n  baseline_model_response_column_name: The column name of baseline model\n    response in the dataset for pairwise metrics. If provided, this will\n    override the `metric_column_mapping` of the `EvalTask`\n  evaluation_service_qps:\
      \ The custom QPS limit for the evaluation service.\n  retry_timeout: How long to keep retrying the evaluation requests for\n    the whole evaluation dataset, in seconds.\n  output_file_name: The file name with csv suffix to store the output\n    metrics_table.\n\nReturns:\n  The evaluation result."
  - signature: 'def display_runs(self):'
    docstring: Displays experiment runs associated with this EvalTask.
- rank: 2766
  id: vertexai.evaluation.eval_task.EvalTask.__init__
  name: __init__
  file_path: env/lib/python3.13/site-packages/vertexai/evaluation/eval_task.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Initializes an EvalTask.\n\nArgs:\n    dataset: The dataset to be evaluated.\n        Supports the following dataset formats:\n        * pandas.DataFrame: Used directly for evaluation.\n        * Dict: Converted to a pandas DataFrame before evaluation.\n        * str: Interpreted as a file path or URI. Supported formats include:\n            * Local JSONL or CSV files:  Loaded from the local filesystem.\n            * GCS JSONL or CSV files: Loaded from Google Cloud Storage\n                (e.g., 'gs://bucket/data.csv').\n            * BigQuery table URI: Loaded from Google Cloud BigQuery\n                (e.g., 'bq://project-id.dataset.table_name').\n    metrics: The list of metric names, or Metric instances to evaluate.\n      Prompt template is required for PairwiseMetric.\n    experiment: The name of the experiment to log the evaluations to.\n    metric_column_mapping: An optional dictionary column mapping that\n      overrides the metric prompt template input variable\
    \ names with\n      mapped the evaluation dataset column names, used during evaluation.\n      For example, if the input_variables of the metric prompt template\n      are [\"context\", \"reference\"], the metric_column_mapping can be\n        {\n            \"context\": \"news_context\",\n            \"reference\": \"ground_truth\",\n            \"response\": \"model_1_response\"\n        }\n      if the dataset has columns \"news_context\", \"ground_truth\" and\n      \"model_1_response\".\n    output_uri_prefix: GCS location to store the metrics_table from\n      evaluation results."
  signature: 'def __init__(self, *, dataset: typing.Union[pandas.DataFrame, str, typing.Dict[str, typing.Any]], metrics: typing.List[typing.Union[typing.Literal[exact_match, bleu, rouge_1, rouge_2, rouge_l, rouge_l_sum, tool_call_valid, tool_name_match, tool_parameter_key_match, tool_parameter_kv_match], vertexai.evaluation.metrics._base.CustomMetric, vertexai.evaluation.metrics._base._AutomaticMetric, vertexai.evaluation.metrics._base._TranslationMetric, vertexai.evaluation.metrics.pointwise_metric.PointwiseMetric, vertexai.evaluation.metrics.pairwise_metric.PairwiseMetric]], experiment: typing.Optional[str]=None, metric_column_mapping: typing.Optional[typing.Dict[str, str]]=None, output_uri_prefix: typing.Optional[str]=''''):'
- rank: 2767
  id: vertexai.evaluation.eval_task.EvalTask.display_runs
  name: display_runs
  file_path: env/lib/python3.13/site-packages/vertexai/evaluation/eval_task.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: Displays experiment runs associated with this EvalTask.
  signature: 'def display_runs(self):'
- rank: 2768
  id: vertexai.evaluation.eval_task.EvalTask.evaluate
  name: evaluate
  file_path: env/lib/python3.13/site-packages/vertexai/evaluation/eval_task.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Runs an evaluation for the EvalTask.\n\nArgs:\n  model: A GenerativeModel instance or a custom model function to generate\n    responses to evaluate. If not provided, the evaluation can be performed\n    in the bring-your-own-response (BYOR) mode.\n  prompt_template: The prompt template to use for the evaluation. If not\n    set, the prompt template that was used to create the EvalTask will be\n    used.\n  experiment_run_name: The name of the experiment run to log the evaluation\n    to if an experiment is set for this EvalTask. If not provided, a random\n    unique experiment run name is used.\n  response_column_name: The column name of model response in the dataset. If\n    provided, this will override the `metric_column_mapping` of the `EvalTask`.\n  baseline_model_response_column_name: The column name of baseline model\n    response in the dataset for pairwise metrics. If provided, this will\n    override the `metric_column_mapping` of the `EvalTask`\n  evaluation_service_qps:\
    \ The custom QPS limit for the evaluation service.\n  retry_timeout: How long to keep retrying the evaluation requests for\n    the whole evaluation dataset, in seconds.\n  output_file_name: The file name with csv suffix to store the output\n    metrics_table.\n\nReturns:\n  The evaluation result."
  signature: 'def evaluate(self, *, model: typing.Optional[typing.Union[vertexai.evaluation.eval_task.GenerativeModel, typing.Callable[[str], str]]]=None, prompt_template: typing.Optional[str]=None, experiment_run_name: typing.Optional[str]=None, response_column_name: typing.Optional[str]=None, baseline_model_response_column_name: typing.Optional[str]=None, evaluation_service_qps: typing.Optional[float]=None, retry_timeout: float=120.0, output_file_name: typing.Optional[str]=None) -> vertexai.evaluation.eval_task.EvalResult:'
- rank: 2769
  id: vertexai.evaluation.metrics
  name: metrics
  file_path: env/lib/python3.13/site-packages/vertexai/evaluation/metrics/__init__.py
  type: MODULE
  group: Orphan
  usage_score: 0
  docstring: Evaluation Metrics Module.
- rank: 2770
  id: vertexai.evaluation.metrics.metric_prompt_template
  name: metric_prompt_template
  file_path: env/lib/python3.13/site-packages/vertexai/evaluation/metrics/metric_prompt_template.py
  type: MODULE
  group: Orphan
  usage_score: 0
  docstring: Metric prompt template classes for model-based metrics evaluation.
  methods:
  - signature: 'def serialize_dict_in_order(elements: typing.Optional[typing.Dict[str, str]]):'
    docstring: Serializes dictionary to ordered string value without brackets.
- rank: 2771
  id: vertexai.evaluation.metrics.metric_prompt_template.PairwiseMetricPromptTemplate
  name: PairwiseMetricPromptTemplate
  file_path: env/lib/python3.13/site-packages/vertexai/evaluation/metrics/metric_prompt_template.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Pairwise metric prompt template for pairwise model-based metrics.


    [Note: Inherited members from _MetricPromptTemplate are omitted.]'
  constructor_signature: 'def __init__(self, *, criteria: typing.Dict[str, str], rating_rubric: typing.Dict[str, str], input_variables: typing.Optional[typing.List[str]]=None, instruction: typing.Optional[str]=None, metric_definition: typing.Optional[str]=None, evaluation_steps: typing.Optional[typing.Dict[str, str]]=None, few_shot_examples: typing.Optional[typing.List[str]]=None):'
  methods:
  - signature: 'def get_default_pairwise_instruction(self) -> str:'
    docstring: Returns the default instruction for the metric prompt template.
  - signature: 'def get_default_pairwise_evaluation_steps(self) -> typing.Dict[str, str]:'
    docstring: Returns the default evaluation steps for the metric prompt template.
  omitted_inherited_members_from:
  - _MetricPromptTemplate
- rank: 2772
  id: vertexai.evaluation.metrics.metric_prompt_template.PairwiseMetricPromptTemplate.__init__
  name: __init__
  file_path: env/lib/python3.13/site-packages/vertexai/evaluation/metrics/metric_prompt_template.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Initializes a pairwise metric prompt template.\n\nArgs:\n    criteria: The standards and measures used to evaluate the model\n      responses. It is a dictionary of criterion names and criterion\n      definitions.\n    rating_rubric: A dictionary mapping of rating name and rating\n      definition, used to assign ratings or scores based on specific\n      criteria.\n    input_variables: An optional list of input fields to use in the metric\n      prompt template for generating model-based evaluation results.\n      Candidate model \"response\" column and \"baseline_model_response\" column\n      are included by default. If metric_column_mapping is provided, the\n      mapping values of the input fields will be used to retrieve data from\n      the evaluation dataset.\n    instruction: The general instruction to the model that performs the\n      evaluation. If not provided, a default pairwise metric instruction\n      will be used.\n    metric_definition: The optional metric\
    \ definition. It is a string\n      describing the metric to be evaluated at a high level. If not\n      provided, this field will not be included in the prompt template.\n    evaluation_steps: The optional gudelines of evaluation steps. A\n      dictionary of evaluation step name and evaluation step definition. If\n      not provided, a default pairwise metric evaluation steps will be used.\n    few_shot_examples: The optional list of few-shot examples to be used in\n      the prompt, to provide the model with demonstrations of how to perform\n      the evaluation, and improve the evaluation accuracy. If not provided,\n      this field will not be included in the prompt template."
  signature: 'def __init__(self, *, criteria: typing.Dict[str, str], rating_rubric: typing.Dict[str, str], input_variables: typing.Optional[typing.List[str]]=None, instruction: typing.Optional[str]=None, metric_definition: typing.Optional[str]=None, evaluation_steps: typing.Optional[typing.Dict[str, str]]=None, few_shot_examples: typing.Optional[typing.List[str]]=None):'
- rank: 2773
  id: vertexai.evaluation.metrics.metric_prompt_template.PairwiseMetricPromptTemplate.get_default_pairwise_evaluation_steps
  name: get_default_pairwise_evaluation_steps
  file_path: env/lib/python3.13/site-packages/vertexai/evaluation/metrics/metric_prompt_template.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: Returns the default evaluation steps for the metric prompt template.
  signature: 'def get_default_pairwise_evaluation_steps(self) -> typing.Dict[str, str]:'
- rank: 2774
  id: vertexai.evaluation.metrics.metric_prompt_template.PairwiseMetricPromptTemplate.get_default_pairwise_instruction
  name: get_default_pairwise_instruction
  file_path: env/lib/python3.13/site-packages/vertexai/evaluation/metrics/metric_prompt_template.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: Returns the default instruction for the metric prompt template.
  signature: 'def get_default_pairwise_instruction(self) -> str:'
- rank: 2775
  id: vertexai.evaluation.metrics.metric_prompt_template.PointwiseMetricPromptTemplate
  name: PointwiseMetricPromptTemplate
  file_path: env/lib/python3.13/site-packages/vertexai/evaluation/metrics/metric_prompt_template.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Pointwise metric prompt template for pointwise model-based metrics.


    [Note: Inherited members from _MetricPromptTemplate are omitted.]'
  constructor_signature: 'def __init__(self, *, criteria: typing.Dict[str, str], rating_rubric: typing.Dict[str, str], input_variables: typing.Optional[typing.List[str]]=None, instruction: typing.Optional[str]=None, metric_definition: typing.Optional[str]=None, evaluation_steps: typing.Optional[typing.Dict[str, str]]=None, few_shot_examples: typing.Optional[typing.List[str]]=None):'
  methods:
  - signature: 'def get_default_pointwise_instruction(self) -> str:'
    docstring: Returns the default instruction for the metric prompt template.
  - signature: 'def get_default_pointwise_evaluation_steps(self) -> typing.Dict[str, str]:'
    docstring: Returns the default evaluation steps for the metric prompt template.
  omitted_inherited_members_from:
  - _MetricPromptTemplate
- rank: 2776
  id: vertexai.evaluation.metrics.metric_prompt_template.PointwiseMetricPromptTemplate.__init__
  name: __init__
  file_path: env/lib/python3.13/site-packages/vertexai/evaluation/metrics/metric_prompt_template.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Initializes a pointwise metric prompt template.\n\nArgs:\n    criteria: The standards and measures used to evaluate the model\n      responses. It is a dictionary of criterion names and criterion\n      definitions.\n    rating_rubric: A dictionary mapping of rating name and rating\n      definition, used to assign ratings or scores based on specific\n      criteria.\n    input_variables: An optional list of input fields to use in the metric\n      prompt template for generating model-based evaluation results. Model\n      \"response\" column is included by default. If metric_column_mapping is\n      provided, the mapping values of the input fields will be used to\n      retrieve data from the evaluation dataset.\n    instruction: The general instruction to the model that performs the\n      evaluation. If not provided, a default pointwise metric instruction\n      will be used.\n    metric_definition: The optional metric definition. It is a string\n      describing the metric\
    \ to be evaluated at a high level. If not\n      provided, this field will not be included in the prompt template.\n    evaluation_steps: The optional gudelines of evaluation steps. A\n      dictionary of evaluation step name and evaluation step definition. If\n      not provided, a default pointwise metric evaluation steps will be\n      used.\n    few_shot_examples: The optional list of few-shot examples to be used in\n      the prompt, to provide the model with demonstrations of how to perform\n      the evaluation, and improve the evaluation accuracy. If not provided,\n      this field will not be included in the prompt template."
  signature: 'def __init__(self, *, criteria: typing.Dict[str, str], rating_rubric: typing.Dict[str, str], input_variables: typing.Optional[typing.List[str]]=None, instruction: typing.Optional[str]=None, metric_definition: typing.Optional[str]=None, evaluation_steps: typing.Optional[typing.Dict[str, str]]=None, few_shot_examples: typing.Optional[typing.List[str]]=None):'
- rank: 2777
  id: vertexai.evaluation.metrics.metric_prompt_template.PointwiseMetricPromptTemplate.get_default_pointwise_evaluation_steps
  name: get_default_pointwise_evaluation_steps
  file_path: env/lib/python3.13/site-packages/vertexai/evaluation/metrics/metric_prompt_template.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: Returns the default evaluation steps for the metric prompt template.
  signature: 'def get_default_pointwise_evaluation_steps(self) -> typing.Dict[str, str]:'
- rank: 2778
  id: vertexai.evaluation.metrics.metric_prompt_template.PointwiseMetricPromptTemplate.get_default_pointwise_instruction
  name: get_default_pointwise_instruction
  file_path: env/lib/python3.13/site-packages/vertexai/evaluation/metrics/metric_prompt_template.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: Returns the default instruction for the metric prompt template.
  signature: 'def get_default_pointwise_instruction(self) -> str:'
- rank: 2779
  id: vertexai.evaluation.metrics.metric_prompt_template.serialize_dict_in_order
  name: serialize_dict_in_order
  file_path: env/lib/python3.13/site-packages/vertexai/evaluation/metrics/metric_prompt_template.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: Serializes dictionary to ordered string value without brackets.
  signature: 'def serialize_dict_in_order(elements: typing.Optional[typing.Dict[str, str]]):'
- rank: 2780
  id: vertexai.evaluation.metrics.metric_prompt_template_examples
  name: metric_prompt_template_examples
  file_path: env/lib/python3.13/site-packages/vertexai/evaluation/metrics/metric_prompt_template_examples.py
  type: MODULE
  group: Orphan
  usage_score: 0
  docstring: Example metric prompt templates for model-based evaluation.
- rank: 2781
  id: vertexai.evaluation.metrics.metric_prompt_template_examples.MetricPromptTemplateExamples
  name: MetricPromptTemplateExamples
  file_path: env/lib/python3.13/site-packages/vertexai/evaluation/metrics/metric_prompt_template_examples.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: Examples of metric prompt templates for model-based evaluation.
  methods:
  - signature: 'def get_prompt_template(cls, metric_name: str) -> str:'
    docstring: Returns the prompt template for the given metric name.
  - signature: 'def list_example_metric_names(cls) -> typing.List[str]:'
    docstring: Returns a list of all metric prompt templates.
- rank: 2782
  id: vertexai.evaluation.metrics.metric_prompt_template_examples.MetricPromptTemplateExamples.list_example_metric_names
  name: list_example_metric_names
  file_path: env/lib/python3.13/site-packages/vertexai/evaluation/metrics/metric_prompt_template_examples.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: Returns a list of all metric prompt templates.
  signature: 'def list_example_metric_names(cls) -> typing.List[str]:'
- rank: 2783
  id: vertexai.evaluation.metrics.metric_prompt_template_examples.Pairwise
  name: Pairwise
  file_path: env/lib/python3.13/site-packages/vertexai/evaluation/metrics/metric_prompt_template_examples.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: Example PairwiseMetric instances.
  properties:
  - signature: 'FLUENCY: vertexai.evaluation.metrics.pairwise_metric.PairwiseMetric'
  - signature: 'COHERENCE: vertexai.evaluation.metrics.pairwise_metric.PairwiseMetric'
  - signature: 'SAFETY: vertexai.evaluation.metrics.pairwise_metric.PairwiseMetric'
  - signature: 'GROUNDEDNESS: vertexai.evaluation.metrics.pairwise_metric.PairwiseMetric'
  - signature: 'INSTRUCTION_FOLLOWING: vertexai.evaluation.metrics.pairwise_metric.PairwiseMetric'
  - signature: 'VERBOSITY: vertexai.evaluation.metrics.pairwise_metric.PairwiseMetric'
  - signature: 'TEXT_QUALITY: vertexai.evaluation.metrics.pairwise_metric.PairwiseMetric'
  - signature: 'SUMMARIZATION_QUALITY: vertexai.evaluation.metrics.pairwise_metric.PairwiseMetric'
  - signature: 'QUESTION_ANSWERING_QUALITY: vertexai.evaluation.metrics.pairwise_metric.PairwiseMetric'
  - signature: 'MULTI_TURN_CHAT_QUALITY: vertexai.evaluation.metrics.pairwise_metric.PairwiseMetric'
  - signature: 'MULTI_TURN_SAFETY: vertexai.evaluation.metrics.pairwise_metric.PairwiseMetric'
- rank: 2784
  id: vertexai.evaluation.metrics.metric_prompt_template_examples.Pointwise
  name: Pointwise
  file_path: env/lib/python3.13/site-packages/vertexai/evaluation/metrics/metric_prompt_template_examples.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: Example PointwiseMetric instances.
  properties:
  - signature: 'FLUENCY: vertexai.evaluation.metrics.pointwise_metric.PointwiseMetric'
  - signature: 'COHERENCE: vertexai.evaluation.metrics.pointwise_metric.PointwiseMetric'
  - signature: 'SAFETY: vertexai.evaluation.metrics.pointwise_metric.PointwiseMetric'
  - signature: 'GROUNDEDNESS: vertexai.evaluation.metrics.pointwise_metric.PointwiseMetric'
  - signature: 'INSTRUCTION_FOLLOWING: vertexai.evaluation.metrics.pointwise_metric.PointwiseMetric'
  - signature: 'VERBOSITY: vertexai.evaluation.metrics.pointwise_metric.PointwiseMetric'
  - signature: 'TEXT_QUALITY: vertexai.evaluation.metrics.pointwise_metric.PointwiseMetric'
  - signature: 'SUMMARIZATION_QUALITY: vertexai.evaluation.metrics.pointwise_metric.PointwiseMetric'
  - signature: 'QUESTION_ANSWERING_QUALITY: vertexai.evaluation.metrics.pointwise_metric.PointwiseMetric'
  - signature: 'MULTI_TURN_CHAT_QUALITY: vertexai.evaluation.metrics.pointwise_metric.PointwiseMetric'
  - signature: 'MULTI_TURN_SAFETY: vertexai.evaluation.metrics.pointwise_metric.PointwiseMetric'
- rank: 2785
  id: vertexai.evaluation.metrics.pairwise_metric
  name: pairwise_metric
  file_path: env/lib/python3.13/site-packages/vertexai/evaluation/metrics/pairwise_metric.py
  type: MODULE
  group: Orphan
  usage_score: 0
  docstring: Model-based Pairwise Metric.
- rank: 2786
  id: vertexai.evaluation.metrics.pairwise_metric.PairwiseMetric
  name: PairwiseMetric
  file_path: env/lib/python3.13/site-packages/vertexai/evaluation/metrics/pairwise_metric.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: "A Model-based Pairwise Metric.\n\nA model-based evaluation metric that compares two generative models' responses\nside-by-side, and allows users to A/B test their generative models to\ndetermine which model is performing better.\n\nFor more details on when to use pairwise metrics, see\n[Evaluation methods and\nmetrics](https://cloud.google.com/vertex-ai/generative-ai/docs/models/determine-eval#pointwise_versus_pairwise).\n\nResult Details:\n\n    * In `EvalResult.summary_metrics`, win rates for both the baseline and\n    candidate model are computed. The win rate is computed as proportion of\n    wins of one model's responses to total attempts as a decimal value\n    between 0 and 1.\n\n    * In `EvalResult.metrics_table`, a pairwise metric produces two\n    evaluation results per dataset row:\n        * `pairwise_choice`: The choice shows whether the candidate model or\n          the baseline model performs better, or if they are equally good.\n        * `explanation`: The\
    \ rationale behind each verdict using\n          chain-of-thought reasoning. The explanation helps users scrutinize\n          the judgment and builds appropriate trust in the decisions.\n\n    See [documentation\n    page](https://cloud.google.com/vertex-ai/generative-ai/docs/models/determine-eval#understand-results)\n    for more details on understanding the metric results.\n\nUsage Examples:\n\n    ```\n    baseline_model = GenerativeModel(\"gemini-1.0-pro\")\n    candidate_model = GenerativeModel(\"gemini-1.5-pro\")\n\n    pairwise_groundedness = PairwiseMetric(\n        metric_prompt_template=MetricPromptTemplateExamples.get_prompt_template(\n            \"pairwise_groundedness\"\n        ),\n        baseline_model=baseline_model,\n    )\n    eval_dataset = pd.DataFrame({\n          \"prompt\"  : [...],\n    })\n    pairwise_task = EvalTask(\n        dataset=eval_dataset,\n        metrics=[pairwise_groundedness],\n        experiment=\"my-pairwise-experiment\",\n    )\n    pairwise_result\
    \ = pairwise_task.evaluate(\n        model=candidate_model,\n        experiment_run_name=\"gemini-pairwise-eval-run\",\n    )\n    ```\n\n[Note: Inherited members from _base._ModelBasedMetric are omitted.]"
  constructor_signature: 'def __init__(self, *, metric: str, metric_prompt_template: typing.Union[vertexai.evaluation.metrics.metric_prompt_template.PairwiseMetricPromptTemplate, str], baseline_model: typing.Optional[typing.Union[vertexai.generative_models.GenerativeModel, typing.Callable[[str], str]]]=None):'
  methods:
  - signature: 'def baseline_model(self) -> typing.Union[vertexai.generative_models.GenerativeModel, typing.Callable[[str], str]]:'
  omitted_inherited_members_from:
  - _base._ModelBasedMetric
- rank: 2787
  id: vertexai.evaluation.metrics.pairwise_metric.PairwiseMetric.__init__
  name: __init__
  file_path: env/lib/python3.13/site-packages/vertexai/evaluation/metrics/pairwise_metric.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Initializes a pairwise evaluation metric.\n\nArgs:\n  metric: The pairwise evaluation metric name.\n  metric_prompt_template: Pairwise metric prompt template for performing\n    the pairwise model-based evaluation. A freeform string is also accepted.\n  baseline_model: The baseline model for side-by-side comparison. If not\n    specified, `baseline_model_response` column is required in the dataset\n    to perform bring-your-own-response(BYOR) evaluation."
  signature: 'def __init__(self, *, metric: str, metric_prompt_template: typing.Union[vertexai.evaluation.metrics.metric_prompt_template.PairwiseMetricPromptTemplate, str], baseline_model: typing.Optional[typing.Union[vertexai.generative_models.GenerativeModel, typing.Callable[[str], str]]]=None):'
- rank: 2788
  id: vertexai.evaluation.metrics.pairwise_metric.PairwiseMetric.baseline_model
  name: baseline_model
  file_path: env/lib/python3.13/site-packages/vertexai/evaluation/metrics/pairwise_metric.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def baseline_model(self) -> typing.Union[vertexai.generative_models.GenerativeModel, typing.Callable[[str], str]]:'
- rank: 2789
  id: vertexai.evaluation.metrics.pointwise_metric
  name: pointwise_metric
  file_path: env/lib/python3.13/site-packages/vertexai/evaluation/metrics/pointwise_metric.py
  type: MODULE
  group: Orphan
  usage_score: 0
  docstring: Model-based Pointwise Metric.
- rank: 2790
  id: vertexai.evaluation.metrics.pointwise_metric.Comet
  name: Comet
  file_path: env/lib/python3.13/site-packages/vertexai/evaluation/metrics/pointwise_metric.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'A COMET metric.


    Evaluates a score for the given instance using

    https://huggingface.co/Unbabel/wmt22-comet-da


    [Note: Inherited members from _base._TranslationMetric are omitted.]'
  constructor_signature: 'def __init__(self, *, version: str=''COMET_22_SRC_REF'', source_language: str=None, target_language: str=None):'
  omitted_inherited_members_from:
  - _base._TranslationMetric
- rank: 2791
  id: vertexai.evaluation.metrics.pointwise_metric.Comet.__init__
  name: __init__
  file_path: env/lib/python3.13/site-packages/vertexai/evaluation/metrics/pointwise_metric.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Initializes the COMET metric.\n\nArgs:\n  version: The COMET version to use for evaluation eg.\n    \"COMET_22_SRC_REF\".\n  source_language: Optional. The source language of the translation.\n  target_language: Optional. The target language of the translation."
  signature: 'def __init__(self, *, version: str=''COMET_22_SRC_REF'', source_language: str=None, target_language: str=None):'
- rank: 2792
  id: vertexai.evaluation.metrics.pointwise_metric.MetricX
  name: MetricX
  file_path: env/lib/python3.13/site-packages/vertexai/evaluation/metrics/pointwise_metric.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'A MetricX metric.


    Evaluates a score for the given instance using

    https://github.com/google-research/metricx


    [Note: Inherited members from _base._TranslationMetric are omitted.]'
  constructor_signature: 'def __init__(self, *, version: str=''METRICX_24_SRC_REF'', source_language: str=None, target_language: str=None):'
  omitted_inherited_members_from:
  - _base._TranslationMetric
- rank: 2793
  id: vertexai.evaluation.metrics.pointwise_metric.MetricX.__init__
  name: __init__
  file_path: env/lib/python3.13/site-packages/vertexai/evaluation/metrics/pointwise_metric.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Initializes the MetricX metric.\n\nArgs:\n  version: The MetricX version to use for evaluation. Can be one of\n    \"METRICX_24_SRC_REF\", \"METRICX_24_SRC\", or \"METRICX_24_REF\".\n  source_language: Optional. The source language of the translation.\n  target_language: Optional. The target language of the translation."
  signature: 'def __init__(self, *, version: str=''METRICX_24_SRC_REF'', source_language: str=None, target_language: str=None):'
- rank: 2794
  id: vertexai.evaluation.metrics.pointwise_metric.PointwiseMetric
  name: PointwiseMetric
  file_path: env/lib/python3.13/site-packages/vertexai/evaluation/metrics/pointwise_metric.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: "A Model-based Pointwise Metric.\n\nA model-based evaluation metric that evaluate a single generative model's\nresponse.\n\nFor more details on when to use model-based pointwise metrics, see\n[Evaluation methods and metrics](https://cloud.google.com/vertex-ai/generative-ai/docs/models/determine-eval).\n\nUsage Examples:\n\n    ```\n    candidate_model = GenerativeModel(\"gemini-1.5-pro\")\n    eval_dataset = pd.DataFrame({\n        \"prompt\"  : [...],\n    })\n    fluency_metric = PointwiseMetric(\n        metric=\"fluency\",\n        metric_prompt_template=MetricPromptTemplateExamples.get_prompt_template('fluency'),\n    )\n    pointwise_eval_task = EvalTask(\n        dataset=eval_dataset,\n        metrics=[\n            fluency_metric,\n            MetricPromptTemplateExamples.Pointwise.GROUNDEDNESS,\n        ],\n    )\n    pointwise_result = pointwise_eval_task.evaluate(\n        model=candidate_model,\n    )\n    ```\n\n[Note: Inherited members from _base._ModelBasedMetric\
    \ are omitted.]"
  constructor_signature: 'def __init__(self, *, metric: str, metric_prompt_template: typing.Union[vertexai.evaluation.metrics.metric_prompt_template.PointwiseMetricPromptTemplate, str]):'
  omitted_inherited_members_from:
  - _base._ModelBasedMetric
- rank: 2795
  id: vertexai.evaluation.metrics.pointwise_metric.PointwiseMetric.__init__
  name: __init__
  file_path: env/lib/python3.13/site-packages/vertexai/evaluation/metrics/pointwise_metric.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Initializes a pointwise evaluation metric.\n\nArgs:\n  metric: The pointwise evaluation metric name.\n  metric_prompt_template: Pointwise metric prompt template for performing\n    the model-based evaluation. A freeform string is also accepted."
  signature: 'def __init__(self, *, metric: str, metric_prompt_template: typing.Union[vertexai.evaluation.metrics.metric_prompt_template.PointwiseMetricPromptTemplate, str]):'
- rank: 2796
  id: vertexai.evaluation.notebook_utils
  name: notebook_utils
  file_path: env/lib/python3.13/site-packages/vertexai/evaluation/notebook_utils.py
  type: MODULE
  group: Orphan
  usage_score: 0
  docstring: Python functions which run only within a Jupyter or Colab notebook.
  methods:
  - signature: 'def is_ipython_available() -> bool:'
  - signature: 'def display_eval_result(*, eval_result: vertexai.preview.evaluation._base.EvalResult, title: typing.Optional[str]=None, metrics: typing.Optional[typing.List[str]]=None) -> None:'
    docstring: "Displays evaluation results in a notebook using IPython.display.\n\nArgs:\n    eval_result: An object containing evaluation results with\n      `summary_metrics` and `metrics_table` attributes.\n    title: A string title to display above the results.\n    metrics: A list of metric name substrings to filter displayed columns. If\n      provided, only metrics whose names contain any of these strings will be\n      displayed."
  - signature: 'def display_explanations(*, eval_result: vertexai.preview.evaluation._base.EvalResult, num: int=1, metrics: typing.Optional[typing.List[str]]=None) -> None:'
    docstring: "Displays the explanations in a notebook using IPython.display.\n\nArgs:\n    eval_result: An object containing evaluation results. It is expected to\n      have attributes `summary_metrics` and `metrics_table`.\n    num: The number of row samples to display. Defaults to 1. If the number of\n      rows is less than `num`, all rows will be displayed.\n    metrics: A list of metric name substrings to filter displayed columns. If\n      provided, only metrics whose names contain any of these strings will be\n      displayed."
  - signature: 'def display_radar_plot(eval_results_with_title: typing.List[typing.Tuple[str, vertexai.preview.evaluation._base.EvalResult]], metrics: typing.List[str], radar_range: typing.Tuple[float, float]) -> None:'
    docstring: "Plots a radar plot comparing evaluation results.\n\nArgs:\n    eval_results_with_title: List of (title, eval_result) tuples.\n    metrics: A list of metrics whose mean values will be plotted.\n    radar_range: Range of the radar plot axes."
  - signature: 'def display_bar_plot(eval_results_with_title: typing.List[typing.Tuple[str, vertexai.preview.evaluation._base.EvalResult]], metrics: typing.List[str]) -> None:'
    docstring: "Plots a bar plot comparing evaluation results.\n\nArgs:\n    eval_results_with_title: List of (title, eval_result) tuples.\n    metrics: A list of metrics whose mean values will be plotted."
  - signature: 'def generate_uuid(length: int) -> str:'
    docstring: Generates a uuid of a specified length (default=8).
- rank: 2797
  id: vertexai.evaluation.notebook_utils.display_bar_plot
  name: display_bar_plot
  file_path: env/lib/python3.13/site-packages/vertexai/evaluation/notebook_utils.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Plots a bar plot comparing evaluation results.\n\nArgs:\n    eval_results_with_title: List of (title, eval_result) tuples.\n    metrics: A list of metrics whose mean values will be plotted."
  signature: 'def display_bar_plot(eval_results_with_title: typing.List[typing.Tuple[str, vertexai.preview.evaluation._base.EvalResult]], metrics: typing.List[str]) -> None:'
- rank: 2798
  id: vertexai.evaluation.notebook_utils.display_eval_result
  name: display_eval_result
  file_path: env/lib/python3.13/site-packages/vertexai/evaluation/notebook_utils.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Displays evaluation results in a notebook using IPython.display.\n\nArgs:\n    eval_result: An object containing evaluation results with\n      `summary_metrics` and `metrics_table` attributes.\n    title: A string title to display above the results.\n    metrics: A list of metric name substrings to filter displayed columns. If\n      provided, only metrics whose names contain any of these strings will be\n      displayed."
  signature: 'def display_eval_result(*, eval_result: vertexai.preview.evaluation._base.EvalResult, title: typing.Optional[str]=None, metrics: typing.Optional[typing.List[str]]=None) -> None:'
- rank: 2799
  id: vertexai.evaluation.notebook_utils.display_explanations
  name: display_explanations
  file_path: env/lib/python3.13/site-packages/vertexai/evaluation/notebook_utils.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Displays the explanations in a notebook using IPython.display.\n\nArgs:\n    eval_result: An object containing evaluation results. It is expected to\n      have attributes `summary_metrics` and `metrics_table`.\n    num: The number of row samples to display. Defaults to 1. If the number of\n      rows is less than `num`, all rows will be displayed.\n    metrics: A list of metric name substrings to filter displayed columns. If\n      provided, only metrics whose names contain any of these strings will be\n      displayed."
  signature: 'def display_explanations(*, eval_result: vertexai.preview.evaluation._base.EvalResult, num: int=1, metrics: typing.Optional[typing.List[str]]=None) -> None:'
- rank: 2800
  id: vertexai.evaluation.notebook_utils.display_radar_plot
  name: display_radar_plot
  file_path: env/lib/python3.13/site-packages/vertexai/evaluation/notebook_utils.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Plots a radar plot comparing evaluation results.\n\nArgs:\n    eval_results_with_title: List of (title, eval_result) tuples.\n    metrics: A list of metrics whose mean values will be plotted.\n    radar_range: Range of the radar plot axes."
  signature: 'def display_radar_plot(eval_results_with_title: typing.List[typing.Tuple[str, vertexai.preview.evaluation._base.EvalResult]], metrics: typing.List[str], radar_range: typing.Tuple[float, float]) -> None:'
- rank: 2801
  id: vertexai.evaluation.prompt_template
  name: prompt_template
  file_path: env/lib/python3.13/site-packages/vertexai/evaluation/prompt_template.py
  type: MODULE
  group: Orphan
  usage_score: 0
  docstring: Prompt template for creating prompts with variables.
- rank: 2802
  id: vertexai.evaluation.prompt_template.PromptTemplate
  name: PromptTemplate
  file_path: env/lib/python3.13/site-packages/vertexai/evaluation/prompt_template.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: "A prompt template for creating prompts with variables.\n\nThe `PromptTemplate` class allows users to define a template string with\nvariables represented in curly braces `{variable}`. The variable\nnames cannot contain spaces and must start with a letter or underscore,\nfollowed by letters, digits, or underscore. These variables can be\nreplaced with specific values using the `assemble` method, providing\nflexibility in generating dynamic prompts.\n\nUsage:\n\n    ```\n    template_str = \"Hello, {name}! Today is {day}. How are you?\"\n    prompt_template = PromptTemplate(template_str)\n    completed_prompt = prompt_template.assemble(name=\"John\", day=\"Monday\")\n    print(completed_prompt)\n    ```"
  constructor_signature: 'def __init__(self, template: str):'
  methods:
  - signature: 'def assemble(self) -> vertexai.evaluation.prompt_template.PromptTemplate:'
    docstring: "Replaces only the provided variables in the template with specific values.\n\nArgs:\n    **kwargs: Keyword arguments where keys are placeholder names and values\n      are the replacements.\n\nReturns:\n    A new PromptTemplate instance with the updated template string."
- rank: 2803
  id: vertexai.evaluation.prompt_template.PromptTemplate.__init__
  name: __init__
  file_path: env/lib/python3.13/site-packages/vertexai/evaluation/prompt_template.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Initializes the PromptTemplate with a given template.\n\nArgs:\n    template: The template string with variables. Variables should be\n      represented in curly braces `{variable}`."
  signature: 'def __init__(self, template: str):'
- rank: 2804
  id: vertexai.evaluation.prompt_template.PromptTemplate.assemble
  name: assemble
  file_path: env/lib/python3.13/site-packages/vertexai/evaluation/prompt_template.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Replaces only the provided variables in the template with specific values.\n\nArgs:\n    **kwargs: Keyword arguments where keys are placeholder names and values\n      are the replacements.\n\nReturns:\n    A new PromptTemplate instance with the updated template string."
  signature: 'def assemble(self) -> vertexai.evaluation.prompt_template.PromptTemplate:'
- rank: 2805
  id: vertexai.evaluation.utils
  name: utils
  file_path: env/lib/python3.13/site-packages/vertexai/evaluation/utils.py
  type: MODULE
  group: Orphan
  usage_score: 0
  methods:
  - signature: 'def rate_limit(rate: typing.Optional[float]) -> typing.Callable[[Any], typing.Any]:'
    docstring: Decorator version of rate limiter.
  - signature: 'def wrapper():'
  - signature: 'def create_evaluation_service_client(api_base_path_override: typing.Optional[str]) -> vertexai.evaluation.utils._EvaluationServiceClientWithOverride:'
    docstring: "Creates a client for the evaluation service.\n\nArgs:\n  api_base_path_override: Optional. Override default api base path.\n\nReturns:\n  Instantiated Vertex AI EvaluationServiceClient with optional\n  overrides."
  - signature: 'def load_dataset(source: typing.Union[str, pandas.DataFrame, typing.Dict[str, typing.Any]]) -> pandas.DataFrame:'
    docstring: "Loads dataset from various sources into a DataFrame.\n\nArgs:\n    source: The dataset source. Supports the following dataset formats:\n    * pandas.DataFrame: Used directly for evaluation.\n    * Dict: Converted to a pandas DataFrame before evaluation.\n    * str: Interpreted as a file path or URI. Supported formats include:\n        * Local JSONL or CSV files:  Loaded from the local filesystem.\n        * GCS JSONL or CSV files: Loaded from Google Cloud Storage\n            (e.g., 'gs://bucket/data.csv').\n        * BigQuery table URI: Loaded from Google Cloud BigQuery\n            (e.g., 'bq://project-id.dataset.table_name').\n\nReturns:\n    The dataset in pandas DataFrame format."
  - signature: 'def upload_evaluation_results(eval_result: vertexai.evaluation._base.EvalResult, destination_uri_prefix: str, file_name: typing.Optional[str], candidate_model_name: typing.Optional[str], baseline_model_name: typing.Optional[str], dataset_uri: typing.Optional[str], metrics: typing.Optional[typing.List[typing.Union[str, vertexai.evaluation.metrics._base._Metric]]]) -> None:'
    docstring: "Uploads eval results to GCS destination.\n\nArgs:\n    eval_result: Eval results to upload.\n    destination_uri_prefix: GCS folder to store the data.\n    file_name: Optional. File name to store the metrics table.\n    candidate_model_name: Optional. Candidate model name.\n    baseline_model_name: Optional. Baseline model name.\n    dataset_uri: Optional. URI pointing to the dataset.\n    metrics: Optional. List of metrics used for evaluation."
  - signature: 'def initialize_metric_column_mapping(metric_column_mapping: typing.Optional[typing.Dict[str, str]], dataset: pandas.DataFrame):'
    docstring: Initializes metric column mapping with dataset columns.
- rank: 2806
  id: vertexai.evaluation.utils.RateLimiter
  name: RateLimiter
  file_path: env/lib/python3.13/site-packages/vertexai/evaluation/utils.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: "Helper class for rate-limiting requests to Vertex AI to improve QoS.\n\nAttributes:\n    seconds_per_event: The time interval (in seconds) between events to\n        maintain the desired rate.\n    last: The timestamp of the last event.\n    _lock: A lock to ensure thread safety."
  constructor_signature: 'def __init__(self, rate: typing.Optional[float]):'
  methods:
  - signature: 'def sleep_and_advance(self):'
    docstring: Blocks the current thread until the next event can be admitted.
- rank: 2807
  id: vertexai.evaluation.utils.RateLimiter.__init__
  name: __init__
  file_path: env/lib/python3.13/site-packages/vertexai/evaluation/utils.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Initializes the rate limiter.\n\nA simple rate limiter for controlling the frequency of API calls. This class\nimplements a token bucket algorithm to limit the rate at which events\ncan occur. It's designed for cases where the batch size (number of events\nper call) is always 1 for traffic shaping and rate limiting.\n\nArgs:\n    rate: The number of queries allowed per second.\nRaises:\n    ValueError: If the rate is not positive."
  signature: 'def __init__(self, rate: typing.Optional[float]):'
- rank: 2808
  id: vertexai.evaluation.utils.RateLimiter.sleep_and_advance
  name: sleep_and_advance
  file_path: env/lib/python3.13/site-packages/vertexai/evaluation/utils.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: Blocks the current thread until the next event can be admitted.
  signature: 'def sleep_and_advance(self):'
- rank: 2809
  id: vertexai.evaluation.utils.create_evaluation_service_client
  name: create_evaluation_service_client
  file_path: env/lib/python3.13/site-packages/vertexai/evaluation/utils.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Creates a client for the evaluation service.\n\nArgs:\n  api_base_path_override: Optional. Override default api base path.\n\nReturns:\n  Instantiated Vertex AI EvaluationServiceClient with optional\n  overrides."
  signature: 'def create_evaluation_service_client(api_base_path_override: typing.Optional[str]) -> vertexai.evaluation.utils._EvaluationServiceClientWithOverride:'
- rank: 2810
  id: vertexai.evaluation.utils.initialize_metric_column_mapping
  name: initialize_metric_column_mapping
  file_path: env/lib/python3.13/site-packages/vertexai/evaluation/utils.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: Initializes metric column mapping with dataset columns.
  signature: 'def initialize_metric_column_mapping(metric_column_mapping: typing.Optional[typing.Dict[str, str]], dataset: pandas.DataFrame):'
- rank: 2811
  id: vertexai.evaluation.utils.load_dataset
  name: load_dataset
  file_path: env/lib/python3.13/site-packages/vertexai/evaluation/utils.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Loads dataset from various sources into a DataFrame.\n\nArgs:\n    source: The dataset source. Supports the following dataset formats:\n    * pandas.DataFrame: Used directly for evaluation.\n    * Dict: Converted to a pandas DataFrame before evaluation.\n    * str: Interpreted as a file path or URI. Supported formats include:\n        * Local JSONL or CSV files:  Loaded from the local filesystem.\n        * GCS JSONL or CSV files: Loaded from Google Cloud Storage\n            (e.g., 'gs://bucket/data.csv').\n        * BigQuery table URI: Loaded from Google Cloud BigQuery\n            (e.g., 'bq://project-id.dataset.table_name').\n\nReturns:\n    The dataset in pandas DataFrame format."
  signature: 'def load_dataset(source: typing.Union[str, pandas.DataFrame, typing.Dict[str, typing.Any]]) -> pandas.DataFrame:'
- rank: 2812
  id: vertexai.evaluation.utils.rate_limit
  name: rate_limit
  file_path: env/lib/python3.13/site-packages/vertexai/evaluation/utils.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: Decorator version of rate limiter.
  signature: 'def rate_limit(rate: typing.Optional[float]) -> typing.Callable[[Any], typing.Any]:'
- rank: 2813
  id: vertexai.evaluation.utils.upload_evaluation_results
  name: upload_evaluation_results
  file_path: env/lib/python3.13/site-packages/vertexai/evaluation/utils.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Uploads eval results to GCS destination.\n\nArgs:\n    eval_result: Eval results to upload.\n    destination_uri_prefix: GCS folder to store the data.\n    file_name: Optional. File name to store the metrics table.\n    candidate_model_name: Optional. Candidate model name.\n    baseline_model_name: Optional. Baseline model name.\n    dataset_uri: Optional. URI pointing to the dataset.\n    metrics: Optional. List of metrics used for evaluation."
  signature: 'def upload_evaluation_results(eval_result: vertexai.evaluation._base.EvalResult, destination_uri_prefix: str, file_name: typing.Optional[str], candidate_model_name: typing.Optional[str], baseline_model_name: typing.Optional[str], dataset_uri: typing.Optional[str], metrics: typing.Optional[typing.List[typing.Union[str, vertexai.evaluation.metrics._base._Metric]]]) -> None:'
- rank: 2814
  id: vertexai.generative_models
  name: generative_models
  file_path: env/lib/python3.13/site-packages/vertexai/generative_models/__init__.py
  type: MODULE
  group: Orphan
  usage_score: 0
  docstring: Classes for working with the Gemini models.
- rank: 2815
  id: vertexai.language_models
  name: language_models
  file_path: env/lib/python3.13/site-packages/vertexai/language_models/__init__.py
  type: MODULE
  group: Orphan
  usage_score: 0
  docstring: Classes for working with language models.
- rank: 2816
  id: vertexai.model_garden
  name: model_garden
  file_path: env/lib/python3.13/site-packages/vertexai/model_garden/__init__.py
  type: MODULE
  group: Orphan
  usage_score: 0
  docstring: Classes and functions for working with Model Garden.
- rank: 2817
  id: vertexai.preview
  name: preview
  file_path: env/lib/python3.13/site-packages/vertexai/preview/__init__.py
  type: MODULE
  group: Orphan
  usage_score: 0
- rank: 2818
  id: vertexai.preview.batch_prediction
  name: batch_prediction
  file_path: env/lib/python3.13/site-packages/vertexai/preview/batch_prediction.py
  type: MODULE
  group: Orphan
  usage_score: 0
  docstring: Classes for batch prediction.
- rank: 2819
  id: vertexai.preview.caching
  name: caching
  file_path: env/lib/python3.13/site-packages/vertexai/preview/caching.py
  type: MODULE
  group: Orphan
  usage_score: 0
- rank: 2820
  id: vertexai.preview.evaluation
  name: evaluation
  file_path: env/lib/python3.13/site-packages/vertexai/preview/evaluation/__init__.py
  type: MODULE
  group: Orphan
  usage_score: 0
  docstring: Vertex Gen AI Evaluation Service Module.
- rank: 2821
  id: vertexai.preview.evaluation.autorater_utils
  name: autorater_utils
  file_path: env/lib/python3.13/site-packages/vertexai/preview/evaluation/autorater_utils.py
  type: MODULE
  group: Orphan
  usage_score: 0
  docstring: Autorater Utils Class and Functions.
  methods:
  - signature: 'def tune_autorater(*, base_model: typing.Union[str, vertexai.generative_models.GenerativeModel], train_dataset: str, validation_dataset: typing.Optional[str]=None, tuned_model_display_name: typing.Optional[str]=None, epochs: typing.Optional[int]=None, learning_rate_multiplier: typing.Optional[float]=None, adapter_size: typing.Optional[typing.Literal[1, 4, 8, 16]]=None, labels: typing.Optional[typing.Dict[str, str]]=None, time_out_hours: int=10) -> vertexai.preview.evaluation.autorater_utils.AutoraterConfig:'
    docstring: "Lora Tune an autorater model.\n\nArgs:\n    base_model: Model name for tuning, e.g., \"gemini-1.0-pro-002\".\n    train_dataset: Cloud Storage path to file containing training dataset for\n      tuning. The dataset should be in JSONL format.\n    validation_dataset: Cloud Storage path to file containing validation\n      dataset for tuning. The dataset should be in JSONL format.\n    tuned_model_display_name: The display name of the\n      [TunedModel][google.cloud.aiplatform.v1.Model]. The name can be up to\n      128 characters long and can consist of any UTF-8 characters.\n    epochs: Number of training epoches for this tuning job.\n    learning_rate_multiplier: Learning rate multiplier for tuning.\n    adapter_size: Adapter size for tuning.\n    labels: User-defined metadata to be associated with trained models\n    time_out_hours: Timeout in hours for tuning job. Default value is 10\n      hours.\n\nReturns:\n    A `AutoraterConfig` object with tuned model endpoint."
  - signature: 'def evaluate_autorater(*, evaluate_autorater_input: pandas.DataFrame, eval_metrics: typing.List[typing.Union[vertexai.preview.evaluation.autorater_utils.PointwiseMetric, vertexai.preview.evaluation.autorater_utils.PairwiseMetric]], autorater_config: typing.Optional[vertexai.preview.evaluation.autorater_utils.AutoraterConfig]=None, eval_dataset_metadata: typing.Dict[str, typing.Any]=None) -> vertexai.preview.evaluation.autorater_utils.AutoraterEvalResult:'
    docstring: "Evaluates the autorater model using human evaluation results.\n\nArgs:\n    evaluate_autorater_input: Autorater evaluation input, including\n      evaluation results from human evaluation and autorater model.\n    eval_metrics: List of model based metrics.\n    autorater_config: Autorater configuration.\n    eval_dataset_metadata: Evaluation dataset metadata.\n    **kwargs: Additional arguments added to AutoraterEvalResult.\n\nReturns:\n    Autorater evalaution result ."
- rank: 2822
  id: vertexai.preview.evaluation.autorater_utils.evaluate_autorater
  name: evaluate_autorater
  file_path: env/lib/python3.13/site-packages/vertexai/preview/evaluation/autorater_utils.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Evaluates the autorater model using human evaluation results.\n\nArgs:\n    evaluate_autorater_input: Autorater evaluation input, including\n      evaluation results from human evaluation and autorater model.\n    eval_metrics: List of model based metrics.\n    autorater_config: Autorater configuration.\n    eval_dataset_metadata: Evaluation dataset metadata.\n    **kwargs: Additional arguments added to AutoraterEvalResult.\n\nReturns:\n    Autorater evalaution result ."
  signature: 'def evaluate_autorater(*, evaluate_autorater_input: pandas.DataFrame, eval_metrics: typing.List[typing.Union[vertexai.preview.evaluation.autorater_utils.PointwiseMetric, vertexai.preview.evaluation.autorater_utils.PairwiseMetric]], autorater_config: typing.Optional[vertexai.preview.evaluation.autorater_utils.AutoraterConfig]=None, eval_dataset_metadata: typing.Dict[str, typing.Any]=None) -> vertexai.preview.evaluation.autorater_utils.AutoraterEvalResult:'
- rank: 2823
  id: vertexai.preview.evaluation.autorater_utils.tune_autorater
  name: tune_autorater
  file_path: env/lib/python3.13/site-packages/vertexai/preview/evaluation/autorater_utils.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Lora Tune an autorater model.\n\nArgs:\n    base_model: Model name for tuning, e.g., \"gemini-1.0-pro-002\".\n    train_dataset: Cloud Storage path to file containing training dataset for\n      tuning. The dataset should be in JSONL format.\n    validation_dataset: Cloud Storage path to file containing validation\n      dataset for tuning. The dataset should be in JSONL format.\n    tuned_model_display_name: The display name of the\n      [TunedModel][google.cloud.aiplatform.v1.Model]. The name can be up to\n      128 characters long and can consist of any UTF-8 characters.\n    epochs: Number of training epoches for this tuning job.\n    learning_rate_multiplier: Learning rate multiplier for tuning.\n    adapter_size: Adapter size for tuning.\n    labels: User-defined metadata to be associated with trained models\n    time_out_hours: Timeout in hours for tuning job. Default value is 10\n      hours.\n\nReturns:\n    A `AutoraterConfig` object with tuned model endpoint."
  signature: 'def tune_autorater(*, base_model: typing.Union[str, vertexai.generative_models.GenerativeModel], train_dataset: str, validation_dataset: typing.Optional[str]=None, tuned_model_display_name: typing.Optional[str]=None, epochs: typing.Optional[int]=None, learning_rate_multiplier: typing.Optional[float]=None, adapter_size: typing.Optional[typing.Literal[1, 4, 8, 16]]=None, labels: typing.Optional[typing.Dict[str, str]]=None, time_out_hours: int=10) -> vertexai.preview.evaluation.autorater_utils.AutoraterConfig:'
- rank: 2824
  id: vertexai.preview.evaluation.constants
  name: constants
  file_path: env/lib/python3.13/site-packages/vertexai/preview/evaluation/constants.py
  type: MODULE
  group: Orphan
  usage_score: 0
  docstring: Constants for evaluation.
- rank: 2825
  id: vertexai.preview.evaluation.constants.Dataset
  name: Dataset
  file_path: env/lib/python3.13/site-packages/vertexai/preview/evaluation/constants.py
  type: CLASS
  group: Orphan
  usage_score: 0
  constructor_signature: 'def __init__(self, *, MODEL_RESPONSE_COLUMN: str = ''response'', BASELINE_MODEL_RESPONSE_COLUMN: str = ''baseline_model_response'', PROMPT_COLUMN: str = ''prompt'', REFERENCE_COLUMN: str = ''reference'', PREDICTED_TRAJECTORY_COLUMN: str = ''predicted_trajectory'', REFERENCE_TRAJECTORY_COLUMN: str = ''reference_trajectory'', RUBRICS_COLUMN: str = ''rubrics''):'
  properties:
  - signature: 'MODEL_RESPONSE_COLUMN: str'
  - signature: 'BASELINE_MODEL_RESPONSE_COLUMN: str'
  - signature: 'PROMPT_COLUMN: str'
  - signature: 'REFERENCE_COLUMN: str'
  - signature: 'PREDICTED_TRAJECTORY_COLUMN: str'
  - signature: 'REFERENCE_TRAJECTORY_COLUMN: str'
  - signature: 'RUBRICS_COLUMN: str'
- rank: 2826
  id: vertexai.preview.evaluation.constants.Metric
  name: Metric
  file_path: env/lib/python3.13/site-packages/vertexai/preview/evaluation/constants.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: Namespace for Metrics.
  constructor_signature: 'def __init__(self, *, COHERENCE: str = ''coherence'', FLUENCY: str = ''fluency'', SAFETY: str = ''safety'', GROUNDEDNESS: str = ''groundedness'', INSTRUCTION_FOLLOWING: str = ''instruction_following'', VERBOSITY: str = ''verbosity'', TEXT_QUALITY: str = ''text_quality'', SUMMARIZATION_QUALITY: str = ''summarization_quality'', QUESTION_ANSWERING_QUALITY: str = ''question_answering_quality'', MULTI_TURN_CHAT_QUALITY: str = ''multi_turn_chat_quality'', MULTI_TURN_SAFETY: str = ''multi_turn_safety'', RUBRIC_BASED_INSTRUCTION_FOLLOWING: str = ''rubric_based_instruction_following'', PAIRWISE_COHERENCE: str = ''pairwise_coherence'', PAIRWISE_FLUENCY: str = ''pairwise_fluency'', PAIRWISE_SAFETY: str = ''pairwise_safety'', PAIRWISE_GROUNDEDNESS: str = ''pairwise_groundedness'', PAIRWISE_INSTRUCTION_FOLLOWING: str = ''pairwise_instruction_following'', PAIRWISE_VERBOSITY: str = ''pairwise_verbosity'', PAIRWISE_TEXT_QUALITY: str = ''pairwise_text_quality'', PAIRWISE_SUMMARIZATION_QUALITY:
    str = ''pairwise_summarization_quality'', PAIRWISE_QUESTION_ANSWERING_QUALITY: str = ''pairwise_question_answering_quality'', PAIRWISE_MULTI_TURN_CHAT_QUALITY: str = ''pairwise_multi_turn_chat_quality'', PAIRWISE_MULTI_TURN_SAFETY: str = ''pairwise_multi_turn_safety'', POINTWISE_METRIC: str = ''pointwise_metric'', PAIRWISE_METRIC: str = ''pairwise_metric'', EXACT_MATCH: str = ''exact_match'', BLEU: str = ''bleu'', ROUGE: str = ''rouge'', ROUGE_1: str = ''rouge_1'', ROUGE_2: str = ''rouge_2'', ROUGE_L: str = ''rouge_l'', ROUGE_L_SUM: str = ''rouge_l_sum'', TOOL_CALL_VALID: str = ''tool_call_valid'', TOOL_NAME_MATCH: str = ''tool_name_match'', TOOL_PARAMETER_KEY_MATCH: str = ''tool_parameter_key_match'', TOOL_PARAMETER_KV_MATCH: str = ''tool_parameter_kv_match'', TRAJECTORY_EXACT_MATCH: str = ''trajectory_exact_match'', TRAJECTORY_IN_ORDER_MATCH: str = ''trajectory_in_order_match'', TRAJECTORY_ANY_ORDER_MATCH: str = ''trajectory_any_order_match'', TRAJECTORY_PRECISION: str = ''trajectory_precision'',
    TRAJECTORY_RECALL: str = ''trajectory_recall'', TRAJECTORY_SINGLE_TOOL_USE: str = ''trajectory_single_tool_use'', LATENCY: str = ''latency_in_seconds'', FAILURE: str = ''failure'', AUTOMATIC_METRIC_LIST: Any = (EXACT_MATCH, BLEU, ROUGE, ROUGE_1, ROUGE_2, ROUGE_L, ROUGE_L_SUM, TOOL_CALL_VALID, TOOL_NAME_MATCH, TOOL_PARAMETER_KEY_MATCH, TOOL_PARAMETER_KV_MATCH), TRAJECTORY_METRIC_LIST: Any = (TRAJECTORY_EXACT_MATCH, TRAJECTORY_IN_ORDER_MATCH, TRAJECTORY_ANY_ORDER_MATCH, TRAJECTORY_PRECISION, TRAJECTORY_RECALL, TRAJECTORY_SINGLE_TOOL_USE), DEFAULT_METRIC_LIST: Any = (LATENCY, FAILURE), POINTWISE_METRIC_PROMPT_TEMPLATE_EXAMPLE_LIST: Any = (COHERENCE, FLUENCY, SAFETY, GROUNDEDNESS, INSTRUCTION_FOLLOWING, VERBOSITY, TEXT_QUALITY, SUMMARIZATION_QUALITY, QUESTION_ANSWERING_QUALITY, MULTI_TURN_CHAT_QUALITY, MULTI_TURN_SAFETY), PAIRWISE_METRIC_PROMPT_TEMPLATE_EXAMPLE_LIST: Any = (PAIRWISE_COHERENCE, PAIRWISE_FLUENCY, PAIRWISE_SAFETY, PAIRWISE_GROUNDEDNESS, PAIRWISE_INSTRUCTION_FOLLOWING, PAIRWISE_VERBOSITY,
    PAIRWISE_TEXT_QUALITY, PAIRWISE_SUMMARIZATION_QUALITY, PAIRWISE_QUESTION_ANSWERING_QUALITY, PAIRWISE_MULTI_TURN_CHAT_QUALITY, PAIRWISE_MULTI_TURN_SAFETY)):'
  properties:
  - signature: 'COHERENCE: str'
  - signature: 'FLUENCY: str'
  - signature: 'SAFETY: str'
  - signature: 'GROUNDEDNESS: str'
  - signature: 'INSTRUCTION_FOLLOWING: str'
  - signature: 'VERBOSITY: str'
  - signature: 'TEXT_QUALITY: str'
  - signature: 'SUMMARIZATION_QUALITY: str'
  - signature: 'QUESTION_ANSWERING_QUALITY: str'
  - signature: 'MULTI_TURN_CHAT_QUALITY: str'
  - signature: 'MULTI_TURN_SAFETY: str'
  - signature: 'RUBRIC_BASED_INSTRUCTION_FOLLOWING: str'
  - signature: 'PAIRWISE_COHERENCE: str'
  - signature: 'PAIRWISE_FLUENCY: str'
  - signature: 'PAIRWISE_SAFETY: str'
  - signature: 'PAIRWISE_GROUNDEDNESS: str'
  - signature: 'PAIRWISE_INSTRUCTION_FOLLOWING: str'
  - signature: 'PAIRWISE_VERBOSITY: str'
  - signature: 'PAIRWISE_TEXT_QUALITY: str'
  - signature: 'PAIRWISE_SUMMARIZATION_QUALITY: str'
  - signature: 'PAIRWISE_QUESTION_ANSWERING_QUALITY: str'
  - signature: 'PAIRWISE_MULTI_TURN_CHAT_QUALITY: str'
  - signature: 'PAIRWISE_MULTI_TURN_SAFETY: str'
  - signature: 'POINTWISE_METRIC: str'
  - signature: 'PAIRWISE_METRIC: str'
  - signature: 'EXACT_MATCH: str'
  - signature: 'BLEU: str'
  - signature: 'ROUGE: str'
  - signature: 'ROUGE_1: str'
  - signature: 'ROUGE_2: str'
  - signature: 'ROUGE_L: str'
  - signature: 'ROUGE_L_SUM: str'
  - signature: 'TOOL_CALL_VALID: str'
  - signature: 'TOOL_NAME_MATCH: str'
  - signature: 'TOOL_PARAMETER_KEY_MATCH: str'
  - signature: 'TOOL_PARAMETER_KV_MATCH: str'
  - signature: 'TRAJECTORY_EXACT_MATCH: str'
  - signature: 'TRAJECTORY_IN_ORDER_MATCH: str'
  - signature: 'TRAJECTORY_ANY_ORDER_MATCH: str'
  - signature: 'TRAJECTORY_PRECISION: str'
  - signature: 'TRAJECTORY_RECALL: str'
  - signature: 'TRAJECTORY_SINGLE_TOOL_USE: str'
  - signature: 'LATENCY: str'
  - signature: 'FAILURE: str'
  - signature: 'AUTOMATIC_METRIC_LIST: Any'
  - signature: 'TRAJECTORY_METRIC_LIST: Any'
  - signature: 'DEFAULT_METRIC_LIST: Any'
  - signature: 'POINTWISE_METRIC_PROMPT_TEMPLATE_EXAMPLE_LIST: Any'
  - signature: 'PAIRWISE_METRIC_PROMPT_TEMPLATE_EXAMPLE_LIST: Any'
- rank: 2827
  id: vertexai.preview.evaluation.constants.MetricResult
  name: MetricResult
  file_path: env/lib/python3.13/site-packages/vertexai/preview/evaluation/constants.py
  type: CLASS
  group: Orphan
  usage_score: 0
  constructor_signature: 'def __init__(self, *, ROW_COUNT_KEY: str = ''row_count'', SCORE_KEY: str = ''score'', EXPLANATION_KEY: str = ''explanation'', CUSTOM_OUTPUT_KEY: str = ''custom_output'', RAW_OUTPUT_KEY: str = ''raw_output'', RAW_OUTPUTS_KEY: str = ''raw_outputs'', PAIRWISE_CHOICE_KEY: str = ''pairwise_choice'', IS_UNSAFE_KEY: str = ''is_unsafe'', IS_UNSAFE_PROBABILITY_KEY: str = ''is_unsafe_probability'', VIOLATED_POLICIES_KEY: str = ''violated_policies'', RUBRIC_LEVEL_INSTRUCTION_FOLLOWING_KEY: str = ''per_rubric_result'', EXACT_MATCH_RESULTS: str = ''exact_match_results'', BLEU_RESULTS: str = ''bleu_results'', ROUGE_RESULTS: str = ''rouge_results'', TOOL_CALL_VALID_RESULTS: str = ''tool_call_valid_results'', TOOL_NAME_MATCH_RESULTS: str = ''tool_name_match_results'', TOOL_PARAMETER_KEY_MATCH_RESULTS: str = ''tool_parameter_key_match_results'', TOOL_PARAMETER_KV_MATCH_RESULTS: str = ''tool_parameter_kv_match_results'', TRAJECTORY_EXACT_MATCH_RESULTS: str = ''trajectory_exact_match_results'',
    TRAJECTORY_IN_ORDER_MATCH_RESULTS: str = ''trajectory_in_order_match_results'', TRAJECTORY_ANY_ORDER_MATCH_RESULTS: str = ''trajectory_any_order_match_results'', TRAJECTORY_PRECISION_RESULTS: str = ''trajectory_precision_results'', TRAJECTORY_RECALL_RESULTS: str = ''trajectory_recall_results'', TRAJECTORY_SINGLE_TOOL_USE_RESULTS: str = ''trajectory_single_tool_use_results'', POINTWISE_METRIC_RESULT: str = ''pointwise_metric_result'', PAIRWISE_METRIC_RESULT: str = ''pairwise_metric_result'', RUBRIC_BASED_INSTRUCTION_FOLLOWING_RESULT: str = ''rubric_based_instruction_following_result'', AUTOMATIC_METRIC_RESULTS_LIST: Any = (EXACT_MATCH_RESULTS, BLEU_RESULTS, ROUGE_RESULTS, TOOL_CALL_VALID_RESULTS, TOOL_NAME_MATCH_RESULTS, TOOL_PARAMETER_KEY_MATCH_RESULTS, TOOL_PARAMETER_KV_MATCH_RESULTS, TRAJECTORY_EXACT_MATCH_RESULTS, TRAJECTORY_IN_ORDER_MATCH_RESULTS, TRAJECTORY_ANY_ORDER_MATCH_RESULTS, TRAJECTORY_PRECISION_RESULTS, TRAJECTORY_RECALL_RESULTS, TRAJECTORY_SINGLE_TOOL_USE_RESULTS)):'
  properties:
  - signature: 'ROW_COUNT_KEY: str'
  - signature: 'SCORE_KEY: str'
  - signature: 'EXPLANATION_KEY: str'
  - signature: 'CUSTOM_OUTPUT_KEY: str'
  - signature: 'RAW_OUTPUT_KEY: str'
  - signature: 'RAW_OUTPUTS_KEY: str'
  - signature: 'PAIRWISE_CHOICE_KEY: str'
  - signature: 'IS_UNSAFE_KEY: str'
  - signature: 'IS_UNSAFE_PROBABILITY_KEY: str'
  - signature: 'VIOLATED_POLICIES_KEY: str'
  - signature: 'RUBRIC_LEVEL_INSTRUCTION_FOLLOWING_KEY: str'
  - signature: 'EXACT_MATCH_RESULTS: str'
  - signature: 'BLEU_RESULTS: str'
  - signature: 'ROUGE_RESULTS: str'
  - signature: 'TOOL_CALL_VALID_RESULTS: str'
  - signature: 'TOOL_NAME_MATCH_RESULTS: str'
  - signature: 'TOOL_PARAMETER_KEY_MATCH_RESULTS: str'
  - signature: 'TOOL_PARAMETER_KV_MATCH_RESULTS: str'
  - signature: 'TRAJECTORY_EXACT_MATCH_RESULTS: str'
  - signature: 'TRAJECTORY_IN_ORDER_MATCH_RESULTS: str'
  - signature: 'TRAJECTORY_ANY_ORDER_MATCH_RESULTS: str'
  - signature: 'TRAJECTORY_PRECISION_RESULTS: str'
  - signature: 'TRAJECTORY_RECALL_RESULTS: str'
  - signature: 'TRAJECTORY_SINGLE_TOOL_USE_RESULTS: str'
  - signature: 'POINTWISE_METRIC_RESULT: str'
  - signature: 'PAIRWISE_METRIC_RESULT: str'
  - signature: 'RUBRIC_BASED_INSTRUCTION_FOLLOWING_RESULT: str'
  - signature: 'AUTOMATIC_METRIC_RESULTS_LIST: Any'
- rank: 2828
  id: vertexai.preview.evaluation.constants.QuotaLimit
  name: QuotaLimit
  file_path: env/lib/python3.13/site-packages/vertexai/preview/evaluation/constants.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: Generative AI on Vertex AI quota limits.
  constructor_signature: 'def __init__(self, *, EVAL_SERVICE_QPS: int = 10):'
  properties:
  - signature: 'EVAL_SERVICE_QPS: int'
- rank: 2829
  id: vertexai.preview.evaluation.eval_task
  name: eval_task
  file_path: env/lib/python3.13/site-packages/vertexai/preview/evaluation/eval_task.py
  type: MODULE
  group: Orphan
  usage_score: 0
  docstring: Evaluation Task class.
- rank: 2830
  id: vertexai.preview.evaluation.eval_task.EvalTask
  name: EvalTask
  file_path: env/lib/python3.13/site-packages/vertexai/preview/evaluation/eval_task.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: "A class representing an EvalTask.\n\nAn evaluation task assesses the ability of a Gen AI model, agent or\napplication to perform a specific task in response to prompts.\nEach evaluation task includes an evaluation dataset, which can be a set of\ntest cases and a set of metrics for assessment. These tasks provide the\nframework for running evaluations in a standardized and repeatable way,\nallowing for comparative assessment with varying run-specific parameters.\n\nDataset Details:\n\n    Default dataset column names:\n        * prompt_column_name: \"prompt\"\n        * reference_column_name: \"reference\"\n        * response_column_name: \"response\"\n        * baseline_model_response_column_name: \"baseline_model_response\"\n        * rubrics_column_name: \"rubrics\"\n\n    Requirement for different use cases:\n      * Bring-your-own-response (BYOR): You already have the data that you\n          want to evaluate stored in the dataset. Response column name can be\n        \
    \  customized by providing `response_column_name` parameter, or in the\n          `metric_column_mapping`. For BYOR pairwise evaluation, the baseline\n          model response column name can be customized by providing\n          `baseline_model_response_column_name` parameter, or\n          in the `metric_column_mapping`. If the `response` column or\n          `baseline_model_response` column is present while the\n          corresponding model is specified, an error will be raised.\n\n      * Perform model/agent inference without a prompt template: You have a dataset\n          containing the input prompts to the model/agent and want to perform\n          inference before evaluation. A column named `prompt` is required\n          in the evaluation dataset and is used directly as input to the model/agent.\n\n      * Perform model/agent inference with a prompt template: You have a dataset\n          containing the input variables to the prompt template and want to\n          assemble\
    \ the prompts for inference. Evaluation dataset\n          must contain column names corresponding to the variable names in\n          the prompt template. For example, if prompt template is\n          \"Instruction: {instruction}, context: {context}\", the dataset must\n          contain `instruction` and `context` columns.\n\nMetrics Details:\n\n    The supported metrics descriptions, rating rubrics, and the required\n    input variables can be found on the Vertex AI public documentation page.\n    [Evaluation methods and metrics](https://cloud.google.com/vertex-ai/generative-ai/docs/models/determine-eval).\n\nUsage Examples:\n\n    1. To perform bring-your-own-response(BYOR) evaluation, provide the model\n    responses in the `response` column in the dataset. If a pairwise metric is\n    used for BYOR evaluation, provide the baseline model responses in the\n    `baseline_model_response` column.\n\n      ```\n      eval_dataset = pd.DataFrame({\n              \"prompt\"  : [...],\n\
    \              \"reference\": [...],\n              \"response\" : [...],\n              \"baseline_model_response\": [...],\n      })\n      eval_task = EvalTask(\n        dataset=eval_dataset,\n        metrics=[\n                \"bleu\",\n                \"rouge_l_sum\",\n                MetricPromptTemplateExamples.Pointwise.FLUENCY,\n                MetricPromptTemplateExamples.Pairwise.SAFETY\n        ],\n        experiment=\"my-experiment\",\n      )\n      eval_result = eval_task.evaluate(experiment_run_name=\"eval-experiment-run\")\n      ```\n\n    2. To perform evaluation with Gemini model inference, specify the `model`\n    parameter with a `GenerativeModel` instance.  The input column name to the\n    model is `prompt` and must be present in the dataset.\n\n      ```\n      eval_dataset = pd.DataFrame({\n            \"reference\": [...],\n            \"prompt\"  : [...],\n      })\n      result = EvalTask(\n          dataset=eval_dataset,\n          metrics=[\"exact_match\"\
    , \"bleu\", \"rouge_1\", \"rouge_l_sum\"],\n          experiment=\"my-experiment\",\n      ).evaluate(\n          model=GenerativeModel(\"gemini-1.5-pro\"),\n          experiment_run_name=\"gemini-eval-run\"\n      )\n      ```\n\n    3. If a `prompt_template` is specified, the `prompt` column is not required.\n    Prompts can be assembled from the evaluation dataset, and all prompt\n    template variable names must be present in the dataset columns.\n      ```\n      eval_dataset = pd.DataFrame({\n          \"context\"    : [...],\n          \"instruction\": [...],\n      })\n      result = EvalTask(\n          dataset=eval_dataset,\n          metrics=[MetricPromptTemplateExamples.Pointwise.SUMMARIZATION_QUALITY],\n      ).evaluate(\n          model=GenerativeModel(\"gemini-1.5-pro\"),\n          prompt_template=\"{instruction}. Article: {context}. Summary:\",\n      )\n      ```\n\n    4. To perform evaluation with custom model inference, specify the `model`\n    parameter with a custom\
    \ inference function. The input column name to the\n    custom inference function is `prompt` and must be present in the dataset.\n\n      ```\n      from openai import OpenAI\n      client = OpenAI()\n      def custom_model_fn(input: str) -> str:\n        response = client.chat.completions.create(\n          model=\"gpt-3.5-turbo\",\n          messages=[\n            {\"role\": \"user\", \"content\": input}\n          ]\n        )\n        return response.choices[0].message.content\n\n      eval_dataset = pd.DataFrame({\n            \"prompt\"  : [...],\n            \"reference\": [...],\n      })\n      result = EvalTask(\n          dataset=eval_dataset,\n          metrics=[MetricPromptTemplateExamples.Pointwise.SAFETY],\n          experiment=\"my-experiment\",\n      ).evaluate(\n          model=custom_model_fn,\n          experiment_run_name=\"gpt-eval-run\"\n      )\n      ```\n\n    5. To perform pairwise metric evaluation with model inference step, specify\n    the `baseline_model`\
    \ input to a `PairwiseMetric` instance and the candidate\n    `model` input to the `EvalTask.evaluate()` function. The input column name\n    to both models is `prompt` and must be present in the dataset.\n\n      ```\n      baseline_model = GenerativeModel(\"gemini-1.0-pro\")\n      candidate_model = GenerativeModel(\"gemini-1.5-pro\")\n\n      pairwise_groundedness = PairwiseMetric(\n          metric_prompt_template=MetricPromptTemplateExamples.get_prompt_template(\n              \"pairwise_groundedness\"\n          ),\n          baseline_model=baseline_model,\n      )\n      eval_dataset = pd.DataFrame({\n            \"prompt\"  : [...],\n      })\n      result = EvalTask(\n          dataset=eval_dataset,\n          metrics=[pairwise_groundedness],\n          experiment=\"my-pairwise-experiment\",\n      ).evaluate(\n          model=candidate_model,\n          experiment_run_name=\"gemini-pairwise-eval-run\",\n      )\n      ```"
  constructor_signature: 'def __init__(self, *, dataset: typing.Union[pandas.DataFrame, str, typing.Dict[str, typing.Any], google.colab.sheets.InteractiveSheet], metrics: typing.List[typing.Union[typing.Literal[exact_match, bleu, rouge_1, rouge_2, rouge_l, rouge_l_sum, tool_call_valid, tool_name_match, tool_parameter_key_match, tool_parameter_kv_match, trajectory_exact_match, trajectory_in_order_match, trajectory_any_order_match, trajectory_precision, trajectory_recall, rubric_based_instruction_following], vertexai.preview.evaluation.metrics._base.CustomMetric, vertexai.preview.evaluation.metrics._base._AutomaticMetric, vertexai.preview.evaluation.metrics.pointwise_metric.PointwiseMetric, vertexai.preview.evaluation.metrics.pairwise_metric.PairwiseMetric, vertexai.preview.evaluation.metrics.rubric_based_metric.RubricBasedMetric]], experiment: typing.Optional[str]=None, metric_column_mapping: typing.Optional[typing.Dict[str, str]]=None, output_uri_prefix: typing.Optional[str]='''', autorater_config:
    typing.Optional[vertexai.preview.evaluation.eval_task.AutoraterConfig]=None):'
  methods:
  - signature: 'def dataset(self) -> pandas.DataFrame:'
    docstring: Returns evaluation dataset.
  - signature: 'def metrics(self) -> typing.List[typing.Union[str, vertexai.preview.evaluation.metrics._base.CustomMetric]]:'
    docstring: Returns metrics.
  - signature: 'def autorater_config(self) -> typing.Optional[vertexai.preview.evaluation.eval_task.AutoraterConfig]:'
    docstring: Returns autorater config.
  - signature: 'def experiment(self) -> typing.Optional[str]:'
    docstring: Returns experiment name.
  - signature: 'def evaluate(self, *, model: typing.Optional[vertexai.preview.evaluation.eval_task._ModelType]=None, runnable: typing.Optional[vertexai.preview.evaluation.eval_task._RunnableType]=None, prompt_template: typing.Optional[str]=None, experiment_run_name: typing.Optional[str]=None, response_column_name: typing.Optional[str]=None, baseline_model_response_column_name: typing.Optional[str]=None, evaluation_service_qps: typing.Optional[float]=None, retry_timeout: float=120.0, output_file_name: typing.Optional[str]='''') -> vertexai.preview.evaluation.eval_task.EvalResult:'
    docstring: "Runs an evaluation for the EvalTask.\n\nArgs:\n  model: A GenerativeModel instance or a custom model function to generate\n    responses to evaluate. If not provided, the evaluation can be performed\n    in the bring-your-own-response (BYOR) mode.\n  runnable: The runnable to generate responses to evaluate. If not provided,\n    the evaluation is computed with the `response` and/or `predicted_trajectory`\n    column in the `dataset`.\n  prompt_template: The prompt template to use for the evaluation. If not\n    set, the prompt template that was used to create the EvalTask will be\n    used.\n  experiment_run_name: The name of the experiment run to log the evaluation\n    to if an experiment is set for this EvalTask. If not provided, a random\n    unique experiment run name is used.\n  response_column_name: The column name of model response in the dataset. If\n    provided, this will override the `metric_column_mapping` of the `EvalTask`.\n  baseline_model_response_column_name:\
      \ The column name of baseline model\n    response in the dataset for pairwise metrics. If provided, this will\n    override the `metric_column_mapping` of the `EvalTask`\n  evaluation_service_qps: The custom QPS limit for the evaluation service.\n  retry_timeout: How long to keep retrying the evaluation requests for\n    the whole evaluation dataset, in seconds.\n  output_file_name: The file name with csv suffix to store the output\n    metrics_table.\n\nReturns:\n  The evaluation result."
  - signature: 'def display_runs(self):'
    docstring: Displays experiment runs associated with this EvalTask.
- rank: 2831
  id: vertexai.preview.evaluation.eval_task.EvalTask.__init__
  name: __init__
  file_path: env/lib/python3.13/site-packages/vertexai/preview/evaluation/eval_task.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Initializes an EvalTask.\n\nArgs:\n    dataset: The dataset to be evaluated.\n        Supports the following dataset formats:\n        * pandas.DataFrame: Used directly for evaluation.\n        * Dict: Converted to a pandas DataFrame before evaluation.\n        * str: Interpreted as a file path or URI. Supported formats include:\n            * Local JSONL or CSV files:  Loaded from the local filesystem.\n            * GCS JSONL or CSV files: Loaded from Google Cloud Storage\n                (e.g., 'gs://bucket/data.csv').\n            * BigQuery table URI: Loaded from Google Cloud BigQuery\n                (e.g., 'bq://project-id.dataset.table_name').\n    metrics: The list of metric names, or Metric instances to evaluate.\n      Prompt template is required for PairwiseMetric.\n    experiment: The name of the experiment to log the evaluations to.\n    metric_column_mapping: An optional dictionary column mapping that\n      overrides the metric prompt template input variable\
    \ names with\n      mapped the evaluation dataset column names, used during evaluation.\n      For example, if the input_variables of the metric prompt template\n      are [\"context\", \"reference\"], the metric_column_mapping can be\n        {\n            \"context\": \"news_context\",\n            \"reference\": \"ground_truth\",\n            \"response\": \"model_1_response\"\n        }\n      if the dataset has columns \"news_context\", \"ground_truth\" and\n      \"model_1_response\".\n    output_uri_prefix: GCS location to store the metrics_table from\n      evaluation results.\n    autorater_config: The autorater config for model based evaluation.\n      If autorater config is specified on a metric, it will override the\n      autorater config specified here."
  signature: 'def __init__(self, *, dataset: typing.Union[pandas.DataFrame, str, typing.Dict[str, typing.Any], google.colab.sheets.InteractiveSheet], metrics: typing.List[typing.Union[typing.Literal[exact_match, bleu, rouge_1, rouge_2, rouge_l, rouge_l_sum, tool_call_valid, tool_name_match, tool_parameter_key_match, tool_parameter_kv_match, trajectory_exact_match, trajectory_in_order_match, trajectory_any_order_match, trajectory_precision, trajectory_recall, rubric_based_instruction_following], vertexai.preview.evaluation.metrics._base.CustomMetric, vertexai.preview.evaluation.metrics._base._AutomaticMetric, vertexai.preview.evaluation.metrics.pointwise_metric.PointwiseMetric, vertexai.preview.evaluation.metrics.pairwise_metric.PairwiseMetric, vertexai.preview.evaluation.metrics.rubric_based_metric.RubricBasedMetric]], experiment: typing.Optional[str]=None, metric_column_mapping: typing.Optional[typing.Dict[str, str]]=None, output_uri_prefix: typing.Optional[str]='''', autorater_config:
    typing.Optional[vertexai.preview.evaluation.eval_task.AutoraterConfig]=None):'
- rank: 2832
  id: vertexai.preview.evaluation.eval_task.EvalTask.display_runs
  name: display_runs
  file_path: env/lib/python3.13/site-packages/vertexai/preview/evaluation/eval_task.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: Displays experiment runs associated with this EvalTask.
  signature: 'def display_runs(self):'
- rank: 2833
  id: vertexai.preview.evaluation.eval_task.EvalTask.evaluate
  name: evaluate
  file_path: env/lib/python3.13/site-packages/vertexai/preview/evaluation/eval_task.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Runs an evaluation for the EvalTask.\n\nArgs:\n  model: A GenerativeModel instance or a custom model function to generate\n    responses to evaluate. If not provided, the evaluation can be performed\n    in the bring-your-own-response (BYOR) mode.\n  runnable: The runnable to generate responses to evaluate. If not provided,\n    the evaluation is computed with the `response` and/or `predicted_trajectory`\n    column in the `dataset`.\n  prompt_template: The prompt template to use for the evaluation. If not\n    set, the prompt template that was used to create the EvalTask will be\n    used.\n  experiment_run_name: The name of the experiment run to log the evaluation\n    to if an experiment is set for this EvalTask. If not provided, a random\n    unique experiment run name is used.\n  response_column_name: The column name of model response in the dataset. If\n    provided, this will override the `metric_column_mapping` of the `EvalTask`.\n  baseline_model_response_column_name:\
    \ The column name of baseline model\n    response in the dataset for pairwise metrics. If provided, this will\n    override the `metric_column_mapping` of the `EvalTask`\n  evaluation_service_qps: The custom QPS limit for the evaluation service.\n  retry_timeout: How long to keep retrying the evaluation requests for\n    the whole evaluation dataset, in seconds.\n  output_file_name: The file name with csv suffix to store the output\n    metrics_table.\n\nReturns:\n  The evaluation result."
  signature: 'def evaluate(self, *, model: typing.Optional[vertexai.preview.evaluation.eval_task._ModelType]=None, runnable: typing.Optional[vertexai.preview.evaluation.eval_task._RunnableType]=None, prompt_template: typing.Optional[str]=None, experiment_run_name: typing.Optional[str]=None, response_column_name: typing.Optional[str]=None, baseline_model_response_column_name: typing.Optional[str]=None, evaluation_service_qps: typing.Optional[float]=None, retry_timeout: float=120.0, output_file_name: typing.Optional[str]='''') -> vertexai.preview.evaluation.eval_task.EvalResult:'
- rank: 2834
  id: vertexai.preview.evaluation.metric_utils
  name: metric_utils
  file_path: env/lib/python3.13/site-packages/vertexai/preview/evaluation/metric_utils.py
  type: MODULE
  group: Orphan
  usage_score: 0
  docstring: Utility functions for metrics.
  methods:
  - signature: 'def dump(metric: typing.Union[vertexai.preview.evaluation.metric_utils.PointwiseMetric, vertexai.preview.evaluation.metric_utils.PairwiseMetric, vertexai.preview.evaluation.metric_utils.RubricBasedMetric], file_path: str, version: typing.Optional[str]):'
    docstring: "Dumps a metric object to a YAML file.\n\nArgs:\n  metric: The metric to be dumped to a file.\n  file_path: The path to the file. Local and GCS files are supported.\n  version: Optional. The version of the metric. Defaults to the timestamp\n    when the metric file is created."
  - signature: 'def dumps(metric: typing.Union[vertexai.preview.evaluation.metric_utils.PointwiseMetric, vertexai.preview.evaluation.metric_utils.PairwiseMetric, vertexai.preview.evaluation.metric_utils.RubricBasedMetric], version: typing.Optional[str]) -> str:'
    docstring: "Dumps a metric object to YAML data.\n\nArgs:\n  metric: The metric to be dumped to YAML data.\n  version: Optional. The version of the metric. Defaults to the timestamp\n    when the metric file is created.\n\nReturns:\n  The YAML data of the metric."
  - signature: 'def load(file_path: str, baseline_model: typing.Optional[typing.Union[vertexai.preview.evaluation.metric_utils.GenerativeModel, typing.Callable[[str], str]]]) -> typing.Union[vertexai.preview.evaluation.metric_utils.PointwiseMetric, vertexai.preview.evaluation.metric_utils.PairwiseMetric, vertexai.preview.evaluation.metric_utils.RubricBasedMetric]:'
    docstring: "Loads a metric object from a YAML file.\n\nArgs:\n  file_path: Path to the file containing the autorater metric configuration.\n    Local and GCS files are supported.\n  baseline_model: Optional. The baseline model to use for pairwise metrics.\n\nReturns:\n  The metric object loaded from the file."
  - signature: 'def loads(yaml_data: str, baseline_model: typing.Optional[typing.Union[vertexai.preview.evaluation.metric_utils.GenerativeModel, typing.Callable[[str], str]]]) -> typing.Union[vertexai.preview.evaluation.metric_utils.PointwiseMetric, vertexai.preview.evaluation.metric_utils.PairwiseMetric, vertexai.preview.evaluation.metric_utils.RubricBasedMetric]:'
    docstring: "Loads a metric object from YAML data.\n\nArgs:\n  yaml_data: YAML data containing the autorater metric configuration.\n  baseline_model: Optional. The baseline model to use for pairwise metrics.\n\nReturns:\n  The metric object loaded from the YAML data."
- rank: 2835
  id: vertexai.preview.evaluation.metric_utils.dump
  name: dump
  file_path: env/lib/python3.13/site-packages/vertexai/preview/evaluation/metric_utils.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Dumps a metric object to a YAML file.\n\nArgs:\n  metric: The metric to be dumped to a file.\n  file_path: The path to the file. Local and GCS files are supported.\n  version: Optional. The version of the metric. Defaults to the timestamp\n    when the metric file is created."
  signature: 'def dump(metric: typing.Union[vertexai.preview.evaluation.metric_utils.PointwiseMetric, vertexai.preview.evaluation.metric_utils.PairwiseMetric, vertexai.preview.evaluation.metric_utils.RubricBasedMetric], file_path: str, version: typing.Optional[str]):'
- rank: 2836
  id: vertexai.preview.evaluation.metric_utils.dumps
  name: dumps
  file_path: env/lib/python3.13/site-packages/vertexai/preview/evaluation/metric_utils.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Dumps a metric object to YAML data.\n\nArgs:\n  metric: The metric to be dumped to YAML data.\n  version: Optional. The version of the metric. Defaults to the timestamp\n    when the metric file is created.\n\nReturns:\n  The YAML data of the metric."
  signature: 'def dumps(metric: typing.Union[vertexai.preview.evaluation.metric_utils.PointwiseMetric, vertexai.preview.evaluation.metric_utils.PairwiseMetric, vertexai.preview.evaluation.metric_utils.RubricBasedMetric], version: typing.Optional[str]) -> str:'
- rank: 2837
  id: vertexai.preview.evaluation.metric_utils.load
  name: load
  file_path: env/lib/python3.13/site-packages/vertexai/preview/evaluation/metric_utils.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Loads a metric object from a YAML file.\n\nArgs:\n  file_path: Path to the file containing the autorater metric configuration.\n    Local and GCS files are supported.\n  baseline_model: Optional. The baseline model to use for pairwise metrics.\n\nReturns:\n  The metric object loaded from the file."
  signature: 'def load(file_path: str, baseline_model: typing.Optional[typing.Union[vertexai.preview.evaluation.metric_utils.GenerativeModel, typing.Callable[[str], str]]]) -> typing.Union[vertexai.preview.evaluation.metric_utils.PointwiseMetric, vertexai.preview.evaluation.metric_utils.PairwiseMetric, vertexai.preview.evaluation.metric_utils.RubricBasedMetric]:'
- rank: 2838
  id: vertexai.preview.evaluation.metric_utils.loads
  name: loads
  file_path: env/lib/python3.13/site-packages/vertexai/preview/evaluation/metric_utils.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Loads a metric object from YAML data.\n\nArgs:\n  yaml_data: YAML data containing the autorater metric configuration.\n  baseline_model: Optional. The baseline model to use for pairwise metrics.\n\nReturns:\n  The metric object loaded from the YAML data."
  signature: 'def loads(yaml_data: str, baseline_model: typing.Optional[typing.Union[vertexai.preview.evaluation.metric_utils.GenerativeModel, typing.Callable[[str], str]]]) -> typing.Union[vertexai.preview.evaluation.metric_utils.PointwiseMetric, vertexai.preview.evaluation.metric_utils.PairwiseMetric, vertexai.preview.evaluation.metric_utils.RubricBasedMetric]:'
- rank: 2839
  id: vertexai.preview.evaluation.metrics
  name: metrics
  file_path: env/lib/python3.13/site-packages/vertexai/preview/evaluation/metrics/__init__.py
  type: MODULE
  group: Orphan
  usage_score: 0
  docstring: Evaluation Metrics Module.
- rank: 2840
  id: vertexai.preview.evaluation.metrics.custom_output_config
  name: custom_output_config
  file_path: env/lib/python3.13/site-packages/vertexai/preview/evaluation/metrics/custom_output_config.py
  type: MODULE
  group: Orphan
  usage_score: 0
  docstring: Custom output config for model-based metrics.
- rank: 2841
  id: vertexai.preview.evaluation.metrics.custom_output_config.CustomOutputConfig
  name: CustomOutputConfig
  file_path: env/lib/python3.13/site-packages/vertexai/preview/evaluation/metrics/custom_output_config.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: "Custom output config for model-based metrics.\n\nAttributes:\n    return_raw_output: Whether to return the raw output of the metric\n        function.\n    parsing_fn: Function to parse the raw output of the metric."
  constructor_signature: 'def __init__(self, return_raw_output: bool, parsing_fn: typing.Optional[typing.Callable[[str], typing.Dict[str, typing.Any]]]):'
- rank: 2842
  id: vertexai.preview.evaluation.metrics.custom_output_config.CustomOutputConfig.__init__
  name: __init__
  file_path: env/lib/python3.13/site-packages/vertexai/preview/evaluation/metrics/custom_output_config.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: Initializes CustomOutputConfig.
  signature: 'def __init__(self, return_raw_output: bool, parsing_fn: typing.Optional[typing.Callable[[str], typing.Dict[str, typing.Any]]]):'
- rank: 2843
  id: vertexai.preview.evaluation.metrics.metric_prompt_template
  name: metric_prompt_template
  file_path: env/lib/python3.13/site-packages/vertexai/preview/evaluation/metrics/metric_prompt_template.py
  type: MODULE
  group: Orphan
  usage_score: 0
  docstring: Metric prompt template classes for model-based metrics evaluation.
  methods:
  - signature: 'def serialize_dict_in_order(elements: typing.Optional[typing.Dict[str, str]]):'
    docstring: Serializes dictionary to ordered string value without brackets.
- rank: 2844
  id: vertexai.preview.evaluation.metrics.metric_prompt_template.PairwiseMetricPromptTemplate
  name: PairwiseMetricPromptTemplate
  file_path: env/lib/python3.13/site-packages/vertexai/preview/evaluation/metrics/metric_prompt_template.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Pairwise metric prompt template for pairwise model-based metrics.


    [Note: Inherited members from _MetricPromptTemplate are omitted.]'
  constructor_signature: 'def __init__(self, *, criteria: typing.Dict[str, str], rating_rubric: typing.Dict[str, str], input_variables: typing.Optional[typing.List[str]]=None, instruction: typing.Optional[str]=None, metric_definition: typing.Optional[str]=None, evaluation_steps: typing.Optional[typing.Dict[str, str]]=None, few_shot_examples: typing.Optional[typing.List[str]]=None):'
  methods:
  - signature: 'def get_default_pairwise_instruction(self) -> str:'
    docstring: Returns the default instruction for the metric prompt template.
  - signature: 'def get_default_pairwise_evaluation_steps(self) -> typing.Dict[str, str]:'
    docstring: Returns the default evaluation steps for the metric prompt template.
  omitted_inherited_members_from:
  - _MetricPromptTemplate
- rank: 2845
  id: vertexai.preview.evaluation.metrics.metric_prompt_template.PairwiseMetricPromptTemplate.__init__
  name: __init__
  file_path: env/lib/python3.13/site-packages/vertexai/preview/evaluation/metrics/metric_prompt_template.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Initializes a pairwise metric prompt template.\n\nArgs:\n    criteria: The standards and measures used to evaluate the model\n      responses. It is a dictionary of criterion names and criterion\n      definitions.\n    rating_rubric: A dictionary mapping of rating name and rating\n      definition, used to assign ratings or scores based on specific\n      criteria.\n    input_variables: An optional list of input fields to use in the metric\n      prompt template for generating model-based evaluation results.\n      Candidate model \"response\" column and \"baseline_model_response\" column\n      are included by default. If metric_column_mapping is provided, the\n      mapping values of the input fields will be used to retrieve data from\n      the evaluation dataset.\n    instruction: The general instruction to the model that performs the\n      evaluation. If not provided, a default pairwise metric instruction\n      will be used.\n    metric_definition: The optional metric\
    \ definition. It is a string\n      describing the metric to be evaluated at a high level. If not\n      provided, this field will not be included in the prompt template.\n    evaluation_steps: The optional gudelines of evaluation steps. A\n      dictionary of evaluation step name and evaluation step definition. If\n      not provided, a default pairwise metric evaluation steps will be used.\n    few_shot_examples: The optional list of few-shot examples to be used in\n      the prompt, to provide the model with demonstrations of how to perform\n      the evaluation, and improve the evaluation accuracy. If not provided,\n      this field will not be included in the prompt template."
  signature: 'def __init__(self, *, criteria: typing.Dict[str, str], rating_rubric: typing.Dict[str, str], input_variables: typing.Optional[typing.List[str]]=None, instruction: typing.Optional[str]=None, metric_definition: typing.Optional[str]=None, evaluation_steps: typing.Optional[typing.Dict[str, str]]=None, few_shot_examples: typing.Optional[typing.List[str]]=None):'
- rank: 2846
  id: vertexai.preview.evaluation.metrics.metric_prompt_template.PairwiseMetricPromptTemplate.get_default_pairwise_evaluation_steps
  name: get_default_pairwise_evaluation_steps
  file_path: env/lib/python3.13/site-packages/vertexai/preview/evaluation/metrics/metric_prompt_template.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: Returns the default evaluation steps for the metric prompt template.
  signature: 'def get_default_pairwise_evaluation_steps(self) -> typing.Dict[str, str]:'
- rank: 2847
  id: vertexai.preview.evaluation.metrics.metric_prompt_template.PairwiseMetricPromptTemplate.get_default_pairwise_instruction
  name: get_default_pairwise_instruction
  file_path: env/lib/python3.13/site-packages/vertexai/preview/evaluation/metrics/metric_prompt_template.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: Returns the default instruction for the metric prompt template.
  signature: 'def get_default_pairwise_instruction(self) -> str:'
- rank: 2848
  id: vertexai.preview.evaluation.metrics.metric_prompt_template.PointwiseMetricPromptTemplate
  name: PointwiseMetricPromptTemplate
  file_path: env/lib/python3.13/site-packages/vertexai/preview/evaluation/metrics/metric_prompt_template.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Pointwise metric prompt template for pointwise model-based metrics.


    [Note: Inherited members from _MetricPromptTemplate are omitted.]'
  constructor_signature: 'def __init__(self, *, criteria: typing.Dict[str, str], rating_rubric: typing.Dict[str, str], input_variables: typing.Optional[typing.List[str]]=None, instruction: typing.Optional[str]=None, metric_definition: typing.Optional[str]=None, evaluation_steps: typing.Optional[typing.Dict[str, str]]=None, few_shot_examples: typing.Optional[typing.List[str]]=None):'
  methods:
  - signature: 'def get_default_pointwise_instruction(self) -> str:'
    docstring: Returns the default instruction for the metric prompt template.
  - signature: 'def get_default_pointwise_evaluation_steps(self) -> typing.Dict[str, str]:'
    docstring: Returns the default evaluation steps for the metric prompt template.
  omitted_inherited_members_from:
  - _MetricPromptTemplate
- rank: 2849
  id: vertexai.preview.evaluation.metrics.metric_prompt_template.PointwiseMetricPromptTemplate.__init__
  name: __init__
  file_path: env/lib/python3.13/site-packages/vertexai/preview/evaluation/metrics/metric_prompt_template.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Initializes a pointwise metric prompt template.\n\nArgs:\n    criteria: The standards and measures used to evaluate the model\n      responses. It is a dictionary of criterion names and criterion\n      definitions.\n    rating_rubric: A dictionary mapping of rating name and rating\n      definition, used to assign ratings or scores based on specific\n      criteria.\n    input_variables: An optional list of input fields to use in the metric\n      prompt template for generating model-based evaluation results. Model\n      \"response\" column is included by default. If metric_column_mapping is\n      provided, the mapping values of the input fields will be used to\n      retrieve data from the evaluation dataset.\n    instruction: The general instruction to the model that performs the\n      evaluation. If not provided, a default pointwise metric instruction\n      will be used.\n    metric_definition: The optional metric definition. It is a string\n      describing the metric\
    \ to be evaluated at a high level. If not\n      provided, this field will not be included in the prompt template.\n    evaluation_steps: The optional gudelines of evaluation steps. A\n      dictionary of evaluation step name and evaluation step definition. If\n      not provided, a default pointwise metric evaluation steps will be\n      used.\n    few_shot_examples: The optional list of few-shot examples to be used in\n      the prompt, to provide the model with demonstrations of how to perform\n      the evaluation, and improve the evaluation accuracy. If not provided,\n      this field will not be included in the prompt template."
  signature: 'def __init__(self, *, criteria: typing.Dict[str, str], rating_rubric: typing.Dict[str, str], input_variables: typing.Optional[typing.List[str]]=None, instruction: typing.Optional[str]=None, metric_definition: typing.Optional[str]=None, evaluation_steps: typing.Optional[typing.Dict[str, str]]=None, few_shot_examples: typing.Optional[typing.List[str]]=None):'
- rank: 2850
  id: vertexai.preview.evaluation.metrics.metric_prompt_template.PointwiseMetricPromptTemplate.get_default_pointwise_evaluation_steps
  name: get_default_pointwise_evaluation_steps
  file_path: env/lib/python3.13/site-packages/vertexai/preview/evaluation/metrics/metric_prompt_template.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: Returns the default evaluation steps for the metric prompt template.
  signature: 'def get_default_pointwise_evaluation_steps(self) -> typing.Dict[str, str]:'
- rank: 2851
  id: vertexai.preview.evaluation.metrics.metric_prompt_template.PointwiseMetricPromptTemplate.get_default_pointwise_instruction
  name: get_default_pointwise_instruction
  file_path: env/lib/python3.13/site-packages/vertexai/preview/evaluation/metrics/metric_prompt_template.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: Returns the default instruction for the metric prompt template.
  signature: 'def get_default_pointwise_instruction(self) -> str:'
- rank: 2852
  id: vertexai.preview.evaluation.metrics.metric_prompt_template.serialize_dict_in_order
  name: serialize_dict_in_order
  file_path: env/lib/python3.13/site-packages/vertexai/preview/evaluation/metrics/metric_prompt_template.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: Serializes dictionary to ordered string value without brackets.
  signature: 'def serialize_dict_in_order(elements: typing.Optional[typing.Dict[str, str]]):'
- rank: 2853
  id: vertexai.preview.evaluation.metrics.metric_prompt_template_examples
  name: metric_prompt_template_examples
  file_path: env/lib/python3.13/site-packages/vertexai/preview/evaluation/metrics/metric_prompt_template_examples.py
  type: MODULE
  group: Orphan
  usage_score: 0
  docstring: Example metric prompt templates for model-based evaluation.
- rank: 2854
  id: vertexai.preview.evaluation.metrics.metric_prompt_template_examples.MetricPromptTemplateExamples
  name: MetricPromptTemplateExamples
  file_path: env/lib/python3.13/site-packages/vertexai/preview/evaluation/metrics/metric_prompt_template_examples.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: Examples of metric prompt templates for model-based evaluation.
  methods:
  - signature: 'def get_prompt_template(cls, metric_name: str) -> str:'
    docstring: Returns the prompt template for the given metric name.
  - signature: 'def list_example_metric_names(cls) -> typing.List[str]:'
    docstring: Returns a list of all metric prompt templates.
- rank: 2855
  id: vertexai.preview.evaluation.metrics.metric_prompt_template_examples.Pairwise
  name: Pairwise
  file_path: env/lib/python3.13/site-packages/vertexai/preview/evaluation/metrics/metric_prompt_template_examples.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: Example PairwiseMetric instances.
  properties:
  - signature: 'FLUENCY: vertexai.preview.evaluation.metrics.pairwise_metric.PairwiseMetric'
  - signature: 'COHERENCE: vertexai.preview.evaluation.metrics.pairwise_metric.PairwiseMetric'
  - signature: 'SAFETY: vertexai.preview.evaluation.metrics.pairwise_metric.PairwiseMetric'
  - signature: 'GROUNDEDNESS: vertexai.preview.evaluation.metrics.pairwise_metric.PairwiseMetric'
  - signature: 'INSTRUCTION_FOLLOWING: vertexai.preview.evaluation.metrics.pairwise_metric.PairwiseMetric'
  - signature: 'VERBOSITY: vertexai.preview.evaluation.metrics.pairwise_metric.PairwiseMetric'
  - signature: 'TEXT_QUALITY: vertexai.preview.evaluation.metrics.pairwise_metric.PairwiseMetric'
  - signature: 'SUMMARIZATION_QUALITY: vertexai.preview.evaluation.metrics.pairwise_metric.PairwiseMetric'
  - signature: 'QUESTION_ANSWERING_QUALITY: vertexai.preview.evaluation.metrics.pairwise_metric.PairwiseMetric'
  - signature: 'MULTI_TURN_CHAT_QUALITY: vertexai.preview.evaluation.metrics.pairwise_metric.PairwiseMetric'
  - signature: 'MULTI_TURN_SAFETY: vertexai.preview.evaluation.metrics.pairwise_metric.PairwiseMetric'
- rank: 2856
  id: vertexai.preview.evaluation.metrics.metric_prompt_template_examples.Pointwise
  name: Pointwise
  file_path: env/lib/python3.13/site-packages/vertexai/preview/evaluation/metrics/metric_prompt_template_examples.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: Example PointwiseMetric instances.
  properties:
  - signature: 'FLUENCY: vertexai.preview.evaluation.metrics.pointwise_metric.PointwiseMetric'
  - signature: 'COHERENCE: vertexai.preview.evaluation.metrics.pointwise_metric.PointwiseMetric'
  - signature: 'SAFETY: vertexai.preview.evaluation.metrics.pointwise_metric.PointwiseMetric'
  - signature: 'GROUNDEDNESS: vertexai.preview.evaluation.metrics.pointwise_metric.PointwiseMetric'
  - signature: 'INSTRUCTION_FOLLOWING: vertexai.preview.evaluation.metrics.pointwise_metric.PointwiseMetric'
  - signature: 'VERBOSITY: vertexai.preview.evaluation.metrics.pointwise_metric.PointwiseMetric'
  - signature: 'TEXT_QUALITY: vertexai.preview.evaluation.metrics.pointwise_metric.PointwiseMetric'
  - signature: 'SUMMARIZATION_QUALITY: vertexai.preview.evaluation.metrics.pointwise_metric.PointwiseMetric'
  - signature: 'QUESTION_ANSWERING_QUALITY: vertexai.preview.evaluation.metrics.pointwise_metric.PointwiseMetric'
  - signature: 'MULTI_TURN_CHAT_QUALITY: vertexai.preview.evaluation.metrics.pointwise_metric.PointwiseMetric'
  - signature: 'MULTI_TURN_SAFETY: vertexai.preview.evaluation.metrics.pointwise_metric.PointwiseMetric'
- rank: 2857
  id: vertexai.preview.evaluation.metrics.pairwise_metric
  name: pairwise_metric
  file_path: env/lib/python3.13/site-packages/vertexai/preview/evaluation/metrics/pairwise_metric.py
  type: MODULE
  group: Orphan
  usage_score: 0
  docstring: Model-based Pairwise Metric.
- rank: 2858
  id: vertexai.preview.evaluation.metrics.pairwise_metric.PairwiseMetric
  name: PairwiseMetric
  file_path: env/lib/python3.13/site-packages/vertexai/preview/evaluation/metrics/pairwise_metric.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: "A Model-based Pairwise Metric.\n\nA model-based evaluation metric that compares two generative models' responses\nside-by-side, and allows users to A/B test their generative models to\ndetermine which model is performing better.\n\nFor more details on when to use pairwise metrics, see\n[Evaluation methods and\nmetrics](https://cloud.google.com/vertex-ai/generative-ai/docs/models/determine-eval#pointwise_versus_pairwise).\n\nResult Details:\n\n    * In `EvalResult.summary_metrics`, win rates for both the baseline and\n    candidate model are computed. The win rate is computed as proportion of\n    wins of one model's responses to total attempts as a decimal value\n    between 0 and 1.\n\n    * In `EvalResult.metrics_table`, a pairwise metric produces two\n    evaluation results per dataset row:\n        * `pairwise_choice`: The choice shows whether the candidate model or\n          the baseline model performs better, or if they are equally good.\n        * `explanation`: The\
    \ rationale behind each verdict using\n          chain-of-thought reasoning. The explanation helps users scrutinize\n          the judgment and builds appropriate trust in the decisions.\n\n    See [documentation\n    page](https://cloud.google.com/vertex-ai/generative-ai/docs/models/determine-eval#understand-results)\n    for more details on understanding the metric results.\n\nUsage Examples:\n\n    ```\n    baseline_model = GenerativeModel(\"gemini-1.0-pro\")\n    candidate_model = GenerativeModel(\"gemini-1.5-pro\")\n\n    pairwise_groundedness = PairwiseMetric(\n        metric_prompt_template=MetricPromptTemplateExamples.get_prompt_template(\n            \"pairwise_groundedness\"\n        ),\n        baseline_model=baseline_model,\n    )\n    eval_dataset = pd.DataFrame({\n          \"prompt\"  : [...],\n    })\n    pairwise_task = EvalTask(\n        dataset=eval_dataset,\n        metrics=[pairwise_groundedness],\n        experiment=\"my-pairwise-experiment\",\n    )\n    pairwise_result\
    \ = pairwise_task.evaluate(\n        model=candidate_model,\n        experiment_run_name=\"gemini-pairwise-eval-run\",\n    )\n    ```\n\n[Note: Inherited members from _base._ModelBasedMetric are omitted.]"
  constructor_signature: 'def __init__(self, *, metric: str, metric_prompt_template: typing.Union[vertexai.preview.evaluation.metrics.metric_prompt_template.PairwiseMetricPromptTemplate, str], baseline_model: typing.Optional[typing.Union[vertexai.preview.generative_models.GenerativeModel, typing.Callable[[str], str]]]=None, system_instruction: typing.Optional[str]=None, autorater_config: typing.Optional[google.cloud.aiplatform_v1beta1.types.evaluation_service.AutoraterConfig]=None, custom_output_config: typing.Optional[vertexai.preview.evaluation.metrics.custom_output_config.CustomOutputConfig]=None):'
  methods:
  - signature: 'def baseline_model(self) -> typing.Union[vertexai.preview.generative_models.GenerativeModel, typing.Callable[[str], str]]:'
  omitted_inherited_members_from:
  - _base._ModelBasedMetric
- rank: 2859
  id: vertexai.preview.evaluation.metrics.pairwise_metric.PairwiseMetric.__init__
  name: __init__
  file_path: env/lib/python3.13/site-packages/vertexai/preview/evaluation/metrics/pairwise_metric.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Initializes a pairwise evaluation metric.\n\nArgs:\n  metric: The pairwise evaluation metric name.\n  metric_prompt_template: Pairwise metric prompt template for performing\n    the pairwise model-based evaluation. A freeform string is also accepted.\n  baseline_model: The baseline model for side-by-side comparison. If not\n    specified, `baseline_model_response` column is required in the dataset\n    to perform bring-your-own-response(BYOR) evaluation.\n  system_instruction: The system instruction for the evaluation.\n  autorater_config: The config for judge model.\n  custom_output_config: Config for custom output from the judge model."
  signature: 'def __init__(self, *, metric: str, metric_prompt_template: typing.Union[vertexai.preview.evaluation.metrics.metric_prompt_template.PairwiseMetricPromptTemplate, str], baseline_model: typing.Optional[typing.Union[vertexai.preview.generative_models.GenerativeModel, typing.Callable[[str], str]]]=None, system_instruction: typing.Optional[str]=None, autorater_config: typing.Optional[google.cloud.aiplatform_v1beta1.types.evaluation_service.AutoraterConfig]=None, custom_output_config: typing.Optional[vertexai.preview.evaluation.metrics.custom_output_config.CustomOutputConfig]=None):'
- rank: 2860
  id: vertexai.preview.evaluation.metrics.pairwise_metric.PairwiseMetric.baseline_model
  name: baseline_model
  file_path: env/lib/python3.13/site-packages/vertexai/preview/evaluation/metrics/pairwise_metric.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def baseline_model(self) -> typing.Union[vertexai.preview.generative_models.GenerativeModel, typing.Callable[[str], str]]:'
- rank: 2861
  id: vertexai.preview.evaluation.metrics.pointwise_metric
  name: pointwise_metric
  file_path: env/lib/python3.13/site-packages/vertexai/preview/evaluation/metrics/pointwise_metric.py
  type: MODULE
  group: Orphan
  usage_score: 0
  docstring: Model-based Pointwise Metric.
- rank: 2862
  id: vertexai.preview.evaluation.metrics.pointwise_metric.PointwiseMetric
  name: PointwiseMetric
  file_path: env/lib/python3.13/site-packages/vertexai/preview/evaluation/metrics/pointwise_metric.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: "A Model-based Pointwise Metric.\n\nA model-based evaluation metric that evaluate a single generative model's\nresponse.\n\nFor more details on when to use model-based pointwise metrics, see\n[Evaluation methods and metrics](https://cloud.google.com/vertex-ai/generative-ai/docs/models/determine-eval).\n\nUsage Examples:\n\n    ```\n    candidate_model = GenerativeModel(\"gemini-1.5-pro\")\n    eval_dataset = pd.DataFrame({\n        \"prompt\"  : [...],\n    })\n    fluency_metric = PointwiseMetric(\n        metric=\"fluency\",\n        metric_prompt_template=MetricPromptTemplateExamples.get_prompt_template('fluency'),\n    )\n    pointwise_eval_task = EvalTask(\n        dataset=eval_dataset,\n        metrics=[\n            fluency_metric,\n            MetricPromptTemplateExamples.Pointwise.GROUNDEDNESS,\n        ],\n    )\n    pointwise_result = pointwise_eval_task.evaluate(\n        model=candidate_model,\n    )\n    ```\n\n[Note: Inherited members from _base._ModelBasedMetric\
    \ are omitted.]"
  constructor_signature: 'def __init__(self, *, metric: str, metric_prompt_template: typing.Union[vertexai.preview.evaluation.metrics.metric_prompt_template.PointwiseMetricPromptTemplate, str], system_instruction: typing.Optional[str]=None, autorater_config: typing.Optional[google.cloud.aiplatform_v1beta1.types.evaluation_service.AutoraterConfig]=None, custom_output_config: typing.Optional[vertexai.preview.evaluation.metrics.custom_output_config.CustomOutputConfig]=None):'
  omitted_inherited_members_from:
  - _base._ModelBasedMetric
- rank: 2863
  id: vertexai.preview.evaluation.metrics.pointwise_metric.PointwiseMetric.__init__
  name: __init__
  file_path: env/lib/python3.13/site-packages/vertexai/preview/evaluation/metrics/pointwise_metric.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Initializes a pointwise evaluation metric.\n\nArgs:\n  metric: The pointwise evaluation metric name.\n  metric_prompt_template: Pointwise metric prompt template for performing\n    the model-based evaluation. A freeform string is also accepted.\n  system_instruction: The system instruction for the evaluation.\n  autorater_config: The config for judge model.\n  custom_output_config: Config for custom output from the judge model."
  signature: 'def __init__(self, *, metric: str, metric_prompt_template: typing.Union[vertexai.preview.evaluation.metrics.metric_prompt_template.PointwiseMetricPromptTemplate, str], system_instruction: typing.Optional[str]=None, autorater_config: typing.Optional[google.cloud.aiplatform_v1beta1.types.evaluation_service.AutoraterConfig]=None, custom_output_config: typing.Optional[vertexai.preview.evaluation.metrics.custom_output_config.CustomOutputConfig]=None):'
- rank: 2864
  id: vertexai.preview.evaluation.metrics.predefined_rubric_metrics
  name: predefined_rubric_metrics
  file_path: env/lib/python3.13/site-packages/vertexai/preview/evaluation/metrics/predefined_rubric_metrics.py
  type: MODULE
  group: Orphan
  usage_score: 0
- rank: 2865
  id: vertexai.preview.evaluation.metrics.predefined_rubric_metrics.Pairwise
  name: Pairwise
  file_path: env/lib/python3.13/site-packages/vertexai/preview/evaluation/metrics/predefined_rubric_metrics.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: Pairwise rubric-based metrics.
  properties:
  - signature: 'INSTRUCTION_FOLLOWING: vertexai.preview.evaluation.metrics.rubric_based_metric.RubricBasedMetric'
  - signature: 'MULTIMODAL_UNDERSTANDING: vertexai.preview.evaluation.metrics.rubric_based_metric.RubricBasedMetric'
  - signature: 'TEXT_QUALITY: vertexai.preview.evaluation.metrics.rubric_based_metric.RubricBasedMetric'
- rank: 2866
  id: vertexai.preview.evaluation.metrics.predefined_rubric_metrics.Pointwise
  name: Pointwise
  file_path: env/lib/python3.13/site-packages/vertexai/preview/evaluation/metrics/predefined_rubric_metrics.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: Pointwise rubric-based metrics.
  properties:
  - signature: 'INSTRUCTION_FOLLOWING: vertexai.preview.evaluation.metrics.rubric_based_metric.RubricBasedMetric'
  - signature: 'MULTIMODAL_UNDERSTANDING: vertexai.preview.evaluation.metrics.rubric_based_metric.RubricBasedMetric'
  - signature: 'TEXT_QUALITY: vertexai.preview.evaluation.metrics.rubric_based_metric.RubricBasedMetric'
- rank: 2867
  id: vertexai.preview.evaluation.metrics.predefined_rubric_metrics.PredefinedRubricMetrics
  name: PredefinedRubricMetrics
  file_path: env/lib/python3.13/site-packages/vertexai/preview/evaluation/metrics/predefined_rubric_metrics.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: Predefined rubric-based metrics.
- rank: 2868
  id: vertexai.preview.evaluation.metrics.rubric_based_metric
  name: rubric_based_metric
  file_path: env/lib/python3.13/site-packages/vertexai/preview/evaluation/metrics/rubric_based_metric.py
  type: MODULE
  group: Orphan
  usage_score: 0
- rank: 2869
  id: vertexai.preview.evaluation.metrics.rubric_based_metric.RubricBasedMetric
  name: RubricBasedMetric
  file_path: env/lib/python3.13/site-packages/vertexai/preview/evaluation/metrics/rubric_based_metric.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Config for Rubric-Based Eval.


    [Note: Inherited members from metrics_base._Metric are omitted.]'
  constructor_signature: 'def __init__(self, *, generation_config: vertexai.preview.evaluation.metrics._base.RubricGenerationConfig, critique_metric: typing.Union[vertexai.preview.evaluation.metrics.pointwise_metric.PointwiseMetric, vertexai.preview.evaluation.metrics.pairwise_metric.PairwiseMetric]):'
  methods:
  - signature: 'def generate_rubrics(self, eval_dataset: pandas.Dataframe) -> pandas.DataFrame:'
    docstring: Generates rubrics for given eval dataset.
  omitted_inherited_members_from:
  - metrics_base._Metric
- rank: 2870
  id: vertexai.preview.evaluation.metrics.rubric_based_metric.RubricBasedMetric.__init__
  name: __init__
  file_path: env/lib/python3.13/site-packages/vertexai/preview/evaluation/metrics/rubric_based_metric.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Initializes RubricBasedMetric.\n\nArgs:\n  generation_config: Config for rubric generation.\n  critique_metric: Pointwise/pairwise metric for rubric critique."
  signature: 'def __init__(self, *, generation_config: vertexai.preview.evaluation.metrics._base.RubricGenerationConfig, critique_metric: typing.Union[vertexai.preview.evaluation.metrics.pointwise_metric.PointwiseMetric, vertexai.preview.evaluation.metrics.pairwise_metric.PairwiseMetric]):'
- rank: 2871
  id: vertexai.preview.evaluation.metrics.rubric_based_metric.RubricBasedMetric.generate_rubrics
  name: generate_rubrics
  file_path: env/lib/python3.13/site-packages/vertexai/preview/evaluation/metrics/rubric_based_metric.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: Generates rubrics for given eval dataset.
  signature: 'def generate_rubrics(self, eval_dataset: pandas.Dataframe) -> pandas.DataFrame:'
- rank: 2872
  id: vertexai.preview.evaluation.multimodal_utils
  name: multimodal_utils
  file_path: env/lib/python3.13/site-packages/vertexai/preview/evaluation/multimodal_utils.py
  type: MODULE
  group: Orphan
  usage_score: 0
  docstring: Utility functions for multimodal evaluation.
  methods:
  - signature: 'def is_multimodal_instance(model_based_metric_instance_input: typing.Dict[str, str]) -> bool:'
    docstring: Checks if the evaluation instance contains multimodal input.
  - signature: 'def convert_multimodal_response_to_content_map(model_based_metric_instance_input: typing.Dict[str, str]) -> vertexai.preview.evaluation.multimodal_utils.ContentMap:'
    docstring: Converts a multimodal model response to a ContentMap.
- rank: 2873
  id: vertexai.preview.evaluation.multimodal_utils.convert_multimodal_response_to_content_map
  name: convert_multimodal_response_to_content_map
  file_path: env/lib/python3.13/site-packages/vertexai/preview/evaluation/multimodal_utils.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: Converts a multimodal model response to a ContentMap.
  signature: 'def convert_multimodal_response_to_content_map(model_based_metric_instance_input: typing.Dict[str, str]) -> vertexai.preview.evaluation.multimodal_utils.ContentMap:'
- rank: 2874
  id: vertexai.preview.evaluation.multimodal_utils.is_multimodal_instance
  name: is_multimodal_instance
  file_path: env/lib/python3.13/site-packages/vertexai/preview/evaluation/multimodal_utils.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: Checks if the evaluation instance contains multimodal input.
  signature: 'def is_multimodal_instance(model_based_metric_instance_input: typing.Dict[str, str]) -> bool:'
- rank: 2875
  id: vertexai.preview.evaluation.notebook_utils
  name: notebook_utils
  file_path: env/lib/python3.13/site-packages/vertexai/preview/evaluation/notebook_utils.py
  type: MODULE
  group: Orphan
  usage_score: 0
  docstring: Python functions which run only within a Jupyter or Colab notebook.
  methods:
  - signature: 'def is_ipython_available() -> bool:'
  - signature: 'def display_eval_result(eval_result: vertexai.preview.evaluation._base.EvalResult, title: typing.Optional[str], metrics: typing.Optional[typing.List[str]]) -> None:'
    docstring: "Displays evaluation results in a notebook using IPython.display.\n\nArgs:\n    eval_result: An object containing evaluation results with\n      `summary_metrics` and `metrics_table` attributes.\n    title: A string title to display above the results.\n    metrics: A list of metric name substrings to filter displayed columns. If\n      provided, only metrics whose names contain any of these strings will be\n      displayed."
  - signature: 'def display_explanations(eval_result: vertexai.preview.evaluation._base.EvalResult, num: int, metrics: typing.Optional[typing.List[str]]) -> None:'
    docstring: "Displays the explanations in a notebook using IPython.display.\n\nArgs:\n    eval_result: An object containing evaluation results. It is expected to\n      have attributes `summary_metrics` and `metrics_table`.\n    num: The number of row samples to display. Defaults to 1. If the number of\n      rows is less than `num`, all rows will be displayed.\n    metrics: A list of metric name substrings to filter displayed columns. If\n      provided, only metrics whose names contain any of these strings will be\n      displayed."
  - signature: 'def display_radar_plot(eval_results_with_title: typing.List[typing.Tuple[str, vertexai.preview.evaluation._base.EvalResult]], metrics: typing.List[str], radar_range: typing.Tuple[float, float]) -> None:'
    docstring: "Plots a radar plot comparing evaluation results.\n\nArgs:\n    eval_results_with_title: List of (title, eval_result) tuples.\n    metrics: A list of metrics whose mean values will be plotted.\n    radar_range: Range of the radar plot axes."
  - signature: 'def display_bar_plot(eval_results_with_title: typing.List[typing.Tuple[str, vertexai.preview.evaluation._base.EvalResult]], metrics: typing.List[str]) -> None:'
    docstring: "Plots a bar plot comparing evaluation results.\n\nArgs:\n    eval_results_with_title: List of (title, eval_result) tuples.\n    metrics: A list of metrics whose mean values will be plotted."
  - signature: 'def generate_uuid(length: int) -> str:'
    docstring: Generates a uuid of a specified length (default=8).
- rank: 2876
  id: vertexai.preview.evaluation.notebook_utils.display_bar_plot
  name: display_bar_plot
  file_path: env/lib/python3.13/site-packages/vertexai/preview/evaluation/notebook_utils.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Plots a bar plot comparing evaluation results.\n\nArgs:\n    eval_results_with_title: List of (title, eval_result) tuples.\n    metrics: A list of metrics whose mean values will be plotted."
  signature: 'def display_bar_plot(eval_results_with_title: typing.List[typing.Tuple[str, vertexai.preview.evaluation._base.EvalResult]], metrics: typing.List[str]) -> None:'
- rank: 2877
  id: vertexai.preview.evaluation.notebook_utils.display_eval_result
  name: display_eval_result
  file_path: env/lib/python3.13/site-packages/vertexai/preview/evaluation/notebook_utils.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Displays evaluation results in a notebook using IPython.display.\n\nArgs:\n    eval_result: An object containing evaluation results with\n      `summary_metrics` and `metrics_table` attributes.\n    title: A string title to display above the results.\n    metrics: A list of metric name substrings to filter displayed columns. If\n      provided, only metrics whose names contain any of these strings will be\n      displayed."
  signature: 'def display_eval_result(eval_result: vertexai.preview.evaluation._base.EvalResult, title: typing.Optional[str], metrics: typing.Optional[typing.List[str]]) -> None:'
- rank: 2878
  id: vertexai.preview.evaluation.notebook_utils.display_explanations
  name: display_explanations
  file_path: env/lib/python3.13/site-packages/vertexai/preview/evaluation/notebook_utils.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Displays the explanations in a notebook using IPython.display.\n\nArgs:\n    eval_result: An object containing evaluation results. It is expected to\n      have attributes `summary_metrics` and `metrics_table`.\n    num: The number of row samples to display. Defaults to 1. If the number of\n      rows is less than `num`, all rows will be displayed.\n    metrics: A list of metric name substrings to filter displayed columns. If\n      provided, only metrics whose names contain any of these strings will be\n      displayed."
  signature: 'def display_explanations(eval_result: vertexai.preview.evaluation._base.EvalResult, num: int, metrics: typing.Optional[typing.List[str]]) -> None:'
- rank: 2879
  id: vertexai.preview.evaluation.notebook_utils.display_radar_plot
  name: display_radar_plot
  file_path: env/lib/python3.13/site-packages/vertexai/preview/evaluation/notebook_utils.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Plots a radar plot comparing evaluation results.\n\nArgs:\n    eval_results_with_title: List of (title, eval_result) tuples.\n    metrics: A list of metrics whose mean values will be plotted.\n    radar_range: Range of the radar plot axes."
  signature: 'def display_radar_plot(eval_results_with_title: typing.List[typing.Tuple[str, vertexai.preview.evaluation._base.EvalResult]], metrics: typing.List[str], radar_range: typing.Tuple[float, float]) -> None:'
- rank: 2880
  id: vertexai.preview.evaluation.prompt_template
  name: prompt_template
  file_path: env/lib/python3.13/site-packages/vertexai/preview/evaluation/prompt_template.py
  type: MODULE
  group: Orphan
  usage_score: 0
  docstring: Prompt template for creating prompts with variables.
- rank: 2881
  id: vertexai.preview.evaluation.prompt_template.PromptTemplate
  name: PromptTemplate
  file_path: env/lib/python3.13/site-packages/vertexai/preview/evaluation/prompt_template.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: "A prompt template for creating prompts with variables.\n\nThe `PromptTemplate` class allows users to define a template string with\nvariables represented in curly braces `{variable}`. The variable\nnames cannot contain spaces and must start with a letter or underscore,\nfollowed by letters, digits, or underscore. These variables can be\nreplaced with specific values using the `assemble` method, providing\nflexibility in generating dynamic prompts.\n\nUsage:\n\n    ```\n    template_str = \"Hello, {name}! Today is {day}. How are you?\"\n    prompt_template = PromptTemplate(template_str)\n    completed_prompt = prompt_template.assemble(name=\"John\", day=\"Monday\")\n    print(completed_prompt)\n    ```"
  constructor_signature: 'def __init__(self, template: str):'
  methods:
  - signature: 'def assemble(self) -> vertexai.preview.evaluation.prompt_template.PromptTemplate:'
    docstring: "Replaces only the provided variables in the template with specific values.\n\nArgs:\n    **kwargs: Keyword arguments where keys are placeholder names and values\n      are the replacements.\n\nReturns:\n    A new PromptTemplate instance with the updated template string."
- rank: 2882
  id: vertexai.preview.evaluation.prompt_template.PromptTemplate.__init__
  name: __init__
  file_path: env/lib/python3.13/site-packages/vertexai/preview/evaluation/prompt_template.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Initializes the PromptTemplate with a given template.\n\nArgs:\n    template: The template string with variables. Variables should be\n      represented in curly braces `{variable}`."
  signature: 'def __init__(self, template: str):'
- rank: 2883
  id: vertexai.preview.evaluation.prompt_template.PromptTemplate.assemble
  name: assemble
  file_path: env/lib/python3.13/site-packages/vertexai/preview/evaluation/prompt_template.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Replaces only the provided variables in the template with specific values.\n\nArgs:\n    **kwargs: Keyword arguments where keys are placeholder names and values\n      are the replacements.\n\nReturns:\n    A new PromptTemplate instance with the updated template string."
  signature: 'def assemble(self) -> vertexai.preview.evaluation.prompt_template.PromptTemplate:'
- rank: 2884
  id: vertexai.preview.evaluation.utils
  name: utils
  file_path: env/lib/python3.13/site-packages/vertexai/preview/evaluation/utils.py
  type: MODULE
  group: Orphan
  usage_score: 0
  docstring: Utility functions for evaluation.
  methods:
  - signature: 'def rate_limit(rate: typing.Optional[float]) -> typing.Callable[[Any], typing.Any]:'
    docstring: Decorator version of rate limiter.
  - signature: 'def wrapper():'
  - signature: 'def create_evaluation_service_client(api_base_path_override: typing.Optional[str]) -> vertexai.preview.evaluation.utils._EvaluationServiceClientWithOverride:'
    docstring: "Creates a client for the evaluation service.\n\nArgs:\n  api_base_path_override: Optional. Override default api base path.\n\nReturns:\n  Instantiated Vertex AI EvaluationServiceClient with optional\n  overrides."
  - signature: 'def load_dataset(source: typing.Union[str, pandas.DataFrame, typing.Dict[str, typing.Any]]) -> pandas.DataFrame:'
    docstring: "Loads dataset from various sources into a DataFrame.\n\nArgs:\n    source: The dataset source. Supports the following dataset formats:\n    * pandas.DataFrame: Used directly for evaluation.\n    * Dict: Converted to a pandas DataFrame before evaluation.\n    * str: Interpreted as a file path or URI. Supported formats include:\n        * Local JSONL or CSV files:  Loaded from the local filesystem.\n        * GCS JSONL or CSV files: Loaded from Google Cloud Storage (e.g.,\n        'gs://bucket/data.csv').\n        * BigQuery table URI: Loaded from Google Cloud\n        BigQuery (e.g., 'bq://project-id.dataset.table_name').\n\nReturns:\n    The dataset in pandas DataFrame format."
  - signature: 'def upload_evaluation_results(eval_result: vertexai.evaluation._base.EvalResult, destination_uri_prefix: str, file_name: typing.Optional[str], candidate_model_name: typing.Optional[str], baseline_model_name: typing.Optional[str], dataset_uri: typing.Optional[str], metrics: typing.Optional[typing.List[typing.Union[str, vertexai.evaluation.metrics._base._Metric]]]) -> None:'
    docstring: "Uploads eval results to GCS destination.\n\nArgs:\n    eval_result: Eval results to upload.\n    destination_uri_prefix: GCS folder to store the data.\n    file_name: Optional. File name to store the metrics table.\n    candidate_model_name: Optional. Candidate model name.\n    baseline_model_name: Optional. Baseline model name.\n    dataset_uri: Optional. URI pointing to the dataset.\n    metrics: Optional. List of metrics used for evaluation."
  - signature: 'def initialize_metric_column_mapping(metric_column_mapping: typing.Optional[typing.Dict[str, str]], dataset: pandas.DataFrame):'
    docstring: Initializes metric column mapping with dataset columns.
  - signature: 'def parse_intermediate_steps(intermediate_steps: typing.List[typing.Dict[str, typing.Any]]):'
    docstring: Parses intermediate steps from the response to create trajectory.
  - signature: 'def parse_rubrics(rubric_generation_response: str) -> typing.Dict[str, typing.Any]:'
    docstring: Parses the rubric generation responses.
  - signature: 'def parse_pairwise_rubric_verdict_pairs(prediction: str, regex: typing.Pattern[str]) -> str:'
    docstring: Parses the pairwise rubric critique responses.
  - signature: 'def parse_pairwise_rubric_result(predictions: typing.List[str]) -> typing.Dict[str, typing.Any]:'
    docstring: Parses the pairwise rubric critique responses.
  - signature: 'def parse_verdict(txt: str):'
    docstring: Parses the verdict from the rubric critique response.
  - signature: 'def parse_question(txt: str):'
    docstring: Parses the question from the rubric critique response.
  - signature: 'def parse_question_blocks(txt: str) -> typing.List[typing.Tuple[str, bool]]:'
    docstring: Parses the question blocks from the rubric critique response.
  - signature: 'def parse_pointwise_rubric_result(results: typing.List[str]) -> typing.Dict[str, typing.Any]:'
    docstring: Parses the pointwise rubric critique responses.
- rank: 2885
  id: vertexai.preview.evaluation.utils.RateLimiter
  name: RateLimiter
  file_path: env/lib/python3.13/site-packages/vertexai/preview/evaluation/utils.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: "Helper class for rate-limiting requests to Vertex AI to improve QoS.\n\nAttributes:\n    seconds_per_event: The time interval (in seconds) between events to\n      maintain the desired rate.\n    last: The timestamp of the last event.\n    _lock: A lock to ensure thread safety."
  constructor_signature: 'def __init__(self, rate: typing.Optional[float]):'
  methods:
  - signature: 'def sleep_and_advance(self):'
    docstring: Blocks the current thread until the next event can be admitted.
- rank: 2886
  id: vertexai.preview.evaluation.utils.RateLimiter.__init__
  name: __init__
  file_path: env/lib/python3.13/site-packages/vertexai/preview/evaluation/utils.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Initializes the rate limiter.\n\nA simple rate limiter for controlling the frequency of API calls. This class\nimplements a token bucket algorithm to limit the rate at which events\ncan occur. It's designed for cases where the batch size (number of events\nper call) is always 1 for traffic shaping and rate limiting.\n\nArgs:\n    rate: The number of queries allowed per second.\n\nRaises:\n    ValueError: If the rate is not positive."
  signature: 'def __init__(self, rate: typing.Optional[float]):'
- rank: 2887
  id: vertexai.preview.evaluation.utils.RateLimiter.sleep_and_advance
  name: sleep_and_advance
  file_path: env/lib/python3.13/site-packages/vertexai/preview/evaluation/utils.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: Blocks the current thread until the next event can be admitted.
  signature: 'def sleep_and_advance(self):'
- rank: 2888
  id: vertexai.preview.evaluation.utils.create_evaluation_service_client
  name: create_evaluation_service_client
  file_path: env/lib/python3.13/site-packages/vertexai/preview/evaluation/utils.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Creates a client for the evaluation service.\n\nArgs:\n  api_base_path_override: Optional. Override default api base path.\n\nReturns:\n  Instantiated Vertex AI EvaluationServiceClient with optional\n  overrides."
  signature: 'def create_evaluation_service_client(api_base_path_override: typing.Optional[str]) -> vertexai.preview.evaluation.utils._EvaluationServiceClientWithOverride:'
- rank: 2889
  id: vertexai.preview.evaluation.utils.initialize_metric_column_mapping
  name: initialize_metric_column_mapping
  file_path: env/lib/python3.13/site-packages/vertexai/preview/evaluation/utils.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: Initializes metric column mapping with dataset columns.
  signature: 'def initialize_metric_column_mapping(metric_column_mapping: typing.Optional[typing.Dict[str, str]], dataset: pandas.DataFrame):'
- rank: 2890
  id: vertexai.preview.evaluation.utils.load_dataset
  name: load_dataset
  file_path: env/lib/python3.13/site-packages/vertexai/preview/evaluation/utils.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Loads dataset from various sources into a DataFrame.\n\nArgs:\n    source: The dataset source. Supports the following dataset formats:\n    * pandas.DataFrame: Used directly for evaluation.\n    * Dict: Converted to a pandas DataFrame before evaluation.\n    * str: Interpreted as a file path or URI. Supported formats include:\n        * Local JSONL or CSV files:  Loaded from the local filesystem.\n        * GCS JSONL or CSV files: Loaded from Google Cloud Storage (e.g.,\n        'gs://bucket/data.csv').\n        * BigQuery table URI: Loaded from Google Cloud\n        BigQuery (e.g., 'bq://project-id.dataset.table_name').\n\nReturns:\n    The dataset in pandas DataFrame format."
  signature: 'def load_dataset(source: typing.Union[str, pandas.DataFrame, typing.Dict[str, typing.Any]]) -> pandas.DataFrame:'
- rank: 2891
  id: vertexai.preview.evaluation.utils.parse_intermediate_steps
  name: parse_intermediate_steps
  file_path: env/lib/python3.13/site-packages/vertexai/preview/evaluation/utils.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: Parses intermediate steps from the response to create trajectory.
  signature: 'def parse_intermediate_steps(intermediate_steps: typing.List[typing.Dict[str, typing.Any]]):'
- rank: 2892
  id: vertexai.preview.evaluation.utils.parse_pairwise_rubric_result
  name: parse_pairwise_rubric_result
  file_path: env/lib/python3.13/site-packages/vertexai/preview/evaluation/utils.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: Parses the pairwise rubric critique responses.
  signature: 'def parse_pairwise_rubric_result(predictions: typing.List[str]) -> typing.Dict[str, typing.Any]:'
- rank: 2893
  id: vertexai.preview.evaluation.utils.parse_pairwise_rubric_verdict_pairs
  name: parse_pairwise_rubric_verdict_pairs
  file_path: env/lib/python3.13/site-packages/vertexai/preview/evaluation/utils.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: Parses the pairwise rubric critique responses.
  signature: 'def parse_pairwise_rubric_verdict_pairs(prediction: str, regex: typing.Pattern[str]) -> str:'
- rank: 2894
  id: vertexai.preview.evaluation.utils.parse_pointwise_rubric_result
  name: parse_pointwise_rubric_result
  file_path: env/lib/python3.13/site-packages/vertexai/preview/evaluation/utils.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: Parses the pointwise rubric critique responses.
  signature: 'def parse_pointwise_rubric_result(results: typing.List[str]) -> typing.Dict[str, typing.Any]:'
- rank: 2895
  id: vertexai.preview.evaluation.utils.parse_question
  name: parse_question
  file_path: env/lib/python3.13/site-packages/vertexai/preview/evaluation/utils.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: Parses the question from the rubric critique response.
  signature: 'def parse_question(txt: str):'
- rank: 2896
  id: vertexai.preview.evaluation.utils.parse_question_blocks
  name: parse_question_blocks
  file_path: env/lib/python3.13/site-packages/vertexai/preview/evaluation/utils.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: Parses the question blocks from the rubric critique response.
  signature: 'def parse_question_blocks(txt: str) -> typing.List[typing.Tuple[str, bool]]:'
- rank: 2897
  id: vertexai.preview.evaluation.utils.parse_rubrics
  name: parse_rubrics
  file_path: env/lib/python3.13/site-packages/vertexai/preview/evaluation/utils.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: Parses the rubric generation responses.
  signature: 'def parse_rubrics(rubric_generation_response: str) -> typing.Dict[str, typing.Any]:'
- rank: 2898
  id: vertexai.preview.evaluation.utils.parse_verdict
  name: parse_verdict
  file_path: env/lib/python3.13/site-packages/vertexai/preview/evaluation/utils.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: Parses the verdict from the rubric critique response.
  signature: 'def parse_verdict(txt: str):'
- rank: 2899
  id: vertexai.preview.evaluation.utils.rate_limit
  name: rate_limit
  file_path: env/lib/python3.13/site-packages/vertexai/preview/evaluation/utils.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: Decorator version of rate limiter.
  signature: 'def rate_limit(rate: typing.Optional[float]) -> typing.Callable[[Any], typing.Any]:'
- rank: 2900
  id: vertexai.preview.evaluation.utils.upload_evaluation_results
  name: upload_evaluation_results
  file_path: env/lib/python3.13/site-packages/vertexai/preview/evaluation/utils.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Uploads eval results to GCS destination.\n\nArgs:\n    eval_result: Eval results to upload.\n    destination_uri_prefix: GCS folder to store the data.\n    file_name: Optional. File name to store the metrics table.\n    candidate_model_name: Optional. Candidate model name.\n    baseline_model_name: Optional. Baseline model name.\n    dataset_uri: Optional. URI pointing to the dataset.\n    metrics: Optional. List of metrics used for evaluation."
  signature: 'def upload_evaluation_results(eval_result: vertexai.evaluation._base.EvalResult, destination_uri_prefix: str, file_name: typing.Optional[str], candidate_model_name: typing.Optional[str], baseline_model_name: typing.Optional[str], dataset_uri: typing.Optional[str], metrics: typing.Optional[typing.List[typing.Union[str, vertexai.evaluation.metrics._base._Metric]]]) -> None:'
- rank: 2901
  id: vertexai.preview.example_stores
  name: example_stores
  file_path: env/lib/python3.13/site-packages/vertexai/preview/example_stores.py
  type: MODULE
  group: Orphan
  usage_score: 0
  docstring: Classes for working with example stores.
- rank: 2902
  id: vertexai.preview.extensions
  name: extensions
  file_path: env/lib/python3.13/site-packages/vertexai/preview/extensions.py
  type: MODULE
  group: Orphan
  usage_score: 0
  docstring: Classes for working with extensions.
- rank: 2903
  id: vertexai.preview.generative_models
  name: generative_models
  file_path: env/lib/python3.13/site-packages/vertexai/preview/generative_models.py
  type: MODULE
  group: Orphan
  usage_score: 0
  docstring: Classes for working with the Gemini models.
- rank: 2904
  id: vertexai.preview.generative_models.ChatSession
  name: ChatSession
  file_path: env/lib/python3.13/site-packages/vertexai/preview/generative_models.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: '[Note: Inherited members from _PreviewChatSession are omitted.]'
  omitted_inherited_members_from:
  - _PreviewChatSession
- rank: 2905
  id: vertexai.preview.generative_models.GenerativeModel
  name: GenerativeModel
  file_path: env/lib/python3.13/site-packages/vertexai/preview/generative_models.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: '[Note: Inherited members from _PreviewGenerativeModel are omitted.]'
  omitted_inherited_members_from:
  - _PreviewGenerativeModel
- rank: 2906
  id: vertexai.preview.language_models
  name: language_models
  file_path: env/lib/python3.13/site-packages/vertexai/preview/language_models.py
  type: MODULE
  group: Orphan
  usage_score: 0
  docstring: Classes for working with language models.
- rank: 2907
  id: vertexai.preview.model_garden
  name: model_garden
  file_path: env/lib/python3.13/site-packages/vertexai/preview/model_garden.py
  type: MODULE
  group: Orphan
  usage_score: 0
  docstring: Classes and functions for working with Model Garden.
- rank: 2908
  id: vertexai.preview.prompts
  name: prompts
  file_path: env/lib/python3.13/site-packages/vertexai/preview/prompts.py
  type: MODULE
  group: Orphan
  usage_score: 0
- rank: 2909
  id: vertexai.preview.rag
  name: rag
  file_path: env/lib/python3.13/site-packages/vertexai/preview/rag/__init__.py
  type: MODULE
  group: Orphan
  usage_score: 0
- rank: 2910
  id: vertexai.preview.rag.rag_data
  name: rag_data
  file_path: env/lib/python3.13/site-packages/vertexai/preview/rag/rag_data.py
  type: MODULE
  group: Orphan
  usage_score: 0
  docstring: RAG data management SDK.
  methods:
  - signature: 'def create_corpus(display_name: typing.Optional[str], description: typing.Optional[str], corpus_type_config: typing.Optional[vertexai.preview.rag.utils.resources.RagCorpusTypeConfig], embedding_model_config: typing.Optional[vertexai.preview.rag.utils.resources.EmbeddingModelConfig], vector_db: typing.Optional[typing.Union[vertexai.preview.rag.utils.resources.Weaviate, vertexai.preview.rag.utils.resources.VertexFeatureStore, vertexai.preview.rag.utils.resources.VertexVectorSearch, vertexai.preview.rag.utils.resources.Pinecone, vertexai.preview.rag.utils.resources.RagManagedDb]], vertex_ai_search_config: typing.Optional[vertexai.preview.rag.utils.resources.VertexAiSearchConfig], backend_config: typing.Optional[vertexai.preview.rag.utils.resources.RagVectorDbConfig], encryption_spec: typing.Optional[google.cloud.aiplatform_v1beta1.types.EncryptionSpec], timeout: int) -> vertexai.preview.rag.utils.resources.RagCorpus:'
    docstring: "Creates a new RagCorpus resource.\n\nExample usage:\n```\nimport vertexai\nfrom vertexai.preview import rag\n\nvertexai.init(project=\"my-project\")\n\nrag_corpus = rag.create_corpus(\n    display_name=\"my-corpus-1\",\n)\n```\n\nArgs:\n    display_name: If not provided, SDK will create one. The display name of\n      the RagCorpus. The name can be up to 128 characters long and can consist\n      of any UTF-8 characters.\n    description: The description of the RagCorpus.\n    corpus_type_config: The corpus type config of the RagCorpus.\n    embedding_model_config: The embedding model config.\n        Note: Deprecated. Use backend_config instead.\n    vector_db: The vector db config of the RagCorpus. If unspecified, the\n      default database Spanner is used.\n        Note: Deprecated. Use backend_config instead.\n    vertex_ai_search_config: The Vertex AI Search config of the RagCorpus.\n        Note: embedding_model_config or vector_db cannot be set if\n          vertex_ai_search_config\
      \ is specified.\n    backend_config: The backend config of the RagCorpus. It can specify a\n      Vector DB and/or the embedding model config.\n    encryption_spec: The encryption spec of the RagCorpus.\n    timeout: Default is 600 seconds.\n\nReturns:\n    RagCorpus.\nRaises:\n    RuntimeError: Failed in RagCorpus creation due to exception.\n    RuntimeError: Failed in RagCorpus creation due to operation error."
  - signature: 'def update_corpus(corpus_name: str, display_name: typing.Optional[str], description: typing.Optional[str], vector_db: typing.Optional[typing.Union[vertexai.preview.rag.utils.resources.Weaviate, vertexai.preview.rag.utils.resources.VertexFeatureStore, vertexai.preview.rag.utils.resources.VertexVectorSearch, vertexai.preview.rag.utils.resources.Pinecone, vertexai.preview.rag.utils.resources.RagManagedDb]], vertex_ai_search_config: typing.Optional[vertexai.preview.rag.utils.resources.VertexAiSearchConfig], backend_config: typing.Optional[vertexai.preview.rag.utils.resources.RagVectorDbConfig], timeout: int) -> vertexai.preview.rag.utils.resources.RagCorpus:'
    docstring: "Updates a RagCorpus resource.\n\nExample usage:\n```\nimport vertexai\nfrom vertexai.preview import rag\n\nvertexai.init(project=\"my-project\")\n\nrag_corpus = rag.update_corpus(\n    corpus_name=\"projects/my-project/locations/us-central1/ragCorpora/my-corpus-1\",\n    display_name=\"my-corpus-1\",\n)\n```\n\nArgs:\n    corpus_name: The name of the RagCorpus resource to update. Format:\n      ``projects/{project}/locations/{location}/ragCorpora/{rag_corpus}`` or\n      ``{rag_corpus}``.\n    display_name: If not provided, the display name will not be updated. The\n      display name of the RagCorpus. The name can be up to 128 characters long\n      and can consist of any UTF-8 characters.\n    description: The description of the RagCorpus. If not provided, the\n      description will not be updated.\n    vector_db: The vector db config of the RagCorpus. If not provided, the\n      vector db will not be updated.\n    vertex_ai_search_config: The Vertex AI Search config of\
      \ the RagCorpus. If\n      not provided, the Vertex AI Search config will not be updated.\n      Note: embedding_model_config or vector_db cannot be set if\n        vertex_ai_search_config is specified.\n    backend_config: The backend config of the RagCorpus. Specifies a Vector DB\n      and/or the embedding model config.\n    timeout: Default is 600 seconds.\n\nReturns:\n    RagCorpus.\nRaises:\n    RuntimeError: Failed in RagCorpus update due to exception.\n    RuntimeError: Failed in RagCorpus update due to operation error."
  - signature: 'def get_corpus(name: str) -> vertexai.preview.rag.utils.resources.RagCorpus:'
    docstring: "Get an existing RagCorpus.\n\nArgs:\n    name: An existing RagCorpus resource name. Format:\n        ``projects/{project}/locations/{location}/ragCorpora/{rag_corpus}``\n        or ``{rag_corpus}``.\nReturns:\n    RagCorpus."
  - signature: 'def list_corpora(page_size: typing.Optional[int], page_token: typing.Optional[str]) -> google.cloud.aiplatform_v1beta1.services.vertex_rag_data_service.pagers.ListRagCorporaPager:'
    docstring: "List all RagCorpora in the same project and location.\n\nExample usage:\n```\nimport vertexai\nfrom vertexai.preview import rag\n\nvertexai.init(project=\"my-project\")\n\n# List all corpora.\nrag_corpora = list(rag.list_corpora())\n\n# Alternatively, return a ListRagCorporaPager.\npager_1 = rag.list_corpora(page_size=10)\n# Then get the next page, use the generated next_page_token from the last pager.\npager_2 = rag.list_corpora(page_size=10, page_token=pager_1.next_page_token)\n\n```\nArgs:\n    page_size: The standard list page size. Leaving out the page_size\n        causes all of the results to be returned.\n    page_token: The standard list page token.\n\nReturns:\n    ListRagCorporaPager."
  - signature: 'def delete_corpus(name: str) -> None:'
    docstring: "Delete an existing RagCorpus.\n\nArgs:\n    name: An existing RagCorpus resource name. Format:\n        ``projects/{project}/locations/{location}/ragCorpora/{rag_corpus}``\n        or ``{rag_corpus}``."
  - signature: 'def upload_file(corpus_name: str, path: typing.Union[str, typing.Sequence[str]], display_name: typing.Optional[str], description: typing.Optional[str], transformation_config: typing.Optional[vertexai.preview.rag.utils.resources.TransformationConfig]) -> vertexai.preview.rag.utils.resources.RagFile:'
    docstring: "Synchronous file upload to an existing RagCorpus.\n\nExample usage:\n\n```\nimport vertexai\nfrom vertexai.preview import rag\n\nvertexai.init(project=\"my-project\")\n\n# Optional.\ntransformation_config = TransformationConfig(\n    chunking_config=ChunkingConfig(\n        chunk_size=1024,\n        chunk_overlap=200,\n    ),\n)\n\nrag_file = rag.upload_file(\n    corpus_name=\"projects/my-project/locations/us-central1/ragCorpora/my-corpus-1\",\n    display_name=\"my_file.txt\",\n    path=\"usr/home/my_file.txt\",\n    transformation_config=transformation_config,\n)\n```\n\nArgs:\n    corpus_name: The name of the RagCorpus resource into which to upload the file.\n        Format: ``projects/{project}/locations/{location}/ragCorpora/{rag_corpus}``\n        or ``{rag_corpus}``.\n    path: A local file path. For example,\n        \"usr/home/my_file.txt\".\n    display_name: The display name of the data file.\n    description: The description of the RagFile.\n    transformation_config:\
      \ The config for transforming the RagFile, such as chunking.\nReturns:\n    RagFile.\nRaises:\n    RuntimeError: Failed in RagFile upload.\n    ValueError: RagCorpus is not found.\n    RuntimeError: Failed in indexing the RagFile."
  - signature: 'def import_files(corpus_name: str, paths: typing.Optional[typing.Sequence[str]], source: typing.Optional[typing.Union[vertexai.preview.rag.utils.resources.SlackChannelsSource, vertexai.preview.rag.utils.resources.JiraSource, vertexai.preview.rag.utils.resources.SharePointSources]], chunk_size: int, chunk_overlap: int, transformation_config: typing.Optional[vertexai.preview.rag.utils.resources.TransformationConfig], timeout: int, max_embedding_requests_per_min: int, global_max_embedding_requests_per_min: typing.Optional[int], use_advanced_pdf_parsing: typing.Optional[bool], partial_failures_sink: typing.Optional[str], layout_parser: typing.Optional[vertexai.preview.rag.utils.resources.LayoutParserConfig], llm_parser: typing.Optional[vertexai.preview.rag.utils.resources.LlmParserConfig], rebuild_ann_index: typing.Optional[bool]) -> google.cloud.aiplatform_v1beta1.ImportRagFilesResponse:'
    docstring: "Import files to an existing RagCorpus, wait until completion.\n\nExample usage:\n\n```\nimport vertexai\nfrom vertexai.preview import rag\nfrom google.protobuf import timestamp_pb2\n\nvertexai.init(project=\"my-project\")\n# Google Drive example\npaths = [\n    \"https://drive.google.com/file/d/123\",\n    \"https://drive.google.com/drive/folders/456\"\n]\n# Google Cloud Storage example\npaths = [\"gs://my_bucket/my_files_dir\", ...]\n\ntransformation_config = TransformationConfig(\n    chunking_config=ChunkingConfig(\n        chunk_size=1024,\n        chunk_overlap=200,\n    ),\n)\n\nresponse = rag.import_files(\n    corpus_name=\"projects/my-project/locations/us-central1/ragCorpora/my-corpus-1\",\n    paths=paths,\n    transformation_config=transformation_config,\n)\n\n# Slack example\nstart_time = timestamp_pb2.Timestamp()\nstart_time.FromJsonString('2020-12-31T21:33:44Z')\nend_time = timestamp_pb2.Timestamp()\nend_time.GetCurrentTime()\nsource = rag.SlackChannelsSource(\n\
      \    channels = [\n        SlackChannel(\"channel1\", \"api_key1\"),\n        SlackChannel(\"channel2\", \"api_key2\", start_time, end_time)\n    ],\n)\n# Jira Example\njira_query = rag.JiraQuery(\n    email=\"xxx@yyy.com\",\n    jira_projects=[\"project1\", \"project2\"],\n    custom_queries=[\"query1\", \"query2\"],\n    api_key=\"api_key\",\n    server_uri=\"server.atlassian.net\"\n)\nsource = rag.JiraSource(\n    queries=[jira_query],\n)\n\nresponse = rag.import_files(\n    corpus_name=\"projects/my-project/locations/us-central1/ragCorpora/my-corpus-1\",\n    source=source,\n    transformation_config=transformation_config,\n)\n\n# SharePoint Example.\nsharepoint_query = rag.SharePointSource(\n    sharepoint_folder_path=\"https://my-sharepoint-site.com/my-folder\",\n    sharepoint_site_name=\"my-sharepoint-site.com\",\n    client_id=\"my-client-id\",\n    client_secret=\"my-client-secret\",\n    tenant_id=\"my-tenant-id\",\n    drive_id=\"my-drive-id\",\n)\nsource = rag.SharePointSources(\n\
      \    share_point_sources=[sharepoint_query],\n)\n\n# Return the number of imported RagFiles after completion.\nprint(response.imported_rag_files_count)\n\n```\nArgs:\n    corpus_name: The name of the RagCorpus resource into which to import files.\n        Format: ``projects/{project}/locations/{location}/ragCorpora/{rag_corpus}``\n        or ``{rag_corpus}``.\n    paths: A list of uris. Eligible uris will be Google Cloud Storage\n        directory (\"gs://my-bucket/my_dir\") or a Google Drive url for file\n        (https://drive.google.com/file/... or folder\n        \"https://drive.google.com/corp/drive/folders/...\").\n    source: The source of the Slack or Jira import.\n        Must be either a SlackChannelsSource or JiraSource.\n    chunk_size: The size of the chunks. This field is deprecated. Please use\n        transformation_config instead.\n    chunk_overlap: The overlap between chunks. This field is deprecated. Please use\n        transformation_config instead.\n    transformation_config:\
      \ The config for transforming the imported\n        RagFiles.\n    max_embedding_requests_per_min:\n        Optional. The max number of queries per\n        minute that this job is allowed to make to the\n        embedding model specified on the corpus. This\n        value is specific to this job and not shared\n        across other import jobs. Consult the Quotas\n        page on the project to set an appropriate value\n        here. If unspecified, a default value of 1,000\n        QPM would be used.\n    global_max_embedding_requests_per_min:\n        Optional. The max number of queries per minute that the indexing\n        pipeline job is allowed to make to the embedding model specified in\n        the project. Please follow the quota usage guideline of the embedding\n        model you use to set the value properly. If this value is not specified,\n        max_embedding_requests_per_min will be used by indexing pipeline job\n        as the global limit and this means parallel import\
      \ jobs are not allowed.\n    timeout: Default is 600 seconds.\n    use_advanced_pdf_parsing: Whether to use advanced PDF\n        parsing on uploaded files. This field is deprecated.\n    partial_failures_sink: Either a GCS path to store partial failures or a\n        BigQuery table to store partial failures. The format is\n        \"gs://my-bucket/my/object.ndjson\" for GCS or\n        \"bq://my-project.my-dataset.my-table\" for BigQuery. An existing GCS\n        object cannot be used. However, the BigQuery table may or may not\n        exist - if it does not exist, it will be created. If it does exist,\n        the schema will be checked and the partial failures will be appended\n        to the table.\n    layout_parser: Configuration for the Document AI Layout Parser Processor\n        to use for document parsing. Optional.\n        If not None, the other parser configs must be None.\n    llm_parser: Configuration for the LLM Parser to use for document parsing.\n        Optional.\n\
      \        If not None, the other parser configs must be None.\n    rebuild_ann_index: Rebuilds the ANN index to optimize for recall on the\n        imported data. Only applicable for RagCorpora running on\n        RagManagedDb with ``retrieval_strategy`` set to ``ANN``. The\n        rebuild will be performed using the existing ANN config set\n        on the RagCorpus. To change the ANN config, please use the\n        UpdateRagCorpus API. Optional.Default is false, i.e., index is not\n        rebuilt.\nReturns:\n    ImportRagFilesResponse."
  - signature: 'def import_files_async(corpus_name: str, paths: typing.Optional[typing.Sequence[str]], source: typing.Optional[typing.Union[vertexai.preview.rag.utils.resources.SlackChannelsSource, vertexai.preview.rag.utils.resources.JiraSource, vertexai.preview.rag.utils.resources.SharePointSources]], chunk_size: int, chunk_overlap: int, transformation_config: typing.Optional[vertexai.preview.rag.utils.resources.TransformationConfig], max_embedding_requests_per_min: int, global_max_embedding_requests_per_min: typing.Optional[int], use_advanced_pdf_parsing: typing.Optional[bool], partial_failures_sink: typing.Optional[str], layout_parser: typing.Optional[vertexai.preview.rag.utils.resources.LayoutParserConfig], llm_parser: typing.Optional[vertexai.preview.rag.utils.resources.LlmParserConfig], rebuild_ann_index: typing.Optional[bool]) -> google.api_core.operation_async.AsyncOperation:'
    docstring: "Import files to an existing RagCorpus asynchronously.\n\nExample usage:\n\n```\nimport vertexai\nfrom vertexai.preview import rag\nfrom google.protobuf import timestamp_pb2\n\nvertexai.init(project=\"my-project\")\n\n# Google Drive example\npaths = [\n    \"https://drive.google.com/file/d/123\",\n    \"https://drive.google.com/drive/folders/456\"\n]\n# Google Cloud Storage example\npaths = [\"gs://my_bucket/my_files_dir\", ...]\n\ntransformation_config = TransformationConfig(\n    chunking_config=ChunkingConfig(\n        chunk_size=1024,\n        chunk_overlap=200,\n    ),\n)\n\nresponse = await rag.import_files_async(\n    corpus_name=\"projects/my-project/locations/us-central1/ragCorpora/my-corpus-1\",\n    paths=paths,\n    transformation_config=transformation_config,\n)\n\n# Slack example\nstart_time = timestamp_pb2.Timestamp()\nstart_time.FromJsonString('2020-12-31T21:33:44Z')\nend_time = timestamp_pb2.Timestamp()\nend_time.GetCurrentTime()\nsource = rag.SlackChannelsSource(\n\
      \    channels = [\n        SlackChannel(\"channel1\", \"api_key1\"),\n        SlackChannel(\"channel2\", \"api_key2\", start_time, end_time)\n    ],\n)\n# Jira Example\njira_query = rag.JiraQuery(\n    email=\"xxx@yyy.com\",\n    jira_projects=[\"project1\", \"project2\"],\n    custom_queries=[\"query1\", \"query2\"],\n    api_key=\"api_key\",\n    server_uri=\"server.atlassian.net\"\n)\nsource = rag.JiraSource(\n    queries=[jira_query],\n)\n\nresponse = await rag.import_files_async(\n    corpus_name=\"projects/my-project/locations/us-central1/ragCorpora/my-corpus-1\",\n    source=source,\n    transformation_config=transformation_config,\n)\n\n# SharePoint Example.\nsharepoint_query = rag.SharePointSource(\n    sharepoint_folder_path=\"https://my-sharepoint-site.com/my-folder\",\n    sharepoint_site_name=\"my-sharepoint-site.com\",\n    client_id=\"my-client-id\",\n    client_secret=\"my-client-secret\",\n    tenant_id=\"my-tenant-id\",\n    drive_id=\"my-drive-id\",\n)\nsource =\
      \ rag.SharePointSources(\n    share_point_sources=[sharepoint_query],\n)\n\n# Get the result.\nawait response.result()\n\n```\nArgs:\n    corpus_name: The name of the RagCorpus resource into which to import files.\n        Format: ``projects/{project}/locations/{location}/ragCorpora/{rag_corpus}``\n        or ``{rag_corpus}``.\n    paths: A list of uris. Eligible uris will be Google Cloud Storage\n        directory (\"gs://my-bucket/my_dir\") or a Google Drive url for file\n        (https://drive.google.com/file/... or folder\n        \"https://drive.google.com/corp/drive/folders/...\").\n    source: The source of the Slack or Jira import.\n        Must be either a SlackChannelsSource or JiraSource.\n    chunk_size: The size of the chunks. This field is deprecated. Please use\n        transformation_config instead.\n    chunk_overlap: The overlap between chunks. This field is deprecated. Please use\n        transformation_config instead.\n    transformation_config: The config for transforming\
      \ the imported\n        RagFiles.\n    max_embedding_requests_per_min:\n        Optional. The max number of queries per\n        minute that this job is allowed to make to the\n        embedding model specified on the corpus. This\n        value is specific to this job and not shared\n        across other import jobs. Consult the Quotas\n        page on the project to set an appropriate value\n        here. If unspecified, a default value of 1,000\n        QPM would be used.\n    global_max_embedding_requests_per_min:\n        Optional. The max number of queries per minute that the indexing\n        pipeline job is allowed to make to the embedding model specified in\n        the project. Please follow the quota usage guideline of the embedding\n        model you use to set the value properly. If this value is not specified,\n        max_embedding_requests_per_min will be used by indexing pipeline job\n        as the global limit and this means parallel import jobs are not allowed.\n\
      \    use_advanced_pdf_parsing: Whether to use advanced PDF\n        parsing on uploaded files.\n    partial_failures_sink: Either a GCS path to store partial failures or a\n        BigQuery table to store partial failures. The format is\n        \"gs://my-bucket/my/object.ndjson\" for GCS or\n        \"bq://my-project.my-dataset.my-table\" for BigQuery. An existing GCS\n        object cannot be used. However, the BigQuery table may or may not\n        exist - if it does not exist, it will be created. If it does exist,\n        the schema will be checked and the partial failures will be appended\n        to the table.\n    layout_parser: Configuration for the Document AI Layout Parser Processor\n        to use for document parsing. Optional.\n        If not None, the other parser configs must be None.\n    llm_parser: Configuration for the LLM Parser to use for document parsing.\n        Optional.\n        If not None, the other parser configs must be None.\n    rebuild_ann_index: Rebuilds\
      \ the ANN index to optimize for recall on the\n        imported data. Only applicable for RagCorpora running on\n        RagManagedDb with ``retrieval_strategy`` set to ``ANN``. The\n        rebuild will be performed using the existing ANN config set\n        on the RagCorpus. To change the ANN config, please use the\n        UpdateRagCorpus API. Optional.Default is false, i.e., index is not\n        rebuilt.\nReturns:\n    operation_async.AsyncOperation."
  - signature: 'def get_file(name: str, corpus_name: typing.Optional[str]) -> vertexai.preview.rag.utils.resources.RagFile:'
    docstring: "Get an existing RagFile.\n\nArgs:\n    name: Either a full RagFile resource name must be provided, or a RagCorpus\n        name and a RagFile name must be provided. Format:\n        ``projects/{project}/locations/{location}/ragCorpora/{rag_corpus}/ragFiles/{rag_file}``\n        or ``{rag_file}``.\n    corpus_name: If `name` is not a full resource name, an existing RagCorpus\n        name must be provided. Format:\n        ``projects/{project}/locations/{location}/ragCorpora/{rag_corpus}``\n        or ``{rag_corpus}``.\nReturns:\n    RagFile."
  - signature: 'def list_files(corpus_name: str, page_size: typing.Optional[int], page_token: typing.Optional[str]) -> google.cloud.aiplatform_v1beta1.services.vertex_rag_data_service.pagers.ListRagFilesPager:'
    docstring: "List all RagFiles in an existing RagCorpus.\n\nExample usage:\n```\nimport vertexai\n\nvertexai.init(project=\"my-project\")\n# List all corpora.\nrag_corpora = list(rag.list_corpora())\n\n# List all files of the first corpus.\nrag_files = list(rag.list_files(corpus_name=rag_corpora[0].name))\n\n# Alternatively, return a ListRagFilesPager.\npager_1 = rag.list_files(\n    corpus_name=rag_corpora[0].name,\n    page_size=10\n)\n# Then get the next page, use the generated next_page_token from the last pager.\npager_2 = rag.list_files(\n    corpus_name=rag_corpora[0].name,\n    page_size=10,\n    page_token=pager_1.next_page_token\n)\n\n```\n\nArgs:\n    corpus_name: An existing RagCorpus name. Format:\n        ``projects/{project}/locations/{location}/ragCorpora/{rag_corpus}``\n        or ``{rag_corpus}``.\n    page_size: The standard list page size. Leaving out the page_size\n        causes all of the results to be returned.\n    page_token: The standard list page token.\nReturns:\n\
      \    ListRagFilesPager."
  - signature: 'def delete_file(name: str, corpus_name: typing.Optional[str]) -> None:'
    docstring: "Delete RagFile from an existing RagCorpus.\n\nArgs:\n    name: Either a full RagFile resource name must be provided, or a RagCorpus\n        name and a RagFile name must be provided. Format:\n        ``projects/{project}/locations/{location}/ragCorpora/{rag_corpus}/ragFiles/{rag_file}``\n        or ``{rag_file}``.\n    corpus_name: If `name` is not a full resource name, an existing RagCorpus\n        name must be provided. Format:\n        ``projects/{project}/locations/{location}/ragCorpora/{rag_corpus}``\n        or ``{rag_corpus}``."
  - signature: 'def update_rag_engine_config(rag_engine_config: vertexai.preview.rag.utils.resources.RagEngineConfig, timeout: int) -> vertexai.preview.rag.utils.resources.RagEngineConfig:'
    docstring: "Update RagEngineConfig.\n\nExample usage:\n```\nimport vertexai\nfrom vertexai.preview import rag\nvertexai.init(project=\"my-project\")\nrag_engine_config = rag.RagEngineConfig(\n    rag_managed_db_config=rag.RagManagedDbConfig(\n        rag_managed_db=rag.RagManagedDb(\n            db_basic_tier=rag.Basic(),\n        ),\n    )\n    ),\n)\nrag.update_rag_engine_config(rag_engine_config=rag_engine_config)\n```\n\nArgs:\n    rag_engine_config: The RagEngineConfig to update.\n    timeout: Default is 600 seconds.\n\nRaises:\n    RuntimeError: Failed in RagEngineConfig update due to exception."
  - signature: 'def get_rag_engine_config(name: str) -> vertexai.preview.rag.utils.resources.RagEngineConfig:'
    docstring: "Get an existing RagEngineConfig.\n\nExample usage:\n```\nimport vertexai\nfrom vertexai.preview import rag\nvertexai.init(project=\"my-project\")\nrag_engine_config = rag.get_rag_engine_config(\n    name=\"projects/my-project/locations/us-central1/ragEngineConfig\"\n)\n```\nArgs:\n    name: The RagEngineConfig resource name pattern of the singleton resource.\n\nReturns:\n    RagEngineConfig.\nRaises:\n    RuntimeError: Failed in getting the RagEngineConfig."
- rank: 2911
  id: vertexai.preview.rag.rag_data.create_corpus
  name: create_corpus
  file_path: env/lib/python3.13/site-packages/vertexai/preview/rag/rag_data.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Creates a new RagCorpus resource.\n\nExample usage:\n```\nimport vertexai\nfrom vertexai.preview import rag\n\nvertexai.init(project=\"my-project\")\n\nrag_corpus = rag.create_corpus(\n    display_name=\"my-corpus-1\",\n)\n```\n\nArgs:\n    display_name: If not provided, SDK will create one. The display name of\n      the RagCorpus. The name can be up to 128 characters long and can consist\n      of any UTF-8 characters.\n    description: The description of the RagCorpus.\n    corpus_type_config: The corpus type config of the RagCorpus.\n    embedding_model_config: The embedding model config.\n        Note: Deprecated. Use backend_config instead.\n    vector_db: The vector db config of the RagCorpus. If unspecified, the\n      default database Spanner is used.\n        Note: Deprecated. Use backend_config instead.\n    vertex_ai_search_config: The Vertex AI Search config of the RagCorpus.\n        Note: embedding_model_config or vector_db cannot be set if\n          vertex_ai_search_config\
    \ is specified.\n    backend_config: The backend config of the RagCorpus. It can specify a\n      Vector DB and/or the embedding model config.\n    encryption_spec: The encryption spec of the RagCorpus.\n    timeout: Default is 600 seconds.\n\nReturns:\n    RagCorpus.\nRaises:\n    RuntimeError: Failed in RagCorpus creation due to exception.\n    RuntimeError: Failed in RagCorpus creation due to operation error."
  signature: 'def create_corpus(display_name: typing.Optional[str], description: typing.Optional[str], corpus_type_config: typing.Optional[vertexai.preview.rag.utils.resources.RagCorpusTypeConfig], embedding_model_config: typing.Optional[vertexai.preview.rag.utils.resources.EmbeddingModelConfig], vector_db: typing.Optional[typing.Union[vertexai.preview.rag.utils.resources.Weaviate, vertexai.preview.rag.utils.resources.VertexFeatureStore, vertexai.preview.rag.utils.resources.VertexVectorSearch, vertexai.preview.rag.utils.resources.Pinecone, vertexai.preview.rag.utils.resources.RagManagedDb]], vertex_ai_search_config: typing.Optional[vertexai.preview.rag.utils.resources.VertexAiSearchConfig], backend_config: typing.Optional[vertexai.preview.rag.utils.resources.RagVectorDbConfig], encryption_spec: typing.Optional[google.cloud.aiplatform_v1beta1.types.EncryptionSpec], timeout: int) -> vertexai.preview.rag.utils.resources.RagCorpus:'
  aliases:
  - vertexai.preview.rag.create_corpus
- rank: 2912
  id: vertexai.preview.rag.rag_data.delete_corpus
  name: delete_corpus
  file_path: env/lib/python3.13/site-packages/vertexai/preview/rag/rag_data.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Delete an existing RagCorpus.\n\nArgs:\n    name: An existing RagCorpus resource name. Format:\n        ``projects/{project}/locations/{location}/ragCorpora/{rag_corpus}``\n        or ``{rag_corpus}``."
  signature: 'def delete_corpus(name: str) -> None:'
  aliases:
  - vertexai.preview.rag.delete_corpus
- rank: 2913
  id: vertexai.preview.rag.rag_data.delete_file
  name: delete_file
  file_path: env/lib/python3.13/site-packages/vertexai/preview/rag/rag_data.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Delete RagFile from an existing RagCorpus.\n\nArgs:\n    name: Either a full RagFile resource name must be provided, or a RagCorpus\n        name and a RagFile name must be provided. Format:\n        ``projects/{project}/locations/{location}/ragCorpora/{rag_corpus}/ragFiles/{rag_file}``\n        or ``{rag_file}``.\n    corpus_name: If `name` is not a full resource name, an existing RagCorpus\n        name must be provided. Format:\n        ``projects/{project}/locations/{location}/ragCorpora/{rag_corpus}``\n        or ``{rag_corpus}``."
  signature: 'def delete_file(name: str, corpus_name: typing.Optional[str]) -> None:'
  aliases:
  - vertexai.preview.rag.delete_file
- rank: 2914
  id: vertexai.preview.rag.rag_data.get_corpus
  name: get_corpus
  file_path: env/lib/python3.13/site-packages/vertexai/preview/rag/rag_data.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Get an existing RagCorpus.\n\nArgs:\n    name: An existing RagCorpus resource name. Format:\n        ``projects/{project}/locations/{location}/ragCorpora/{rag_corpus}``\n        or ``{rag_corpus}``.\nReturns:\n    RagCorpus."
  signature: 'def get_corpus(name: str) -> vertexai.preview.rag.utils.resources.RagCorpus:'
  aliases:
  - vertexai.preview.rag.get_corpus
- rank: 2915
  id: vertexai.preview.rag.rag_data.get_file
  name: get_file
  file_path: env/lib/python3.13/site-packages/vertexai/preview/rag/rag_data.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Get an existing RagFile.\n\nArgs:\n    name: Either a full RagFile resource name must be provided, or a RagCorpus\n        name and a RagFile name must be provided. Format:\n        ``projects/{project}/locations/{location}/ragCorpora/{rag_corpus}/ragFiles/{rag_file}``\n        or ``{rag_file}``.\n    corpus_name: If `name` is not a full resource name, an existing RagCorpus\n        name must be provided. Format:\n        ``projects/{project}/locations/{location}/ragCorpora/{rag_corpus}``\n        or ``{rag_corpus}``.\nReturns:\n    RagFile."
  signature: 'def get_file(name: str, corpus_name: typing.Optional[str]) -> vertexai.preview.rag.utils.resources.RagFile:'
  aliases:
  - vertexai.preview.rag.get_file
- rank: 2916
  id: vertexai.preview.rag.rag_data.get_rag_engine_config
  name: get_rag_engine_config
  file_path: env/lib/python3.13/site-packages/vertexai/preview/rag/rag_data.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Get an existing RagEngineConfig.\n\nExample usage:\n```\nimport vertexai\nfrom vertexai.preview import rag\nvertexai.init(project=\"my-project\")\nrag_engine_config = rag.get_rag_engine_config(\n    name=\"projects/my-project/locations/us-central1/ragEngineConfig\"\n)\n```\nArgs:\n    name: The RagEngineConfig resource name pattern of the singleton resource.\n\nReturns:\n    RagEngineConfig.\nRaises:\n    RuntimeError: Failed in getting the RagEngineConfig."
  signature: 'def get_rag_engine_config(name: str) -> vertexai.preview.rag.utils.resources.RagEngineConfig:'
  aliases:
  - vertexai.preview.rag.get_rag_engine_config
- rank: 2917
  id: vertexai.preview.rag.rag_data.import_files
  name: import_files
  file_path: env/lib/python3.13/site-packages/vertexai/preview/rag/rag_data.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Import files to an existing RagCorpus, wait until completion.\n\nExample usage:\n\n```\nimport vertexai\nfrom vertexai.preview import rag\nfrom google.protobuf import timestamp_pb2\n\nvertexai.init(project=\"my-project\")\n# Google Drive example\npaths = [\n    \"https://drive.google.com/file/d/123\",\n    \"https://drive.google.com/drive/folders/456\"\n]\n# Google Cloud Storage example\npaths = [\"gs://my_bucket/my_files_dir\", ...]\n\ntransformation_config = TransformationConfig(\n    chunking_config=ChunkingConfig(\n        chunk_size=1024,\n        chunk_overlap=200,\n    ),\n)\n\nresponse = rag.import_files(\n    corpus_name=\"projects/my-project/locations/us-central1/ragCorpora/my-corpus-1\",\n    paths=paths,\n    transformation_config=transformation_config,\n)\n\n# Slack example\nstart_time = timestamp_pb2.Timestamp()\nstart_time.FromJsonString('2020-12-31T21:33:44Z')\nend_time = timestamp_pb2.Timestamp()\nend_time.GetCurrentTime()\nsource = rag.SlackChannelsSource(\n\
    \    channels = [\n        SlackChannel(\"channel1\", \"api_key1\"),\n        SlackChannel(\"channel2\", \"api_key2\", start_time, end_time)\n    ],\n)\n# Jira Example\njira_query = rag.JiraQuery(\n    email=\"xxx@yyy.com\",\n    jira_projects=[\"project1\", \"project2\"],\n    custom_queries=[\"query1\", \"query2\"],\n    api_key=\"api_key\",\n    server_uri=\"server.atlassian.net\"\n)\nsource = rag.JiraSource(\n    queries=[jira_query],\n)\n\nresponse = rag.import_files(\n    corpus_name=\"projects/my-project/locations/us-central1/ragCorpora/my-corpus-1\",\n    source=source,\n    transformation_config=transformation_config,\n)\n\n# SharePoint Example.\nsharepoint_query = rag.SharePointSource(\n    sharepoint_folder_path=\"https://my-sharepoint-site.com/my-folder\",\n    sharepoint_site_name=\"my-sharepoint-site.com\",\n    client_id=\"my-client-id\",\n    client_secret=\"my-client-secret\",\n    tenant_id=\"my-tenant-id\",\n    drive_id=\"my-drive-id\",\n)\nsource = rag.SharePointSources(\n\
    \    share_point_sources=[sharepoint_query],\n)\n\n# Return the number of imported RagFiles after completion.\nprint(response.imported_rag_files_count)\n\n```\nArgs:\n    corpus_name: The name of the RagCorpus resource into which to import files.\n        Format: ``projects/{project}/locations/{location}/ragCorpora/{rag_corpus}``\n        or ``{rag_corpus}``.\n    paths: A list of uris. Eligible uris will be Google Cloud Storage\n        directory (\"gs://my-bucket/my_dir\") or a Google Drive url for file\n        (https://drive.google.com/file/... or folder\n        \"https://drive.google.com/corp/drive/folders/...\").\n    source: The source of the Slack or Jira import.\n        Must be either a SlackChannelsSource or JiraSource.\n    chunk_size: The size of the chunks. This field is deprecated. Please use\n        transformation_config instead.\n    chunk_overlap: The overlap between chunks. This field is deprecated. Please use\n        transformation_config instead.\n    transformation_config:\
    \ The config for transforming the imported\n        RagFiles.\n    max_embedding_requests_per_min:\n        Optional. The max number of queries per\n        minute that this job is allowed to make to the\n        embedding model specified on the corpus. This\n        value is specific to this job and not shared\n        across other import jobs. Consult the Quotas\n        page on the project to set an appropriate value\n        here. If unspecified, a default value of 1,000\n        QPM would be used.\n    global_max_embedding_requests_per_min:\n        Optional. The max number of queries per minute that the indexing\n        pipeline job is allowed to make to the embedding model specified in\n        the project. Please follow the quota usage guideline of the embedding\n        model you use to set the value properly. If this value is not specified,\n        max_embedding_requests_per_min will be used by indexing pipeline job\n        as the global limit and this means parallel import\
    \ jobs are not allowed.\n    timeout: Default is 600 seconds.\n    use_advanced_pdf_parsing: Whether to use advanced PDF\n        parsing on uploaded files. This field is deprecated.\n    partial_failures_sink: Either a GCS path to store partial failures or a\n        BigQuery table to store partial failures. The format is\n        \"gs://my-bucket/my/object.ndjson\" for GCS or\n        \"bq://my-project.my-dataset.my-table\" for BigQuery. An existing GCS\n        object cannot be used. However, the BigQuery table may or may not\n        exist - if it does not exist, it will be created. If it does exist,\n        the schema will be checked and the partial failures will be appended\n        to the table.\n    layout_parser: Configuration for the Document AI Layout Parser Processor\n        to use for document parsing. Optional.\n        If not None, the other parser configs must be None.\n    llm_parser: Configuration for the LLM Parser to use for document parsing.\n        Optional.\n\
    \        If not None, the other parser configs must be None.\n    rebuild_ann_index: Rebuilds the ANN index to optimize for recall on the\n        imported data. Only applicable for RagCorpora running on\n        RagManagedDb with ``retrieval_strategy`` set to ``ANN``. The\n        rebuild will be performed using the existing ANN config set\n        on the RagCorpus. To change the ANN config, please use the\n        UpdateRagCorpus API. Optional.Default is false, i.e., index is not\n        rebuilt.\nReturns:\n    ImportRagFilesResponse."
  signature: 'def import_files(corpus_name: str, paths: typing.Optional[typing.Sequence[str]], source: typing.Optional[typing.Union[vertexai.preview.rag.utils.resources.SlackChannelsSource, vertexai.preview.rag.utils.resources.JiraSource, vertexai.preview.rag.utils.resources.SharePointSources]], chunk_size: int, chunk_overlap: int, transformation_config: typing.Optional[vertexai.preview.rag.utils.resources.TransformationConfig], timeout: int, max_embedding_requests_per_min: int, global_max_embedding_requests_per_min: typing.Optional[int], use_advanced_pdf_parsing: typing.Optional[bool], partial_failures_sink: typing.Optional[str], layout_parser: typing.Optional[vertexai.preview.rag.utils.resources.LayoutParserConfig], llm_parser: typing.Optional[vertexai.preview.rag.utils.resources.LlmParserConfig], rebuild_ann_index: typing.Optional[bool]) -> google.cloud.aiplatform_v1beta1.ImportRagFilesResponse:'
  aliases:
  - vertexai.preview.rag.import_files
- rank: 2918
  id: vertexai.preview.rag.rag_data.import_files_async
  name: import_files_async
  file_path: env/lib/python3.13/site-packages/vertexai/preview/rag/rag_data.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Import files to an existing RagCorpus asynchronously.\n\nExample usage:\n\n```\nimport vertexai\nfrom vertexai.preview import rag\nfrom google.protobuf import timestamp_pb2\n\nvertexai.init(project=\"my-project\")\n\n# Google Drive example\npaths = [\n    \"https://drive.google.com/file/d/123\",\n    \"https://drive.google.com/drive/folders/456\"\n]\n# Google Cloud Storage example\npaths = [\"gs://my_bucket/my_files_dir\", ...]\n\ntransformation_config = TransformationConfig(\n    chunking_config=ChunkingConfig(\n        chunk_size=1024,\n        chunk_overlap=200,\n    ),\n)\n\nresponse = await rag.import_files_async(\n    corpus_name=\"projects/my-project/locations/us-central1/ragCorpora/my-corpus-1\",\n    paths=paths,\n    transformation_config=transformation_config,\n)\n\n# Slack example\nstart_time = timestamp_pb2.Timestamp()\nstart_time.FromJsonString('2020-12-31T21:33:44Z')\nend_time = timestamp_pb2.Timestamp()\nend_time.GetCurrentTime()\nsource = rag.SlackChannelsSource(\n\
    \    channels = [\n        SlackChannel(\"channel1\", \"api_key1\"),\n        SlackChannel(\"channel2\", \"api_key2\", start_time, end_time)\n    ],\n)\n# Jira Example\njira_query = rag.JiraQuery(\n    email=\"xxx@yyy.com\",\n    jira_projects=[\"project1\", \"project2\"],\n    custom_queries=[\"query1\", \"query2\"],\n    api_key=\"api_key\",\n    server_uri=\"server.atlassian.net\"\n)\nsource = rag.JiraSource(\n    queries=[jira_query],\n)\n\nresponse = await rag.import_files_async(\n    corpus_name=\"projects/my-project/locations/us-central1/ragCorpora/my-corpus-1\",\n    source=source,\n    transformation_config=transformation_config,\n)\n\n# SharePoint Example.\nsharepoint_query = rag.SharePointSource(\n    sharepoint_folder_path=\"https://my-sharepoint-site.com/my-folder\",\n    sharepoint_site_name=\"my-sharepoint-site.com\",\n    client_id=\"my-client-id\",\n    client_secret=\"my-client-secret\",\n    tenant_id=\"my-tenant-id\",\n    drive_id=\"my-drive-id\",\n)\nsource = rag.SharePointSources(\n\
    \    share_point_sources=[sharepoint_query],\n)\n\n# Get the result.\nawait response.result()\n\n```\nArgs:\n    corpus_name: The name of the RagCorpus resource into which to import files.\n        Format: ``projects/{project}/locations/{location}/ragCorpora/{rag_corpus}``\n        or ``{rag_corpus}``.\n    paths: A list of uris. Eligible uris will be Google Cloud Storage\n        directory (\"gs://my-bucket/my_dir\") or a Google Drive url for file\n        (https://drive.google.com/file/... or folder\n        \"https://drive.google.com/corp/drive/folders/...\").\n    source: The source of the Slack or Jira import.\n        Must be either a SlackChannelsSource or JiraSource.\n    chunk_size: The size of the chunks. This field is deprecated. Please use\n        transformation_config instead.\n    chunk_overlap: The overlap between chunks. This field is deprecated. Please use\n        transformation_config instead.\n    transformation_config: The config for transforming the imported\n\
    \        RagFiles.\n    max_embedding_requests_per_min:\n        Optional. The max number of queries per\n        minute that this job is allowed to make to the\n        embedding model specified on the corpus. This\n        value is specific to this job and not shared\n        across other import jobs. Consult the Quotas\n        page on the project to set an appropriate value\n        here. If unspecified, a default value of 1,000\n        QPM would be used.\n    global_max_embedding_requests_per_min:\n        Optional. The max number of queries per minute that the indexing\n        pipeline job is allowed to make to the embedding model specified in\n        the project. Please follow the quota usage guideline of the embedding\n        model you use to set the value properly. If this value is not specified,\n        max_embedding_requests_per_min will be used by indexing pipeline job\n        as the global limit and this means parallel import jobs are not allowed.\n    use_advanced_pdf_parsing:\
    \ Whether to use advanced PDF\n        parsing on uploaded files.\n    partial_failures_sink: Either a GCS path to store partial failures or a\n        BigQuery table to store partial failures. The format is\n        \"gs://my-bucket/my/object.ndjson\" for GCS or\n        \"bq://my-project.my-dataset.my-table\" for BigQuery. An existing GCS\n        object cannot be used. However, the BigQuery table may or may not\n        exist - if it does not exist, it will be created. If it does exist,\n        the schema will be checked and the partial failures will be appended\n        to the table.\n    layout_parser: Configuration for the Document AI Layout Parser Processor\n        to use for document parsing. Optional.\n        If not None, the other parser configs must be None.\n    llm_parser: Configuration for the LLM Parser to use for document parsing.\n        Optional.\n        If not None, the other parser configs must be None.\n    rebuild_ann_index: Rebuilds the ANN index to optimize\
    \ for recall on the\n        imported data. Only applicable for RagCorpora running on\n        RagManagedDb with ``retrieval_strategy`` set to ``ANN``. The\n        rebuild will be performed using the existing ANN config set\n        on the RagCorpus. To change the ANN config, please use the\n        UpdateRagCorpus API. Optional.Default is false, i.e., index is not\n        rebuilt.\nReturns:\n    operation_async.AsyncOperation."
  signature: 'def import_files_async(corpus_name: str, paths: typing.Optional[typing.Sequence[str]], source: typing.Optional[typing.Union[vertexai.preview.rag.utils.resources.SlackChannelsSource, vertexai.preview.rag.utils.resources.JiraSource, vertexai.preview.rag.utils.resources.SharePointSources]], chunk_size: int, chunk_overlap: int, transformation_config: typing.Optional[vertexai.preview.rag.utils.resources.TransformationConfig], max_embedding_requests_per_min: int, global_max_embedding_requests_per_min: typing.Optional[int], use_advanced_pdf_parsing: typing.Optional[bool], partial_failures_sink: typing.Optional[str], layout_parser: typing.Optional[vertexai.preview.rag.utils.resources.LayoutParserConfig], llm_parser: typing.Optional[vertexai.preview.rag.utils.resources.LlmParserConfig], rebuild_ann_index: typing.Optional[bool]) -> google.api_core.operation_async.AsyncOperation:'
  aliases:
  - vertexai.preview.rag.import_files_async
- rank: 2919
  id: vertexai.preview.rag.rag_data.list_corpora
  name: list_corpora
  file_path: env/lib/python3.13/site-packages/vertexai/preview/rag/rag_data.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "List all RagCorpora in the same project and location.\n\nExample usage:\n```\nimport vertexai\nfrom vertexai.preview import rag\n\nvertexai.init(project=\"my-project\")\n\n# List all corpora.\nrag_corpora = list(rag.list_corpora())\n\n# Alternatively, return a ListRagCorporaPager.\npager_1 = rag.list_corpora(page_size=10)\n# Then get the next page, use the generated next_page_token from the last pager.\npager_2 = rag.list_corpora(page_size=10, page_token=pager_1.next_page_token)\n\n```\nArgs:\n    page_size: The standard list page size. Leaving out the page_size\n        causes all of the results to be returned.\n    page_token: The standard list page token.\n\nReturns:\n    ListRagCorporaPager."
  signature: 'def list_corpora(page_size: typing.Optional[int], page_token: typing.Optional[str]) -> google.cloud.aiplatform_v1beta1.services.vertex_rag_data_service.pagers.ListRagCorporaPager:'
  aliases:
  - vertexai.preview.rag.list_corpora
- rank: 2920
  id: vertexai.preview.rag.rag_data.list_files
  name: list_files
  file_path: env/lib/python3.13/site-packages/vertexai/preview/rag/rag_data.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "List all RagFiles in an existing RagCorpus.\n\nExample usage:\n```\nimport vertexai\n\nvertexai.init(project=\"my-project\")\n# List all corpora.\nrag_corpora = list(rag.list_corpora())\n\n# List all files of the first corpus.\nrag_files = list(rag.list_files(corpus_name=rag_corpora[0].name))\n\n# Alternatively, return a ListRagFilesPager.\npager_1 = rag.list_files(\n    corpus_name=rag_corpora[0].name,\n    page_size=10\n)\n# Then get the next page, use the generated next_page_token from the last pager.\npager_2 = rag.list_files(\n    corpus_name=rag_corpora[0].name,\n    page_size=10,\n    page_token=pager_1.next_page_token\n)\n\n```\n\nArgs:\n    corpus_name: An existing RagCorpus name. Format:\n        ``projects/{project}/locations/{location}/ragCorpora/{rag_corpus}``\n        or ``{rag_corpus}``.\n    page_size: The standard list page size. Leaving out the page_size\n        causes all of the results to be returned.\n    page_token: The standard list page token.\nReturns:\n\
    \    ListRagFilesPager."
  signature: 'def list_files(corpus_name: str, page_size: typing.Optional[int], page_token: typing.Optional[str]) -> google.cloud.aiplatform_v1beta1.services.vertex_rag_data_service.pagers.ListRagFilesPager:'
  aliases:
  - vertexai.preview.rag.list_files
- rank: 2921
  id: vertexai.preview.rag.rag_data.update_corpus
  name: update_corpus
  file_path: env/lib/python3.13/site-packages/vertexai/preview/rag/rag_data.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Updates a RagCorpus resource.\n\nExample usage:\n```\nimport vertexai\nfrom vertexai.preview import rag\n\nvertexai.init(project=\"my-project\")\n\nrag_corpus = rag.update_corpus(\n    corpus_name=\"projects/my-project/locations/us-central1/ragCorpora/my-corpus-1\",\n    display_name=\"my-corpus-1\",\n)\n```\n\nArgs:\n    corpus_name: The name of the RagCorpus resource to update. Format:\n      ``projects/{project}/locations/{location}/ragCorpora/{rag_corpus}`` or\n      ``{rag_corpus}``.\n    display_name: If not provided, the display name will not be updated. The\n      display name of the RagCorpus. The name can be up to 128 characters long\n      and can consist of any UTF-8 characters.\n    description: The description of the RagCorpus. If not provided, the\n      description will not be updated.\n    vector_db: The vector db config of the RagCorpus. If not provided, the\n      vector db will not be updated.\n    vertex_ai_search_config: The Vertex AI Search config of\
    \ the RagCorpus. If\n      not provided, the Vertex AI Search config will not be updated.\n      Note: embedding_model_config or vector_db cannot be set if\n        vertex_ai_search_config is specified.\n    backend_config: The backend config of the RagCorpus. Specifies a Vector DB\n      and/or the embedding model config.\n    timeout: Default is 600 seconds.\n\nReturns:\n    RagCorpus.\nRaises:\n    RuntimeError: Failed in RagCorpus update due to exception.\n    RuntimeError: Failed in RagCorpus update due to operation error."
  signature: 'def update_corpus(corpus_name: str, display_name: typing.Optional[str], description: typing.Optional[str], vector_db: typing.Optional[typing.Union[vertexai.preview.rag.utils.resources.Weaviate, vertexai.preview.rag.utils.resources.VertexFeatureStore, vertexai.preview.rag.utils.resources.VertexVectorSearch, vertexai.preview.rag.utils.resources.Pinecone, vertexai.preview.rag.utils.resources.RagManagedDb]], vertex_ai_search_config: typing.Optional[vertexai.preview.rag.utils.resources.VertexAiSearchConfig], backend_config: typing.Optional[vertexai.preview.rag.utils.resources.RagVectorDbConfig], timeout: int) -> vertexai.preview.rag.utils.resources.RagCorpus:'
  aliases:
  - vertexai.preview.rag.update_corpus
- rank: 2922
  id: vertexai.preview.rag.rag_data.update_rag_engine_config
  name: update_rag_engine_config
  file_path: env/lib/python3.13/site-packages/vertexai/preview/rag/rag_data.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Update RagEngineConfig.\n\nExample usage:\n```\nimport vertexai\nfrom vertexai.preview import rag\nvertexai.init(project=\"my-project\")\nrag_engine_config = rag.RagEngineConfig(\n    rag_managed_db_config=rag.RagManagedDbConfig(\n        rag_managed_db=rag.RagManagedDb(\n            db_basic_tier=rag.Basic(),\n        ),\n    )\n    ),\n)\nrag.update_rag_engine_config(rag_engine_config=rag_engine_config)\n```\n\nArgs:\n    rag_engine_config: The RagEngineConfig to update.\n    timeout: Default is 600 seconds.\n\nRaises:\n    RuntimeError: Failed in RagEngineConfig update due to exception."
  signature: 'def update_rag_engine_config(rag_engine_config: vertexai.preview.rag.utils.resources.RagEngineConfig, timeout: int) -> vertexai.preview.rag.utils.resources.RagEngineConfig:'
  aliases:
  - vertexai.preview.rag.update_rag_engine_config
- rank: 2923
  id: vertexai.preview.rag.rag_data.upload_file
  name: upload_file
  file_path: env/lib/python3.13/site-packages/vertexai/preview/rag/rag_data.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Synchronous file upload to an existing RagCorpus.\n\nExample usage:\n\n```\nimport vertexai\nfrom vertexai.preview import rag\n\nvertexai.init(project=\"my-project\")\n\n# Optional.\ntransformation_config = TransformationConfig(\n    chunking_config=ChunkingConfig(\n        chunk_size=1024,\n        chunk_overlap=200,\n    ),\n)\n\nrag_file = rag.upload_file(\n    corpus_name=\"projects/my-project/locations/us-central1/ragCorpora/my-corpus-1\",\n    display_name=\"my_file.txt\",\n    path=\"usr/home/my_file.txt\",\n    transformation_config=transformation_config,\n)\n```\n\nArgs:\n    corpus_name: The name of the RagCorpus resource into which to upload the file.\n        Format: ``projects/{project}/locations/{location}/ragCorpora/{rag_corpus}``\n        or ``{rag_corpus}``.\n    path: A local file path. For example,\n        \"usr/home/my_file.txt\".\n    display_name: The display name of the data file.\n    description: The description of the RagFile.\n    transformation_config:\
    \ The config for transforming the RagFile, such as chunking.\nReturns:\n    RagFile.\nRaises:\n    RuntimeError: Failed in RagFile upload.\n    ValueError: RagCorpus is not found.\n    RuntimeError: Failed in indexing the RagFile."
  signature: 'def upload_file(corpus_name: str, path: typing.Union[str, typing.Sequence[str]], display_name: typing.Optional[str], description: typing.Optional[str], transformation_config: typing.Optional[vertexai.preview.rag.utils.resources.TransformationConfig]) -> vertexai.preview.rag.utils.resources.RagFile:'
  aliases:
  - vertexai.preview.rag.upload_file
- rank: 2924
  id: vertexai.preview.rag.rag_retrieval
  name: rag_retrieval
  file_path: env/lib/python3.13/site-packages/vertexai/preview/rag/rag_retrieval.py
  type: MODULE
  group: Orphan
  usage_score: 0
  docstring: Retrieval query to get relevant contexts.
  methods:
  - signature: 'def retrieval_query(text: str, rag_resources: typing.Optional[typing.List[vertexai.preview.rag.utils.resources.RagResource]], rag_corpora: typing.Optional[typing.List[str]], similarity_top_k: typing.Optional[int], vector_distance_threshold: typing.Optional[float], vector_search_alpha: typing.Optional[float], rag_retrieval_config: typing.Optional[vertexai.preview.rag.utils.resources.RagRetrievalConfig]) -> google.cloud.aiplatform_v1beta1.RetrieveContextsResponse:'
    docstring: "Retrieve top k relevant docs/chunks.\n\nExample usage:\n```\nimport vertexai\n\nvertexai.init(project=\"my-project\")\n\n# Using deprecated parameters\nresults = vertexai.preview.rag.retrieval_query(\n    text=\"Why is the sky blue?\",\n    rag_resources=[vertexai.preview.rag.RagResource(\n        rag_corpus=\"projects/my-project/locations/us-central1/ragCorpora/rag-corpus-1\",\n        rag_file_ids=[\"rag-file-1\", \"rag-file-2\", ...],\n    )],\n    similarity_top_k=2,\n    vector_distance_threshold=0.5,\n    vector_search_alpha=0.5,\n)\n\n# Using RagRetrievalConfig. Equivalent to the above example.\nconfig = vertexai.preview.rag.RagRetrievalConfig(\n    top_k=2,\n    filter=vertexai.preview.rag.Filter(\n        vector_distance_threshold=0.5\n    ),\n    hybrid_search=vertexai.preview.rag.rag_retrieval_config.hybrid_search(\n        alpha=0.5\n    ),\n    ranking=vertex.preview.rag.Ranking(\n        llm_ranker=vertexai.preview.rag.LlmRanker(\n            model_name=\"gemini-1.5-flash-002\"\
      \n        )\n    )\n)\n\nresults = vertexai.preview.rag.retrieval_query(\n    text=\"Why is the sky blue?\",\n    rag_resources=[vertexai.preview.rag.RagResource(\n        rag_corpus=\"projects/my-project/locations/us-central1/ragCorpora/rag-corpus-1\",\n        rag_file_ids=[\"rag-file-1\", \"rag-file-2\", ...],\n    )],\n    rag_retrieval_config=config,\n)\n```\n\nArgs:\n    text: The query in text format to get relevant contexts.\n    rag_resources: A list of RagResource. It can be used to specify corpus\n        only or ragfiles. Currently only support one corpus or multiple files\n        from one corpus. In the future we may open up multiple corpora support.\n    rag_corpora: If rag_resources is not specified, use rag_corpora as a list\n        of rag corpora names. Deprecated. Use rag_resources instead.\n    similarity_top_k: The number of contexts to retrieve. Deprecated. Use\n        rag_retrieval_config.top_k instead.\n    vector_distance_threshold: Optional. Only return\
      \ contexts with vector\n        distance smaller than the threshold. Deprecated. Use\n        rag_retrieval_config.filter.vector_distance_threshold instead.\n    vector_search_alpha: Optional. Controls the weight between dense and\n        sparse vector search results. The range is [0, 1], where 0 means\n        sparse vector search only and 1 means dense vector search only.\n        The default value is 0.5. Deprecated. Use\n        rag_retrieval_config.hybrid_search.alpha instead.\n    rag_retrieval_config: Optional. The config containing the retrieval\n        parameters, including top_k, vector_distance_threshold,\n        and alpha.\n\nReturns:\n    RetrieveContextsResonse."
- rank: 2925
  id: vertexai.preview.rag.rag_retrieval.retrieval_query
  name: retrieval_query
  file_path: env/lib/python3.13/site-packages/vertexai/preview/rag/rag_retrieval.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Retrieve top k relevant docs/chunks.\n\nExample usage:\n```\nimport vertexai\n\nvertexai.init(project=\"my-project\")\n\n# Using deprecated parameters\nresults = vertexai.preview.rag.retrieval_query(\n    text=\"Why is the sky blue?\",\n    rag_resources=[vertexai.preview.rag.RagResource(\n        rag_corpus=\"projects/my-project/locations/us-central1/ragCorpora/rag-corpus-1\",\n        rag_file_ids=[\"rag-file-1\", \"rag-file-2\", ...],\n    )],\n    similarity_top_k=2,\n    vector_distance_threshold=0.5,\n    vector_search_alpha=0.5,\n)\n\n# Using RagRetrievalConfig. Equivalent to the above example.\nconfig = vertexai.preview.rag.RagRetrievalConfig(\n    top_k=2,\n    filter=vertexai.preview.rag.Filter(\n        vector_distance_threshold=0.5\n    ),\n    hybrid_search=vertexai.preview.rag.rag_retrieval_config.hybrid_search(\n        alpha=0.5\n    ),\n    ranking=vertex.preview.rag.Ranking(\n        llm_ranker=vertexai.preview.rag.LlmRanker(\n            model_name=\"gemini-1.5-flash-002\"\
    \n        )\n    )\n)\n\nresults = vertexai.preview.rag.retrieval_query(\n    text=\"Why is the sky blue?\",\n    rag_resources=[vertexai.preview.rag.RagResource(\n        rag_corpus=\"projects/my-project/locations/us-central1/ragCorpora/rag-corpus-1\",\n        rag_file_ids=[\"rag-file-1\", \"rag-file-2\", ...],\n    )],\n    rag_retrieval_config=config,\n)\n```\n\nArgs:\n    text: The query in text format to get relevant contexts.\n    rag_resources: A list of RagResource. It can be used to specify corpus\n        only or ragfiles. Currently only support one corpus or multiple files\n        from one corpus. In the future we may open up multiple corpora support.\n    rag_corpora: If rag_resources is not specified, use rag_corpora as a list\n        of rag corpora names. Deprecated. Use rag_resources instead.\n    similarity_top_k: The number of contexts to retrieve. Deprecated. Use\n        rag_retrieval_config.top_k instead.\n    vector_distance_threshold: Optional. Only return contexts\
    \ with vector\n        distance smaller than the threshold. Deprecated. Use\n        rag_retrieval_config.filter.vector_distance_threshold instead.\n    vector_search_alpha: Optional. Controls the weight between dense and\n        sparse vector search results. The range is [0, 1], where 0 means\n        sparse vector search only and 1 means dense vector search only.\n        The default value is 0.5. Deprecated. Use\n        rag_retrieval_config.hybrid_search.alpha instead.\n    rag_retrieval_config: Optional. The config containing the retrieval\n        parameters, including top_k, vector_distance_threshold,\n        and alpha.\n\nReturns:\n    RetrieveContextsResonse."
  signature: 'def retrieval_query(text: str, rag_resources: typing.Optional[typing.List[vertexai.preview.rag.utils.resources.RagResource]], rag_corpora: typing.Optional[typing.List[str]], similarity_top_k: typing.Optional[int], vector_distance_threshold: typing.Optional[float], vector_search_alpha: typing.Optional[float], rag_retrieval_config: typing.Optional[vertexai.preview.rag.utils.resources.RagRetrievalConfig]) -> google.cloud.aiplatform_v1beta1.RetrieveContextsResponse:'
- rank: 2926
  id: vertexai.preview.rag.rag_store
  name: rag_store
  file_path: env/lib/python3.13/site-packages/vertexai/preview/rag/rag_store.py
  type: MODULE
  group: Orphan
  usage_score: 0
  docstring: RAG retrieval tool for content generation.
- rank: 2927
  id: vertexai.preview.rag.rag_store.Retrieval
  name: Retrieval
  file_path: env/lib/python3.13/site-packages/vertexai/preview/rag/rag_store.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Defines a retrieval tool that a model can call to access external knowledge.


    [Note: Inherited members from generative_models.grounding.Retrieval are omitted.]'
  constructor_signature: 'def __init__(self, source: typing.Union[vertexai.preview.rag.rag_store.VertexRagStore], disable_attribution: typing.Optional[bool]):'
  aliases:
  - vertexai.preview.rag.Retrieval
  omitted_inherited_members_from:
  - generative_models.grounding.Retrieval
- rank: 2928
  id: vertexai.preview.rag.rag_store.Retrieval.__init__
  name: __init__
  file_path: env/lib/python3.13/site-packages/vertexai/preview/rag/rag_store.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def __init__(self, source: typing.Union[vertexai.preview.rag.rag_store.VertexRagStore], disable_attribution: typing.Optional[bool]):'
- rank: 2929
  id: vertexai.preview.rag.rag_store.VertexRagStore
  name: VertexRagStore
  file_path: env/lib/python3.13/site-packages/vertexai/preview/rag/rag_store.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: Retrieve from Vertex RAG Store.
  constructor_signature: 'def __init__(self, rag_resources: typing.Optional[typing.List[vertexai.preview.rag.utils.resources.RagResource]], rag_corpora: typing.Optional[typing.List[str]], similarity_top_k: typing.Optional[int], vector_distance_threshold: typing.Optional[float], rag_retrieval_config: typing.Optional[vertexai.preview.rag.utils.resources.RagRetrievalConfig]):'
  aliases:
  - vertexai.preview.rag.VertexRagStore
- rank: 2930
  id: vertexai.preview.rag.rag_store.VertexRagStore.__init__
  name: __init__
  file_path: env/lib/python3.13/site-packages/vertexai/preview/rag/rag_store.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Initializes a Vertex RAG store tool.\n\nExample usage:\n```\nimport vertexai\n\nvertexai.init(project=\"my-project\")\n\n# Using deprecated parameters\ntool = Tool.from_retrieval(\n    retrieval=vertexai.preview.rag.Retrieval(\n        source=vertexai.preview.rag.VertexRagStore(\n            rag_corpora=[\"projects/my-project/locations/us-central1/ragCorpora/rag-corpus-1\"],\n            similarity_top_k=3,\n            vector_distance_threshold=0.4,\n        ),\n    )\n)\n\n# Using RagRetrievalConfig. Equivalent to the above example.\nconfig = vertexai.preview.rag.RagRetrievalConfig(\n    top_k=2,\n    filter=vertexai.preview.rag.RagRetrievalConfig.Filter(\n        vector_distance_threshold=0.5\n    ),\n)\n\ntool = Tool.from_retrieval(\n    retrieval=vertexai.preview.rag.Retrieval(\n        source=vertexai.preview.rag.VertexRagStore(\n            rag_corpora=[\"projects/my-project/locations/us-central1/ragCorpora/rag-corpus-1\"],\n            rag_retrieval_config=config,\n\
    \        ),\n    )\n)\n```\n\nArgs:\n    rag_resources: List of RagResource to retrieve from. It can be used\n        to specify corpus only or ragfiles. Currently only support one\n        corpus or multiple files from one corpus. In the future we\n        may open up multiple corpora support.\n    rag_corpora: If rag_resources is not specified, use rag_corpora as a\n        list of rag corpora names. Deprecated. Use rag_resources instead.\n    similarity_top_k: Number of top k results to return from the selected\n        corpora. Deprecated. Use rag_retrieval_config.top_k instead.\n    vector_distance_threshold (float):\n        Optional. Only return results with vector distance smaller\n        than the threshold. Deprecated. Use\n        rag_retrieval_config.filter.vector_distance_threshold instead.\n    rag_retrieval_config: Optional. The config containing the retrieval\n        parameters, including top_k and vector_distance_threshold."
  signature: 'def __init__(self, rag_resources: typing.Optional[typing.List[vertexai.preview.rag.utils.resources.RagResource]], rag_corpora: typing.Optional[typing.List[str]], similarity_top_k: typing.Optional[int], vector_distance_threshold: typing.Optional[float], rag_retrieval_config: typing.Optional[vertexai.preview.rag.utils.resources.RagRetrievalConfig]):'
- rank: 2931
  id: vertexai.preview.rag.utils.resources
  name: resources
  file_path: env/lib/python3.13/site-packages/vertexai/preview/rag/utils/resources.py
  type: MODULE
  group: Orphan
  usage_score: 0
- rank: 2932
  id: vertexai.preview.rag.utils.resources.ANN
  name: ANN
  file_path: env/lib/python3.13/site-packages/vertexai/preview/rag/utils/resources.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: "Config for ANN search.\n\nRagManagedDb uses a tree-based structure to partition data and\nfacilitate faster searches. As a tradeoff, it requires longer\nindexing time and manual triggering of index rebuild via the\nImportRagFiles and UpdateRagCorpus API.\n\nAttributes:\n    tree_depth (int):\n        The depth of the tree-based structure. Only\n        depth values of 2 and 3 are supported.\n\n        Recommended value is 2 if you have if you have\n        O(10K) files in the RagCorpus and set this to 3\n        if more than that.\n\n        Default value is 2.\n    leaf_count (int):\n        Number of leaf nodes in the tree-based structure. Each leaf\n        node contains groups of closely related vectors along with\n        their corresponding centroid.\n\n        Recommended value is 10 * sqrt(num of RagFiles in your\n        RagCorpus).\n\n        Default value is 500."
  constructor_signature: 'def __init__(self, *, tree_depth: typing.Optional[int] = None, leaf_count: typing.Optional[int] = None):'
  properties:
  - signature: 'tree_depth: typing.Optional[int]'
  - signature: 'leaf_count: typing.Optional[int]'
- rank: 2933
  id: vertexai.preview.rag.utils.resources.Basic
  name: Basic
  file_path: env/lib/python3.13/site-packages/vertexai/preview/rag/utils/resources.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Basic tier is a cost-effective and low compute tier suitable for the following cases:


    * Experimenting with RagManagedDb.

    * Small data size.

    * Latency insensitive workload.

    * Only using RAG Engine with external vector DBs.


    NOTE: This is the default tier if not explicitly chosen.'
- rank: 2934
  id: vertexai.preview.rag.utils.resources.ChunkingConfig
  name: ChunkingConfig
  file_path: env/lib/python3.13/site-packages/vertexai/preview/rag/utils/resources.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: "ChunkingConfig.\n\nAttributes:\n    chunk_size: The size of each chunk.\n    chunk_overlap: The size of the overlap between chunks."
  constructor_signature: 'def __init__(self, *, chunk_size: int, chunk_overlap: int):'
  properties:
  - signature: 'chunk_size: int'
  - signature: 'chunk_overlap: int'
- rank: 2935
  id: vertexai.preview.rag.utils.resources.DocumentCorpus
  name: DocumentCorpus
  file_path: env/lib/python3.13/site-packages/vertexai/preview/rag/utils/resources.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: DocumentCorpus.
- rank: 2936
  id: vertexai.preview.rag.utils.resources.EmbeddingModelConfig
  name: EmbeddingModelConfig
  file_path: env/lib/python3.13/site-packages/vertexai/preview/rag/utils/resources.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: "EmbeddingModelConfig.\n\nThe representation of the embedding model config. Users input a 1P embedding\nmodel as a Publisher model resource, or a 1P fine tuned embedding model\nas an Endpoint resource.\n\nAttributes:\n    publisher_model: 1P publisher model resource name. Format:\n        ``publishers/google/models/{model}`` or\n        ``projects/{project}/locations/{location}/publishers/google/models/{model}``\n    endpoint: 1P fine tuned embedding model resource name. Format:\n        ``endpoints/{endpoint}`` or\n        ``projects/{project}/locations/{location}/endpoints/{endpoint}``.\n    model:\n        Output only. The resource name of the model that is deployed\n        on the endpoint. Present only when the endpoint is not a\n        publisher model. Pattern:\n        ``projects/{project}/locations/{location}/models/{model}``\n    model_version_id:\n        Output only. Version ID of the model that is\n        deployed on the endpoint. Present only when the\n      \
    \  endpoint is not a publisher model."
  constructor_signature: 'def __init__(self, *, publisher_model: typing.Optional[str] = None, endpoint: typing.Optional[str] = None, model: typing.Optional[str] = None, model_version_id: typing.Optional[str] = None):'
  properties:
  - signature: 'publisher_model: typing.Optional[str]'
  - signature: 'endpoint: typing.Optional[str]'
  - signature: 'model: typing.Optional[str]'
  - signature: 'model_version_id: typing.Optional[str]'
- rank: 2937
  id: vertexai.preview.rag.utils.resources.Enterprise
  name: Enterprise
  file_path: env/lib/python3.13/site-packages/vertexai/preview/rag/utils/resources.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Enterprise tier offers production grade performance along with


    autoscaling functionality. It is suitable for customers with large

    amounts of data or performance sensitive workloads.


    NOTE: This is deprecated. Use Scaled tier instead.'
- rank: 2938
  id: vertexai.preview.rag.utils.resources.Filter
  name: Filter
  file_path: env/lib/python3.13/site-packages/vertexai/preview/rag/utils/resources.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: "Filter.\n\nAttributes:\n    vector_distance_threshold: Only returns contexts with vector\n        distance smaller than the threshold.\n    vector_similarity_threshold: Only returns contexts with vector\n        similarity larger than the threshold.\n    metadata_filter: String for metadata filtering."
  constructor_signature: 'def __init__(self, *, vector_distance_threshold: typing.Optional[float] = None, vector_similarity_threshold: typing.Optional[float] = None, metadata_filter: typing.Optional[str] = None):'
  properties:
  - signature: 'vector_distance_threshold: typing.Optional[float]'
  - signature: 'vector_similarity_threshold: typing.Optional[float]'
  - signature: 'metadata_filter: typing.Optional[str]'
- rank: 2939
  id: vertexai.preview.rag.utils.resources.HybridSearch
  name: HybridSearch
  file_path: env/lib/python3.13/site-packages/vertexai/preview/rag/utils/resources.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: "HybridSearch.\n\nAttributes:\n    alpha: Alpha value controls the weight between dense and\n        sparse vector search results. The range is [0, 1], while 0\n        means sparse vector search only and 1 means dense vector\n        search only. The default value is 0.5 which balances sparse\n        and dense vector search equally."
  constructor_signature: 'def __init__(self, *, alpha: typing.Optional[float] = None):'
  properties:
  - signature: 'alpha: typing.Optional[float]'
- rank: 2940
  id: vertexai.preview.rag.utils.resources.JiraQuery
  name: JiraQuery
  file_path: env/lib/python3.13/site-packages/vertexai/preview/rag/utils/resources.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: "JiraQuery.\n\nAttributes:\n    email: The Jira email address.\n    jira_projects: A list of Jira projects to import in their entirety.\n    custom_queries: A list of custom JQL Jira queries to import.\n    api_key: The SecretManager version resource name for Jira API access. Format:\n        ``projects/{project}/secrets/{secret}/versions/{version}``\n        See: https://support.atlassian.com/atlassian-account/docs/manage-api-tokens-for-your-atlassian-account/\n    server_uri: The Jira server URI. Format:\n        ``{server}.atlassian.net``"
  constructor_signature: 'def __init__(self, *, email: str, jira_projects: typing.Sequence[str], custom_queries: typing.Sequence[str], api_key: str, server_uri: str):'
  properties:
  - signature: 'email: str'
  - signature: 'jira_projects: typing.Sequence[str]'
  - signature: 'custom_queries: typing.Sequence[str]'
  - signature: 'api_key: str'
  - signature: 'server_uri: str'
- rank: 2941
  id: vertexai.preview.rag.utils.resources.JiraSource
  name: JiraSource
  file_path: env/lib/python3.13/site-packages/vertexai/preview/rag/utils/resources.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: "JiraSource.\n\nAttributes:\n    queries: The Jira queries."
  constructor_signature: 'def __init__(self, *, queries: typing.Sequence[vertexai.preview.rag.utils.resources.JiraQuery]):'
  properties:
  - signature: 'queries: typing.Sequence[vertexai.preview.rag.utils.resources.JiraQuery]'
- rank: 2942
  id: vertexai.preview.rag.utils.resources.KNN
  name: KNN
  file_path: env/lib/python3.13/site-packages/vertexai/preview/rag/utils/resources.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: Config for KNN search.
- rank: 2943
  id: vertexai.preview.rag.utils.resources.LayoutParserConfig
  name: LayoutParserConfig
  file_path: env/lib/python3.13/site-packages/vertexai/preview/rag/utils/resources.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: "Configuration for the Document AI Layout Parser Processor.\n\nAttributes:\n    processor_name (str):\n        The full resource name of a Document AI processor or processor\n        version. The processor must have type `LAYOUT_PARSER_PROCESSOR`.\n        Format:\n        -  `projects/{project_id}/locations/{location}/processors/{processor_id}`\n        -  `projects/{project_id}/locations/{location}/processors/{processor_id}/processorVersions/{processor_version_id}`\n    max_parsing_requests_per_min (int):\n        The maximum number of requests the job is allowed to make to the\n        Document AI processor per minute. Consult\n        https://cloud.google.com/document-ai/quotas and the Quota page for\n        your project to set an appropriate value here. If unspecified, a\n        default value of 120 QPM will be used.\n    global_max_parsing_requests_per_min (int):\n        The maximum number of requests the job is allowed to make to\n        the Document AI processor\
    \ per minute in this project.\n        Consult https://cloud.google.com/document-ai/quotas and the\n        Quota page for your project to set an appropriate value\n        here. If this value is not specified,\n        max_parsing_requests_per_min will be used by indexing\n        pipeline as the global limit."
  constructor_signature: 'def __init__(self, *, processor_name: str, max_parsing_requests_per_min: typing.Optional[int] = None, global_max_parsing_requests_per_min: typing.Optional[int] = None):'
  properties:
  - signature: 'processor_name: str'
  - signature: 'max_parsing_requests_per_min: typing.Optional[int]'
  - signature: 'global_max_parsing_requests_per_min: typing.Optional[int]'
- rank: 2944
  id: vertexai.preview.rag.utils.resources.LlmParserConfig
  name: LlmParserConfig
  file_path: env/lib/python3.13/site-packages/vertexai/preview/rag/utils/resources.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: "Configuration for the LLM Parser Processor.\n\nAttributes:\n    model_name (str):\n        The full resource name of a Vertex AI model. Format:\n        -  `projects/{project_id}/locations/{location}/publishers/google/models/{model_id}`\n        -  `projects/{project_id}/locations/{location}/models/{model_id}`\n    max_parsing_requests_per_min (int):\n        The maximum number of requests the job is allowed to make to the\n        Vertex AI model per minute. Consult\n        https://cloud.google.com/vertex-ai/generative-ai/docs/quotas and\n        the Quota page for your project to set an appropriate value here.\n        If unspecified, a default value of 5000 QPM will be used.\n    global_max_parsing_requests_per_min (int):\n        The maximum number of requests the job is allowed to make to\n        the LLM model per minute in this project. Consult\n        https://cloud.google.com/vertex-ai/generative-ai/docs/quotas\n        and your document size to set an appropriate\
    \ value here. If\n        this value is not specified, max_parsing_requests_per_min\n        will be used by indexing pipeline job as the global limit.\n    custom_parsing_prompt (str):\n        A custom prompt to use for parsing."
  constructor_signature: 'def __init__(self, *, model_name: str, max_parsing_requests_per_min: typing.Optional[int] = None, global_max_parsing_requests_per_min: typing.Optional[int] = None, custom_parsing_prompt: typing.Optional[str] = None):'
  properties:
  - signature: 'model_name: str'
  - signature: 'max_parsing_requests_per_min: typing.Optional[int]'
  - signature: 'global_max_parsing_requests_per_min: typing.Optional[int]'
  - signature: 'custom_parsing_prompt: typing.Optional[str]'
- rank: 2945
  id: vertexai.preview.rag.utils.resources.LlmRanker
  name: LlmRanker
  file_path: env/lib/python3.13/site-packages/vertexai/preview/rag/utils/resources.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: "LlmRanker.\n\nAttributes:\n    model_name: The model name used for ranking. Only Gemini models are\n        supported for now."
  constructor_signature: 'def __init__(self, *, model_name: typing.Optional[str] = None):'
  properties:
  - signature: 'model_name: typing.Optional[str]'
- rank: 2946
  id: vertexai.preview.rag.utils.resources.MemoryCorpus
  name: MemoryCorpus
  file_path: env/lib/python3.13/site-packages/vertexai/preview/rag/utils/resources.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: "MemoryCorpus.\n\nAttributes:\n    llm_parser: The LLM parser to use for the memory corpus."
  constructor_signature: 'def __init__(self, *, llm_parser: typing.Optional[vertexai.preview.rag.utils.resources.LlmParserConfig] = None):'
  properties:
  - signature: 'llm_parser: typing.Optional[vertexai.preview.rag.utils.resources.LlmParserConfig]'
- rank: 2947
  id: vertexai.preview.rag.utils.resources.Pinecone
  name: Pinecone
  file_path: env/lib/python3.13/site-packages/vertexai/preview/rag/utils/resources.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: "Pinecone.\n\nAttributes:\n    index_name: The Pinecone index name.\n    api_key: The SecretManager resource name for the Pinecone DB API token. Format:\n        ``projects/{project}/secrets/{secret}/versions/{version}``"
  constructor_signature: 'def __init__(self, *, index_name: typing.Optional[str] = None, api_key: typing.Optional[str] = None):'
  properties:
  - signature: 'index_name: typing.Optional[str]'
  - signature: 'api_key: typing.Optional[str]'
- rank: 2948
  id: vertexai.preview.rag.utils.resources.RagCorpus
  name: RagCorpus
  file_path: env/lib/python3.13/site-packages/vertexai/preview/rag/utils/resources.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: "RAG corpus(output only).\n\nAttributes:\n    name: Generated resource name. Format:\n        ``projects/{project}/locations/{location}/ragCorpora/{rag_corpus_id}``\n    display_name: Display name that was configured at client side.\n    description: The description of the RagCorpus.\n    corpus_type_config: The corpus type config of the RagCorpus.\n    embedding_model_config: The embedding model config of the RagCorpus.\n        Note: Deprecated. Use backend_config instead.\n    vector_db: The Vector DB of the RagCorpus.\n        Note: Deprecated. Use backend_config instead.\n    vertex_ai_search_config: The Vertex AI Search config of the RagCorpus.\n    backend_config: The backend config of the RagCorpus. It can specify a\n        Vector DB and/or the embedding model config.\n    encryption_spec: The encryption spec of the RagCorpus. Immutable."
  constructor_signature: 'def __init__(self, *, name: typing.Optional[str] = None, display_name: typing.Optional[str] = None, description: typing.Optional[str] = None, corpus_type_config: typing.Optional[vertexai.preview.rag.utils.resources.RagCorpusTypeConfig] = None, embedding_model_config: typing.Optional[vertexai.preview.rag.utils.resources.EmbeddingModelConfig] = None, vector_db: typing.Optional[typing.Union[vertexai.preview.rag.utils.resources.Weaviate, vertexai.preview.rag.utils.resources.VertexFeatureStore, vertexai.preview.rag.utils.resources.VertexVectorSearch, vertexai.preview.rag.utils.resources.Pinecone, vertexai.preview.rag.utils.resources.RagManagedDb]] = None, vertex_ai_search_config: typing.Optional[vertexai.preview.rag.utils.resources.VertexAiSearchConfig] = None, backend_config: typing.Optional[vertexai.preview.rag.utils.resources.RagVectorDbConfig] = None, encryption_spec: typing.Optional[google.cloud.aiplatform_v1beta1.types.EncryptionSpec] = None):'
  properties:
  - signature: 'name: typing.Optional[str]'
  - signature: 'display_name: typing.Optional[str]'
  - signature: 'description: typing.Optional[str]'
  - signature: 'corpus_type_config: typing.Optional[vertexai.preview.rag.utils.resources.RagCorpusTypeConfig]'
  - signature: 'embedding_model_config: typing.Optional[vertexai.preview.rag.utils.resources.EmbeddingModelConfig]'
  - signature: 'vector_db: typing.Optional[typing.Union[vertexai.preview.rag.utils.resources.Weaviate, vertexai.preview.rag.utils.resources.VertexFeatureStore, vertexai.preview.rag.utils.resources.VertexVectorSearch, vertexai.preview.rag.utils.resources.Pinecone, vertexai.preview.rag.utils.resources.RagManagedDb]]'
  - signature: 'vertex_ai_search_config: typing.Optional[vertexai.preview.rag.utils.resources.VertexAiSearchConfig]'
  - signature: 'backend_config: typing.Optional[vertexai.preview.rag.utils.resources.RagVectorDbConfig]'
  - signature: 'encryption_spec: typing.Optional[google.cloud.aiplatform_v1beta1.types.EncryptionSpec]'
- rank: 2949
  id: vertexai.preview.rag.utils.resources.RagCorpusTypeConfig
  name: RagCorpusTypeConfig
  file_path: env/lib/python3.13/site-packages/vertexai/preview/rag/utils/resources.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: "CorpusTypeConfig.\n\nAttributes:\n    corpus_type_config: Can be one of the following: DocumentCorpus,\n        MemoryCorpus."
  constructor_signature: 'def __init__(self, *, corpus_type_config: typing.Optional[typing.Union[vertexai.preview.rag.utils.resources.DocumentCorpus, vertexai.preview.rag.utils.resources.MemoryCorpus]] = None):'
  properties:
  - signature: 'corpus_type_config: typing.Optional[typing.Union[vertexai.preview.rag.utils.resources.DocumentCorpus, vertexai.preview.rag.utils.resources.MemoryCorpus]]'
- rank: 2950
  id: vertexai.preview.rag.utils.resources.RagEmbeddingModelConfig
  name: RagEmbeddingModelConfig
  file_path: env/lib/python3.13/site-packages/vertexai/preview/rag/utils/resources.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: "RagEmbeddingModelConfig.\n\nAttributes:\n    vertex_prediction_endpoint: The Vertex AI Prediction Endpoint resource\n        name. Format:\n        ``projects/{project}/locations/{location}/endpoints/{endpoint}``"
  constructor_signature: 'def __init__(self, *, vertex_prediction_endpoint: typing.Optional[vertexai.preview.rag.utils.resources.VertexPredictionEndpoint] = None):'
  properties:
  - signature: 'vertex_prediction_endpoint: typing.Optional[vertexai.preview.rag.utils.resources.VertexPredictionEndpoint]'
- rank: 2951
  id: vertexai.preview.rag.utils.resources.RagEngineConfig
  name: RagEngineConfig
  file_path: env/lib/python3.13/site-packages/vertexai/preview/rag/utils/resources.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: "RagEngineConfig.\n\nAttributes:\n    name: Generated resource name for singleton resource. Format:\n      ``projects/{project}/locations/{location}/ragEngineConfig``\n    rag_managed_db_config: The config of the RagManagedDb used by RagEngine.\n      The default tier is Basic."
  constructor_signature: 'def __init__(self, *, name: str, rag_managed_db_config: typing.Optional[vertexai.preview.rag.utils.resources.RagManagedDbConfig] = None):'
  properties:
  - signature: 'name: str'
  - signature: 'rag_managed_db_config: typing.Optional[vertexai.preview.rag.utils.resources.RagManagedDbConfig]'
- rank: 2952
  id: vertexai.preview.rag.utils.resources.RagFile
  name: RagFile
  file_path: env/lib/python3.13/site-packages/vertexai/preview/rag/utils/resources.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: "RAG file (output only).\n\nAttributes:\n    name: Generated resource name. Format:\n        ``projects/{project}/locations/{location}/ragCorpora/{rag_corpus_id}/ragFiles/{rag_file}``\n    display_name: Display name that was configured at client side.\n    description: The description of the RagFile."
  constructor_signature: 'def __init__(self, *, name: typing.Optional[str] = None, display_name: typing.Optional[str] = None, description: typing.Optional[str] = None):'
  properties:
  - signature: 'name: typing.Optional[str]'
  - signature: 'display_name: typing.Optional[str]'
  - signature: 'description: typing.Optional[str]'
- rank: 2953
  id: vertexai.preview.rag.utils.resources.RagManagedDb
  name: RagManagedDb
  file_path: env/lib/python3.13/site-packages/vertexai/preview/rag/utils/resources.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: "RagManagedDb.\n\nAttributes:\n    retrieval_strategy: Performs a KNN or ANN search on RagCorpus.\n        Default choice is KNN if not specified."
  constructor_signature: 'def __init__(self, *, retrieval_strategy: typing.Optional[typing.Union[vertexai.preview.rag.utils.resources.KNN, vertexai.preview.rag.utils.resources.ANN]] = None):'
  properties:
  - signature: 'retrieval_strategy: typing.Optional[typing.Union[vertexai.preview.rag.utils.resources.KNN, vertexai.preview.rag.utils.resources.ANN]]'
- rank: 2954
  id: vertexai.preview.rag.utils.resources.RagManagedDbConfig
  name: RagManagedDbConfig
  file_path: env/lib/python3.13/site-packages/vertexai/preview/rag/utils/resources.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: "RagManagedDbConfig.\n\nThe config of the RagManagedDb used by RagEngine.\n\nAttributes:\n    tier: The tier of the RagManagedDb. The default tier is Basic."
  constructor_signature: 'def __init__(self, *, tier: typing.Optional[typing.Union[vertexai.preview.rag.utils.resources.Enterprise, vertexai.preview.rag.utils.resources.Basic, vertexai.preview.rag.utils.resources.Scaled, vertexai.preview.rag.utils.resources.Unprovisioned]] = None):'
  properties:
  - signature: 'tier: typing.Optional[typing.Union[vertexai.preview.rag.utils.resources.Enterprise, vertexai.preview.rag.utils.resources.Basic, vertexai.preview.rag.utils.resources.Scaled, vertexai.preview.rag.utils.resources.Unprovisioned]]'
- rank: 2955
  id: vertexai.preview.rag.utils.resources.RagResource
  name: RagResource
  file_path: env/lib/python3.13/site-packages/vertexai/preview/rag/utils/resources.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: "RagResource.\n\nThe representation of the rag source. It can be used to specify corpus only\nor ragfiles. Currently only support one corpus or multiple files from one\ncorpus. In the future we may open up multiple corpora support.\n\nAttributes:\n    rag_corpus: A Rag corpus resource name or corpus id. Format:\n        ``projects/{project}/locations/{location}/ragCorpora/{rag_corpus_id}``\n        or ``{rag_corpus_id}``.\n    rag_files_id: List of Rag file resource name or file ids in the same corpus. Format:\n        ``{rag_file}``."
  constructor_signature: 'def __init__(self, *, rag_corpus: typing.Optional[str] = None, rag_file_ids: typing.Optional[typing.List[str]] = None):'
  properties:
  - signature: 'rag_corpus: typing.Optional[str]'
  - signature: 'rag_file_ids: typing.Optional[typing.List[str]]'
- rank: 2956
  id: vertexai.preview.rag.utils.resources.RagRetrievalConfig
  name: RagRetrievalConfig
  file_path: env/lib/python3.13/site-packages/vertexai/preview/rag/utils/resources.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: "RagRetrievalConfig.\n\nAttributes:\n    top_k: The number of contexts to retrieve.\n    filter: Config for filters.\n    hybrid_search (google.cloud.aiplatform_v1beta1.types.RagRetrievalConfig.HybridSearch):\n        Config for Hybrid Search.\n    ranking (google.cloud.aiplatform_v1beta1.types.RagRetrievalConfig.Ranking):\n        Config for ranking and reranking."
  constructor_signature: 'def __init__(self, *, top_k: typing.Optional[int] = None, filter: typing.Optional[vertexai.preview.rag.utils.resources.Filter] = None, hybrid_search: typing.Optional[vertexai.preview.rag.utils.resources.HybridSearch] = None, ranking: typing.Optional[vertexai.preview.rag.utils.resources.Ranking] = None):'
  properties:
  - signature: 'top_k: typing.Optional[int]'
  - signature: 'filter: typing.Optional[vertexai.preview.rag.utils.resources.Filter]'
  - signature: 'hybrid_search: typing.Optional[vertexai.preview.rag.utils.resources.HybridSearch]'
  - signature: 'ranking: typing.Optional[vertexai.preview.rag.utils.resources.Ranking]'
- rank: 2957
  id: vertexai.preview.rag.utils.resources.RagVectorDbConfig
  name: RagVectorDbConfig
  file_path: env/lib/python3.13/site-packages/vertexai/preview/rag/utils/resources.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: "RagVectorDbConfig.\n\nAttributes:\n    vector_db: Can be one of the following: Weaviate, VertexFeatureStore,\n        VertexVectorSearch, Pinecone, RagManagedDb.\n    rag_embedding_model_config: The embedding model config of the Vector DB."
  constructor_signature: 'def __init__(self, *, vector_db: typing.Optional[typing.Union[vertexai.preview.rag.utils.resources.Weaviate, vertexai.preview.rag.utils.resources.VertexFeatureStore, vertexai.preview.rag.utils.resources.VertexVectorSearch, vertexai.preview.rag.utils.resources.Pinecone, vertexai.preview.rag.utils.resources.RagManagedDb]] = None, rag_embedding_model_config: typing.Optional[vertexai.preview.rag.utils.resources.RagEmbeddingModelConfig] = None):'
  properties:
  - signature: 'vector_db: typing.Optional[typing.Union[vertexai.preview.rag.utils.resources.Weaviate, vertexai.preview.rag.utils.resources.VertexFeatureStore, vertexai.preview.rag.utils.resources.VertexVectorSearch, vertexai.preview.rag.utils.resources.Pinecone, vertexai.preview.rag.utils.resources.RagManagedDb]]'
  - signature: 'rag_embedding_model_config: typing.Optional[vertexai.preview.rag.utils.resources.RagEmbeddingModelConfig]'
- rank: 2958
  id: vertexai.preview.rag.utils.resources.RankService
  name: RankService
  file_path: env/lib/python3.13/site-packages/vertexai/preview/rag/utils/resources.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: "RankService.\n\nAttributes:\n    model_name: The model name of the rank service. Format:\n        ``semantic-ranker-512@latest``"
  constructor_signature: 'def __init__(self, *, model_name: typing.Optional[str] = None):'
  properties:
  - signature: 'model_name: typing.Optional[str]'
- rank: 2959
  id: vertexai.preview.rag.utils.resources.Ranking
  name: Ranking
  file_path: env/lib/python3.13/site-packages/vertexai/preview/rag/utils/resources.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: "Ranking.\n\nAttributes:\n    rank_service: (google.cloud.aiplatform_v1beta1.types.RagRetrievalConfig.Ranking.RankService)\n            Config for Rank Service.\n    llm_ranker (google.cloud.aiplatform_v1beta1.types.RagRetrievalConfig.Ranking.LlmRanker):\n            Config for LlmRanker."
  constructor_signature: 'def __init__(self, *, rank_service: typing.Optional[vertexai.preview.rag.utils.resources.RankService] = None, llm_ranker: typing.Optional[vertexai.preview.rag.utils.resources.LlmRanker] = None):'
  properties:
  - signature: 'rank_service: typing.Optional[vertexai.preview.rag.utils.resources.RankService]'
  - signature: 'llm_ranker: typing.Optional[vertexai.preview.rag.utils.resources.LlmRanker]'
- rank: 2960
  id: vertexai.preview.rag.utils.resources.Scaled
  name: Scaled
  file_path: env/lib/python3.13/site-packages/vertexai/preview/rag/utils/resources.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Scaled tier offers production grade performance along with


    autoscaling functionality. It is suitable for customers with large

    amounts of data or performance sensitive workloads.'
- rank: 2961
  id: vertexai.preview.rag.utils.resources.SharePointSource
  name: SharePointSource
  file_path: env/lib/python3.13/site-packages/vertexai/preview/rag/utils/resources.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: "SharePointSource.\n\nAttributes:\n    sharepoint_folder_path: The path of the SharePoint folder to download\n        from.\n    sharepoint_folder_id: The ID of the SharePoint folder to download\n        from.\n    drive_name: The name of the drive to download from.\n    drive_id: The ID of the drive to download from.\n    client_id: The Application ID for the app registered in\n        Microsoft Azure Portal. The application must\n        also be configured with MS Graph permissions\n        \"Files.ReadAll\", \"Sites.ReadAll\" and\n        BrowserSiteLists.Read.All.\n    client_secret: The application secret for the app registered\n        in Azure.\n    tenant_id: Unique identifier of the Azure Active\n        Directory Instance.\n    sharepoint_site_name: The name of the SharePoint site to download\n        from. This can be the site name or the site id."
  constructor_signature: 'def __init__(self, *, sharepoint_folder_path: typing.Optional[str] = None, sharepoint_folder_id: typing.Optional[str] = None, drive_name: typing.Optional[str] = None, drive_id: typing.Optional[str] = None, client_id: str = None, client_secret: str = None, tenant_id: str = None, sharepoint_site_name: str = None):'
  properties:
  - signature: 'sharepoint_folder_path: typing.Optional[str]'
  - signature: 'sharepoint_folder_id: typing.Optional[str]'
  - signature: 'drive_name: typing.Optional[str]'
  - signature: 'drive_id: typing.Optional[str]'
  - signature: 'client_id: str'
  - signature: 'client_secret: str'
  - signature: 'tenant_id: str'
  - signature: 'sharepoint_site_name: str'
- rank: 2962
  id: vertexai.preview.rag.utils.resources.SharePointSources
  name: SharePointSources
  file_path: env/lib/python3.13/site-packages/vertexai/preview/rag/utils/resources.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: "SharePointSources.\n\nAttributes:\n    share_point_sources: The SharePoint sources."
  constructor_signature: 'def __init__(self, *, share_point_sources: typing.Sequence[vertexai.preview.rag.utils.resources.SharePointSource]):'
  properties:
  - signature: 'share_point_sources: typing.Sequence[vertexai.preview.rag.utils.resources.SharePointSource]'
- rank: 2963
  id: vertexai.preview.rag.utils.resources.SlackChannel
  name: SlackChannel
  file_path: env/lib/python3.13/site-packages/vertexai/preview/rag/utils/resources.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: "SlackChannel.\n\nAttributes:\n    channel_id: The Slack channel ID.\n    api_key: The SecretManager resource name for the Slack API token. Format:\n        ``projects/{project}/secrets/{secret}/versions/{version}``\n        See: https://api.slack.com/tutorials/tracks/getting-a-token.\n    start_time: The starting timestamp for messages to import.\n    end_time: The ending timestamp for messages to import."
  constructor_signature: 'def __init__(self, *, channel_id: str, api_key: str, start_time: typing.Optional[google.protobuf.timestamp_pb2.Timestamp] = None, end_time: typing.Optional[google.protobuf.timestamp_pb2.Timestamp] = None):'
  properties:
  - signature: 'channel_id: str'
  - signature: 'api_key: str'
  - signature: 'start_time: typing.Optional[google.protobuf.timestamp_pb2.Timestamp]'
  - signature: 'end_time: typing.Optional[google.protobuf.timestamp_pb2.Timestamp]'
- rank: 2964
  id: vertexai.preview.rag.utils.resources.SlackChannelsSource
  name: SlackChannelsSource
  file_path: env/lib/python3.13/site-packages/vertexai/preview/rag/utils/resources.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: "SlackChannelsSource.\n\nAttributes:\n    channels: The Slack channels."
  constructor_signature: 'def __init__(self, *, channels: typing.Sequence[vertexai.preview.rag.utils.resources.SlackChannel]):'
  properties:
  - signature: 'channels: typing.Sequence[vertexai.preview.rag.utils.resources.SlackChannel]'
- rank: 2965
  id: vertexai.preview.rag.utils.resources.TransformationConfig
  name: TransformationConfig
  file_path: env/lib/python3.13/site-packages/vertexai/preview/rag/utils/resources.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: "TransformationConfig.\n\nAttributes:\n    chunking_config: The chunking config."
  constructor_signature: 'def __init__(self, *, chunking_config: typing.Optional[vertexai.preview.rag.utils.resources.ChunkingConfig] = None):'
  properties:
  - signature: 'chunking_config: typing.Optional[vertexai.preview.rag.utils.resources.ChunkingConfig]'
- rank: 2966
  id: vertexai.preview.rag.utils.resources.Unprovisioned
  name: Unprovisioned
  file_path: env/lib/python3.13/site-packages/vertexai/preview/rag/utils/resources.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Disables the RAG Engine service and deletes all your data held within

    this service. This will halt the billing of the service.


    NOTE: Once deleted the data cannot be recovered. To start using

    RAG Engine again, you will need to update the tier by calling the

    UpdateRagEngineConfig API.'
- rank: 2967
  id: vertexai.preview.rag.utils.resources.VertexAiSearchConfig
  name: VertexAiSearchConfig
  file_path: env/lib/python3.13/site-packages/vertexai/preview/rag/utils/resources.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: "VertexAiSearchConfig.\n\nAttributes:\n    serving_config: The resource name of the Vertex AI Search serving config.\n        Format:\n            ``projects/{project}/locations/{location}/collections/{collection}/engines/{engine}/servingConfigs/{serving_config}``\n        or\n            ``projects/{project}/locations/{location}/collections/{collection}/dataStores/{data_store}/servingConfigs/{serving_config}``"
  constructor_signature: 'def __init__(self, *, serving_config: typing.Optional[str] = None):'
  properties:
  - signature: 'serving_config: typing.Optional[str]'
- rank: 2968
  id: vertexai.preview.rag.utils.resources.VertexFeatureStore
  name: VertexFeatureStore
  file_path: env/lib/python3.13/site-packages/vertexai/preview/rag/utils/resources.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: "VertexFeatureStore.\n\nAttributes:\n    resource_name: The resource name of the FeatureView. Format:\n        ``projects/{project}/locations/{location}/featureOnlineStores/\n          {feature_online_store}/featureViews/{feature_view}``"
  constructor_signature: 'def __init__(self, *, resource_name: typing.Optional[str] = None):'
  properties:
  - signature: 'resource_name: typing.Optional[str]'
- rank: 2969
  id: vertexai.preview.rag.utils.resources.VertexPredictionEndpoint
  name: VertexPredictionEndpoint
  file_path: env/lib/python3.13/site-packages/vertexai/preview/rag/utils/resources.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: "VertexPredictionEndpoint.\n\nAttributes:\n    publisher_model: 1P publisher model resource name. Format:\n        ``publishers/google/models/{model}`` or\n        ``projects/{project}/locations/{location}/publishers/google/models/{model}``\n    endpoint: 1P fine tuned embedding model resource name. Format:\n        ``endpoints/{endpoint}`` or\n        ``projects/{project}/locations/{location}/endpoints/{endpoint}``.\n    model:\n        Output only. The resource name of the model that is deployed\n        on the endpoint. Present only when the endpoint is not a\n        publisher model. Pattern:\n        ``projects/{project}/locations/{location}/models/{model}``\n    model_version_id:\n        Output only. Version ID of the model that is\n        deployed on the endpoint. Present only when the\n        endpoint is not a publisher model."
  constructor_signature: 'def __init__(self, *, endpoint: typing.Optional[str] = None, publisher_model: typing.Optional[str] = None, model: typing.Optional[str] = None, model_version_id: typing.Optional[str] = None):'
  properties:
  - signature: 'endpoint: typing.Optional[str]'
  - signature: 'publisher_model: typing.Optional[str]'
  - signature: 'model: typing.Optional[str]'
  - signature: 'model_version_id: typing.Optional[str]'
- rank: 2970
  id: vertexai.preview.rag.utils.resources.VertexVectorSearch
  name: VertexVectorSearch
  file_path: env/lib/python3.13/site-packages/vertexai/preview/rag/utils/resources.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: "VertexVectorSearch.\n\nAttributes:\n    index_endpoint (str):\n        The resource name of the Index Endpoint. Format:\n        ``projects/{project}/locations/{location}/indexEndpoints/{index_endpoint}``\n    index (str):\n        The resource name of the Index. Format:\n        ``projects/{project}/locations/{location}/indexes/{index}``"
  constructor_signature: 'def __init__(self, *, index_endpoint: typing.Optional[str] = None, index: typing.Optional[str] = None):'
  properties:
  - signature: 'index_endpoint: typing.Optional[str]'
  - signature: 'index: typing.Optional[str]'
- rank: 2971
  id: vertexai.preview.rag.utils.resources.Weaviate
  name: Weaviate
  file_path: env/lib/python3.13/site-packages/vertexai/preview/rag/utils/resources.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: "Weaviate.\n\nAttributes:\n    weaviate_http_endpoint: The Weaviate DB instance HTTP endpoint\n    collection_name: The corresponding Weaviate collection this corpus maps to\n    api_key: The SecretManager resource name for the Weaviate DB API token. Format:\n        ``projects/{project}/secrets/{secret}/versions/{version}``"
  constructor_signature: 'def __init__(self, *, weaviate_http_endpoint: typing.Optional[str] = None, collection_name: typing.Optional[str] = None, api_key: typing.Optional[str] = None):'
  properties:
  - signature: 'weaviate_http_endpoint: typing.Optional[str]'
  - signature: 'collection_name: typing.Optional[str]'
  - signature: 'api_key: typing.Optional[str]'
- rank: 2972
  id: vertexai.preview.reasoning_engines
  name: reasoning_engines
  file_path: env/lib/python3.13/site-packages/vertexai/preview/reasoning_engines/__init__.py
  type: MODULE
  group: Orphan
  usage_score: 0
  docstring: Classes for working with reasoning engines.
- rank: 2973
  id: vertexai.preview.reasoning_engines.templates.a2a
  name: a2a
  file_path: env/lib/python3.13/site-packages/vertexai/preview/reasoning_engines/templates/a2a.py
  type: MODULE
  group: Orphan
  usage_score: 0
  methods:
  - signature: 'def create_agent_card(agent_name: typing.Optional[str], description: typing.Optional[str], skills: typing.Optional[typing.List[a2a.types.AgentSkill]], agent_card: typing.Optional[typing.Dict[str, typing.Any]], default_input_modes: typing.Optional[typing.List[str]], default_output_modes: typing.Optional[typing.List[str]]) -> a2a.types.AgentCard:'
    docstring: "Creates an AgentCard object.\n\nThe function can be called in two ways:\n1. By providing the individual parameters: agent_name, description, and skills.\n2. By providing a single dictionary containing all the data.\n\nIf a dictionary is provided, the other parameters are ignored.\n\nArgs:\n    agent_name (Optional[str]): The name of the agent.\n    description (Optional[str]): A description of the agent.\n    skills (Optional[List[AgentSkill]]): A list of AgentSkills.\n    agent_card (Optional[Dict[str, Any]]): Agent Card as a dictionary.\n    default_input_modes (Optional[List[str]]): A list of input modes,\n        default to [\"text/plain\"].\n    default_output_modes (Optional[List[str]]): A list of output modes,\n        default to [\"application/json\"].\n\nReturns:\n    AgentCard: A fully constructed AgentCard object.\n\nRaises:\n    ValueError: If neither a dictionary nor the required parameters are provided."
  - signature: 'def default_a2a_agent() -> vertexai.preview.reasoning_engines.templates.a2a.A2aAgent:'
    docstring: Creates a default A2aAgent instance.
- rank: 2974
  id: vertexai.preview.reasoning_engines.templates.a2a.A2aAgent
  name: A2aAgent
  file_path: env/lib/python3.13/site-packages/vertexai/preview/reasoning_engines/templates/a2a.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: A class to initialize and set up an Agent-to-Agent application.
  constructor_signature: 'def __init__(self, *, agent_card: a2a.types.AgentCard, task_store_builder: typing.Callable[Ellipsis, a2a.server.tasks.TaskStore]=None, task_store_kwargs: typing.Optional[typing.Mapping[str, typing.Any]]=None, agent_executor_kwargs: typing.Optional[typing.Mapping[str, typing.Any]]=None, agent_executor_builder: typing.Optional[typing.Callable[Ellipsis, a2a.server.agent_execution.AgentExecutor]]=None, request_handler_kwargs: typing.Optional[typing.Mapping[str, typing.Any]]=None, request_handler_builder: typing.Optional[typing.Callable[Ellipsis, a2a.server.request_handlers.RequestHandler]]=None, extended_agent_card: a2a.types.AgentCard=None):'
  methods:
  - signature: 'def clone(self) -> vertexai.preview.reasoning_engines.templates.a2a.A2aAgent:'
    docstring: Clones the A2A agent.
  - signature: 'def set_up(self):'
    docstring: Sets up the A2A application.
  - signature: 'def on_message_send(self, request: fastapi.Request, context: a2a.server.context.ServerCallContext) -> dict[str, typing.Any]:'
  - signature: 'def on_cancel_task(self, request: fastapi.Request, context: a2a.server.context.ServerCallContext) -> dict[str, typing.Any]:'
  - signature: 'def on_get_task(self, request: fastapi.Request, context: a2a.server.context.ServerCallContext) -> dict[str, typing.Any]:'
  - signature: 'def handle_authenticated_agent_card(self, request: fastapi.Request, context: a2a.server.context.ServerCallContext) -> dict[str, typing.Any]:'
  - signature: 'def register_operations(self) -> typing.Dict[str, typing.List[str]]:'
    docstring: Registers the operations of the A2A Agent.
- rank: 2975
  id: vertexai.preview.reasoning_engines.templates.a2a.A2aAgent.__init__
  name: __init__
  file_path: env/lib/python3.13/site-packages/vertexai/preview/reasoning_engines/templates/a2a.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: Initializes the A2A agent.
  signature: 'def __init__(self, *, agent_card: a2a.types.AgentCard, task_store_builder: typing.Callable[Ellipsis, a2a.server.tasks.TaskStore]=None, task_store_kwargs: typing.Optional[typing.Mapping[str, typing.Any]]=None, agent_executor_kwargs: typing.Optional[typing.Mapping[str, typing.Any]]=None, agent_executor_builder: typing.Optional[typing.Callable[Ellipsis, a2a.server.agent_execution.AgentExecutor]]=None, request_handler_kwargs: typing.Optional[typing.Mapping[str, typing.Any]]=None, request_handler_builder: typing.Optional[typing.Callable[Ellipsis, a2a.server.request_handlers.RequestHandler]]=None, extended_agent_card: a2a.types.AgentCard=None):'
- rank: 2976
  id: vertexai.preview.reasoning_engines.templates.a2a.A2aAgent.clone
  name: clone
  file_path: env/lib/python3.13/site-packages/vertexai/preview/reasoning_engines/templates/a2a.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: Clones the A2A agent.
  signature: 'def clone(self) -> vertexai.preview.reasoning_engines.templates.a2a.A2aAgent:'
- rank: 2977
  id: vertexai.preview.reasoning_engines.templates.a2a.A2aAgent.handle_authenticated_agent_card
  name: handle_authenticated_agent_card
  file_path: env/lib/python3.13/site-packages/vertexai/preview/reasoning_engines/templates/a2a.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def handle_authenticated_agent_card(self, request: fastapi.Request, context: a2a.server.context.ServerCallContext) -> dict[str, typing.Any]:'
- rank: 2978
  id: vertexai.preview.reasoning_engines.templates.a2a.A2aAgent.on_cancel_task
  name: on_cancel_task
  file_path: env/lib/python3.13/site-packages/vertexai/preview/reasoning_engines/templates/a2a.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def on_cancel_task(self, request: fastapi.Request, context: a2a.server.context.ServerCallContext) -> dict[str, typing.Any]:'
- rank: 2979
  id: vertexai.preview.reasoning_engines.templates.a2a.A2aAgent.on_get_task
  name: on_get_task
  file_path: env/lib/python3.13/site-packages/vertexai/preview/reasoning_engines/templates/a2a.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def on_get_task(self, request: fastapi.Request, context: a2a.server.context.ServerCallContext) -> dict[str, typing.Any]:'
- rank: 2980
  id: vertexai.preview.reasoning_engines.templates.a2a.A2aAgent.on_message_send
  name: on_message_send
  file_path: env/lib/python3.13/site-packages/vertexai/preview/reasoning_engines/templates/a2a.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def on_message_send(self, request: fastapi.Request, context: a2a.server.context.ServerCallContext) -> dict[str, typing.Any]:'
- rank: 2981
  id: vertexai.preview.reasoning_engines.templates.a2a.A2aAgent.register_operations
  name: register_operations
  file_path: env/lib/python3.13/site-packages/vertexai/preview/reasoning_engines/templates/a2a.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: Registers the operations of the A2A Agent.
  signature: 'def register_operations(self) -> typing.Dict[str, typing.List[str]]:'
- rank: 2982
  id: vertexai.preview.reasoning_engines.templates.a2a.A2aAgent.set_up
  name: set_up
  file_path: env/lib/python3.13/site-packages/vertexai/preview/reasoning_engines/templates/a2a.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: Sets up the A2A application.
  signature: 'def set_up(self):'
- rank: 2983
  id: vertexai.preview.reasoning_engines.templates.a2a.HelloWorldAgentExecutor
  name: HelloWorldAgentExecutor
  file_path: env/lib/python3.13/site-packages/vertexai/preview/reasoning_engines/templates/a2a.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Hello World Agent Executor.


    [Note: Inherited members from AgentExecutor are omitted.]'
  methods:
  - signature: 'def get_agent_response(self) -> str:'
  - signature: 'def execute(self, context: a2a.server.agent_execution.RequestContext, event_queue: a2a.server.events.EventQueue) -> None:'
  - signature: 'def cancel(self, context: a2a.server.agent_execution.RequestContext, event_queue: a2a.server.events.EventQueue) -> None:'
  omitted_inherited_members_from:
  - AgentExecutor
- rank: 2984
  id: vertexai.preview.reasoning_engines.templates.a2a.HelloWorldAgentExecutor.cancel
  name: cancel
  file_path: env/lib/python3.13/site-packages/vertexai/preview/reasoning_engines/templates/a2a.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def cancel(self, context: a2a.server.agent_execution.RequestContext, event_queue: a2a.server.events.EventQueue) -> None:'
- rank: 2985
  id: vertexai.preview.reasoning_engines.templates.a2a.HelloWorldAgentExecutor.execute
  name: execute
  file_path: env/lib/python3.13/site-packages/vertexai/preview/reasoning_engines/templates/a2a.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def execute(self, context: a2a.server.agent_execution.RequestContext, event_queue: a2a.server.events.EventQueue) -> None:'
- rank: 2986
  id: vertexai.preview.reasoning_engines.templates.a2a.create_agent_card
  name: create_agent_card
  file_path: env/lib/python3.13/site-packages/vertexai/preview/reasoning_engines/templates/a2a.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Creates an AgentCard object.\n\nThe function can be called in two ways:\n1. By providing the individual parameters: agent_name, description, and skills.\n2. By providing a single dictionary containing all the data.\n\nIf a dictionary is provided, the other parameters are ignored.\n\nArgs:\n    agent_name (Optional[str]): The name of the agent.\n    description (Optional[str]): A description of the agent.\n    skills (Optional[List[AgentSkill]]): A list of AgentSkills.\n    agent_card (Optional[Dict[str, Any]]): Agent Card as a dictionary.\n    default_input_modes (Optional[List[str]]): A list of input modes,\n        default to [\"text/plain\"].\n    default_output_modes (Optional[List[str]]): A list of output modes,\n        default to [\"application/json\"].\n\nReturns:\n    AgentCard: A fully constructed AgentCard object.\n\nRaises:\n    ValueError: If neither a dictionary nor the required parameters are provided."
  signature: 'def create_agent_card(agent_name: typing.Optional[str], description: typing.Optional[str], skills: typing.Optional[typing.List[a2a.types.AgentSkill]], agent_card: typing.Optional[typing.Dict[str, typing.Any]], default_input_modes: typing.Optional[typing.List[str]], default_output_modes: typing.Optional[typing.List[str]]) -> a2a.types.AgentCard:'
- rank: 2987
  id: vertexai.preview.reasoning_engines.templates.a2a.default_a2a_agent
  name: default_a2a_agent
  file_path: env/lib/python3.13/site-packages/vertexai/preview/reasoning_engines/templates/a2a.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: Creates a default A2aAgent instance.
  signature: 'def default_a2a_agent() -> vertexai.preview.reasoning_engines.templates.a2a.A2aAgent:'
- rank: 2988
  id: vertexai.preview.reasoning_engines.templates.adk
  name: adk
  file_path: env/lib/python3.13/site-packages/vertexai/preview/reasoning_engines/templates/adk.py
  type: MODULE
  group: Orphan
  usage_score: 0
  methods:
  - signature: 'def get_adk_version() -> typing.Optional[str]:'
    docstring: Returns the version of the ADK package.
  - signature: 'def is_version_sufficient(version_to_check: str) -> bool:'
    docstring: "Compares the existing version of ADK with the required version.\n\nArgs:\n    version_to_check: The version string to check.\n\nReturns:\n    True if the existing version is sufficient, False otherwise."
- rank: 2989
  id: vertexai.preview.reasoning_engines.templates.adk.AdkApp
  name: AdkApp
  file_path: env/lib/python3.13/site-packages/vertexai/preview/reasoning_engines/templates/adk.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: An ADK Application.
  constructor_signature: 'def __init__(self, *, agent: google.adk.agents.BaseAgent, plugins: typing.Optional[typing.List[google.adk.plugins.base_plugin.BasePlugin]]=None, enable_tracing: typing.Optional[bool]=None, session_service_builder: typing.Optional[typing.Callable[Ellipsis, google.adk.sessions.BaseSessionService]]=None, artifact_service_builder: typing.Optional[typing.Callable[Ellipsis, google.adk.artifacts.BaseArtifactService]]=None, memory_service_builder: typing.Optional[typing.Callable[Ellipsis, google.adk.memory.BaseMemoryService]]=None, credential_service_builder: typing.Optional[typing.Callable[Ellipsis, google.adk.auth.credential_service.base_credential_service.BaseCredentialService]]=None, env_vars: typing.Optional[typing.Dict[str, str]]=None):'
  methods:
  - signature: 'def clone(self):'
    docstring: Returns a clone of the ADK application.
  - signature: 'def set_up(self):'
    docstring: Sets up the ADK application.
  - signature: 'def stream_query(self, *, message: typing.Union[str, typing.Dict[str, typing.Any]], user_id: str, session_id: typing.Optional[str]=None, run_config: typing.Optional[typing.Dict[str, typing.Any]]=None):'
    docstring: "Streams responses from the ADK application in response to a message.\n\nArgs:\n    message (Union[str, Dict[str, Any]]):\n        Required. The message to stream responses for.\n    user_id (str):\n        Required. The ID of the user.\n    session_id (str):\n        Optional. The ID of the session. If not provided, a new\n        session will be created for the user.\n    run_config (Optional[Dict[str, Any]]):\n        Optional. The run config to use for the query. If you want to\n        pass in a `run_config` pydantic object, you can pass in a dict\n        representing it as `run_config.model_dump(mode=\"json\")`.\n    **kwargs (dict[str, Any]):\n        Optional. Additional keyword arguments to pass to the\n        runner.\n\nYields:\n    The output of querying the ADK application."
  - signature: 'def async_stream_query(self, *, message: typing.Union[str, typing.Dict[str, typing.Any]], user_id: str, session_id: typing.Optional[str]=None, run_config: typing.Optional[typing.Dict[str, typing.Any]]=None) -> typing.AsyncIterable[typing.Dict[str, typing.Any]]:'
    docstring: "Streams responses asynchronously from the ADK application.\n\nArgs:\n    message (str):\n        Required. The message to stream responses for.\n    user_id (str):\n        Required. The ID of the user.\n    session_id (str):\n        Optional. The ID of the session. If not provided, a new\n        session will be created for the user.\n    run_config (Optional[Dict[str, Any]]):\n        Optional. The run config to use for the query. If you want to\n        pass in a `run_config` pydantic object, you can pass in a dict\n        representing it as `run_config.model_dump(mode=\"json\")`.\n    **kwargs (dict[str, Any]):\n        Optional. Additional keyword arguments to pass to the\n        runner.\n\nYields:\n    Event dictionaries asynchronously."
  - signature: 'def streaming_agent_run_with_events(self, request_json: str):'
  - signature: 'def bidi_stream_query(self, request_queue: typing.Any) -> typing.AsyncIterable[typing.Any]:'
    docstring: "Bidi streaming query the ADK application.\n\nArgs:\n    request_queue:\n        The queue of requests to stream responses for, with the type of\n        asyncio.Queue[Any].\n\nRaises:\n    TypeError: If the request_queue is not an asyncio.Queue instance.\n    ValueError: If the first request does not have a user_id.\n    ValidationError: If failed to convert to LiveRequest.\n\nYields:\n    The stream responses of querying the ADK application."
  - signature: 'def async_get_session(self, *, user_id: str, session_id: str):'
    docstring: "Get a session for the given user.\n\nArgs:\n    user_id (str):\n        Required. The ID of the user.\n    session_id (str):\n        Required. The ID of the session.\n    **kwargs (dict[str, Any]):\n        Optional. Additional keyword arguments to pass to the\n        session service.\n\nReturns:\n    Session: The session instance (if any). It returns None if the\n    session is not found.\n\nRaises:\n    RuntimeError: If the session is not found."
  - signature: 'def get_session(self, *, user_id: str, session_id: str):'
    docstring: Get a session for the given user.
  - signature: 'def async_list_sessions(self, *, user_id: str):'
    docstring: "List sessions for the given user.\n\nArgs:\n    user_id (str):\n        Required. The ID of the user.\n    **kwargs (dict[str, Any]):\n        Optional. Additional keyword arguments to pass to the\n        session service.\n\nReturns:\n    ListSessionsResponse: The list of sessions."
  - signature: 'def list_sessions(self, *, user_id: str):'
    docstring: List sessions for the given user.
  - signature: 'def async_create_session(self, *, user_id: str, session_id: typing.Optional[str]=None, state: typing.Optional[typing.Dict[str, typing.Any]]=None):'
    docstring: "Creates a new session.\n\nArgs:\n    user_id (str):\n        Required. The ID of the user.\n    session_id (str):\n        Optional. The ID of the session. If not provided, an ID\n        will be be generated for the session.\n    state (dict[str, Any]):\n        Optional. The initial state of the session.\n    **kwargs (dict[str, Any]):\n        Optional. Additional keyword arguments to pass to the\n        session service.\n\nReturns:\n    Session: The newly created session instance."
  - signature: 'def create_session(self, *, user_id: str, session_id: typing.Optional[str]=None, state: typing.Optional[typing.Dict[str, typing.Any]]=None):'
    docstring: Creates a new session.
  - signature: 'def async_delete_session(self, *, user_id: str, session_id: str):'
    docstring: "Deletes a session for the given user.\n\nArgs:\n    user_id (str):\n        Required. The ID of the user.\n    session_id (str):\n        Required. The ID of the session.\n    **kwargs (dict[str, Any]):\n        Optional. Additional keyword arguments to pass to the\n        session service."
  - signature: 'def delete_session(self, *, user_id: str, session_id: str):'
    docstring: Deletes a session for the given user.
  - signature: 'def async_add_session_to_memory(self, *, session: typing.Dict[str, typing.Any]):'
    docstring: "Generates memories.\n\nArgs:\n    session (Dict[str, Any]):\n        Required. The session to use for generating memories. It should\n        be a dictionary representing an ADK Session object, e.g.\n        session.model_dump(mode=\"json\")."
  - signature: 'def async_search_memory(self, *, user_id: str, query: str):'
    docstring: "Searches memories for the given user.\n\nArgs:\n    user_id: The id of the user.\n    query: The query to match the memories on.\n\nReturns:\n    A SearchMemoryResponse containing the matching memories."
  - signature: 'def register_operations(self) -> typing.Dict[str, typing.List[str]]:'
    docstring: Registers the operations of the ADK application.
  - signature: 'def project_id(self) -> typing.Optional[str]:'
  properties:
  - signature: 'agent_framework: str'
- rank: 2990
  id: vertexai.preview.reasoning_engines.templates.adk.AdkApp.__init__
  name: __init__
  file_path: env/lib/python3.13/site-packages/vertexai/preview/reasoning_engines/templates/adk.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: An ADK Application.
  signature: 'def __init__(self, *, agent: google.adk.agents.BaseAgent, plugins: typing.Optional[typing.List[google.adk.plugins.base_plugin.BasePlugin]]=None, enable_tracing: typing.Optional[bool]=None, session_service_builder: typing.Optional[typing.Callable[Ellipsis, google.adk.sessions.BaseSessionService]]=None, artifact_service_builder: typing.Optional[typing.Callable[Ellipsis, google.adk.artifacts.BaseArtifactService]]=None, memory_service_builder: typing.Optional[typing.Callable[Ellipsis, google.adk.memory.BaseMemoryService]]=None, credential_service_builder: typing.Optional[typing.Callable[Ellipsis, google.adk.auth.credential_service.base_credential_service.BaseCredentialService]]=None, env_vars: typing.Optional[typing.Dict[str, str]]=None):'
- rank: 2991
  id: vertexai.preview.reasoning_engines.templates.adk.AdkApp.async_add_session_to_memory
  name: async_add_session_to_memory
  file_path: env/lib/python3.13/site-packages/vertexai/preview/reasoning_engines/templates/adk.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Generates memories.\n\nArgs:\n    session (Dict[str, Any]):\n        Required. The session to use for generating memories. It should\n        be a dictionary representing an ADK Session object, e.g.\n        session.model_dump(mode=\"json\")."
  signature: 'def async_add_session_to_memory(self, *, session: typing.Dict[str, typing.Any]):'
- rank: 2992
  id: vertexai.preview.reasoning_engines.templates.adk.AdkApp.async_create_session
  name: async_create_session
  file_path: env/lib/python3.13/site-packages/vertexai/preview/reasoning_engines/templates/adk.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Creates a new session.\n\nArgs:\n    user_id (str):\n        Required. The ID of the user.\n    session_id (str):\n        Optional. The ID of the session. If not provided, an ID\n        will be be generated for the session.\n    state (dict[str, Any]):\n        Optional. The initial state of the session.\n    **kwargs (dict[str, Any]):\n        Optional. Additional keyword arguments to pass to the\n        session service.\n\nReturns:\n    Session: The newly created session instance."
  signature: 'def async_create_session(self, *, user_id: str, session_id: typing.Optional[str]=None, state: typing.Optional[typing.Dict[str, typing.Any]]=None):'
- rank: 2993
  id: vertexai.preview.reasoning_engines.templates.adk.AdkApp.async_delete_session
  name: async_delete_session
  file_path: env/lib/python3.13/site-packages/vertexai/preview/reasoning_engines/templates/adk.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Deletes a session for the given user.\n\nArgs:\n    user_id (str):\n        Required. The ID of the user.\n    session_id (str):\n        Required. The ID of the session.\n    **kwargs (dict[str, Any]):\n        Optional. Additional keyword arguments to pass to the\n        session service."
  signature: 'def async_delete_session(self, *, user_id: str, session_id: str):'
- rank: 2994
  id: vertexai.preview.reasoning_engines.templates.adk.AdkApp.async_get_session
  name: async_get_session
  file_path: env/lib/python3.13/site-packages/vertexai/preview/reasoning_engines/templates/adk.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Get a session for the given user.\n\nArgs:\n    user_id (str):\n        Required. The ID of the user.\n    session_id (str):\n        Required. The ID of the session.\n    **kwargs (dict[str, Any]):\n        Optional. Additional keyword arguments to pass to the\n        session service.\n\nReturns:\n    Session: The session instance (if any). It returns None if the\n    session is not found.\n\nRaises:\n    RuntimeError: If the session is not found."
  signature: 'def async_get_session(self, *, user_id: str, session_id: str):'
- rank: 2995
  id: vertexai.preview.reasoning_engines.templates.adk.AdkApp.async_list_sessions
  name: async_list_sessions
  file_path: env/lib/python3.13/site-packages/vertexai/preview/reasoning_engines/templates/adk.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "List sessions for the given user.\n\nArgs:\n    user_id (str):\n        Required. The ID of the user.\n    **kwargs (dict[str, Any]):\n        Optional. Additional keyword arguments to pass to the\n        session service.\n\nReturns:\n    ListSessionsResponse: The list of sessions."
  signature: 'def async_list_sessions(self, *, user_id: str):'
- rank: 2996
  id: vertexai.preview.reasoning_engines.templates.adk.AdkApp.async_search_memory
  name: async_search_memory
  file_path: env/lib/python3.13/site-packages/vertexai/preview/reasoning_engines/templates/adk.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Searches memories for the given user.\n\nArgs:\n    user_id: The id of the user.\n    query: The query to match the memories on.\n\nReturns:\n    A SearchMemoryResponse containing the matching memories."
  signature: 'def async_search_memory(self, *, user_id: str, query: str):'
- rank: 2997
  id: vertexai.preview.reasoning_engines.templates.adk.AdkApp.async_stream_query
  name: async_stream_query
  file_path: env/lib/python3.13/site-packages/vertexai/preview/reasoning_engines/templates/adk.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Streams responses asynchronously from the ADK application.\n\nArgs:\n    message (str):\n        Required. The message to stream responses for.\n    user_id (str):\n        Required. The ID of the user.\n    session_id (str):\n        Optional. The ID of the session. If not provided, a new\n        session will be created for the user.\n    run_config (Optional[Dict[str, Any]]):\n        Optional. The run config to use for the query. If you want to\n        pass in a `run_config` pydantic object, you can pass in a dict\n        representing it as `run_config.model_dump(mode=\"json\")`.\n    **kwargs (dict[str, Any]):\n        Optional. Additional keyword arguments to pass to the\n        runner.\n\nYields:\n    Event dictionaries asynchronously."
  signature: 'def async_stream_query(self, *, message: typing.Union[str, typing.Dict[str, typing.Any]], user_id: str, session_id: typing.Optional[str]=None, run_config: typing.Optional[typing.Dict[str, typing.Any]]=None) -> typing.AsyncIterable[typing.Dict[str, typing.Any]]:'
- rank: 2998
  id: vertexai.preview.reasoning_engines.templates.adk.AdkApp.bidi_stream_query
  name: bidi_stream_query
  file_path: env/lib/python3.13/site-packages/vertexai/preview/reasoning_engines/templates/adk.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Bidi streaming query the ADK application.\n\nArgs:\n    request_queue:\n        The queue of requests to stream responses for, with the type of\n        asyncio.Queue[Any].\n\nRaises:\n    TypeError: If the request_queue is not an asyncio.Queue instance.\n    ValueError: If the first request does not have a user_id.\n    ValidationError: If failed to convert to LiveRequest.\n\nYields:\n    The stream responses of querying the ADK application."
  signature: 'def bidi_stream_query(self, request_queue: typing.Any) -> typing.AsyncIterable[typing.Any]:'
- rank: 2999
  id: vertexai.preview.reasoning_engines.templates.adk.AdkApp.clone
  name: clone
  file_path: env/lib/python3.13/site-packages/vertexai/preview/reasoning_engines/templates/adk.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: Returns a clone of the ADK application.
  signature: 'def clone(self):'
- rank: 3000
  id: vertexai.preview.reasoning_engines.templates.adk.AdkApp.create_session
  name: create_session
  file_path: env/lib/python3.13/site-packages/vertexai/preview/reasoning_engines/templates/adk.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: Creates a new session.
  signature: 'def create_session(self, *, user_id: str, session_id: typing.Optional[str]=None, state: typing.Optional[typing.Dict[str, typing.Any]]=None):'
- rank: 3001
  id: vertexai.preview.reasoning_engines.templates.adk.AdkApp.delete_session
  name: delete_session
  file_path: env/lib/python3.13/site-packages/vertexai/preview/reasoning_engines/templates/adk.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: Deletes a session for the given user.
  signature: 'def delete_session(self, *, user_id: str, session_id: str):'
- rank: 3002
  id: vertexai.preview.reasoning_engines.templates.adk.AdkApp.get_session
  name: get_session
  file_path: env/lib/python3.13/site-packages/vertexai/preview/reasoning_engines/templates/adk.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: Get a session for the given user.
  signature: 'def get_session(self, *, user_id: str, session_id: str):'
- rank: 3003
  id: vertexai.preview.reasoning_engines.templates.adk.AdkApp.list_sessions
  name: list_sessions
  file_path: env/lib/python3.13/site-packages/vertexai/preview/reasoning_engines/templates/adk.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: List sessions for the given user.
  signature: 'def list_sessions(self, *, user_id: str):'
- rank: 3004
  id: vertexai.preview.reasoning_engines.templates.adk.AdkApp.project_id
  name: project_id
  file_path: env/lib/python3.13/site-packages/vertexai/preview/reasoning_engines/templates/adk.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def project_id(self) -> typing.Optional[str]:'
- rank: 3005
  id: vertexai.preview.reasoning_engines.templates.adk.AdkApp.register_operations
  name: register_operations
  file_path: env/lib/python3.13/site-packages/vertexai/preview/reasoning_engines/templates/adk.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: Registers the operations of the ADK application.
  signature: 'def register_operations(self) -> typing.Dict[str, typing.List[str]]:'
- rank: 3006
  id: vertexai.preview.reasoning_engines.templates.adk.AdkApp.set_up
  name: set_up
  file_path: env/lib/python3.13/site-packages/vertexai/preview/reasoning_engines/templates/adk.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: Sets up the ADK application.
  signature: 'def set_up(self):'
- rank: 3007
  id: vertexai.preview.reasoning_engines.templates.adk.AdkApp.stream_query
  name: stream_query
  file_path: env/lib/python3.13/site-packages/vertexai/preview/reasoning_engines/templates/adk.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Streams responses from the ADK application in response to a message.\n\nArgs:\n    message (Union[str, Dict[str, Any]]):\n        Required. The message to stream responses for.\n    user_id (str):\n        Required. The ID of the user.\n    session_id (str):\n        Optional. The ID of the session. If not provided, a new\n        session will be created for the user.\n    run_config (Optional[Dict[str, Any]]):\n        Optional. The run config to use for the query. If you want to\n        pass in a `run_config` pydantic object, you can pass in a dict\n        representing it as `run_config.model_dump(mode=\"json\")`.\n    **kwargs (dict[str, Any]):\n        Optional. Additional keyword arguments to pass to the\n        runner.\n\nYields:\n    The output of querying the ADK application."
  signature: 'def stream_query(self, *, message: typing.Union[str, typing.Dict[str, typing.Any]], user_id: str, session_id: typing.Optional[str]=None, run_config: typing.Optional[typing.Dict[str, typing.Any]]=None):'
- rank: 3008
  id: vertexai.preview.reasoning_engines.templates.adk.AdkApp.streaming_agent_run_with_events
  name: streaming_agent_run_with_events
  file_path: env/lib/python3.13/site-packages/vertexai/preview/reasoning_engines/templates/adk.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def streaming_agent_run_with_events(self, request_json: str):'
- rank: 3009
  id: vertexai.preview.reasoning_engines.templates.adk.get_adk_version
  name: get_adk_version
  file_path: env/lib/python3.13/site-packages/vertexai/preview/reasoning_engines/templates/adk.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: Returns the version of the ADK package.
  signature: 'def get_adk_version() -> typing.Optional[str]:'
- rank: 3010
  id: vertexai.preview.reasoning_engines.templates.adk.is_version_sufficient
  name: is_version_sufficient
  file_path: env/lib/python3.13/site-packages/vertexai/preview/reasoning_engines/templates/adk.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Compares the existing version of ADK with the required version.\n\nArgs:\n    version_to_check: The version string to check.\n\nReturns:\n    True if the existing version is sufficient, False otherwise."
  signature: 'def is_version_sufficient(version_to_check: str) -> bool:'
- rank: 3011
  id: vertexai.preview.reasoning_engines.templates.ag2
  name: ag2
  file_path: env/lib/python3.13/site-packages/vertexai/preview/reasoning_engines/templates/ag2.py
  type: MODULE
  group: Orphan
  usage_score: 0
- rank: 3012
  id: vertexai.preview.reasoning_engines.templates.ag2.AG2Agent
  name: AG2Agent
  file_path: env/lib/python3.13/site-packages/vertexai/preview/reasoning_engines/templates/ag2.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'An AG2 Agent.


    See https://cloud.google.com/vertex-ai/generative-ai/docs/agent-engine/develop/ag2

    for details.'
  constructor_signature: 'def __init__(self, model: str, runnable_name: str, *, api_type: typing.Optional[str]=None, llm_config: typing.Optional[typing.Mapping[str, typing.Any]]=None, system_instruction: typing.Optional[str]=None, runnable_kwargs: typing.Optional[typing.Mapping[str, typing.Any]]=None, runnable_builder: typing.Optional[typing.Callable[Ellipsis, ConversableAgent]]=None, tools: typing.Optional[typing.Sequence[typing.Callable[Ellipsis, typing.Any]]]=None, enable_tracing: bool=False):'
  methods:
  - signature: 'def set_up(self):'
    docstring: 'Sets up the agent for execution of queries at runtime.


      It initializes the runnable, binds the runnable with tools.


      This method should not be called for an object that being passed to

      the ReasoningEngine service for deployment, as it initializes clients

      that can not be serialized.'
  - signature: 'def clone(self) -> vertexai.preview.reasoning_engines.templates.ag2.AG2Agent:'
    docstring: Returns a clone of the AG2Agent.
  - signature: 'def query(self, *, input: typing.Union[str, typing.Mapping[str, typing.Any]], max_turns: typing.Optional[int]=None) -> typing.Dict[str, typing.Any]:'
    docstring: "Queries the Agent with the given input.\n\nArgs:\n    input (Union[str, Mapping[str, Any]]):\n        Required. The input to be passed to the Agent.\n    max_turns (int):\n        Optional. The maximum number of turns to run the agent for.\n        If not provided, the agent will run indefinitely.\n        If `max_turns` is a `float`, it will be converted to `int`\n        through rounding.\n    **kwargs:\n        Optional. Any additional keyword arguments to be passed to the\n        `.run()` method of the corresponding runnable.\n        Details of the kwargs can be found in\n        https://docs.ag2.ai/docs/api-reference/autogen/ConversableAgent#run.\n        The `user_input` parameter defaults to `False`, and should not\n        be passed through `kwargs`.\n\nReturns:\n    The output of querying the Agent with the given input."
  properties:
  - signature: 'agent_framework: str'
- rank: 3013
  id: vertexai.preview.reasoning_engines.templates.ag2.AG2Agent.__init__
  name: __init__
  file_path: env/lib/python3.13/site-packages/vertexai/preview/reasoning_engines/templates/ag2.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Initializes the AG2 Agent.\n\nUnder-the-hood, assuming .set_up() is called, this will correspond to\n```python\n# runnable_builder\nrunnable = runnable_builder(\n    llm_config=llm_config,\n    system_message=system_instruction,\n    **runnable_kwargs,\n)\n```\n\nWhen everything is based on their default values, this corresponds to\n```python\n# llm_config\nllm_config = {\n    \"config_list\": [{\n        \"project_id\":       initializer.global_config.project,\n        \"location\":         initializer.global_config.location,\n        \"model\":            \"gemini-1.0-pro-001\",\n        \"api_type\":         \"google\",\n    }]\n}\n\n# runnable_builder\nrunnable = ConversableAgent(\n    llm_config=llm_config,\n    name=\"Default AG2 Agent\"\n    system_message=\"You are a helpful AI Assistant.\",\n    human_input_mode=\"NEVER\",\n)\n```\n\nBy default, if `llm_config` is not specified, a default configuration\nwill be created using the provided `model` and `api_type`.\n\n\
    If `runnable_builder` is not specified, a default runnable builder will\nbe used, configured with the `system_instruction`, `runnable_name` and\n`runnable_kwargs`.\n\nArgs:\n    model (str):\n        Required. The name of the model (e.g. \"gemini-1.0-pro\").\n        Used to create a default `llm_config` if one is not provided.\n        This parameter is ignored if `llm_config` is provided.\n    runnable_name (str):\n        Required. The name of the runnable.\n        This name is used as the default `runnable_kwargs[\"name\"]`\n        unless `runnable_kwargs` already contains a \"name\", in which\n        case the provided `runnable_kwargs[\"name\"]` will be used.\n    api_type (str):\n        Optional. The API type to use for the language model.\n        Used to create a default `llm_config` if one is not provided.\n        This parameter is ignored if `llm_config` is provided.\n    llm_config (Mapping[str, Any]):\n        Optional. Configuration dictionary for the language model.\n\
    \        If provided, this configuration will be used directly.\n        Otherwise, a default `llm_config` will be created using `model`\n        and `api_type`. This `llm_config` is used as the default\n        `runnable_kwargs[\"llm_config\"]` unless `runnable_kwargs` already\n        contains a \"llm_config\", in which case the provided\n        `runnable_kwargs[\"llm_config\"]` will be used.\n    system_instruction (str):\n        Optional. The system instruction for the agent.\n        This instruction is used as the default\n        `runnable_kwargs[\"system_message\"]` unless `runnable_kwargs`\n        already contains a \"system_message\", in which case the provided\n        `runnable_kwargs[\"system_message\"]` will be used.\n    runnable_kwargs (Mapping[str, Any]):\n        Optional. Additional keyword arguments for the constructor of\n        the runnable. Details of the kwargs can be found in\n        https://docs.ag2.ai/docs/api-reference/autogen/ConversableAgent.\n    \
    \    `runnable_kwargs` only supports `human_input_mode=\"NEVER\"`.\n        Other `human_input_mode` values will trigger a warning.\n    runnable_builder (Callable[..., \"ConversableAgent\"]):\n        Optional. Callable that returns a new runnable. This can be used\n        for customizing the orchestration logic of the Agent.\n        If not provided, a default runnable builder will be used.\n    tools (Sequence[Callable[..., Any]]):\n        Optional. The tools for the agent to be able to use. All input\n        callables (e.g. function or class method) will be converted\n        to a AG2 tool . Defaults to None.\n    enable_tracing (bool):\n        Optional. Whether to enable tracing in Cloud Trace. Defaults to\n        False."
  signature: 'def __init__(self, model: str, runnable_name: str, *, api_type: typing.Optional[str]=None, llm_config: typing.Optional[typing.Mapping[str, typing.Any]]=None, system_instruction: typing.Optional[str]=None, runnable_kwargs: typing.Optional[typing.Mapping[str, typing.Any]]=None, runnable_builder: typing.Optional[typing.Callable[Ellipsis, ConversableAgent]]=None, tools: typing.Optional[typing.Sequence[typing.Callable[Ellipsis, typing.Any]]]=None, enable_tracing: bool=False):'
- rank: 3014
  id: vertexai.preview.reasoning_engines.templates.ag2.AG2Agent.clone
  name: clone
  file_path: env/lib/python3.13/site-packages/vertexai/preview/reasoning_engines/templates/ag2.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: Returns a clone of the AG2Agent.
  signature: 'def clone(self) -> vertexai.preview.reasoning_engines.templates.ag2.AG2Agent:'
- rank: 3015
  id: vertexai.preview.reasoning_engines.templates.ag2.AG2Agent.query
  name: query
  file_path: env/lib/python3.13/site-packages/vertexai/preview/reasoning_engines/templates/ag2.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Queries the Agent with the given input.\n\nArgs:\n    input (Union[str, Mapping[str, Any]]):\n        Required. The input to be passed to the Agent.\n    max_turns (int):\n        Optional. The maximum number of turns to run the agent for.\n        If not provided, the agent will run indefinitely.\n        If `max_turns` is a `float`, it will be converted to `int`\n        through rounding.\n    **kwargs:\n        Optional. Any additional keyword arguments to be passed to the\n        `.run()` method of the corresponding runnable.\n        Details of the kwargs can be found in\n        https://docs.ag2.ai/docs/api-reference/autogen/ConversableAgent#run.\n        The `user_input` parameter defaults to `False`, and should not\n        be passed through `kwargs`.\n\nReturns:\n    The output of querying the Agent with the given input."
  signature: 'def query(self, *, input: typing.Union[str, typing.Mapping[str, typing.Any]], max_turns: typing.Optional[int]=None) -> typing.Dict[str, typing.Any]:'
- rank: 3016
  id: vertexai.preview.reasoning_engines.templates.ag2.AG2Agent.set_up
  name: set_up
  file_path: env/lib/python3.13/site-packages/vertexai/preview/reasoning_engines/templates/ag2.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: 'Sets up the agent for execution of queries at runtime.


    It initializes the runnable, binds the runnable with tools.


    This method should not be called for an object that being passed to

    the ReasoningEngine service for deployment, as it initializes clients

    that can not be serialized.'
  signature: 'def set_up(self):'
- rank: 3017
  id: vertexai.preview.reasoning_engines.templates.langchain
  name: langchain
  file_path: env/lib/python3.13/site-packages/vertexai/preview/reasoning_engines/templates/langchain.py
  type: MODULE
  group: Orphan
  usage_score: 0
- rank: 3018
  id: vertexai.preview.reasoning_engines.templates.langchain.LangchainAgent
  name: LangchainAgent
  file_path: env/lib/python3.13/site-packages/vertexai/preview/reasoning_engines/templates/langchain.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'A Langchain Agent.


    See https://cloud.google.com/vertex-ai/generative-ai/docs/agent-engine/develop/langchain

    for details.'
  constructor_signature: 'def __init__(self, model: str, *, system_instruction: typing.Optional[str]=None, prompt: typing.Optional[RunnableSerializable]=None, tools: typing.Optional[typing.Sequence[_ToolLike]]=None, output_parser: typing.Optional[RunnableSerializable]=None, chat_history: typing.Optional[GetSessionHistoryCallable]=None, model_kwargs: typing.Optional[typing.Mapping[str, typing.Any]]=None, model_tool_kwargs: typing.Optional[typing.Mapping[str, typing.Any]]=None, agent_executor_kwargs: typing.Optional[typing.Mapping[str, typing.Any]]=None, runnable_kwargs: typing.Optional[typing.Mapping[str, typing.Any]]=None, model_builder: typing.Optional[typing.Callable]=None, runnable_builder: typing.Optional[typing.Callable]=None, enable_tracing: bool=False):'
  methods:
  - signature: 'def set_up(self):'
    docstring: 'Sets up the agent for execution of queries at runtime.


      It initializes the model, binds the model with tools, and connects it

      with the prompt template and output parser.


      This method should not be called for an object that being passed to

      the ReasoningEngine service for deployment, as it initializes clients

      that can not be serialized.'
  - signature: 'def clone(self) -> vertexai.preview.reasoning_engines.templates.langchain.LangchainAgent:'
    docstring: Returns a clone of the LangchainAgent.
  - signature: 'def query(self, *, input: typing.Union[str, typing.Mapping[str, typing.Any]], config: typing.Optional[RunnableConfig]=None) -> typing.Dict[str, typing.Any]:'
    docstring: "Queries the Agent with the given input and config.\n\nArgs:\n    input (Union[str, Mapping[str, Any]]):\n        Required. The input to be passed to the Agent.\n    config (langchain_core.runnables.RunnableConfig):\n        Optional. The config (if any) to be used for invoking the Agent.\n    **kwargs:\n        Optional. Any additional keyword arguments to be passed to the\n        `.invoke()` method of the corresponding AgentExecutor.\n\nReturns:\n    The output of querying the Agent with the given input and config."
  - signature: 'def stream_query(self, *, input: typing.Union[str, typing.Mapping[str, typing.Any]], config: typing.Optional[RunnableConfig]=None) -> typing.Iterable[typing.Any]:'
    docstring: "Stream queries the Agent with the given input and config.\n\nArgs:\n    input (Union[str, Mapping[str, Any]]):\n        Required. The input to be passed to the Agent.\n    config (langchain_core.runnables.RunnableConfig):\n        Optional. The config (if any) to be used for invoking the Agent.\n    **kwargs:\n        Optional. Any additional keyword arguments to be passed to the\n        `.invoke()` method of the corresponding AgentExecutor.\n\nYields:\n    The output of querying the Agent with the given input and config."
  properties:
  - signature: 'agent_framework: str'
- rank: 3019
  id: vertexai.preview.reasoning_engines.templates.langchain.LangchainAgent.__init__
  name: __init__
  file_path: env/lib/python3.13/site-packages/vertexai/preview/reasoning_engines/templates/langchain.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Initializes the LangchainAgent.\n\nUnder-the-hood, assuming .set_up() is called, this will correspond to\n\n```\nmodel = model_builder(model_name=model, model_kwargs=model_kwargs)\nrunnable = runnable_builder(\n    prompt=prompt,\n    model=model,\n    tools=tools,\n    output_parser=output_parser,\n    chat_history=chat_history,\n    agent_executor_kwargs=agent_executor_kwargs,\n    runnable_kwargs=runnable_kwargs,\n)\n```\n\nWhen everything is based on their default values, this corresponds to\n```\n# model_builder\nfrom langchain_google_vertexai import ChatVertexAI\nllm = ChatVertexAI(model_name=model, **model_kwargs)\n\n# runnable_builder\nfrom langchain import agents\nfrom langchain_core.runnables.history import RunnableWithMessageHistory\nllm_with_tools = llm.bind_tools(tools=tools, **model_tool_kwargs)\nagent_executor = agents.AgentExecutor(\n    agent=prompt | llm_with_tools | output_parser,\n    tools=tools,\n    **agent_executor_kwargs,\n)\nrunnable = RunnableWithMessageHistory(\n\
    \    runnable=agent_executor,\n    get_session_history=chat_history,\n    **runnable_kwargs,\n)\n```\n\nArgs:\n    model (str):\n        Optional. The name of the model (e.g. \"gemini-1.0-pro\").\n    system_instruction (str):\n        Optional. The system instruction to use for the agent. This\n        argument should not be specified if `prompt` is specified.\n    prompt (langchain_core.runnables.RunnableSerializable):\n        Optional. The prompt template for the model. Defaults to a\n        ChatPromptTemplate.\n    tools (Sequence[langchain_core.tools.BaseTool, Callable]):\n        Optional. The tools for the agent to be able to use. All input\n        callables (e.g. function or class method) will be converted\n        to a langchain.tools.base.StructuredTool. Defaults to None.\n    output_parser (langchain_core.runnables.RunnableSerializable):\n        Optional. The output parser for the model. Defaults to an\n        output parser that works with Gemini function-calling.\n \
    \   chat_history (langchain_core.runnables.history.GetSessionHistoryCallable):\n        Optional. Callable that returns a new BaseChatMessageHistory.\n        Defaults to None, i.e. chat_history is not preserved.\n    model_kwargs (Mapping[str, Any]):\n        Optional. Additional keyword arguments for the constructor of\n        chat_models.ChatVertexAI. An example would be\n        ```\n        {\n            # temperature (float): Sampling temperature, it controls the\n            # degree of randomness in token selection.\n            \"temperature\": 0.28,\n            # max_output_tokens (int): Token limit determines the\n            # maximum amount of text output from one prompt.\n            \"max_output_tokens\": 1000,\n            # top_p (float): Tokens are selected from most probable to\n            # least, until the sum of their probabilities equals the\n            # top_p value.\n            \"top_p\": 0.95,\n            # top_k (int): How the model selects tokens for\
    \ output, the\n            # next token is selected from among the top_k most probable\n            # tokens.\n            \"top_k\": 40,\n        }\n        ```\n    model_tool_kwargs (Mapping[str, Any]):\n        Optional. Additional keyword arguments when binding tools to the\n        model using `model.bind_tools()`.\n    agent_executor_kwargs (Mapping[str, Any]):\n        Optional. Additional keyword arguments for the constructor of\n        langchain.agents.AgentExecutor. An example would be\n        ```\n        {\n            # Whether to return the agent's trajectory of intermediate\n            # steps at the end in addition to the final output.\n            \"return_intermediate_steps\": False,\n            # The maximum number of steps to take before ending the\n            # execution loop.\n            \"max_iterations\": 15,\n            # The method to use for early stopping if the agent never\n            # returns `AgentFinish`. Either 'force' or 'generate'.\n     \
    \       \"early_stopping_method\": \"force\",\n            # How to handle errors raised by the agent's output parser.\n            # Defaults to `False`, which raises the error.\n            \"handle_parsing_errors\": False,\n        }\n        ```\n    runnable_kwargs (Mapping[str, Any]):\n        Optional. Additional keyword arguments for the constructor of\n        langchain.runnables.history.RunnableWithMessageHistory if\n        chat_history is specified. If chat_history is None, this will be\n        ignored.\n    model_builder (Callable):\n        Optional. Callable that returns a new language model. Defaults\n        to a a callable that returns ChatVertexAI based on `model`,\n        `model_kwargs` and the parameters in `vertexai.init`.\n    runnable_builder (Callable):\n        Optional. Callable that returns a new runnable. This can be used\n        for customizing the orchestration logic of the Agent based on\n        the model returned by `model_builder` and the rest of\
    \ the input\n        arguments.\n    enable_tracing (bool):\n        Optional. Whether to enable tracing in Cloud Trace. Defaults to\n        False.\n\nRaises:\n    ValueError: If both `prompt` and `system_instruction` are specified.\n    TypeError: If there is an invalid tool (e.g. function with an input\n    that did not specify its type)."
  signature: 'def __init__(self, model: str, *, system_instruction: typing.Optional[str]=None, prompt: typing.Optional[RunnableSerializable]=None, tools: typing.Optional[typing.Sequence[_ToolLike]]=None, output_parser: typing.Optional[RunnableSerializable]=None, chat_history: typing.Optional[GetSessionHistoryCallable]=None, model_kwargs: typing.Optional[typing.Mapping[str, typing.Any]]=None, model_tool_kwargs: typing.Optional[typing.Mapping[str, typing.Any]]=None, agent_executor_kwargs: typing.Optional[typing.Mapping[str, typing.Any]]=None, runnable_kwargs: typing.Optional[typing.Mapping[str, typing.Any]]=None, model_builder: typing.Optional[typing.Callable]=None, runnable_builder: typing.Optional[typing.Callable]=None, enable_tracing: bool=False):'
- rank: 3020
  id: vertexai.preview.reasoning_engines.templates.langchain.LangchainAgent.clone
  name: clone
  file_path: env/lib/python3.13/site-packages/vertexai/preview/reasoning_engines/templates/langchain.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: Returns a clone of the LangchainAgent.
  signature: 'def clone(self) -> vertexai.preview.reasoning_engines.templates.langchain.LangchainAgent:'
- rank: 3021
  id: vertexai.preview.reasoning_engines.templates.langchain.LangchainAgent.query
  name: query
  file_path: env/lib/python3.13/site-packages/vertexai/preview/reasoning_engines/templates/langchain.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Queries the Agent with the given input and config.\n\nArgs:\n    input (Union[str, Mapping[str, Any]]):\n        Required. The input to be passed to the Agent.\n    config (langchain_core.runnables.RunnableConfig):\n        Optional. The config (if any) to be used for invoking the Agent.\n    **kwargs:\n        Optional. Any additional keyword arguments to be passed to the\n        `.invoke()` method of the corresponding AgentExecutor.\n\nReturns:\n    The output of querying the Agent with the given input and config."
  signature: 'def query(self, *, input: typing.Union[str, typing.Mapping[str, typing.Any]], config: typing.Optional[RunnableConfig]=None) -> typing.Dict[str, typing.Any]:'
- rank: 3022
  id: vertexai.preview.reasoning_engines.templates.langchain.LangchainAgent.set_up
  name: set_up
  file_path: env/lib/python3.13/site-packages/vertexai/preview/reasoning_engines/templates/langchain.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: 'Sets up the agent for execution of queries at runtime.


    It initializes the model, binds the model with tools, and connects it

    with the prompt template and output parser.


    This method should not be called for an object that being passed to

    the ReasoningEngine service for deployment, as it initializes clients

    that can not be serialized.'
  signature: 'def set_up(self):'
- rank: 3023
  id: vertexai.preview.reasoning_engines.templates.langchain.LangchainAgent.stream_query
  name: stream_query
  file_path: env/lib/python3.13/site-packages/vertexai/preview/reasoning_engines/templates/langchain.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Stream queries the Agent with the given input and config.\n\nArgs:\n    input (Union[str, Mapping[str, Any]]):\n        Required. The input to be passed to the Agent.\n    config (langchain_core.runnables.RunnableConfig):\n        Optional. The config (if any) to be used for invoking the Agent.\n    **kwargs:\n        Optional. Any additional keyword arguments to be passed to the\n        `.invoke()` method of the corresponding AgentExecutor.\n\nYields:\n    The output of querying the Agent with the given input and config."
  signature: 'def stream_query(self, *, input: typing.Union[str, typing.Mapping[str, typing.Any]], config: typing.Optional[RunnableConfig]=None) -> typing.Iterable[typing.Any]:'
- rank: 3024
  id: vertexai.preview.reasoning_engines.templates.langgraph
  name: langgraph
  file_path: env/lib/python3.13/site-packages/vertexai/preview/reasoning_engines/templates/langgraph.py
  type: MODULE
  group: Orphan
  usage_score: 0
- rank: 3025
  id: vertexai.preview.reasoning_engines.templates.langgraph.LanggraphAgent
  name: LanggraphAgent
  file_path: env/lib/python3.13/site-packages/vertexai/preview/reasoning_engines/templates/langgraph.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'A LangGraph Agent.


    See https://cloud.google.com/vertex-ai/generative-ai/docs/agent-engine/develop/langgraph

    for details.'
  constructor_signature: 'def __init__(self, model: str, *, tools: typing.Optional[typing.Sequence[_ToolLike]]=None, model_kwargs: typing.Optional[typing.Mapping[str, typing.Any]]=None, model_tool_kwargs: typing.Optional[typing.Mapping[str, typing.Any]]=None, model_builder: typing.Optional[typing.Callable[Ellipsis, BaseLanguageModel]]=None, runnable_kwargs: typing.Optional[typing.Mapping[str, typing.Any]]=None, runnable_builder: typing.Optional[typing.Callable[Ellipsis, RunnableSerializable]]=None, checkpointer_kwargs: typing.Optional[typing.Mapping[str, typing.Any]]=None, checkpointer_builder: typing.Optional[typing.Callable[Ellipsis, BaseCheckpointSaver]]=None, enable_tracing: bool=False):'
  methods:
  - signature: 'def set_up(self):'
    docstring: 'Sets up the agent for execution of queries at runtime.


      It initializes the model, binds the model with tools, and connects it

      with the prompt template and output parser.


      This method should not be called for an object that being passed to

      the ReasoningEngine service for deployment, as it initializes clients

      that can not be serialized.'
  - signature: 'def clone(self) -> vertexai.preview.reasoning_engines.templates.langgraph.LanggraphAgent:'
    docstring: Returns a clone of the LanggraphAgent.
  - signature: 'def query(self, *, input: typing.Union[str, typing.Mapping[str, typing.Any]], config: typing.Optional[RunnableConfig]=None) -> typing.Dict[str, typing.Any]:'
    docstring: "Queries the Agent with the given input and config.\n\nArgs:\n    input (Union[str, Mapping[str, Any]]):\n        Required. The input to be passed to the Agent.\n    config (langchain_core.runnables.RunnableConfig):\n        Optional. The config (if any) to be used for invoking the Agent.\n    **kwargs:\n        Optional. Any additional keyword arguments to be passed to the\n        `.invoke()` method of the corresponding AgentExecutor.\n\nReturns:\n    The output of querying the Agent with the given input and config."
  - signature: 'def stream_query(self, *, input: typing.Union[str, typing.Mapping[str, typing.Any]], config: typing.Optional[RunnableConfig]=None) -> typing.Iterable[typing.Any]:'
    docstring: "Stream queries the Agent with the given input and config.\n\nArgs:\n    input (Union[str, Mapping[str, Any]]):\n        Required. The input to be passed to the Agent.\n    config (langchain_core.runnables.RunnableConfig):\n        Optional. The config (if any) to be used for invoking the Agent.\n    **kwargs:\n        Optional. Any additional keyword arguments to be passed to the\n        `.invoke()` method of the corresponding AgentExecutor.\n\nYields:\n    The output of querying the Agent with the given input and config."
  - signature: 'def get_state_history(self, config: typing.Optional[RunnableConfig]) -> typing.Iterable[typing.Any]:'
    docstring: "Gets the state history of the Agent.\n\nArgs:\n    config (Optional[RunnableConfig]):\n        Optional. The config for invoking the Agent.\n    **kwargs:\n        Optional. Additional keyword arguments for the `.invoke()` method.\n\nYields:\n    Dict[str, Any]: The state history of the Agent."
  - signature: 'def get_state(self, config: typing.Optional[RunnableConfig]) -> typing.Dict[str, typing.Any]:'
    docstring: "Gets the current state of the Agent.\n\nArgs:\n    config (Optional[RunnableConfig]):\n        Optional. The config for invoking the Agent.\n    **kwargs:\n        Optional. Additional keyword arguments for the `.invoke()` method.\n\nReturns:\n    Dict[str, Any]: The current state of the Agent."
  - signature: 'def update_state(self, config: typing.Optional[RunnableConfig]) -> typing.Dict[str, typing.Any]:'
    docstring: "Updates the state of the Agent.\n\nArgs:\n    config (Optional[RunnableConfig]):\n        Optional. The config for invoking the Agent.\n    **kwargs:\n        Optional. Additional keyword arguments for the `.invoke()` method.\n\nReturns:\n    Dict[str, Any]: The updated state of the Agent."
  - signature: 'def register_operations(self) -> typing.Mapping[str, typing.Sequence[str]]:'
    docstring: "Registers the operations of the Agent.\n\nThis mapping defines how different operation modes (e.g., \"\", \"stream\")\nare implemented by specific methods of the Agent.  The \"default\" mode,\nrepresented by the empty string `\"\"`, is associated with the `query`\nAPI, while the \"stream\" mode is associated with the `stream_query` API.\n\nReturns:\n    Mapping[str, Sequence[str]]: A mapping of operation modes to a list\n    of method names that implement those operation modes."
  properties:
  - signature: 'agent_framework: str'
- rank: 3026
  id: vertexai.preview.reasoning_engines.templates.langgraph.LanggraphAgent.__init__
  name: __init__
  file_path: env/lib/python3.13/site-packages/vertexai/preview/reasoning_engines/templates/langgraph.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Initializes the LangGraph Agent.\n\nUnder-the-hood, assuming .set_up() is called, this will correspond to\n```python\nmodel = model_builder(model_name=model, model_kwargs=model_kwargs)\nrunnable = runnable_builder(\n    model=model,\n    tools=tools,\n    model_tool_kwargs=model_tool_kwargs,\n    runnable_kwargs=runnable_kwargs,\n)\n```\n\nWhen everything is based on their default values, this corresponds to\n```python\n# model_builder\nfrom langchain_google_vertexai import ChatVertexAI\nllm = ChatVertexAI(model_name=model, **model_kwargs)\n\n# runnable_builder\nfrom langgraph.prebuilt import create_react_agent\nllm_with_tools = llm.bind_tools(tools=tools, **model_tool_kwargs)\nrunnable = create_react_agent(\n    llm_with_tools,\n    tools=tools,\n    **runnable_kwargs,\n)\n```\n\nBy default, no checkpointer is used (i.e. there is no state history). To\nenable checkpointing, provide a `checkpointer_builder` function that\nreturns a checkpointer instance.\n\n**Example using\
    \ Spanner:**\n```python\ndef checkpointer_builder(instance_id, database_id, project_id, **kwargs):\n    from langchain_google_spanner import SpannerCheckpointSaver\n\n    checkpointer = SpannerCheckpointSaver(instance_id, database_id, project_id)\n    with checkpointer.cursor() as cur:\n        cur.execute(\"DROP TABLE IF EXISTS checkpoints\")\n        cur.execute(\"DROP TABLE IF EXISTS checkpoint_writes\")\n    checkpointer.setup()\n\n    return checkpointer\n```\n\n**Example using an in-memory checkpointer:**\n```python\ndef checkpointer_builder(**kwargs):\n    from langgraph.checkpoint.memory import MemorySaver\n\n    return MemorySaver()\n```\n\nThe `checkpointer_builder` function will be called with any keyword\narguments passed to the agent's constructor.  Ensure your\n`checkpointer_builder` function accepts `**kwargs` to handle these\narguments, even if unused.\n\nArgs:\n    model (str):\n        Optional. The name of the model (e.g. \"gemini-1.0-pro\").\n    tools (Sequence[langchain_core.tools.BaseTool,\
    \ Callable]):\n        Optional. The tools for the agent to be able to use. All input\n        callables (e.g. function or class method) will be converted\n        to a langchain.tools.base.StructuredTool. Defaults to None.\n    model_kwargs (Mapping[str, Any]):\n        Optional. Additional keyword arguments for the constructor of\n        chat_models.ChatVertexAI. An example would be\n        ```\n        {\n            # temperature (float): Sampling temperature, it controls the\n            # degree of randomness in token selection.\n            \"temperature\": 0.28,\n            # max_output_tokens (int): Token limit determines the\n            # maximum amount of text output from one prompt.\n            \"max_output_tokens\": 1000,\n            # top_p (float): Tokens are selected from most probable to\n            # least, until the sum of their probabilities equals the\n            # top_p value.\n            \"top_p\": 0.95,\n            # top_k (int): How the model selects\
    \ tokens for output, the\n            # next token is selected from among the top_k most probable\n            # tokens.\n            \"top_k\": 40,\n        }\n        ```\n    model_tool_kwargs (Mapping[str, Any]):\n        Optional. Additional keyword arguments when binding tools to the\n        model using `model.bind_tools()`.\n    model_builder (Callable[..., \"BaseLanguageModel\"]):\n        Optional. Callable that returns a new language model. Defaults\n        to a a callable that returns ChatVertexAI based on `model`,\n        `model_kwargs` and the parameters in `vertexai.init`.\n    runnable_kwargs (Mapping[str, Any]):\n        Optional. Additional keyword arguments for the constructor of\n        langchain.runnables.history.RunnableWithMessageHistory if\n        chat_history is specified. If chat_history is None, this will be\n        ignored.\n    runnable_builder (Callable[..., \"RunnableSerializable\"]):\n        Optional. Callable that returns a new runnable. This can\
    \ be used\n        for customizing the orchestration logic of the Agent based on\n        the model returned by `model_builder` and the rest of the input\n        arguments.\n    checkpointer_kwargs (Mapping[str, Any]):\n        Optional. Additional keyword arguments for the constructor of\n        the checkpointer returned by `checkpointer_builder`.\n    checkpointer_builder (Callable[..., \"BaseCheckpointSaver\"]):\n        Optional. Callable that returns a checkpointer. This can be used\n        for defining the checkpointer of the Agent. Defaults to None.\n    enable_tracing (bool):\n        Optional. Whether to enable tracing in Cloud Trace. Defaults to\n        False.\n\nRaises:\n    TypeError: If there is an invalid tool (e.g. function with an input\n    that did not specify its type)."
  signature: 'def __init__(self, model: str, *, tools: typing.Optional[typing.Sequence[_ToolLike]]=None, model_kwargs: typing.Optional[typing.Mapping[str, typing.Any]]=None, model_tool_kwargs: typing.Optional[typing.Mapping[str, typing.Any]]=None, model_builder: typing.Optional[typing.Callable[Ellipsis, BaseLanguageModel]]=None, runnable_kwargs: typing.Optional[typing.Mapping[str, typing.Any]]=None, runnable_builder: typing.Optional[typing.Callable[Ellipsis, RunnableSerializable]]=None, checkpointer_kwargs: typing.Optional[typing.Mapping[str, typing.Any]]=None, checkpointer_builder: typing.Optional[typing.Callable[Ellipsis, BaseCheckpointSaver]]=None, enable_tracing: bool=False):'
- rank: 3027
  id: vertexai.preview.reasoning_engines.templates.langgraph.LanggraphAgent.clone
  name: clone
  file_path: env/lib/python3.13/site-packages/vertexai/preview/reasoning_engines/templates/langgraph.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: Returns a clone of the LanggraphAgent.
  signature: 'def clone(self) -> vertexai.preview.reasoning_engines.templates.langgraph.LanggraphAgent:'
- rank: 3028
  id: vertexai.preview.reasoning_engines.templates.langgraph.LanggraphAgent.get_state
  name: get_state
  file_path: env/lib/python3.13/site-packages/vertexai/preview/reasoning_engines/templates/langgraph.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Gets the current state of the Agent.\n\nArgs:\n    config (Optional[RunnableConfig]):\n        Optional. The config for invoking the Agent.\n    **kwargs:\n        Optional. Additional keyword arguments for the `.invoke()` method.\n\nReturns:\n    Dict[str, Any]: The current state of the Agent."
  signature: 'def get_state(self, config: typing.Optional[RunnableConfig]) -> typing.Dict[str, typing.Any]:'
- rank: 3029
  id: vertexai.preview.reasoning_engines.templates.langgraph.LanggraphAgent.get_state_history
  name: get_state_history
  file_path: env/lib/python3.13/site-packages/vertexai/preview/reasoning_engines/templates/langgraph.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Gets the state history of the Agent.\n\nArgs:\n    config (Optional[RunnableConfig]):\n        Optional. The config for invoking the Agent.\n    **kwargs:\n        Optional. Additional keyword arguments for the `.invoke()` method.\n\nYields:\n    Dict[str, Any]: The state history of the Agent."
  signature: 'def get_state_history(self, config: typing.Optional[RunnableConfig]) -> typing.Iterable[typing.Any]:'
- rank: 3030
  id: vertexai.preview.reasoning_engines.templates.langgraph.LanggraphAgent.query
  name: query
  file_path: env/lib/python3.13/site-packages/vertexai/preview/reasoning_engines/templates/langgraph.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Queries the Agent with the given input and config.\n\nArgs:\n    input (Union[str, Mapping[str, Any]]):\n        Required. The input to be passed to the Agent.\n    config (langchain_core.runnables.RunnableConfig):\n        Optional. The config (if any) to be used for invoking the Agent.\n    **kwargs:\n        Optional. Any additional keyword arguments to be passed to the\n        `.invoke()` method of the corresponding AgentExecutor.\n\nReturns:\n    The output of querying the Agent with the given input and config."
  signature: 'def query(self, *, input: typing.Union[str, typing.Mapping[str, typing.Any]], config: typing.Optional[RunnableConfig]=None) -> typing.Dict[str, typing.Any]:'
- rank: 3031
  id: vertexai.preview.reasoning_engines.templates.langgraph.LanggraphAgent.register_operations
  name: register_operations
  file_path: env/lib/python3.13/site-packages/vertexai/preview/reasoning_engines/templates/langgraph.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Registers the operations of the Agent.\n\nThis mapping defines how different operation modes (e.g., \"\", \"stream\")\nare implemented by specific methods of the Agent.  The \"default\" mode,\nrepresented by the empty string `\"\"`, is associated with the `query`\nAPI, while the \"stream\" mode is associated with the `stream_query` API.\n\nReturns:\n    Mapping[str, Sequence[str]]: A mapping of operation modes to a list\n    of method names that implement those operation modes."
  signature: 'def register_operations(self) -> typing.Mapping[str, typing.Sequence[str]]:'
- rank: 3032
  id: vertexai.preview.reasoning_engines.templates.langgraph.LanggraphAgent.set_up
  name: set_up
  file_path: env/lib/python3.13/site-packages/vertexai/preview/reasoning_engines/templates/langgraph.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: 'Sets up the agent for execution of queries at runtime.


    It initializes the model, binds the model with tools, and connects it

    with the prompt template and output parser.


    This method should not be called for an object that being passed to

    the ReasoningEngine service for deployment, as it initializes clients

    that can not be serialized.'
  signature: 'def set_up(self):'
- rank: 3033
  id: vertexai.preview.reasoning_engines.templates.langgraph.LanggraphAgent.stream_query
  name: stream_query
  file_path: env/lib/python3.13/site-packages/vertexai/preview/reasoning_engines/templates/langgraph.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Stream queries the Agent with the given input and config.\n\nArgs:\n    input (Union[str, Mapping[str, Any]]):\n        Required. The input to be passed to the Agent.\n    config (langchain_core.runnables.RunnableConfig):\n        Optional. The config (if any) to be used for invoking the Agent.\n    **kwargs:\n        Optional. Any additional keyword arguments to be passed to the\n        `.invoke()` method of the corresponding AgentExecutor.\n\nYields:\n    The output of querying the Agent with the given input and config."
  signature: 'def stream_query(self, *, input: typing.Union[str, typing.Mapping[str, typing.Any]], config: typing.Optional[RunnableConfig]=None) -> typing.Iterable[typing.Any]:'
- rank: 3034
  id: vertexai.preview.reasoning_engines.templates.langgraph.LanggraphAgent.update_state
  name: update_state
  file_path: env/lib/python3.13/site-packages/vertexai/preview/reasoning_engines/templates/langgraph.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Updates the state of the Agent.\n\nArgs:\n    config (Optional[RunnableConfig]):\n        Optional. The config for invoking the Agent.\n    **kwargs:\n        Optional. Additional keyword arguments for the `.invoke()` method.\n\nReturns:\n    Dict[str, Any]: The updated state of the Agent."
  signature: 'def update_state(self, config: typing.Optional[RunnableConfig]) -> typing.Dict[str, typing.Any]:'
- rank: 3035
  id: vertexai.preview.reasoning_engines.templates.llama_index
  name: llama_index
  file_path: env/lib/python3.13/site-packages/vertexai/preview/reasoning_engines/templates/llama_index.py
  type: MODULE
  group: Orphan
  usage_score: 0
- rank: 3036
  id: vertexai.preview.reasoning_engines.templates.llama_index.LlamaIndexQueryPipelineAgent
  name: LlamaIndexQueryPipelineAgent
  file_path: env/lib/python3.13/site-packages/vertexai/preview/reasoning_engines/templates/llama_index.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'A LlamaIndex Query Pipeline Agent.


    This agent uses a query pipeline for LLAIndex, including prompt, model,

    retrieval and summarization steps. More details can be found in

    https://docs.llamaindex.ai/en/stable/module_guides/querying/pipeline/.'
  constructor_signature: 'def __init__(self, model: str, *, system_instruction: typing.Optional[str]=None, prompt: typing.Optional[QueryComponent]=None, model_kwargs: typing.Optional[typing.Mapping[str, typing.Any]]=None, model_builder: typing.Optional[typing.Callable[Ellipsis, FunctionCallingLLM]]=None, retriever_kwargs: typing.Optional[typing.Mapping[str, typing.Any]]=None, retriever_builder: typing.Optional[typing.Callable[Ellipsis, QueryComponent]]=None, response_synthesizer_kwargs: typing.Optional[typing.Mapping[str, typing.Any]]=None, response_synthesizer_builder: typing.Optional[typing.Callable[Ellipsis, QueryComponent]]=None, runnable_kwargs: typing.Optional[typing.Mapping[str, typing.Any]]=None, runnable_builder: typing.Optional[typing.Callable[Ellipsis, llama_index.core.query_pipeline.QueryPipeline]]=None, enable_tracing: bool=False):'
  methods:
  - signature: 'def set_up(self):'
    docstring: 'Sets up the agent for execution of queries at runtime.


      It initializes the model, connects it with the prompt template,

      retriever and response_synthesizer.


      This method should not be called for an object that being passed to

      the ReasoningEngine service for deployment, as it initializes clients

      that can not be serialized.'
  - signature: 'def clone(self) -> vertexai.preview.reasoning_engines.templates.llama_index.LlamaIndexQueryPipelineAgent:'
    docstring: Returns a clone of the LlamaIndexQueryPipelineAgent.
  - signature: 'def query(self, input: typing.Union[str, typing.Mapping[str, typing.Any]]) -> typing.Union[str, typing.Dict[str, typing.Any], typing.Sequence[typing.Union[str, typing.Dict[str, typing.Any]]]]:'
    docstring: "Queries the Agent with the given input and config.\n\nArgs:\n    input (Union[str, Mapping[str, Any]]):\n        Required. The input to be passed to the Agent.\n    **kwargs:\n        Optional. Any additional keyword arguments to be passed to the\n        `.invoke()` method of the corresponding AgentExecutor.\n\nReturns:\n    The output of querying the Agent with the given input and config."
  properties:
  - signature: 'agent_framework: str'
- rank: 3037
  id: vertexai.preview.reasoning_engines.templates.llama_index.LlamaIndexQueryPipelineAgent.__init__
  name: __init__
  file_path: env/lib/python3.13/site-packages/vertexai/preview/reasoning_engines/templates/llama_index.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Initializes the LlamaIndexQueryPipelineAgent.\n\nUnder-the-hood, assuming .set_up() is called, this will correspond to\n```python\n# model_builder\nmodel = model_builder(model_name, project, location, model_kwargs)\n\n# runnable_builder\nrunnable = runnable_builder(\n    prompt=prompt,\n    model=model,\n    retriever=retriever_builder(model, retriever_kwargs),\n    response_synthesizer=response_synthesizer_builder(\n        model, response_synthesizer_kwargs\n    ),\n    runnable_kwargs=runnable_kwargs,\n)\n```\n\nWhen everything is based on their default values, this corresponds to a\nquery pipeline `Prompt - Model`:\n```python\n# Default Model Builder\nmodel = google_genai.GoogleGenAI(\n    model=model_name,\n    vertexai_config={\n        \"project\": initializer.global_config.project,\n        \"location\": initializer.global_config.location,\n    },\n)\n\n# Default Prompt Builder\nprompt = prompts.ChatPromptTemplate(\n    message_templates=[\n        types.ChatMessage(\n\
    \            role=types.MessageRole.USER,\n            content=\"{input}\",\n        ),\n    ],\n)\n\n# Default Runnable Builder\nrunnable = QueryPipeline(\n    modules = {\n        \"prompt\": prompt,\n        \"model\": model,\n    },\n)\npipeline.add_link(\"prompt\", \"model\")\n```\n\nWhen `system_instruction` is specified, the prompt will be updated to\ninclude the system instruction.\n```python\n# Updated Prompt Builder\nprompt = prompts.ChatPromptTemplate(\n    message_templates=[\n        types.ChatMessage(\n            role=types.MessageRole.SYSTEM,\n            content=system_instruction,\n        ),\n        types.ChatMessage(\n            role=types.MessageRole.USER,\n            content=\"{input}\",\n        ),\n    ],\n)\n```\n\nWhen all inputs are specified, this corresponds to a query pipeline\n`Prompt - Model - Retriever - Summarizer`:\n```python\nrunnable = QueryPipeline(\n    modules = {\n        \"prompt\": prompt,\n        \"model\": model,\n        \"retriever\"\
    : retriever_builder(retriever_kwargs),\n        \"response_synthesizer\": response_synthesizer_builder(\n            response_synthesizer_kwargs\n        ),\n    },\n)\npipeline.add_link(\"prompt\", \"model\")\npipeline.add_link(\"model\", \"retriever\")\npipeline.add_link(\"model\", \"response_synthesizer\", dest_key=\"query_str\")\npipeline.add_link(\"retriever\", \"response_synthesizer\", dest_key=\"nodes\")\n```\n\nArgs:\n    model (str):\n        The name of the model (e.g. \"gemini-1.0-pro\").\n    system_instruction (str):\n        Optional. The system instruction to use for the agent.\n    prompt (llama_index.core.base.query_pipeline.query.QUERY_COMPONENT_TYPE):\n        Optional.  The prompt template for the model.\n    model_kwargs (Mapping[str, Any]):\n        Optional. Keyword arguments for the model constructor of the\n        google_genai.GoogleGenAI. An example of a model_kwargs is:\n        ```python\n        {\n            # api_key (string): The API key for the GoogleGenAI\
    \ model.\n            # The API can also be fetched from the GOOGLE_API_KEY\n            # environment variable. If `vertexai_config` is provided,\n            # the API key is ignored.\n            \"api_key\": \"your_api_key\",\n            # temperature (float): Sampling temperature, it controls the\n            # degree of randomness in token selection. If not provided,\n            # the default temperature is 0.1.\n            \"temperature\": 0.1,\n            # context_window (int): The context window of the model.\n            # If not provided, the default context window is 200000.\n            \"context_window\": 200000,\n            # max_tokens (int): Token limit determines the maximum\n            # amount of text output from one prompt. If not provided,\n            # the default max_tokens is 256.\n            \"max_tokens\": 256,\n            # is_function_calling_model (bool): Whether the model is a\n            # function calling model. If not provided, the default\n\
    \            # is_function_calling_model is True.\n            \"is_function_calling_model\": True,\n        }\n        ```\n    model_builder (Callable):\n        Optional. Callable that returns a language model.\n    retriever_kwargs (Mapping[str, Any]):\n        Optional. Keyword arguments for the retriever constructor.\n    retriever_builder (Callable):\n        Optional. Callable that returns a retriever object.\n    response_synthesizer_kwargs (Mapping[str, Any]):\n        Optional. Keyword arguments for the response synthesizer constructor.\n    response_synthesizer_builder (Callable):\n        Optional. Callable that returns a response_synthesizer object.\n    runnable_kwargs (Mapping[str, Any]):\n        Optional. Keyword arguments for the runnable constructor.\n    runnable_builder (Callable):\n        Optional. Callable that returns a runnable (query pipeline).\n    enable_tracing (bool):\n        Optional. Whether to enable tracing. Defaults to False."
  signature: 'def __init__(self, model: str, *, system_instruction: typing.Optional[str]=None, prompt: typing.Optional[QueryComponent]=None, model_kwargs: typing.Optional[typing.Mapping[str, typing.Any]]=None, model_builder: typing.Optional[typing.Callable[Ellipsis, FunctionCallingLLM]]=None, retriever_kwargs: typing.Optional[typing.Mapping[str, typing.Any]]=None, retriever_builder: typing.Optional[typing.Callable[Ellipsis, QueryComponent]]=None, response_synthesizer_kwargs: typing.Optional[typing.Mapping[str, typing.Any]]=None, response_synthesizer_builder: typing.Optional[typing.Callable[Ellipsis, QueryComponent]]=None, runnable_kwargs: typing.Optional[typing.Mapping[str, typing.Any]]=None, runnable_builder: typing.Optional[typing.Callable[Ellipsis, llama_index.core.query_pipeline.QueryPipeline]]=None, enable_tracing: bool=False):'
- rank: 3038
  id: vertexai.preview.reasoning_engines.templates.llama_index.LlamaIndexQueryPipelineAgent.clone
  name: clone
  file_path: env/lib/python3.13/site-packages/vertexai/preview/reasoning_engines/templates/llama_index.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: Returns a clone of the LlamaIndexQueryPipelineAgent.
  signature: 'def clone(self) -> vertexai.preview.reasoning_engines.templates.llama_index.LlamaIndexQueryPipelineAgent:'
- rank: 3039
  id: vertexai.preview.reasoning_engines.templates.llama_index.LlamaIndexQueryPipelineAgent.query
  name: query
  file_path: env/lib/python3.13/site-packages/vertexai/preview/reasoning_engines/templates/llama_index.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Queries the Agent with the given input and config.\n\nArgs:\n    input (Union[str, Mapping[str, Any]]):\n        Required. The input to be passed to the Agent.\n    **kwargs:\n        Optional. Any additional keyword arguments to be passed to the\n        `.invoke()` method of the corresponding AgentExecutor.\n\nReturns:\n    The output of querying the Agent with the given input and config."
  signature: 'def query(self, input: typing.Union[str, typing.Mapping[str, typing.Any]]) -> typing.Union[str, typing.Dict[str, typing.Any], typing.Sequence[typing.Union[str, typing.Dict[str, typing.Any]]]]:'
- rank: 3040
  id: vertexai.preview.reasoning_engines.templates.llama_index.LlamaIndexQueryPipelineAgent.set_up
  name: set_up
  file_path: env/lib/python3.13/site-packages/vertexai/preview/reasoning_engines/templates/llama_index.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: 'Sets up the agent for execution of queries at runtime.


    It initializes the model, connects it with the prompt template,

    retriever and response_synthesizer.


    This method should not be called for an object that being passed to

    the ReasoningEngine service for deployment, as it initializes clients

    that can not be serialized.'
  signature: 'def set_up(self):'
- rank: 3041
  id: vertexai.preview.tokenization
  name: tokenization
  file_path: env/lib/python3.13/site-packages/vertexai/preview/tokenization.py
  type: MODULE
  group: Orphan
  usage_score: 0
- rank: 3042
  id: vertexai.preview.tuning
  name: tuning
  file_path: env/lib/python3.13/site-packages/vertexai/preview/tuning/__init__.py
  type: MODULE
  group: Orphan
  usage_score: 0
  docstring: Classes for tuning models.
- rank: 3043
  id: vertexai.preview.tuning.sft
  name: sft
  file_path: env/lib/python3.13/site-packages/vertexai/preview/tuning/sft.py
  type: MODULE
  group: Orphan
  usage_score: 0
  docstring: Classes for supervised tuning.
- rank: 3044
  id: vertexai.preview.vision_models
  name: vision_models
  file_path: env/lib/python3.13/site-packages/vertexai/preview/vision_models.py
  type: MODULE
  group: Orphan
  usage_score: 0
  docstring: Classes for working with vision models.
- rank: 3045
  id: vertexai.rag
  name: rag
  file_path: env/lib/python3.13/site-packages/vertexai/rag/__init__.py
  type: MODULE
  group: Orphan
  usage_score: 0
- rank: 3046
  id: vertexai.rag.rag_data
  name: rag_data
  file_path: env/lib/python3.13/site-packages/vertexai/rag/rag_data.py
  type: MODULE
  group: Orphan
  usage_score: 0
  docstring: RAG data management SDK.
  methods:
  - signature: 'def create_corpus(display_name: typing.Optional[str], description: typing.Optional[str], vertex_ai_search_config: typing.Optional[vertexai.rag.utils.resources.VertexAiSearchConfig], backend_config: typing.Optional[typing.Union[vertexai.rag.utils.resources.RagVectorDbConfig, None]], encryption_spec: typing.Optional[google.cloud.aiplatform_v1.types.EncryptionSpec], timeout: int) -> vertexai.rag.utils.resources.RagCorpus:'
    docstring: "Creates a new RagCorpus resource.\n\nExample usage:\n```\nimport vertexai\nfrom vertexai import rag\n\nvertexai.init(project=\"my-project\")\n\nrag_corpus = rag.create_corpus(\n    display_name=\"my-corpus-1\",\n)\n```\n\nArgs:\n    display_name: If not provided, SDK will create one. The display name of\n      the RagCorpus. The name can be up to 128 characters long and can consist\n      of any UTF-8 characters.\n    description: The description of the RagCorpus.\n    vertex_ai_search_config: The Vertex AI Search config of the RagCorpus.\n        Note: backend_config cannot be set if vertex_ai_search_config is\n          specified.\n    backend_config: The backend config of the RagCorpus, specifying a data\n      store and/or embedding model.\n    encryption_spec: The encryption spec of the RagCorpus.\n    timeout: Default is 600 seconds.\n\nReturns:\n    RagCorpus.\nRaises:\n    RuntimeError: Failed in RagCorpus creation due to exception.\n    RuntimeError: Failed in RagCorpus\
      \ creation due to operation error."
  - signature: 'def update_corpus(corpus_name: str, display_name: typing.Optional[str], description: typing.Optional[str], vertex_ai_search_config: typing.Optional[vertexai.rag.utils.resources.VertexAiSearchConfig], backend_config: typing.Optional[typing.Union[vertexai.rag.utils.resources.RagVectorDbConfig, None]], timeout: int) -> vertexai.rag.utils.resources.RagCorpus:'
    docstring: "Updates a RagCorpus resource.\n\nIt is intended to update 3rd party vector DBs (Vector Search, Vertex AI\nFeature Store, Weaviate, Pinecone) but not Vertex RagManagedDb.\n\nExample usage:\n```\nimport vertexai\nfrom vertexai import rag\n\nvertexai.init(project=\"my-project\")\n\nrag_corpus = rag.update_corpus(\n    corpus_name=\"projects/my-project/locations/us-central1/ragCorpora/my-corpus-1\",\n    display_name=\"my-corpus-1\",\n)\n```\n\nArgs:\n    corpus_name: The name of the RagCorpus resource to update. Format:\n      ``projects/{project}/locations/{location}/ragCorpora/{rag_corpus}`` or\n      ``{rag_corpus}``.\n    display_name: If not provided, the display name will not be updated. The\n      display name of the RagCorpus. The name can be up to 128 characters long\n      and can consist of any UTF-8 characters.\n    description: The description of the RagCorpus. If not provided, the\n      description will not be updated.\n    vertex_ai_search_config: The Vertex\
      \ AI Search config of the RagCorpus. If\n      not provided, the Vertex AI Search config will not be updated.\n      Note: backend_config cannot be set if vertex_ai_search_config is\n        specified.\n    backend_config: The backend config of the RagCorpus, specifying a data\n      store and/or embedding model.\n    timeout: Default is 600 seconds.\n\nReturns:\n    RagCorpus.\nRaises:\n    RuntimeError: Failed in RagCorpus update due to exception.\n    RuntimeError: Failed in RagCorpus update due to operation error."
  - signature: 'def get_corpus(name: str) -> vertexai.rag.utils.resources.RagCorpus:'
    docstring: "Get an existing RagCorpus.\n\nArgs:\n    name: An existing RagCorpus resource name. Format:\n        ``projects/{project}/locations/{location}/ragCorpora/{rag_corpus}``\n        or ``{rag_corpus}``.\nReturns:\n    RagCorpus."
  - signature: 'def list_corpora(page_size: typing.Optional[int], page_token: typing.Optional[str]) -> google.cloud.aiplatform_v1.services.vertex_rag_data_service.pagers.ListRagCorporaPager:'
    docstring: "List all RagCorpora in the same project and location.\n\nExample usage:\n```\nimport vertexai\nfrom vertexai import rag\n\nvertexai.init(project=\"my-project\")\n\n# List all corpora.\nrag_corpora = list(rag.list_corpora())\n\n# Alternatively, return a ListRagCorporaPager.\npager_1 = rag.list_corpora(page_size=10)\n# Then get the next page, use the generated next_page_token from the last pager.\npager_2 = rag.list_corpora(page_size=10, page_token=pager_1.next_page_token)\n\n```\nArgs:\n    page_size: The standard list page size. Leaving out the page_size\n        causes all of the results to be returned.\n    page_token: The standard list page token.\n\nReturns:\n    ListRagCorporaPager."
  - signature: 'def delete_corpus(name: str) -> None:'
    docstring: "Delete an existing RagCorpus.\n\nArgs:\n    name: An existing RagCorpus resource name. Format:\n        ``projects/{project}/locations/{location}/ragCorpora/{rag_corpus}``\n        or ``{rag_corpus}``."
  - signature: 'def upload_file(corpus_name: str, path: typing.Union[str, typing.Sequence[str]], display_name: typing.Optional[str], description: typing.Optional[str], transformation_config: typing.Optional[vertexai.rag.utils.resources.TransformationConfig], timeout: int) -> vertexai.rag.utils.resources.RagFile:'
    docstring: "Synchronous file upload to an existing RagCorpus.\n\nExample usage:\n\n```\nimport vertexai\nfrom vertexai import rag\n\nvertexai.init(project=\"my-project\")\n\n// Optional.\ntransformation_config = TransformationConfig(\n    chunking_config=ChunkingConfig(\n        chunk_size=1024,\n        chunk_overlap=200,\n    ),\n)\n\nrag_file = rag.upload_file(\n    corpus_name=\"projects/my-project/locations/us-central1/ragCorpora/my-corpus-1\",\n    display_name=\"my_file.txt\",\n    path=\"usr/home/my_file.txt\",\n    transformation_config=transformation_config,\n)\n```\n\nArgs:\n    corpus_name: The name of the RagCorpus resource into which to upload the file.\n        Format: ``projects/{project}/locations/{location}/ragCorpora/{rag_corpus}``\n        or ``{rag_corpus}``.\n    path: A local file path. For example,\n        \"usr/home/my_file.txt\".\n    display_name: The display name of the data file.\n    description: The description of the RagFile.\n    transformation_config:\
      \ The config for transforming the RagFile, like chunking.\n    timeout: Default is 600 seconds.\n\nReturns:\n    RagFile.\nRaises:\n    RuntimeError: Failed in RagFile upload.\n    ValueError: RagCorpus is not found.\n    RuntimeError: Failed in indexing the RagFile."
  - signature: 'def import_files(corpus_name: str, paths: typing.Optional[typing.Sequence[str]], source: typing.Optional[typing.Union[vertexai.rag.utils.resources.SlackChannelsSource, vertexai.rag.utils.resources.JiraSource, vertexai.rag.utils.resources.SharePointSources]], transformation_config: typing.Optional[vertexai.rag.utils.resources.TransformationConfig], timeout: int, max_embedding_requests_per_min: int, import_result_sink: typing.Optional[str], partial_failures_sink: typing.Optional[str], layout_parser: typing.Optional[vertexai.rag.utils.resources.LayoutParserConfig], llm_parser: typing.Optional[vertexai.rag.utils.resources.LlmParserConfig]) -> google.cloud.aiplatform_v1.ImportRagFilesResponse:'
    docstring: "Import files to an existing RagCorpus, wait until completion.\n\nExample usage:\n\n```\nimport vertexai\nfrom vertexai import rag\nfrom google.protobuf import timestamp_pb2\n\nvertexai.init(project=\"my-project\")\n# Google Drive example\npaths = [\n    \"https://drive.google.com/file/d/123\",\n    \"https://drive.google.com/drive/folders/456\"\n]\n# Google Cloud Storage example\npaths = [\"gs://my_bucket/my_files_dir\", ...]\n\ntransformation_config = TransformationConfig(\n    chunking_config=ChunkingConfig(\n        chunk_size=1024,\n        chunk_overlap=200,\n    ),\n)\n\nresponse = rag.import_files(\n    corpus_name=\"projects/my-project/locations/us-central1/ragCorpora/my-corpus-1\",\n    paths=paths,\n    transformation_config=transformation_config,\n)\n\n# Slack example\nstart_time = timestamp_pb2.Timestamp()\nstart_time.FromJsonString('2020-12-31T21:33:44Z')\nend_time = timestamp_pb2.Timestamp()\nend_time.GetCurrentTime()\nsource = rag.SlackChannelsSource(\n   \
      \ channels = [\n        SlackChannel(\"channel1\", \"api_key1\"),\n        SlackChannel(\"channel2\", \"api_key2\", start_time, end_time)\n    ],\n)\n# Jira Example\njira_query = rag.JiraQuery(\n    email=\"xxx@yyy.com\",\n    jira_projects=[\"project1\", \"project2\"],\n    custom_queries=[\"query1\", \"query2\"],\n    api_key=\"api_key\",\n    server_uri=\"server.atlassian.net\"\n)\nsource = rag.JiraSource(\n    queries=[jira_query],\n)\n\nresponse = rag.import_files(\n    corpus_name=\"projects/my-project/locations/us-central1/ragCorpora/my-corpus-1\",\n    source=source,\n    transformation_config=transformation_config,\n)\n\n# SharePoint Example.\nsharepoint_query = rag.SharePointSource(\n    sharepoint_folder_path=\"https://my-sharepoint-site.com/my-folder\",\n    sharepoint_site_name=\"my-sharepoint-site.com\",\n    client_id=\"my-client-id\",\n    client_secret=\"my-client-secret\",\n    tenant_id=\"my-tenant-id\",\n    drive_id=\"my-drive-id\",\n)\nsource = rag.SharePointSources(\n\
      \    share_point_sources=[sharepoint_query],\n)\n\n# Return the number of imported RagFiles after completion.\nprint(response.imported_rag_files_count)\n\n# Document AI Layout Parser example.\nparser = LayoutParserConfig(\n    processor_name=\"projects/my-project/locations/us-central1/processors/my-processor-id\",\n    max_parsing_requests_per_min=120,\n)\nresponse = rag.import_files(\n    corpus_name=\"projects/my-project/locations/us-central1/ragCorpora/my-corpus-1\",\n    paths=paths,\n    parser=parser,\n)\n\n```\nArgs:\n    corpus_name: The name of the RagCorpus resource into which to import files.\n        Format: ``projects/{project}/locations/{location}/ragCorpora/{rag_corpus}``\n        or ``{rag_corpus}``.\n    paths: A list of uris. Eligible uris will be Google Cloud Storage\n        directory (\"gs://my-bucket/my_dir\") or a Google Drive url for file\n        (https://drive.google.com/file/... or folder\n        \"https://drive.google.com/corp/drive/folders/...\").\n  \
      \  source: The source of the Slack or Jira import.\n        Must be either a SlackChannelsSource or JiraSource.\n    transformation_config: The config for transforming the imported\n        RagFiles.\n    max_embedding_requests_per_min:\n        Optional. The max number of queries per\n        minute that this job is allowed to make to the\n        embedding model specified on the corpus. This\n        value is specific to this job and not shared\n        across other import jobs. Consult the Quotas\n        page on the project to set an appropriate value\n        here. If unspecified, a default value of 1,000\n        QPM would be used.\n    timeout: Default is 600 seconds.\n    import_result_sink: Either a GCS path to store import results or a\n        BigQuery table to store import results. The format is\n        \"gs://my-bucket/my/object.ndjson\" for GCS or\n        \"bq://my-project.my-dataset.my-table\" for BigQuery. An existing GCS\n        object cannot be used. However, the\
      \ BigQuery table may or may not\n        exist - if it does not exist, it will be created. If it does exist,\n        the schema will be checked and the import results will be appended\n        to the table.\n    partial_failures_sink: Deprecated. Prefer to use `import_result_sink`.\n        Either a GCS path to store partial failures or a BigQuery table to\n        store partial failures. The format is\n        \"gs://my-bucket/my/object.ndjson\" for GCS or\n        \"bq://my-project.my-dataset.my-table\" for BigQuery. An existing GCS\n        object cannot be used. However, the BigQuery table may or may not\n        exist - if it does not exist, it will be created. If it does exist,\n        the schema will be checked and the partial failures will be appended\n        to the table.\n    parser: Document parser to use. Should be either None (default parser),\n        or a LayoutParserConfig (to parse documents using a Document AI\n        Layout Parser processor).\nReturns:\n    ImportRagFilesResponse."
  - signature: 'def import_files_async(corpus_name: str, paths: typing.Optional[typing.Sequence[str]], source: typing.Optional[typing.Union[vertexai.rag.utils.resources.SlackChannelsSource, vertexai.rag.utils.resources.JiraSource, vertexai.rag.utils.resources.SharePointSources]], transformation_config: typing.Optional[vertexai.rag.utils.resources.TransformationConfig], max_embedding_requests_per_min: int, import_result_sink: typing.Optional[str], partial_failures_sink: typing.Optional[str], layout_parser: typing.Optional[vertexai.rag.utils.resources.LayoutParserConfig], llm_parser: typing.Optional[vertexai.rag.utils.resources.LlmParserConfig]) -> google.api_core.operation_async.AsyncOperation:'
    docstring: "Import files to an existing RagCorpus asynchronously.\n\nExample usage:\n\n```\nimport vertexai\nfrom vertexai import rag\nfrom google.protobuf import timestamp_pb2\n\nvertexai.init(project=\"my-project\")\n\n# Google Drive example\npaths = [\n    \"https://drive.google.com/file/d/123\",\n    \"https://drive.google.com/drive/folders/456\"\n]\n# Google Cloud Storage example\npaths = [\"gs://my_bucket/my_files_dir\", ...]\n\ntransformation_config = TransformationConfig(\n    chunking_config=ChunkingConfig(\n        chunk_size=1024,\n        chunk_overlap=200,\n    ),\n)\n\nresponse = await rag.import_files_async(\n    corpus_name=\"projects/my-project/locations/us-central1/ragCorpora/my-corpus-1\",\n    paths=paths,\n    transformation_config=transformation_config,\n)\n\n# Slack example\nstart_time = timestamp_pb2.Timestamp()\nstart_time.FromJsonString('2020-12-31T21:33:44Z')\nend_time = timestamp_pb2.Timestamp()\nend_time.GetCurrentTime()\nsource = rag.SlackChannelsSource(\n\
      \    channels = [\n        SlackChannel(\"channel1\", \"api_key1\"),\n        SlackChannel(\"channel2\", \"api_key2\", start_time, end_time)\n    ],\n)\n# Jira Example\njira_query = rag.JiraQuery(\n    email=\"xxx@yyy.com\",\n    jira_projects=[\"project1\", \"project2\"],\n    custom_queries=[\"query1\", \"query2\"],\n    api_key=\"api_key\",\n    server_uri=\"server.atlassian.net\"\n)\nsource = rag.JiraSource(\n    queries=[jira_query],\n)\n\nresponse = await rag.import_files_async(\n    corpus_name=\"projects/my-project/locations/us-central1/ragCorpora/my-corpus-1\",\n    source=source,\n    transformation_config=transformation_config,\n)\n\n# SharePoint Example.\nsharepoint_query = rag.SharePointSource(\n    sharepoint_folder_path=\"https://my-sharepoint-site.com/my-folder\",\n    sharepoint_site_name=\"my-sharepoint-site.com\",\n    client_id=\"my-client-id\",\n    client_secret=\"my-client-secret\",\n    tenant_id=\"my-tenant-id\",\n    drive_id=\"my-drive-id\",\n)\nsource =\
      \ rag.SharePointSources(\n    share_point_sources=[sharepoint_query],\n)\n\n# Document AI Layout Parser example.\nparser = LayoutParserConfig(\n    processor_name=\"projects/my-project/locations/us-central1/processors/my-processor-id\",\n    max_parsing_requests_per_min=120,\n)\nresponse = rag.import_files_async(\n    corpus_name=\"projects/my-project/locations/us-central1/ragCorpora/my-corpus-1\",\n    paths=paths,\n    parser=parser,\n)\n\n# Get the result.\nawait response.result()\n\n```\nArgs:\n    corpus_name: The name of the RagCorpus resource into which to import files.\n        Format: ``projects/{project}/locations/{location}/ragCorpora/{rag_corpus}``\n        or ``{rag_corpus}``.\n    paths: A list of uris. Eligible uris will be Google Cloud Storage\n        directory (\"gs://my-bucket/my_dir\") or a Google Drive url for file\n        (https://drive.google.com/file/... or folder\n        \"https://drive.google.com/corp/drive/folders/...\").\n    source: The source of the\
      \ Slack or Jira import.\n        Must be either a SlackChannelsSource or JiraSource.\n    transformation_config: The config for transforming the imported\n        RagFiles.\n    max_embedding_requests_per_min:\n        Optional. The max number of queries per\n        minute that this job is allowed to make to the\n        embedding model specified on the corpus. This\n        value is specific to this job and not shared\n        across other import jobs. Consult the Quotas\n        page on the project to set an appropriate value\n        here. If unspecified, a default value of 1,000\n        QPM would be used.\n    import_result_sink: Either a GCS path to store import results or a\n        BigQuery table to store import results. The format is\n        \"gs://my-bucket/my/object.ndjson\" for GCS or\n        \"bq://my-project.my-dataset.my-table\" for BigQuery. An existing GCS\n        object cannot be used. However, the BigQuery table may or may not\n        exist - if it does not\
      \ exist, it will be created. If it does exist,\n        the schema will be checked and the import results will be appended\n        to the table.\n    partial_failures_sink: Deprecated. Prefer to use `import_result_sink`.\n        Either a GCS path to store partial failures or a BigQuery table to\n        store partial failures. The format is\n        \"gs://my-bucket/my/object.ndjson\" for GCS or\n        \"bq://my-project.my-dataset.my-table\" for BigQuery. An existing GCS\n        object cannot be used. However, the BigQuery table may or may not\n        exist - if it does not exist, it will be created. If it does exist,\n        the schema will be checked and the partial failures will be appended\n        to the table.\n    parser: Document parser to use. Should be either None (default parser),\n        or a LayoutParserConfig (to parse documents using a Document AI\n        Layout Parser processor).\nReturns:\n    operation_async.AsyncOperation."
  - signature: 'def get_file(name: str, corpus_name: typing.Optional[str]) -> vertexai.rag.utils.resources.RagFile:'
    docstring: "Get an existing RagFile.\n\nArgs:\n    name: Either a full RagFile resource name must be provided, or a RagCorpus\n        name and a RagFile name must be provided. Format:\n        ``projects/{project}/locations/{location}/ragCorpora/{rag_corpus}/ragFiles/{rag_file}``\n        or ``{rag_file}``.\n    corpus_name: If `name` is not a full resource name, an existing RagCorpus\n        name must be provided. Format:\n        ``projects/{project}/locations/{location}/ragCorpora/{rag_corpus}``\n        or ``{rag_corpus}``.\nReturns:\n    RagFile."
  - signature: 'def list_files(corpus_name: str, page_size: typing.Optional[int], page_token: typing.Optional[str]) -> google.cloud.aiplatform_v1.services.vertex_rag_data_service.pagers.ListRagFilesPager:'
    docstring: "List all RagFiles in an existing RagCorpus.\n\nExample usage:\n```\nimport vertexai\n\nvertexai.init(project=\"my-project\")\n# List all corpora.\nrag_corpora = list(rag.list_corpora())\n\n# List all files of the first corpus.\nrag_files = list(rag.list_files(corpus_name=rag_corpora[0].name))\n\n# Alternatively, return a ListRagFilesPager.\npager_1 = rag.list_files(\n    corpus_name=rag_corpora[0].name,\n    page_size=10\n)\n# Then get the next page, use the generated next_page_token from the last pager.\npager_2 = rag.list_files(\n    corpus_name=rag_corpora[0].name,\n    page_size=10,\n    page_token=pager_1.next_page_token\n)\n\n```\n\nArgs:\n    corpus_name: An existing RagCorpus name. Format:\n        ``projects/{project}/locations/{location}/ragCorpora/{rag_corpus}``\n        or ``{rag_corpus}``.\n    page_size: The standard list page size. Leaving out the page_size\n        causes all of the results to be returned.\n    page_token: The standard list page token.\nReturns:\n\
      \    ListRagFilesPager."
  - signature: 'def delete_file(name: str, corpus_name: typing.Optional[str]) -> None:'
    docstring: "Delete RagFile from an existing RagCorpus.\n\nArgs:\n    name: Either a full RagFile resource name must be provided, or a RagCorpus\n        name and a RagFile name must be provided. Format:\n        ``projects/{project}/locations/{location}/ragCorpora/{rag_corpus}/ragFiles/{rag_file}``\n        or ``{rag_file}``.\n    corpus_name: If `name` is not a full resource name, an existing RagCorpus\n        name must be provided. Format:\n        ``projects/{project}/locations/{location}/ragCorpora/{rag_corpus}``\n        or ``{rag_corpus}``."
  - signature: 'def update_rag_engine_config(rag_engine_config: vertexai.rag.utils.resources.RagEngineConfig, timeout: int) -> vertexai.rag.utils.resources.RagEngineConfig:'
    docstring: "Update RagEngineConfig.\n\nExample usage:\n```\nimport vertexai\nfrom vertexai import rag\nvertexai.init(project=\"my-project\")\nrag_engine_config = rag.RagEngineConfig(\n    rag_managed_db_config=rag.RagManagedDbConfig(\n        rag_managed_db=rag.RagManagedDb(\n            db_basic_tier=rag.Basic(),\n        ),\n    )\n    ),\n)\nrag.update_rag_engine_config(rag_engine_config=rag_engine_config)\n```\n\nArgs:\n    rag_engine_config: The RagEngineConfig to update.\n    timeout: Default is 600 seconds.\n\nRaises:\n    RuntimeError: Failed in RagEngineConfig update due to exception."
  - signature: 'def get_rag_engine_config(name: str) -> vertexai.rag.utils.resources.RagEngineConfig:'
    docstring: "Get an existing RagEngineConfig.\n\nExample usage:\n```\nimport vertexai\nfrom vertexai import rag\nvertexai.init(project=\"my-project\")\nrag_engine_config = rag.get_rag_engine_config(\n    name=\"projects/my-project/locations/us-central1/ragEngineConfig\"\n)\n```\nArgs:\n    name: The RagEngineConfig resource name pattern of the singleton resource.\n\nReturns:\n    RagEngineConfig.\nRaises:\n    RuntimeError: Failed in getting the RagEngineConfig."
  - signature: 'def add_inline_citations_and_references(original_text_str, grounding_supports, grounding_chunks) -> vertexai.rag.utils.resources.RagCitedGenerationResponse:'
    docstring: "Adds inline citations to a text string based on grounding_supports and grounding_chunks.\n\nArgs:\n    original_text_str (str): The text (as a Unicode string) to which citations\n      will be added.\n    grounding_supports (list): A list of objects, where each object represents\n      a grounding support and has attributes: - segment: An object with\n      'end_index' (byte offset relative to UTF-8). - grounding_chunk_indices:\n      A list of integers.\n    grounding_chunks (list): A list of objects, where each object is a source\n      chunk wrapper. To get URI: obj.retrieved_context.uri. To get page\n      span: obj.retrieved_context.rag_chunk.page_span.\n\nReturns:\n    RagCitedGenerationResponse: An object containing the text with inline\n                               citations and a formatted bibliography string.\n\nRaises:\n    TypeError: If original_text_str is not a string, or if grounding_supports,\n               grounding_chunks, or internally generated reference\
      \ dictionaries\n               are of an unexpected type (raised by this function or helpers).\n    ValueError: If original_text_str has encoding/decoding issues,\n                if segment data in grounding_supports is invalid,\n                if calculated insertion indices are out of bounds,\n                or if essential data within grounding_chunks (like the chunks\n                themselves, retrieved_context, or URI) is None when a value\n                is expected (raised by this function or helpers).\n    IndexError: If chunk indices used for citation or bibliography generation\n                are out of bounds for the provided grounding_chunks (raised by helpers).\n    AttributeError: If expected attributes (e.g., 'retrieved_context', 'uri')\n                    are missing from the data structures within grounding_chunks\n                    (raised by helpers).\n  Example usage:\n  ```\n  import vertexai\n\n  vertexai.init(project=\"my-project\")\n\n  rag_retrieval_tool\
      \ = Tool.from_retrieval(\n    retrieval=rag.Retrieval(\n        source=rag.VertexRagStore(\n            rag_resources=[\n                rag.RagResource(\n                    rag_corpus=corpus_name,\n                    # Optional: supply IDs from `rag.list_files()`.\n                    # rag_file_ids=[\"rag-file-1\", \"rag-file-2\", ...],\n                )\n            ],\n            rag_retrieval_config=rag.RagRetrievalConfig(\n                top_k=10,\n                filter=rag.utils.resources.Filter(vector_distance_threshold=0.5),\n            ),\n        ),\n    )\n  )\n\nrag_model = GenerativeModel(\n    model_name=\"gemini-2.5-pro-preview-05-06\", tools=[rag_retrieval_tool]\n)\nresponse = rag_model.generate_content(\"Why is the sky blue?\")\n\nrag_cited_generation_response = rag.add_inline_citations_and_references(\n    original_text_str=response.candidates[0].content.parts[0].text,\n    grounding_supports=list(response.candidates[0].grounding_metadata.grounding_supports),\n\
      \    grounding_chunks=list(response.candidates[0].grounding_metadata.grounding_chunks),\n)\nprint(rag_cited_generation_response.cited_text)\nprint(rag_cited_generation_response.final_bibliography)"
- rank: 3047
  id: vertexai.rag.rag_data.add_inline_citations_and_references
  name: add_inline_citations_and_references
  file_path: env/lib/python3.13/site-packages/vertexai/rag/rag_data.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Adds inline citations to a text string based on grounding_supports and grounding_chunks.\n\nArgs:\n    original_text_str (str): The text (as a Unicode string) to which citations\n      will be added.\n    grounding_supports (list): A list of objects, where each object represents\n      a grounding support and has attributes: - segment: An object with\n      'end_index' (byte offset relative to UTF-8). - grounding_chunk_indices:\n      A list of integers.\n    grounding_chunks (list): A list of objects, where each object is a source\n      chunk wrapper. To get URI: obj.retrieved_context.uri. To get page\n      span: obj.retrieved_context.rag_chunk.page_span.\n\nReturns:\n    RagCitedGenerationResponse: An object containing the text with inline\n                               citations and a formatted bibliography string.\n\nRaises:\n    TypeError: If original_text_str is not a string, or if grounding_supports,\n               grounding_chunks, or internally generated reference\
    \ dictionaries\n               are of an unexpected type (raised by this function or helpers).\n    ValueError: If original_text_str has encoding/decoding issues,\n                if segment data in grounding_supports is invalid,\n                if calculated insertion indices are out of bounds,\n                or if essential data within grounding_chunks (like the chunks\n                themselves, retrieved_context, or URI) is None when a value\n                is expected (raised by this function or helpers).\n    IndexError: If chunk indices used for citation or bibliography generation\n                are out of bounds for the provided grounding_chunks (raised by helpers).\n    AttributeError: If expected attributes (e.g., 'retrieved_context', 'uri')\n                    are missing from the data structures within grounding_chunks\n                    (raised by helpers).\n  Example usage:\n  ```\n  import vertexai\n\n  vertexai.init(project=\"my-project\")\n\n  rag_retrieval_tool\
    \ = Tool.from_retrieval(\n    retrieval=rag.Retrieval(\n        source=rag.VertexRagStore(\n            rag_resources=[\n                rag.RagResource(\n                    rag_corpus=corpus_name,\n                    # Optional: supply IDs from `rag.list_files()`.\n                    # rag_file_ids=[\"rag-file-1\", \"rag-file-2\", ...],\n                )\n            ],\n            rag_retrieval_config=rag.RagRetrievalConfig(\n                top_k=10,\n                filter=rag.utils.resources.Filter(vector_distance_threshold=0.5),\n            ),\n        ),\n    )\n  )\n\nrag_model = GenerativeModel(\n    model_name=\"gemini-2.5-pro-preview-05-06\", tools=[rag_retrieval_tool]\n)\nresponse = rag_model.generate_content(\"Why is the sky blue?\")\n\nrag_cited_generation_response = rag.add_inline_citations_and_references(\n    original_text_str=response.candidates[0].content.parts[0].text,\n    grounding_supports=list(response.candidates[0].grounding_metadata.grounding_supports),\n\
    \    grounding_chunks=list(response.candidates[0].grounding_metadata.grounding_chunks),\n)\nprint(rag_cited_generation_response.cited_text)\nprint(rag_cited_generation_response.final_bibliography)"
  signature: 'def add_inline_citations_and_references(original_text_str, grounding_supports, grounding_chunks) -> vertexai.rag.utils.resources.RagCitedGenerationResponse:'
  aliases:
  - vertexai.rag.add_inline_citations_and_references
- rank: 3048
  id: vertexai.rag.rag_data.create_corpus
  name: create_corpus
  file_path: env/lib/python3.13/site-packages/vertexai/rag/rag_data.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Creates a new RagCorpus resource.\n\nExample usage:\n```\nimport vertexai\nfrom vertexai import rag\n\nvertexai.init(project=\"my-project\")\n\nrag_corpus = rag.create_corpus(\n    display_name=\"my-corpus-1\",\n)\n```\n\nArgs:\n    display_name: If not provided, SDK will create one. The display name of\n      the RagCorpus. The name can be up to 128 characters long and can consist\n      of any UTF-8 characters.\n    description: The description of the RagCorpus.\n    vertex_ai_search_config: The Vertex AI Search config of the RagCorpus.\n        Note: backend_config cannot be set if vertex_ai_search_config is\n          specified.\n    backend_config: The backend config of the RagCorpus, specifying a data\n      store and/or embedding model.\n    encryption_spec: The encryption spec of the RagCorpus.\n    timeout: Default is 600 seconds.\n\nReturns:\n    RagCorpus.\nRaises:\n    RuntimeError: Failed in RagCorpus creation due to exception.\n    RuntimeError: Failed in RagCorpus\
    \ creation due to operation error."
  signature: 'def create_corpus(display_name: typing.Optional[str], description: typing.Optional[str], vertex_ai_search_config: typing.Optional[vertexai.rag.utils.resources.VertexAiSearchConfig], backend_config: typing.Optional[typing.Union[vertexai.rag.utils.resources.RagVectorDbConfig, None]], encryption_spec: typing.Optional[google.cloud.aiplatform_v1.types.EncryptionSpec], timeout: int) -> vertexai.rag.utils.resources.RagCorpus:'
  aliases:
  - vertexai.rag.create_corpus
- rank: 3049
  id: vertexai.rag.rag_data.delete_corpus
  name: delete_corpus
  file_path: env/lib/python3.13/site-packages/vertexai/rag/rag_data.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Delete an existing RagCorpus.\n\nArgs:\n    name: An existing RagCorpus resource name. Format:\n        ``projects/{project}/locations/{location}/ragCorpora/{rag_corpus}``\n        or ``{rag_corpus}``."
  signature: 'def delete_corpus(name: str) -> None:'
  aliases:
  - vertexai.rag.delete_corpus
- rank: 3050
  id: vertexai.rag.rag_data.delete_file
  name: delete_file
  file_path: env/lib/python3.13/site-packages/vertexai/rag/rag_data.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Delete RagFile from an existing RagCorpus.\n\nArgs:\n    name: Either a full RagFile resource name must be provided, or a RagCorpus\n        name and a RagFile name must be provided. Format:\n        ``projects/{project}/locations/{location}/ragCorpora/{rag_corpus}/ragFiles/{rag_file}``\n        or ``{rag_file}``.\n    corpus_name: If `name` is not a full resource name, an existing RagCorpus\n        name must be provided. Format:\n        ``projects/{project}/locations/{location}/ragCorpora/{rag_corpus}``\n        or ``{rag_corpus}``."
  signature: 'def delete_file(name: str, corpus_name: typing.Optional[str]) -> None:'
  aliases:
  - vertexai.rag.delete_file
- rank: 3051
  id: vertexai.rag.rag_data.get_corpus
  name: get_corpus
  file_path: env/lib/python3.13/site-packages/vertexai/rag/rag_data.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Get an existing RagCorpus.\n\nArgs:\n    name: An existing RagCorpus resource name. Format:\n        ``projects/{project}/locations/{location}/ragCorpora/{rag_corpus}``\n        or ``{rag_corpus}``.\nReturns:\n    RagCorpus."
  signature: 'def get_corpus(name: str) -> vertexai.rag.utils.resources.RagCorpus:'
  aliases:
  - vertexai.rag.get_corpus
- rank: 3052
  id: vertexai.rag.rag_data.get_file
  name: get_file
  file_path: env/lib/python3.13/site-packages/vertexai/rag/rag_data.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Get an existing RagFile.\n\nArgs:\n    name: Either a full RagFile resource name must be provided, or a RagCorpus\n        name and a RagFile name must be provided. Format:\n        ``projects/{project}/locations/{location}/ragCorpora/{rag_corpus}/ragFiles/{rag_file}``\n        or ``{rag_file}``.\n    corpus_name: If `name` is not a full resource name, an existing RagCorpus\n        name must be provided. Format:\n        ``projects/{project}/locations/{location}/ragCorpora/{rag_corpus}``\n        or ``{rag_corpus}``.\nReturns:\n    RagFile."
  signature: 'def get_file(name: str, corpus_name: typing.Optional[str]) -> vertexai.rag.utils.resources.RagFile:'
  aliases:
  - vertexai.rag.get_file
- rank: 3053
  id: vertexai.rag.rag_data.get_rag_engine_config
  name: get_rag_engine_config
  file_path: env/lib/python3.13/site-packages/vertexai/rag/rag_data.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Get an existing RagEngineConfig.\n\nExample usage:\n```\nimport vertexai\nfrom vertexai import rag\nvertexai.init(project=\"my-project\")\nrag_engine_config = rag.get_rag_engine_config(\n    name=\"projects/my-project/locations/us-central1/ragEngineConfig\"\n)\n```\nArgs:\n    name: The RagEngineConfig resource name pattern of the singleton resource.\n\nReturns:\n    RagEngineConfig.\nRaises:\n    RuntimeError: Failed in getting the RagEngineConfig."
  signature: 'def get_rag_engine_config(name: str) -> vertexai.rag.utils.resources.RagEngineConfig:'
  aliases:
  - vertexai.rag.get_rag_engine_config
- rank: 3054
  id: vertexai.rag.rag_data.import_files
  name: import_files
  file_path: env/lib/python3.13/site-packages/vertexai/rag/rag_data.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Import files to an existing RagCorpus, wait until completion.\n\nExample usage:\n\n```\nimport vertexai\nfrom vertexai import rag\nfrom google.protobuf import timestamp_pb2\n\nvertexai.init(project=\"my-project\")\n# Google Drive example\npaths = [\n    \"https://drive.google.com/file/d/123\",\n    \"https://drive.google.com/drive/folders/456\"\n]\n# Google Cloud Storage example\npaths = [\"gs://my_bucket/my_files_dir\", ...]\n\ntransformation_config = TransformationConfig(\n    chunking_config=ChunkingConfig(\n        chunk_size=1024,\n        chunk_overlap=200,\n    ),\n)\n\nresponse = rag.import_files(\n    corpus_name=\"projects/my-project/locations/us-central1/ragCorpora/my-corpus-1\",\n    paths=paths,\n    transformation_config=transformation_config,\n)\n\n# Slack example\nstart_time = timestamp_pb2.Timestamp()\nstart_time.FromJsonString('2020-12-31T21:33:44Z')\nend_time = timestamp_pb2.Timestamp()\nend_time.GetCurrentTime()\nsource = rag.SlackChannelsSource(\n    channels\
    \ = [\n        SlackChannel(\"channel1\", \"api_key1\"),\n        SlackChannel(\"channel2\", \"api_key2\", start_time, end_time)\n    ],\n)\n# Jira Example\njira_query = rag.JiraQuery(\n    email=\"xxx@yyy.com\",\n    jira_projects=[\"project1\", \"project2\"],\n    custom_queries=[\"query1\", \"query2\"],\n    api_key=\"api_key\",\n    server_uri=\"server.atlassian.net\"\n)\nsource = rag.JiraSource(\n    queries=[jira_query],\n)\n\nresponse = rag.import_files(\n    corpus_name=\"projects/my-project/locations/us-central1/ragCorpora/my-corpus-1\",\n    source=source,\n    transformation_config=transformation_config,\n)\n\n# SharePoint Example.\nsharepoint_query = rag.SharePointSource(\n    sharepoint_folder_path=\"https://my-sharepoint-site.com/my-folder\",\n    sharepoint_site_name=\"my-sharepoint-site.com\",\n    client_id=\"my-client-id\",\n    client_secret=\"my-client-secret\",\n    tenant_id=\"my-tenant-id\",\n    drive_id=\"my-drive-id\",\n)\nsource = rag.SharePointSources(\n \
    \   share_point_sources=[sharepoint_query],\n)\n\n# Return the number of imported RagFiles after completion.\nprint(response.imported_rag_files_count)\n\n# Document AI Layout Parser example.\nparser = LayoutParserConfig(\n    processor_name=\"projects/my-project/locations/us-central1/processors/my-processor-id\",\n    max_parsing_requests_per_min=120,\n)\nresponse = rag.import_files(\n    corpus_name=\"projects/my-project/locations/us-central1/ragCorpora/my-corpus-1\",\n    paths=paths,\n    parser=parser,\n)\n\n```\nArgs:\n    corpus_name: The name of the RagCorpus resource into which to import files.\n        Format: ``projects/{project}/locations/{location}/ragCorpora/{rag_corpus}``\n        or ``{rag_corpus}``.\n    paths: A list of uris. Eligible uris will be Google Cloud Storage\n        directory (\"gs://my-bucket/my_dir\") or a Google Drive url for file\n        (https://drive.google.com/file/... or folder\n        \"https://drive.google.com/corp/drive/folders/...\").\n    source:\
    \ The source of the Slack or Jira import.\n        Must be either a SlackChannelsSource or JiraSource.\n    transformation_config: The config for transforming the imported\n        RagFiles.\n    max_embedding_requests_per_min:\n        Optional. The max number of queries per\n        minute that this job is allowed to make to the\n        embedding model specified on the corpus. This\n        value is specific to this job and not shared\n        across other import jobs. Consult the Quotas\n        page on the project to set an appropriate value\n        here. If unspecified, a default value of 1,000\n        QPM would be used.\n    timeout: Default is 600 seconds.\n    import_result_sink: Either a GCS path to store import results or a\n        BigQuery table to store import results. The format is\n        \"gs://my-bucket/my/object.ndjson\" for GCS or\n        \"bq://my-project.my-dataset.my-table\" for BigQuery. An existing GCS\n        object cannot be used. However, the BigQuery\
    \ table may or may not\n        exist - if it does not exist, it will be created. If it does exist,\n        the schema will be checked and the import results will be appended\n        to the table.\n    partial_failures_sink: Deprecated. Prefer to use `import_result_sink`.\n        Either a GCS path to store partial failures or a BigQuery table to\n        store partial failures. The format is\n        \"gs://my-bucket/my/object.ndjson\" for GCS or\n        \"bq://my-project.my-dataset.my-table\" for BigQuery. An existing GCS\n        object cannot be used. However, the BigQuery table may or may not\n        exist - if it does not exist, it will be created. If it does exist,\n        the schema will be checked and the partial failures will be appended\n        to the table.\n    parser: Document parser to use. Should be either None (default parser),\n        or a LayoutParserConfig (to parse documents using a Document AI\n        Layout Parser processor).\nReturns:\n    ImportRagFilesResponse."
  signature: 'def import_files(corpus_name: str, paths: typing.Optional[typing.Sequence[str]], source: typing.Optional[typing.Union[vertexai.rag.utils.resources.SlackChannelsSource, vertexai.rag.utils.resources.JiraSource, vertexai.rag.utils.resources.SharePointSources]], transformation_config: typing.Optional[vertexai.rag.utils.resources.TransformationConfig], timeout: int, max_embedding_requests_per_min: int, import_result_sink: typing.Optional[str], partial_failures_sink: typing.Optional[str], layout_parser: typing.Optional[vertexai.rag.utils.resources.LayoutParserConfig], llm_parser: typing.Optional[vertexai.rag.utils.resources.LlmParserConfig]) -> google.cloud.aiplatform_v1.ImportRagFilesResponse:'
  aliases:
  - vertexai.rag.import_files
- rank: 3055
  id: vertexai.rag.rag_data.import_files_async
  name: import_files_async
  file_path: env/lib/python3.13/site-packages/vertexai/rag/rag_data.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Import files to an existing RagCorpus asynchronously.\n\nExample usage:\n\n```\nimport vertexai\nfrom vertexai import rag\nfrom google.protobuf import timestamp_pb2\n\nvertexai.init(project=\"my-project\")\n\n# Google Drive example\npaths = [\n    \"https://drive.google.com/file/d/123\",\n    \"https://drive.google.com/drive/folders/456\"\n]\n# Google Cloud Storage example\npaths = [\"gs://my_bucket/my_files_dir\", ...]\n\ntransformation_config = TransformationConfig(\n    chunking_config=ChunkingConfig(\n        chunk_size=1024,\n        chunk_overlap=200,\n    ),\n)\n\nresponse = await rag.import_files_async(\n    corpus_name=\"projects/my-project/locations/us-central1/ragCorpora/my-corpus-1\",\n    paths=paths,\n    transformation_config=transformation_config,\n)\n\n# Slack example\nstart_time = timestamp_pb2.Timestamp()\nstart_time.FromJsonString('2020-12-31T21:33:44Z')\nend_time = timestamp_pb2.Timestamp()\nend_time.GetCurrentTime()\nsource = rag.SlackChannelsSource(\n\
    \    channels = [\n        SlackChannel(\"channel1\", \"api_key1\"),\n        SlackChannel(\"channel2\", \"api_key2\", start_time, end_time)\n    ],\n)\n# Jira Example\njira_query = rag.JiraQuery(\n    email=\"xxx@yyy.com\",\n    jira_projects=[\"project1\", \"project2\"],\n    custom_queries=[\"query1\", \"query2\"],\n    api_key=\"api_key\",\n    server_uri=\"server.atlassian.net\"\n)\nsource = rag.JiraSource(\n    queries=[jira_query],\n)\n\nresponse = await rag.import_files_async(\n    corpus_name=\"projects/my-project/locations/us-central1/ragCorpora/my-corpus-1\",\n    source=source,\n    transformation_config=transformation_config,\n)\n\n# SharePoint Example.\nsharepoint_query = rag.SharePointSource(\n    sharepoint_folder_path=\"https://my-sharepoint-site.com/my-folder\",\n    sharepoint_site_name=\"my-sharepoint-site.com\",\n    client_id=\"my-client-id\",\n    client_secret=\"my-client-secret\",\n    tenant_id=\"my-tenant-id\",\n    drive_id=\"my-drive-id\",\n)\nsource = rag.SharePointSources(\n\
    \    share_point_sources=[sharepoint_query],\n)\n\n# Document AI Layout Parser example.\nparser = LayoutParserConfig(\n    processor_name=\"projects/my-project/locations/us-central1/processors/my-processor-id\",\n    max_parsing_requests_per_min=120,\n)\nresponse = rag.import_files_async(\n    corpus_name=\"projects/my-project/locations/us-central1/ragCorpora/my-corpus-1\",\n    paths=paths,\n    parser=parser,\n)\n\n# Get the result.\nawait response.result()\n\n```\nArgs:\n    corpus_name: The name of the RagCorpus resource into which to import files.\n        Format: ``projects/{project}/locations/{location}/ragCorpora/{rag_corpus}``\n        or ``{rag_corpus}``.\n    paths: A list of uris. Eligible uris will be Google Cloud Storage\n        directory (\"gs://my-bucket/my_dir\") or a Google Drive url for file\n        (https://drive.google.com/file/... or folder\n        \"https://drive.google.com/corp/drive/folders/...\").\n    source: The source of the Slack or Jira import.\n   \
    \     Must be either a SlackChannelsSource or JiraSource.\n    transformation_config: The config for transforming the imported\n        RagFiles.\n    max_embedding_requests_per_min:\n        Optional. The max number of queries per\n        minute that this job is allowed to make to the\n        embedding model specified on the corpus. This\n        value is specific to this job and not shared\n        across other import jobs. Consult the Quotas\n        page on the project to set an appropriate value\n        here. If unspecified, a default value of 1,000\n        QPM would be used.\n    import_result_sink: Either a GCS path to store import results or a\n        BigQuery table to store import results. The format is\n        \"gs://my-bucket/my/object.ndjson\" for GCS or\n        \"bq://my-project.my-dataset.my-table\" for BigQuery. An existing GCS\n        object cannot be used. However, the BigQuery table may or may not\n        exist - if it does not exist, it will be created. If\
    \ it does exist,\n        the schema will be checked and the import results will be appended\n        to the table.\n    partial_failures_sink: Deprecated. Prefer to use `import_result_sink`.\n        Either a GCS path to store partial failures or a BigQuery table to\n        store partial failures. The format is\n        \"gs://my-bucket/my/object.ndjson\" for GCS or\n        \"bq://my-project.my-dataset.my-table\" for BigQuery. An existing GCS\n        object cannot be used. However, the BigQuery table may or may not\n        exist - if it does not exist, it will be created. If it does exist,\n        the schema will be checked and the partial failures will be appended\n        to the table.\n    parser: Document parser to use. Should be either None (default parser),\n        or a LayoutParserConfig (to parse documents using a Document AI\n        Layout Parser processor).\nReturns:\n    operation_async.AsyncOperation."
  signature: 'def import_files_async(corpus_name: str, paths: typing.Optional[typing.Sequence[str]], source: typing.Optional[typing.Union[vertexai.rag.utils.resources.SlackChannelsSource, vertexai.rag.utils.resources.JiraSource, vertexai.rag.utils.resources.SharePointSources]], transformation_config: typing.Optional[vertexai.rag.utils.resources.TransformationConfig], max_embedding_requests_per_min: int, import_result_sink: typing.Optional[str], partial_failures_sink: typing.Optional[str], layout_parser: typing.Optional[vertexai.rag.utils.resources.LayoutParserConfig], llm_parser: typing.Optional[vertexai.rag.utils.resources.LlmParserConfig]) -> google.api_core.operation_async.AsyncOperation:'
  aliases:
  - vertexai.rag.import_files_async
- rank: 3056
  id: vertexai.rag.rag_data.list_corpora
  name: list_corpora
  file_path: env/lib/python3.13/site-packages/vertexai/rag/rag_data.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "List all RagCorpora in the same project and location.\n\nExample usage:\n```\nimport vertexai\nfrom vertexai import rag\n\nvertexai.init(project=\"my-project\")\n\n# List all corpora.\nrag_corpora = list(rag.list_corpora())\n\n# Alternatively, return a ListRagCorporaPager.\npager_1 = rag.list_corpora(page_size=10)\n# Then get the next page, use the generated next_page_token from the last pager.\npager_2 = rag.list_corpora(page_size=10, page_token=pager_1.next_page_token)\n\n```\nArgs:\n    page_size: The standard list page size. Leaving out the page_size\n        causes all of the results to be returned.\n    page_token: The standard list page token.\n\nReturns:\n    ListRagCorporaPager."
  signature: 'def list_corpora(page_size: typing.Optional[int], page_token: typing.Optional[str]) -> google.cloud.aiplatform_v1.services.vertex_rag_data_service.pagers.ListRagCorporaPager:'
  aliases:
  - vertexai.rag.list_corpora
- rank: 3057
  id: vertexai.rag.rag_data.list_files
  name: list_files
  file_path: env/lib/python3.13/site-packages/vertexai/rag/rag_data.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "List all RagFiles in an existing RagCorpus.\n\nExample usage:\n```\nimport vertexai\n\nvertexai.init(project=\"my-project\")\n# List all corpora.\nrag_corpora = list(rag.list_corpora())\n\n# List all files of the first corpus.\nrag_files = list(rag.list_files(corpus_name=rag_corpora[0].name))\n\n# Alternatively, return a ListRagFilesPager.\npager_1 = rag.list_files(\n    corpus_name=rag_corpora[0].name,\n    page_size=10\n)\n# Then get the next page, use the generated next_page_token from the last pager.\npager_2 = rag.list_files(\n    corpus_name=rag_corpora[0].name,\n    page_size=10,\n    page_token=pager_1.next_page_token\n)\n\n```\n\nArgs:\n    corpus_name: An existing RagCorpus name. Format:\n        ``projects/{project}/locations/{location}/ragCorpora/{rag_corpus}``\n        or ``{rag_corpus}``.\n    page_size: The standard list page size. Leaving out the page_size\n        causes all of the results to be returned.\n    page_token: The standard list page token.\nReturns:\n\
    \    ListRagFilesPager."
  signature: 'def list_files(corpus_name: str, page_size: typing.Optional[int], page_token: typing.Optional[str]) -> google.cloud.aiplatform_v1.services.vertex_rag_data_service.pagers.ListRagFilesPager:'
  aliases:
  - vertexai.rag.list_files
- rank: 3058
  id: vertexai.rag.rag_data.update_corpus
  name: update_corpus
  file_path: env/lib/python3.13/site-packages/vertexai/rag/rag_data.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Updates a RagCorpus resource.\n\nIt is intended to update 3rd party vector DBs (Vector Search, Vertex AI\nFeature Store, Weaviate, Pinecone) but not Vertex RagManagedDb.\n\nExample usage:\n```\nimport vertexai\nfrom vertexai import rag\n\nvertexai.init(project=\"my-project\")\n\nrag_corpus = rag.update_corpus(\n    corpus_name=\"projects/my-project/locations/us-central1/ragCorpora/my-corpus-1\",\n    display_name=\"my-corpus-1\",\n)\n```\n\nArgs:\n    corpus_name: The name of the RagCorpus resource to update. Format:\n      ``projects/{project}/locations/{location}/ragCorpora/{rag_corpus}`` or\n      ``{rag_corpus}``.\n    display_name: If not provided, the display name will not be updated. The\n      display name of the RagCorpus. The name can be up to 128 characters long\n      and can consist of any UTF-8 characters.\n    description: The description of the RagCorpus. If not provided, the\n      description will not be updated.\n    vertex_ai_search_config: The Vertex AI\
    \ Search config of the RagCorpus. If\n      not provided, the Vertex AI Search config will not be updated.\n      Note: backend_config cannot be set if vertex_ai_search_config is\n        specified.\n    backend_config: The backend config of the RagCorpus, specifying a data\n      store and/or embedding model.\n    timeout: Default is 600 seconds.\n\nReturns:\n    RagCorpus.\nRaises:\n    RuntimeError: Failed in RagCorpus update due to exception.\n    RuntimeError: Failed in RagCorpus update due to operation error."
  signature: 'def update_corpus(corpus_name: str, display_name: typing.Optional[str], description: typing.Optional[str], vertex_ai_search_config: typing.Optional[vertexai.rag.utils.resources.VertexAiSearchConfig], backend_config: typing.Optional[typing.Union[vertexai.rag.utils.resources.RagVectorDbConfig, None]], timeout: int) -> vertexai.rag.utils.resources.RagCorpus:'
  aliases:
  - vertexai.rag.update_corpus
- rank: 3059
  id: vertexai.rag.rag_data.update_rag_engine_config
  name: update_rag_engine_config
  file_path: env/lib/python3.13/site-packages/vertexai/rag/rag_data.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Update RagEngineConfig.\n\nExample usage:\n```\nimport vertexai\nfrom vertexai import rag\nvertexai.init(project=\"my-project\")\nrag_engine_config = rag.RagEngineConfig(\n    rag_managed_db_config=rag.RagManagedDbConfig(\n        rag_managed_db=rag.RagManagedDb(\n            db_basic_tier=rag.Basic(),\n        ),\n    )\n    ),\n)\nrag.update_rag_engine_config(rag_engine_config=rag_engine_config)\n```\n\nArgs:\n    rag_engine_config: The RagEngineConfig to update.\n    timeout: Default is 600 seconds.\n\nRaises:\n    RuntimeError: Failed in RagEngineConfig update due to exception."
  signature: 'def update_rag_engine_config(rag_engine_config: vertexai.rag.utils.resources.RagEngineConfig, timeout: int) -> vertexai.rag.utils.resources.RagEngineConfig:'
  aliases:
  - vertexai.rag.update_rag_engine_config
- rank: 3060
  id: vertexai.rag.rag_data.upload_file
  name: upload_file
  file_path: env/lib/python3.13/site-packages/vertexai/rag/rag_data.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Synchronous file upload to an existing RagCorpus.\n\nExample usage:\n\n```\nimport vertexai\nfrom vertexai import rag\n\nvertexai.init(project=\"my-project\")\n\n// Optional.\ntransformation_config = TransformationConfig(\n    chunking_config=ChunkingConfig(\n        chunk_size=1024,\n        chunk_overlap=200,\n    ),\n)\n\nrag_file = rag.upload_file(\n    corpus_name=\"projects/my-project/locations/us-central1/ragCorpora/my-corpus-1\",\n    display_name=\"my_file.txt\",\n    path=\"usr/home/my_file.txt\",\n    transformation_config=transformation_config,\n)\n```\n\nArgs:\n    corpus_name: The name of the RagCorpus resource into which to upload the file.\n        Format: ``projects/{project}/locations/{location}/ragCorpora/{rag_corpus}``\n        or ``{rag_corpus}``.\n    path: A local file path. For example,\n        \"usr/home/my_file.txt\".\n    display_name: The display name of the data file.\n    description: The description of the RagFile.\n    transformation_config:\
    \ The config for transforming the RagFile, like chunking.\n    timeout: Default is 600 seconds.\n\nReturns:\n    RagFile.\nRaises:\n    RuntimeError: Failed in RagFile upload.\n    ValueError: RagCorpus is not found.\n    RuntimeError: Failed in indexing the RagFile."
  signature: 'def upload_file(corpus_name: str, path: typing.Union[str, typing.Sequence[str]], display_name: typing.Optional[str], description: typing.Optional[str], transformation_config: typing.Optional[vertexai.rag.utils.resources.TransformationConfig], timeout: int) -> vertexai.rag.utils.resources.RagFile:'
  aliases:
  - vertexai.rag.upload_file
- rank: 3061
  id: vertexai.rag.rag_inline_citations
  name: rag_inline_citations
  file_path: env/lib/python3.13/site-packages/vertexai/rag/rag_inline_citations.py
  type: MODULE
  group: Orphan
  usage_score: 0
  docstring: Helper functions for processing and formatting citations from RAG generation outputs.
  methods:
  - signature: 'def populate_cited_chunk_references(grounding_supports, grounding_chunks, cited_refs_dict) -> None:'
    docstring: "Populates cited_refs_dict with URI information for all unique chunk indices found in grounding_supports.\n\nArgs:\n    grounding_supports: A list of support items, where each item might contain\n      grounding chunk indices.\n    grounding_chunks: A list of all available chunk items from which to retrieve\n      context and URI.\n    cited_refs_dict: A dictionary to populate with chunk_idx as key and URI\n      as value.\n\nRaises:\n    TypeError: If grounding_chunks is not a list, or cited_refs_dict is not a\n      dictionary.\n    ValueError: If grounding_chunks or cited_refs_dict is None.\n                If a chunk_item at a valid index is None.\n                If 'retrieved_context' or 'uri' attribute of a chunk is None.\n    IndexError: If a chunk_idx is out of bounds for grounding_chunks.\n    AttributeError: If 'retrieved_context' or 'uri' attribute is missing from\n      a chunk or its context."
  - signature: 'def format_bibliography(cited_refs_dict, grounding_chunks) -> str:'
    docstring: "Formats the bibliography string from the populated cited_refs_dict.\n\nOmits page information if page numbers are not valid (e.g., not >= 1).\n\nArgs:\n    cited_refs_dict: A dictionary with chunk_idx as key and URI as value.\n      It's expected that populate_cited_chunk_references has successfully\n      populated this dict.\n    grounding_chunks: A list of all available chunk items, used to retrieve page\n      span information.\n\nReturns:\n    A string representing the formatted bibliography, with each reference\n    on a new line.\n\nRaises:\n    TypeError: If cited_refs_dict is not a dictionary or grounding_chunks is not a list.\n    ValueError: If cited_refs_dict or grounding_chunks is None.\n                If a chunk_item in grounding_chunks referenced by cited_refs_dict is None.\n    IndexError: If a chunk_idx from cited_refs_dict is out of bounds for\n      grounding_chunks."
- rank: 3062
  id: vertexai.rag.rag_inline_citations.format_bibliography
  name: format_bibliography
  file_path: env/lib/python3.13/site-packages/vertexai/rag/rag_inline_citations.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Formats the bibliography string from the populated cited_refs_dict.\n\nOmits page information if page numbers are not valid (e.g., not >= 1).\n\nArgs:\n    cited_refs_dict: A dictionary with chunk_idx as key and URI as value.\n      It's expected that populate_cited_chunk_references has successfully\n      populated this dict.\n    grounding_chunks: A list of all available chunk items, used to retrieve page\n      span information.\n\nReturns:\n    A string representing the formatted bibliography, with each reference\n    on a new line.\n\nRaises:\n    TypeError: If cited_refs_dict is not a dictionary or grounding_chunks is not a list.\n    ValueError: If cited_refs_dict or grounding_chunks is None.\n                If a chunk_item in grounding_chunks referenced by cited_refs_dict is None.\n    IndexError: If a chunk_idx from cited_refs_dict is out of bounds for\n      grounding_chunks."
  signature: 'def format_bibliography(cited_refs_dict, grounding_chunks) -> str:'
- rank: 3063
  id: vertexai.rag.rag_inline_citations.populate_cited_chunk_references
  name: populate_cited_chunk_references
  file_path: env/lib/python3.13/site-packages/vertexai/rag/rag_inline_citations.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Populates cited_refs_dict with URI information for all unique chunk indices found in grounding_supports.\n\nArgs:\n    grounding_supports: A list of support items, where each item might contain\n      grounding chunk indices.\n    grounding_chunks: A list of all available chunk items from which to retrieve\n      context and URI.\n    cited_refs_dict: A dictionary to populate with chunk_idx as key and URI\n      as value.\n\nRaises:\n    TypeError: If grounding_chunks is not a list, or cited_refs_dict is not a\n      dictionary.\n    ValueError: If grounding_chunks or cited_refs_dict is None.\n                If a chunk_item at a valid index is None.\n                If 'retrieved_context' or 'uri' attribute of a chunk is None.\n    IndexError: If a chunk_idx is out of bounds for grounding_chunks.\n    AttributeError: If 'retrieved_context' or 'uri' attribute is missing from\n      a chunk or its context."
  signature: 'def populate_cited_chunk_references(grounding_supports, grounding_chunks, cited_refs_dict) -> None:'
- rank: 3064
  id: vertexai.rag.rag_retrieval
  name: rag_retrieval
  file_path: env/lib/python3.13/site-packages/vertexai/rag/rag_retrieval.py
  type: MODULE
  group: Orphan
  usage_score: 0
  docstring: Retrieval query to get relevant contexts.
  methods:
  - signature: 'def retrieval_query(text: str, parent_override: typing.Optional[str], api_path_override: typing.Optional[str], rag_resources: typing.Optional[typing.List[vertexai.rag.utils.resources.RagResource]], rag_retrieval_config: typing.Optional[vertexai.rag.utils.resources.RagRetrievalConfig]) -> google.cloud.aiplatform_v1.RetrieveContextsResponse:'
    docstring: "Retrieve top k relevant docs/chunks.\n\nExample usage:\n```\nimport vertexai\n\nvertexai.init(project=\"my-project\")\n\nconfig = vertexai.rag.rag_retrieval_config(\n    top_k=2,\n    filter=vertexai.rag.rag_retrieval_config.filter(\n        vector_distance_threshold=0.5\n    ),\n    ranking=vertex.rag.Ranking(\n        llm_ranker=vertexai.rag.LlmRanker(\n            model_name=\"gemini-1.5-flash-002\"\n        )\n    )\n)\n\nresults = vertexai.rag.retrieval_query(\n    text=\"Why is the sky blue?\",\n    rag_resources=[vertexai.rag.RagResource(\n        rag_corpus=\"projects/my-project/locations/us-central1/ragCorpora/rag-corpus-1\",\n        rag_file_ids=[\"rag-file-1\", \"rag-file-2\", ...],\n    )],\n    rag_retrieval_config=config,\n)\n```\n\nArgs:\n    text: The query in text format to get relevant contexts.\n    parent_override: Optional. The resource path of the parent.\n    api_path_override: Optional. The base API endpoint to use for the request.\n    rag_resources:\
      \ A list of RagResource. It can be used to specify corpus\n        only or ragfiles. Currently only support one corpus or multiple files\n        from one corpus. In the future we may open up multiple corpora support.\n    rag_retrieval_config: Optional. The config containing the retrieval\n        parameters, including similarity_top_k and vector_distance_threshold\n\nReturns:\n    RetrieveContextsResonse."
- rank: 3065
  id: vertexai.rag.rag_retrieval.retrieval_query
  name: retrieval_query
  file_path: env/lib/python3.13/site-packages/vertexai/rag/rag_retrieval.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Retrieve top k relevant docs/chunks.\n\nExample usage:\n```\nimport vertexai\n\nvertexai.init(project=\"my-project\")\n\nconfig = vertexai.rag.rag_retrieval_config(\n    top_k=2,\n    filter=vertexai.rag.rag_retrieval_config.filter(\n        vector_distance_threshold=0.5\n    ),\n    ranking=vertex.rag.Ranking(\n        llm_ranker=vertexai.rag.LlmRanker(\n            model_name=\"gemini-1.5-flash-002\"\n        )\n    )\n)\n\nresults = vertexai.rag.retrieval_query(\n    text=\"Why is the sky blue?\",\n    rag_resources=[vertexai.rag.RagResource(\n        rag_corpus=\"projects/my-project/locations/us-central1/ragCorpora/rag-corpus-1\",\n        rag_file_ids=[\"rag-file-1\", \"rag-file-2\", ...],\n    )],\n    rag_retrieval_config=config,\n)\n```\n\nArgs:\n    text: The query in text format to get relevant contexts.\n    parent_override: Optional. The resource path of the parent.\n    api_path_override: Optional. The base API endpoint to use for the request.\n    rag_resources:\
    \ A list of RagResource. It can be used to specify corpus\n        only or ragfiles. Currently only support one corpus or multiple files\n        from one corpus. In the future we may open up multiple corpora support.\n    rag_retrieval_config: Optional. The config containing the retrieval\n        parameters, including similarity_top_k and vector_distance_threshold\n\nReturns:\n    RetrieveContextsResonse."
  signature: 'def retrieval_query(text: str, parent_override: typing.Optional[str], api_path_override: typing.Optional[str], rag_resources: typing.Optional[typing.List[vertexai.rag.utils.resources.RagResource]], rag_retrieval_config: typing.Optional[vertexai.rag.utils.resources.RagRetrievalConfig]) -> google.cloud.aiplatform_v1.RetrieveContextsResponse:'
- rank: 3066
  id: vertexai.rag.rag_store
  name: rag_store
  file_path: env/lib/python3.13/site-packages/vertexai/rag/rag_store.py
  type: MODULE
  group: Orphan
  usage_score: 0
  docstring: RAG retrieval tool for content generation.
- rank: 3067
  id: vertexai.rag.rag_store.Retrieval
  name: Retrieval
  file_path: env/lib/python3.13/site-packages/vertexai/rag/rag_store.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Defines a retrieval tool that a model can call to access external knowledge.


    [Note: Inherited members from generative_models.grounding.Retrieval are omitted.]'
  constructor_signature: 'def __init__(self, source: typing.Union[vertexai.rag.rag_store.VertexRagStore], disable_attribution: typing.Optional[bool]):'
  aliases:
  - vertexai.rag.Retrieval
  omitted_inherited_members_from:
  - generative_models.grounding.Retrieval
- rank: 3068
  id: vertexai.rag.rag_store.Retrieval.__init__
  name: __init__
  file_path: env/lib/python3.13/site-packages/vertexai/rag/rag_store.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def __init__(self, source: typing.Union[vertexai.rag.rag_store.VertexRagStore], disable_attribution: typing.Optional[bool]):'
- rank: 3069
  id: vertexai.rag.rag_store.VertexRagStore
  name: VertexRagStore
  file_path: env/lib/python3.13/site-packages/vertexai/rag/rag_store.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: Retrieve from Vertex RAG Store.
  constructor_signature: 'def __init__(self, rag_resources: typing.Optional[typing.List[vertexai.rag.utils.resources.RagResource]], rag_retrieval_config: typing.Optional[vertexai.rag.utils.resources.RagRetrievalConfig]):'
  aliases:
  - vertexai.rag.VertexRagStore
- rank: 3070
  id: vertexai.rag.rag_store.VertexRagStore.__init__
  name: __init__
  file_path: env/lib/python3.13/site-packages/vertexai/rag/rag_store.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Initializes a Vertex RAG store tool.\n\nExample usage:\n```\nimport vertexai\n\nvertexai.init(project=\"my-project\")\n\nconfig = vertexai.rag.RagRetrievalConfig(\n    top_k=2,\n    filter=vertexai.rag.RagRetrievalConfig.Filter(\n        vector_distance_threshold=0.5\n    ),\n    ranking=vertex.rag.Ranking(\n        llm_ranker=vertexai.rag.LlmRanker(\n            model_name=\"gemini-1.5-flash-002\"\n        )\n    )\n)\n\ntool = Tool.from_retrieval(\n    retrieval=vertexai.rag.Retrieval(\n        source=vertexai.rag.VertexRagStore(\n            rag_corpora=[\"projects/my-project/locations/us-central1/ragCorpora/rag-corpus-1\"],\n            rag_retrieval_config=config,\n        ),\n    )\n)\n```\n\nArgs:\n    rag_resources: List of RagResource to retrieve from. It can be used\n        to specify corpus only or ragfiles. Currently only support one\n        corpus or multiple files from one corpus. In the future we\n        may open up multiple corpora support.\n    rag_retrieval_config:\
    \ Optional. The config containing the retrieval\n        parameters, including similarity_top_k and vector_distance_threshold."
  signature: 'def __init__(self, rag_resources: typing.Optional[typing.List[vertexai.rag.utils.resources.RagResource]], rag_retrieval_config: typing.Optional[vertexai.rag.utils.resources.RagRetrievalConfig]):'
- rank: 3071
  id: vertexai.rag.utils.resources
  name: resources
  file_path: env/lib/python3.13/site-packages/vertexai/rag/utils/resources.py
  type: MODULE
  group: Orphan
  usage_score: 0
- rank: 3072
  id: vertexai.rag.utils.resources.Basic
  name: Basic
  file_path: env/lib/python3.13/site-packages/vertexai/rag/utils/resources.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Basic tier is a cost-effective and low compute tier suitable for the following cases:


    * Experimenting with RagManagedDb.

    * Small data size.

    * Latency insensitive workload.

    * Only using RAG Engine with external vector DBs.


    NOTE: This is the default tier if not explicitly chosen.'
- rank: 3073
  id: vertexai.rag.utils.resources.ChunkingConfig
  name: ChunkingConfig
  file_path: env/lib/python3.13/site-packages/vertexai/rag/utils/resources.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: "ChunkingConfig.\n\nAttributes:\n    chunk_size: The size of each chunk.\n    chunk_overlap: The size of the overlap between chunks."
  constructor_signature: 'def __init__(self, *, chunk_size: int, chunk_overlap: int):'
  properties:
  - signature: 'chunk_size: int'
  - signature: 'chunk_overlap: int'
- rank: 3074
  id: vertexai.rag.utils.resources.Filter
  name: Filter
  file_path: env/lib/python3.13/site-packages/vertexai/rag/utils/resources.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: "Filter.\n\nAttributes:\n    vector_distance_threshold: Only returns contexts with vector\n        distance smaller than the threshold.\n    vector_similarity_threshold: Only returns contexts with vector\n        similarity larger than the threshold.\n    metadata_filter: String for metadata filtering."
  constructor_signature: 'def __init__(self, *, vector_distance_threshold: typing.Optional[float] = None, vector_similarity_threshold: typing.Optional[float] = None, metadata_filter: typing.Optional[str] = None):'
  properties:
  - signature: 'vector_distance_threshold: typing.Optional[float]'
  - signature: 'vector_similarity_threshold: typing.Optional[float]'
  - signature: 'metadata_filter: typing.Optional[str]'
- rank: 3075
  id: vertexai.rag.utils.resources.JiraQuery
  name: JiraQuery
  file_path: env/lib/python3.13/site-packages/vertexai/rag/utils/resources.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: "JiraQuery.\n\nAttributes:\n    email: The Jira email address.\n    jira_projects: A list of Jira projects to import in their entirety.\n    custom_queries: A list of custom JQL Jira queries to import.\n    api_key: The SecretManager version resource name for Jira API access. Format:\n        ``projects/{project}/secrets/{secret}/versions/{version}``\n        See: https://support.atlassian.com/atlassian-account/docs/manage-api-tokens-for-your-atlassian-account/\n    server_uri: The Jira server URI. Format:\n        ``{server}.atlassian.net``"
  constructor_signature: 'def __init__(self, *, email: str, jira_projects: typing.Sequence[str], custom_queries: typing.Sequence[str], api_key: str, server_uri: str):'
  properties:
  - signature: 'email: str'
  - signature: 'jira_projects: typing.Sequence[str]'
  - signature: 'custom_queries: typing.Sequence[str]'
  - signature: 'api_key: str'
  - signature: 'server_uri: str'
- rank: 3076
  id: vertexai.rag.utils.resources.JiraSource
  name: JiraSource
  file_path: env/lib/python3.13/site-packages/vertexai/rag/utils/resources.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: "JiraSource.\n\nAttributes:\n    queries: The Jira queries."
  constructor_signature: 'def __init__(self, *, queries: typing.Sequence[vertexai.rag.utils.resources.JiraQuery]):'
  properties:
  - signature: 'queries: typing.Sequence[vertexai.rag.utils.resources.JiraQuery]'
- rank: 3077
  id: vertexai.rag.utils.resources.LayoutParserConfig
  name: LayoutParserConfig
  file_path: env/lib/python3.13/site-packages/vertexai/rag/utils/resources.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: "Configuration for the Document AI Layout Parser Processor.\n\nAttributes:\n    processor_name: The full resource name of a Document AI processor or\n        processor version. The processor must have type\n        `LAYOUT_PARSER_PROCESSOR`.\n        Format must be one of the following:\n        -  `projects/{project_id}/locations/{location}/processors/{processor_id}`\n        -  `projects/{project_id}/locations/{location}/processors/{processor_id}/processorVersions/{processor_version_id}`\n    max_parsing_requests_per_min: The maximum number of requests the job is\n        allowed to make to the Document AI processor per minute. Consult\n        https://cloud.google.com/document-ai/quotas and the Quota page for\n        your project to set an appropriate value here. If unspecified, a\n        default value of 120 QPM will be used."
  constructor_signature: 'def __init__(self, *, processor_name: str, max_parsing_requests_per_min: typing.Optional[int] = None):'
  properties:
  - signature: 'processor_name: str'
  - signature: 'max_parsing_requests_per_min: typing.Optional[int]'
- rank: 3078
  id: vertexai.rag.utils.resources.LlmParserConfig
  name: LlmParserConfig
  file_path: env/lib/python3.13/site-packages/vertexai/rag/utils/resources.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: "Configuration for the Document AI Layout Parser Processor.\n\nAttributes:\n    model_name (str):\n        The full resource name of a Vertex AI model. Format:\n        -  `projects/{project_id}/locations/{location}/publishers/google/models/{model_id}`\n        -  `projects/{project_id}/locations/{location}/models/{model_id}`\n    max_parsing_requests_per_min (int):\n        The maximum number of requests the job is allowed to make to the\n        Vertex AI model per minute. Consult\n        https://cloud.google.com/vertex-ai/generative-ai/docs/quotas and\n        the Quota page for your project to set an appropriate value here.\n        If unspecified, a default value of 120 QPM will be used.\n    custom_parsing_prompt (str):\n        A custom prompt to use for parsing."
  constructor_signature: 'def __init__(self, *, model_name: str, max_parsing_requests_per_min: typing.Optional[int] = None, custom_parsing_prompt: typing.Optional[str] = None):'
  properties:
  - signature: 'model_name: str'
  - signature: 'max_parsing_requests_per_min: typing.Optional[int]'
  - signature: 'custom_parsing_prompt: typing.Optional[str]'
- rank: 3079
  id: vertexai.rag.utils.resources.LlmRanker
  name: LlmRanker
  file_path: env/lib/python3.13/site-packages/vertexai/rag/utils/resources.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: "LlmRanker.\n\nAttributes:\n    model_name: The model name used for ranking. Only Gemini models are\n        supported for now."
  constructor_signature: 'def __init__(self, *, model_name: typing.Optional[str] = None):'
  properties:
  - signature: 'model_name: typing.Optional[str]'
- rank: 3080
  id: vertexai.rag.utils.resources.Pinecone
  name: Pinecone
  file_path: env/lib/python3.13/site-packages/vertexai/rag/utils/resources.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: "Pinecone.\n\nAttributes:\n    index_name: The Pinecone index name.\n    api_key: The SecretManager resource name for the Pinecone DB API token. Format:\n        ``projects/{project}/secrets/{secret}/versions/{version}``"
  constructor_signature: 'def __init__(self, *, index_name: typing.Optional[str] = None, api_key: typing.Optional[str] = None):'
  properties:
  - signature: 'index_name: typing.Optional[str]'
  - signature: 'api_key: typing.Optional[str]'
- rank: 3081
  id: vertexai.rag.utils.resources.RagCitedGenerationResponse
  name: RagCitedGenerationResponse
  file_path: env/lib/python3.13/site-packages/vertexai/rag/utils/resources.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: "RagCitedGenerationResponse.\n\nAttributes:\n    cited_text: The text with inline citations.\n    final_bibliography: List of all unique cited chunks, their URIs, and page\n      numbers (if applicable)."
  constructor_signature: 'def __init__(self, *, cited_text: str, final_bibliography: str):'
  properties:
  - signature: 'cited_text: str'
  - signature: 'final_bibliography: str'
- rank: 3082
  id: vertexai.rag.utils.resources.RagCorpus
  name: RagCorpus
  file_path: env/lib/python3.13/site-packages/vertexai/rag/utils/resources.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: "RAG corpus(output only).\n\nAttributes:\n    name: Generated resource name. Format:\n        ``projects/{project}/locations/{location}/ragCorpora/{rag_corpus_id}``\n    display_name: Display name that was configured at client side.\n    description: The description of the RagCorpus.\n    vertex_ai_search_config: The Vertex AI Search config of the RagCorpus.\n    backend_config: The backend config of the RagCorpus. It can be a data\n        store and/or retrieval engine.\n    encryption_spec: The encryption spec of the RagCorpus. Immutable."
  constructor_signature: 'def __init__(self, *, name: typing.Optional[str] = None, display_name: typing.Optional[str] = None, description: typing.Optional[str] = None, vertex_ai_search_config: typing.Optional[vertexai.rag.utils.resources.VertexAiSearchConfig] = None, backend_config: typing.Optional[typing.Union[vertexai.rag.utils.resources.RagVectorDbConfig, None]] = None, encryption_spec: typing.Optional[google.cloud.aiplatform_v1.types.EncryptionSpec] = None):'
  properties:
  - signature: 'name: typing.Optional[str]'
  - signature: 'display_name: typing.Optional[str]'
  - signature: 'description: typing.Optional[str]'
  - signature: 'vertex_ai_search_config: typing.Optional[vertexai.rag.utils.resources.VertexAiSearchConfig]'
  - signature: 'backend_config: typing.Optional[typing.Union[vertexai.rag.utils.resources.RagVectorDbConfig, None]]'
  - signature: 'encryption_spec: typing.Optional[google.cloud.aiplatform_v1.types.EncryptionSpec]'
- rank: 3083
  id: vertexai.rag.utils.resources.RagEmbeddingModelConfig
  name: RagEmbeddingModelConfig
  file_path: env/lib/python3.13/site-packages/vertexai/rag/utils/resources.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: "RagEmbeddingModelConfig.\n\nAttributes:\n    vertex_prediction_endpoint: The Vertex AI Prediction Endpoint config."
  constructor_signature: 'def __init__(self, *, vertex_prediction_endpoint: typing.Optional[vertexai.rag.utils.resources.VertexPredictionEndpoint] = None):'
  properties:
  - signature: 'vertex_prediction_endpoint: typing.Optional[vertexai.rag.utils.resources.VertexPredictionEndpoint]'
- rank: 3084
  id: vertexai.rag.utils.resources.RagEngineConfig
  name: RagEngineConfig
  file_path: env/lib/python3.13/site-packages/vertexai/rag/utils/resources.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: "RagEngineConfig.\n\nAttributes:\n    name: Generated resource name for singleton resource. Format:\n      ``projects/{project}/locations/{location}/ragEngineConfig``\n    rag_managed_db_config: The config of the RagManagedDb used by RagEngine.\n      The default tier is Basic."
  constructor_signature: 'def __init__(self, *, name: str, rag_managed_db_config: typing.Optional[vertexai.rag.utils.resources.RagManagedDbConfig] = None):'
  properties:
  - signature: 'name: str'
  - signature: 'rag_managed_db_config: typing.Optional[vertexai.rag.utils.resources.RagManagedDbConfig]'
- rank: 3085
  id: vertexai.rag.utils.resources.RagFile
  name: RagFile
  file_path: env/lib/python3.13/site-packages/vertexai/rag/utils/resources.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: "RAG file (output only).\n\nAttributes:\n    name: Generated resource name. Format:\n        ``projects/{project}/locations/{location}/ragCorpora/{rag_corpus_id}/ragFiles/{rag_file}``\n    display_name: Display name that was configured at client side.\n    description: The description of the RagFile."
  constructor_signature: 'def __init__(self, *, name: typing.Optional[str] = None, display_name: typing.Optional[str] = None, description: typing.Optional[str] = None):'
  properties:
  - signature: 'name: typing.Optional[str]'
  - signature: 'display_name: typing.Optional[str]'
  - signature: 'description: typing.Optional[str]'
- rank: 3086
  id: vertexai.rag.utils.resources.RagManagedDb
  name: RagManagedDb
  file_path: env/lib/python3.13/site-packages/vertexai/rag/utils/resources.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: RagManagedDb.
- rank: 3087
  id: vertexai.rag.utils.resources.RagManagedDbConfig
  name: RagManagedDbConfig
  file_path: env/lib/python3.13/site-packages/vertexai/rag/utils/resources.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: "RagManagedDbConfig.\n\nThe config of the RagManagedDb used by RagEngine.\n\nAttributes:\n    tier: The tier of the RagManagedDb. The default tier is Basic."
  constructor_signature: 'def __init__(self, *, tier: typing.Optional[typing.Union[vertexai.rag.utils.resources.Basic, vertexai.rag.utils.resources.Scaled, vertexai.rag.utils.resources.Unprovisioned]] = None):'
  properties:
  - signature: 'tier: typing.Optional[typing.Union[vertexai.rag.utils.resources.Basic, vertexai.rag.utils.resources.Scaled, vertexai.rag.utils.resources.Unprovisioned]]'
- rank: 3088
  id: vertexai.rag.utils.resources.RagResource
  name: RagResource
  file_path: env/lib/python3.13/site-packages/vertexai/rag/utils/resources.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: "RagResource.\n\nThe representation of the rag source. It can be used to specify corpus only\nor ragfiles. Currently only support one corpus or multiple files from one\ncorpus. In the future we may open up multiple corpora support.\n\nAttributes:\n    rag_corpus: A Rag corpus resource name or corpus id. Format:\n        ``projects/{project}/locations/{location}/ragCorpora/{rag_corpus_id}``\n        or ``{rag_corpus_id}``.\n    rag_files_id: List of Rag file resource name or file ids in the same corpus. Format:\n        ``{rag_file}``."
  constructor_signature: 'def __init__(self, *, rag_corpus: typing.Optional[str] = None, rag_file_ids: typing.Optional[typing.List[str]] = None):'
  properties:
  - signature: 'rag_corpus: typing.Optional[str]'
  - signature: 'rag_file_ids: typing.Optional[typing.List[str]]'
- rank: 3089
  id: vertexai.rag.utils.resources.RagRetrievalConfig
  name: RagRetrievalConfig
  file_path: env/lib/python3.13/site-packages/vertexai/rag/utils/resources.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: "RagRetrievalConfig.\n\nAttributes:\n    top_k: The number of contexts to retrieve.\n    filter: Config for filters.\n    ranking: Config for ranking."
  constructor_signature: 'def __init__(self, *, top_k: typing.Optional[int] = None, filter: typing.Optional[vertexai.rag.utils.resources.Filter] = None, ranking: typing.Optional[vertexai.rag.utils.resources.Ranking] = None):'
  properties:
  - signature: 'top_k: typing.Optional[int]'
  - signature: 'filter: typing.Optional[vertexai.rag.utils.resources.Filter]'
  - signature: 'ranking: typing.Optional[vertexai.rag.utils.resources.Ranking]'
- rank: 3090
  id: vertexai.rag.utils.resources.RagVectorDbConfig
  name: RagVectorDbConfig
  file_path: env/lib/python3.13/site-packages/vertexai/rag/utils/resources.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: "RagVectorDbConfig.\n\nAttributes:\n    vector_db: Can be one of the following: RagManagedDb, Pinecone,\n    VertexVectorSearch.\n    rag_embedding_model_config: The embedding model config of the Vector DB."
  constructor_signature: 'def __init__(self, *, vector_db: typing.Optional[typing.Union[vertexai.rag.utils.resources.VertexVectorSearch, vertexai.rag.utils.resources.Pinecone, vertexai.rag.utils.resources.RagManagedDb]] = None, rag_embedding_model_config: typing.Optional[vertexai.rag.utils.resources.RagEmbeddingModelConfig] = None):'
  properties:
  - signature: 'vector_db: typing.Optional[typing.Union[vertexai.rag.utils.resources.VertexVectorSearch, vertexai.rag.utils.resources.Pinecone, vertexai.rag.utils.resources.RagManagedDb]]'
  - signature: 'rag_embedding_model_config: typing.Optional[vertexai.rag.utils.resources.RagEmbeddingModelConfig]'
- rank: 3091
  id: vertexai.rag.utils.resources.RankService
  name: RankService
  file_path: env/lib/python3.13/site-packages/vertexai/rag/utils/resources.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: "RankService.\n\nAttributes:\n    model_name: The model name of the rank service. Format:\n        ``semantic-ranker-512@latest``"
  constructor_signature: 'def __init__(self, *, model_name: typing.Optional[str] = None):'
  properties:
  - signature: 'model_name: typing.Optional[str]'
- rank: 3092
  id: vertexai.rag.utils.resources.Ranking
  name: Ranking
  file_path: env/lib/python3.13/site-packages/vertexai/rag/utils/resources.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: "Ranking.\n\nAttributes:\n    rank_service: Config for Rank Service.\n    llm_ranker: Config for LlmRanker."
  constructor_signature: 'def __init__(self, *, rank_service: typing.Optional[vertexai.rag.utils.resources.RankService] = None, llm_ranker: typing.Optional[vertexai.rag.utils.resources.LlmRanker] = None):'
  properties:
  - signature: 'rank_service: typing.Optional[vertexai.rag.utils.resources.RankService]'
  - signature: 'llm_ranker: typing.Optional[vertexai.rag.utils.resources.LlmRanker]'
- rank: 3093
  id: vertexai.rag.utils.resources.Scaled
  name: Scaled
  file_path: env/lib/python3.13/site-packages/vertexai/rag/utils/resources.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Scaled tier offers production grade performance along with


    autoscaling functionality. It is suitable for customers with large

    amounts of data or performance sensitive workloads.'
- rank: 3094
  id: vertexai.rag.utils.resources.SharePointSource
  name: SharePointSource
  file_path: env/lib/python3.13/site-packages/vertexai/rag/utils/resources.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: "SharePointSource.\n\nAttributes:\n    sharepoint_folder_path: The path of the SharePoint folder to download\n        from.\n    sharepoint_folder_id: The ID of the SharePoint folder to download\n        from.\n    drive_name: The name of the drive to download from.\n    drive_id: The ID of the drive to download from.\n    client_id: The Application ID for the app registered in\n        Microsoft Azure Portal. The application must\n        also be configured with MS Graph permissions\n        \"Files.ReadAll\", \"Sites.ReadAll\" and\n        BrowserSiteLists.Read.All.\n    client_secret: The application secret for the app registered\n        in Azure.\n    tenant_id: Unique identifier of the Azure Active\n        Directory Instance.\n    sharepoint_site_name: The name of the SharePoint site to download\n        from. This can be the site name or the site id."
  constructor_signature: 'def __init__(self, *, sharepoint_folder_path: typing.Optional[str] = None, sharepoint_folder_id: typing.Optional[str] = None, drive_name: typing.Optional[str] = None, drive_id: typing.Optional[str] = None, client_id: str = None, client_secret: str = None, tenant_id: str = None, sharepoint_site_name: str = None):'
  properties:
  - signature: 'sharepoint_folder_path: typing.Optional[str]'
  - signature: 'sharepoint_folder_id: typing.Optional[str]'
  - signature: 'drive_name: typing.Optional[str]'
  - signature: 'drive_id: typing.Optional[str]'
  - signature: 'client_id: str'
  - signature: 'client_secret: str'
  - signature: 'tenant_id: str'
  - signature: 'sharepoint_site_name: str'
- rank: 3095
  id: vertexai.rag.utils.resources.SharePointSources
  name: SharePointSources
  file_path: env/lib/python3.13/site-packages/vertexai/rag/utils/resources.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: "SharePointSources.\n\nAttributes:\n    share_point_sources: The SharePoint sources."
  constructor_signature: 'def __init__(self, *, share_point_sources: typing.Sequence[vertexai.rag.utils.resources.SharePointSource]):'
  properties:
  - signature: 'share_point_sources: typing.Sequence[vertexai.rag.utils.resources.SharePointSource]'
- rank: 3096
  id: vertexai.rag.utils.resources.SlackChannel
  name: SlackChannel
  file_path: env/lib/python3.13/site-packages/vertexai/rag/utils/resources.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: "SlackChannel.\n\nAttributes:\n    channel_id: The Slack channel ID.\n    api_key: The SecretManager resource name for the Slack API token. Format:\n        ``projects/{project}/secrets/{secret}/versions/{version}``\n        See: https://api.slack.com/tutorials/tracks/getting-a-token.\n    start_time: The starting timestamp for messages to import.\n    end_time: The ending timestamp for messages to import."
  constructor_signature: 'def __init__(self, *, channel_id: str, api_key: str, start_time: typing.Optional[google.protobuf.timestamp_pb2.Timestamp] = None, end_time: typing.Optional[google.protobuf.timestamp_pb2.Timestamp] = None):'
  properties:
  - signature: 'channel_id: str'
  - signature: 'api_key: str'
  - signature: 'start_time: typing.Optional[google.protobuf.timestamp_pb2.Timestamp]'
  - signature: 'end_time: typing.Optional[google.protobuf.timestamp_pb2.Timestamp]'
- rank: 3097
  id: vertexai.rag.utils.resources.SlackChannelsSource
  name: SlackChannelsSource
  file_path: env/lib/python3.13/site-packages/vertexai/rag/utils/resources.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: "SlackChannelsSource.\n\nAttributes:\n    channels: The Slack channels."
  constructor_signature: 'def __init__(self, *, channels: typing.Sequence[vertexai.rag.utils.resources.SlackChannel]):'
  properties:
  - signature: 'channels: typing.Sequence[vertexai.rag.utils.resources.SlackChannel]'
- rank: 3098
  id: vertexai.rag.utils.resources.TransformationConfig
  name: TransformationConfig
  file_path: env/lib/python3.13/site-packages/vertexai/rag/utils/resources.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: "TransformationConfig.\n\nAttributes:\n    chunking_config: The chunking config."
  constructor_signature: 'def __init__(self, *, chunking_config: typing.Optional[vertexai.rag.utils.resources.ChunkingConfig] = None):'
  properties:
  - signature: 'chunking_config: typing.Optional[vertexai.rag.utils.resources.ChunkingConfig]'
- rank: 3099
  id: vertexai.rag.utils.resources.Unprovisioned
  name: Unprovisioned
  file_path: env/lib/python3.13/site-packages/vertexai/rag/utils/resources.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Disables the RAG Engine service and deletes all your data held within

    this service. This will halt the billing of the service.


    NOTE: Once deleted the data cannot be recovered. To start using

    RAG Engine again, you will need to update the tier by calling the

    UpdateRagEngineConfig API.'
- rank: 3100
  id: vertexai.rag.utils.resources.VertexAiSearchConfig
  name: VertexAiSearchConfig
  file_path: env/lib/python3.13/site-packages/vertexai/rag/utils/resources.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: "VertexAiSearchConfig.\n\nAttributes:\n    serving_config: The resource name of the Vertex AI Search serving config.\n        Format:\n            ``projects/{project}/locations/{location}/collections/{collection}/engines/{engine}/servingConfigs/{serving_config}``\n        or\n            ``projects/{project}/locations/{location}/collections/{collection}/dataStores/{data_store}/servingConfigs/{serving_config}``"
  constructor_signature: 'def __init__(self, *, serving_config: typing.Optional[str] = None):'
  properties:
  - signature: 'serving_config: typing.Optional[str]'
- rank: 3101
  id: vertexai.rag.utils.resources.VertexFeatureStore
  name: VertexFeatureStore
  file_path: env/lib/python3.13/site-packages/vertexai/rag/utils/resources.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: "VertexFeatureStore.\n\nAttributes:\n    resource_name: The resource name of the FeatureView. Format:\n        ``projects/{project}/locations/{location}/featureOnlineStores/\n          {feature_online_store}/featureViews/{feature_view}``"
  constructor_signature: 'def __init__(self, *, resource_name: typing.Optional[str] = None):'
  properties:
  - signature: 'resource_name: typing.Optional[str]'
- rank: 3102
  id: vertexai.rag.utils.resources.VertexPredictionEndpoint
  name: VertexPredictionEndpoint
  file_path: env/lib/python3.13/site-packages/vertexai/rag/utils/resources.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: "VertexPredictionEndpoint.\n\nAttributes:\n    publisher_model: 1P publisher model resource name. Format:\n        ``publishers/google/models/{model}`` or\n        ``projects/{project}/locations/{location}/publishers/google/models/{model}``\n    endpoint: 1P fine tuned embedding model resource name. Format:\n        ``endpoints/{endpoint}`` or\n        ``projects/{project}/locations/{location}/endpoints/{endpoint}``.\n    model:\n        Output only. The resource name of the model that is deployed\n        on the endpoint. Present only when the endpoint is not a\n        publisher model. Pattern:\n        ``projects/{project}/locations/{location}/models/{model}``\n    model_version_id:\n        Output only. Version ID of the model that is\n        deployed on the endpoint. Present only when the\n        endpoint is not a publisher model."
  constructor_signature: 'def __init__(self, *, endpoint: typing.Optional[str] = None, publisher_model: typing.Optional[str] = None, model: typing.Optional[str] = None, model_version_id: typing.Optional[str] = None):'
  properties:
  - signature: 'endpoint: typing.Optional[str]'
  - signature: 'publisher_model: typing.Optional[str]'
  - signature: 'model: typing.Optional[str]'
  - signature: 'model_version_id: typing.Optional[str]'
- rank: 3103
  id: vertexai.rag.utils.resources.VertexVectorSearch
  name: VertexVectorSearch
  file_path: env/lib/python3.13/site-packages/vertexai/rag/utils/resources.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: "VertexVectorSearch.\n\nAttributes:\n    index_endpoint (str):\n        The resource name of the Index Endpoint. Format:\n        ``projects/{project}/locations/{location}/indexEndpoints/{index_endpoint}``\n    index (str):\n        The resource name of the Index. Format:\n        ``projects/{project}/locations/{location}/indexes/{index}``"
  constructor_signature: 'def __init__(self, *, index_endpoint: typing.Optional[str] = None, index: typing.Optional[str] = None):'
  properties:
  - signature: 'index_endpoint: typing.Optional[str]'
  - signature: 'index: typing.Optional[str]'
- rank: 3104
  id: vertexai.rag.utils.resources.Weaviate
  name: Weaviate
  file_path: env/lib/python3.13/site-packages/vertexai/rag/utils/resources.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: "Weaviate.\n\nAttributes:\n    weaviate_http_endpoint: The Weaviate DB instance HTTP endpoint\n    collection_name: The corresponding Weaviate collection this corpus maps to\n    api_key: The SecretManager resource name for the Weaviate DB API token. Format:\n        ``projects/{project}/secrets/{secret}/versions/{version}``"
  constructor_signature: 'def __init__(self, *, weaviate_http_endpoint: typing.Optional[str] = None, collection_name: typing.Optional[str] = None, api_key: typing.Optional[str] = None):'
  properties:
  - signature: 'weaviate_http_endpoint: typing.Optional[str]'
  - signature: 'collection_name: typing.Optional[str]'
  - signature: 'api_key: typing.Optional[str]'
- rank: 3105
  id: vertexai.resources
  name: resources
  file_path: env/lib/python3.13/site-packages/vertexai/resources/__init__.py
  type: MODULE
  group: Orphan
  usage_score: 0
  docstring: The vertexai resources module.
- rank: 3106
  id: vertexai.resources.preview
  name: preview
  file_path: env/lib/python3.13/site-packages/vertexai/resources/preview/__init__.py
  type: MODULE
  group: Orphan
  usage_score: 0
  docstring: The vertexai resources preview module.
- rank: 3107
  id: vertexai.resources.preview.feature_store
  name: feature_store
  file_path: env/lib/python3.13/site-packages/vertexai/resources/preview/feature_store/__init__.py
  type: MODULE
  group: Orphan
  usage_score: 0
  docstring: The vertexai resources preview module.
- rank: 3108
  id: vertexai.resources.preview.feature_store.feature
  name: feature
  file_path: env/lib/python3.13/site-packages/vertexai/resources/preview/feature_store/feature.py
  type: MODULE
  group: Orphan
  usage_score: 0
- rank: 3109
  id: vertexai.resources.preview.feature_store.feature.Feature
  name: Feature
  file_path: env/lib/python3.13/site-packages/vertexai/resources/preview/feature_store/feature.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Class for managing Feature resources.


    [Note: Inherited members from base.VertexAiResourceNounWithFutureManager are omitted.]'
  constructor_signature: 'def __init__(self, name: str, feature_group_id: typing.Optional[str], project: typing.Optional[str], location: typing.Optional[str], latest_stats_count: typing.Optional[int], credentials: typing.Optional[google.auth.credentials.Credentials]):'
  methods:
  - signature: 'def version_column_name(self) -> str:'
    docstring: The name of the BigQuery Table/View column hosting data for this version.
  - signature: 'def description(self) -> str:'
    docstring: The description of the feature.
  - signature: 'def point_of_contact(self) -> str:'
    docstring: The point of contact for the feature.
  - signature: 'def feature_stats_and_anomalies(self) -> typing.List[google.cloud.aiplatform.compat.types.feature_monitor_v1beta1.FeatureStatsAndAnomaly]:'
    docstring: The number of latest stats to return. Only present when gca_feature is set.
  properties:
  - signature: 'client_class: Any'
  omitted_inherited_members_from:
  - base.VertexAiResourceNounWithFutureManager
- rank: 3110
  id: vertexai.resources.preview.feature_store.feature.Feature.__init__
  name: __init__
  file_path: env/lib/python3.13/site-packages/vertexai/resources/preview/feature_store/feature.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Retrieves an existing managed feature.\n\nArgs:\n    name:\n        The resource name\n        (`projects/.../locations/.../featureGroups/.../features/...`) or\n        ID.\n    feature_group_id:\n        The feature group ID. Must be passed in if name is an ID and not\n        a resource path.\n    project:\n        Project to retrieve feature from. If not set, the project set in\n        aiplatform.init will be used.\n    location:\n        Location to retrieve feature from. If not set, the location set\n        in aiplatform.init will be used.\n    gca_feature_arg:\n        The GCA feature object.\n        Only set when calling from get_feature with latest_stats_count set.\n    credentials:\n        Custom credentials to use to retrieve this feature. Overrides\n        credentials set in aiplatform.init."
  signature: 'def __init__(self, name: str, feature_group_id: typing.Optional[str], project: typing.Optional[str], location: typing.Optional[str], latest_stats_count: typing.Optional[int], credentials: typing.Optional[google.auth.credentials.Credentials]):'
- rank: 3111
  id: vertexai.resources.preview.feature_store.feature.Feature.feature_stats_and_anomalies
  name: feature_stats_and_anomalies
  file_path: env/lib/python3.13/site-packages/vertexai/resources/preview/feature_store/feature.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: The number of latest stats to return. Only present when gca_feature is set.
  signature: 'def feature_stats_and_anomalies(self) -> typing.List[google.cloud.aiplatform.compat.types.feature_monitor_v1beta1.FeatureStatsAndAnomaly]:'
- rank: 3112
  id: vertexai.resources.preview.feature_store.feature_group
  name: feature_group
  file_path: env/lib/python3.13/site-packages/vertexai/resources/preview/feature_store/feature_group.py
  type: MODULE
  group: Orphan
  usage_score: 0
- rank: 3113
  id: vertexai.resources.preview.feature_store.feature_group.FeatureGroup
  name: FeatureGroup
  file_path: env/lib/python3.13/site-packages/vertexai/resources/preview/feature_store/feature_group.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Class for managing Feature Group resources.


    [Note: Inherited members from base.VertexAiResourceNounWithFutureManager are omitted.]'
  constructor_signature: 'def __init__(self, name: str, project: typing.Optional[str], location: typing.Optional[str], credentials: typing.Optional[google.auth.credentials.Credentials]):'
  methods:
  - signature: 'def create(cls, name: str, source: vertexai.resources.preview.feature_store.utils.FeatureGroupBigQuerySource, labels: typing.Optional[typing.Dict[str, str]], description: typing.Optional[str], project: typing.Optional[str], location: typing.Optional[str], credentials: typing.Optional[google.auth.credentials.Credentials], request_metadata: typing.Optional[typing.Sequence[typing.Tuple[str, str]]], create_request_timeout: typing.Optional[float], sync: bool) -> vertexai.resources.preview.feature_store.feature_group.FeatureGroup:'
    docstring: "Creates a new feature group.\n\nArgs:\n    name: The name of the feature group.\n    source: The BigQuery source of the feature group.\n    labels:\n        The labels with user-defined metadata to organize your\n        FeatureGroup.\n\n        Label keys and values can be no longer than 64\n        characters (Unicode codepoints), can only\n        contain lowercase letters, numeric characters,\n        underscores and dashes. International characters\n        are allowed.\n\n        See https://goo.gl/xmQnxf for more information\n        on and examples of labels. No more than 64 user\n        labels can be associated with one\n        FeatureGroup(System labels are excluded).\"\n        System reserved label keys are prefixed with\n        \"aiplatform.googleapis.com/\" and are immutable.\n    description: Description of the FeatureGroup.\n    project:\n        Project to create feature group in. If unset, the project set in\n        aiplatform.init will be used.\n  \
      \  location:\n        Location to create feature group in. If not set, location set in\n        aiplatform.init will be used.\n    credentials:\n        Custom credentials to use to create this feature group.\n        Overrides credentials set in aiplatform.init.\n    request_metadata:\n        Strings which should be sent along with the request as metadata.\n    create_request_timeout:\n        The timeout for the create request in seconds.\n    sync:\n        Whether to execute this creation synchronously. If False, this\n        method will be executed in concurrent Future and any downstream\n        object will be immediately returned and synced when the Future\n        has completed.\n\nReturns:\n    FeatureGroup - the FeatureGroup resource object."
  - signature: 'def delete(self, force: bool, sync: bool) -> None:'
    docstring: "Deletes this feature group.\n\nWARNING: This deletion is permanent.\n\nArgs:\n    force:\n        If set to True, all features under this online store will be\n        deleted prior to online store deletion. Otherwise, deletion\n        will only succeed if the online store has no FeatureViews.\n\n        If set to true, any Features under this FeatureGroup will also\n        be deleted. (Otherwise, the request will only work if the\n        FeatureGroup has no Features.)\n    sync:\n        Whether to execute this deletion synchronously. If False, this\n        method will be executed in concurrent Future and any downstream\n        object will be immediately returned and synced when the Future\n        has completed."
  - signature: 'def get_feature(self, feature_id: str, latest_stats_count: typing.Optional[int], credentials: typing.Optional[google.auth.credentials.Credentials]) -> vertexai.resources.preview.feature_store.Feature:'
    docstring: "Retrieves an existing managed feature.\n\nArgs:\n    feature_id: The ID of the feature.\n    latest_stats_count:\n        The number of latest stats to retrieve. Only returns stats if\n        Feature Monitor is created, and historical stats were generated.\n    credentials:\n        Custom credentials to use to retrieve the feature under this\n        feature group. The order of which credentials are used is as\n        follows: (1) this parameter (2) credentials passed to FeatureGroup\n        constructor (3) credentials set in aiplatform.init.\n\nReturns:\n    Feature - the Feature resource object under this feature group."
  - signature: 'def create_feature(self, name: str, version_column_name: typing.Optional[str], description: typing.Optional[str], labels: typing.Optional[typing.Dict[str, str]], point_of_contact: typing.Optional[str], project: typing.Optional[str], location: typing.Optional[str], credentials: typing.Optional[google.auth.credentials.Credentials], request_metadata: typing.Optional[typing.Sequence[typing.Tuple[str, str]]], create_request_timeout: typing.Optional[float], sync: bool) -> vertexai.resources.preview.feature_store.Feature:'
    docstring: "Creates a new feature.\n\nArgs:\n    name: The name of the feature.\n    version_column_name:\n        The name of the BigQuery Table/View column hosting data for this\n        version. If no value is provided, will use feature_id.\n    description: Description of the feature.\n    labels:\n        The labels with user-defined metadata to organize your Features.\n        Label keys and values can be no longer than 64 characters\n        (Unicode codepoints), can only contain lowercase letters,\n        numeric characters, underscores and dashes. International\n        characters are allowed.\n\n        See https://goo.gl/xmQnxf for more information on and examples\n        of labels. No more than 64 user labels can be associated with\n        one Feature (System labels are excluded).\" System reserved label\n        keys are prefixed with \"aiplatform.googleapis.com/\" and are\n        immutable.\n    point_of_contact:\n        Entity responsible for maintaining this feature.\
      \ Can be comma\n        separated list of email addresses or URIs.\n    project:\n        Project to create feature in. If unset, the project set in\n        aiplatform.init will be used.\n    location:\n        Location to create feature in. If not set, location set in\n        aiplatform.init will be used.\n    credentials:\n        Custom credentials to use to create this feature. Overrides\n        credentials set in aiplatform.init.\n    request_metadata:\n        Strings which should be sent along with the request as metadata.\n    create_request_timeout:\n        The timeout for the create request in seconds.\n    sync:\n        Whether to execute this creation synchronously. If False, this\n        method will be executed in concurrent Future and any downstream\n        object will be immediately returned and synced when the Future\n        has completed.\n\nReturns:\n    Feature - the Feature resource object."
  - signature: 'def list_features(self, project: typing.Optional[str], location: typing.Optional[str], credentials: typing.Optional[google.auth.credentials.Credentials]) -> typing.List[vertexai.resources.preview.feature_store.Feature]:'
    docstring: "Lists features under this feature group.\n\nArgs:\n    project:\n        Project to list features in. If unset, the project set in\n        aiplatform.init will be used.\n    location:\n        Location to list features in. If not set, location set in\n        aiplatform.init will be used.\n    credentials:\n        Custom credentials to use to list features. Overrides\n        credentials set in aiplatform.init.\n\nReturns:\n    List of features under this feature group."
  - signature: 'def get_feature_monitor(self, feature_monitor_id: str, credentials: typing.Optional[google.auth.credentials.Credentials]) -> vertexai.resources.preview.feature_store.feature_monitor.FeatureMonitor:'
    docstring: "Retrieves an existing feature monitor.\n\nArgs:\n    feature_monitor_id: The ID of the feature monitor.\n    credentials:\n        Custom credentials to use to retrieve the feature monitor under this\n        feature group. The order of which credentials are used is as\n        follows: (1) this parameter (2) credentials passed to FeatureGroup\n        constructor (3) credentials set in aiplatform.init.\n\nReturns:\n    FeatureMonitor - the Feature Monitor resource object under this\n    feature group."
  - signature: 'def create_feature_monitor(self, name: str, description: typing.Optional[str], labels: typing.Optional[typing.Dict[str, str]], schedule_config: typing.Optional[str], feature_selection_configs: typing.Optional[typing.List[typing.Tuple[str, float]]], project: typing.Optional[str], location: typing.Optional[str], credentials: typing.Optional[google.auth.credentials.Credentials], request_metadata: typing.Optional[typing.Sequence[typing.Tuple[str, str]]], create_request_timeout: typing.Optional[float]) -> vertexai.resources.preview.feature_store.feature_monitor.FeatureMonitor:'
    docstring: "Creates a new feature monitor.\n\nArgs:\n    name: The name of the feature monitor.\n    description: Description of the feature monitor.\n    labels:\n        The labels with user-defined metadata to organize your FeatureMonitors.\n        Label keys and values can be no longer than 64 characters\n        (Unicode codepoints), can only contain lowercase letters,\n        numeric characters, underscores and dashes. International\n        characters are allowed.\n\n        See https://goo.gl/xmQnxf for more information on and examples\n        of labels. No more than 64 user labels can be associated with\n        one FeatureMonitor (System labels are excluded).\" System reserved label\n        keys are prefixed with \"aiplatform.googleapis.com/\" and are\n        immutable.\n    schedule_config:\n        Configures when data is to be monitored for this\n        FeatureMonitor. At the end of the scheduled time,\n        the stats and drift are generated for the selected features.\n\
      \        Example format: \"TZ=America/New_York 0 9 * * *\" (monitors\n        daily at 9 AM EST).\n    feature_selection_configs:\n        List of tuples of feature id and monitoring threshold. If unset,\n        all features in the feature group will be monitored, and the\n        default thresholds 0.3 will be used.\n    project:\n        Project to create feature in. If unset, the project set in\n        aiplatform.init will be used.\n    location:\n        Location to create feature in. If not set, location set in\n        aiplatform.init will be used.\n    credentials:\n        Custom credentials to use to create this feature. Overrides\n        credentials set in aiplatform.init.\n    request_metadata:\n        Strings which should be sent along with the request as metadata.\n    create_request_timeout:\n        The timeout for the create request in seconds.\n\nReturns:\n    FeatureMonitor - the FeatureMonitor resource object."
  - signature: 'def list_feature_monitors(self, project: typing.Optional[str], location: typing.Optional[str], credentials: typing.Optional[google.auth.credentials.Credentials]) -> typing.List[vertexai.resources.preview.feature_store.feature_monitor.FeatureMonitor]:'
    docstring: "Lists features monitors under this feature group.\n\nArgs:\n    project:\n        Project to list feature monitors in. If unset, the project set in\n        aiplatform.init will be used.\n    location:\n        Location to list feature monitors in. If not set, location set in\n        aiplatform.init will be used.\n    credentials:\n        Custom credentials to use to list feature monitors. Overrides\n        credentials set in aiplatform.init.\n\nReturns:\n    List of feature monitors under this feature group."
  - signature: 'def source(self) -> vertexai.resources.preview.feature_store.utils.FeatureGroupBigQuerySource:'
  properties:
  - signature: 'client_class: Any'
  omitted_inherited_members_from:
  - base.VertexAiResourceNounWithFutureManager
- rank: 3114
  id: vertexai.resources.preview.feature_store.feature_group.FeatureGroup.__init__
  name: __init__
  file_path: env/lib/python3.13/site-packages/vertexai/resources/preview/feature_store/feature_group.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Retrieves an existing managed feature group.\n\nArgs:\n    name:\n        The resource name\n        (`projects/.../locations/.../featureGroups/...`) or ID.\n    project:\n        Project to retrieve feature group from. If unset, the\n        project set in aiplatform.init will be used.\n    location:\n        Location to retrieve feature group from. If not set,\n        location set in aiplatform.init will be used.\n    credentials:\n        Custom credentials to use to retrieve this feature group.\n        Overrides credentials set in aiplatform.init."
  signature: 'def __init__(self, name: str, project: typing.Optional[str], location: typing.Optional[str], credentials: typing.Optional[google.auth.credentials.Credentials]):'
- rank: 3115
  id: vertexai.resources.preview.feature_store.feature_group.FeatureGroup.create
  name: create
  file_path: env/lib/python3.13/site-packages/vertexai/resources/preview/feature_store/feature_group.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Creates a new feature group.\n\nArgs:\n    name: The name of the feature group.\n    source: The BigQuery source of the feature group.\n    labels:\n        The labels with user-defined metadata to organize your\n        FeatureGroup.\n\n        Label keys and values can be no longer than 64\n        characters (Unicode codepoints), can only\n        contain lowercase letters, numeric characters,\n        underscores and dashes. International characters\n        are allowed.\n\n        See https://goo.gl/xmQnxf for more information\n        on and examples of labels. No more than 64 user\n        labels can be associated with one\n        FeatureGroup(System labels are excluded).\"\n        System reserved label keys are prefixed with\n        \"aiplatform.googleapis.com/\" and are immutable.\n    description: Description of the FeatureGroup.\n    project:\n        Project to create feature group in. If unset, the project set in\n        aiplatform.init will be used.\n    location:\n\
    \        Location to create feature group in. If not set, location set in\n        aiplatform.init will be used.\n    credentials:\n        Custom credentials to use to create this feature group.\n        Overrides credentials set in aiplatform.init.\n    request_metadata:\n        Strings which should be sent along with the request as metadata.\n    create_request_timeout:\n        The timeout for the create request in seconds.\n    sync:\n        Whether to execute this creation synchronously. If False, this\n        method will be executed in concurrent Future and any downstream\n        object will be immediately returned and synced when the Future\n        has completed.\n\nReturns:\n    FeatureGroup - the FeatureGroup resource object."
  signature: 'def create(cls, name: str, source: vertexai.resources.preview.feature_store.utils.FeatureGroupBigQuerySource, labels: typing.Optional[typing.Dict[str, str]], description: typing.Optional[str], project: typing.Optional[str], location: typing.Optional[str], credentials: typing.Optional[google.auth.credentials.Credentials], request_metadata: typing.Optional[typing.Sequence[typing.Tuple[str, str]]], create_request_timeout: typing.Optional[float], sync: bool) -> vertexai.resources.preview.feature_store.feature_group.FeatureGroup:'
- rank: 3116
  id: vertexai.resources.preview.feature_store.feature_group.FeatureGroup.create_feature
  name: create_feature
  file_path: env/lib/python3.13/site-packages/vertexai/resources/preview/feature_store/feature_group.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Creates a new feature.\n\nArgs:\n    name: The name of the feature.\n    version_column_name:\n        The name of the BigQuery Table/View column hosting data for this\n        version. If no value is provided, will use feature_id.\n    description: Description of the feature.\n    labels:\n        The labels with user-defined metadata to organize your Features.\n        Label keys and values can be no longer than 64 characters\n        (Unicode codepoints), can only contain lowercase letters,\n        numeric characters, underscores and dashes. International\n        characters are allowed.\n\n        See https://goo.gl/xmQnxf for more information on and examples\n        of labels. No more than 64 user labels can be associated with\n        one Feature (System labels are excluded).\" System reserved label\n        keys are prefixed with \"aiplatform.googleapis.com/\" and are\n        immutable.\n    point_of_contact:\n        Entity responsible for maintaining this feature.\
    \ Can be comma\n        separated list of email addresses or URIs.\n    project:\n        Project to create feature in. If unset, the project set in\n        aiplatform.init will be used.\n    location:\n        Location to create feature in. If not set, location set in\n        aiplatform.init will be used.\n    credentials:\n        Custom credentials to use to create this feature. Overrides\n        credentials set in aiplatform.init.\n    request_metadata:\n        Strings which should be sent along with the request as metadata.\n    create_request_timeout:\n        The timeout for the create request in seconds.\n    sync:\n        Whether to execute this creation synchronously. If False, this\n        method will be executed in concurrent Future and any downstream\n        object will be immediately returned and synced when the Future\n        has completed.\n\nReturns:\n    Feature - the Feature resource object."
  signature: 'def create_feature(self, name: str, version_column_name: typing.Optional[str], description: typing.Optional[str], labels: typing.Optional[typing.Dict[str, str]], point_of_contact: typing.Optional[str], project: typing.Optional[str], location: typing.Optional[str], credentials: typing.Optional[google.auth.credentials.Credentials], request_metadata: typing.Optional[typing.Sequence[typing.Tuple[str, str]]], create_request_timeout: typing.Optional[float], sync: bool) -> vertexai.resources.preview.feature_store.Feature:'
- rank: 3117
  id: vertexai.resources.preview.feature_store.feature_group.FeatureGroup.create_feature_monitor
  name: create_feature_monitor
  file_path: env/lib/python3.13/site-packages/vertexai/resources/preview/feature_store/feature_group.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Creates a new feature monitor.\n\nArgs:\n    name: The name of the feature monitor.\n    description: Description of the feature monitor.\n    labels:\n        The labels with user-defined metadata to organize your FeatureMonitors.\n        Label keys and values can be no longer than 64 characters\n        (Unicode codepoints), can only contain lowercase letters,\n        numeric characters, underscores and dashes. International\n        characters are allowed.\n\n        See https://goo.gl/xmQnxf for more information on and examples\n        of labels. No more than 64 user labels can be associated with\n        one FeatureMonitor (System labels are excluded).\" System reserved label\n        keys are prefixed with \"aiplatform.googleapis.com/\" and are\n        immutable.\n    schedule_config:\n        Configures when data is to be monitored for this\n        FeatureMonitor. At the end of the scheduled time,\n        the stats and drift are generated for the selected features.\n\
    \        Example format: \"TZ=America/New_York 0 9 * * *\" (monitors\n        daily at 9 AM EST).\n    feature_selection_configs:\n        List of tuples of feature id and monitoring threshold. If unset,\n        all features in the feature group will be monitored, and the\n        default thresholds 0.3 will be used.\n    project:\n        Project to create feature in. If unset, the project set in\n        aiplatform.init will be used.\n    location:\n        Location to create feature in. If not set, location set in\n        aiplatform.init will be used.\n    credentials:\n        Custom credentials to use to create this feature. Overrides\n        credentials set in aiplatform.init.\n    request_metadata:\n        Strings which should be sent along with the request as metadata.\n    create_request_timeout:\n        The timeout for the create request in seconds.\n\nReturns:\n    FeatureMonitor - the FeatureMonitor resource object."
  signature: 'def create_feature_monitor(self, name: str, description: typing.Optional[str], labels: typing.Optional[typing.Dict[str, str]], schedule_config: typing.Optional[str], feature_selection_configs: typing.Optional[typing.List[typing.Tuple[str, float]]], project: typing.Optional[str], location: typing.Optional[str], credentials: typing.Optional[google.auth.credentials.Credentials], request_metadata: typing.Optional[typing.Sequence[typing.Tuple[str, str]]], create_request_timeout: typing.Optional[float]) -> vertexai.resources.preview.feature_store.feature_monitor.FeatureMonitor:'
- rank: 3118
  id: vertexai.resources.preview.feature_store.feature_group.FeatureGroup.delete
  name: delete
  file_path: env/lib/python3.13/site-packages/vertexai/resources/preview/feature_store/feature_group.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Deletes this feature group.\n\nWARNING: This deletion is permanent.\n\nArgs:\n    force:\n        If set to True, all features under this online store will be\n        deleted prior to online store deletion. Otherwise, deletion\n        will only succeed if the online store has no FeatureViews.\n\n        If set to true, any Features under this FeatureGroup will also\n        be deleted. (Otherwise, the request will only work if the\n        FeatureGroup has no Features.)\n    sync:\n        Whether to execute this deletion synchronously. If False, this\n        method will be executed in concurrent Future and any downstream\n        object will be immediately returned and synced when the Future\n        has completed."
  signature: 'def delete(self, force: bool, sync: bool) -> None:'
- rank: 3119
  id: vertexai.resources.preview.feature_store.feature_group.FeatureGroup.get_feature
  name: get_feature
  file_path: env/lib/python3.13/site-packages/vertexai/resources/preview/feature_store/feature_group.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Retrieves an existing managed feature.\n\nArgs:\n    feature_id: The ID of the feature.\n    latest_stats_count:\n        The number of latest stats to retrieve. Only returns stats if\n        Feature Monitor is created, and historical stats were generated.\n    credentials:\n        Custom credentials to use to retrieve the feature under this\n        feature group. The order of which credentials are used is as\n        follows: (1) this parameter (2) credentials passed to FeatureGroup\n        constructor (3) credentials set in aiplatform.init.\n\nReturns:\n    Feature - the Feature resource object under this feature group."
  signature: 'def get_feature(self, feature_id: str, latest_stats_count: typing.Optional[int], credentials: typing.Optional[google.auth.credentials.Credentials]) -> vertexai.resources.preview.feature_store.Feature:'
- rank: 3120
  id: vertexai.resources.preview.feature_store.feature_group.FeatureGroup.get_feature_monitor
  name: get_feature_monitor
  file_path: env/lib/python3.13/site-packages/vertexai/resources/preview/feature_store/feature_group.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Retrieves an existing feature monitor.\n\nArgs:\n    feature_monitor_id: The ID of the feature monitor.\n    credentials:\n        Custom credentials to use to retrieve the feature monitor under this\n        feature group. The order of which credentials are used is as\n        follows: (1) this parameter (2) credentials passed to FeatureGroup\n        constructor (3) credentials set in aiplatform.init.\n\nReturns:\n    FeatureMonitor - the Feature Monitor resource object under this\n    feature group."
  signature: 'def get_feature_monitor(self, feature_monitor_id: str, credentials: typing.Optional[google.auth.credentials.Credentials]) -> vertexai.resources.preview.feature_store.feature_monitor.FeatureMonitor:'
- rank: 3121
  id: vertexai.resources.preview.feature_store.feature_group.FeatureGroup.list_feature_monitors
  name: list_feature_monitors
  file_path: env/lib/python3.13/site-packages/vertexai/resources/preview/feature_store/feature_group.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Lists features monitors under this feature group.\n\nArgs:\n    project:\n        Project to list feature monitors in. If unset, the project set in\n        aiplatform.init will be used.\n    location:\n        Location to list feature monitors in. If not set, location set in\n        aiplatform.init will be used.\n    credentials:\n        Custom credentials to use to list feature monitors. Overrides\n        credentials set in aiplatform.init.\n\nReturns:\n    List of feature monitors under this feature group."
  signature: 'def list_feature_monitors(self, project: typing.Optional[str], location: typing.Optional[str], credentials: typing.Optional[google.auth.credentials.Credentials]) -> typing.List[vertexai.resources.preview.feature_store.feature_monitor.FeatureMonitor]:'
- rank: 3122
  id: vertexai.resources.preview.feature_store.feature_group.FeatureGroup.list_features
  name: list_features
  file_path: env/lib/python3.13/site-packages/vertexai/resources/preview/feature_store/feature_group.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Lists features under this feature group.\n\nArgs:\n    project:\n        Project to list features in. If unset, the project set in\n        aiplatform.init will be used.\n    location:\n        Location to list features in. If not set, location set in\n        aiplatform.init will be used.\n    credentials:\n        Custom credentials to use to list features. Overrides\n        credentials set in aiplatform.init.\n\nReturns:\n    List of features under this feature group."
  signature: 'def list_features(self, project: typing.Optional[str], location: typing.Optional[str], credentials: typing.Optional[google.auth.credentials.Credentials]) -> typing.List[vertexai.resources.preview.feature_store.Feature]:'
- rank: 3123
  id: vertexai.resources.preview.feature_store.feature_group.FeatureGroup.source
  name: source
  file_path: env/lib/python3.13/site-packages/vertexai/resources/preview/feature_store/feature_group.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def source(self) -> vertexai.resources.preview.feature_store.utils.FeatureGroupBigQuerySource:'
- rank: 3124
  id: vertexai.resources.preview.feature_store.feature_monitor
  name: feature_monitor
  file_path: env/lib/python3.13/site-packages/vertexai/resources/preview/feature_store/feature_monitor.py
  type: MODULE
  group: Orphan
  usage_score: 0
- rank: 3125
  id: vertexai.resources.preview.feature_store.feature_monitor.FeatureMonitor
  name: FeatureMonitor
  file_path: env/lib/python3.13/site-packages/vertexai/resources/preview/feature_store/feature_monitor.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Class for managing Feature Monitor resources.


    [Note: Inherited members from base.VertexAiResourceNounWithFutureManager are omitted.]'
  constructor_signature: 'def __init__(self, name: str, feature_group_id: typing.Optional[str], project: typing.Optional[str], location: typing.Optional[str], credentials: typing.Optional[google.auth.credentials.Credentials]):'
  methods:
  - signature: 'def description(self) -> str:'
    docstring: The description of the feature monitor.
  - signature: 'def schedule_config(self) -> str:'
    docstring: The schedule config of the feature monitor.
  - signature: 'def feature_selection_configs(self) -> typing.List[typing.Tuple[str, float]]:'
    docstring: The feature and it's drift threshold configs of the feature monitor.
  - signature: 'def create_feature_monitor_job(self, description: typing.Optional[str], labels: typing.Optional[typing.Dict[str, str]], project: typing.Optional[str], location: typing.Optional[str], credentials: typing.Optional[google.auth.credentials.Credentials], request_metadata: typing.Optional[typing.Sequence[typing.Tuple[str, str]]], create_request_timeout: typing.Optional[float]) -> FeatureMonitorJob:'
    docstring: "Creates a new feature monitor job.\n\nArgs:\n    description: Description of the feature monitor job.\n    labels:\n        The labels with user-defined metadata to organize your\n        FeatureMonitorJobs.\n        Label keys and values can be no longer than 64 characters\n        (Unicode codepoints), can only contain lowercase letters,\n        numeric characters, underscores and dashes. International\n        characters are allowed.\n\n        See https://goo.gl/xmQnxf for more information on and examples\n        of labels. No more than 64 user labels can be associated with\n        one FeatureMonitor (System labels are excluded).\" System reserved label\n        keys are prefixed with \"aiplatform.googleapis.com/\" and are\n        immutable.\n    project:\n        Project to create feature in. If unset, the project set in\n        aiplatform.init will be used.\n    location:\n        Location to create feature in. If not set, location set in\n        aiplatform.init\
      \ will be used.\n    credentials:\n        Custom credentials to use to create this feature. Overrides\n        credentials set in aiplatform.init.\n    request_metadata:\n        Strings which should be sent along with the request as metadata.\n    create_request_timeout:\n        The timeout for the create request in seconds.\n\nReturns:\n    FeatureMonitorJob - the FeatureMonitorJob resource object."
  - signature: 'def get_feature_monitor_job(self, feature_monitor_job_id: str, credentials: typing.Optional[google.auth.credentials.Credentials]) -> FeatureMonitorJob:'
    docstring: "Retrieves an existing feature monitor.\n\nArgs:\n    feature_monitor_job_id: The ID of the feature monitor job.\n    credentials:\n        Custom credentials to use to retrieve the feature monitor job under this\n        feature monitor. The order of which credentials are used is as\n        follows - (1) this parameter (2) credentials passed to FeatureMonitor\n        constructor (3) credentials set in aiplatform.init.\n\nReturns:\n    FeatureMonitorJob - the Feature Monitor Job resource object under this\n    feature monitor."
  - signature: 'def list_feature_monitor_jobs(self, project: typing.Optional[str], location: typing.Optional[str], credentials: typing.Optional[google.auth.credentials.Credentials]) -> typing.List[FeatureMonitorJob]:'
    docstring: "Lists features monitor jobs under this feature monitor.\n\nArgs:\n    project:\n        Project to list feature monitors in. If unset, the project set in\n        aiplatform.init will be used.\n    location:\n        Location to list feature monitors in. If not set, location set in\n        aiplatform.init will be used.\n    credentials:\n        Custom credentials to use to list feature monitors. Overrides\n        credentials set in aiplatform.init.\n\nReturns:\n    List of feature monitor jobs under this feature monitor."
  properties:
  - signature: 'client_class: Any'
  omitted_inherited_members_from:
  - base.VertexAiResourceNounWithFutureManager
- rank: 3126
  id: vertexai.resources.preview.feature_store.feature_monitor.FeatureMonitor.__init__
  name: __init__
  file_path: env/lib/python3.13/site-packages/vertexai/resources/preview/feature_store/feature_monitor.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Retrieves an existing managed feature.\n\nArgs:\n    name:\n        The resource name\n        (`projects/.../locations/.../featureGroups/.../featureMonitors/...`) or\n        ID.\n    feature_group_id:\n        The feature group ID. Must be passed in if name is an ID and not\n        a resource path.\n    project:\n        Project to retrieve feature from. If not set, the project set in\n        aiplatform.init will be used.\n    location:\n        Location to retrieve feature from. If not set, the location set\n        in aiplatform.init will be used.\n    credentials:\n        Custom credentials to use to retrieve this feature. Overrides\n        credentials set in aiplatform.init."
  signature: 'def __init__(self, name: str, feature_group_id: typing.Optional[str], project: typing.Optional[str], location: typing.Optional[str], credentials: typing.Optional[google.auth.credentials.Credentials]):'
- rank: 3127
  id: vertexai.resources.preview.feature_store.feature_monitor.FeatureMonitor.create_feature_monitor_job
  name: create_feature_monitor_job
  file_path: env/lib/python3.13/site-packages/vertexai/resources/preview/feature_store/feature_monitor.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Creates a new feature monitor job.\n\nArgs:\n    description: Description of the feature monitor job.\n    labels:\n        The labels with user-defined metadata to organize your\n        FeatureMonitorJobs.\n        Label keys and values can be no longer than 64 characters\n        (Unicode codepoints), can only contain lowercase letters,\n        numeric characters, underscores and dashes. International\n        characters are allowed.\n\n        See https://goo.gl/xmQnxf for more information on and examples\n        of labels. No more than 64 user labels can be associated with\n        one FeatureMonitor (System labels are excluded).\" System reserved label\n        keys are prefixed with \"aiplatform.googleapis.com/\" and are\n        immutable.\n    project:\n        Project to create feature in. If unset, the project set in\n        aiplatform.init will be used.\n    location:\n        Location to create feature in. If not set, location set in\n        aiplatform.init\
    \ will be used.\n    credentials:\n        Custom credentials to use to create this feature. Overrides\n        credentials set in aiplatform.init.\n    request_metadata:\n        Strings which should be sent along with the request as metadata.\n    create_request_timeout:\n        The timeout for the create request in seconds.\n\nReturns:\n    FeatureMonitorJob - the FeatureMonitorJob resource object."
  signature: 'def create_feature_monitor_job(self, description: typing.Optional[str], labels: typing.Optional[typing.Dict[str, str]], project: typing.Optional[str], location: typing.Optional[str], credentials: typing.Optional[google.auth.credentials.Credentials], request_metadata: typing.Optional[typing.Sequence[typing.Tuple[str, str]]], create_request_timeout: typing.Optional[float]) -> FeatureMonitorJob:'
- rank: 3128
  id: vertexai.resources.preview.feature_store.feature_monitor.FeatureMonitor.feature_selection_configs
  name: feature_selection_configs
  file_path: env/lib/python3.13/site-packages/vertexai/resources/preview/feature_store/feature_monitor.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: The feature and it's drift threshold configs of the feature monitor.
  signature: 'def feature_selection_configs(self) -> typing.List[typing.Tuple[str, float]]:'
- rank: 3129
  id: vertexai.resources.preview.feature_store.feature_monitor.FeatureMonitor.get_feature_monitor_job
  name: get_feature_monitor_job
  file_path: env/lib/python3.13/site-packages/vertexai/resources/preview/feature_store/feature_monitor.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Retrieves an existing feature monitor.\n\nArgs:\n    feature_monitor_job_id: The ID of the feature monitor job.\n    credentials:\n        Custom credentials to use to retrieve the feature monitor job under this\n        feature monitor. The order of which credentials are used is as\n        follows - (1) this parameter (2) credentials passed to FeatureMonitor\n        constructor (3) credentials set in aiplatform.init.\n\nReturns:\n    FeatureMonitorJob - the Feature Monitor Job resource object under this\n    feature monitor."
  signature: 'def get_feature_monitor_job(self, feature_monitor_job_id: str, credentials: typing.Optional[google.auth.credentials.Credentials]) -> FeatureMonitorJob:'
- rank: 3130
  id: vertexai.resources.preview.feature_store.feature_monitor.FeatureMonitor.list_feature_monitor_jobs
  name: list_feature_monitor_jobs
  file_path: env/lib/python3.13/site-packages/vertexai/resources/preview/feature_store/feature_monitor.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Lists features monitor jobs under this feature monitor.\n\nArgs:\n    project:\n        Project to list feature monitors in. If unset, the project set in\n        aiplatform.init will be used.\n    location:\n        Location to list feature monitors in. If not set, location set in\n        aiplatform.init will be used.\n    credentials:\n        Custom credentials to use to list feature monitors. Overrides\n        credentials set in aiplatform.init.\n\nReturns:\n    List of feature monitor jobs under this feature monitor."
  signature: 'def list_feature_monitor_jobs(self, project: typing.Optional[str], location: typing.Optional[str], credentials: typing.Optional[google.auth.credentials.Credentials]) -> typing.List[FeatureMonitorJob]:'
- rank: 3131
  id: vertexai.resources.preview.feature_store.feature_monitor.FeatureMonitorJob
  name: FeatureMonitorJob
  file_path: env/lib/python3.13/site-packages/vertexai/resources/preview/feature_store/feature_monitor.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Class for managing Feature Monitor Job resources.


    [Note: Inherited members from base.VertexAiResourceNounWithFutureManager are omitted.]'
  constructor_signature: 'def __init__(self, name: str, project: typing.Optional[str], location: typing.Optional[str], credentials: typing.Optional[google.auth.credentials.Credentials]):'
  methods:
  - signature: 'def description(self) -> str:'
    docstring: The description of the feature monitor.
  - signature: 'def feature_stats_and_anomalies(self) -> typing.List[google.cloud.aiplatform.compat.types.feature_monitor_v1beta1.FeatureStatsAndAnomaly]:'
    docstring: The feature stats and anomaly of the feature monitor job.
  properties:
  - signature: 'client_class: Any'
  omitted_inherited_members_from:
  - base.VertexAiResourceNounWithFutureManager
- rank: 3132
  id: vertexai.resources.preview.feature_store.feature_monitor.FeatureMonitorJob.__init__
  name: __init__
  file_path: env/lib/python3.13/site-packages/vertexai/resources/preview/feature_store/feature_monitor.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Retrieves an existing managed feature monitor job.\n\nArgs:\n    name: The resource name\n      (`projects/.../locations/.../featureGroups/.../featureMonitors/.../featureMonitorJobs/...`)\n    project: Project to retrieve the feature monitor job from. If\n      unset, the project set in aiplatform.init will be used.\n    location: Location to retrieve the feature monitor job from. If\n      not set, location set in aiplatform.init will be used.\n    credentials: Custom credentials to use to retrieve this feature\n      monitor job. Overrides credentials set in aiplatform.init."
  signature: 'def __init__(self, name: str, project: typing.Optional[str], location: typing.Optional[str], credentials: typing.Optional[google.auth.credentials.Credentials]):'
- rank: 3133
  id: vertexai.resources.preview.feature_store.feature_monitor.FeatureMonitorJob.feature_stats_and_anomalies
  name: feature_stats_and_anomalies
  file_path: env/lib/python3.13/site-packages/vertexai/resources/preview/feature_store/feature_monitor.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: The feature stats and anomaly of the feature monitor job.
  signature: 'def feature_stats_and_anomalies(self) -> typing.List[google.cloud.aiplatform.compat.types.feature_monitor_v1beta1.FeatureStatsAndAnomaly]:'
- rank: 3134
  id: vertexai.resources.preview.feature_store.feature_online_store
  name: feature_online_store
  file_path: env/lib/python3.13/site-packages/vertexai/resources/preview/feature_store/feature_online_store.py
  type: MODULE
  group: Orphan
  usage_score: 0
- rank: 3135
  id: vertexai.resources.preview.feature_store.feature_online_store.FeatureOnlineStore
  name: FeatureOnlineStore
  file_path: env/lib/python3.13/site-packages/vertexai/resources/preview/feature_store/feature_online_store.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Class for managing Feature Online Store resources.


    [Note: Inherited members from base.VertexAiResourceNounWithFutureManager are omitted.]'
  constructor_signature: 'def __init__(self, name: str, project: typing.Optional[str], location: typing.Optional[str], credentials: typing.Optional[google.auth.credentials.Credentials]):'
  methods:
  - signature: 'def create_bigtable_store(cls, name: str, min_node_count: typing.Optional[int], max_node_count: typing.Optional[int], cpu_utilization_target: typing.Optional[int], labels: typing.Optional[typing.Dict[str, str]], project: typing.Optional[str], location: typing.Optional[str], credentials: typing.Optional[google.auth.credentials.Credentials], request_metadata: typing.Optional[typing.Sequence[typing.Tuple[str, str]]], create_request_timeout: typing.Optional[float], sync: bool) -> vertexai.resources.preview.feature_store.feature_online_store.FeatureOnlineStore:'
    docstring: "Creates a Bigtable online store.\n\nExample Usage:\n\n    my_fos = vertexai.preview.FeatureOnlineStore.create_bigtable_store('my_fos')\n\nArgs:\n    name: The name of the feature online store.\n    min_node_count:\n        The minimum number of Bigtable nodes to scale down to.  Must be\n        greater than or equal to 1.\n    max_node_count:\n        The maximum number of Bigtable nodes to scale up to.  Must\n        satisfy min_node_count <= max_node_count <= (10 *\n        min_node_count).\n    cpu_utilization_target:\n        A percentage of the cluster's CPU capacity. Can be from 10% to\n        80%. When a cluster's CPU utilization exceeds the target that\n        you have set, Bigtable immediately adds nodes to the cluster.\n        When CPU utilization is substantially lower than the target,\n        Bigtable removes nodes. If not set will default to 50%.\n    labels:\n        The labels with user-defined metadata to organize your feature\n        online store. Label\
      \ keys and values can be no longer than 64\n        characters (Unicode codepoints), can only contain lowercase\n        letters, numeric characters, underscores and dashes.\n        International characters are allowed. See https://goo.gl/xmQnxf\n        for more information on and examples of labels. No more than 64\n        user labels can be associated with one feature online store\n        (System labels are excluded).\" System reserved label keys are\n        prefixed with \"aiplatform.googleapis.com/\" and are immutable.\n    project:\n        Project to create feature online store in. If unset, the project\n        set in aiplatform.init will be used.\n    location:\n        Location to create feature online store in. If not set, location\n        set in aiplatform.init will be used.\n    credentials:\n        Custom credentials to use to create this feature online store.\n        Overrides credentials set in aiplatform.init.\n    request_metadata:\n        Strings which should\
      \ be sent along with the request as metadata.\n    create_request_timeout:\n        The timeout for the create request in seconds.\n    sync:\n        Whether to execute this creation synchronously. If False, this\n        method will be executed in concurrent Future and any downstream\n        object will be immediately returned and synced when the Future\n        has completed.\n\nReturns:\n    FeatureOnlineStore - the FeatureOnlineStore resource object."
  - signature: 'def create_optimized_store(cls, name: str, enable_private_service_connect: bool, project_allowlist: typing.Optional[typing.Sequence[str]], labels: typing.Optional[typing.Dict[str, str]], project: typing.Optional[str], location: typing.Optional[str], credentials: typing.Optional[google.auth.credentials.Credentials], request_metadata: typing.Optional[typing.Sequence[typing.Tuple[str, str]]], create_request_timeout: typing.Optional[float], sync: bool) -> vertexai.resources.preview.feature_store.feature_online_store.FeatureOnlineStore:'
    docstring: "Creates an Optimized online store.\n\nExample Usage:\n\n    ```\n    # Create optimized store with public endpoint.\n    my_fos = vertexai.preview.FeatureOnlineStore.create_optimized_store('my_fos')\n    ```\n\n    ```\n    # Create optimized online store with private service connect.\n    my_fos = vertexai.preview.FeatureOnlineStore.create_optimized_store(\n        'my_fos',\n        enable_private_service_connect=True,\n        project_allowlist=['my-project'],\n    )\n    ```\n\nArgs:\n    name: The name of the feature online store.\n    enable_private_service_connect:\n        Optional. If true, expose the optimized online store\n        via private service connect. Otherwise the optimized online\n        store will be accessible through public endpoint.\n    project_allowlist:\n        A list of Projects from which the forwarding\n        rule will target the service attachment. Only needed when\n        `enable_private_service_connect` is set to true.\n    labels:\n\
      \        The labels with user-defined metadata to organize your feature\n        online store. Label keys and values can be no longer than 64\n        characters (Unicode codepoints), can only contain lowercase\n        letters, numeric characters, underscores and dashes.\n        International characters are allowed. See https://goo.gl/xmQnxf\n        for more information on and examples of labels. No more than 64\n        user labels can be associated with one feature online store\n        (System labels are excluded).\" System reserved label keys are\n        prefixed with \"aiplatform.googleapis.com/\" and are immutable.\n    project:\n        Project to create feature online store in. If unset, the project\n        set in aiplatform.init will be used.\n    location:\n        Location to create feature online store in. If not set, location\n        set in aiplatform.init will be used.\n    credentials:\n        Custom credentials to use to create this feature online store.\n  \
      \      Overrides credentials set in aiplatform.init.\n    request_metadata:\n        Strings which should be sent along with the request as metadata.\n    create_request_timeout:\n        The timeout for the create request in seconds.\n    sync:\n        Whether to execute this creation synchronously. If False, this\n        method will be executed in concurrent Future and any downstream\n        object will be immediately returned and synced when the Future\n        has completed.\n\nReturns:\n    FeatureOnlineStore - the FeatureOnlineStore resource object."
  - signature: 'def delete(self, force: bool, sync: bool) -> None:'
    docstring: "Deletes this online store.\n\nWARNING: This deletion is permanent.\n\nArgs:\n    force:\n        If set to True, all feature views under this online store will\n        be deleted prior to online store deletion. Otherwise, deletion\n        will only succeed if the online store has no FeatureViews.\n    sync:\n        Whether to execute this deletion synchronously. If False, this\n        method will be executed in concurrent Future and any downstream\n        object will be immediately returned and synced when the Future\n        has completed."
  - signature: 'def feature_online_store_type(self) -> vertexai.resources.preview.feature_store.feature_online_store.FeatureOnlineStoreType:'
  - signature: 'def labels(self) -> typing.Dict[str, str]:'
  - signature: 'def create_feature_view(self, name: str, source: typing.Union[vertexai.resources.preview.feature_store.utils.FeatureViewBigQuerySource, vertexai.resources.preview.feature_store.utils.FeatureViewVertexRagSource, vertexai.resources.preview.feature_store.utils.FeatureViewRegistrySource], labels: typing.Optional[typing.Dict[str, str]], sync_config: typing.Optional[str], index_config: typing.Optional[vertexai.resources.preview.feature_store.utils.IndexConfig], project: typing.Optional[str], location: typing.Optional[str], credentials: typing.Optional[google.auth.credentials.Credentials], request_metadata: typing.Optional[typing.Sequence[typing.Tuple[str, str]]], create_request_timeout: typing.Optional[float], sync: bool) -> vertexai.resources.preview.feature_store.feature_view.FeatureView:'
    docstring: "Creates a FeatureView from a BigQuery source.\n\nExample Usage:\n```\nexisting_fos = FeatureOnlineStore('my_fos')\nnew_fv = existing_fos.create_feature_view(\n        'my_fos',\n        BigQuerySource(\n            uri='bq://my-proj/dataset/table',\n            entity_id_columns=['entity_id'],\n        )\n)\n# Example for how to create an embedding FeatureView.\nembedding_fv = existing_fos.create_feature_view(\n        'my_fos',\n        BigQuerySource(\n            uri='bq://my-proj/dataset/table',\n            entity_id_columns=['entity_id'],\n        )\n        index_config=IndexConfig(\n            embedding_column=\"embedding\",\n            filter_column=[\"currency_code\", \"gender\",\n            crowding_column=\"crowding\",\n            dimentions=1536,\n            distance_measure_type=DistanceMeasureType.SQUARED_L2_DISTANCE,\n            algorithm_config=TreeAhConfig(),\n        )\n    )\n```\nArgs:\n    name: The name of the feature view.\n    source:\n    \
      \    The source to load data from when a feature view sync runs.\n        Currently supports a BigQuery source, Vertex RAG source, Registry source.\n    labels:\n        The labels with user-defined metadata to organize your\n        FeatureViews.\n\n        Label keys and values can be no longer than 64 characters\n        (Unicode codepoints), can only contain lowercase letters,\n        numeric characters, underscores and dashes. International\n        characters are allowed.\n\n        See https://goo.gl/xmQnxf for more information on and examples\n        of labels. No more than 64 user labels can be associated with\n        one FeatureOnlineStore(System labels are excluded).\" System\n        reserved label keys are prefixed with\n        \"aiplatform.googleapis.com/\" and are immutable.\n    sync_config:\n        Configures when data is to be synced/updated for this\n        FeatureView. At the end of the sync the latest feature values\n        for each entity ID of this FeatureView\
      \ are made ready for online\n        serving. Example format: \"TZ=America/New_York 0 9 * * *\" (sync\n        daily at 9 AM EST).\n    index_config:\n        Configuration for index preparation for vector search. It\n        contains the required configurations to create an index from\n        source data, so that approximate nearest neighbor (a.k.a ANN)\n        algorithms search can be performed during online serving.\n    project:\n        Project to create feature view in. If unset, the project set in\n        aiplatform.init will be used.\n    location:\n        Location to create feature view in. If not set, location set in\n        aiplatform.init will be used.\n    credentials:\n        Custom credentials to use to create this feature view.\n        Overrides credentials set in aiplatform.init.\n    request_metadata:\n        Strings which should be sent along with the request as metadata.\n    create_request_timeout:\n        The timeout for the create request in seconds.\n\
      \    sync:\n        Whether to execute this creation synchronously. If False, this\n        method will be executed in concurrent Future and any downstream\n        object will be immediately returned and synced when the Future\n        has completed.\n\nReturns:\n    FeatureView - the FeatureView resource object."
  - signature: 'def list_feature_views(self, project: typing.Optional[str], location: typing.Optional[str], credentials: typing.Optional[google.auth.credentials.Credentials]) -> typing.List[vertexai.resources.preview.feature_store.feature_view.FeatureView]:'
    docstring: "Lists feature views under this feature online store.\n\nArgs:\n    project:\n        Project to list feature views in. If unset, the project set in\n        aiplatform.init will be used.\n    location:\n        Location to list feature views in. If not set, location set in\n        aiplatform.init will be used.\n    credentials:\n        Custom credentials to use to list feature views. Overrides\n        credentials set in aiplatform.init.\n\nReturns:\n    List of feature views under this feature online store."
  properties:
  - signature: 'client_class: Any'
  omitted_inherited_members_from:
  - base.VertexAiResourceNounWithFutureManager
- rank: 3136
  id: vertexai.resources.preview.feature_store.feature_online_store.FeatureOnlineStore.__init__
  name: __init__
  file_path: env/lib/python3.13/site-packages/vertexai/resources/preview/feature_store/feature_online_store.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Retrieves an existing managed feature online store.\n\nArgs:\n    name:\n        The resource name\n        (`projects/.../locations/.../featureOnlineStores/...`) or ID.\n    project:\n        Project to retrieve feature online store from. If unset, the\n        project set in aiplatform.init will be used.\n    location:\n        Location to retrieve feature online store from. If not set,\n        location set in aiplatform.init will be used.\n    credentials:\n        Custom credentials to use to retrieve this feature online store.\n        Overrides credentials set in aiplatform.init."
  signature: 'def __init__(self, name: str, project: typing.Optional[str], location: typing.Optional[str], credentials: typing.Optional[google.auth.credentials.Credentials]):'
- rank: 3137
  id: vertexai.resources.preview.feature_store.feature_online_store.FeatureOnlineStore.create_bigtable_store
  name: create_bigtable_store
  file_path: env/lib/python3.13/site-packages/vertexai/resources/preview/feature_store/feature_online_store.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Creates a Bigtable online store.\n\nExample Usage:\n\n    my_fos = vertexai.preview.FeatureOnlineStore.create_bigtable_store('my_fos')\n\nArgs:\n    name: The name of the feature online store.\n    min_node_count:\n        The minimum number of Bigtable nodes to scale down to.  Must be\n        greater than or equal to 1.\n    max_node_count:\n        The maximum number of Bigtable nodes to scale up to.  Must\n        satisfy min_node_count <= max_node_count <= (10 *\n        min_node_count).\n    cpu_utilization_target:\n        A percentage of the cluster's CPU capacity. Can be from 10% to\n        80%. When a cluster's CPU utilization exceeds the target that\n        you have set, Bigtable immediately adds nodes to the cluster.\n        When CPU utilization is substantially lower than the target,\n        Bigtable removes nodes. If not set will default to 50%.\n    labels:\n        The labels with user-defined metadata to organize your feature\n        online store. Label\
    \ keys and values can be no longer than 64\n        characters (Unicode codepoints), can only contain lowercase\n        letters, numeric characters, underscores and dashes.\n        International characters are allowed. See https://goo.gl/xmQnxf\n        for more information on and examples of labels. No more than 64\n        user labels can be associated with one feature online store\n        (System labels are excluded).\" System reserved label keys are\n        prefixed with \"aiplatform.googleapis.com/\" and are immutable.\n    project:\n        Project to create feature online store in. If unset, the project\n        set in aiplatform.init will be used.\n    location:\n        Location to create feature online store in. If not set, location\n        set in aiplatform.init will be used.\n    credentials:\n        Custom credentials to use to create this feature online store.\n        Overrides credentials set in aiplatform.init.\n    request_metadata:\n        Strings which should\
    \ be sent along with the request as metadata.\n    create_request_timeout:\n        The timeout for the create request in seconds.\n    sync:\n        Whether to execute this creation synchronously. If False, this\n        method will be executed in concurrent Future and any downstream\n        object will be immediately returned and synced when the Future\n        has completed.\n\nReturns:\n    FeatureOnlineStore - the FeatureOnlineStore resource object."
  signature: 'def create_bigtable_store(cls, name: str, min_node_count: typing.Optional[int], max_node_count: typing.Optional[int], cpu_utilization_target: typing.Optional[int], labels: typing.Optional[typing.Dict[str, str]], project: typing.Optional[str], location: typing.Optional[str], credentials: typing.Optional[google.auth.credentials.Credentials], request_metadata: typing.Optional[typing.Sequence[typing.Tuple[str, str]]], create_request_timeout: typing.Optional[float], sync: bool) -> vertexai.resources.preview.feature_store.feature_online_store.FeatureOnlineStore:'
- rank: 3138
  id: vertexai.resources.preview.feature_store.feature_online_store.FeatureOnlineStore.create_feature_view
  name: create_feature_view
  file_path: env/lib/python3.13/site-packages/vertexai/resources/preview/feature_store/feature_online_store.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Creates a FeatureView from a BigQuery source.\n\nExample Usage:\n```\nexisting_fos = FeatureOnlineStore('my_fos')\nnew_fv = existing_fos.create_feature_view(\n        'my_fos',\n        BigQuerySource(\n            uri='bq://my-proj/dataset/table',\n            entity_id_columns=['entity_id'],\n        )\n)\n# Example for how to create an embedding FeatureView.\nembedding_fv = existing_fos.create_feature_view(\n        'my_fos',\n        BigQuerySource(\n            uri='bq://my-proj/dataset/table',\n            entity_id_columns=['entity_id'],\n        )\n        index_config=IndexConfig(\n            embedding_column=\"embedding\",\n            filter_column=[\"currency_code\", \"gender\",\n            crowding_column=\"crowding\",\n            dimentions=1536,\n            distance_measure_type=DistanceMeasureType.SQUARED_L2_DISTANCE,\n            algorithm_config=TreeAhConfig(),\n        )\n    )\n```\nArgs:\n    name: The name of the feature view.\n    source:\n      \
    \  The source to load data from when a feature view sync runs.\n        Currently supports a BigQuery source, Vertex RAG source, Registry source.\n    labels:\n        The labels with user-defined metadata to organize your\n        FeatureViews.\n\n        Label keys and values can be no longer than 64 characters\n        (Unicode codepoints), can only contain lowercase letters,\n        numeric characters, underscores and dashes. International\n        characters are allowed.\n\n        See https://goo.gl/xmQnxf for more information on and examples\n        of labels. No more than 64 user labels can be associated with\n        one FeatureOnlineStore(System labels are excluded).\" System\n        reserved label keys are prefixed with\n        \"aiplatform.googleapis.com/\" and are immutable.\n    sync_config:\n        Configures when data is to be synced/updated for this\n        FeatureView. At the end of the sync the latest feature values\n        for each entity ID of this FeatureView\
    \ are made ready for online\n        serving. Example format: \"TZ=America/New_York 0 9 * * *\" (sync\n        daily at 9 AM EST).\n    index_config:\n        Configuration for index preparation for vector search. It\n        contains the required configurations to create an index from\n        source data, so that approximate nearest neighbor (a.k.a ANN)\n        algorithms search can be performed during online serving.\n    project:\n        Project to create feature view in. If unset, the project set in\n        aiplatform.init will be used.\n    location:\n        Location to create feature view in. If not set, location set in\n        aiplatform.init will be used.\n    credentials:\n        Custom credentials to use to create this feature view.\n        Overrides credentials set in aiplatform.init.\n    request_metadata:\n        Strings which should be sent along with the request as metadata.\n    create_request_timeout:\n        The timeout for the create request in seconds.\n\
    \    sync:\n        Whether to execute this creation synchronously. If False, this\n        method will be executed in concurrent Future and any downstream\n        object will be immediately returned and synced when the Future\n        has completed.\n\nReturns:\n    FeatureView - the FeatureView resource object."
  signature: 'def create_feature_view(self, name: str, source: typing.Union[vertexai.resources.preview.feature_store.utils.FeatureViewBigQuerySource, vertexai.resources.preview.feature_store.utils.FeatureViewVertexRagSource, vertexai.resources.preview.feature_store.utils.FeatureViewRegistrySource], labels: typing.Optional[typing.Dict[str, str]], sync_config: typing.Optional[str], index_config: typing.Optional[vertexai.resources.preview.feature_store.utils.IndexConfig], project: typing.Optional[str], location: typing.Optional[str], credentials: typing.Optional[google.auth.credentials.Credentials], request_metadata: typing.Optional[typing.Sequence[typing.Tuple[str, str]]], create_request_timeout: typing.Optional[float], sync: bool) -> vertexai.resources.preview.feature_store.feature_view.FeatureView:'
- rank: 3139
  id: vertexai.resources.preview.feature_store.feature_online_store.FeatureOnlineStore.create_optimized_store
  name: create_optimized_store
  file_path: env/lib/python3.13/site-packages/vertexai/resources/preview/feature_store/feature_online_store.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Creates an Optimized online store.\n\nExample Usage:\n\n    ```\n    # Create optimized store with public endpoint.\n    my_fos = vertexai.preview.FeatureOnlineStore.create_optimized_store('my_fos')\n    ```\n\n    ```\n    # Create optimized online store with private service connect.\n    my_fos = vertexai.preview.FeatureOnlineStore.create_optimized_store(\n        'my_fos',\n        enable_private_service_connect=True,\n        project_allowlist=['my-project'],\n    )\n    ```\n\nArgs:\n    name: The name of the feature online store.\n    enable_private_service_connect:\n        Optional. If true, expose the optimized online store\n        via private service connect. Otherwise the optimized online\n        store will be accessible through public endpoint.\n    project_allowlist:\n        A list of Projects from which the forwarding\n        rule will target the service attachment. Only needed when\n        `enable_private_service_connect` is set to true.\n    labels:\n \
    \       The labels with user-defined metadata to organize your feature\n        online store. Label keys and values can be no longer than 64\n        characters (Unicode codepoints), can only contain lowercase\n        letters, numeric characters, underscores and dashes.\n        International characters are allowed. See https://goo.gl/xmQnxf\n        for more information on and examples of labels. No more than 64\n        user labels can be associated with one feature online store\n        (System labels are excluded).\" System reserved label keys are\n        prefixed with \"aiplatform.googleapis.com/\" and are immutable.\n    project:\n        Project to create feature online store in. If unset, the project\n        set in aiplatform.init will be used.\n    location:\n        Location to create feature online store in. If not set, location\n        set in aiplatform.init will be used.\n    credentials:\n        Custom credentials to use to create this feature online store.\n     \
    \   Overrides credentials set in aiplatform.init.\n    request_metadata:\n        Strings which should be sent along with the request as metadata.\n    create_request_timeout:\n        The timeout for the create request in seconds.\n    sync:\n        Whether to execute this creation synchronously. If False, this\n        method will be executed in concurrent Future and any downstream\n        object will be immediately returned and synced when the Future\n        has completed.\n\nReturns:\n    FeatureOnlineStore - the FeatureOnlineStore resource object."
  signature: 'def create_optimized_store(cls, name: str, enable_private_service_connect: bool, project_allowlist: typing.Optional[typing.Sequence[str]], labels: typing.Optional[typing.Dict[str, str]], project: typing.Optional[str], location: typing.Optional[str], credentials: typing.Optional[google.auth.credentials.Credentials], request_metadata: typing.Optional[typing.Sequence[typing.Tuple[str, str]]], create_request_timeout: typing.Optional[float], sync: bool) -> vertexai.resources.preview.feature_store.feature_online_store.FeatureOnlineStore:'
- rank: 3140
  id: vertexai.resources.preview.feature_store.feature_online_store.FeatureOnlineStore.delete
  name: delete
  file_path: env/lib/python3.13/site-packages/vertexai/resources/preview/feature_store/feature_online_store.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Deletes this online store.\n\nWARNING: This deletion is permanent.\n\nArgs:\n    force:\n        If set to True, all feature views under this online store will\n        be deleted prior to online store deletion. Otherwise, deletion\n        will only succeed if the online store has no FeatureViews.\n    sync:\n        Whether to execute this deletion synchronously. If False, this\n        method will be executed in concurrent Future and any downstream\n        object will be immediately returned and synced when the Future\n        has completed."
  signature: 'def delete(self, force: bool, sync: bool) -> None:'
- rank: 3141
  id: vertexai.resources.preview.feature_store.feature_online_store.FeatureOnlineStore.feature_online_store_type
  name: feature_online_store_type
  file_path: env/lib/python3.13/site-packages/vertexai/resources/preview/feature_store/feature_online_store.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def feature_online_store_type(self) -> vertexai.resources.preview.feature_store.feature_online_store.FeatureOnlineStoreType:'
- rank: 3142
  id: vertexai.resources.preview.feature_store.feature_online_store.FeatureOnlineStore.list_feature_views
  name: list_feature_views
  file_path: env/lib/python3.13/site-packages/vertexai/resources/preview/feature_store/feature_online_store.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Lists feature views under this feature online store.\n\nArgs:\n    project:\n        Project to list feature views in. If unset, the project set in\n        aiplatform.init will be used.\n    location:\n        Location to list feature views in. If not set, location set in\n        aiplatform.init will be used.\n    credentials:\n        Custom credentials to use to list feature views. Overrides\n        credentials set in aiplatform.init.\n\nReturns:\n    List of feature views under this feature online store."
  signature: 'def list_feature_views(self, project: typing.Optional[str], location: typing.Optional[str], credentials: typing.Optional[google.auth.credentials.Credentials]) -> typing.List[vertexai.resources.preview.feature_store.feature_view.FeatureView]:'
- rank: 3143
  id: vertexai.resources.preview.feature_store.feature_online_store.FeatureOnlineStoreType
  name: FeatureOnlineStoreType
  file_path: env/lib/python3.13/site-packages/vertexai/resources/preview/feature_store/feature_online_store.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: '[Note: Inherited members from enum.Enum are omitted.]'
  properties:
  - signature: 'UNKNOWN: int'
  - signature: 'BIGTABLE: int'
  - signature: 'OPTIMIZED: int'
  omitted_inherited_members_from:
  - enum.Enum
- rank: 3144
  id: vertexai.resources.preview.feature_store.feature_view
  name: feature_view
  file_path: env/lib/python3.13/site-packages/vertexai/resources/preview/feature_store/feature_view.py
  type: MODULE
  group: Orphan
  usage_score: 0
- rank: 3145
  id: vertexai.resources.preview.feature_store.feature_view.FeatureView
  name: FeatureView
  file_path: env/lib/python3.13/site-packages/vertexai/resources/preview/feature_store/feature_view.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Class for managing Feature View resources.


    [Note: Inherited members from base.VertexAiResourceNounWithFutureManager are omitted.]'
  constructor_signature: 'def __init__(self, name: str, feature_online_store_id: typing.Optional[str], project: typing.Optional[str], location: typing.Optional[str], credentials: typing.Optional[google.auth.credentials.Credentials]):'
  methods:
  - signature: 'def list(cls, feature_online_store_id: str, filter: typing.Optional[str], project: typing.Optional[str], location: typing.Optional[str], credentials: typing.Optional[google.auth.credentials.Credentials]) -> typing.List[vertexai.resources.preview.feature_store.feature_view.FeatureView]:'
    docstring: "List all feature view under feature_online_store_id.\n\nExample Usage:\n```\nfeature_views = vertexai.preview.FeatureView.list(\n    feature_online_store_id=\"my_fos\",\n    filter=labels.label_key=label_value)\n```\nArgs:\n    feature_online_store_id:\n        Parentfeature online store ID.\n    filter:\n        Filter to apply on the returned feature online store.\n    project:\n        Project to use to get a list of feature views. If unset, the\n        project set in aiplatform.init will be used.\n    location:\n        Location to use to get a list feature views. If not set,\n        location set in aiplatform.init will be used.\n    credentials:\n        Custom credentials to use to get a list of feature views.\n        Overrides credentials set in aiplatform.init.\n\nReturns:\n    List[FeatureView] - list of FeatureView resource object."
  - signature: 'def delete(self, sync: bool) -> None:'
    docstring: "Deletes this feature view.\n\nWARNING: This deletion is permanent.\n\nArgs:\n    sync:\n        Whether to execute this deletion synchronously. If False, this\n        method will be executed in concurrent Future and any downstream\n        object will be immediately returned and synced when the Future\n        has completed."
  - signature: 'def sync(self) -> FeatureViewSync:'
    docstring: "Starts an on-demand Sync for the FeatureView.\n\nArgs: None\n\nReturns:\n    \"FeatureViewSync\" - FeatureViewSync instance"
  - signature: 'def get_sync(self, name) -> FeatureViewSync:'
    docstring: "Gets the FeatureViewSync resource for the given name.\n\nArgs:\n    name: The resource ID\n\nReturns:\n    \"FeatureViewSync\" - FeatureViewSync instance"
  - signature: 'def list_syncs(self, filter: typing.Optional[str]) -> typing.List[FeatureViewSync]:'
    docstring: "List all feature view under this FeatureView.\n\nArgs:\n    parent_resource_name: Fully qualified name of the parent FeatureView\n      resource.\n    filter: Filter to apply on the returned feature online store.\n\nReturns:\n    List[FeatureViewSync] - list of FeatureViewSync resource object."
  - signature: 'def read(self, key: typing.List[str], connection_options: typing.Optional[vertexai.resources.preview.feature_store.utils.ConnectionOptions], request_timeout: typing.Optional[float]) -> vertexai.resources.preview.feature_store.utils.FeatureViewReadResponse:'
    docstring: "Read the feature values from FeatureView.\n\n  Example Usage:\n    Read feature view. Use this for Bigtable online stores and for\n    Optimized online stores that use public endpoint.\n    ```\n    data = vertexai.preview.FeatureView(\n        name='feature_view_name', feature_online_store_id='fos_name')\n        .read(key=[12345, 6789])\n        .to_dict()\n    ```\n\n    Read feature view using IP with an insecure gRPC channel. Use this\n    for optimized online stores using private service connect.\n    ```\n    data = vertexai.preview.FeatureView(\n        name='feature_view_name', feature_online_store_id='fos_name')\n        .read(\n            key=[12345, 6789],\n            connection_options=fs_utils.ConnectionOptions(\n                host=\"<ip>\",\n                transport=fs_utils.ConnectionOptions.InsecureGrpcChannel()))\n        .to_dict()\n    ```\nArgs:\n    key: The request key to read feature values for.\n    connection_options:\n        If specified,\
      \ use these options to connect to a host for sending\n        requests instead of the default\n        `<region>-aiplatform.googleapis.com` or the feature online\n        store's public endpoint.\n\nReturns:\n    \"FeatureViewReadResponse\" - FeatureViewReadResponse object. It is\n    intermediate class that can be further converted by to_dict() or\n    to_proto()."
  - signature: 'def search(self, entity_id: typing.Optional[str], embedding_value: typing.Optional[typing.List[float]], neighbor_count: typing.Optional[int], string_filters: typing.Optional[typing.List[google.cloud.aiplatform.compat.types.feature_online_store_service.NearestNeighborQuery.StringFilter]], per_crowding_attribute_neighbor_count: typing.Optional[int], return_full_entity: bool, approximate_neighbor_candidates: typing.Optional[int], leaf_nodes_search_fraction: typing.Optional[float], request_timeout: typing.Optional[float]) -> vertexai.resources.preview.feature_store.utils.SearchNearestEntitiesResponse:'
    docstring: "Search the nearest entities from FeatureView.\n\nExample Usage:\n```\n  data = vertexai.preview.FeatureView(\n      name='feature_view_name', feature_online_store_id='fos_name')\n    .search(entity_id='sample_entity')\n    .to_dict()\n```\nArgs:\n    entity_id: The entity id whose similar entities should be searched\n      for.\n    embedding_value: The embedding vector that be used for similar\n      search.\n    neighbor_count: The number of similar entities to be retrieved\n      from feature view for each query.\n    string_filters: The list of string filters.\n    per_crowding_attribute_neighbor_count: Crowding is a constraint on a\n    neighbor list produced by nearest neighbor search requiring that\n      no more than sper_crowding_attribute_neighbor_count of the k\n      neighbors returned have the same value of crowding_attribute.\n      It's used for improving result diversity.\n    return_full_entity: If true, return full entities including the\n      features\
      \ other than embeddings.\n    approximate_neighbor_candidates: The number of neighbors to find via\n      approximate search before exact reordering is performed; if set,\n      this value must be > neighbor_count.\n    leaf_nodes_search_fraction: The fraction of the number of leaves to\n      search, set at query time allows user to tune search performance.\n      This value increase result in both search accuracy and latency\n      increase. The value should be between 0.0 and 1.0.\n\nReturns:\n    \"SearchNearestEntitiesResponse\" - SearchNearestEntitiesResponse\n    object. It is intermediate class that can be further converted by\n    to_dict() or to_proto()"
  properties:
  - signature: 'client_class: Any'
  omitted_inherited_members_from:
  - base.VertexAiResourceNounWithFutureManager
- rank: 3146
  id: vertexai.resources.preview.feature_store.feature_view.FeatureView.__init__
  name: __init__
  file_path: env/lib/python3.13/site-packages/vertexai/resources/preview/feature_store/feature_view.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Retrieves an existing managed feature view.\n\nArgs:\n    name:\n        The resource name\n        (`projects/.../locations/.../featureOnlineStores/.../featureViews/...`)\n        or ID.\n    feature_online_store_id:\n        The feature online store ID. Must be passed in if name is an ID\n        and not a resource path.\n    project:\n        Project to retrieve the feature view from. If unset, the project\n        set in aiplatform.init will be used.\n    location:\n        Location to retrieve the feature view from. If not set, location\n        set in aiplatform.init will be used.\n    credentials:\n        Custom credentials to use to retrieve this feature view.\n        Overrides credentials set in aiplatform.init."
  signature: 'def __init__(self, name: str, feature_online_store_id: typing.Optional[str], project: typing.Optional[str], location: typing.Optional[str], credentials: typing.Optional[google.auth.credentials.Credentials]):'
- rank: 3147
  id: vertexai.resources.preview.feature_store.feature_view.FeatureView.delete
  name: delete
  file_path: env/lib/python3.13/site-packages/vertexai/resources/preview/feature_store/feature_view.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Deletes this feature view.\n\nWARNING: This deletion is permanent.\n\nArgs:\n    sync:\n        Whether to execute this deletion synchronously. If False, this\n        method will be executed in concurrent Future and any downstream\n        object will be immediately returned and synced when the Future\n        has completed."
  signature: 'def delete(self, sync: bool) -> None:'
- rank: 3148
  id: vertexai.resources.preview.feature_store.feature_view.FeatureView.get_sync
  name: get_sync
  file_path: env/lib/python3.13/site-packages/vertexai/resources/preview/feature_store/feature_view.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Gets the FeatureViewSync resource for the given name.\n\nArgs:\n    name: The resource ID\n\nReturns:\n    \"FeatureViewSync\" - FeatureViewSync instance"
  signature: 'def get_sync(self, name) -> FeatureViewSync:'
- rank: 3149
  id: vertexai.resources.preview.feature_store.feature_view.FeatureView.list
  name: list
  file_path: env/lib/python3.13/site-packages/vertexai/resources/preview/feature_store/feature_view.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "List all feature view under feature_online_store_id.\n\nExample Usage:\n```\nfeature_views = vertexai.preview.FeatureView.list(\n    feature_online_store_id=\"my_fos\",\n    filter=labels.label_key=label_value)\n```\nArgs:\n    feature_online_store_id:\n        Parentfeature online store ID.\n    filter:\n        Filter to apply on the returned feature online store.\n    project:\n        Project to use to get a list of feature views. If unset, the\n        project set in aiplatform.init will be used.\n    location:\n        Location to use to get a list feature views. If not set,\n        location set in aiplatform.init will be used.\n    credentials:\n        Custom credentials to use to get a list of feature views.\n        Overrides credentials set in aiplatform.init.\n\nReturns:\n    List[FeatureView] - list of FeatureView resource object."
  signature: 'def list(cls, feature_online_store_id: str, filter: typing.Optional[str], project: typing.Optional[str], location: typing.Optional[str], credentials: typing.Optional[google.auth.credentials.Credentials]) -> typing.List[vertexai.resources.preview.feature_store.feature_view.FeatureView]:'
- rank: 3150
  id: vertexai.resources.preview.feature_store.feature_view.FeatureView.list_syncs
  name: list_syncs
  file_path: env/lib/python3.13/site-packages/vertexai/resources/preview/feature_store/feature_view.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "List all feature view under this FeatureView.\n\nArgs:\n    parent_resource_name: Fully qualified name of the parent FeatureView\n      resource.\n    filter: Filter to apply on the returned feature online store.\n\nReturns:\n    List[FeatureViewSync] - list of FeatureViewSync resource object."
  signature: 'def list_syncs(self, filter: typing.Optional[str]) -> typing.List[FeatureViewSync]:'
- rank: 3151
  id: vertexai.resources.preview.feature_store.feature_view.FeatureView.read
  name: read
  file_path: env/lib/python3.13/site-packages/vertexai/resources/preview/feature_store/feature_view.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Read the feature values from FeatureView.\n\n  Example Usage:\n    Read feature view. Use this for Bigtable online stores and for\n    Optimized online stores that use public endpoint.\n    ```\n    data = vertexai.preview.FeatureView(\n        name='feature_view_name', feature_online_store_id='fos_name')\n        .read(key=[12345, 6789])\n        .to_dict()\n    ```\n\n    Read feature view using IP with an insecure gRPC channel. Use this\n    for optimized online stores using private service connect.\n    ```\n    data = vertexai.preview.FeatureView(\n        name='feature_view_name', feature_online_store_id='fos_name')\n        .read(\n            key=[12345, 6789],\n            connection_options=fs_utils.ConnectionOptions(\n                host=\"<ip>\",\n                transport=fs_utils.ConnectionOptions.InsecureGrpcChannel()))\n        .to_dict()\n    ```\nArgs:\n    key: The request key to read feature values for.\n    connection_options:\n        If specified, use\
    \ these options to connect to a host for sending\n        requests instead of the default\n        `<region>-aiplatform.googleapis.com` or the feature online\n        store's public endpoint.\n\nReturns:\n    \"FeatureViewReadResponse\" - FeatureViewReadResponse object. It is\n    intermediate class that can be further converted by to_dict() or\n    to_proto()."
  signature: 'def read(self, key: typing.List[str], connection_options: typing.Optional[vertexai.resources.preview.feature_store.utils.ConnectionOptions], request_timeout: typing.Optional[float]) -> vertexai.resources.preview.feature_store.utils.FeatureViewReadResponse:'
- rank: 3152
  id: vertexai.resources.preview.feature_store.feature_view.FeatureView.search
  name: search
  file_path: env/lib/python3.13/site-packages/vertexai/resources/preview/feature_store/feature_view.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Search the nearest entities from FeatureView.\n\nExample Usage:\n```\n  data = vertexai.preview.FeatureView(\n      name='feature_view_name', feature_online_store_id='fos_name')\n    .search(entity_id='sample_entity')\n    .to_dict()\n```\nArgs:\n    entity_id: The entity id whose similar entities should be searched\n      for.\n    embedding_value: The embedding vector that be used for similar\n      search.\n    neighbor_count: The number of similar entities to be retrieved\n      from feature view for each query.\n    string_filters: The list of string filters.\n    per_crowding_attribute_neighbor_count: Crowding is a constraint on a\n    neighbor list produced by nearest neighbor search requiring that\n      no more than sper_crowding_attribute_neighbor_count of the k\n      neighbors returned have the same value of crowding_attribute.\n      It's used for improving result diversity.\n    return_full_entity: If true, return full entities including the\n      features other\
    \ than embeddings.\n    approximate_neighbor_candidates: The number of neighbors to find via\n      approximate search before exact reordering is performed; if set,\n      this value must be > neighbor_count.\n    leaf_nodes_search_fraction: The fraction of the number of leaves to\n      search, set at query time allows user to tune search performance.\n      This value increase result in both search accuracy and latency\n      increase. The value should be between 0.0 and 1.0.\n\nReturns:\n    \"SearchNearestEntitiesResponse\" - SearchNearestEntitiesResponse\n    object. It is intermediate class that can be further converted by\n    to_dict() or to_proto()"
  signature: 'def search(self, entity_id: typing.Optional[str], embedding_value: typing.Optional[typing.List[float]], neighbor_count: typing.Optional[int], string_filters: typing.Optional[typing.List[google.cloud.aiplatform.compat.types.feature_online_store_service.NearestNeighborQuery.StringFilter]], per_crowding_attribute_neighbor_count: typing.Optional[int], return_full_entity: bool, approximate_neighbor_candidates: typing.Optional[int], leaf_nodes_search_fraction: typing.Optional[float], request_timeout: typing.Optional[float]) -> vertexai.resources.preview.feature_store.utils.SearchNearestEntitiesResponse:'
- rank: 3153
  id: vertexai.resources.preview.feature_store.feature_view.FeatureView.sync
  name: sync
  file_path: env/lib/python3.13/site-packages/vertexai/resources/preview/feature_store/feature_view.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Starts an on-demand Sync for the FeatureView.\n\nArgs: None\n\nReturns:\n    \"FeatureViewSync\" - FeatureViewSync instance"
  signature: 'def sync(self) -> FeatureViewSync:'
- rank: 3154
  id: vertexai.resources.preview.feature_store.feature_view.FeatureViewSync
  name: FeatureViewSync
  file_path: env/lib/python3.13/site-packages/vertexai/resources/preview/feature_store/feature_view.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Class for managing Feature View Sync resources.


    [Note: Inherited members from base.VertexAiResourceNounWithFutureManager are omitted.]'
  constructor_signature: 'def __init__(self, name: str, project: typing.Optional[str], location: typing.Optional[str], credentials: typing.Optional[google.auth.credentials.Credentials]):'
  methods:
  - signature: 'def sync_method(cls) -> str:'
    docstring: Returns the sync method.
  properties:
  - signature: 'client_class: Any'
  omitted_inherited_members_from:
  - base.VertexAiResourceNounWithFutureManager
- rank: 3155
  id: vertexai.resources.preview.feature_store.feature_view.FeatureViewSync.__init__
  name: __init__
  file_path: env/lib/python3.13/site-packages/vertexai/resources/preview/feature_store/feature_view.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Retrieves an existing managed feature view sync.\n\nArgs:\n    name: The resource name\n      (`projects/.../locations/.../featureOnlineStores/.../featureViews/.../featureViewSyncs/...`)\n    project: Project to retrieve the feature view from. If unset, the\n      project set in aiplatform.init will be used.\n    location: Location to retrieve the feature view from. If not set,\n      location set in aiplatform.init will be used.\n    credentials: Custom credentials to use to retrieve this feature view.\n      Overrides credentials set in aiplatform.init."
  signature: 'def __init__(self, name: str, project: typing.Optional[str], location: typing.Optional[str], credentials: typing.Optional[google.auth.credentials.Credentials]):'
- rank: 3156
  id: vertexai.resources.preview.feature_store.offline_store
  name: offline_store
  file_path: env/lib/python3.13/site-packages/vertexai/resources/preview/feature_store/offline_store.py
  type: MODULE
  group: Orphan
  usage_score: 0
  methods:
  - signature: 'def fetch_historical_feature_values(entity_df: bigframes.pandas.DataFrame, features: typing.List[typing.Union[str, vertexai.resources.preview.feature_store.Feature]], feature_age_threshold: typing.Optional[datetime.timedelta], dry_run: bool, project: typing.Optional[str], location: typing.Optional[str], credentials: typing.Optional[google.auth.credentials.Credentials]) -> typing.Union[bigframes.pandas.DataFrame, None]:'
    docstring: "Fetch historical data at the timestamp specified for each entity.\n\nThis runs a Point-In-Time Lookup (PITL) query in BigQuery across all\nfeatures and returns the historical feature values. Feature data will be\njoined by matching their entity_id_column(s) with corresponding columns in\nthe entity data frame.\n\nArgs:\n  entity_df:\n    An entity DataFrame where one/multiple columns have entity ID.\n    One column should have a timestamp (used for feature lookup). Other\n    columns may have feature data. Entity IDs may be repeated with\n    different timestamp values (in the timestamp column) to lookup data for\n    entities at different points in time.\n  features:\n    Feature data will be joined with the entity data frame.\n     * If `str` is given use `project.feature_group.feature` as the format.\n      `project_id.feature_group_id.feature_id` may be used if features are\n      in another project.\n     * If `FeatureView` is given, the *sources* of the FeatureView\
      \ will be\n       used - but data will be read from the backing BigQuery table.\n  feature_age_threshold:\n    How far back from the timestamp to look for features values. If no\n    feature values are found, empty/null value will be populated.\n  dry_run:\n    Build the Point-In-Time Lookup (PITL) query but don't run it. The PITL\n    query will be printed to stdout.\n  project:\n    The project to use for feature lookup and running the Point-In-Time\n    Lookup (PITL) query in BigQuery. If unset, the project set in\n    aiplatform.init will be used.\n  location:\n    The location to use for feature lookup and running the Point-In-Time\n    Lookup (PITL) query in BigQuery. If unset, the project set in\n    aiplatform.init will be used.\n  credentials:\n    Custom credentials to use for feature lookup and running the\n    Point-In-Time Lookup (PITL) query in BigQuery. Overrides credentials\n    set in aiplatform.init.\n\nReturns:\n  A `bigframes.pandas.DataFrame` with the historical\
      \ feature values. `None`\n  if in `dry_run` mode."
- rank: 3157
  id: vertexai.resources.preview.feature_store.offline_store.fetch_historical_feature_values
  name: fetch_historical_feature_values
  file_path: env/lib/python3.13/site-packages/vertexai/resources/preview/feature_store/offline_store.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Fetch historical data at the timestamp specified for each entity.\n\nThis runs a Point-In-Time Lookup (PITL) query in BigQuery across all\nfeatures and returns the historical feature values. Feature data will be\njoined by matching their entity_id_column(s) with corresponding columns in\nthe entity data frame.\n\nArgs:\n  entity_df:\n    An entity DataFrame where one/multiple columns have entity ID.\n    One column should have a timestamp (used for feature lookup). Other\n    columns may have feature data. Entity IDs may be repeated with\n    different timestamp values (in the timestamp column) to lookup data for\n    entities at different points in time.\n  features:\n    Feature data will be joined with the entity data frame.\n     * If `str` is given use `project.feature_group.feature` as the format.\n      `project_id.feature_group_id.feature_id` may be used if features are\n      in another project.\n     * If `FeatureView` is given, the *sources* of the FeatureView will\
    \ be\n       used - but data will be read from the backing BigQuery table.\n  feature_age_threshold:\n    How far back from the timestamp to look for features values. If no\n    feature values are found, empty/null value will be populated.\n  dry_run:\n    Build the Point-In-Time Lookup (PITL) query but don't run it. The PITL\n    query will be printed to stdout.\n  project:\n    The project to use for feature lookup and running the Point-In-Time\n    Lookup (PITL) query in BigQuery. If unset, the project set in\n    aiplatform.init will be used.\n  location:\n    The location to use for feature lookup and running the Point-In-Time\n    Lookup (PITL) query in BigQuery. If unset, the project set in\n    aiplatform.init will be used.\n  credentials:\n    Custom credentials to use for feature lookup and running the\n    Point-In-Time Lookup (PITL) query in BigQuery. Overrides credentials\n    set in aiplatform.init.\n\nReturns:\n  A `bigframes.pandas.DataFrame` with the historical feature\
    \ values. `None`\n  if in `dry_run` mode."
  signature: 'def fetch_historical_feature_values(entity_df: bigframes.pandas.DataFrame, features: typing.List[typing.Union[str, vertexai.resources.preview.feature_store.Feature]], feature_age_threshold: typing.Optional[datetime.timedelta], dry_run: bool, project: typing.Optional[str], location: typing.Optional[str], credentials: typing.Optional[google.auth.credentials.Credentials]) -> typing.Union[bigframes.pandas.DataFrame, None]:'
- rank: 3158
  id: vertexai.resources.preview.feature_store.utils
  name: utils
  file_path: env/lib/python3.13/site-packages/vertexai/resources/preview/feature_store/utils.py
  type: MODULE
  group: Orphan
  usage_score: 0
  methods:
  - signature: 'def get_feature_online_store_name(online_store_name: str) -> str:'
    docstring: "Extract Feature Online Store's name from FeatureView's full resource name.\n\nArgs:\n    online_store_name: Full resource name is projects/project_number/\n      locations/us-central1/featureOnlineStores/fos_name/featureViews/fv_name\n\nReturns:\n    str: feature online store name."
- rank: 3159
  id: vertexai.resources.preview.feature_store.utils.AlgorithmConfig
  name: AlgorithmConfig
  file_path: env/lib/python3.13/site-packages/vertexai/resources/preview/feature_store/utils.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Base class for configuration options for matching algorithm.


    [Note: Inherited members from abc.ABC are omitted.]'
  methods:
  - signature: 'def as_dict(self) -> typing.Dict:'
    docstring: "Returns the configuration as a dictionary.\n\nReturns:\n    Dict[str, Any]"
  omitted_inherited_members_from:
  - abc.ABC
- rank: 3160
  id: vertexai.resources.preview.feature_store.utils.AlgorithmConfig.as_dict
  name: as_dict
  file_path: env/lib/python3.13/site-packages/vertexai/resources/preview/feature_store/utils.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Returns the configuration as a dictionary.\n\nReturns:\n    Dict[str, Any]"
  signature: 'def as_dict(self) -> typing.Dict:'
- rank: 3161
  id: vertexai.resources.preview.feature_store.utils.BruteForceConfig
  name: BruteForceConfig
  file_path: env/lib/python3.13/site-packages/vertexai/resources/preview/feature_store/utils.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Configuration options for using brute force search.


    It simply implements the standard linear search in the database for each

    query.


    [Note: Inherited members from abc.ABC are omitted.]'
  methods:
  - signature: 'def as_dict(self) -> typing.Dict[str, typing.Any]:'
  inherited_methods:
    AlgorithmConfig:
    - signature: 'def as_dict(self) -> typing.Dict:'
      docstring: "Returns the configuration as a dictionary.\n\nReturns:\n    Dict[str, Any]"
  omitted_inherited_members_from:
  - abc.ABC
- rank: 3162
  id: vertexai.resources.preview.feature_store.utils.ConnectionOptions
  name: ConnectionOptions
  file_path: env/lib/python3.13/site-packages/vertexai/resources/preview/feature_store/utils.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: Represents connection options used for sending RPCs to the online store.
  constructor_signature: 'def __init__(self, *, host: str, transport: typing.Union[InsecureGrpcChannel]):'
  properties:
  - signature: 'host: str'
  - signature: 'transport: typing.Union[InsecureGrpcChannel]'
- rank: 3163
  id: vertexai.resources.preview.feature_store.utils.DistanceMeasureType
  name: DistanceMeasureType
  file_path: env/lib/python3.13/site-packages/vertexai/resources/preview/feature_store/utils.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'The distance measure used in nearest neighbor search.


    [Note: Inherited members from enum.Enum are omitted.]'
  properties:
  - signature: 'DISTANCE_MEASURE_TYPE_UNSPECIFIED: int'
  - signature: 'SQUARED_L2_DISTANCE: int'
  - signature: 'COSINE_DISTANCE: int'
  - signature: 'DOT_PRODUCT_DISTANCE: int'
  omitted_inherited_members_from:
  - enum.Enum
- rank: 3164
  id: vertexai.resources.preview.feature_store.utils.FeatureGroupBigQuerySource
  name: FeatureGroupBigQuerySource
  file_path: env/lib/python3.13/site-packages/vertexai/resources/preview/feature_store/utils.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: BigQuery source for the Feature Group.
  constructor_signature: 'def __init__(self, *, uri: str, entity_id_columns: typing.Optional[typing.List[str]] = None):'
  properties:
  - signature: 'uri: str'
  - signature: 'entity_id_columns: typing.Optional[typing.List[str]]'
- rank: 3165
  id: vertexai.resources.preview.feature_store.utils.FeatureViewBigQuerySource
  name: FeatureViewBigQuerySource
  file_path: env/lib/python3.13/site-packages/vertexai/resources/preview/feature_store/utils.py
  type: CLASS
  group: Orphan
  usage_score: 0
  constructor_signature: 'def __init__(self, *, uri: str, entity_id_columns: typing.List[str]):'
  properties:
  - signature: 'uri: str'
  - signature: 'entity_id_columns: typing.List[str]'
- rank: 3166
  id: vertexai.resources.preview.feature_store.utils.FeatureViewReadResponse
  name: FeatureViewReadResponse
  file_path: env/lib/python3.13/site-packages/vertexai/resources/preview/feature_store/utils.py
  type: CLASS
  group: Orphan
  usage_score: 0
  constructor_signature: 'def __init__(self, response: google.cloud.aiplatform.compat.types.feature_online_store_service.FetchFeatureValuesResponse):'
  methods:
  - signature: 'def to_dict(self) -> typing.Dict[str, typing.Any]:'
  - signature: 'def to_proto(self) -> google.cloud.aiplatform.compat.types.feature_online_store_service.FetchFeatureValuesResponse:'
- rank: 3167
  id: vertexai.resources.preview.feature_store.utils.FeatureViewRegistrySource
  name: FeatureViewRegistrySource
  file_path: env/lib/python3.13/site-packages/vertexai/resources/preview/feature_store/utils.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: "Configuration options for Feature View being registered with Feature Registry features.\n\nAttributes:\n    features : Use `<feature_group_id>.<feature_id>` as\n      the format for each feature.\n    project_number : Optional. The project number of the project that owns the\n      Feature Registry if in a different project."
  constructor_signature: 'def __init__(self, *, features: typing.List[str], project_number: typing.Optional[int] = None):'
  properties:
  - signature: 'features: typing.List[str]'
  - signature: 'project_number: typing.Optional[int]'
- rank: 3168
  id: vertexai.resources.preview.feature_store.utils.FeatureViewVertexRagSource
  name: FeatureViewVertexRagSource
  file_path: env/lib/python3.13/site-packages/vertexai/resources/preview/feature_store/utils.py
  type: CLASS
  group: Orphan
  usage_score: 0
  constructor_signature: 'def __init__(self, *, uri: str, rag_corpus_id: typing.Optional[str] = None):'
  properties:
  - signature: 'uri: str'
  - signature: 'rag_corpus_id: typing.Optional[str]'
- rank: 3169
  id: vertexai.resources.preview.feature_store.utils.IndexConfig
  name: IndexConfig
  file_path: env/lib/python3.13/site-packages/vertexai/resources/preview/feature_store/utils.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: Configuration options for the Vertex FeatureView for embedding.
  constructor_signature: 'def __init__(self, *, embedding_column: str, dimensions: int, algorithm_config: vertexai.resources.preview.feature_store.utils.AlgorithmConfig = Factory(TreeAhConfig()), filter_columns: typing.Optional[typing.List[str]] = None, crowding_column: typing.Optional[str] = None, distance_measure_type: typing.Optional[vertexai.resources.preview.feature_store.utils.DistanceMeasureType] = None):'
  methods:
  - signature: 'def as_dict(self) -> typing.Dict[str, typing.Any]:'
    docstring: "Returns the configuration as a dictionary.\n\nReturns:\n    Dict[str, Any]"
  properties:
  - signature: 'embedding_column: str'
  - signature: 'dimensions: int'
  - signature: 'algorithm_config: vertexai.resources.preview.feature_store.utils.AlgorithmConfig'
  - signature: 'filter_columns: typing.Optional[typing.List[str]]'
  - signature: 'crowding_column: typing.Optional[str]'
  - signature: 'distance_measure_type: typing.Optional[vertexai.resources.preview.feature_store.utils.DistanceMeasureType]'
- rank: 3170
  id: vertexai.resources.preview.feature_store.utils.IndexConfig.as_dict
  name: as_dict
  file_path: env/lib/python3.13/site-packages/vertexai/resources/preview/feature_store/utils.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Returns the configuration as a dictionary.\n\nReturns:\n    Dict[str, Any]"
  signature: 'def as_dict(self) -> typing.Dict[str, typing.Any]:'
- rank: 3171
  id: vertexai.resources.preview.feature_store.utils.InsecureGrpcChannel
  name: InsecureGrpcChannel
  file_path: env/lib/python3.13/site-packages/vertexai/resources/preview/feature_store/utils.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: Use an insecure gRPC channel to connect to the host.
- rank: 3172
  id: vertexai.resources.preview.feature_store.utils.PublicEndpointNotFoundError
  name: PublicEndpointNotFoundError
  file_path: env/lib/python3.13/site-packages/vertexai/resources/preview/feature_store/utils.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: 'Public endpoint has not been created yet.


    [Note: Inherited members from RuntimeError are omitted.]'
  omitted_inherited_members_from:
  - RuntimeError
- rank: 3173
  id: vertexai.resources.preview.feature_store.utils.SearchNearestEntitiesResponse
  name: SearchNearestEntitiesResponse
  file_path: env/lib/python3.13/site-packages/vertexai/resources/preview/feature_store/utils.py
  type: CLASS
  group: Orphan
  usage_score: 0
  constructor_signature: 'def __init__(self, response: google.cloud.aiplatform.compat.types.feature_online_store_service.SearchNearestEntitiesResponse):'
  methods:
  - signature: 'def to_dict(self) -> typing.Dict[str, typing.Any]:'
  - signature: 'def to_proto(self) -> google.cloud.aiplatform.compat.types.feature_online_store_service.SearchNearestEntitiesResponse:'
- rank: 3174
  id: vertexai.resources.preview.feature_store.utils.TreeAhConfig
  name: TreeAhConfig
  file_path: env/lib/python3.13/site-packages/vertexai/resources/preview/feature_store/utils.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: "Configuration options for using the tree-AH algorithm (Shallow tree + Asymmetric Hashing).\n\nPlease refer to this paper for more details: https://arxiv.org/abs/1908.10396\n\nArgs:\n    leaf_node_embedding_count (int): Optional. Number of embeddings on each\n      leaf node. The default value is 1000 if not set.\n\n[Note: Inherited members from abc.ABC are omitted.]"
  constructor_signature: 'def __init__(self, *, leaf_node_embedding_count: typing.Optional[int] = None):'
  methods:
  - signature: 'def as_dict(self) -> typing.Dict:'
  properties:
  - signature: 'leaf_node_embedding_count: typing.Optional[int]'
  inherited_methods:
    AlgorithmConfig:
    - signature: 'def as_dict(self) -> typing.Dict:'
      docstring: "Returns the configuration as a dictionary.\n\nReturns:\n    Dict[str, Any]"
  omitted_inherited_members_from:
  - abc.ABC
- rank: 3175
  id: vertexai.resources.preview.feature_store.utils.get_feature_online_store_name
  name: get_feature_online_store_name
  file_path: env/lib/python3.13/site-packages/vertexai/resources/preview/feature_store/utils.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Extract Feature Online Store's name from FeatureView's full resource name.\n\nArgs:\n    online_store_name: Full resource name is projects/project_number/\n      locations/us-central1/featureOnlineStores/fos_name/featureViews/fv_name\n\nReturns:\n    str: feature online store name."
  signature: 'def get_feature_online_store_name(online_store_name: str) -> str:'
- rank: 3176
  id: vertexai.resources.preview.ml_monitoring
  name: ml_monitoring
  file_path: env/lib/python3.13/site-packages/vertexai/resources/preview/ml_monitoring/__init__.py
  type: MODULE
  group: Orphan
  usage_score: 0
- rank: 3177
  id: vertexai.resources.preview.ml_monitoring.model_monitors
  name: model_monitors
  file_path: env/lib/python3.13/site-packages/vertexai/resources/preview/ml_monitoring/model_monitors.py
  type: MODULE
  group: Orphan
  usage_score: 0
- rank: 3178
  id: vertexai.resources.preview.ml_monitoring.model_monitors.AlertsSearchResponse
  name: AlertsSearchResponse
  file_path: env/lib/python3.13/site-packages/vertexai/resources/preview/ml_monitoring/model_monitors.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: "AlertsSearchResponse represents a response of the search alerts request.\n\nAttributes:\n    next_page_token (str):\n        The page token that can be used by the next call.\n    model_monitoring_alerts (List[model_monitoring_alert.ModelMonitoringAlert]):\n        Alerts retrieved for requested objectives.\n    total_alerts (int):\n        Total number of alerts retrieved for requested objectives."
  constructor_signature: 'def __init__(self, *, next_page_token: str, total_alerts: int, model_monitoring_alerts: typing.List[google.cloud.aiplatform.compat.types.model_monitoring_alert_v1beta1.ModelMonitoringAlert] = list()):'
  methods:
  - signature: 'def raw_search_alerts_response(self) -> google.cloud.aiplatform.compat.types.model_monitoring_service_v1beta1.SearchModelMonitoringAlertsResponse:'
    docstring: Raw search metrics response.
  properties:
  - signature: 'next_page_token: str'
  - signature: 'total_alerts: int'
  - signature: 'model_monitoring_alerts: typing.List[google.cloud.aiplatform.compat.types.model_monitoring_alert_v1beta1.ModelMonitoringAlert]'
- rank: 3179
  id: vertexai.resources.preview.ml_monitoring.model_monitors.AlertsSearchResponse.raw_search_alerts_response
  name: raw_search_alerts_response
  file_path: env/lib/python3.13/site-packages/vertexai/resources/preview/ml_monitoring/model_monitors.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: Raw search metrics response.
  signature: 'def raw_search_alerts_response(self) -> google.cloud.aiplatform.compat.types.model_monitoring_service_v1beta1.SearchModelMonitoringAlertsResponse:'
- rank: 3180
  id: vertexai.resources.preview.ml_monitoring.model_monitors.ListJobsResponse
  name: ListJobsResponse
  file_path: env/lib/python3.13/site-packages/vertexai/resources/preview/ml_monitoring/model_monitors.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: "ListJobsResponse represents a response of the list jobs request.\n\nAttributes:\n    list_jobs (List[model_monitoring_job.ModelMonitoringJob]):\n        Jobs retrieved for request.\n    next_page_token (str):\n        The page token that can be used by the next call."
  constructor_signature: 'def __init__(self, *, next_page_token: str, list_jobs: typing.List[google.cloud.aiplatform.compat.types.model_monitoring_job_v1beta1.ModelMonitoringJob] = list()):'
  methods:
  - signature: 'def raw_list_jobs_response(self) -> google.cloud.aiplatform.compat.types.model_monitoring_service_v1beta1.ListModelMonitoringJobsResponse:'
    docstring: Raw list jobs response.
  properties:
  - signature: 'next_page_token: str'
  - signature: 'list_jobs: typing.List[google.cloud.aiplatform.compat.types.model_monitoring_job_v1beta1.ModelMonitoringJob]'
- rank: 3181
  id: vertexai.resources.preview.ml_monitoring.model_monitors.ListJobsResponse.raw_list_jobs_response
  name: raw_list_jobs_response
  file_path: env/lib/python3.13/site-packages/vertexai/resources/preview/ml_monitoring/model_monitors.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: Raw list jobs response.
  signature: 'def raw_list_jobs_response(self) -> google.cloud.aiplatform.compat.types.model_monitoring_service_v1beta1.ListModelMonitoringJobsResponse:'
- rank: 3182
  id: vertexai.resources.preview.ml_monitoring.model_monitors.ListSchedulesResponse
  name: ListSchedulesResponse
  file_path: env/lib/python3.13/site-packages/vertexai/resources/preview/ml_monitoring/model_monitors.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: "ListSchedulesResponse represents a response of the list jobs request.\n\nAttributes:\n    list_schedules (List[schedule.Schedule]):\n        Jobs retrieved for request.\n    next_page_token (str):\n        The page token that can be used by the next call."
  constructor_signature: 'def __init__(self, *, next_page_token: str, list_schedules: typing.List[google.cloud.aiplatform.compat.types.schedule_v1beta1.Schedule] = list()):'
  methods:
  - signature: 'def raw_list_schedules_response(self) -> google.cloud.aiplatform.compat.types.schedule_service_v1beta1.ListSchedulesResponse:'
    docstring: Raw list jobs response.
  properties:
  - signature: 'next_page_token: str'
  - signature: 'list_schedules: typing.List[google.cloud.aiplatform.compat.types.schedule_v1beta1.Schedule]'
- rank: 3183
  id: vertexai.resources.preview.ml_monitoring.model_monitors.MetricsSearchResponse
  name: MetricsSearchResponse
  file_path: env/lib/python3.13/site-packages/vertexai/resources/preview/ml_monitoring/model_monitors.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: "MetricsSearchResponse represents a response of the search metrics request.\n\nAttributes:\n    monitoring_stats (List[model_monitoring_stats.ModelMonitoringStats]):\n        Stats retrieved for requested objectives.\n    next_page_token (str):\n        The page token that can be used by the next call."
  constructor_signature: 'def __init__(self, *, next_page_token: str, monitoring_stats: typing.List[google.cloud.aiplatform.compat.types.model_monitoring_stats_v1beta1.ModelMonitoringStats] = list()):'
  methods:
  - signature: 'def raw_search_metrics_response(self) -> google.cloud.aiplatform.compat.types.model_monitoring_service_v1beta1.SearchModelMonitoringStatsResponse:'
    docstring: Raw search metrics response.
  properties:
  - signature: 'next_page_token: str'
  - signature: 'monitoring_stats: typing.List[google.cloud.aiplatform.compat.types.model_monitoring_stats_v1beta1.ModelMonitoringStats]'
- rank: 3184
  id: vertexai.resources.preview.ml_monitoring.model_monitors.MetricsSearchResponse.raw_search_metrics_response
  name: raw_search_metrics_response
  file_path: env/lib/python3.13/site-packages/vertexai/resources/preview/ml_monitoring/model_monitors.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: Raw search metrics response.
  signature: 'def raw_search_metrics_response(self) -> google.cloud.aiplatform.compat.types.model_monitoring_service_v1beta1.SearchModelMonitoringStatsResponse:'
- rank: 3185
  id: vertexai.resources.preview.ml_monitoring.model_monitors.ModelMonitor
  name: ModelMonitor
  file_path: env/lib/python3.13/site-packages/vertexai/resources/preview/ml_monitoring/model_monitors.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: "Initializer for ModelMonitor.\n\nArgs:\n    model_monitor_name (str):\n        Required. A fully-qualified model monitor resource name or model\n        monitor ID.\n        Example: \"projects/123/locations/us-central1/modelMonitors/456\" or\n        \"456\" when project and location are initialized or passed.\n    project (str):\n        Required. Project to retrieve model monitor from. If not set,\n        project set in aiplatform.init will be used.\n    location (str):\n        Required. Location to retrieve model monitor from. If not set,\n        location set in aiplatform.init will be used.\n    credentials (auth_credentials.Credentials):\n        Optional. Custom credentials to use to retrieve this model monitor.\n        Overrides credentials set in aiplatform.init.\n\n[Note: Inherited members from base.VertexAiResourceNounWithFutureManager are omitted.]"
  constructor_signature: 'def __init__(self, model_monitor_name: str, project: typing.Optional[str], location: typing.Optional[str], credentials: typing.Optional[google.auth.credentials.Credentials]):'
  methods:
  - signature: 'def create(cls, model_name: str, model_version_id: str, training_dataset: typing.Optional[vertexai.resources.preview.ml_monitoring.spec.objective.MonitoringInput], display_name: typing.Optional[str], model_monitoring_schema: typing.Optional[vertexai.resources.preview.ml_monitoring.spec.schema.ModelMonitoringSchema], tabular_objective_spec: typing.Optional[vertexai.resources.preview.ml_monitoring.spec.objective.TabularObjective], output_spec: typing.Optional[vertexai.resources.preview.ml_monitoring.spec.output.OutputSpec], notification_spec: typing.Optional[vertexai.resources.preview.ml_monitoring.spec.notification.NotificationSpec], explanation_spec: typing.Optional[google.cloud.aiplatform.compat.types.explanation_v1beta1.ExplanationSpec], project: typing.Optional[str], location: typing.Optional[str], credentials: typing.Optional[google.auth.credentials.Credentials], model_monitor_id: typing.Optional[str]) -> vertexai.resources.preview.ml_monitoring.model_monitors.ModelMonitor:'
    docstring: "Creates a new ModelMonitor.\n\nArgs:\n    model_name (str):\n        Required. A model resource name as model monitoring target.\n        Format: ``projects/{project}/locations/{location}/models/{model}``\n    model_version_id (str):\n        Required. Model version id.\n    training_dataset (objective.MonitoringInput):\n        Optional. Training dataset used to train the model. It can serve\n        as a baseline dataset to identify changes in production.\n    display_name (str):\n        Optional. The user-defined name of the ModelMonitor.\n        The name can be up to 128 characters long and can comprise any\n        UTF-8 character.\n        Display name of the ModelMonitor.\n    model_monitoring_schema (schema.ModelMonitoringSchema):\n        Required for most models, but optional for Vertex AI AutoML\n        Tables unless the schema information is not available.\n        The Monitoring Schema specifies the model's features, prediction\n        outputs and ground\
      \ truth properties. It is used to extract\n        pertinent data from the dataset and to process features based on\n        their properties. Make sure that the schema aligns with your\n        dataset, if it does not, Vertex AI will be unable to extract\n        data form the dataset.\n    tabular_objective_spec (objective.TabularObjective):\n        Optional. The default tabular monitoring objective spec for\n        the model monitor. It can be overriden in the ModelMonitoringJob\n        objective spec.\n    output_spec (output.OutputSpec):\n        Optional. The default monitoring metrics/logs export spec, it\n        can be overriden in the ModelMonitoringJob output spec.\n        If not specified, a default Google Cloud Storage bucket will be\n        created under your project.\n    notification_spec (notification.NotificationSpec):\n        Optional. The default notification spec for monitoring result.\n        It can be overriden in the ModelMonitoringJob notification spec.\n\
      \    explanation_spec (explanation.ExplanationSpec):\n        Optional. The default explanation spec for feature attribution\n        monitoring. It can be overriden in the ModelMonitoringJob\n        explanation spec.\n    project (str):\n        Optional. Project to retrieve model monitor from. If not set,\n        project set in aiplatform.init will be used.\n    location (str):\n        Optional. Location to retrieve model monitor from. If not set,\n        location set in aiplatform.init will be used.\n    credentials (auth_credentials.Credentials):\n        Optional. Custom credentials to use to create this model monitor.\n        Overrides credentials set in aiplatform.init.\n    model_monitor_id (str):\n        Optional. The unique ID of the model monitor, which will become\n        the final component of the model monitor resource name.\n        If not specified, it will be generated by Vertex AI.\n\nReturns:\n    ModelMonitor: The model monitor that was created."
  - signature: 'def update(self, display_name: typing.Optional[str], training_dataset: typing.Optional[vertexai.resources.preview.ml_monitoring.spec.objective.MonitoringInput], model_monitoring_schema: typing.Optional[vertexai.resources.preview.ml_monitoring.spec.schema.ModelMonitoringSchema], tabular_objective_spec: typing.Optional[vertexai.resources.preview.ml_monitoring.spec.objective.TabularObjective], output_spec: typing.Optional[vertexai.resources.preview.ml_monitoring.spec.output.OutputSpec], notification_spec: typing.Optional[vertexai.resources.preview.ml_monitoring.spec.notification.NotificationSpec], explanation_spec: typing.Optional[google.cloud.aiplatform.compat.types.explanation_v1beta1.ExplanationSpec]) -> vertexai.resources.preview.ml_monitoring.model_monitors.ModelMonitor:'
    docstring: "Updates an existing ModelMonitor.\n\nArgs:\n    display_name (str):\n        Optional. The user-defined name of the ModelMonitor.\n        The name can be up to 128 characters long and can comprise any\n        UTF-8 character.\n        Display name of the ModelMonitor.\n    training_dataset (objective.MonitoringInput):\n        Optional. Training dataset used to train the model. It can serve\n        as a baseline dataset to identify changes in production.\n    model_monitoring_schema (schema.ModelMonitoringSchema):\n        Optional. The Monitoring Schema specifies the model's features,\n        prediction outputs and ground truth properties. It is used to\n        extract pertinent data from the dataset and to process features\n        based on their properties. Make sure that the schema aligns with\n        your dataset, if it does not, Vertex AI will be unable to\n        extract data form the dataset.\n    tabular_objective_spec (objective.TabularObjective):\n     \
      \   Optional. The default tabular monitoring objective spec for\n        the model monitor. It can be overriden in the ModelMonitoringJob\n        objective spec.\n    output_spec (output.OutputSpec):\n        Optional. The default monitoring metrics/logs export spec, it\n        can be overriden in the ModelMonitoringJob output spec.\n    notification_spec (notification.NotificationSpec):\n        Optional. The default notification spec for monitoring result.\n        It can be overriden in the ModelMonitoringJob notification spec.\n    explanation_spec (explanation.ExplanationSpec):\n        Optional. The default explanation spec for feature attribution\n        monitoring. It can be overriden in the ModelMonitoringJob\n        explanation spec.\n\nReturns:\n    ModelMonitor: The updated model monitor."
  - signature: 'def delete(self, force: bool, sync: bool) -> None:'
    docstring: "Force delete the model monitor.\n\nArgs:\n    force (bool):\n        Required. If force is set to True, all schedules on this\n        ModelMonitor will be deleted first. Default is False.\n    sync (bool):\n        Whether to execute this method synchronously. If False, this method\n        will be executed in concurrent Future and any downstream object will\n        be immediately returned and synced when the Future has completed.\n        Default is True."
  - signature: 'def create_schedule(self, cron: str, target_dataset: vertexai.resources.preview.ml_monitoring.spec.objective.MonitoringInput, display_name: typing.Optional[str], model_monitoring_job_display_name: typing.Optional[str], start_time: typing.Optional[google.protobuf.timestamp_pb2.Timestamp], end_time: typing.Optional[google.protobuf.timestamp_pb2.Timestamp], tabular_objective_spec: typing.Optional[vertexai.resources.preview.ml_monitoring.spec.objective.TabularObjective], baseline_dataset: typing.Optional[vertexai.resources.preview.ml_monitoring.spec.objective.MonitoringInput], output_spec: typing.Optional[vertexai.resources.preview.ml_monitoring.spec.output.OutputSpec], notification_spec: typing.Optional[vertexai.resources.preview.ml_monitoring.spec.notification.NotificationSpec], explanation_spec: typing.Optional[google.cloud.aiplatform.compat.types.explanation_v1beta1.ExplanationSpec]) -> google.cloud.aiplatform.compat.types.schedule_v1beta1.Schedule:'
    docstring: "Creates a new Scheduled run for model monitoring job.\n\nArgs:\n    cron (str):\n        Required. Cron schedule (https://en.wikipedia.org/wiki/Cron) to\n        launch scheduled runs. To explicitly set a timezone to the cron\n        tab, apply a prefix in the cron tab: \"CRON_TZ=${IANA_TIME_ZONE}\"\n        or \"TZ=${IANA_TIME_ZONE}\". The ${IANA_TIME_ZONE} may only be a\n        valid string from IANA time zone database. For example,\n        \"CRON_TZ=America/New_York 1 * * * *\", or\n        \"TZ=America/New_York 1 * * * *\".\n    target_dataset (objective.MonitoringInput):\n        Required. The target dataset for analysis.\n    display_name (str):\n        Optional. The user-defined name of the Schedule.\n        The name can be up to 128 characters long and can be consist of\n        any UTF-8 characters.\n        Display name of the Schedule.\n    model_monitoring_job_display_name (str):\n        Optional. The user-defined name of the ModelMonitoringJob.\n      \
      \  The name can be up to 128 characters long and can be consist of\n        any UTF-8 characters.\n        Display name of the ModelMonitoringJob.\n    start_time (timestamp_pb2.Timestamp):\n        Optional. Timestamp after which the first run can be scheduled.\n        Default to Schedule create time if not specified.\n    end_time (timestamp_pb2.Timestamp):\n        Optional. Timestamp after which no new runs can be scheduled.\n        If specified, The schedule will be completed when the end_time\n        is reached.\n        If not specified, new runs will keep getting scheduled until\n        this Schedule is paused or deleted. Already scheduled runs will\n        be allowed to complete. Unset if not specified.\n    tabular_objective_spec (objective.TabularObjective):\n        Optional. The tabular monitoring objective spec. If not set,\n        the default tabular objective spec in ModelMonitor will be\n        used. You must either set here or set the default one in the\n \
      \       ModelMonitor.\n    baseline_dataset (objective.MonitoringInput):\n        Optional. The baseline dataset for monitoring job.\n        If not set, the training dataset in ModelMonitor will be\n        used as baseline dataset.\n    output_spec (output.OutputSpec):\n        Optional. The monitoring metrics/logs export spec.\n        If not set, will use the default output_spec defined in\n        ModelMonitor.\n    notification_spec (notification.NotificationSpec):\n        Optional. The notification spec for monitoring result.\n        If not set, will use the default notification_spec defined in\n        ModelMonitor.\n    explanation_spec (explanation.ExplanationSpec):\n        Optional. The explanation spec for feature attribution\n        monitoring.\n        If not set, will use the default explanation_spec defined in\n        ModelMonitor.\n\nReturns:\n    Schedule: The created schedule."
  - signature: 'def update_schedule(self, schedule_name: str, display_name: typing.Optional[str], model_monitoring_job_display_name: typing.Optional[str], cron: typing.Optional[str], baseline_dataset: typing.Optional[vertexai.resources.preview.ml_monitoring.spec.objective.MonitoringInput], target_dataset: typing.Optional[vertexai.resources.preview.ml_monitoring.spec.objective.MonitoringInput], tabular_objective_spec: typing.Optional[vertexai.resources.preview.ml_monitoring.spec.objective.TabularObjective], output_spec: typing.Optional[vertexai.resources.preview.ml_monitoring.spec.output.OutputSpec], notification_spec: typing.Optional[vertexai.resources.preview.ml_monitoring.spec.notification.NotificationSpec], explanation_spec: typing.Optional[google.cloud.aiplatform.compat.types.explanation_v1beta1.ExplanationSpec], end_time: typing.Optional[google.protobuf.timestamp_pb2.Timestamp]) -> google.cloud.aiplatform.compat.types.schedule_v1beta1.Schedule:'
    docstring: "Updates an existing Schedule.\n\nArgs:\n    schedule_name (str):\n        Required. The resource name of schedule that needs to be updated.\n        Format: ``projects/{project}/locations/{location}/schedules/{schedule}``\n        or\n        ``{schedule}``\n    display_name (str):\n        Optional. The user-defined name of the Schedule.\n        The name can be up to 128 characters long and can be consist of\n        any UTF-8 characters.\n        Display name of the Schedule.\n    model_monitoring_job_display_name (str):\n        Optional. The user-defined display name of the ModelMonitoringJob\n        that needs to be updated.\n    cron (str):\n        Optional. Cron schedule (https://en.wikipedia.org/wiki/Cron) to\n        launch scheduled runs. To explicitly set a timezone to the cron\n        tab, apply a prefix in the cron tab: \"CRON_TZ=${IANA_TIME_ZONE}\"\n        or \"TZ=${IANA_TIME_ZONE}\". The ${IANA_TIME_ZONE} may only be a\n        valid string from IANA time\
      \ zone database. For example,\n        \"CRON_TZ=America/New_York 1 * * * *\", or\n        \"TZ=America/New_York 1 * * * *\".\n    baseline_dataset (objective.MonitoringInput):\n        Optional. The baseline dataset for monitoring job.\n    target_dataset (objective.MonitoringInput):\n        Optional. The target dataset for analysis.\n    tabular_objective_spec (objective.TabularObjective):\n        Optional. The tabular monitoring objective spec.\n    output_spec (output.OutputSpec):\n        Optional. The monitoring metrics/logs export spec.\n    notification_spec (notification.NotificationSpec):\n        Optional. The notification spec for monitoring result.\n    explanation_spec (explanation.ExplanationSpec):\n        Optional. The explanation spec for feature attribution\n        monitoring.\n    end_time (timestamp_pb2.Timestamp):\n        Optional. Timestamp after which no new runs can be scheduled.\n\nReturns:\n    Schedule: The updated schedule."
  - signature: 'def delete_schedule(self, schedule_name: str) -> None:'
    docstring: "Deletes an existing Schedule.\n\nArgs:\n    schedule_name (str):\n        Required. The resource name of schedule that needs to be deleted.\n        Format: ``projects/{project}/locations/{location}/schedules/{schedule}``\n        or\n        ``{schedule}``"
  - signature: 'def pause_schedule(self, schedule_name: str) -> None:'
    docstring: "Pauses an existing Schedule.\n\nArgs:\n    schedule_name (str):\n        Required. The resource name of schedule that needs to be paused.\n        Format: ``projects/{project}/locations/{location}/schedules/{schedule}``\n        or\n        ``{schedule}``"
  - signature: 'def resume_schedule(self, schedule_name: str) -> None:'
    docstring: "Resumes an existing Schedule.\n\nArgs:\n    schedule_name (str):\n        Required. The resource name of schedule that needs to be resumed.\n        Format: ``projects/{project}/locations/{location}/schedules/{schedule}``\n        or\n        ``{schedule}``"
  - signature: 'def get_schedule(self, schedule_name: str) -> google.cloud.aiplatform.compat.types.schedule_v1beta1.Schedule:'
    docstring: "Gets an existing Schedule.\n\nArgs:\n    schedule_name (str):\n        Required. The resource name of schedule that needs to be fetched.\n        Format: ``projects/{project}/locations/{location}/schedules/{schedule}``\n        or\n        ``{schedule}``\n\nReturns:\n    Schedule: The schedule requested."
  - signature: 'def list_schedules(self, filter: typing.Optional[str], page_size: typing.Optional[int], page_token: typing.Optional[str]) -> vertexai.resources.preview.ml_monitoring.model_monitors.ListSchedulesResponse.list_schedules:'
    docstring: "List Schedules.\n\nArgs:\n    filter (str):\n        Optional. Lists the Schedules that match the filter expression.\n        The\n        following fields are supported:\n\n        -  ``display_name``: Supports ``=``, ``!=`` comparisons, and\n           ``:`` wildcard.\n        -  ``state``: Supports ``=`` and ``!=`` comparisons.\n        -  ``request``: Supports existence of the <request_type>\n           check. (e.g. ``create_pipeline_job_request:*`` -->\n           Schedule has create_pipeline_job_request).\n        -  ``create_time``: Supports ``=``, ``!=``, ``<``, ``>``,\n           ``<=``, and ``>=`` comparisons. Values must be in RFC\n           3339 format.\n        -  ``start_time``: Supports ``=``, ``!=``, ``<``, ``>``,\n           ``<=``, and ``>=`` comparisons. Values must be in RFC\n           3339 format.\n        -  ``end_time``: Supports ``=``, ``!=``, ``<``, ``>``,\n           ``<=``, ``>=`` comparisons and ``:*`` existence check.\n           Values must\
      \ be in RFC 3339 format.\n        -  ``next_run_time``: Supports ``=``, ``!=``, ``<``, ``>``,\n           ``<=``, and ``>=`` comparisons. Values must be in RFC\n           3339 format.\n\n        Filter expressions can be combined together using logical\n        operators (``NOT``, ``AND`` & ``OR``). The syntax to define\n        filter expression is based on https://google.aip.dev/160.\n    page_size (int):\n        Optional. The standard page list size.\n    page_token (str):\n        Optional. A page token received from a previous call.\n\nReturns:\n    MetricsSearchResponse: The model monitoring stats results."
  - signature: 'def run(self, target_dataset: vertexai.resources.preview.ml_monitoring.spec.objective.MonitoringInput, display_name: typing.Optional[str], model_monitoring_job_id: typing.Optional[str], sync: typing.Optional[bool], tabular_objective_spec: typing.Optional[vertexai.resources.preview.ml_monitoring.spec.objective.TabularObjective], baseline_dataset: typing.Optional[vertexai.resources.preview.ml_monitoring.spec.objective.MonitoringInput], output_spec: typing.Optional[vertexai.resources.preview.ml_monitoring.spec.output.OutputSpec], notification_spec: typing.Optional[vertexai.resources.preview.ml_monitoring.spec.notification.NotificationSpec], explanation_spec: typing.Optional[google.cloud.aiplatform.compat.types.explanation_v1beta1.ExplanationSpec]) -> vertexai.resources.preview.ml_monitoring.model_monitors.ModelMonitoringJob:'
    docstring: "Creates a new ModelMonitoringJob.\n\nArgs:\n    target_dataset (objective.MonitoringInput):\n        Required. The target dataset for analysis.\n    display_name (str):\n        Optional. The user-defined name of the ModelMonitoringJob.\n        The name can be up to 128 characters long and can comprise any\n        UTF-8 character.\n        Display name of the ModelMonitoringJob.\n    model_monitoring_job_id (str):\n        Optional. The unique ID of the model monitoring job run, which\n        will become the final component of the model monitoring job\n        resource name. The maximum length is 63 characters, and valid\n        characters are /^[a-z]([a-z0-9-]{0,61}[a-z0-9])?$/.\n        If not specified, it will be generated by Vertex AI.\n    sync (bool):\n        Whether to execute this method synchronously. If False, this\n        method will be executed in concurrent Future and any downstream\n        object will be immediately returned and synced when the Future\n\
      \        has completed. Default is False.\n    tabular_objective_spec (objective.TabularObjective):\n        Optional. The tabular monitoring objective spec for the model\n        monitoring job.\n    baseline_dataset (objective.MonitoringInput):\n        Optional. The baseline dataset for monitoring job.\n        If not set, the training dataset in ModelMonitor will be\n        used as baseline dataset.\n    output_spec (output.OutputSpec):\n        Optional. The monitoring metrics/logs export spec.\n        If not set, will use the default output_spec defined in\n        ModelMonitor.\n    notification_spec (notification.NotificationSpec):\n        Optional. The notification spec for monitoring result.\n        If not set, will use the default notification_spec defined in\n        ModelMonitor.\n    explanation_config (explanation.ExplanationSpec):\n        Optional. The explanation spec for feature attribution\n        monitoring.\n        If not set, will use the default explanation_spec\
      \ defined in\n        ModelMonitor.\n\nReturns:\n    ModelMonitoringJob: The model monitoring job that was created."
  - signature: 'def search_metrics(self, stats_name: typing.Optional[str], objective_type: typing.Optional[str], model_monitoring_job_name: typing.Optional[str], schedule_name: typing.Optional[str], algorithm: typing.Optional[str], start_time: typing.Optional[google.protobuf.timestamp_pb2.Timestamp], end_time: typing.Optional[google.protobuf.timestamp_pb2.Timestamp], page_size: typing.Optional[int], page_token: typing.Optional[str]) -> vertexai.resources.preview.ml_monitoring.model_monitors.MetricsSearchResponse.monitoring_stats:'
    docstring: "Search ModelMonitoringStats.\n\nArgs:\n    stats_name (str):\n        Optional. The stats name filter for the search, if not set, all\n        stats will be returned.\n        For tabular model it's the feature name.\n    objective_type (str):\n        Optional. One of the supported monitoring objectives:\n            `raw-feature-drift`\n            `prediction-output-drift`\n            `feature-attribution`\n    model_monitoring_job_name (str):\n        Optional. The resource name of a particular model monitoring\n        job that the user wants to search metrics result from.\n        Format:\n        ``projects/{project}/locations/{location}/modelMonitors/{model_monitor}/modelMonitoringJobs/{model_monitoring_job}``\n    schedule_name (str):\n        Optional. The resource name of a particular model monitoring\n        schedule that the user wants to search metrics result from.\n        Format: ``projects/{project}/locations/{location}/schedules/{schedule}``\n    algorithm\
      \ (str):\n        Optional. The algorithm type filter for the search, eg:\n        jensen_shannon_divergence, l_infinity.\n    start_time (timestamp_pb2.Timestamp):\n        Optional. Inclusive start of the time interval for which results\n        should be returned.\n    end_time (timestamp_pb2.Timestamp):\n        Optional. Exclusive end of the time interval for which results\n        should be returned.\n    page_size (int):\n        Optional. The standard page list size.\n    page_token (str):\n        Optional. A page token received from a previous call.\n\nReturns:\n    MetricsSearchResponse: The model monitoring stats results."
  - signature: 'def search_alerts(self, stats_name: typing.Optional[str], objective_type: typing.Optional[str], model_monitoring_job_name: typing.Optional[str], start_time: typing.Optional[google.protobuf.timestamp_pb2.Timestamp], end_time: typing.Optional[google.protobuf.timestamp_pb2.Timestamp], page_size: typing.Optional[int], page_token: typing.Optional[str]) -> typing.Dict[str, typing.Any]:'
    docstring: "Search ModelMonitoringAlerts.\n\nArgs:\n    stats_name (str):\n        Optional. The stats name filter for the search, if not set, all\n        stats will be returned.\n        For tabular models, provide the name of the feature to return\n        alerts from.\n    objective_type (str):\n        Optional. Return alerts from one of the supported monitoring\n        objectives:\n            `raw-feature-drift`\n            `prediction-output-drift`\n            `feature-attribution`\n    model_monitoring_job_name (str):\n        Optional. The resource name of a particular model monitoring\n        job that the user wants to search metrics result from.\n        Format:\n        ``projects/{project}/locations/{location}/modelMonitors/{model_monitor}/modelMonitoringJobs/{model_monitoring_job}``\n    start_time (timestamp_pb2.Timestamp):\n        Optional. Inclusive start of the time interval for which alerts\n        should be returned.\n    end_time (timestamp_pb2.Timestamp):\n\
      \        Optional. Exclusive end of the time interval for which alerts\n        should be returned.\n    page_size (int):\n        Optional. The standard page list size.\n    page_token (str):\n        Optional. A page token received from a previous call.\n\nReturns:\n    AlertsSearchResponse: The model monitoring alerts results."
  - signature: 'def list_jobs(self, page_size: typing.Optional[int], page_token: typing.Optional[str]) -> vertexai.resources.preview.ml_monitoring.model_monitors.ListJobsResponse.list_jobs:'
    docstring: "List ModelMonitoringJobs.\n\nArgs:\n    page_size (int):\n        Optional. The standard page list size.\n    page_token (str):\n        Optional. A page token received from a previous call.\n\nReturns:\n    ListJobsResponse.list_jobs: The list model monitoring jobs responses."
  - signature: 'def delete_model_monitoring_job(self, model_monitoring_job_name: str) -> None:'
    docstring: "Delete a model monitoring job.\n\nArgs:\n\n    model_monitoring_job_name (str):\n        Required. The resource name of the model monitoring job that\n        needs to be deleted.\n        Format:\n        ``projects/{project}/locations/{location}/modelMonitors/{model_monitor}/modelMonitoringJobs/{model_monitoring_job}``\n        or\n        ``{model_monitoring_job}``"
  - signature: 'def get_model_monitoring_job(self, model_monitoring_job_name: str) -> vertexai.resources.preview.ml_monitoring.model_monitors.ModelMonitoringJob:'
    docstring: "Get the specified ModelMonitoringJob.\n\nArgs:\n    model_monitoring_job_name (str):\n        Required. The resource name of the ModelMonitoringJob that is needed.\n        Format:\n        ``projects/{project}/locations/{location}/modelMonitors/{model_monitor}/modelMonitoringJobs/{model_monitoring_job}``\n        or\n        ``{model_monitoring_job}``\n\nReturns:\n    ModelMonitoringJob: The model monitoring job get."
  - signature: 'def show_feature_drift_stats(self, model_monitoring_job_name: str) -> None:'
    docstring: "The method to visualize the feature drift result from a model monitoring job as a histogram chart and a table.\n\nArgs:\n    model_monitoring_job_name (str):\n        Required. The resource name of model monitoring job to show the\n        drift stats from.\n        Format: ``projects/{project}/locations/{location}/modelMonitors/{model_monitor}/modelMonitoringJobs/{model_monitoring_job}``\n        or\n        ``{model_monitoring_job}``"
  - signature: 'def get_schema(self) -> google.cloud.aiplatform.compat.types.model_monitor_v1beta1.ModelMonitoringSchema:'
    docstring: Get the schema of the model monitor.
  - signature: 'def show_output_drift_stats(self, model_monitoring_job_name: str) -> None:'
    docstring: "The method to visualize the prediction output drift result from a model monitoring job as a histogram chart and a table.\n\nArgs:\n    model_monitoring_job_name (str):\n        Required. The resource name of model monitoring job to show the\n        drift stats from.\n        Format: ``projects/{project}/locations/{location}/modelMonitors/{model_monitor}/modelMonitoringJobs/{model_monitoring_job}``\n        or\n        ``{model_monitoring_job}``"
  - signature: 'def show_feature_attribution_drift_stats(self, model_monitoring_job_name: str) -> None:'
    docstring: "The method to visualize the feature attribution drift result from a model monitoring job as a histogram chart and a table.\n\nArgs:\n    model_monitoring_job_name (str):\n        Required. The resource name of model monitoring job to show the\n        feature attribution drift stats from.\n        Format:\n        ``projects/{project}/locations/{location}/modelMonitors/{model_monitor}/modelMonitoringJobs/{model_monitoring_job}``\n        or\n        ``{model_monitoring_job}``"
  properties:
  - signature: 'client_class: Any'
  omitted_inherited_members_from:
  - base.VertexAiResourceNounWithFutureManager
- rank: 3186
  id: vertexai.resources.preview.ml_monitoring.model_monitors.ModelMonitor.__init__
  name: __init__
  file_path: env/lib/python3.13/site-packages/vertexai/resources/preview/ml_monitoring/model_monitors.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def __init__(self, model_monitor_name: str, project: typing.Optional[str], location: typing.Optional[str], credentials: typing.Optional[google.auth.credentials.Credentials]):'
- rank: 3187
  id: vertexai.resources.preview.ml_monitoring.model_monitors.ModelMonitor.create
  name: create
  file_path: env/lib/python3.13/site-packages/vertexai/resources/preview/ml_monitoring/model_monitors.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Creates a new ModelMonitor.\n\nArgs:\n    model_name (str):\n        Required. A model resource name as model monitoring target.\n        Format: ``projects/{project}/locations/{location}/models/{model}``\n    model_version_id (str):\n        Required. Model version id.\n    training_dataset (objective.MonitoringInput):\n        Optional. Training dataset used to train the model. It can serve\n        as a baseline dataset to identify changes in production.\n    display_name (str):\n        Optional. The user-defined name of the ModelMonitor.\n        The name can be up to 128 characters long and can comprise any\n        UTF-8 character.\n        Display name of the ModelMonitor.\n    model_monitoring_schema (schema.ModelMonitoringSchema):\n        Required for most models, but optional for Vertex AI AutoML\n        Tables unless the schema information is not available.\n        The Monitoring Schema specifies the model's features, prediction\n        outputs and ground truth\
    \ properties. It is used to extract\n        pertinent data from the dataset and to process features based on\n        their properties. Make sure that the schema aligns with your\n        dataset, if it does not, Vertex AI will be unable to extract\n        data form the dataset.\n    tabular_objective_spec (objective.TabularObjective):\n        Optional. The default tabular monitoring objective spec for\n        the model monitor. It can be overriden in the ModelMonitoringJob\n        objective spec.\n    output_spec (output.OutputSpec):\n        Optional. The default monitoring metrics/logs export spec, it\n        can be overriden in the ModelMonitoringJob output spec.\n        If not specified, a default Google Cloud Storage bucket will be\n        created under your project.\n    notification_spec (notification.NotificationSpec):\n        Optional. The default notification spec for monitoring result.\n        It can be overriden in the ModelMonitoringJob notification spec.\n  \
    \  explanation_spec (explanation.ExplanationSpec):\n        Optional. The default explanation spec for feature attribution\n        monitoring. It can be overriden in the ModelMonitoringJob\n        explanation spec.\n    project (str):\n        Optional. Project to retrieve model monitor from. If not set,\n        project set in aiplatform.init will be used.\n    location (str):\n        Optional. Location to retrieve model monitor from. If not set,\n        location set in aiplatform.init will be used.\n    credentials (auth_credentials.Credentials):\n        Optional. Custom credentials to use to create this model monitor.\n        Overrides credentials set in aiplatform.init.\n    model_monitor_id (str):\n        Optional. The unique ID of the model monitor, which will become\n        the final component of the model monitor resource name.\n        If not specified, it will be generated by Vertex AI.\n\nReturns:\n    ModelMonitor: The model monitor that was created."
  signature: 'def create(cls, model_name: str, model_version_id: str, training_dataset: typing.Optional[vertexai.resources.preview.ml_monitoring.spec.objective.MonitoringInput], display_name: typing.Optional[str], model_monitoring_schema: typing.Optional[vertexai.resources.preview.ml_monitoring.spec.schema.ModelMonitoringSchema], tabular_objective_spec: typing.Optional[vertexai.resources.preview.ml_monitoring.spec.objective.TabularObjective], output_spec: typing.Optional[vertexai.resources.preview.ml_monitoring.spec.output.OutputSpec], notification_spec: typing.Optional[vertexai.resources.preview.ml_monitoring.spec.notification.NotificationSpec], explanation_spec: typing.Optional[google.cloud.aiplatform.compat.types.explanation_v1beta1.ExplanationSpec], project: typing.Optional[str], location: typing.Optional[str], credentials: typing.Optional[google.auth.credentials.Credentials], model_monitor_id: typing.Optional[str]) -> vertexai.resources.preview.ml_monitoring.model_monitors.ModelMonitor:'
- rank: 3188
  id: vertexai.resources.preview.ml_monitoring.model_monitors.ModelMonitor.create_schedule
  name: create_schedule
  file_path: env/lib/python3.13/site-packages/vertexai/resources/preview/ml_monitoring/model_monitors.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Creates a new Scheduled run for model monitoring job.\n\nArgs:\n    cron (str):\n        Required. Cron schedule (https://en.wikipedia.org/wiki/Cron) to\n        launch scheduled runs. To explicitly set a timezone to the cron\n        tab, apply a prefix in the cron tab: \"CRON_TZ=${IANA_TIME_ZONE}\"\n        or \"TZ=${IANA_TIME_ZONE}\". The ${IANA_TIME_ZONE} may only be a\n        valid string from IANA time zone database. For example,\n        \"CRON_TZ=America/New_York 1 * * * *\", or\n        \"TZ=America/New_York 1 * * * *\".\n    target_dataset (objective.MonitoringInput):\n        Required. The target dataset for analysis.\n    display_name (str):\n        Optional. The user-defined name of the Schedule.\n        The name can be up to 128 characters long and can be consist of\n        any UTF-8 characters.\n        Display name of the Schedule.\n    model_monitoring_job_display_name (str):\n        Optional. The user-defined name of the ModelMonitoringJob.\n        The\
    \ name can be up to 128 characters long and can be consist of\n        any UTF-8 characters.\n        Display name of the ModelMonitoringJob.\n    start_time (timestamp_pb2.Timestamp):\n        Optional. Timestamp after which the first run can be scheduled.\n        Default to Schedule create time if not specified.\n    end_time (timestamp_pb2.Timestamp):\n        Optional. Timestamp after which no new runs can be scheduled.\n        If specified, The schedule will be completed when the end_time\n        is reached.\n        If not specified, new runs will keep getting scheduled until\n        this Schedule is paused or deleted. Already scheduled runs will\n        be allowed to complete. Unset if not specified.\n    tabular_objective_spec (objective.TabularObjective):\n        Optional. The tabular monitoring objective spec. If not set,\n        the default tabular objective spec in ModelMonitor will be\n        used. You must either set here or set the default one in the\n        ModelMonitor.\n\
    \    baseline_dataset (objective.MonitoringInput):\n        Optional. The baseline dataset for monitoring job.\n        If not set, the training dataset in ModelMonitor will be\n        used as baseline dataset.\n    output_spec (output.OutputSpec):\n        Optional. The monitoring metrics/logs export spec.\n        If not set, will use the default output_spec defined in\n        ModelMonitor.\n    notification_spec (notification.NotificationSpec):\n        Optional. The notification spec for monitoring result.\n        If not set, will use the default notification_spec defined in\n        ModelMonitor.\n    explanation_spec (explanation.ExplanationSpec):\n        Optional. The explanation spec for feature attribution\n        monitoring.\n        If not set, will use the default explanation_spec defined in\n        ModelMonitor.\n\nReturns:\n    Schedule: The created schedule."
  signature: 'def create_schedule(self, cron: str, target_dataset: vertexai.resources.preview.ml_monitoring.spec.objective.MonitoringInput, display_name: typing.Optional[str], model_monitoring_job_display_name: typing.Optional[str], start_time: typing.Optional[google.protobuf.timestamp_pb2.Timestamp], end_time: typing.Optional[google.protobuf.timestamp_pb2.Timestamp], tabular_objective_spec: typing.Optional[vertexai.resources.preview.ml_monitoring.spec.objective.TabularObjective], baseline_dataset: typing.Optional[vertexai.resources.preview.ml_monitoring.spec.objective.MonitoringInput], output_spec: typing.Optional[vertexai.resources.preview.ml_monitoring.spec.output.OutputSpec], notification_spec: typing.Optional[vertexai.resources.preview.ml_monitoring.spec.notification.NotificationSpec], explanation_spec: typing.Optional[google.cloud.aiplatform.compat.types.explanation_v1beta1.ExplanationSpec]) -> google.cloud.aiplatform.compat.types.schedule_v1beta1.Schedule:'
- rank: 3189
  id: vertexai.resources.preview.ml_monitoring.model_monitors.ModelMonitor.delete
  name: delete
  file_path: env/lib/python3.13/site-packages/vertexai/resources/preview/ml_monitoring/model_monitors.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Force delete the model monitor.\n\nArgs:\n    force (bool):\n        Required. If force is set to True, all schedules on this\n        ModelMonitor will be deleted first. Default is False.\n    sync (bool):\n        Whether to execute this method synchronously. If False, this method\n        will be executed in concurrent Future and any downstream object will\n        be immediately returned and synced when the Future has completed.\n        Default is True."
  signature: 'def delete(self, force: bool, sync: bool) -> None:'
- rank: 3190
  id: vertexai.resources.preview.ml_monitoring.model_monitors.ModelMonitor.delete_model_monitoring_job
  name: delete_model_monitoring_job
  file_path: env/lib/python3.13/site-packages/vertexai/resources/preview/ml_monitoring/model_monitors.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Delete a model monitoring job.\n\nArgs:\n\n    model_monitoring_job_name (str):\n        Required. The resource name of the model monitoring job that\n        needs to be deleted.\n        Format:\n        ``projects/{project}/locations/{location}/modelMonitors/{model_monitor}/modelMonitoringJobs/{model_monitoring_job}``\n        or\n        ``{model_monitoring_job}``"
  signature: 'def delete_model_monitoring_job(self, model_monitoring_job_name: str) -> None:'
- rank: 3191
  id: vertexai.resources.preview.ml_monitoring.model_monitors.ModelMonitor.delete_schedule
  name: delete_schedule
  file_path: env/lib/python3.13/site-packages/vertexai/resources/preview/ml_monitoring/model_monitors.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Deletes an existing Schedule.\n\nArgs:\n    schedule_name (str):\n        Required. The resource name of schedule that needs to be deleted.\n        Format: ``projects/{project}/locations/{location}/schedules/{schedule}``\n        or\n        ``{schedule}``"
  signature: 'def delete_schedule(self, schedule_name: str) -> None:'
- rank: 3192
  id: vertexai.resources.preview.ml_monitoring.model_monitors.ModelMonitor.get_model_monitoring_job
  name: get_model_monitoring_job
  file_path: env/lib/python3.13/site-packages/vertexai/resources/preview/ml_monitoring/model_monitors.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Get the specified ModelMonitoringJob.\n\nArgs:\n    model_monitoring_job_name (str):\n        Required. The resource name of the ModelMonitoringJob that is needed.\n        Format:\n        ``projects/{project}/locations/{location}/modelMonitors/{model_monitor}/modelMonitoringJobs/{model_monitoring_job}``\n        or\n        ``{model_monitoring_job}``\n\nReturns:\n    ModelMonitoringJob: The model monitoring job get."
  signature: 'def get_model_monitoring_job(self, model_monitoring_job_name: str) -> vertexai.resources.preview.ml_monitoring.model_monitors.ModelMonitoringJob:'
- rank: 3193
  id: vertexai.resources.preview.ml_monitoring.model_monitors.ModelMonitor.get_schedule
  name: get_schedule
  file_path: env/lib/python3.13/site-packages/vertexai/resources/preview/ml_monitoring/model_monitors.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Gets an existing Schedule.\n\nArgs:\n    schedule_name (str):\n        Required. The resource name of schedule that needs to be fetched.\n        Format: ``projects/{project}/locations/{location}/schedules/{schedule}``\n        or\n        ``{schedule}``\n\nReturns:\n    Schedule: The schedule requested."
  signature: 'def get_schedule(self, schedule_name: str) -> google.cloud.aiplatform.compat.types.schedule_v1beta1.Schedule:'
- rank: 3194
  id: vertexai.resources.preview.ml_monitoring.model_monitors.ModelMonitor.get_schema
  name: get_schema
  file_path: env/lib/python3.13/site-packages/vertexai/resources/preview/ml_monitoring/model_monitors.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: Get the schema of the model monitor.
  signature: 'def get_schema(self) -> google.cloud.aiplatform.compat.types.model_monitor_v1beta1.ModelMonitoringSchema:'
- rank: 3195
  id: vertexai.resources.preview.ml_monitoring.model_monitors.ModelMonitor.list_jobs
  name: list_jobs
  file_path: env/lib/python3.13/site-packages/vertexai/resources/preview/ml_monitoring/model_monitors.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "List ModelMonitoringJobs.\n\nArgs:\n    page_size (int):\n        Optional. The standard page list size.\n    page_token (str):\n        Optional. A page token received from a previous call.\n\nReturns:\n    ListJobsResponse.list_jobs: The list model monitoring jobs responses."
  signature: 'def list_jobs(self, page_size: typing.Optional[int], page_token: typing.Optional[str]) -> vertexai.resources.preview.ml_monitoring.model_monitors.ListJobsResponse.list_jobs:'
- rank: 3196
  id: vertexai.resources.preview.ml_monitoring.model_monitors.ModelMonitor.list_schedules
  name: list_schedules
  file_path: env/lib/python3.13/site-packages/vertexai/resources/preview/ml_monitoring/model_monitors.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "List Schedules.\n\nArgs:\n    filter (str):\n        Optional. Lists the Schedules that match the filter expression.\n        The\n        following fields are supported:\n\n        -  ``display_name``: Supports ``=``, ``!=`` comparisons, and\n           ``:`` wildcard.\n        -  ``state``: Supports ``=`` and ``!=`` comparisons.\n        -  ``request``: Supports existence of the <request_type>\n           check. (e.g. ``create_pipeline_job_request:*`` -->\n           Schedule has create_pipeline_job_request).\n        -  ``create_time``: Supports ``=``, ``!=``, ``<``, ``>``,\n           ``<=``, and ``>=`` comparisons. Values must be in RFC\n           3339 format.\n        -  ``start_time``: Supports ``=``, ``!=``, ``<``, ``>``,\n           ``<=``, and ``>=`` comparisons. Values must be in RFC\n           3339 format.\n        -  ``end_time``: Supports ``=``, ``!=``, ``<``, ``>``,\n           ``<=``, ``>=`` comparisons and ``:*`` existence check.\n           Values must be\
    \ in RFC 3339 format.\n        -  ``next_run_time``: Supports ``=``, ``!=``, ``<``, ``>``,\n           ``<=``, and ``>=`` comparisons. Values must be in RFC\n           3339 format.\n\n        Filter expressions can be combined together using logical\n        operators (``NOT``, ``AND`` & ``OR``). The syntax to define\n        filter expression is based on https://google.aip.dev/160.\n    page_size (int):\n        Optional. The standard page list size.\n    page_token (str):\n        Optional. A page token received from a previous call.\n\nReturns:\n    MetricsSearchResponse: The model monitoring stats results."
  signature: 'def list_schedules(self, filter: typing.Optional[str], page_size: typing.Optional[int], page_token: typing.Optional[str]) -> vertexai.resources.preview.ml_monitoring.model_monitors.ListSchedulesResponse.list_schedules:'
- rank: 3197
  id: vertexai.resources.preview.ml_monitoring.model_monitors.ModelMonitor.pause_schedule
  name: pause_schedule
  file_path: env/lib/python3.13/site-packages/vertexai/resources/preview/ml_monitoring/model_monitors.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Pauses an existing Schedule.\n\nArgs:\n    schedule_name (str):\n        Required. The resource name of schedule that needs to be paused.\n        Format: ``projects/{project}/locations/{location}/schedules/{schedule}``\n        or\n        ``{schedule}``"
  signature: 'def pause_schedule(self, schedule_name: str) -> None:'
- rank: 3198
  id: vertexai.resources.preview.ml_monitoring.model_monitors.ModelMonitor.resume_schedule
  name: resume_schedule
  file_path: env/lib/python3.13/site-packages/vertexai/resources/preview/ml_monitoring/model_monitors.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Resumes an existing Schedule.\n\nArgs:\n    schedule_name (str):\n        Required. The resource name of schedule that needs to be resumed.\n        Format: ``projects/{project}/locations/{location}/schedules/{schedule}``\n        or\n        ``{schedule}``"
  signature: 'def resume_schedule(self, schedule_name: str) -> None:'
- rank: 3199
  id: vertexai.resources.preview.ml_monitoring.model_monitors.ModelMonitor.run
  name: run
  file_path: env/lib/python3.13/site-packages/vertexai/resources/preview/ml_monitoring/model_monitors.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Creates a new ModelMonitoringJob.\n\nArgs:\n    target_dataset (objective.MonitoringInput):\n        Required. The target dataset for analysis.\n    display_name (str):\n        Optional. The user-defined name of the ModelMonitoringJob.\n        The name can be up to 128 characters long and can comprise any\n        UTF-8 character.\n        Display name of the ModelMonitoringJob.\n    model_monitoring_job_id (str):\n        Optional. The unique ID of the model monitoring job run, which\n        will become the final component of the model monitoring job\n        resource name. The maximum length is 63 characters, and valid\n        characters are /^[a-z]([a-z0-9-]{0,61}[a-z0-9])?$/.\n        If not specified, it will be generated by Vertex AI.\n    sync (bool):\n        Whether to execute this method synchronously. If False, this\n        method will be executed in concurrent Future and any downstream\n        object will be immediately returned and synced when the Future\n\
    \        has completed. Default is False.\n    tabular_objective_spec (objective.TabularObjective):\n        Optional. The tabular monitoring objective spec for the model\n        monitoring job.\n    baseline_dataset (objective.MonitoringInput):\n        Optional. The baseline dataset for monitoring job.\n        If not set, the training dataset in ModelMonitor will be\n        used as baseline dataset.\n    output_spec (output.OutputSpec):\n        Optional. The monitoring metrics/logs export spec.\n        If not set, will use the default output_spec defined in\n        ModelMonitor.\n    notification_spec (notification.NotificationSpec):\n        Optional. The notification spec for monitoring result.\n        If not set, will use the default notification_spec defined in\n        ModelMonitor.\n    explanation_config (explanation.ExplanationSpec):\n        Optional. The explanation spec for feature attribution\n        monitoring.\n        If not set, will use the default explanation_spec\
    \ defined in\n        ModelMonitor.\n\nReturns:\n    ModelMonitoringJob: The model monitoring job that was created."
  signature: 'def run(self, target_dataset: vertexai.resources.preview.ml_monitoring.spec.objective.MonitoringInput, display_name: typing.Optional[str], model_monitoring_job_id: typing.Optional[str], sync: typing.Optional[bool], tabular_objective_spec: typing.Optional[vertexai.resources.preview.ml_monitoring.spec.objective.TabularObjective], baseline_dataset: typing.Optional[vertexai.resources.preview.ml_monitoring.spec.objective.MonitoringInput], output_spec: typing.Optional[vertexai.resources.preview.ml_monitoring.spec.output.OutputSpec], notification_spec: typing.Optional[vertexai.resources.preview.ml_monitoring.spec.notification.NotificationSpec], explanation_spec: typing.Optional[google.cloud.aiplatform.compat.types.explanation_v1beta1.ExplanationSpec]) -> vertexai.resources.preview.ml_monitoring.model_monitors.ModelMonitoringJob:'
- rank: 3200
  id: vertexai.resources.preview.ml_monitoring.model_monitors.ModelMonitor.search_alerts
  name: search_alerts
  file_path: env/lib/python3.13/site-packages/vertexai/resources/preview/ml_monitoring/model_monitors.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Search ModelMonitoringAlerts.\n\nArgs:\n    stats_name (str):\n        Optional. The stats name filter for the search, if not set, all\n        stats will be returned.\n        For tabular models, provide the name of the feature to return\n        alerts from.\n    objective_type (str):\n        Optional. Return alerts from one of the supported monitoring\n        objectives:\n            `raw-feature-drift`\n            `prediction-output-drift`\n            `feature-attribution`\n    model_monitoring_job_name (str):\n        Optional. The resource name of a particular model monitoring\n        job that the user wants to search metrics result from.\n        Format:\n        ``projects/{project}/locations/{location}/modelMonitors/{model_monitor}/modelMonitoringJobs/{model_monitoring_job}``\n    start_time (timestamp_pb2.Timestamp):\n        Optional. Inclusive start of the time interval for which alerts\n        should be returned.\n    end_time (timestamp_pb2.Timestamp):\n\
    \        Optional. Exclusive end of the time interval for which alerts\n        should be returned.\n    page_size (int):\n        Optional. The standard page list size.\n    page_token (str):\n        Optional. A page token received from a previous call.\n\nReturns:\n    AlertsSearchResponse: The model monitoring alerts results."
  signature: 'def search_alerts(self, stats_name: typing.Optional[str], objective_type: typing.Optional[str], model_monitoring_job_name: typing.Optional[str], start_time: typing.Optional[google.protobuf.timestamp_pb2.Timestamp], end_time: typing.Optional[google.protobuf.timestamp_pb2.Timestamp], page_size: typing.Optional[int], page_token: typing.Optional[str]) -> typing.Dict[str, typing.Any]:'
- rank: 3201
  id: vertexai.resources.preview.ml_monitoring.model_monitors.ModelMonitor.search_metrics
  name: search_metrics
  file_path: env/lib/python3.13/site-packages/vertexai/resources/preview/ml_monitoring/model_monitors.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Search ModelMonitoringStats.\n\nArgs:\n    stats_name (str):\n        Optional. The stats name filter for the search, if not set, all\n        stats will be returned.\n        For tabular model it's the feature name.\n    objective_type (str):\n        Optional. One of the supported monitoring objectives:\n            `raw-feature-drift`\n            `prediction-output-drift`\n            `feature-attribution`\n    model_monitoring_job_name (str):\n        Optional. The resource name of a particular model monitoring\n        job that the user wants to search metrics result from.\n        Format:\n        ``projects/{project}/locations/{location}/modelMonitors/{model_monitor}/modelMonitoringJobs/{model_monitoring_job}``\n    schedule_name (str):\n        Optional. The resource name of a particular model monitoring\n        schedule that the user wants to search metrics result from.\n        Format: ``projects/{project}/locations/{location}/schedules/{schedule}``\n    algorithm\
    \ (str):\n        Optional. The algorithm type filter for the search, eg:\n        jensen_shannon_divergence, l_infinity.\n    start_time (timestamp_pb2.Timestamp):\n        Optional. Inclusive start of the time interval for which results\n        should be returned.\n    end_time (timestamp_pb2.Timestamp):\n        Optional. Exclusive end of the time interval for which results\n        should be returned.\n    page_size (int):\n        Optional. The standard page list size.\n    page_token (str):\n        Optional. A page token received from a previous call.\n\nReturns:\n    MetricsSearchResponse: The model monitoring stats results."
  signature: 'def search_metrics(self, stats_name: typing.Optional[str], objective_type: typing.Optional[str], model_monitoring_job_name: typing.Optional[str], schedule_name: typing.Optional[str], algorithm: typing.Optional[str], start_time: typing.Optional[google.protobuf.timestamp_pb2.Timestamp], end_time: typing.Optional[google.protobuf.timestamp_pb2.Timestamp], page_size: typing.Optional[int], page_token: typing.Optional[str]) -> vertexai.resources.preview.ml_monitoring.model_monitors.MetricsSearchResponse.monitoring_stats:'
- rank: 3202
  id: vertexai.resources.preview.ml_monitoring.model_monitors.ModelMonitor.show_feature_attribution_drift_stats
  name: show_feature_attribution_drift_stats
  file_path: env/lib/python3.13/site-packages/vertexai/resources/preview/ml_monitoring/model_monitors.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "The method to visualize the feature attribution drift result from a model monitoring job as a histogram chart and a table.\n\nArgs:\n    model_monitoring_job_name (str):\n        Required. The resource name of model monitoring job to show the\n        feature attribution drift stats from.\n        Format:\n        ``projects/{project}/locations/{location}/modelMonitors/{model_monitor}/modelMonitoringJobs/{model_monitoring_job}``\n        or\n        ``{model_monitoring_job}``"
  signature: 'def show_feature_attribution_drift_stats(self, model_monitoring_job_name: str) -> None:'
- rank: 3203
  id: vertexai.resources.preview.ml_monitoring.model_monitors.ModelMonitor.show_feature_drift_stats
  name: show_feature_drift_stats
  file_path: env/lib/python3.13/site-packages/vertexai/resources/preview/ml_monitoring/model_monitors.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "The method to visualize the feature drift result from a model monitoring job as a histogram chart and a table.\n\nArgs:\n    model_monitoring_job_name (str):\n        Required. The resource name of model monitoring job to show the\n        drift stats from.\n        Format: ``projects/{project}/locations/{location}/modelMonitors/{model_monitor}/modelMonitoringJobs/{model_monitoring_job}``\n        or\n        ``{model_monitoring_job}``"
  signature: 'def show_feature_drift_stats(self, model_monitoring_job_name: str) -> None:'
- rank: 3204
  id: vertexai.resources.preview.ml_monitoring.model_monitors.ModelMonitor.show_output_drift_stats
  name: show_output_drift_stats
  file_path: env/lib/python3.13/site-packages/vertexai/resources/preview/ml_monitoring/model_monitors.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "The method to visualize the prediction output drift result from a model monitoring job as a histogram chart and a table.\n\nArgs:\n    model_monitoring_job_name (str):\n        Required. The resource name of model monitoring job to show the\n        drift stats from.\n        Format: ``projects/{project}/locations/{location}/modelMonitors/{model_monitor}/modelMonitoringJobs/{model_monitoring_job}``\n        or\n        ``{model_monitoring_job}``"
  signature: 'def show_output_drift_stats(self, model_monitoring_job_name: str) -> None:'
- rank: 3205
  id: vertexai.resources.preview.ml_monitoring.model_monitors.ModelMonitor.update
  name: update
  file_path: env/lib/python3.13/site-packages/vertexai/resources/preview/ml_monitoring/model_monitors.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Updates an existing ModelMonitor.\n\nArgs:\n    display_name (str):\n        Optional. The user-defined name of the ModelMonitor.\n        The name can be up to 128 characters long and can comprise any\n        UTF-8 character.\n        Display name of the ModelMonitor.\n    training_dataset (objective.MonitoringInput):\n        Optional. Training dataset used to train the model. It can serve\n        as a baseline dataset to identify changes in production.\n    model_monitoring_schema (schema.ModelMonitoringSchema):\n        Optional. The Monitoring Schema specifies the model's features,\n        prediction outputs and ground truth properties. It is used to\n        extract pertinent data from the dataset and to process features\n        based on their properties. Make sure that the schema aligns with\n        your dataset, if it does not, Vertex AI will be unable to\n        extract data form the dataset.\n    tabular_objective_spec (objective.TabularObjective):\n       \
    \ Optional. The default tabular monitoring objective spec for\n        the model monitor. It can be overriden in the ModelMonitoringJob\n        objective spec.\n    output_spec (output.OutputSpec):\n        Optional. The default monitoring metrics/logs export spec, it\n        can be overriden in the ModelMonitoringJob output spec.\n    notification_spec (notification.NotificationSpec):\n        Optional. The default notification spec for monitoring result.\n        It can be overriden in the ModelMonitoringJob notification spec.\n    explanation_spec (explanation.ExplanationSpec):\n        Optional. The default explanation spec for feature attribution\n        monitoring. It can be overriden in the ModelMonitoringJob\n        explanation spec.\n\nReturns:\n    ModelMonitor: The updated model monitor."
  signature: 'def update(self, display_name: typing.Optional[str], training_dataset: typing.Optional[vertexai.resources.preview.ml_monitoring.spec.objective.MonitoringInput], model_monitoring_schema: typing.Optional[vertexai.resources.preview.ml_monitoring.spec.schema.ModelMonitoringSchema], tabular_objective_spec: typing.Optional[vertexai.resources.preview.ml_monitoring.spec.objective.TabularObjective], output_spec: typing.Optional[vertexai.resources.preview.ml_monitoring.spec.output.OutputSpec], notification_spec: typing.Optional[vertexai.resources.preview.ml_monitoring.spec.notification.NotificationSpec], explanation_spec: typing.Optional[google.cloud.aiplatform.compat.types.explanation_v1beta1.ExplanationSpec]) -> vertexai.resources.preview.ml_monitoring.model_monitors.ModelMonitor:'
- rank: 3206
  id: vertexai.resources.preview.ml_monitoring.model_monitors.ModelMonitor.update_schedule
  name: update_schedule
  file_path: env/lib/python3.13/site-packages/vertexai/resources/preview/ml_monitoring/model_monitors.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Updates an existing Schedule.\n\nArgs:\n    schedule_name (str):\n        Required. The resource name of schedule that needs to be updated.\n        Format: ``projects/{project}/locations/{location}/schedules/{schedule}``\n        or\n        ``{schedule}``\n    display_name (str):\n        Optional. The user-defined name of the Schedule.\n        The name can be up to 128 characters long and can be consist of\n        any UTF-8 characters.\n        Display name of the Schedule.\n    model_monitoring_job_display_name (str):\n        Optional. The user-defined display name of the ModelMonitoringJob\n        that needs to be updated.\n    cron (str):\n        Optional. Cron schedule (https://en.wikipedia.org/wiki/Cron) to\n        launch scheduled runs. To explicitly set a timezone to the cron\n        tab, apply a prefix in the cron tab: \"CRON_TZ=${IANA_TIME_ZONE}\"\n        or \"TZ=${IANA_TIME_ZONE}\". The ${IANA_TIME_ZONE} may only be a\n        valid string from IANA time\
    \ zone database. For example,\n        \"CRON_TZ=America/New_York 1 * * * *\", or\n        \"TZ=America/New_York 1 * * * *\".\n    baseline_dataset (objective.MonitoringInput):\n        Optional. The baseline dataset for monitoring job.\n    target_dataset (objective.MonitoringInput):\n        Optional. The target dataset for analysis.\n    tabular_objective_spec (objective.TabularObjective):\n        Optional. The tabular monitoring objective spec.\n    output_spec (output.OutputSpec):\n        Optional. The monitoring metrics/logs export spec.\n    notification_spec (notification.NotificationSpec):\n        Optional. The notification spec for monitoring result.\n    explanation_spec (explanation.ExplanationSpec):\n        Optional. The explanation spec for feature attribution\n        monitoring.\n    end_time (timestamp_pb2.Timestamp):\n        Optional. Timestamp after which no new runs can be scheduled.\n\nReturns:\n    Schedule: The updated schedule."
  signature: 'def update_schedule(self, schedule_name: str, display_name: typing.Optional[str], model_monitoring_job_display_name: typing.Optional[str], cron: typing.Optional[str], baseline_dataset: typing.Optional[vertexai.resources.preview.ml_monitoring.spec.objective.MonitoringInput], target_dataset: typing.Optional[vertexai.resources.preview.ml_monitoring.spec.objective.MonitoringInput], tabular_objective_spec: typing.Optional[vertexai.resources.preview.ml_monitoring.spec.objective.TabularObjective], output_spec: typing.Optional[vertexai.resources.preview.ml_monitoring.spec.output.OutputSpec], notification_spec: typing.Optional[vertexai.resources.preview.ml_monitoring.spec.notification.NotificationSpec], explanation_spec: typing.Optional[google.cloud.aiplatform.compat.types.explanation_v1beta1.ExplanationSpec], end_time: typing.Optional[google.protobuf.timestamp_pb2.Timestamp]) -> google.cloud.aiplatform.compat.types.schedule_v1beta1.Schedule:'
- rank: 3207
  id: vertexai.resources.preview.ml_monitoring.model_monitors.ModelMonitoringJob
  name: ModelMonitoringJob
  file_path: env/lib/python3.13/site-packages/vertexai/resources/preview/ml_monitoring/model_monitors.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: "Initializer for ModelMonitoringJob.\n\nExample Usage:\n\n     my_monitoring_job = aiplatform.ModelMonitoringJob(\n         model_monitoring_job_name='projects/123/locations/us-central1/modelMonitors/\\\n         my_model_monitor_id/modelMonitoringJobs/my_monitoring_job_id'\n     )\n     or\n     my_monitoring_job = aiplatform.aiplatform.ModelMonitoringJob(\n         model_monitoring_job_name='my_monitoring_job_id',\n         model_monitor_id='my_model_monitor_id',\n     )\nArgs:\n     model_monitoring_job_name (str):\n         Required. The resource name for the Model Monitoring Job if\n         provided alone, or the model monitoring job id if provided with\n         model_monitor_id.\n     model_monitor_id (str):\n         Optional. The model monitor id depends on the way of initializing\n         ModelMonitoringJob.\n     project (str):\n         Required. Project to retrieve endpoint from. If not set, project\n         set in aiplatform.init will be used.\n     location\
    \ (str):\n         Required. Location to retrieve endpoint from. If not set,\n         location set in aiplatform.init will be used.\n     credentials (auth_credentials.Credentials):\n         Optional. Custom credentials to use to init model monitoring job.\n         Overrides credentials set in aiplatform.init.\n\n[Note: Inherited members from base.VertexAiStatefulResource are omitted.]"
  constructor_signature: 'def __init__(self, model_monitoring_job_name: str, model_monitor_id: typing.Optional[str], project: typing.Optional[str], location: typing.Optional[str], credentials: typing.Optional[google.auth.credentials.Credentials]):'
  methods:
  - signature: 'def state(self) -> google.cloud.aiplatform.compat.types.job_state_v1beta1.JobState:'
    docstring: "Fetch Job again and return the current JobState.\n\nReturns:\n    state (job_state.JobState):\n        Enum that describes the state of a Model Monitoring Job."
  - signature: 'def create(cls, model_monitor_name: str, target_dataset: vertexai.resources.preview.ml_monitoring.spec.objective.MonitoringInput, display_name: typing.Optional[str], model_monitoring_job_id: typing.Optional[str], project: typing.Optional[str], location: typing.Optional[str], credentials: typing.Optional[google.auth.credentials.Credentials], baseline_dataset: typing.Optional[vertexai.resources.preview.ml_monitoring.spec.objective.MonitoringInput], tabular_objective_spec: typing.Optional[vertexai.resources.preview.ml_monitoring.spec.objective.TabularObjective], output_spec: typing.Optional[vertexai.resources.preview.ml_monitoring.spec.output.OutputSpec], notification_spec: typing.Optional[vertexai.resources.preview.ml_monitoring.spec.notification.NotificationSpec], explanation_spec: typing.Optional[google.cloud.aiplatform.compat.types.explanation_v1beta1.ExplanationSpec], sync: bool) -> vertexai.resources.preview.ml_monitoring.model_monitors.ModelMonitoringJob:'
    docstring: "Creates a new ModelMonitoringJob.\n\nArgs:\n    model_monitor_name (str):\n        Required. The parent model monitor resource name. Format:\n        ``projects/{project}/locations/{location}/modelMonitors/{model_monitor}``\n    target_dataset (objective.MonitoringInput):\n        Required. The target dataset for analysis.\n    display_name (str):\n        Optional. The user-defined name of the ModelMonitoringJob.\n        The name can be up to 128 characters long and can comprise any\n        UTF-8 character.\n    model_monitoring_job_id (str):\n        Optional. The unique ID of the model monitoring job run, which\n        will become the final component of the model monitoring job\n        resource name. The maximum length is 63 characters, and valid\n        characters are /^[a-z]([a-z0-9-]{0,61}[a-z0-9])?$/.\n        If not specified, it will be generated by Vertex AI.\n    project (str):\n        Optional. Project to retrieve endpoint from. If not set, project\n   \
      \     set in aiplatform.init will be used.\n    location (str):\n        Optional. Location to retrieve endpoint from. If not set,\n        location set in aiplatform.init will be used.\n    credentials (auth_credentials.Credentials):\n        Optional. Custom credentials to use to create model monitoring job.\n        Overrides credentials set in aiplatform.init.\n    baseline_dataset (objective.MonitoringInput):\n        Optional. The baseline dataset for monitoring job.\n        If not set, the training dataset in ModelMonitor will be\n        used as baseline dataset.\n    output_spec (output.OutputSpec):\n        Optional. The monitoring metrics/logs export spec.\n        If not set, will use the default output_spec defined in\n        ModelMonitor.\n    notification_spec (notification.NotificationSpec):\n        Optional. The notification spec for monitoring result.\n        If not set, will use the default notification_spec defined in\n        ModelMonitor.\n    explanation_spec\
      \ (explanation.ExplanationSpec):\n        Optional. The explanation spec for feature attribution\n        monitoring.\n        If not set, will use the default explanation_spec defined in\n        ModelMonitor.\n    sync (bool):\n        Required. Whether to execute this method synchronously. If False, this\n        method will be executed in concurrent Future and any downstream\n        object will be immediately returned and synced when the Future\n        has completed. Default is False.\nReturns:\n    ModelMonitoringJob: The model monitoring job that was created."
  - signature: 'def delete(self) -> None:'
    docstring: Deletes an Model Monitoring Job.
  properties:
  - signature: 'client_class: Any'
  omitted_inherited_members_from:
  - base.VertexAiStatefulResource
- rank: 3208
  id: vertexai.resources.preview.ml_monitoring.model_monitors.ModelMonitoringJob.__init__
  name: __init__
  file_path: env/lib/python3.13/site-packages/vertexai/resources/preview/ml_monitoring/model_monitors.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def __init__(self, model_monitoring_job_name: str, model_monitor_id: typing.Optional[str], project: typing.Optional[str], location: typing.Optional[str], credentials: typing.Optional[google.auth.credentials.Credentials]):'
- rank: 3209
  id: vertexai.resources.preview.ml_monitoring.model_monitors.ModelMonitoringJob.create
  name: create
  file_path: env/lib/python3.13/site-packages/vertexai/resources/preview/ml_monitoring/model_monitors.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Creates a new ModelMonitoringJob.\n\nArgs:\n    model_monitor_name (str):\n        Required. The parent model monitor resource name. Format:\n        ``projects/{project}/locations/{location}/modelMonitors/{model_monitor}``\n    target_dataset (objective.MonitoringInput):\n        Required. The target dataset for analysis.\n    display_name (str):\n        Optional. The user-defined name of the ModelMonitoringJob.\n        The name can be up to 128 characters long and can comprise any\n        UTF-8 character.\n    model_monitoring_job_id (str):\n        Optional. The unique ID of the model monitoring job run, which\n        will become the final component of the model monitoring job\n        resource name. The maximum length is 63 characters, and valid\n        characters are /^[a-z]([a-z0-9-]{0,61}[a-z0-9])?$/.\n        If not specified, it will be generated by Vertex AI.\n    project (str):\n        Optional. Project to retrieve endpoint from. If not set, project\n     \
    \   set in aiplatform.init will be used.\n    location (str):\n        Optional. Location to retrieve endpoint from. If not set,\n        location set in aiplatform.init will be used.\n    credentials (auth_credentials.Credentials):\n        Optional. Custom credentials to use to create model monitoring job.\n        Overrides credentials set in aiplatform.init.\n    baseline_dataset (objective.MonitoringInput):\n        Optional. The baseline dataset for monitoring job.\n        If not set, the training dataset in ModelMonitor will be\n        used as baseline dataset.\n    output_spec (output.OutputSpec):\n        Optional. The monitoring metrics/logs export spec.\n        If not set, will use the default output_spec defined in\n        ModelMonitor.\n    notification_spec (notification.NotificationSpec):\n        Optional. The notification spec for monitoring result.\n        If not set, will use the default notification_spec defined in\n        ModelMonitor.\n    explanation_spec\
    \ (explanation.ExplanationSpec):\n        Optional. The explanation spec for feature attribution\n        monitoring.\n        If not set, will use the default explanation_spec defined in\n        ModelMonitor.\n    sync (bool):\n        Required. Whether to execute this method synchronously. If False, this\n        method will be executed in concurrent Future and any downstream\n        object will be immediately returned and synced when the Future\n        has completed. Default is False.\nReturns:\n    ModelMonitoringJob: The model monitoring job that was created."
  signature: 'def create(cls, model_monitor_name: str, target_dataset: vertexai.resources.preview.ml_monitoring.spec.objective.MonitoringInput, display_name: typing.Optional[str], model_monitoring_job_id: typing.Optional[str], project: typing.Optional[str], location: typing.Optional[str], credentials: typing.Optional[google.auth.credentials.Credentials], baseline_dataset: typing.Optional[vertexai.resources.preview.ml_monitoring.spec.objective.MonitoringInput], tabular_objective_spec: typing.Optional[vertexai.resources.preview.ml_monitoring.spec.objective.TabularObjective], output_spec: typing.Optional[vertexai.resources.preview.ml_monitoring.spec.output.OutputSpec], notification_spec: typing.Optional[vertexai.resources.preview.ml_monitoring.spec.notification.NotificationSpec], explanation_spec: typing.Optional[google.cloud.aiplatform.compat.types.explanation_v1beta1.ExplanationSpec], sync: bool) -> vertexai.resources.preview.ml_monitoring.model_monitors.ModelMonitoringJob:'
- rank: 3210
  id: vertexai.resources.preview.ml_monitoring.model_monitors.ModelMonitoringJob.state
  name: state
  file_path: env/lib/python3.13/site-packages/vertexai/resources/preview/ml_monitoring/model_monitors.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Fetch Job again and return the current JobState.\n\nReturns:\n    state (job_state.JobState):\n        Enum that describes the state of a Model Monitoring Job."
  signature: 'def state(self) -> google.cloud.aiplatform.compat.types.job_state_v1beta1.JobState:'
- rank: 3211
  id: vertexai.resources.preview.ml_monitoring.spec
  name: spec
  file_path: env/lib/python3.13/site-packages/vertexai/resources/preview/ml_monitoring/spec/__init__.py
  type: MODULE
  group: Orphan
  usage_score: 0
- rank: 3212
  id: vertexai.resources.preview.ml_monitoring.spec.notification
  name: notification
  file_path: env/lib/python3.13/site-packages/vertexai/resources/preview/ml_monitoring/spec/notification.py
  type: MODULE
  group: Orphan
  usage_score: 0
- rank: 3213
  id: vertexai.resources.preview.ml_monitoring.spec.notification.NotificationSpec
  name: NotificationSpec
  file_path: env/lib/python3.13/site-packages/vertexai/resources/preview/ml_monitoring/spec/notification.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: "Initializer for NotificationSpec.\n\nArgs:\n    user_emails (List[str]):\n        Optional. The email addresses to send the alert to.\n    notification_channels (List[str]):\n        Optional. The notification channels to send the alert to.\n        Format: ``projects/{project}/notificationChannels/{channel}``\n    enable_cloud_logging (bool):\n        Optional. If dump the anomalies to Cloud Logging. The anomalies will\n        be put to json payload. This can be further sinked to Pub/Sub or any\n        other services supported by Cloud Logging."
  constructor_signature: 'def __init__(self, user_emails: typing.Optional[typing.List[str]], notification_channels: typing.Optional[typing.List[str]], enable_cloud_logging: typing.Optional[bool]):'
  aliases:
  - vertexai.resources.preview.ml_monitoring.spec.NotificationSpec
- rank: 3214
  id: vertexai.resources.preview.ml_monitoring.spec.notification.NotificationSpec.__init__
  name: __init__
  file_path: env/lib/python3.13/site-packages/vertexai/resources/preview/ml_monitoring/spec/notification.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def __init__(self, user_emails: typing.Optional[typing.List[str]], notification_channels: typing.Optional[typing.List[str]], enable_cloud_logging: typing.Optional[bool]):'
- rank: 3215
  id: vertexai.resources.preview.ml_monitoring.spec.objective
  name: objective
  file_path: env/lib/python3.13/site-packages/vertexai/resources/preview/ml_monitoring/spec/objective.py
  type: MODULE
  group: Orphan
  usage_score: 0
- rank: 3216
  id: vertexai.resources.preview.ml_monitoring.spec.objective.DataDriftSpec
  name: DataDriftSpec
  file_path: env/lib/python3.13/site-packages/vertexai/resources/preview/ml_monitoring/spec/objective.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: "Data drift monitoring spec.\n\nData drift measures the distribution distance between the current dataset\nand a baseline dataset. A typical use case is to detect data drift between\nthe recent production serving dataset and the training dataset, or to\ncompare the recent production dataset with a dataset from a previous period.\n\nExample:\n    feature_drift_spec=DataDriftSpec(\n            features=[\"feature1\"]\n            categorical_metric_type=\"l_infinity\",\n            numeric_metric_type=\"jensen_shannon_divergence\",\n            default_categorical_alert_threshold=0.01,\n            default_numeric_alert_threshold=0.02,\n            feature_alert_thresholds={\"feature1\":0.02, \"feature2\":0.01},\n    )\n\nAttributes:\n    features (List[str]):\n        Optional. Feature names / Prediction output names interested in\n        monitoring. These should be a subset of the input feature names or\n        prediction output names specified in the monitoring schema.\n\
    \        If not specified, all features / prediction outputs outlied in the\n        monitoring schema will be used.\n    categorical_metric_type (str):\n        Optional. Supported metrics type: l_infinity, jensen_shannon_divergence\n    numeric_metric_type (str):\n        Optional. Supported metrics type: jensen_shannon_divergence\n    default_categorical_alert_threshold (float):\n        Optional. Default alert threshold for all the categorical features.\n    default_numeric_alert_threshold (float):\n        Optional. Default alert threshold for all the numeric features.\n    feature_alert_thresholds (Dict[str, float]):\n        Optional. Per feature alert threshold will override default alert\n        threshold."
  constructor_signature: 'def __init__(self, features: typing.Optional[typing.List[str]], categorical_metric_type: typing.Optional[str], numeric_metric_type: typing.Optional[str], default_categorical_alert_threshold: typing.Optional[float], default_numeric_alert_threshold: typing.Optional[float], feature_alert_thresholds: typing.Optional[typing.Dict[str, float]]):'
  aliases:
  - vertexai.resources.preview.ml_monitoring.spec.DataDriftSpec
- rank: 3217
  id: vertexai.resources.preview.ml_monitoring.spec.objective.DataDriftSpec.__init__
  name: __init__
  file_path: env/lib/python3.13/site-packages/vertexai/resources/preview/ml_monitoring/spec/objective.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def __init__(self, features: typing.Optional[typing.List[str]], categorical_metric_type: typing.Optional[str], numeric_metric_type: typing.Optional[str], default_categorical_alert_threshold: typing.Optional[float], default_numeric_alert_threshold: typing.Optional[float], feature_alert_thresholds: typing.Optional[typing.Dict[str, float]]):'
- rank: 3218
  id: vertexai.resources.preview.ml_monitoring.spec.objective.FeatureAttributionSpec
  name: FeatureAttributionSpec
  file_path: env/lib/python3.13/site-packages/vertexai/resources/preview/ml_monitoring/spec/objective.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: "Feature attribution spec.\n\nExample:\n    feature_attribution_spec=FeatureAttributionSpec(\n            features=[\"feature1\"]\n            default_alert_threshold=0.01,\n            feature_alert_thresholds={\"feature1\":0.02, \"feature2\":0.01},\n            batch_dedicated_resources=BatchDedicatedResources(\n                starting_replica_count=1,\n                max_replica_count=2,\n                machine_spec=my_machine_spec,\n            ),\n    )\n\nAttributes:\n    features (List[str]):\n        Optional. Input feature names interested in monitoring. These should\n        be a subset of the input feature names specified in the monitoring\n        schema.\n        If not specified, all features outlied in the monitoring schema will\n        be used.\n    default_alert_threshold (float):\n        Optional. Default alert threshold for all the features.\n    feature_alert_thresholds (Dict[str, float]):\n        Optional. Per feature alert threshold will override\
    \ default alert\n        threshold.\n    batch_dedicated_resources (machine_resources.BatchDedicatedResources):\n        Optional. The config of resources used by the Model Monitoring during\n        the batch explanation for non-AutoML models. If not set, `n1-standard-2`\n        machine type will be used by default."
  constructor_signature: 'def __init__(self, features: typing.Optional[typing.List[str]], default_alert_threshold: typing.Optional[float], feature_alert_thresholds: typing.Optional[typing.Dict[str, float]], batch_dedicated_resources: typing.Optional[google.cloud.aiplatform.compat.types.machine_resources_v1beta1.BatchDedicatedResources]):'
  aliases:
  - vertexai.resources.preview.ml_monitoring.spec.FeatureAttributionSpec
- rank: 3219
  id: vertexai.resources.preview.ml_monitoring.spec.objective.FeatureAttributionSpec.__init__
  name: __init__
  file_path: env/lib/python3.13/site-packages/vertexai/resources/preview/ml_monitoring/spec/objective.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def __init__(self, features: typing.Optional[typing.List[str]], default_alert_threshold: typing.Optional[float], feature_alert_thresholds: typing.Optional[typing.Dict[str, float]], batch_dedicated_resources: typing.Optional[google.cloud.aiplatform.compat.types.machine_resources_v1beta1.BatchDedicatedResources]):'
- rank: 3220
  id: vertexai.resources.preview.ml_monitoring.spec.objective.MonitoringInput
  name: MonitoringInput
  file_path: env/lib/python3.13/site-packages/vertexai/resources/preview/ml_monitoring/spec/objective.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: "Model monitoring data input spec.\n\nAttributes:\n    vertex_dataset (str):\n        Optional. Resource name of the Vertex AI managed dataset.\n        Format: ``projects/{project}/locations/{location}/datasets/{dataset}``\n        At least one source of dataset should be provided, and if one of the\n        fields is set, no need to set other sources\n        (vertex_dataset, gcs_uri, table_uri, query, batch_prediction_job,\n        endpoints).\n    gcs_uri (str):\n        Optional. Google Cloud Storage URI to the input file(s). May contain\n        wildcards.\n    data_format (str):\n        Optional. Data format of Google Cloud Storage file(s). Should be\n        provided if a gcs_uri is set.\n        Supported formats:\n            \"csv\", \"jsonl\", \"tf-record\"\n    table_uri (str):\n        Optonal. BigQuery URI to a table, up to 2000 characters long.\n        All the columns in the table will be selected. Accepted forms:\n\n        -  BigQuery path. For example:\n\
    \            ``bq://projectId.bqDatasetId.bqTableId``.\n    query (str):\n        Optional. Standard SQL for BigQuery to be used instead of the\n        ``table_uri``.\n    timestamp_field (str):\n        Optional. The timestamp field in the dataset.\n        the ``timestamp_field`` must be specified if you'd like to use\n        ``start_time``, ``end_time``, ``offset`` or ``window``.\n        If you use ``query`` to specify the dataset, make sure the\n        ``timestamp_field`` is in the selection fields.\n    batch_prediction_job (str):\n        Optional. Vertex AI Batch Prediction Job resource name.\n        Format: ``projects/{project}/locations/{location}/batchPredictionJobs/{batch_prediction_job}``\n    endpoints (List[str]):\n        Optional. List of Vertex AI Endpoint resource names.\n        Format: ``projects/{project}/locations/{location}/endpoints/{endpoint}``\n    start_time (timestamp_pb2.Timestamp):\n        Optional. Inclusive start of the time interval for which results\n\
    \        should be returned. Should be set together with ``end_time``.\n    end_time (timestamp_pb2.Timestamp):\n        Optional. Exclusive end of the time interval for which results\n        should be returned. Should be set together with ``start_time`.`\n    offset (str):\n        Optional. Offset is the time difference from the cut-off time.\n        For scheduled jobs, the cut-off time is the scheduled time.\n        For non-scheduled jobs, it's the time when the job was created.\n        Currently we support the following format:\n        'w|W': Week, 'd|D': Day, 'h|H': Hour\n        E.g. '1h' stands for 1 hour, '2d' stands for 2 days.\n    window (str):\n        Optional. Window refers to the scope of data selected for analysis.\n        It allows you to specify the quantity of data you wish to examine.\n        It refers to the data time window prior to the cut-off time or the\n        cut-off time minus the offset.\n        Currently we support the following format:\n      \
    \  'w|W': Week, 'd|D': Day, 'h|H': Hour\n        E.g. '1h' stands for 1 hour, '2d' stands for 2 days."
  constructor_signature: 'def __init__(self, vertex_dataset: typing.Optional[str], gcs_uri: typing.Optional[str], data_format: typing.Optional[str], table_uri: typing.Optional[str], query: typing.Optional[str], timestamp_field: typing.Optional[str], batch_prediction_job: typing.Optional[str], endpoints: typing.Optional[typing.List[str]], start_time: typing.Optional[google.protobuf.timestamp_pb2.Timestamp], end_time: typing.Optional[google.protobuf.timestamp_pb2.Timestamp], offset: typing.Optional[str], window: typing.Optional[str]):'
  aliases:
  - vertexai.resources.preview.ml_monitoring.spec.MonitoringInput
- rank: 3221
  id: vertexai.resources.preview.ml_monitoring.spec.objective.MonitoringInput.__init__
  name: __init__
  file_path: env/lib/python3.13/site-packages/vertexai/resources/preview/ml_monitoring/spec/objective.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def __init__(self, vertex_dataset: typing.Optional[str], gcs_uri: typing.Optional[str], data_format: typing.Optional[str], table_uri: typing.Optional[str], query: typing.Optional[str], timestamp_field: typing.Optional[str], batch_prediction_job: typing.Optional[str], endpoints: typing.Optional[typing.List[str]], start_time: typing.Optional[google.protobuf.timestamp_pb2.Timestamp], end_time: typing.Optional[google.protobuf.timestamp_pb2.Timestamp], offset: typing.Optional[str], window: typing.Optional[str]):'
- rank: 3222
  id: vertexai.resources.preview.ml_monitoring.spec.objective.ObjectiveSpec
  name: ObjectiveSpec
  file_path: env/lib/python3.13/site-packages/vertexai/resources/preview/ml_monitoring/spec/objective.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: "Initializer for ObjectiveSpec.\n\nArgs:\n    baseline_dataset (MonitoringInput):\n        Required. Baseline datasets that are used by all the monitoring\n        objectives. It could be the training dataset or production serving\n        dataset from a previous period.\n    target_dataset (MonitoringInput):\n        Required. Target dataset for monitoring analysis, it's used by all\n        the monitoring objectives.\n    tabular_objective (TabularObjective):\n        Optional. The tabular monitoring objective.\n    explanation_spec (explanation.ExplanationSpec):\n        Optional. The explanation spec. This spec is required when the\n        objectives spec includes feature attribution objectives."
  constructor_signature: 'def __init__(self, baseline_dataset: vertexai.resources.preview.ml_monitoring.spec.objective.MonitoringInput, target_dataset: vertexai.resources.preview.ml_monitoring.spec.objective.MonitoringInput, tabular_objective: typing.Optional[vertexai.resources.preview.ml_monitoring.spec.objective.TabularObjective], explanation_spec: typing.Optional[google.cloud.aiplatform.compat.types.explanation_v1beta1.ExplanationSpec]):'
  aliases:
  - vertexai.resources.preview.ml_monitoring.spec.ObjectiveSpec
- rank: 3223
  id: vertexai.resources.preview.ml_monitoring.spec.objective.ObjectiveSpec.__init__
  name: __init__
  file_path: env/lib/python3.13/site-packages/vertexai/resources/preview/ml_monitoring/spec/objective.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def __init__(self, baseline_dataset: vertexai.resources.preview.ml_monitoring.spec.objective.MonitoringInput, target_dataset: vertexai.resources.preview.ml_monitoring.spec.objective.MonitoringInput, tabular_objective: typing.Optional[vertexai.resources.preview.ml_monitoring.spec.objective.TabularObjective], explanation_spec: typing.Optional[google.cloud.aiplatform.compat.types.explanation_v1beta1.ExplanationSpec]):'
- rank: 3224
  id: vertexai.resources.preview.ml_monitoring.spec.objective.TabularObjective
  name: TabularObjective
  file_path: env/lib/python3.13/site-packages/vertexai/resources/preview/ml_monitoring/spec/objective.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: "Initializer for TabularObjective.\n\nAttributes:\n    feature_drift_spec (DataDriftSpec):\n        Optional. Input feature distribution drift monitoring spec.\n    prediction_output_drift_spec (DataDriftSpec):\n        Optional. Prediction output distribution drift monitoring spec.\n    feature_attribution_spec (FeatureAttributionSpec):\n        Optional. Feature attribution monitoring spec."
  constructor_signature: 'def __init__(self, feature_drift_spec: typing.Optional[vertexai.resources.preview.ml_monitoring.spec.objective.DataDriftSpec], prediction_output_drift_spec: typing.Optional[vertexai.resources.preview.ml_monitoring.spec.objective.DataDriftSpec], feature_attribution_spec: typing.Optional[vertexai.resources.preview.ml_monitoring.spec.objective.FeatureAttributionSpec]):'
  aliases:
  - vertexai.resources.preview.ml_monitoring.spec.TabularObjective
- rank: 3225
  id: vertexai.resources.preview.ml_monitoring.spec.objective.TabularObjective.__init__
  name: __init__
  file_path: env/lib/python3.13/site-packages/vertexai/resources/preview/ml_monitoring/spec/objective.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def __init__(self, feature_drift_spec: typing.Optional[vertexai.resources.preview.ml_monitoring.spec.objective.DataDriftSpec], prediction_output_drift_spec: typing.Optional[vertexai.resources.preview.ml_monitoring.spec.objective.DataDriftSpec], feature_attribution_spec: typing.Optional[vertexai.resources.preview.ml_monitoring.spec.objective.FeatureAttributionSpec]):'
- rank: 3226
  id: vertexai.resources.preview.ml_monitoring.spec.output
  name: output
  file_path: env/lib/python3.13/site-packages/vertexai/resources/preview/ml_monitoring/spec/output.py
  type: MODULE
  group: Orphan
  usage_score: 0
- rank: 3227
  id: vertexai.resources.preview.ml_monitoring.spec.output.OutputSpec
  name: OutputSpec
  file_path: env/lib/python3.13/site-packages/vertexai/resources/preview/ml_monitoring/spec/output.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: "Initializer for OutputSpec.\n\nArgs:\n    data_source (str):\n        Optional. Google Cloud Storage base folder path for metrics, error\n        logs, etc."
  constructor_signature: 'def __init__(self, gcs_base_dir: str):'
- rank: 3228
  id: vertexai.resources.preview.ml_monitoring.spec.output.OutputSpec.__init__
  name: __init__
  file_path: env/lib/python3.13/site-packages/vertexai/resources/preview/ml_monitoring/spec/output.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def __init__(self, gcs_base_dir: str):'
- rank: 3229
  id: vertexai.resources.preview.ml_monitoring.spec.schema
  name: schema
  file_path: env/lib/python3.13/site-packages/vertexai/resources/preview/ml_monitoring/spec/schema.py
  type: MODULE
  group: Orphan
  usage_score: 0
  methods:
  - signature: 'def transform_schema_from_bigquery(feature_fields: typing.Optional[typing.List[str]], ground_truth_fields: typing.Optional[typing.List[str]], prediction_fields: typing.Optional[typing.List[str]], table: typing.Optional[str], query: typing.Optional[str]) -> vertexai.resources.preview.ml_monitoring.spec.schema.ModelMonitoringSchema:'
    docstring: "Transform the existing dataset to ModelMonitoringSchema as model monitor\ncould accept.\n\nArgs:\n    feature_fields (List[str]):\n        Optional. The input feature fields for given dataset.\n        By default all features we find would be the input features.\n    ground_truth_fields (List[str]):\n        Optional. The ground truth fields for given dataset.\n        By default all features we find would be the input features.\n    prediction_fields (List[str]):\n        Optional. The prediction output field for given dataset.\n        By default all features we find would be the input features.\n    table (str):\n        Optional. The BigQuery table uri.\n    query (str):\n        Optional. The BigQuery query."
  - signature: 'def transform_schema_from_csv(file_path: str, feature_fields: typing.Optional[typing.List[str]], ground_truth_fields: typing.Optional[typing.List[str]], prediction_fields: typing.Optional[typing.List[str]]) -> vertexai.resources.preview.ml_monitoring.spec.schema.ModelMonitoringSchema:'
    docstring: "Transform the existing dataset to ModelMonitoringSchema as model monitor could accept.\n\nArgs:\n    file_path (str):\n        Required. The dataset file path.\n    feature_fields (List[str]):\n        Optional. The input feature fields for given dataset.\n        By default all features we find would be the input features.\n    ground_truth_fields (List[str]):\n        Optional. The ground truth fields for given dataset.\n        By default all features we find would be the input features.\n    prediction_fields (List[str]):s\n        Optional. The prediction output field for given dataset.\n        By default all features we find would be the input features."
  - signature: 'def transform_schema_from_json(file_path: str, feature_fields: typing.Optional[typing.List[str]], ground_truth_fields: typing.Optional[typing.List[str]], prediction_fields: typing.Optional[typing.List[str]]) -> vertexai.resources.preview.ml_monitoring.spec.schema.ModelMonitoringSchema:'
    docstring: "Transform the existing dataset to ModelMonitoringSchema as model monitor\ncould accept.\n\nArgs:\n    file_path (str):\n        Required. The dataset file path.\n    feature_fields (List[str]):\n        Optional. The input feature fields for given dataset.\n        By default all features we find would be the input features.\n    ground_truth_fields (List[str]):\n        Optional. The ground truth fields for given dataset.\n        By default all features we find would be the input features.\n    prediction_fields (List[str]):\n        Optional. The prediction output field for given dataset.\n        By default all features we find would be the input features."
- rank: 3230
  id: vertexai.resources.preview.ml_monitoring.spec.schema.FieldSchema
  name: FieldSchema
  file_path: env/lib/python3.13/site-packages/vertexai/resources/preview/ml_monitoring/spec/schema.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: "Field Schema.\n\nThe class identifies the data type of a single feature,\nwhich combines together to form the Schema for different fields in\nModelMonitoringSchema.\n\nAttributes:\n    name (str):\n        Required. Field name.\n    data_type (str):\n        Required. Supported data types are: ``float``, ``integer``\n        ``boolean``, ``string``, ``categorical``.\n    repeated (bool):\n        Optional. Describes if the schema field is an array of given data\n        type."
  constructor_signature: 'def __init__(self, name: str, data_type: str, repeated: typing.Optional[bool]):'
- rank: 3231
  id: vertexai.resources.preview.ml_monitoring.spec.schema.FieldSchema.__init__
  name: __init__
  file_path: env/lib/python3.13/site-packages/vertexai/resources/preview/ml_monitoring/spec/schema.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def __init__(self, name: str, data_type: str, repeated: typing.Optional[bool]):'
- rank: 3232
  id: vertexai.resources.preview.ml_monitoring.spec.schema.ModelMonitoringSchema
  name: ModelMonitoringSchema
  file_path: env/lib/python3.13/site-packages/vertexai/resources/preview/ml_monitoring/spec/schema.py
  type: CLASS
  group: Orphan
  usage_score: 0
  docstring: "Initializer for ModelMonitoringSchema.\n\nArgs:\n    feature_fields (MutableSequence[FieldSchema]):\n        Required. Feature names of the model. Vertex AI will try to match\n        the features from your dataset as follows:\n        * For 'csv' files, the header names are required, and we will\n          extract thecorresponding feature values when the header names\n          align with the feature names.\n        * For 'jsonl' files, we will extract the corresponding feature\n          values if the key names match the feature names. Note: Nested\n          features are not supported, so please ensure your features are\n          flattened. Ensure the feature values are scalar or an array of\n          scalars.\n        * For 'bigquery' dataset, we will extract the corresponding feature\n          values if the column names match the feature names.\n          Note: The column type can be a scalar or an array of scalars.\n          STRUCT or JSON types are not supported.\
    \ You may use SQL queries to\n          select or aggregate the relevant features from your original\n          table. However, ensure that the 'schema' of the query results\n          meets our requirements.\n        * For the Vertex AI Endpoint Request Response Logging table or\n          Vertex AI Batch Prediction Job results. If the prediction\n          instance format is an array, ensure that the sequence in\n          ``feature_fields`` matches the order of features in the prediction\n          instance. We will match the feature with the array in the order\n          specified in ``feature_fields``.\n    prediction_fields (MutableSequence[FieldSchema]):\n        Optional. Prediction output names of the model. The requirements are\n        the same as the ``feature_fields``.\n        For AutoML Tables, the prediction output name presented in schema\n        will be: `predicted_{target_column}`, the `target_column` is the one\n        you specified when you train the model.\n \
    \       For Prediction output drift analysis:\n        * AutoML Classification, the distribution of the argmax label will\n          be analyzed.\n        * AutoML Regression, the distribution of the value will be analyzed.\n    ground_truth_fields (MutableSequence[FieldSchema]):\n        Optional. Target /ground truth names of the model."
  constructor_signature: 'def __init__(self, feature_fields: typing.MutableSequence[vertexai.resources.preview.ml_monitoring.spec.schema.FieldSchema], ground_truth_fields: typing.Optional[typing.MutableSequence[vertexai.resources.preview.ml_monitoring.spec.schema.FieldSchema]], prediction_fields: typing.Optional[typing.MutableSequence[vertexai.resources.preview.ml_monitoring.spec.schema.FieldSchema]]):'
  methods:
  - signature: 'def to_json(self, output_dir: typing.Optional[str]) -> str:'
    docstring: "Transform ModelMonitoringSchema to json format.\n\nArgs:\n    output_dir (str):\n        Optional. The output directory that the transformed json file\n        would be put into."
- rank: 3233
  id: vertexai.resources.preview.ml_monitoring.spec.schema.ModelMonitoringSchema.__init__
  name: __init__
  file_path: env/lib/python3.13/site-packages/vertexai/resources/preview/ml_monitoring/spec/schema.py
  type: METHOD
  group: Orphan
  usage_score: 0
  signature: 'def __init__(self, feature_fields: typing.MutableSequence[vertexai.resources.preview.ml_monitoring.spec.schema.FieldSchema], ground_truth_fields: typing.Optional[typing.MutableSequence[vertexai.resources.preview.ml_monitoring.spec.schema.FieldSchema]], prediction_fields: typing.Optional[typing.MutableSequence[vertexai.resources.preview.ml_monitoring.spec.schema.FieldSchema]]):'
- rank: 3234
  id: vertexai.resources.preview.ml_monitoring.spec.schema.ModelMonitoringSchema.to_json
  name: to_json
  file_path: env/lib/python3.13/site-packages/vertexai/resources/preview/ml_monitoring/spec/schema.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Transform ModelMonitoringSchema to json format.\n\nArgs:\n    output_dir (str):\n        Optional. The output directory that the transformed json file\n        would be put into."
  signature: 'def to_json(self, output_dir: typing.Optional[str]) -> str:'
- rank: 3235
  id: vertexai.resources.preview.ml_monitoring.spec.schema.transform_schema_from_bigquery
  name: transform_schema_from_bigquery
  file_path: env/lib/python3.13/site-packages/vertexai/resources/preview/ml_monitoring/spec/schema.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Transform the existing dataset to ModelMonitoringSchema as model monitor\ncould accept.\n\nArgs:\n    feature_fields (List[str]):\n        Optional. The input feature fields for given dataset.\n        By default all features we find would be the input features.\n    ground_truth_fields (List[str]):\n        Optional. The ground truth fields for given dataset.\n        By default all features we find would be the input features.\n    prediction_fields (List[str]):\n        Optional. The prediction output field for given dataset.\n        By default all features we find would be the input features.\n    table (str):\n        Optional. The BigQuery table uri.\n    query (str):\n        Optional. The BigQuery query."
  signature: 'def transform_schema_from_bigquery(feature_fields: typing.Optional[typing.List[str]], ground_truth_fields: typing.Optional[typing.List[str]], prediction_fields: typing.Optional[typing.List[str]], table: typing.Optional[str], query: typing.Optional[str]) -> vertexai.resources.preview.ml_monitoring.spec.schema.ModelMonitoringSchema:'
- rank: 3236
  id: vertexai.resources.preview.ml_monitoring.spec.schema.transform_schema_from_csv
  name: transform_schema_from_csv
  file_path: env/lib/python3.13/site-packages/vertexai/resources/preview/ml_monitoring/spec/schema.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Transform the existing dataset to ModelMonitoringSchema as model monitor could accept.\n\nArgs:\n    file_path (str):\n        Required. The dataset file path.\n    feature_fields (List[str]):\n        Optional. The input feature fields for given dataset.\n        By default all features we find would be the input features.\n    ground_truth_fields (List[str]):\n        Optional. The ground truth fields for given dataset.\n        By default all features we find would be the input features.\n    prediction_fields (List[str]):s\n        Optional. The prediction output field for given dataset.\n        By default all features we find would be the input features."
  signature: 'def transform_schema_from_csv(file_path: str, feature_fields: typing.Optional[typing.List[str]], ground_truth_fields: typing.Optional[typing.List[str]], prediction_fields: typing.Optional[typing.List[str]]) -> vertexai.resources.preview.ml_monitoring.spec.schema.ModelMonitoringSchema:'
- rank: 3237
  id: vertexai.resources.preview.ml_monitoring.spec.schema.transform_schema_from_json
  name: transform_schema_from_json
  file_path: env/lib/python3.13/site-packages/vertexai/resources/preview/ml_monitoring/spec/schema.py
  type: METHOD
  group: Orphan
  usage_score: 0
  docstring: "Transform the existing dataset to ModelMonitoringSchema as model monitor\ncould accept.\n\nArgs:\n    file_path (str):\n        Required. The dataset file path.\n    feature_fields (List[str]):\n        Optional. The input feature fields for given dataset.\n        By default all features we find would be the input features.\n    ground_truth_fields (List[str]):\n        Optional. The ground truth fields for given dataset.\n        By default all features we find would be the input features.\n    prediction_fields (List[str]):\n        Optional. The prediction output field for given dataset.\n        By default all features we find would be the input features."
  signature: 'def transform_schema_from_json(file_path: str, feature_fields: typing.Optional[typing.List[str]], ground_truth_fields: typing.Optional[typing.List[str]], prediction_fields: typing.Optional[typing.List[str]]) -> vertexai.resources.preview.ml_monitoring.spec.schema.ModelMonitoringSchema:'
- rank: 3238
  id: vertexai.tuning
  name: tuning
  file_path: env/lib/python3.13/site-packages/vertexai/tuning/__init__.py
  type: MODULE
  group: Orphan
  usage_score: 0
  docstring: Classes for tuning models.
- rank: 3239
  id: vertexai.tuning.sft
  name: sft
  file_path: env/lib/python3.13/site-packages/vertexai/tuning/sft.py
  type: MODULE
  group: Orphan
  usage_score: 0
  docstring: Classes for supervised tuning.
- rank: 3240
  id: vertexai.vision_models
  name: vision_models
  file_path: env/lib/python3.13/site-packages/vertexai/vision_models/__init__.py
  type: MODULE
  group: Orphan
  usage_score: 0
  docstring: Classes for working with vision models.
